From rmh at temple.edu  Wed Jun  1 00:12:02 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 31 May 2016 18:12:02 -0400
Subject: [R] Searching for antilog function
In-Reply-To: <BLU436-SMTP1727A2BB2DBF0627C8FA469DF460@phx.gbl>
References: <loom.20041125T051716-875@post.gmane.org>
	<BLU436-SMTP1727A2BB2DBF0627C8FA469DF460@phx.gbl>
Message-ID: <CAGx1TMDX3d7A3jta-uCYnER72J_g+FN8PFHh_rZqxyMaYAGT1A@mail.gmail.com>

Use power

> log(78,10)
[1] 1.892095
> 10^log(78,10)
[1] 78

On Tue, May 31, 2016 at 4:14 PM, Carlos <arnobras at hotmail.com> wrote:
> The following function can do the work as well
>
>  antilog<-function(lx,base)
>  {
>  lbx<-lx/log(exp(1),base=base)
>  result<-exp(lbx)
>  result
>  }
>
> This solution is based on the change of base formula which states that :
>
> log (x,base=b) = log(x,base=a)/log(b,base=a)
>
> The original logarithm is changed into natural logarithm and then the
> exponential function is employed
>
> The arguments are:
>
> 'lx', de logarithm we have.
> 'base', the base what was employed to obtain lx
>
> For example:
>
> log(78,10) = 1.892095
>
> Then the antllog is
>
> antilog(1.892095,10)
>
> 78
>
> As expected.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jun  1 02:56:48 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 1 Jun 2016 10:56:48 +1000
Subject: [R] Variable labels and value labels
In-Reply-To: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
References: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
Message-ID: <CA+8X3fU=nenzXRJy1GyWMFe8Dx6Qf-LKy2BMFYusrT9by_HF9A@mail.gmail.com>

Hi Georg,
You may find the "add.value.labels" function in the prettyR package useful.

Jim

On Tue, May 31, 2016 at 10:00 PM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I am using R for social sciences. In this field I am used to use short
> variable names like "q1" for question 1, "q2" for question 2 and so on and
> label the variables like q1 : "Please tell us your age" or q2 : "Could you
> state us your household income?" or something similar indicating which
> question is stored in the variable.
>
> Similar I am used to label values like 1: "Less than 18 years", 2 : "18 to
> 30 years", 3 : "31 to 60 years" and 4 : "61 years and more".
>
> I know that the packages Hmisc and memisc have a functionality for this
> but these labeling functions are limited to the packages they were defined
> for. Using the question tests as variable names is possible but very
> inconvenient.
>
> I there another way for labeling variables and values in R?
>
> Kind regards
>
> Georg Maubach
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Wed Jun  1 03:26:31 2016
From: valkremk at gmail.com (Val)
Date: Tue, 31 May 2016 20:26:31 -0500
Subject: [R] Extract from a text file
In-Reply-To: <alpine.BSF.2.00.1605302239170.3513@pedal.dcn.davis.ca.us>
References: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>
	<alpine.BSF.2.00.1605302239170.3513@pedal.dcn.davis.ca.us>
Message-ID: <CAJOiR6aC1sHOTi-_rB2CXVd2ZuqAiVNyfJw=_Khjwh8OU-rUBA@mail.gmail.com>

Thank you so much Jeff. It worked for this example.

When I read it from a file (c:\data\test.txt) it did not work

KLEM="c:\data"
KR=paste(KLEM,"\test.txt",sep="")
indta <- readLines(KR, skip=46)  # not interested in the first 46 lines)

pattern <- "^.*group (\\d+)[^:]*: *([-+0-9.eE]*).*$"
firstlines <- grep( pattern, indta )
# Replace the matched portion (entire string) with the first capture # string
v1 <- as.numeric( sub( pattern, "\\1", indta[ firstlines ] ) )
# Replace the matched portion (entire string) with the second capture # string
v2 <- as.numeric( sub( pattern, "\\2", indta[ firstlines ] ) )
# Convert the lines just after the first lines to numeric
v3 <- as.numeric( indta[ firstlines + 1 ] )
# put it all into a data frame
result <- data.frame( Group = v1, Mean = v2, SE = v3 )

result
[1] Group Mean  SE
<0 rows> (or 0-length row.names)

Thank you in advance


On Tue, May 31, 2016 at 1:12 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Please learn to post in plain text (the setting is in your email client...
> somewhere), as HTML is "What We See Is Not What You Saw" on this mailing
> list.  In conjunction with that, try reading some of the fine material
> mentioned in the Posting Guide about making reproducible examples like this
> one:
>
> # You could read in a file
> # indta <- readLines( "out.txt" )
> # but there is no "current directory" in an email
> # so here I have used the dput() function to make source code
> # that creates a self-contained R object
>
> indta <- c(
> "Mean of weight  group 1, SE of mean  :  72.289037489555276",
> " 11.512956539215610",
> "Average weight of group 2, SE of Mean :  83.940053900595013",
> "  10.198495690144522",
> "group 3 mean , SE of Mean     :                78.310441258245469",
> " 13.015876679555",
> "Mean of weight of group 4, SE of Mean               : 76.967516495101669",
> " 12.1254882985", "")
>
> # Regular expression patterns are discussed all over the internet
> # in many places OTHER than R
> # You can start with ?regex, but there are many fine tutorials also
>
> pattern <- "^.*group (\\d+)[^:]*: *([-+0-9.eE]*).*$"
> # For this task the regex has to match the whole "first line" of each set
> #  ^ =match starting at the beginning of the string
> #  .* =any character, zero or more times
> #  "group " =match these characters
> #  ( =first capture string starts here
> #  \\d = any digit (first backslash for R, second backslash for regex)
> #  + =one or more of the preceding (any digit)
> #  ) =end of first capture string
> #  [^:] =any non-colon character
> #  * =zero or more of the preceding (non-colon character)
> #  : =match a colon exactly
> #  " *" =match zero or more spaces
> #  ( =second capture string starts here
> #  [ =start of a set of equally acceptable characters
> #  -+ =either of these characters are acceptable
> #  0-9 =any digit would be acceptable
> #  . =a period is acceptable (this is inside the [])
> #  eE =in case you get exponential notation input
> #  ] =end of the set of acceptable characters (number)
> #  * =number of acceptable characters can be zero or more
> #  ) =second capture string stops here
> #  .* =zero or more of any character (just in case)
> #  $ =at end of pattern, requires that the match reach the end
> #     of the string
>
> # identify indexes of strings that match the pattern
> firstlines <- grep( pattern, indta )
> # Replace the matched portion (entire string) with the first capture #
> string
> v1 <- as.numeric( sub( pattern, "\\1", indta[ firstlines ] ) )
> # Replace the matched portion (entire string) with the second capture #
> string
> v2 <- as.numeric( sub( pattern, "\\2", indta[ firstlines ] ) )
> # Convert the lines just after the first lines to numeric
> v3 <- as.numeric( indta[ firstlines + 1 ] )
> # put it all into a data frame
> result <- data.frame( Group = v1, Mean = v2, SE = v3 )
>
> Figuring out how to deliver your result (output) is a separate question that
> depends where you want it to go.
>
>
> On Mon, 30 May 2016, Val wrote:
>
>> Hi all,
>>
>> I have a messy text file and from this text file I want extract some
>> information
>> here is the text file (out.txt).  One record has tow lines. The mean comes
>> in the first line and the SE of the mean is on the second line. Here is
>> the
>> sample of the data.
>>
>> Mean of weight  group 1, SE of mean  :  72.289037489555276
>> 11.512956539215610
>> Average weight of group 2, SE of Mean :  83.940053900595013
>>  10.198495690144522
>> group 3 mean , SE of Mean     :                78.310441258245469
>> 13.015876679555
>> Mean of weight of group 4, SE of Mean               : 76.967516495101669
>> 12.1254882985
>>
>> I want produce the following  table. How do i read it first and then
>> produce a
>>
>>
>> Gr1  72.289037489555276   11.512956539215610
>> Gr2  83.940053900595013   10.198495690144522
>> Gr3  78.310441258245469   13.015876679555
>> Gr4  76.967516495101669   12.1254882985
>>
>>
>> Thank you in advance
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From jdnewmil at dcn.davis.ca.us  Wed Jun  1 04:05:39 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 31 May 2016 19:05:39 -0700
Subject: [R] Extract from a text file
In-Reply-To: <CAJOiR6aC1sHOTi-_rB2CXVd2ZuqAiVNyfJw=_Khjwh8OU-rUBA@mail.gmail.com>
References: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>
	<alpine.BSF.2.00.1605302239170.3513@pedal.dcn.davis.ca.us>
	<CAJOiR6aC1sHOTi-_rB2CXVd2ZuqAiVNyfJw=_Khjwh8OU-rUBA@mail.gmail.com>
Message-ID: <D6AF5A9D-8D7D-4F60-8888-4EEA7973B0A5@dcn.davis.ca.us>

You need to go back and study how I made my solution reproducible and make your problem reproducible. 

You probably also ought to spend some time comparing the regex pattern to your actual data... the point of this list is to learn how to construct these solutions yourself.
-- 
Sent from my phone. Please excuse my brevity.

On May 31, 2016 6:26:31 PM PDT, Val <valkremk at gmail.com> wrote:
>Thank you so much Jeff. It worked for this example.
>
>When I read it from a file (c:\data\test.txt) it did not work
>
>KLEM="c:\data"
>KR=paste(KLEM,"\test.txt",sep="")
>indta <- readLines(KR, skip=46)  # not interested in the first 46
>lines)
>
>pattern <- "^.*group (\\d+)[^:]*: *([-+0-9.eE]*).*$"
>firstlines <- grep( pattern, indta )
># Replace the matched portion (entire string) with the first capture #
>string
>v1 <- as.numeric( sub( pattern, "\\1", indta[ firstlines ] ) )
># Replace the matched portion (entire string) with the second capture #
>string
>v2 <- as.numeric( sub( pattern, "\\2", indta[ firstlines ] ) )
># Convert the lines just after the first lines to numeric
>v3 <- as.numeric( indta[ firstlines + 1 ] )
># put it all into a data frame
>result <- data.frame( Group = v1, Mean = v2, SE = v3 )
>
>result
>[1] Group Mean  SE
><0 rows> (or 0-length row.names)
>
>Thank you in advance
>
>
>On Tue, May 31, 2016 at 1:12 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> Please learn to post in plain text (the setting is in your email
>client...
>> somewhere), as HTML is "What We See Is Not What You Saw" on this
>mailing
>> list.  In conjunction with that, try reading some of the fine
>material
>> mentioned in the Posting Guide about making reproducible examples
>like this
>> one:
>>
>> # You could read in a file
>> # indta <- readLines( "out.txt" )
>> # but there is no "current directory" in an email
>> # so here I have used the dput() function to make source code
>> # that creates a self-contained R object
>>
>> indta <- c(
>> "Mean of weight  group 1, SE of mean  :  72.289037489555276",
>> " 11.512956539215610",
>> "Average weight of group 2, SE of Mean :  83.940053900595013",
>> "  10.198495690144522",
>> "group 3 mean , SE of Mean     :                78.310441258245469",
>> " 13.015876679555",
>> "Mean of weight of group 4, SE of Mean               :
>76.967516495101669",
>> " 12.1254882985", "")
>>
>> # Regular expression patterns are discussed all over the internet
>> # in many places OTHER than R
>> # You can start with ?regex, but there are many fine tutorials also
>>
>> pattern <- "^.*group (\\d+)[^:]*: *([-+0-9.eE]*).*$"
>> # For this task the regex has to match the whole "first line" of each
>set
>> #  ^ =match starting at the beginning of the string
>> #  .* =any character, zero or more times
>> #  "group " =match these characters
>> #  ( =first capture string starts here
>> #  \\d = any digit (first backslash for R, second backslash for
>regex)
>> #  + =one or more of the preceding (any digit)
>> #  ) =end of first capture string
>> #  [^:] =any non-colon character
>> #  * =zero or more of the preceding (non-colon character)
>> #  : =match a colon exactly
>> #  " *" =match zero or more spaces
>> #  ( =second capture string starts here
>> #  [ =start of a set of equally acceptable characters
>> #  -+ =either of these characters are acceptable
>> #  0-9 =any digit would be acceptable
>> #  . =a period is acceptable (this is inside the [])
>> #  eE =in case you get exponential notation input
>> #  ] =end of the set of acceptable characters (number)
>> #  * =number of acceptable characters can be zero or more
>> #  ) =second capture string stops here
>> #  .* =zero or more of any character (just in case)
>> #  $ =at end of pattern, requires that the match reach the end
>> #     of the string
>>
>> # identify indexes of strings that match the pattern
>> firstlines <- grep( pattern, indta )
>> # Replace the matched portion (entire string) with the first capture
>#
>> string
>> v1 <- as.numeric( sub( pattern, "\\1", indta[ firstlines ] ) )
>> # Replace the matched portion (entire string) with the second capture
>#
>> string
>> v2 <- as.numeric( sub( pattern, "\\2", indta[ firstlines ] ) )
>> # Convert the lines just after the first lines to numeric
>> v3 <- as.numeric( indta[ firstlines + 1 ] )
>> # put it all into a data frame
>> result <- data.frame( Group = v1, Mean = v2, SE = v3 )
>>
>> Figuring out how to deliver your result (output) is a separate
>question that
>> depends where you want it to go.
>>
>>
>> On Mon, 30 May 2016, Val wrote:
>>
>>> Hi all,
>>>
>>> I have a messy text file and from this text file I want extract some
>>> information
>>> here is the text file (out.txt).  One record has tow lines. The mean
>comes
>>> in the first line and the SE of the mean is on the second line. Here
>is
>>> the
>>> sample of the data.
>>>
>>> Mean of weight  group 1, SE of mean  :  72.289037489555276
>>> 11.512956539215610
>>> Average weight of group 2, SE of Mean :  83.940053900595013
>>>  10.198495690144522
>>> group 3 mean , SE of Mean     :                78.310441258245469
>>> 13.015876679555
>>> Mean of weight of group 4, SE of Mean               :
>76.967516495101669
>>> 12.1254882985
>>>
>>> I want produce the following  table. How do i read it first and then
>>> produce a
>>>
>>>
>>> Gr1  72.289037489555276   11.512956539215610
>>> Gr2  83.940053900595013   10.198495690144522
>>> Gr3  78.310441258245469   13.015876679555
>>> Gr4  76.967516495101669   12.1254882985
>>>
>>>
>>> Thank you in advance
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jun  1 05:27:36 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 31 May 2016 20:27:36 -0700
Subject: [R] Extract from a text file
In-Reply-To: <D6AF5A9D-8D7D-4F60-8888-4EEA7973B0A5@dcn.davis.ca.us>
References: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>
	<alpine.BSF.2.00.1605302239170.3513@pedal.dcn.davis.ca.us>
	<CAJOiR6aC1sHOTi-_rB2CXVd2ZuqAiVNyfJw=_Khjwh8OU-rUBA@mail.gmail.com>
	<D6AF5A9D-8D7D-4F60-8888-4EEA7973B0A5@dcn.davis.ca.us>
Message-ID: <CAGxFJbTtSUiY+2shT=niGXjDC020vk8_hChwpubYMt0FBRRYTQ@mail.gmail.com>

On Tue, May 31, 2016 at 7:05 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> You need to go back and study how I made my solution reproducible and make your problem reproducible.
>
> You probably also ought to spend some time comparing the regex pattern to your actual data... the point of this list is to learn how to construct these solutions yourself.


Ah, if only that were the case.

(or is that just the grumbling of an old curmudgeon?)

Cheers,
Bert


> --
> Sent from my phone. Please excuse my brevity.
>
> On May 31, 2016 6:26:31 PM PDT, Val <valkremk at gmail.com> wrote:
>>Thank you so much Jeff. It worked for this example.
>>
>>When I read it from a file (c:\data\test.txt) it did not work
>>
>>KLEM="c:\data"
>>KR=paste(KLEM,"\test.txt",sep="")
>>indta <- readLines(KR, skip=46)  # not interested in the first 46
>>lines)
>>
>>pattern <- "^.*group (\\d+)[^:]*: *([-+0-9.eE]*).*$"
>>firstlines <- grep( pattern, indta )
>># Replace the matched portion (entire string) with the first capture #
>>string
>>v1 <- as.numeric( sub( pattern, "\\1", indta[ firstlines ] ) )
>># Replace the matched portion (entire string) with the second capture #
>>string
>>v2 <- as.numeric( sub( pattern, "\\2", indta[ firstlines ] ) )
>># Convert the lines just after the first lines to numeric
>>v3 <- as.numeric( indta[ firstlines + 1 ] )
>># put it all into a data frame
>>result <- data.frame( Group = v1, Mean = v2, SE = v3 )
>>
>>result
>>[1] Group Mean  SE
>><0 rows> (or 0-length row.names)
>>
>>Thank you in advance
>>
>>
>>On Tue, May 31, 2016 at 1:12 AM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> Please learn to post in plain text (the setting is in your email
>>client...
>>> somewhere), as HTML is "What We See Is Not What You Saw" on this
>>mailing
>>> list.  In conjunction with that, try reading some of the fine
>>material
>>> mentioned in the Posting Guide about making reproducible examples
>>like this
>>> one:
>>>
>>> # You could read in a file
>>> # indta <- readLines( "out.txt" )
>>> # but there is no "current directory" in an email
>>> # so here I have used the dput() function to make source code
>>> # that creates a self-contained R object
>>>
>>> indta <- c(
>>> "Mean of weight  group 1, SE of mean  :  72.289037489555276",
>>> " 11.512956539215610",
>>> "Average weight of group 2, SE of Mean :  83.940053900595013",
>>> "  10.198495690144522",
>>> "group 3 mean , SE of Mean     :                78.310441258245469",
>>> " 13.015876679555",
>>> "Mean of weight of group 4, SE of Mean               :
>>76.967516495101669",
>>> " 12.1254882985", "")
>>>
>>> # Regular expression patterns are discussed all over the internet
>>> # in many places OTHER than R
>>> # You can start with ?regex, but there are many fine tutorials also
>>>
>>> pattern <- "^.*group (\\d+)[^:]*: *([-+0-9.eE]*).*$"
>>> # For this task the regex has to match the whole "first line" of each
>>set
>>> #  ^ =match starting at the beginning of the string
>>> #  .* =any character, zero or more times
>>> #  "group " =match these characters
>>> #  ( =first capture string starts here
>>> #  \\d = any digit (first backslash for R, second backslash for
>>regex)
>>> #  + =one or more of the preceding (any digit)
>>> #  ) =end of first capture string
>>> #  [^:] =any non-colon character
>>> #  * =zero or more of the preceding (non-colon character)
>>> #  : =match a colon exactly
>>> #  " *" =match zero or more spaces
>>> #  ( =second capture string starts here
>>> #  [ =start of a set of equally acceptable characters
>>> #  -+ =either of these characters are acceptable
>>> #  0-9 =any digit would be acceptable
>>> #  . =a period is acceptable (this is inside the [])
>>> #  eE =in case you get exponential notation input
>>> #  ] =end of the set of acceptable characters (number)
>>> #  * =number of acceptable characters can be zero or more
>>> #  ) =second capture string stops here
>>> #  .* =zero or more of any character (just in case)
>>> #  $ =at end of pattern, requires that the match reach the end
>>> #     of the string
>>>
>>> # identify indexes of strings that match the pattern
>>> firstlines <- grep( pattern, indta )
>>> # Replace the matched portion (entire string) with the first capture
>>#
>>> string
>>> v1 <- as.numeric( sub( pattern, "\\1", indta[ firstlines ] ) )
>>> # Replace the matched portion (entire string) with the second capture
>>#
>>> string
>>> v2 <- as.numeric( sub( pattern, "\\2", indta[ firstlines ] ) )
>>> # Convert the lines just after the first lines to numeric
>>> v3 <- as.numeric( indta[ firstlines + 1 ] )
>>> # put it all into a data frame
>>> result <- data.frame( Group = v1, Mean = v2, SE = v3 )
>>>
>>> Figuring out how to deliver your result (output) is a separate
>>question that
>>> depends where you want it to go.
>>>
>>>
>>> On Mon, 30 May 2016, Val wrote:
>>>
>>>> Hi all,
>>>>
>>>> I have a messy text file and from this text file I want extract some
>>>> information
>>>> here is the text file (out.txt).  One record has tow lines. The mean
>>comes
>>>> in the first line and the SE of the mean is on the second line. Here
>>is
>>>> the
>>>> sample of the data.
>>>>
>>>> Mean of weight  group 1, SE of mean  :  72.289037489555276
>>>> 11.512956539215610
>>>> Average weight of group 2, SE of Mean :  83.940053900595013
>>>>  10.198495690144522
>>>> group 3 mean , SE of Mean     :                78.310441258245469
>>>> 13.015876679555
>>>> Mean of weight of group 4, SE of Mean               :
>>76.967516495101669
>>>> 12.1254882985
>>>>
>>>> I want produce the following  table. How do i read it first and then
>>>> produce a
>>>>
>>>>
>>>> Gr1  72.289037489555276   11.512956539215610
>>>> Gr2  83.940053900595013   10.198495690144522
>>>> Gr3  78.310441258245469   13.015876679555
>>>> Gr4  76.967516495101669   12.1254882985
>>>>
>>>>
>>>> Thank you in advance
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>>                                       Live:   OO#.. Dead: OO#..
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>>
>>---------------------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Jun  1 08:24:45 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 1 Jun 2016 18:24:45 +1200
Subject: [R] [FORGED] Re:  Extract from a text file
In-Reply-To: <CAGxFJbTtSUiY+2shT=niGXjDC020vk8_hChwpubYMt0FBRRYTQ@mail.gmail.com>
References: <CAJOiR6YNh5300ziX6MGCUN+i-029tX7JKdpZeKoUNs00xP1-3A@mail.gmail.com>
	<alpine.BSF.2.00.1605302239170.3513@pedal.dcn.davis.ca.us>
	<CAJOiR6aC1sHOTi-_rB2CXVd2ZuqAiVNyfJw=_Khjwh8OU-rUBA@mail.gmail.com>
	<D6AF5A9D-8D7D-4F60-8888-4EEA7973B0A5@dcn.davis.ca.us>
	<CAGxFJbTtSUiY+2shT=niGXjDC020vk8_hChwpubYMt0FBRRYTQ@mail.gmail.com>
Message-ID: <4c9bd773-1e3d-9c66-f637-8a2f09a34a44@auckland.ac.nz>

On 01/06/16 15:27, Bert Gunter wrote:
> On Tue, May 31, 2016 at 7:05 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> You need to go back and study how I made my solution reproducible and make your problem reproducible.
>>
>> You probably also ought to spend some time comparing the regex pattern to your actual data... the point of this list is to learn how to construct these solutions yourself.
>
>
> Ah, if only that were the case.
>
> (or is that just the grumbling of an old curmudgeon?)


Both! :-)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From petr.pikal at precheza.cz  Wed Jun  1 09:00:22 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 1 Jun 2016 07:00:22 +0000
Subject: [R] Pairwise table from cloumns
In-Reply-To: <CAF+w_Q1A=ca9YPQvBiwwvz7+jLEmrDf8dqJ7tHEoXYUajrp4Fg@mail.gmail.com>
References: <CAF+w_Q0aKGUFA=mt+tZpeh1pS9mBv4NWki21t47ZsyaFRXoyPg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D18F@SRVEXCHMBX.precheza.cz>
	<CAF+w_Q1A=ca9YPQvBiwwvz7+jLEmrDf8dqJ7tHEoXYUajrp4Fg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D47D@SRVEXCHMBX.precheza.cz>

Hi

Keep your replies on the list, you can get more and better replies.
Do not post in HTML
combination of values is easily achieved e.g. by expand grid

expand.grid(mat[,1], mat[,2])

Regards
Petr


From: ameneh deljoo [mailto:amene.deljoo at gmail.com]
Sent: Tuesday, May 31, 2016 3:45 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] Pairwise table from cloumns

thanks for your reply.
I wanna a matrix with all possible combination of data.  For example, a combination of column 1 and 2.
{(1,2)(1,3)(1,4)(2,1)(2,3)(2,4)...}

On Tue, May 31, 2016 at 3:19 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

your message is rather scrambled and to be honest not well understandable (by me).

having two column matrix

> mat<-matrix(1:8, 4,2)
> mat
     [,1] [,2]
[1,]    1    5
[2,]    2    6
[3,]    3    7
[4,]    4    8

You can calculate eg. distance

> dist(mat, diag=T, upper=T)
         1        2        3        4
1 0.000000 1.414214 2.828427 4.242641
2 1.414214 0.000000 1.414214 2.828427
3 2.828427 1.414214 0.000000 1.414214
4 4.242641 2.828427 1.414214 0.000000

But from your description I do not understand how you want to reshape your data.

Example, please.

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of ameneh
> deljoo
> Sent: Tuesday, May 31, 2016 12:13 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Pairwise table from cloumns
>
> *Hi Group
> **I have a large data set of individual pairwise values (100 rows) **that I**
> need to reshape into a pairwise matrix for mantel tests of similarity these
> values** .
> **I need this matrix for a Pathfinder network analysis. *
>
> *I have a different data(word) such as :*
>
>
>
>
>
>   living thing
>   0
>
>
>   animal
>   1
>
>
>   blood
>   2
>
>
>   bird
>   3
>
>
>   feathers
>   4
>
>
>   robin
>   5
>
>
>   chicken
> ....
>   6
>
>
>
>   *I need the final matrix to be formatted as based on the similarity
> **      A1    A2    A3    A4
> ** A1  0     32   40     32
> * *A2  32    0    49     38
> ** A3  40    49   0      53
> ** A4  32    38   53     0*
>
> *....*
>
>
> Are there any functions/packages that will make this easier? Thanks Ameneh
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Jun  1 10:45:37 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 1 Jun 2016 10:45:37 +0200
Subject: [R] Application of "merge" and "within"
In-Reply-To: <f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
	<f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
Message-ID: <7252E1E4-94D9-42FE-8F2A-267E340A375B@gmail.com>

Notice that within-group processing is intended. I'd try

> first <- function(x)x[1]
> s  <- within(q, {bl <- ave(b, paste(G,a), FUN=first); db <- b - bl})

Or perhaps

q <- within(q, Ga <- paste(G,a))
tbl <- with(q, tapply(b, Ga, first))
s <- within(q, {bl <- tbl[Ga]; db <- b - bl})

-pd


On 28 May 2016, at 22:53 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 27/05/2016 7:00 PM, Santosh wrote:
>> Dear Rxperts!
>> 
>> Is there a way to compute relative values.. using within().. function?
>> 
>> Any assistance/suggestions are highly welcome!!
>> Thanks again,
>> Santosh...
>> ___________________________________________________________________
>> A sample dataset and the computation "outside" within()  function is shown..
>> 
>> q <- data.frame(GL = rep(paste("G",1:3,sep = ""),each = 50),
>>                G  = rep(1:3,each = 50),
>>                D = rep(paste("D",1:5,sep = ""),each = 30),
>>                a = rep(1:15,each = 10),
>>                t = rep(seq(10),15),
>>                b = round(runif(150,10,20)))
>> r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
>> names(r)[3] <- "bl"
>> s <- merge(q,r)
>> s$db <- s$b-s$bl
>> 
>>> head(s,5)
>>    G  a GL  D  t  b bl db
>> 1   1  1 G1 D1  1 13 13  0
>> 2   1  1 G1 D1  2 16 13  3
>> 3   1  1 G1 D1  3 19 13  6
>> 4   1  1 G1 D1  4 12 13 -1
>> 5   1  1 G1 D1  5 19 13  6
> 
> Just use
> 
> s <- within(s, db <- b - bl)
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tr206 at kent.ac.uk  Wed Jun  1 13:18:19 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Wed, 1 Jun 2016 11:18:19 +0000
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <alpine.DEB.2.20.1605311810442.22754@paninaro>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
	<alpine.DEB.2.20.1605282044060.26454@paninaro>
	<1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>,
	<alpine.DEB.2.20.1605310929070.23365@paninaro>
	<1464695293382.79381@kent.ac.uk>,
	<alpine.DEB.2.20.1605311406360.9953@paninaro>
	<1464707128487.37363@kent.ac.uk>,
	<alpine.DEB.2.20.1605311810442.22754@paninaro>
Message-ID: <1464779899285.26323@kent.ac.uk>

Thank you very much. I have applied the example to my case and get following results:

crisis_bubble4<-glm(stock.market.crash~crash.MA+bubble.MA+MP.MA+UTS.MA+UPR.MA+PPI.MA+RV.MA,family=binomial("logit"),data=Data_logitregression_movingaverage)
> summary(crisis_bubble4)

Call:
glm(formula = stock.market.crash ~ crash.MA + bubble.MA + MP.MA + 
    UTS.MA + UPR.MA + PPI.MA + RV.MA, family = binomial("logit"), 
    data = Data_logitregression_movingaverage)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.7828  -0.6686  -0.3186   0.6497   2.4298  

Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept)   -5.2609     0.8927  -5.893 3.79e-09 ***
crash.MA       0.4922     0.4966   0.991  0.32165    
bubble.MA     12.1287     1.3736   8.830  < 2e-16 ***
MP.MA        -20.0724    96.9576  -0.207  0.83599    
UTS.MA       -58.1814    19.3533  -3.006  0.00264 ** 
UPR.MA      -337.5798    64.3078  -5.249 1.53e-07 ***
PPI.MA       729.3769    73.0529   9.984  < 2e-16 ***
RV.MA        116.0011    16.5456   7.011 2.37e-12 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 869.54  on 705  degrees of freedom
Residual deviance: 606.91  on 698  degrees of freedom
AIC: 622.91

Number of Fisher Scoring iterations: 5

> coeftest(crisis_bubble4)

z test of coefficients:

              Estimate Std. Error z value  Pr(>|z|)    
(Intercept)   -5.26088    0.89269 -5.8933 3.786e-09 ***
crash.MA       0.49219    0.49662  0.9911  0.321652    
bubble.MA     12.12868    1.37357  8.8300 < 2.2e-16 ***
MP.MA        -20.07238   96.95755 -0.2070  0.835992    
UTS.MA       -58.18142   19.35330 -3.0063  0.002645 ** 
UPR.MA      -337.57985   64.30779 -5.2494 1.526e-07 ***
PPI.MA       729.37693   73.05288  9.9842 < 2.2e-16 ***
RV.MA        116.00106   16.54560  7.0110 2.366e-12 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> coeftest(crisis_bubble4,vcov=NeweyWest)

z test of coefficients:

              Estimate Std. Error z value Pr(>|z|)  
(Intercept)   -5.26088    5.01706 -1.0486  0.29436  
crash.MA       0.49219    2.41688  0.2036  0.83863  
bubble.MA     12.12868    5.85228  2.0725  0.03822 *
MP.MA        -20.07238  499.37589 -0.0402  0.96794  
UTS.MA       -58.18142   77.08409 -0.7548  0.45038  
UPR.MA      -337.57985  395.35639 -0.8539  0.39318  
PPI.MA       729.37693  358.60868  2.0339  0.04196 *
RV.MA        116.00106   79.52421  1.4587  0.14465  
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> waldtest(crisis_bubble4, vcov = NeweyWest,test="F")
Wald test

Model 1: stock.market.crash ~ crash.MA + bubble.MA + MP.MA + UTS.MA + 
    UPR.MA + PPI.MA + RV.MA
Model 2: stock.market.crash ~ 1
  Res.Df Df      F  Pr(>F)  
1    698                    
2    705 -7 2.3302 0.02351 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> waldtest(crisis_bubble4, vcov = NeweyWest,test="Chisq")
Wald test

Model 1: stock.market.crash ~ crash.MA + bubble.MA + MP.MA + UTS.MA + 
    UPR.MA + PPI.MA + RV.MA
Model 2: stock.market.crash ~ 1
  Res.Df Df  Chisq Pr(>Chisq)  
1    698                       
2    705 -7 16.311    0.02242 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Do you agree with the methodology? I read in a book that it is also possible to use vcov=vcovHAC in the coeftest() function. Nevertheless, I am not sure what kind of HAC I generate with this command. Which weights does this command apply, which bandwith and which kernel?

Kind regards
________________________________________
From: Achim Zeileis <Achim.Zeileis at uibk.ac.at>
Sent: 31 May 2016 17:19
To: T.Riedle
Cc: r-help at r-project.org
Subject: Re: [R] sandwich package: HAC estimators

On Tue, 31 May 2016, T.Riedle wrote:

> Many thanks for your feedback.
>
> If I get the code for the waldtest right I can calculate the Chi2 and
> the F statistic using waldtest().

Yes. In a logit model you would usually use the chi-squared statistic.

> Can I use the waldtest() without using bread()/ estfun()? That is, I
> estimate the logit regression using glm() e.g. logit<-glm(...) and
> insert logit into the waldtest() function.
>
> Does that work to get chi2 under HAC standard errors?

I'm not sure what you mean here but I include a worked example. Caveat:
The data I use are cross-section data with an overly simplified set of
regressors. So none of this makes sense for the application - but it shows
how to use the commands.

## load AER package which provides the example data
## and automatically loads "lmtest" and "sandwich"
library("AER")
data("PSID1976", package = "AER")

## fit a simple logit model and obtain marginal Wald tests
## for the coefficients and an overall chi-squared statistic
m <- glm(participation ~ education, data = PSID1976, family = binomial)
summary(m)
anova(m, test = "Chisq")

## replicate the same statistics with coeftest() and lrtest()
coeftest(m)
lrtest(m)

## the likelihood ratio test is asymptotically equivalent
## to the Wald test leading to a similar chi-squared test here
waldtest(m)

## obtain HAC-corrected (Newey-West) versions of the Wald tests
coeftest(m, vcov = NeweyWest)
waldtest(m, vcov = NeweyWest)

Instead of NeweyWest other covariance estimators (e.g., vcovHAC, kernHAC,
etc.) can also be plugged in.

hth,
Z

> ________________________________________
> From: Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> Sent: 31 May 2016 13:18
> To: T.Riedle
> Cc: r-help at r-project.org
> Subject: Re: [R] sandwich package: HAC estimators
>
> On Tue, 31 May 2016, T.Riedle wrote:
>
>> I understood. But how do I get the R2 an Chi2 of my logistic regression
>> under HAC standard errors? I would like to create a table with HAC SE
>> via e.g. stargazer().
>>
>> Do I get these information by using the functions
>>
>> bread.lrm <- function(x, ...) vcov(x) * nobs(x)
>> estfun.lrm <- function(x, ...) residuals(x, "score")?
>>
>> Do I need to use the coeftest() in this case?
>
> The bread()/estfun() methods enable application of vcovHAC(), kernHAC(),
> NeweyWest(). This in turn enables the application of coeftest(),
> waldtest(), or linearHypothesis() with a suitable vcov argument.
>
> All of these give you different kinds of Wald tests with HAC covariances
> including marginal tests of individual coefficients (coeftest) or global
> tests of nested models (waldtest/linearHypothesis). The latter can serve
> as replacement for the "chi-squared test". For pseudo-R-squared values I'm
> not familiar with HAC-adjusted variants.
>
> And I'm not sure whether there is a LaTeX export solution that encompasses
> all of these aspects simultaneously.
>
>> ________________________________________
>> From: R-help <r-help-bounces at r-project.org> on behalf of Achim Zeileis <Achim.Zeileis at uibk.ac.at>
>> Sent: 31 May 2016 08:36
>> To: Leonardo Ferreira Fontenelle
>> Cc: r-help at r-project.org
>> Subject: Re: [R] sandwich package: HAC estimators
>>
>> On Mon, 30 May 2016, Leonardo Ferreira Fontenelle wrote:
>>
>>> Em S?b 28 mai. 2016, ?s 15:50, Achim Zeileis escreveu:
>>>> On Sat, 28 May 2016, T.Riedle wrote:
>>>>> I thought it would be useful to incorporate the HAC consistent
>>>>> covariance matrix into the logistic regression directly and generate an
>>>>> output of coefficients and the corresponding standard errors. Is there
>>>>> such a function in R?
>>>>
>>>> Not with HAC standard errors, I think.
>>>
>>> Don't glmrob() and summary.glmrob(), from robustbase, do that?
>>
>> No, they implement a different concept of robustness. See also
>> https://CRAN.R-project.org/view=Robust
>>
>> glmrob() implements GLMs that are "robust" or rather "resistant" to
>> outliers and other observations that do not come from the main model
>> equation. Instead of maximum likelihood (ML) estimation other estimation
>> techniques (along with corresponding covariances/standard errors) are
>> used.
>>
>> In contrast, the OP asked for HAC standard errors. The motivation for
>> these is that the main model equation does hold for all observations but
>> that the observations might be heteroskedastic and/or autocorrelated. In
>> this situation, ML estimation is still consistent (albeit not efficient)
>> but the covariance matrix estimate needs to be adjusted.
>>
>>>
>>> Leonardo Ferreira Fontenelle, MD, MPH
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Achim.Zeileis at uibk.ac.at  Wed Jun  1 13:45:14 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 1 Jun 2016 13:45:14 +0200 (CEST)
Subject: [R] sandwich package: HAC estimators
In-Reply-To: <1464779899285.26323@kent.ac.uk>
References: <5a4a4884895348f8b010876f9ca10151@ex13-live-mbn1.ad.kent.ac.uk>
	<alpine.DEB.2.20.1605282044060.26454@paninaro>
	<1464645044.828551.622982401.23A6C61F@webmail.messagingengine.com>,
	<alpine.DEB.2.20.1605310929070.23365@paninaro>
	<1464695293382.79381@kent.ac.uk>, 
	<alpine.DEB.2.20.1605311406360.9953@paninaro>
	<1464707128487.37363@kent.ac.uk>,
	<alpine.DEB.2.20.1605311810442.22754@paninaro>
	<1464779899285.26323@kent.ac.uk>
Message-ID: <alpine.DEB.2.20.1606011336040.3407@paninaro>

On Wed, 1 Jun 2016, T.Riedle wrote:

> Thank you very much. I have applied the example to my case and get 
> following results:
>
> crisis_bubble4<-glm(stock.market.crash~crash.MA+bubble.MA+MP.MA+UTS.MA+UPR.MA+PPI.MA+RV.MA,family=binomial("logit"),data=Data_logitregression_movingaverage)
>> summary(crisis_bubble4)
>
> Call:
> glm(formula = stock.market.crash ~ crash.MA + bubble.MA + MP.MA +
>    UTS.MA + UPR.MA + PPI.MA + RV.MA, family = binomial("logit"),
>    data = Data_logitregression_movingaverage)
>
> Deviance Residuals:
>    Min       1Q   Median       3Q      Max
> -1.7828  -0.6686  -0.3186   0.6497   2.4298
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)   -5.2609     0.8927  -5.893 3.79e-09 ***
> crash.MA       0.4922     0.4966   0.991  0.32165
> bubble.MA     12.1287     1.3736   8.830  < 2e-16 ***
> MP.MA        -20.0724    96.9576  -0.207  0.83599
> UTS.MA       -58.1814    19.3533  -3.006  0.00264 **
> UPR.MA      -337.5798    64.3078  -5.249 1.53e-07 ***
> PPI.MA       729.3769    73.0529   9.984  < 2e-16 ***
> RV.MA        116.0011    16.5456   7.011 2.37e-12 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>    Null deviance: 869.54  on 705  degrees of freedom
> Residual deviance: 606.91  on 698  degrees of freedom
> AIC: 622.91
>
> Number of Fisher Scoring iterations: 5
>
>> coeftest(crisis_bubble4)
>
> z test of coefficients:
>
>              Estimate Std. Error z value  Pr(>|z|)
> (Intercept)   -5.26088    0.89269 -5.8933 3.786e-09 ***
> crash.MA       0.49219    0.49662  0.9911  0.321652
> bubble.MA     12.12868    1.37357  8.8300 < 2.2e-16 ***
> MP.MA        -20.07238   96.95755 -0.2070  0.835992
> UTS.MA       -58.18142   19.35330 -3.0063  0.002645 **
> UPR.MA      -337.57985   64.30779 -5.2494 1.526e-07 ***
> PPI.MA       729.37693   73.05288  9.9842 < 2.2e-16 ***
> RV.MA        116.00106   16.54560  7.0110 2.366e-12 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>> coeftest(crisis_bubble4,vcov=NeweyWest)
>
> z test of coefficients:
>
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)   -5.26088    5.01706 -1.0486  0.29436
> crash.MA       0.49219    2.41688  0.2036  0.83863
> bubble.MA     12.12868    5.85228  2.0725  0.03822 *
> MP.MA        -20.07238  499.37589 -0.0402  0.96794
> UTS.MA       -58.18142   77.08409 -0.7548  0.45038
> UPR.MA      -337.57985  395.35639 -0.8539  0.39318
> PPI.MA       729.37693  358.60868  2.0339  0.04196 *
> RV.MA        116.00106   79.52421  1.4587  0.14465
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>> waldtest(crisis_bubble4, vcov = NeweyWest,test="F")
> Wald test
>
> Model 1: stock.market.crash ~ crash.MA + bubble.MA + MP.MA + UTS.MA +
>    UPR.MA + PPI.MA + RV.MA
> Model 2: stock.market.crash ~ 1
>  Res.Df Df      F  Pr(>F)
> 1    698
> 2    705 -7 2.3302 0.02351 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>> waldtest(crisis_bubble4, vcov = NeweyWest,test="Chisq")
> Wald test
>
> Model 1: stock.market.crash ~ crash.MA + bubble.MA + MP.MA + UTS.MA +
>    UPR.MA + PPI.MA + RV.MA
> Model 2: stock.market.crash ~ 1
>  Res.Df Df  Chisq Pr(>Chisq)
> 1    698
> 2    705 -7 16.311    0.02242 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Do you agree with the methodology?

Well, this is how you _can_ do what you _wanted_ to do. I already 
expressed my doubts about several aspects. First, some coefficients and 
their standard errors are very large which may (or may not) hint at 
problems that are close to separation. Second, given the increase in the 
standard errors, the autocorrelation appears to be substantial and it 
might be good to try to capture these autocorrelations explicitly rather 
than just correcting the standard errors.

> I read in a book that it is also possible to use vcov=vcovHAC in the 
> coeftest() function.

Yes. (I also mentioned that in my e-mail yesterday, see below.)

> Nevertheless, I am not sure what kind of HAC I generate with this 
> command. Which weights does this command apply, which bandwith and which 
> kernel?

Please consult vignette("sandwich", package = "sandwich") for the details. 
In short: Both, vcovHAC and kernHAC use the quadratic spectral kernel with 
Andrews' parametric bandwidth selection. The latter function uses 
prewhitening by default while the latter does not. In contrast, NeweyWest 
uses a Bartlett kernel with Newey & Wests nonparametric lag/bandwidth 
selection and prewhitening by default.

> Kind regards
> ________________________________________
> From: Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> Sent: 31 May 2016 17:19
> To: T.Riedle
> Cc: r-help at r-project.org
> Subject: Re: [R] sandwich package: HAC estimators
>
> On Tue, 31 May 2016, T.Riedle wrote:
>
>> Many thanks for your feedback.
>>
>> If I get the code for the waldtest right I can calculate the Chi2 and
>> the F statistic using waldtest().
>
> Yes. In a logit model you would usually use the chi-squared statistic.
>
>> Can I use the waldtest() without using bread()/ estfun()? That is, I
>> estimate the logit regression using glm() e.g. logit<-glm(...) and
>> insert logit into the waldtest() function.
>>
>> Does that work to get chi2 under HAC standard errors?
>
> I'm not sure what you mean here but I include a worked example. Caveat:
> The data I use are cross-section data with an overly simplified set of
> regressors. So none of this makes sense for the application - but it shows
> how to use the commands.
>
> ## load AER package which provides the example data
> ## and automatically loads "lmtest" and "sandwich"
> library("AER")
> data("PSID1976", package = "AER")
>
> ## fit a simple logit model and obtain marginal Wald tests
> ## for the coefficients and an overall chi-squared statistic
> m <- glm(participation ~ education, data = PSID1976, family = binomial)
> summary(m)
> anova(m, test = "Chisq")
>
> ## replicate the same statistics with coeftest() and lrtest()
> coeftest(m)
> lrtest(m)
>
> ## the likelihood ratio test is asymptotically equivalent
> ## to the Wald test leading to a similar chi-squared test here
> waldtest(m)
>
> ## obtain HAC-corrected (Newey-West) versions of the Wald tests
> coeftest(m, vcov = NeweyWest)
> waldtest(m, vcov = NeweyWest)
>
> Instead of NeweyWest other covariance estimators (e.g., vcovHAC, kernHAC,
> etc.) can also be plugged in.
>
> hth,
> Z
>
>> ________________________________________
>> From: Achim Zeileis <Achim.Zeileis at uibk.ac.at>
>> Sent: 31 May 2016 13:18
>> To: T.Riedle
>> Cc: r-help at r-project.org
>> Subject: Re: [R] sandwich package: HAC estimators
>>
>> On Tue, 31 May 2016, T.Riedle wrote:
>>
>>> I understood. But how do I get the R2 an Chi2 of my logistic regression
>>> under HAC standard errors? I would like to create a table with HAC SE
>>> via e.g. stargazer().
>>>
>>> Do I get these information by using the functions
>>>
>>> bread.lrm <- function(x, ...) vcov(x) * nobs(x)
>>> estfun.lrm <- function(x, ...) residuals(x, "score")?
>>>
>>> Do I need to use the coeftest() in this case?
>>
>> The bread()/estfun() methods enable application of vcovHAC(), kernHAC(),
>> NeweyWest(). This in turn enables the application of coeftest(),
>> waldtest(), or linearHypothesis() with a suitable vcov argument.
>>
>> All of these give you different kinds of Wald tests with HAC covariances
>> including marginal tests of individual coefficients (coeftest) or global
>> tests of nested models (waldtest/linearHypothesis). The latter can serve
>> as replacement for the "chi-squared test". For pseudo-R-squared values I'm
>> not familiar with HAC-adjusted variants.
>>
>> And I'm not sure whether there is a LaTeX export solution that encompasses
>> all of these aspects simultaneously.
>>
>>> ________________________________________
>>> From: R-help <r-help-bounces at r-project.org> on behalf of Achim Zeileis <Achim.Zeileis at uibk.ac.at>
>>> Sent: 31 May 2016 08:36
>>> To: Leonardo Ferreira Fontenelle
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] sandwich package: HAC estimators
>>>
>>> On Mon, 30 May 2016, Leonardo Ferreira Fontenelle wrote:
>>>
>>>> Em S?b 28 mai. 2016, ?s 15:50, Achim Zeileis escreveu:
>>>>> On Sat, 28 May 2016, T.Riedle wrote:
>>>>>> I thought it would be useful to incorporate the HAC consistent
>>>>>> covariance matrix into the logistic regression directly and generate an
>>>>>> output of coefficients and the corresponding standard errors. Is there
>>>>>> such a function in R?
>>>>>
>>>>> Not with HAC standard errors, I think.
>>>>
>>>> Don't glmrob() and summary.glmrob(), from robustbase, do that?
>>>
>>> No, they implement a different concept of robustness. See also
>>> https://CRAN.R-project.org/view=Robust
>>>
>>> glmrob() implements GLMs that are "robust" or rather "resistant" to
>>> outliers and other observations that do not come from the main model
>>> equation. Instead of maximum likelihood (ML) estimation other estimation
>>> techniques (along with corresponding covariances/standard errors) are
>>> used.
>>>
>>> In contrast, the OP asked for HAC standard errors. The motivation for
>>> these is that the main model equation does hold for all observations but
>>> that the observations might be heteroskedastic and/or autocorrelated. In
>>> this situation, ML estimation is still consistent (albeit not efficient)
>>> but the covariance matrix estimate needs to be adjusted.
>>>
>>>>
>>>> Leonardo Ferreira Fontenelle, MD, MPH
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From tea3rd at gmail.com  Wed Jun  1 14:06:53 2016
From: tea3rd at gmail.com (Thomas Adams)
Date: Wed, 1 Jun 2016 07:06:53 -0500
Subject: [R] Help needed to format data for boxplot time-series
Message-ID: <CAGxgkWhCsbA_hesw69dPnGL18F2pP59rvZvwfJ9ngpyOeMtVFQ@mail.gmail.com>

All:

I have used R in combination with GRASS GIS spatial data (using spgrass)
many times in the past to generate a 'time series' of boxplots, to show
variations over time. But I have a new problem, not involving spatial data,
but rather, true time-series data (snippet shown below). So, what I want to
do is to generate a 'time-series' of boxplots based on the column
'valid_time' for the 'values' column data. What I can not figure out is how
to either select or format the data for the series of individual boxplots.
Somehow it seems I need to use reshape; do I group the data within a loop?
This does not seem efficient. The full set of data I have covers a 30 day
period at 6-hourly time steps with 9320 rows

Data

lid|ens_num|basis_time|valid_time|value
MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 00:00:00|1431.4787995285
MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777643846512
MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777778561401
MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777441774178
MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777441774178
MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 06:00:00|1430.25545361671
MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404370083809
MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 12:00:00|1429.0170196373
MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801239487267
MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 18:00:00|1427.75029553108
MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976794630909
MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976727273464
MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 18:00:00|532.97639048624
MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976895667076
MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 00:00:00|1426.44531239624
MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520648461056
MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520513746166
MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520379031277
MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520783175945
MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 06:00:00|1425.14127226563
MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 06:00:00|408.103669752502
MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 06:00:00|408.105117937565
MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 06:00:00|408.102255246162
MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 06:00:00|408.193086760426
MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 12:00:00|1423.73767783165
MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 12:00:00|356.017269114971
MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 12:00:00|356.245105671883
MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 12:00:00|355.568634854126
MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 12:00:00|357.646308916569
MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 18:00:00|1422.30188653908
MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 18:00:00|310.664962696362
MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 18:00:00|310.956081572628
MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 18:00:00|310.891788891602
MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 18:00:00|311.764674018288
MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 00:00:00|1420.79065490837
MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 00:00:00|271.319441647482
MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 00:00:00|271.90585556159
MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 00:00:00|272.571818617964
MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 00:00:00|272.197900602722
MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 06:00:00|1419.24197253838
MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 06:00:00|238.587209240341
MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 06:00:00|238.386618769836
MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 06:00:00|246.312821885538
MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 06:00:00|237.956154179716
MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 12:00:00|1417.63953892746
MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 12:00:00|209.872343232489
MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 12:00:00|209.899606158257
MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 12:00:00|215.785316521025
MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 12:00:00|208.711723941135
MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 18:00:00|1415.99035924988
MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 18:00:00|184.638914114666
MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 18:00:00|184.573223766661
MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 18:00:00|189.508672138071
MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 18:00:00|183.818062614059
MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 00:00:00|1414.29375993118
MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 00:00:00|162.991595356035
MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 00:00:00|162.881398576403
MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 00:00:00|166.706644703865
MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 00:00:00|162.506082894182
MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 06:00:00|1411.73094387283
MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 06:00:00|144.685525805521
MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 06:00:00|144.518832969093
MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 06:00:00|147.765293413067
MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 06:00:00|144.311169966888
MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 12:00:00|1409.87780585251
MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 12:00:00|128.826771134949
MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 12:00:00|128.591449481988
MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 12:00:00|131.575131694579
MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 12:00:00|128.445443800783
MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 18:00:00|1407.97159016571
MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 18:00:00|115.098490343833
MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 18:00:00|117.685470885491
MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 18:00:00|114.647296500087


Thank you,
Tom

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Jun  1 14:23:08 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 1 Jun 2016 12:23:08 +0000
Subject: [R] Help needed to format data for boxplot time-series
In-Reply-To: <CAGxgkWhCsbA_hesw69dPnGL18F2pP59rvZvwfJ9ngpyOeMtVFQ@mail.gmail.com>
References: <CAGxgkWhCsbA_hesw69dPnGL18F2pP59rvZvwfJ9ngpyOeMtVFQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D68F@SRVEXCHMBX.precheza.cz>

Hi

It is preferable to use output of

dput(yourdata) or dput(yourdata[1:20,])

so that we can use your data.

From your description maybe

boxplot(split(yourdata$value, yourdata$valid_time))

can give you what you want.

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
> Adams
> Sent: Wednesday, June 1, 2016 2:07 PM
> To: r-help at r-project.org
> Subject: [R] Help needed to format data for boxplot time-series
>
> All:
>
> I have used R in combination with GRASS GIS spatial data (using spgrass)
> many times in the past to generate a 'time series' of boxplots, to show
> variations over time. But I have a new problem, not involving spatial data, but
> rather, true time-series data (snippet shown below). So, what I want to do is
> to generate a 'time-series' of boxplots based on the column 'valid_time' for
> the 'values' column data. What I can not figure out is how to either select or
> format the data for the series of individual boxplots.
> Somehow it seems I need to use reshape; do I group the data within a loop?
> This does not seem efficient. The full set of data I have covers a 30 day period
> at 6-hourly time steps with 9320 rows
>
> Data
>
> lid|ens_num|basis_time|valid_time|value
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 00:00:00|1431.4787995285
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777643846512
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777778561401
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777441774178
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777441774178
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 06:00:00|1430.25545361671
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404370083809
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 12:00:00|1429.0170196373
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801239487267
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 18:00:00|1427.75029553108
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976794630909
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976727273464
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 18:00:00|532.97639048624
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976895667076
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 00:00:00|1426.44531239624
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520648461056
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520513746166
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520379031277
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520783175945
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 06:00:00|1425.14127226563
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 06:00:00|408.103669752502
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 06:00:00|408.105117937565
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 06:00:00|408.102255246162
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 06:00:00|408.193086760426
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 12:00:00|1423.73767783165
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 12:00:00|356.017269114971
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 12:00:00|356.245105671883
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 12:00:00|355.568634854126
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 12:00:00|357.646308916569
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 18:00:00|1422.30188653908
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 18:00:00|310.664962696362
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 18:00:00|310.956081572628
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 18:00:00|310.891788891602
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 18:00:00|311.764674018288
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 00:00:00|1420.79065490837
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 00:00:00|271.319441647482
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 00:00:00|271.90585556159
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 00:00:00|272.571818617964
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 00:00:00|272.197900602722
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 06:00:00|1419.24197253838
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 06:00:00|238.587209240341
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 06:00:00|238.386618769836
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 06:00:00|246.312821885538
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 06:00:00|237.956154179716
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 12:00:00|1417.63953892746
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 12:00:00|209.872343232489
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 12:00:00|209.899606158257
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 12:00:00|215.785316521025
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 12:00:00|208.711723941135
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 18:00:00|1415.99035924988
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 18:00:00|184.638914114666
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 18:00:00|184.573223766661
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 18:00:00|189.508672138071
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 18:00:00|183.818062614059
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 00:00:00|1414.29375993118
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 00:00:00|162.991595356035
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 00:00:00|162.881398576403
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 00:00:00|166.706644703865
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 00:00:00|162.506082894182
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 06:00:00|1411.73094387283
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 06:00:00|144.685525805521
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 06:00:00|144.518832969093
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 06:00:00|147.765293413067
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 06:00:00|144.311169966888
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 12:00:00|1409.87780585251
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 12:00:00|128.826771134949
> MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 12:00:00|128.591449481988
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 12:00:00|131.575131694579
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 12:00:00|128.445443800783
> MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 18:00:00|1407.97159016571
> MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 18:00:00|115.098490343833
> MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 18:00:00|117.685470885491
> MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 18:00:00|114.647296500087
>
>
> Thank you,
> Tom
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From tea3rd at gmail.com  Wed Jun  1 14:33:43 2016
From: tea3rd at gmail.com (Thomas Adams)
Date: Wed, 1 Jun 2016 07:33:43 -0500
Subject: [R] Help needed to format data for boxplot time-series
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D68F@SRVEXCHMBX.precheza.cz>
References: <CAGxgkWhCsbA_hesw69dPnGL18F2pP59rvZvwfJ9ngpyOeMtVFQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D68F@SRVEXCHMBX.precheza.cz>
Message-ID: <CAGxgkWht33+xZM-7ziBW=Je7k6MLiUT9VhLGJ0s5R7wp-RqyrQ@mail.gmail.com>

Petr and David,

Thank you so much! Both approaches do precisely what I need. I knew there
had to be a very simple way to do this, but I am still very much a novice
and struggle with data management at times. Also, thank you for the
suggestion to use dput(yourdata) or dput(yourdata[1:20,]) -- I knew such a
thing existed and search for it, but just could not recall the 'dput'
command name.

Regards,
Tom

On Wed, Jun 1, 2016 at 7:23 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> It is preferable to use output of
>
> dput(yourdata) or dput(yourdata[1:20,])
>
> so that we can use your data.
>
> From your description maybe
>
> boxplot(split(yourdata$value, yourdata$valid_time))
>
> can give you what you want.
>
> Regards
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
> > Adams
> > Sent: Wednesday, June 1, 2016 2:07 PM
> > To: r-help at r-project.org
> > Subject: [R] Help needed to format data for boxplot time-series
> >
> > All:
> >
> > I have used R in combination with GRASS GIS spatial data (using spgrass)
> > many times in the past to generate a 'time series' of boxplots, to show
> > variations over time. But I have a new problem, not involving spatial
> data, but
> > rather, true time-series data (snippet shown below). So, what I want to
> do is
> > to generate a 'time-series' of boxplots based on the column 'valid_time'
> for
> > the 'values' column data. What I can not figure out is how to either
> select or
> > format the data for the series of individual boxplots.
> > Somehow it seems I need to use reshape; do I group the data within a
> loop?
> > This does not seem efficient. The full set of data I have covers a 30
> day period
> > at 6-hourly time steps with 9320 rows
> >
> > Data
> >
> > lid|ens_num|basis_time|valid_time|value
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 00:00:00|1431.4787995285
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777643846512
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777778561401
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777441774178
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 00:00:00|740.777441774178
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 06:00:00|1430.25545361671
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404370083809
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 06:00:00|673.404235368919
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 12:00:00|1429.0170196373
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801239487267
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 12:00:00|602.801441559601
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-21 18:00:00|1427.75029553108
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976794630909
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976727273464
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-21 18:00:00|532.97639048624
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-21 18:00:00|532.976895667076
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 00:00:00|1426.44531239624
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520648461056
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520513746166
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520379031277
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 00:00:00|467.520783175945
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 06:00:00|1425.14127226563
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 06:00:00|408.103669752502
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 06:00:00|408.105117937565
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 06:00:00|408.102255246162
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 06:00:00|408.193086760426
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 12:00:00|1423.73767783165
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 12:00:00|356.017269114971
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 12:00:00|356.245105671883
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 12:00:00|355.568634854126
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 12:00:00|357.646308916569
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-22 18:00:00|1422.30188653908
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-22 18:00:00|310.664962696362
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-22 18:00:00|310.956081572628
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-22 18:00:00|310.891788891602
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-22 18:00:00|311.764674018288
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 00:00:00|1420.79065490837
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 00:00:00|271.319441647482
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 00:00:00|271.90585556159
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 00:00:00|272.571818617964
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 00:00:00|272.197900602722
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 06:00:00|1419.24197253838
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 06:00:00|238.587209240341
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 06:00:00|238.386618769836
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 06:00:00|246.312821885538
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 06:00:00|237.956154179716
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 12:00:00|1417.63953892746
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 12:00:00|209.872343232489
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 12:00:00|209.899606158257
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 12:00:00|215.785316521025
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 12:00:00|208.711723941135
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-23 18:00:00|1415.99035924988
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-23 18:00:00|184.638914114666
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-23 18:00:00|184.573223766661
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-23 18:00:00|189.508672138071
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-23 18:00:00|183.818062614059
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 00:00:00|1414.29375993118
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 00:00:00|162.991595356035
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 00:00:00|162.881398576403
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 00:00:00|166.706644703865
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 00:00:00|162.506082894182
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 06:00:00|1411.73094387283
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 06:00:00|144.685525805521
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 06:00:00|144.518832969093
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 06:00:00|147.765293413067
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 06:00:00|144.311169966888
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 12:00:00|1409.87780585251
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 12:00:00|128.826771134949
> > MDBV1|ens02|2016-04-20 18:00:00|2016-04-24 12:00:00|128.591449481988
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 12:00:00|131.575131694579
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 12:00:00|128.445443800783
> > MDBV1|ens01|2016-04-19 06:00:00|2016-04-24 18:00:00|1407.97159016571
> > MDBV1|ens01|2016-04-20 18:00:00|2016-04-24 18:00:00|115.098490343833
> > MDBV1|ens03|2016-04-20 18:00:00|2016-04-24 18:00:00|117.685470885491
> > MDBV1|ens04|2016-04-20 18:00:00|2016-04-24 18:00:00|114.647296500087
> >
> >
> > Thank you,
> > Tom
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 
Thomas E Adams, III
2330 Jack Warner PKWY, #334
Tuscaloosa, AL 35401

1 (513) 739-9512 (cell)

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Wed Jun  1 16:39:30 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Wed, 1 Jun 2016 14:39:30 +0000 (UTC)
Subject: [R] Training set in Self organizing Map
References: <267730348.5184682.1464791970799.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <267730348.5184682.1464791970799.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I want to use Self Organizing Map in R for my data. I want my training set to be the following subset of my data:
 

    subdf=subset(df,Country%in%c("US","FR"))
next I should change this subset to a matrix but I get the following error:
 
    data_train_matrix=as.matrix(scale(subdf))
    error in colMeans(x,na.rm=TRUE):'x' must be numeric
 
Can anyone help me to solve that?
Thanks for any help
Elahe


From G.Maubach at gmx.de  Wed Jun  1 16:54:12 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Wed, 1 Jun 2016 16:54:12 +0200
Subject: [R] Installing miniCRAN on Debian
Message-ID: <trinity-f29d0387-cd3b-4392-9602-24b4abe6d64a-1464792852427@3capp-gmx-bs30>

Hi All,

I am installng miniCRAN on Debian GNU Linux 8 Jessie (Linux analytics7 4.5.0-0.bpo.2-amd64 #1 SMP Debian 4.5.4-1~bpo8+1 (2016-05-13) x86_64 GNU/Linux) and R 3.3.0 

-- cut --
> sessionInfo()
R version 3.3.0 (2016-05-03)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 8 (jessie)

locale:
 [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C               LC_TIME=de_DE.UTF-8       
 [4] LC_COLLATE=de_DE.UTF-8     LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   
 [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.3.0
-- cut --

After running

sudo apt-get install libssl-dev libcurl4-openssl-dev libxml2-dev libhunspell-dev

and calling

install.packages(pkgs = "miniCRAN", repos = "http://cran.csiro.au", dependencies = TRUE)

I get the message

------------------------- ANTICONF ERROR ---------------------------
Configuration failed because hunspell was not found. Try installing:
 * deb: libhunspell-dev (Debian, Ubuntu, etc)
 * rpm: hunspell-devel (Fedora, CentOS, RHEL)
 * brew: hunspell (Mac OSX)
If hunspell is already installed, check that 'pkg-config' is in your
PATH and PKG_CONFIG_PATH contains a hunspell.pc file. If pkg-config
is unavailable you can set INCLUDE_DIR and LIB_DIR manually via:
R CMD INSTALL --configure-vars='INCLUDE_DIR=... LIB_DIR=...'

Running

find / -name hunspell.pc

gives

/usr/lib/x86_64-linux-gnu/pkgconfig/hunspell.pc

and running

find / -name pkg-config

gives

/usr/share/bash-completion/completions/pkg-config

How do I need to configure R correctly to get miniCRAN running?

Kind regards

Georg


From jdnewmil at dcn.davis.ca.us  Wed Jun  1 16:59:54 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 01 Jun 2016 07:59:54 -0700
Subject: [R] Training set in Self organizing Map
In-Reply-To: <267730348.5184682.1464791970799.JavaMail.yahoo@mail.yahoo.com>
References: <267730348.5184682.1464791970799.JavaMail.yahoo.ref@mail.yahoo.com>
	<267730348.5184682.1464791970799.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <0CEE53E2-705F-4B84-B0DC-BA4E0BD984A0@dcn.davis.ca.us>

You did not send  sample of your data, using dput. Before doing that,  I suggest peeling apart your troublesome line of code yourself:

str( as.matrix( scale( subdf ) ) )
str( scale( subdf ) )
str( subdf )

And then think about what the scale function does. Does it make sense to ask it to scale character or factor data? Could you perhaps exclude some of the columns that don't belong in the scaled data? 
-- 
Sent from my phone. Please excuse my brevity.

On June 1, 2016 7:39:30 AM PDT, "ch.elahe via R-help" <r-help at r-project.org> wrote:
>Hi all,
>I want to use Self Organizing Map in R for my data. I want my training
>set to be the following subset of my data:
> 
>
>    subdf=subset(df,Country%in%c("US","FR"))
>next I should change this subset to a matrix but I get the following
>error:
> 
>    data_train_matrix=as.matrix(scale(subdf))
>    error in colMeans(x,na.rm=TRUE):'x' must be numeric
> 
>Can anyone help me to solve that?
>Thanks for any help
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun  1 16:59:54 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 01 Jun 2016 07:59:54 -0700
Subject: [R] Training set in Self organizing Map
In-Reply-To: <267730348.5184682.1464791970799.JavaMail.yahoo@mail.yahoo.com>
References: <267730348.5184682.1464791970799.JavaMail.yahoo.ref@mail.yahoo.com>
	<267730348.5184682.1464791970799.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <0CEE53E2-705F-4B84-B0DC-BA4E0BD984A0@dcn.davis.ca.us>

You did not send  sample of your data, using dput. Before doing that,  I suggest peeling apart your troublesome line of code yourself:

str( as.matrix( scale( subdf ) ) )
str( scale( subdf ) )
str( subdf )

And then think about what the scale function does. Does it make sense to ask it to scale character or factor data? Could you perhaps exclude some of the columns that don't belong in the scaled data? 
-- 
Sent from my phone. Please excuse my brevity.

On June 1, 2016 7:39:30 AM PDT, "ch.elahe via R-help" <r-help at r-project.org> wrote:
>Hi all,
>I want to use Self Organizing Map in R for my data. I want my training
>set to be the following subset of my data:
> 
>
>    subdf=subset(df,Country%in%c("US","FR"))
>next I should change this subset to a matrix but I get the following
>error:
> 
>    data_train_matrix=as.matrix(scale(subdf))
>    error in colMeans(x,na.rm=TRUE):'x' must be numeric
> 
>Can anyone help me to solve that?
>Thanks for any help
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Wed Jun  1 17:01:44 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 01 Jun 2016 15:01:44 +0000
Subject: [R] Training set in Self organizing Map
In-Reply-To: <267730348.5184682.1464791970799.JavaMail.yahoo@mail.yahoo.com>
References: <267730348.5184682.1464791970799.JavaMail.yahoo.ref@mail.yahoo.com>
	<267730348.5184682.1464791970799.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKVAULMAM2CdnBy1=YDpi_4x5ggmcm-js4+RCxU86v2Dt-Hskw@mail.gmail.com>

Hi Elahe,

if you look at your subdf, you will see that the column Country - which is
not numeric - is still present. You might have other non-number columns,
but this I cannot tell.

scale expects a numeric matrix. You give it a data.frame which is silently
cast to a matrix. A matrix can only have one type - unlike the data.frame -
so the presence of the non-numeric columns results in a matrix of type
character. Calculating means of characters is not possible, hence the error.

You need your data.frame to consist only of numeric types - then scale will
proceed without complaints.

Best wishes,
Ulrik



On Wed, 1 Jun 2016 at 16:41 ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi all,
> I want to use Self Organizing Map in R for my data. I want my training set
> to be the following subset of my data:
>
>
>     subdf=subset(df,Country%in%c("US","FR"))
> next I should change this subset to a matrix but I get the following error:
>
>     data_train_matrix=as.matrix(scale(subdf))
>     error in colMeans(x,na.rm=TRUE):'x' must be numeric
>
> Can anyone help me to solve that?
> Thanks for any help
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Sunish.Bilandi at evalueserve.com  Wed Jun  1 08:33:37 2016
From: Sunish.Bilandi at evalueserve.com (Sunish Kumar Bilandi)
Date: Wed, 1 Jun 2016 06:33:37 +0000
Subject: [R] Unable to update R software to 3.3.0
Message-ID: <SG2PR06MB171284796859BE6BC44CD21A9D470@SG2PR06MB1712.apcprd06.prod.outlook.com>

Hi Team,

I am using RedHat 5 and installed R using YUM, (R version 3.2.3) Now I want to update R version tp 3.3.0, but I am unable to do that, Is there any alternate to do this?

Hope to hear from your side.

Regards,


Sunish Bilandi
Business Analyst, CIDA-01
Evalueserve

Office: +91 124 4120000/4154000 (Extn. 1994)
Mobile: 9811937267
Fax: +91 124 406 3430
sunish.bilandi at evalueserve.com<mailto:sunish.bilandi at evalueserve.com>

Evalueserve.com <http://www.evalueserve.com/> | Evalueserve LinkedIn <https://www.linkedin.com/company/evalueserve> | Evalueserve Twitter <https://twitter.com/evalueservenews> | Evalueserve Facebook <https://www.facebook.com/pages/Evalueserve/959196870761417> | Evalueserve Google+ <https://plus.google.com/+evalueserve>

Evalueserve - powered by mind+machine(tm)
Evalueserve is a global professional services provider offering research, analytics, and data management services. We are powered by mind+machine - a unique combination of human expertise and best-in-class technologies that use smart algorithms to simplify key tasks.

________________________________

The information in this e-mail is the property of Evalue...{{dropped:11}}


From carlosalvarezroa at hotmail.com  Wed Jun  1 13:31:34 2016
From: carlosalvarezroa at hotmail.com (Carlos Alvarez Roa)
Date: Wed, 1 Jun 2016 21:31:34 +1000
Subject: [R] Contrast matrix with a continuous variable
Message-ID: <DUB123-W107E10159B3E20661DCE08C4470@phx.gbl>









































Hi all, 

I was wondering if someone could help me designing a contrast matrix when 

you have a continuous variable (Days). 



My model looks like this: 



model<-lme(Y~A*B*Days, data=data_over_time) 



The factor A has two levels (A1 and A2) and factor B has three levels (B1, 

B2, and B3). I measured the response variable Y every two or three days over 

70 days (Days). 

I need to look at only a few comparisons over the 70 days such us: 
                        
A1 and B1 vs A2 and B1, 
                        
A2 and B2 vs A2 and B1, 
                        
A1 and B2 vs A2 and B2 

I could use the function contrast from the package contrast to design the 

matrix with all three comparisons. I know how to do it for specific days at a 

time. This would give me the first comparison for day 1.

a=contrast(model, 
           a=list(A='A1',B='B1',Days=1), 
           b=list(A='A2',B='B1',Days=1)
   ) 


However, I need to run the comparison over the 70 days not at 

individual time points at a time. 



I was wondering if someone could help me designing this contrast matrix. 



Any help would be much appreciated 

Cheers











 		 	   		  
	[[alternative HTML version deleted]]


From juho.kiuru at gmail.com  Wed Jun  1 13:40:19 2016
From: juho.kiuru at gmail.com (Juho Kiuru)
Date: Wed, 1 Jun 2016 14:40:19 +0300
Subject: [R] TwitteR - Number of tweets from multiple locations
Message-ID: <CAEce4UHOd174rMLQoR9uxdnUYBwJFOHiXCY4AFRAW1A=j4MTiA@mail.gmail.com>

Hi all, I am new to R and TwitteR and would love to get some advice from
you.

I managed to get list of tweets containing word 'innovation' tweeted in
Helsinki with following script:

searchTwitter('innovation', n=10000, geocode='60.1920,24.9458,30mi',
since="2016-01-01", until="2016-05-31")

However, I was wondering is it possible to involve multiple locations to
script, so that the result would be number of tweets in each location.

For example, something like this:
Location Tweets
Helsinki 300
Berlin 400
Barcelona 500

Another problem I faced is in setting the time span I would like to have
the count of tweets from. I tried to set the time span from the beginning
of this year to end of May, but it seems like I get only tweets from the
last week of May.

Thanks in advance,
Juho

	[[alternative HTML version deleted]]


From emmanuel.poizot at cnam.fr  Wed Jun  1 14:51:01 2016
From: emmanuel.poizot at cnam.fr (Poizot Emmanuel)
Date: Wed, 1 Jun 2016 14:51:01 +0200
Subject: [R] non-ergodic analysis
Message-ID: <574EDA35.60509@cnam.fr>


Dear all,

I'm looking for a tool to perform  non-ergodic covariance and
correlation analysis. This is in the purpose to study the spatial
autocorrelation of a variable.
Reagrds


*Emmanuel Poizot*
Cnam/Intechmer


From marc_schwartz at me.com  Wed Jun  1 17:16:17 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 01 Jun 2016 10:16:17 -0500
Subject: [R] Unable to update R software to 3.3.0
In-Reply-To: <SG2PR06MB171284796859BE6BC44CD21A9D470@SG2PR06MB1712.apcprd06.prod.outlook.com>
References: <SG2PR06MB171284796859BE6BC44CD21A9D470@SG2PR06MB1712.apcprd06.prod.outlook.com>
Message-ID: <33BC9D1F-9BE0-412C-B6D7-7F76BDF97CC4@me.com>


> On Jun 1, 2016, at 1:33 AM, Sunish Kumar Bilandi <Sunish.Bilandi at evalueserve.com> wrote:
> 
> Hi Team,
> 
> I am using RedHat 5 and installed R using YUM, (R version 3.2.3) Now I want to update R version tp 3.3.0, but I am unable to do that, Is there any alternate to do this?
> 
> Hope to hear from your side.
> 
> Regards,
> 
> 
> Sunish Bilandi
> Business Analyst, CIDA-01
> Evalueserve


Hi,

First, RHEL and related distributions (e.g. Fedora), have a dedicated R-SIG list:
  
  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Future queries in this domain should be submitted there, as many of the RH package maintainers (e.g. Tom Callaway, aka Spot) read that list.

For R 3.3.0, it would appear that it is about a day away from being available for release:

  https://bodhi.fedoraproject.org/updates/FEDORA-EPEL-2016-6fc2c863b0

So for now, it would be available via the EPEL testing repos.

Otherwise, you can wait until it is available via release in the next day or so, or download the RPMS directly here:

  http://koji.fedoraproject.org/koji/buildinfo?buildID=762521

Regards,

Marc Schwartz


From emorway at usgs.gov  Wed Jun  1 18:03:01 2016
From: emorway at usgs.gov (Morway, Eric)
Date: Wed, 1 Jun 2016 09:03:01 -0700
Subject: [R] Trimming time series to only include complete years
In-Reply-To: <alpine.BSF.2.00.1605301456310.85144@pedal.dcn.davis.ca.us>
References: <CAPoqHzrZpb=S6GQRo0O0fszw06pW2_-HKe1MQ34emZANsDJeyQ@mail.gmail.com>
	<alpine.BSF.2.00.1605281251250.73491@pedal.dcn.davis.ca.us>
	<alpine.BSF.2.00.1605301456310.85144@pedal.dcn.davis.ca.us>
Message-ID: <CAPoqHzou=TfHszWqpvAxdepvHO3Lg3-E1TgJfKK0D-rdBz3oFA@mail.gmail.com>

Hello Jeff,  thank you very much for following up with me on this.  It
definitely helped me get on my way with my analysis.  It figures your from
UC Davis (I'm guessing from your email address), I've been helped out by
them often!  -Eric


Eric Morway
Hydrologist
2730 N. Deer Run Rd.
Carson City, NV 89701
(775) 887-7668



On Mon, May 30, 2016 at 3:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Sorry, I put too many bugs (opportunities for excellence!) in this on my
> first pass on this to leave it alone :-(
>
> isPartialWaterYear2 <- function( d ) {
>   dtl <- as.POSIXlt( d )
>   wy1 <- cumsum( ( 9 == dtl$mon ) & ( 1 == dtl$mday ) )
>   # any 0 in wy1 corresponds to first partial water year
>   result <- 0 == wy1
>   # if last day is not Sep 30, mark last water year as partial
>   if ( 8 != dtl$mon[ length( d ) ]
>      | 30 != dtl$mday[ length( d ) ] ) {
>         result[ wy1[ length( d ) ] == wy1 ] <- TRUE
>   }
>   result
> }
>
> dat2 <- dat[ !isPartialWaterYear( dat$Date ), ]
>
> On Sat, 28 May 2016, Jeff Newmiller wrote:
>
> # read about POSIXlt at ?DateTimeClasses
>> # note that the "mon" element is 0-11
>> isPartialWaterYear <- function( d ) {
>>  dtl <- as.POSIXlt( dat$Date )
>>  wy1 <- cumsum( ( 9 == dtl$mon ) & ( 1 == dtl$mday ) )
>>  ( 0 == wy1  # first partial year
>>  | (  8 != dtl$mon[ nrow( dat ) ] # end partial year
>>    & 30 != dtl$mday[ nrow( dat ) ]
>>    ) & wy1[ nrow( dat ) ] == wy1
>>  )
>> }
>>
>> dat2 <- dat[ !isPartialWaterYear( dat$Date ), ]
>>
>> The above assumes that, as you said, the data are continuous at one-day
>> intervals, such that the only partial years will occur at the beginning and
>> end. The "diff" function could be used to identify irregular data within
>> the data interval if needed.
>>
>> On Fri, 27 May 2016, Morway, Eric wrote:
>>
>> In bulk processing streamflow data available from an online database, I'm
>>> wanting to trim the beginning and end of the time series so that daily
>>> data
>>> associated with incomplete "water years" (defined as extending from Oct
>>> 1st
>>> to the following September 30th) is trimmed off the beginning and end of
>>> the series.
>>>
>>> For a small reproducible example, the time series below starts on
>>> 2010-01-01 and ends on 2011-11-05.  So the data between 2010-01-01 and
>>> 2010-09-30 and also between 2011-10-01 and 2011-11-05 is not associated
>>> with a complete set of data for their respective water years.  With the
>>> real data, the initial date of collection is arbitrary, could be 1901 or
>>> 1938, etc.  Because I'm cycling through potentially thousands of
>>> records, I
>>> need help in designing a function that is efficient.
>>>
>>> dat <-
>>>
>>> data.frame(Date=seq(as.Date("2010-01-01"),as.Date("2011-11-05"),by="day"))
>>> dat$Q <- rnorm(nrow(dat))
>>>
>>> dat$wyr <- as.numeric(format(dat$Date,"%Y"))
>>> is.nxt <- as.numeric(format(dat$Date,"%m")) %in% 1:9
>>> dat$wyr[!is.nxt] <- dat$wyr[!is.nxt] + 1
>>>
>>>
>>> function(dat) {
>>>   ...
>>>   returns a subset of dat such that dat$Date > xxxx-09-30 & dat$Date <
>>> yyyy-10-01
>>>   ...
>>> }
>>>
>>> where the years between xxxx-yyyy are "complete" (no missing days).  In
>>> the
>>> example above, the returned dat would extend from 2010-10-01 to
>>> 2011-09-30
>>>
>>> Any offered guidance is very much appreciated.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed Jun  1 19:02:46 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 1 Jun 2016 19:02:46 +0200
Subject: [R] Antwort: Re:  Unable to update R software to 3.3.0
In-Reply-To: <33BC9D1F-9BE0-412C-B6D7-7F76BDF97CC4@me.com>
References: <SG2PR06MB171284796859BE6BC44CD21A9D470@SG2PR06MB1712.apcprd06.prod.outlook.com>
	<33BC9D1F-9BE0-412C-B6D7-7F76BDF97CC4@me.com>
Message-ID: <OFB7E8B08C.8B41E1F5-ONC1257FC5.005B737D-C1257FC5.005DA3AE@lotus.hawesko.de>

Hi all,

I did it today on Debian GNU Linux 8 Jessie this way:

vim /etc/apt/sources.list
deb http://cran.uni-muenster.de/bin/linux/debian jessie-cran3
ESC;:wq

apt.get update
apt-get install r-base r-base-dev

This worked for me.

When installing R packages from within R I found that R needed the 
following:

apt-get install libssl-dev libcurl4-openssl-dev libhunspell-dev 
libxml2-dev 

You probably might to wish to install this also.

HTH.

Kind regards

Georg




Von:    Marc Schwartz <marc_schwartz at me.com>
An:     Sunish Kumar Bilandi <Sunish.Bilandi at evalueserve.com>, 
Kopie:  R-help <r-help at r-project.org>
Datum:  01.06.2016 17:18
Betreff:        Re: [R] Unable to update R software to 3.3.0
Gesendet von:   "R-help" <r-help-bounces at r-project.org>




> On Jun 1, 2016, at 1:33 AM, Sunish Kumar Bilandi 
<Sunish.Bilandi at evalueserve.com> wrote:
> 
> Hi Team,
> 
> I am using RedHat 5 and installed R using YUM, (R version 3.2.3) Now I 
want to update R version tp 3.3.0, but I am unable to do that, Is there 
any alternate to do this?
> 
> Hope to hear from your side.
> 
> Regards,
> 
> 
> Sunish Bilandi
> Business Analyst, CIDA-01
> Evalueserve


Hi,

First, RHEL and related distributions (e.g. Fedora), have a dedicated 
R-SIG list:
 
  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Future queries in this domain should be submitted there, as many of the RH 
package maintainers (e.g. Tom Callaway, aka Spot) read that list.

For R 3.3.0, it would appear that it is about a day away from being 
available for release:

  https://bodhi.fedoraproject.org/updates/FEDORA-EPEL-2016-6fc2c863b0

So for now, it would be available via the EPEL testing repos.

Otherwise, you can wait until it is available via release in the next day 
or so, or download the RPMS directly here:

  http://koji.fedoraproject.org/koji/buildinfo?buildID=762521

Regards,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Wed Jun  1 19:11:31 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 1 Jun 2016 19:11:31 +0200
Subject: [R] Antwort: RE:  Variable labels and value labels
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D135@SRVEXCHMBX.precheza.cz>
References: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502D135@SRVEXCHMBX.precheza.cz>
Message-ID: <OFFC8DE7AA.2CA493A4-ONC1257FC5.005E2EA8-C1257FC5.005E7088@lotus.hawesko.de>

Hi Petr,

I am looking for a general procedure that I can use with any package of R.

As to my current experience it probably will happen that I need a 
procedure from another package than hmisc or memisc and the my solution 
shall work even than so that I do need to find another way to do it.

Kind regards

Georg



Von:    PIKAL Petr <petr.pikal at precheza.cz>
An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, 
"r-help at r-project.org" <r-help at r-project.org>, 
Datum:  31.05.2016 14:56
Betreff:        RE: [R] Variable labels and value labels



Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Tuesday, May 31, 2016 2:01 PM
> To: r-help at r-project.org
> Subject: [R] Variable labels and value labels
>
> Hi All,
>
> I am using R for social sciences. In this field I am used to use short 
variable
> names like "q1" for question 1, "q2" for question 2 and so on and label 
the
> variables like q1 : "Please tell us your age" or q2 : "Could you state 
us your
> household income?" or something similar indicating which question is 
stored
> in the variable.
>
> Similar I am used to label values like 1: "Less than 18 years", 2 : "18 
to
> 30 years", 3 : "31 to 60 years" and 4 : "61 years and more".

Seems to me that it is work for factors

nnn <- sample(1:4, 20, replace=TRUE)
q1 <-factor(nnn, labels=c("Less than 18 years", "18 to 30 years", "31 to 
60 years","61 years and more"))

You can store such variables in data.frame with names "q1" to "qwhatever" 
and possibly "Subject"

And you can store annotation of questions in another data frame with 2 
columns e.g. "Question" and "Description"

Basically it is an approach similar to database and in R you can merge 
those two data.frames by ?merge.
>
> I know that the packages Hmisc and memisc have a functionality for this 
but
> these labeling functions are limited to the packages they were defined 
for.

It seems to me strange. What prevents you to use functions from Hmisc?

Regards
Petr

> Using the question tests as variable names is possible but very 
inconvenient.
>
> I there another way for labeling variables and values in R?
>
> Kind regards
>
> Georg Maubach
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter 
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization 
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.


From marc_schwartz at me.com  Wed Jun  1 19:22:28 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 01 Jun 2016 12:22:28 -0500
Subject: [R] Antwort: Re:  Unable to update R software to 3.3.0
In-Reply-To: <OFB7E8B08C.8B41E1F5-ONC1257FC5.005B737D-C1257FC5.005DA3AE@lotus.hawesko.de>
References: <SG2PR06MB171284796859BE6BC44CD21A9D470@SG2PR06MB1712.apcprd06.prod.outlook.com>
	<33BC9D1F-9BE0-412C-B6D7-7F76BDF97CC4@me.com>
	<OFB7E8B08C.8B41E1F5-ONC1257FC5.005B737D-C1257FC5.005DA3AE@lotus.hawesko.de>
Message-ID: <73E8D7B2-4177-4C8C-B73A-AA8F0163944E@me.com>


> On Jun 1, 2016, at 12:02 PM, G.Maubach at weinwolf.de wrote:
> 
> Hi all,
> 
> I did it today on Debian GNU Linux 8 Jessie this way:
> 
> vim /etc/apt/sources.list
> deb http://cran.uni-muenster.de/bin/linux/debian jessie-cran3
> ESC;:wq
> 
> apt.get update
> apt-get install r-base r-base-dev
> 
> This worked for me.
> 
> When installing R packages from within R I found that R needed the 
> following:
> 
> apt-get install libssl-dev libcurl4-openssl-dev libhunspell-dev 
> libxml2-dev 
> 
> You probably might to wish to install this also.
> 
> HTH.
> 
> Kind regards
> 
> Georg


Georg,

As Sunish noted in his post, he is using Red Hat Enterprise Linux (RHEL), which is an RPM based Linux distribution, as opposed to Debian and it's derivatives like Ubuntu, which use different pre-compiled binaries (.Deb).

Your ability to upgrade on Debian is not relevant to his issue, as a completely different infrastructure (RPM based repositories) is required for RHEL if one wishes to install pre-compiled binaries, as opposed to building from source, which is also an option if one wishes.

Regards,

Marc


> 
> 
> 
> 
> Von:    Marc Schwartz <marc_schwartz at me.com>
> An:     Sunish Kumar Bilandi <Sunish.Bilandi at evalueserve.com>, 
> Kopie:  R-help <r-help at r-project.org>
> Datum:  01.06.2016 17:18
> Betreff:        Re: [R] Unable to update R software to 3.3.0
> Gesendet von:   "R-help" <r-help-bounces at r-project.org>
> 
> 
> 
> 
>> On Jun 1, 2016, at 1:33 AM, Sunish Kumar Bilandi 
> <Sunish.Bilandi at evalueserve.com> wrote:
>> 
>> Hi Team,
>> 
>> I am using RedHat 5 and installed R using YUM, (R version 3.2.3) Now I 
> want to update R version tp 3.3.0, but I am unable to do that, Is there 
> any alternate to do this?
>> 
>> Hope to hear from your side.
>> 
>> Regards,
>> 
>> 
>> Sunish Bilandi
>> Business Analyst, CIDA-01
>> Evalueserve
> 
> 
> Hi,
> 
> First, RHEL and related distributions (e.g. Fedora), have a dedicated 
> R-SIG list:
> 
>  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
> 
> Future queries in this domain should be submitted there, as many of the RH 
> package maintainers (e.g. Tom Callaway, aka Spot) read that list.
> 
> For R 3.3.0, it would appear that it is about a day away from being 
> available for release:
> 
>  https://bodhi.fedoraproject.org/updates/FEDORA-EPEL-2016-6fc2c863b0
> 
> So for now, it would be available via the EPEL testing repos.
> 
> Otherwise, you can wait until it is available via release in the next day 
> or so, or download the RPMS directly here:
> 
>  http://koji.fedoraproject.org/koji/buildinfo?buildID=762521
> 
> Regards,
> 
> Marc Schwartz


From G.Maubach at weinwolf.de  Wed Jun  1 19:37:35 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 1 Jun 2016 19:37:35 +0200
Subject: [R] Antwort: Re:  Variable labels and value labels
In-Reply-To: <CA+8X3fU=nenzXRJy1GyWMFe8Dx6Qf-LKy2BMFYusrT9by_HF9A@mail.gmail.com>
References: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
	<CA+8X3fU=nenzXRJy1GyWMFe8Dx6Qf-LKy2BMFYusrT9by_HF9A@mail.gmail.com>
Message-ID: <OF94AAE502.B31492A3-ONC1257FC5.0060B3F0-C1257FC5.0060D37E@lotus.hawesko.de>

Hi Jim,

many thanks for the hint.

When looking at the documentation I did not get how I do control which 
value gets which label. Is it possible to define it?

Kind regards

Georg




Von:    Jim Lemon <drjimlemon at gmail.com>
An:     G.Maubach at weinwolf.de, r-help mailing list <r-help at r-project.org>, 

Datum:  01.06.2016 03:59
Betreff:        Re: [R] Variable labels and value labels



Hi Georg,
You may find the "add.value.labels" function in the prettyR package 
useful.

Jim

On Tue, May 31, 2016 at 10:00 PM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I am using R for social sciences. In this field I am used to use short
> variable names like "q1" for question 1, "q2" for question 2 and so on 
and
> label the variables like q1 : "Please tell us your age" or q2 : "Could 
you
> state us your household income?" or something similar indicating which
> question is stored in the variable.
>
> Similar I am used to label values like 1: "Less than 18 years", 2 : "18 
to
> 30 years", 3 : "31 to 60 years" and 4 : "61 years and more".
>
> I know that the packages Hmisc and memisc have a functionality for this
> but these labeling functions are limited to the packages they were 
defined
> for. Using the question tests as variable names is possible but very
> inconvenient.
>
> I there another way for labeling variables and values in R?
>
> Kind regards
>
> Georg Maubach
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maillists at pp.inet.fi  Wed Jun  1 19:43:50 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Wed, 1 Jun 2016 20:43:50 +0300
Subject: [R] TwitteR - Number of tweets from multiple locations
In-Reply-To: <CAEce4UHOd174rMLQoR9uxdnUYBwJFOHiXCY4AFRAW1A=j4MTiA@mail.gmail.com>
References: <CAEce4UHOd174rMLQoR9uxdnUYBwJFOHiXCY4AFRAW1A=j4MTiA@mail.gmail.com>
Message-ID: <f457d41e-e6b8-4988-37e9-c285b2fb67c9@pp.inet.fi>

Hi Juho!

01.06.2016, 14:40, Juho Kiuru wrote:
> Hi all, I am new to R and TwitteR and would love to get some advice from
> you.
>
> I managed to get list of tweets containing word 'innovation' tweeted in
> Helsinki with following script:
>
> searchTwitter('innovation', n=10000, geocode='60.1920,24.9458,30mi',
> since="2016-01-01", until="2016-05-31")
>
> However, I was wondering is it possible to involve multiple locations to
> script, so that the result would be number of tweets in each location.
>
> For example, something like this:
> Location Tweets
> Helsinki 300
> Berlin 400
> Barcelona 500

Have your read the documentation ('?searchTwitter'). The argument 
'geocode' cannot be a list, only a single value.

A possible workaround could be to filter tweets based on geocode after 
you have received these. However, since your search pharse is rather ge 
general, you would receive a lot of "noise" as well.

One possibility would be to write a loop with three 'searchTwitter' 
calls with different geocodes. Here you could speed up the data 
collection by setting 'n' to e.g. 100 or 500.

You should, however, consider the fact that geocodes are often supressed 
by the user, so that you would most certainly get only a limited amount 
of tweets.

> Another problem I faced is in setting the time span I would like to have
> the count of tweets from. I tried to set the time span from the beginning
> of this year to end of May, but it seems like I get only tweets from the
> last week of May.

If I remember correctly this is not related to twitteR, but to the 
Twitter API itself. The API limits your search results to contain tweets 
from the last 7 days only.

HTH,
Kimmo

--
Kimmo Elo
?bo Akademi University, Finland / German studies
University of Turku, Finland / DIGIN - Digital Humanities Network


From nourhaine1 at hotmail.fr  Wed Jun  1 19:52:44 2016
From: nourhaine1 at hotmail.fr (nourhaine nefzi)
Date: Wed, 1 Jun 2016 17:52:44 +0000
Subject: [R] Optim():Error in solve.default(crossprod(hm, xm), crossprod(hm,
	ym))
Message-ID: <AM2PR04MB0577A86E9F5DF41B7F55E831E6470@AM2PR04MB0577.eurprd04.prod.outlook.com>

Dear members;
I am stuck trying to find optimal parameters using optim() function. I would be veryy gateful if you could help me on this:

I have the following equation:

                                        Rp,t+1 = rf+ beta*rt+1 (1)

Rp,t+1= the return of the portfolio , fr = free risk rate , rt+1: the return of a strategy. beta has the following expression:
beta=x0+x1*A+ x2*B+ x3*C+x4*D (Estimated using Generalized Method of Moments (GMM).
A,B,C and D are the risk factors related to rt+1.

My objective is to find the optimal values of x1, x2, x3 and x4 that maximize the utility function of the investor.
The code is then :
ret<-cbind(ret)  #ret= rt+1
factors<-cbind(A,B,C,D)

func<-function(x,ret,factors) {
df <- data.frame(A=factors$A*x[1],B=factors$B*x[2],C=factors$C*x[3], D=factors$D*x[4])
H<-as.matrix(factors)
HH<-matrix(H,179,4)
m <- gmm(ret~., data=df, HH)
b<- coef(m)
beta<- b[1]+b[2]*factors$A+b[3]*factors$B+b[4]*factors$C+b[5]*D
beta=cbind(beta)

r=RF+beta*ret  #equation (1)
#Annual Sharpe ratio of the portfolio
averp<-mean(r)*12
sigmap<-sqrt(12)*sd(r)
Sharpe<-averp/sigmap

#Calculating utility
u<-1/nrow(r)*sum((1+r)^(1-5)/(1-5))
obj<-u
result <- list(obj=obj,u=u,beta=beta,r=r,averp=averp,sigmap=sigmap,Sharpe=Sharpe)
return(result)
}

#Catching the obj from the function
Final<-function(x,ret,factors){
bra<-func(x,ret,factors)
#print(bra$obj)
return(-bra$obj)
}
p<-optim(par = c(0,1,2,3),Final,method="Nelder-Mead",ret=ret,factors=factors)
bra<-func(x=p$par,ret=ret,factors=factors)

When I run the code, I get the following error:

Error in solve.default(crossprod(hm, xm), crossprod(hm, ym)) :
  Lapack routine dgesv: system is exactly singular: U[2,2] = 0

Could you please help me ! Thank you in advance

	[[alternative HTML version deleted]]


From vinaypkulkarni at yahoo.com  Wed Jun  1 19:41:59 2016
From: vinaypkulkarni at yahoo.com (VINAY KULKARNI)
Date: Wed, 1 Jun 2016 17:41:59 +0000 (UTC)
Subject: [R] SEM GFI
In-Reply-To: <CAGxFJbTp+0uDC1YDxF-LgDsvcEx_69BU=Nc+BBqMMZnP9j3t9Q@mail.gmail.com>
References: <1103804586.1954135.1464719331934.JavaMail.yahoo.ref@mail.yahoo.com>
	<1103804586.1954135.1464719331934.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbTp+0uDC1YDxF-LgDsvcEx_69BU=Nc+BBqMMZnP9j3t9Q@mail.gmail.com>
Message-ID: <234506459.2505773.1464802919535.JavaMail.yahoo@mail.yahoo.com>

Hi,
Please find below the code:
Thanks,Vinay
>library(sem)?>data1=read.csv("data_1.csv")?>corr=cor(data1)?model1<-specifyModel()brand1_Pric_ind????->???Val_brand1,lamb1,NADist_brand1???????->???Val_brand1,lamb2,NAbrand1_like_me?????->???Val_brand1,lamb3,NAbrand2_Def_Drink ->???Val_brand1,lamb4,NAbrand2_Like -> brand2_Def_Drink,lamb5,NAbrand2_Pleasure -> brand2_Def_Drink,lamb6,NAbrand1_Like -> brand1_like_me,lamb7,NAbrand1_Love -> brand1_like_me,lamb8,NAbrand1_P4WC -> brand1_Like,lamb9,NAbrand1_P4WC -> brand1_Love,lamb10,NAbrand1_Energy -> brand1_P4WC,lamb11,NAbrand1_Different -> brand1_P4WC,lamb12,NAbrand1_Pric_ind <-> brand1_Pric_ind,the1,NADist_brand1 <-> Dist_brand1,the2,NAbrand1_like_me??<-> brand1_like_me,the3,NAbrand2_Def_Drink <-> brand2_Def_Drink,the4,NAbrand2_Like <-> brand2_Like,the5,NAbrand2_Pleasure <-> brand2_Pleasure,the6,NAbrand1_Like <-> brand1_Like,the7,NAbrand1_Love <-> brand1_Love,the8,NAbrand1_P4WC <-> brand1_P4WC,the9,NAbrand1_Energy <-> brand1_Energy,the10,NAbrand1_Different <-> brand1_Different,the11,NAbrand1_like_me??<-> brand2_Def_Drink,the12,NAbrand1_Like <-> brand1_Love,the13,NAVal_brand1 <-> Val_brand1,1,NA??> opt <- options(fit.indices = c("GFI", "AGFI", "RMSEA", "NFI", "NNFI", "CFI", "RNI", "IFI", "SRMR", "AIC", "AICc", "BIC", "CAIC"))?> sem.model1<-sem(model1,corr,36)
> summary(sem.model1)




      From: Bert Gunter <bgunter.4567 at gmail.com>
 To: VINAY KULKARNI <vinaypkulkarni at yahoo.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org>
 Sent: Wednesday, 1 June 2016 2:16 AM
 Subject: Re: [R] SEM GFI
   
Probably impossible to answer without your following the posting guide
and posting your code, etc.

Cheers,

Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, May 31, 2016 at 11:28 AM, VINAY KULKARNI via R-help
<r-help at r-project.org> wrote:
> Hi,
> I am exactly replicating the SEM model which was done in SAS using Proc Calis in R.
> Used sem package in R but not getting the GFI as same as in SAS (approximately 15% difference)
> and also one link is insignificant but in SAS am getting significant.
> Searched through online in different blogs but not able to get the solution.
> Please let me know what might be the reason.
> Thanks,Vinay
>
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Wed Jun  1 23:11:43 2016
From: hannah.hlx at gmail.com (li li)
Date: Wed, 1 Jun 2016 17:11:43 -0400
Subject: [R] Fwd:  model specification using lme
In-Reply-To: <CAJuCY5wMrELKbj+SY7MeAz+qV=-Ya8GRiNRDMSV2dPr_5WJSMg@mail.gmail.com>
References: <CAHLnndYK-UEt84Mb9Rncm_Q1aTOX8EzttfE-Jt1JGN0dg0MMDg@mail.gmail.com>
	<CAJuCY5wMrELKbj+SY7MeAz+qV=-Ya8GRiNRDMSV2dPr_5WJSMg@mail.gmail.com>
Message-ID: <CAHLnndZ1jB3dyBwRTmf-xBOiJ2Q4C27i7scy3KmGC5h5G7xKSw@mail.gmail.com>

Thanks Thierry for the reply. I think I now have a better understanding for
the specification of the random effects when using lme function.
Are my interpretations below correct?

random=~ 1 | individual   (same random intercept no random slope)

random=~ 1 +method| individual    (same random intercept and same random
slope)

random=~ 1 +method:time| individual    (same random intercept and different
random slope for different method)
random=~ 1 +method + method:time| individual    (different random intercept
and different random slope for different method

 The summary results from the lme function shows whether the slopes for the
three methods are equal (parallelism). I also wanted to test the hypotheses
that each of the fixed slopes (corresponding to the three methods) equals
0, can I use multicomp package for that purpose? I am confused on how to
make correct specifications in glht function to test these hypotheses.

Hanna


> summary(mod1)
Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352

Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014
*time              0.07010  0.250983 57  0.279301  0.7810 method2:time
-0.12616  0.360585 57 -0.349877  0.7277 method3:time -0.08010  0.251105 57
-0.318999  0.7509*
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874

Number of Observations: 69
Number of Groups: 7 >



---------- Forwarded message ----------
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Date: 2016-05-30 4:40 GMT-04:00
Subject: Re: [R] model specification using lme
To: li li <hannah.hlx at gmail.com>
Cc: r-help <r-help at r-project.org>



Dear Hanna,

None of the models are correct is you want the same random intercept for
the different methods but different random slope per method.

You can random = ~ 1 + time:method | individual

The easiest way to get alpha_0 and tau_i is to apply post-hoc contrasts.
That is fairly easy to do with the multcomp package.

alpha_0 = (m1 + m2 + m3) / 3
m1 = intercept
m2 = intercept + method2
m3 = intercept + method3
hence alpha_0 = intercept + method2/3 + method3/3

m1 = alpha_0 + tau_1
tau_1 = intercept - method2/3 - method3/3

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-05-29 21:23 GMT+02:00 li li <hannah.hlx at gmail.com>:


> Hi all,
>   For the following data, I consider the following random intercept and
> random slope model. Denote as y_ijk the response value from *j*th
> individual within *i*th method at time point *k*. Assume the following
> model for y_ijk:
>
>       y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk
>
>
> Here alpha_0 is the grand mean;
>           tau_i is the fixed effect for ith method;
>           a_j(i) is random intercept corresponding to the *j*th individual
> within *i*th method, assumed to be common for all three methods;
>           beta_i is the fixed slope corresponding to the ith method;
>           b_j(i) is the random slope corresponding to jth individual for
> the ith method, assumed to be different for different methods;
>           T_k is the time corresponding to y_ijk;
>           e_ijk is the residual.
>
> For this model, I consider the three specification using  the lme function
> as follows:
>
>
> mod1 <- lme(fixed= reponse ~ method*time, random=~ 1 +time | individual,
> data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> mod2 <- lme(fixed= reponse ~ method*time, random=~ 0 +time | individual,
> data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> mod3 <- lme(fixed= reponse ~ method*time, random=~ method +time |
> individual, data=one, weights= varIdent(form=~1|method),
>             control = lmeControl(opt = "optim"))
>
> I think mod1 is the correct one. However, I am kind of confused with the
> right usage of lme function. Can someone familiar with this give some help
> here?
>
> Another question is regarding the fixed effect   tau_1, tau_2 and tau_3
> (corresponding to the three methods). One main question I am interested in
> is whether each of them are statistically different from zero. In the
> summary results below (shaded part), it looks that the result for method 2
> and 3 are given with reference to method 1). Is there a way to obtain
> specific result separately for alpha_0 (the overall mean) and also tau_1,
> tau_2 and tau3?
>
> Thanks very much for the help!
>    Hanna
>
>
> > summary(mod1)Linear mixed-effects model fit by REML
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
>
>
>
>
> > one   response individual time method
> 1    102.9          3    0      3
> 2    103.0          3    3      3
> 3    103.0          3    6      3
> 4    102.8          3    9      3
> 5    102.2          3   12      3
> 6    102.5          3   15      3
> 7    103.0          3   18      3
> 8    102.0          3   24      3
> 9    102.8          1    0      3
> 10   102.7          1    3      3
> 11   103.0          1    6      3
> 12   102.2          1    9      3
> 13   103.0          1   12      3
> 14   102.8          1   15      3
> 15   102.8          1   18      3
> 16   102.9          1   24      3
> 17   102.2          2    0      3
> 18   102.6          2    3      3
> 19   103.4          2    6      3
> 20   102.3          2    9      3
> 21   101.3          2   12      3
> 22   102.1          2   15      3
> 23   102.1          2   18      3
> 24   102.2          2   24      3
> 25   102.7          4    0      3
> 26   102.3          4    3      3
> 27   102.6          4    6      3
> 28   102.7          4    9      3
> 29   102.8          4   12      3
> 30   102.5          5    0      3
> 31   102.4          5    3      3
> 32   102.1          5    6      3
> 33   102.3          6    0      3
> 34   102.3          6    3      3
> 35   101.9          7    0      3
> 36   102.0          7    3      3
> 37   107.4          3    0      1
> 38   101.3          3   12      1
> 39    92.8          3   15      1
> 40    73.7          3   18      1
> 41   104.7          3   24      1
> 42    92.6          1    0      1
> 43   101.9          1   12      1
> 44   106.3          1   15      1
> 45   104.1          1   18      1
> 46    95.6          1   24      1
> 47    79.8          2    0      1
> 48    89.7          2   12      1
> 49    97.0          2   15      1
> 50   108.4          2   18      1
> 51   103.5          2   24      1
> 52    96.4          4    0      1
> 53    89.3          4   12      1
> 54   112.6          5    0      1
> 55    93.3          6    0      1
> 56    99.6          7    0      1
> 57   109.5          3    0      2
> 58    98.5          3   12      2
> 59   103.5          3   24      2
> 60   113.5          1    0      2
> 61    94.5          1   12      2
> 62    88.5          1   24      2
> 63    99.5          2    0      2
> 64    97.5          2   12      2
> 65    98.5          2   24      2
> 66   103.5          4    0      2
> 67    89.5          5    0      2
> 68    87.5          6    0      2
> 69    82.5          7    0      2
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Jun  2 00:57:18 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 2 Jun 2016 08:57:18 +1000
Subject: [R] Variable labels and value labels
In-Reply-To: <OF94AAE502.B31492A3-ONC1257FC5.0060B3F0-C1257FC5.0060D37E@lotus.hawesko.de>
References: <OF1C9BED83.8BE86DD3-ONC1257FC4.00413344-C1257FC4.0041FD1B@lotus.hawesko.de>
	<CA+8X3fU=nenzXRJy1GyWMFe8Dx6Qf-LKy2BMFYusrT9by_HF9A@mail.gmail.com>
	<OF94AAE502.B31492A3-ONC1257FC5.0060B3F0-C1257FC5.0060D37E@lotus.hawesko.de>
Message-ID: <CA+8X3fUTXAa1j9G72aPtJS9QRnQ+RON8jQms0nYBsevRd4TkbA@mail.gmail.com>

Hi Georg,
add.value.labels simply creates an attribute named "value.labels" for
the sorted values of the vector passed to it. The value labels passed
become the names of this attribute in the sorted order. The function
is intended to mimic a factor in reverse. While the factor adds
sequential numeric values to the original values, add.value.labels
adds names to the values passed. It was intended to be a mnemonic for
numeric values that perhaps should have been coded as character. If I
wrote this function now, it would probably look like this:

value.labels<-function(x,labels) {
 if(missing(labels)) return(attr(x,"value.labels"))
 else {
  attr(x,"value.labels") <- sort(unique(x))
  lenvallab <- length(attr(x,"value.labels"))
  if (length(labels) > lenvallab) {
   cat("More value labels than values, only the first",
    lenvallab, "will be used\n")
   labels <- labels[1:lenvallab]
  }
  names(attr(x, "value.labels"))<-labels
  return(x)
 }
}

age<-sample(1:5,100,TRUE)
value.labels(age)
age<-value.labels(age,c("0-19","20-39","40-59","60-79","80+"))
age
value.labels(age)

Jim

On Thu, Jun 2, 2016 at 3:37 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi Jim,
>
> many thanks for the hint.
>
> When looking at the documentation I did not get how I do control which
> value gets which label. Is it possible to define it?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Jim Lemon <drjimlemon at gmail.com>
> An:     G.Maubach at weinwolf.de, r-help mailing list <r-help at r-project.org>,
>
> Datum:  01.06.2016 03:59
> Betreff:        Re: [R] Variable labels and value labels
>
>
>
> Hi Georg,
> You may find the "add.value.labels" function in the prettyR package
> useful.
>
> Jim
>
> On Tue, May 31, 2016 at 10:00 PM,  <G.Maubach at weinwolf.de> wrote:
>> Hi All,
>>
>> I am using R for social sciences. In this field I am used to use short
>> variable names like "q1" for question 1, "q2" for question 2 and so on
> and
>> label the variables like q1 : "Please tell us your age" or q2 : "Could
> you
>> state us your household income?" or something similar indicating which
>> question is stored in the variable.
>>
>> Similar I am used to label values like 1: "Less than 18 years", 2 : "18
> to
>> 30 years", 3 : "31 to 60 years" and 4 : "61 years and more".
>>
>> I know that the packages Hmisc and memisc have a functionality for this
>> but these labeling functions are limited to the packages they were
> defined
>> for. Using the question tests as variable names is possible but very
>> inconvenient.
>>
>> I there another way for labeling variables and values in R?
>>
>> Kind regards
>>
>> Georg Maubach
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From zadig_1 at excite.com  Thu Jun  2 04:30:29 2016
From: zadig_1 at excite.com (ce)
Date: Wed, 01 Jun 2016 22:30:29 -0400
Subject: [R] Making an if condition variable ?
Message-ID: <20160601223029.1880@web003.roc2.bluetie.com>


Dear all,

I want to make an if condition variable like :

a = 10
CONDITION = " a > 0 "

if ( CONDITION ) print(" a is bigger" ) 

I tried get , getElement , eval without success ?

Thanks


From drjimlemon at gmail.com  Thu Jun  2 05:03:01 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 2 Jun 2016 13:03:01 +1000
Subject: [R] Making an if condition variable ?
In-Reply-To: <20160601223029.1880@web003.roc2.bluetie.com>
References: <20160601223029.1880@web003.roc2.bluetie.com>
Message-ID: <CA+8X3fVFKqQ+KX9PtCLQB3QK=+Ti0WzE8p9AKDw4A0BDo-Yw6A@mail.gmail.com>

Hi ce,

a<-10
condition<-expression("a>0")
if(eval(parse(text=condition))) cat("a>0\n")

Jim

On Thu, Jun 2, 2016 at 12:30 PM, ce <zadig_1 at excite.com> wrote:
>
> Dear all,
>
> I want to make an if condition variable like :
>
> a = 10
> CONDITION = " a > 0 "
>
> if ( CONDITION ) print(" a is bigger" )
>
> I tried get , getElement , eval without success ?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Jun  2 05:06:31 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 1 Jun 2016 23:06:31 -0400
Subject: [R] Making an if condition variable ?
In-Reply-To: <20160601223029.1880@web003.roc2.bluetie.com>
References: <20160601223029.1880@web003.roc2.bluetie.com>
Message-ID: <CA+vqiLGiS7sggCiU-y-z4h5irzozHPBQRFCc1rDFT2saGgNecQ@mail.gmail.com>

if ( eval(parse(text=CONDITION ))) print(" a is bigger" )

Best,
Ista
On Jun 1, 2016 10:32 PM, "ce" <zadig_1 at excite.com> wrote:

>
> Dear all,
>
> I want to make an if condition variable like :
>
> a = 10
> CONDITION = " a > 0 "
>
> if ( CONDITION ) print(" a is bigger" )
>
> I tried get , getElement , eval without success ?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Jun  2 05:13:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 01 Jun 2016 20:13:41 -0700
Subject: [R] Making an if condition variable ?
In-Reply-To: <20160601223029.1880@web003.roc2.bluetie.com>
References: <20160601223029.1880@web003.roc2.bluetie.com>
Message-ID: <0EF7215F-B4DD-4DDD-8421-B65C487FE02C@dcn.davis.ca.us>

Beware of getting too "meta" in your programming... it is rarely worth it. Just write the code and move on with life. That is the beauty of a scripting language. 
-- 
Sent from my phone. Please excuse my brevity.

On June 1, 2016 7:30:29 PM PDT, ce <zadig_1 at excite.com> wrote:
>
>Dear all,
>
>I want to make an if condition variable like :
>
>a = 10
>CONDITION = " a > 0 "
>
>if ( CONDITION ) print(" a is bigger" ) 
>
>I tried get , getElement , eval without success ?
>
>Thanks
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rmh at temple.edu  Thu Jun  2 05:20:52 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 1 Jun 2016 23:20:52 -0400
Subject: [R] Making an if condition variable ?
In-Reply-To: <20160601223029.1880@web003.roc2.bluetie.com>
References: <20160601223029.1880@web003.roc2.bluetie.com>
Message-ID: <CAGx1TMBasXBXzaAnQhog2XMTsV-szsEqSQNCZb46=jXRVgF2JQ@mail.gmail.com>

a <- 10
CONDITION <-  (a > 0)

if ( CONDITION ) print(" a is bigger" )

On Wed, Jun 1, 2016 at 10:30 PM, ce <zadig_1 at excite.com> wrote:
>
> Dear all,
>
> I want to make an if condition variable like :
>
> a = 10
> CONDITION = " a > 0 "
>
> if ( CONDITION ) print(" a is bigger" )
>
> I tried get , getElement , eval without success ?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jared.rodecker at gmail.com  Thu Jun  2 01:16:31 2016
From: jared.rodecker at gmail.com (Jared Rodecker)
Date: Wed, 1 Jun 2016 16:16:31 -0700
Subject: [R] httr package syntax (PUT)
Message-ID: <CALVRum4dY=oeURQ7qTw9gPtx-DWPh=cMfHzX==tJtPbhAikD+A@mail.gmail.com>

Greetings fellow R users.

I'm struggling with the syntax of submitting a PUT request

I'm trying to insert a few PUT requests into some legacy R code that I have
that performs daily ETL on a small database. These requests will add users
to an email mailing list in MailChimp.


I have been able to get my GET requests formatted into syntax that R
(specifically the httr package) accepts:

GET("
https://us10.api.mailchimp.com/3.0/lists/list_id_XXXXX/members/MEMBER_HASH_#######",
query = list(apikey = 'XXXXXXXXXXXXXX'))


However when I try to do something similar for PUT requests this simple
syntax isn't working - you can't just pass the API KEY and/or requested
parameters directly through the URL. I get a 401 error if I use the same
syntax I used for GET.


I believe that I need to use the CONFIG option to pass the API key (either
using AUTHENTICATE or ADD_HEADERS) and the requested parameters in the BODY
to get the PUT request to work but I can't get the syntax to work - this
gives a 400 error:


auth <- authenticate("anystring", "XXXXXXXXXXXXXX", type = "basic")

parms <- '[{"email_address" : "some_user at domain.com", "status_if_new" :
"subscribed"}]'

PUT("
https://us10.api.mailchimp.com/3.0/lists/list_id_XXXXX/members/MEMBER_HASH_#######
",config=auth,body=parms,encode="json")


If anyone can point me to a more flushed out example that would be
amazing...but even just some tips on how to get more info on my error
message to help me troubleshoot my syntax would also be a big help.  I've
also been trying to get httpput (from the RCurl package) but also
struggling with the syntax there.


Thanks!


Jared

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Thu Jun  2 08:31:29 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 2 Jun 2016 08:31:29 +0200
Subject: [R] Unable to update R software to 3.3.0
References: <SG2PR06MB171284796859BE6BC44CD21A9D470@SG2PR06MB1712.apcprd06.prod.outlook.com>
Message-ID: <878tyot83i.fsf@hornfels.zedat.fu-berlin.de>

Hi Sunish,

Sunish Kumar Bilandi <Sunish.Bilandi at evalueserve.com> writes:

> Hi Team,
>
> I am using RedHat 5 and installed R using YUM, (R version 3.2.3) Now I
> want to update R version tp 3.3.0, but I am unable to do that, Is
> there any alternate to do this?
>
> Hope to hear from your side.
>
> Regards,
>
>
> Sunish Bilandi
> Business Analyst, CIDA-01
> Evalueserve

You don't say what the problem is, but I'm running Scientific Linux 6.7,
which is based on the corresponding version of Red Hat, and have found
that I cannot install R 3.3.0, because the version of zlib available is
too old.  R 3.3.0 requires zlib >= 1.2.5, whereas the version in the SL
repositories is 1.2.3.

So if this is the problem, then you either have to install newer version
of zlib from source or switch to RH7, which comes with zlib 1.2.7.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From loris.bennett at fu-berlin.de  Thu Jun  2 08:46:48 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 2 Jun 2016 08:46:48 +0200
Subject: [R] Unable to update R software to 3.3.0
References: <SG2PR06MB171284796859BE6BC44CD21A9D470@SG2PR06MB1712.apcprd06.prod.outlook.com>
	<878tyot83i.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <874m9ct7dz.fsf@hornfels.zedat.fu-berlin.de>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> Hi Sunish,
>
> Sunish Kumar Bilandi <Sunish.Bilandi at evalueserve.com> writes:
>
>> Hi Team,
>>
>> I am using RedHat 5 and installed R using YUM, (R version 3.2.3) Now I
>> want to update R version tp 3.3.0, but I am unable to do that, Is
>> there any alternate to do this?
>>
>> Hope to hear from your side.
>>
>> Regards,
>>
>>
>> Sunish Bilandi
>> Business Analyst, CIDA-01
>> Evalueserve
>
> You don't say what the problem is, but I'm running Scientific Linux 6.7,
> which is based on the corresponding version of Red Hat, and have found
> that I cannot install R 3.3.0, because the version of zlib available is
> too old.  R 3.3.0 requires zlib >= 1.2.5, whereas the version in the SL
> repositories is 1.2.3.
>
> So if this is the problem, then you either have to install newer version
> of zlib from source or switch to RH7, which comes with zlib 1.2.7.

I forgot to say that for RH7, R 3.3.0 is available from the EPEL
repository, whereas for RH5 or RH6 you will have to install R from
source.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From maechler at stat.math.ethz.ch  Thu Jun  2 08:48:14 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 2 Jun 2016 08:48:14 +0200
Subject: [R] Making an if condition variable ?
In-Reply-To: <CA+8X3fVFKqQ+KX9PtCLQB3QK=+Ti0WzE8p9AKDw4A0BDo-Yw6A@mail.gmail.com>
References: <20160601223029.1880@web003.roc2.bluetie.com>
	<CA+8X3fVFKqQ+KX9PtCLQB3QK=+Ti0WzE8p9AKDw4A0BDo-Yw6A@mail.gmail.com>
Message-ID: <22351.54958.798111.429036@stat.math.ethz.ch>

>>>>> Jim Lemon <drjimlemon at gmail.com>
>>>>>     on Thu, 2 Jun 2016 13:03:01 +1000 writes:

    > Hi ce,

    > a<-10
    > condition<-expression("a>0")
    > if(eval(parse(text=condition))) cat("a>0\n")

While this may answer the question asked,
the above is *not* good advice, excuse me, Jim :

> fortune(106)

If the answer is parse() you should usually rethink the question.
   -- Thomas Lumley
      R-help (February 2005)

> fortune(181)

Personally I have never regretted trying not to underestimate my own future stupidity.
   -- Greg Snow (explaining why eval(parse(...)) is often suboptimal, answering a question
      triggered by the infamous fortune(106))
      R-help (January 2007)

---------------------

Good advice would emphasize to use  expressions rather than
strings.... and yes that's a bit more sophistication.

But it's worth it.
Martin


> 
    > Jim

    > On Thu, Jun 2, 2016 at 12:30 PM, ce <zadig_1 at excite.com> wrote:
    >> 
    >> Dear all,
    >> 
    >> I want to make an if condition variable like :
    >> 
    >> a = 10
    >> CONDITION = " a > 0 "
    >> 
    >> if ( CONDITION ) print(" a is bigger" )
    >> 
    >> I tried get , getElement , eval without success ?
    >> 
    >> Thanks
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From loris.bennett at fu-berlin.de  Thu Jun  2 09:17:25 2016
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 2 Jun 2016 09:17:25 +0200
Subject: [R] Unable to update R software to 3.3.0
References: <SG2PR06MB171284796859BE6BC44CD21A9D470@SG2PR06MB1712.apcprd06.prod.outlook.com>
	<878tyot83i.fsf@hornfels.zedat.fu-berlin.de>
	<874m9ct7dz.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <87pos0rrei.fsf@hornfels.zedat.fu-berlin.de>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> Loris Bennett <loris.bennett at fu-berlin.de> writes:
>
>> Hi Sunish,
>>
>> Sunish Kumar Bilandi <Sunish.Bilandi at evalueserve.com> writes:
>>
>>> Hi Team,
>>>
>>> I am using RedHat 5 and installed R using YUM, (R version 3.2.3) Now I
>>> want to update R version tp 3.3.0, but I am unable to do that, Is
>>> there any alternate to do this?
>>>
>>> Hope to hear from your side.
>>>
>>> Regards,
>>>
>>>
>>> Sunish Bilandi
>>> Business Analyst, CIDA-01
>>> Evalueserve
>>
>> You don't say what the problem is, but I'm running Scientific Linux 6.7,
>> which is based on the corresponding version of Red Hat, and have found
>> that I cannot install R 3.3.0, because the version of zlib available is
>> too old.  R 3.3.0 requires zlib >= 1.2.5, whereas the version in the SL
>> repositories is 1.2.3.
>>
>> So if this is the problem, then you either have to install newer version
>> of zlib from source or switch to RH7, which comes with zlib 1.2.7.
>
> I forgot to say that for RH7, R 3.3.0 is available from the EPEL
> repository, whereas for RH5 or RH6 you will have to install R from
> source.

I wrote too soon:  Today an update to R 3.3.0 for SL6 has been made
available.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From Rainer at krugs.de  Thu Jun  2 09:59:19 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 02 Jun 2016 09:59:19 +0200
Subject: [R] Making an if condition variable ?
In-Reply-To: <0EF7215F-B4DD-4DDD-8421-B65C487FE02C@dcn.davis.ca.us> (Jeff
	Newmiller's message of "Wed, 01 Jun 2016 20:13:41 -0700")
References: <20160601223029.1880@web003.roc2.bluetie.com>
	<0EF7215F-B4DD-4DDD-8421-B65C487FE02C@dcn.davis.ca.us>
Message-ID: <m21t4gvx60.fsf@krugs.de>

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:

> Beware of getting too "meta" in your programming... it is rarely worth
> it. Just write the code and move on with life. That is the beauty of a
> scripting language.

+1

I think this a very common pitfall (I know it from own experience...)
and I would say a candidate for a fortune?

Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160602/4a93d6ec/attachment.bin>

From milujisb at gmail.com  Thu Jun  2 10:42:55 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Thu, 2 Jun 2016 09:42:55 +0100
Subject: [R] Convert ncdf data to dataframe
Message-ID: <CAMLwc7Og1uQUqh_t=Dv5S4RDW4D=bZd2XNz9C+qDLvrO-eA3BQ@mail.gmail.com>

Dear all,

I have used the following code to read in a ncdf file

library(chron)
library(lattice)
library(ncdf4)
library(data.table)

ncname <- ("/file_path")
ncfname <- paste(ncname, ".nc", sep = "")
dname <- "ssl"  # note: tmp means temperature (not temporary)

ncin <- nc_open(ncfname)
print(ncin)

The attributes of the file are:

     4 variables (excluding dimension variables):
        double longitude[row]
            long_name: longitude
            units: degrees_east
            standard_name: longitude
        double latitude[row]
            long_name: latitude
            units: degrees_north
            standard_name: latitude
        double ssl[col,row]
            long_name: storm surge level
            units: m
            _FillValue: -99999
            scale_factor: 1
            add_offset: 1
        float RP[col]
            long_name: return period
            units: yr
            Contents: The RPs have been estimated following the Peak Over
Threshold Method (see reference below)
            Starting date: 01-Dec-2009
            End date: 30-Nov-2099 21:00:00
     2 dimensions:
        col  Size:8
        row  Size:2242

I would like to convert the data into a dataframe by longitude and
latitude. Is that possible? Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From francesca.pancotto at gmail.com  Thu Jun  2 11:37:50 2016
From: francesca.pancotto at gmail.com (francesca Pancotto)
Date: Thu, 2 Jun 2016 11:37:50 +0200
Subject: [R] Map of Italy data filled at the level of the province
Message-ID: <F92B6E85-00DB-41C4-986B-5D7146F40719@gmail.com>

Dear Users
I am very new to the use of ggplot. I am supposed to make a plot of 
Italian provinces in which I have to fill the color of some provinces 
with the values of a variable(I do not provide the data because it is irrelevant which data to use).

Right now I explored the function map in maps package thanks to which I managed to plot
the map of Italy with provinces borders and select only those provinces contained in the 
vector nomi(which is just a list of character elements with the names of the provinces which are 
just like counties in the US).

map("italy",col=1:20, regions=nomi)

The problem is to fill the provinces level with the values of a variable that is the variable of interest:
I found a series of examples based on US data extracted from very hard to get databases.

Can anyone provide an easy example where to start from?

Thanks in advance
Francesca

----------------------------------
Francesca Pancotto
Professore Associato di Politica Economica
Universit? degli Studi di Modena e Reggio Emilia
Palazzo Dossetti - Viale Allegri, 9 - 42121 Reggio Emilia
Office: +39 0522 523264
Web: https://sites.google.com/site/francescapancotto/
----------------------------------


	[[alternative HTML version deleted]]


From bob at rudis.net  Thu Jun  2 12:21:02 2016
From: bob at rudis.net (boB Rudis)
Date: Thu, 2 Jun 2016 06:21:02 -0400
Subject: [R] Map of Italy data filled at the level of the province
In-Reply-To: <F92B6E85-00DB-41C4-986B-5D7146F40719@gmail.com>
References: <F92B6E85-00DB-41C4-986B-5D7146F40719@gmail.com>
Message-ID: <CAJ4QxaOeaZuPQYtCEAF21O28xigL_w83Pa8dLXOJyCCX-NBjVA@mail.gmail.com>

This should help you get started:

  library(maptools)
  library(ggplot2)
  library(ggalt)
  library(ggthemes)
  library(tibble)
  library(viridis)

  # get italy region map
  italy_map <- map_data("italy")

  # your data will need to have these region names
  print(unique(italy_map$region))

  # we'll simulate some data for this
  set.seed(1492)
  choro_dat <- data_frame(region=unique(italy_map$region),
                          value=sample(100, length(region)))

  # we'll use this in a bit
  italy_proj <- "+proj=aea +lat_1=38.15040684902542
+lat_2=44.925490198742295 +lon_0=12.7880859375"

  gg <- ggplot()

  # lay down the base layer
  gg <- gg + geom_map(data=italy_map, map=italy_map,
                      aes(long, lat, map_id=region),
                      color="#b2b2b2", size=0.1, fill=NA)

  # fill in the regions with the data
  gg <- gg + geom_map(data=choro_dat, map=italy_map,
                      aes(fill=value, map_id=region),
                      color="#b2b2b2", size=0.1)

  # great color palette (use a better legend title)
  gg <- gg + scale_fill_viridis(name="Scale title")

  # decent map projection for italy choropleth
  gg <- gg + coord_proj(italy_proj)

  # good base theme for most maps
  gg <- gg + theme_map()

  # move the legend
  gg <- gg + theme(legend.position=c(0.95, 0.3))

  gg

This uses a continuous color palette for the region fill. You may want
to consider binning data and using a discrete fill (IMO that's usually
a better choice for most choropleths).

-Bob

On Thu, Jun 2, 2016 at 5:37 AM, francesca Pancotto
<francesca.pancotto at gmail.com> wrote:
> Dear Users
> I am very new to the use of ggplot. I am supposed to make a plot of
> Italian provinces in which I have to fill the color of some provinces
> with the values of a variable(I do not provide the data because it is irrelevant which data to use).
>
> Right now I explored the function map in maps package thanks to which I managed to plot
> the map of Italy with provinces borders and select only those provinces contained in the
> vector nomi(which is just a list of character elements with the names of the provinces which are
> just like counties in the US).
>
> map("italy",col=1:20, regions=nomi)
>
> The problem is to fill the provinces level with the values of a variable that is the variable of interest:
> I found a series of examples based on US data extracted from very hard to get databases.
>
> Can anyone provide an easy example where to start from?
>
> Thanks in advance
> Francesca
>
> ----------------------------------
> Francesca Pancotto
> Professore Associato di Politica Economica
> Universit? degli Studi di Modena e Reggio Emilia
> Palazzo Dossetti - Viale Allegri, 9 - 42121 Reggio Emilia
> Office: +39 0522 523264
> Web: https://sites.google.com/site/francescapancotto/
> ----------------------------------
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jean-externe.maurice at edf.fr  Thu Jun  2 12:41:40 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Thu, 2 Jun 2016 10:41:40 +0000
Subject: [R] translating function td of package tempdisagg to FORTRAN
Message-ID: <4ad30546f70b49969462ef8bae4489b2@NOEINTPEXMU007.NEOPROD.EDF.FR>

I am (still) translating long R scripts to FORTRAN to improve speed. My client deals with river's flow.

He has datas for each day of a week, we need to 'disaggregate' them to an hourly base (is that clear ?) . In R, he uses function td of library tempdisagg with the 'denton-cholette' algorithm. I would like to translate this function in FORTRAN.

I searched for denton-cholette on internet but only found 'mathematical answers' I am not able to understand.

I would like to have some  informations about this function :
  Is it only a 'wrapper' to a C or Fortran library or is it a true R function ?
  Is the source (R, Fortran, C, ...) available somewhere ?

Thanks in advance for all information you can give me !
Jean in France

PS please can you send a copy of your response directly to my address 'jean-externe.maurice at edf.fr'
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From bhh at xs4all.nl  Thu Jun  2 12:55:55 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 2 Jun 2016 12:55:55 +0200
Subject: [R] translating function td of package tempdisagg to FORTRAN
In-Reply-To: <4ad30546f70b49969462ef8bae4489b2@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <4ad30546f70b49969462ef8bae4489b2@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <F189753D-BB43-462D-8F96-625AD802F2D9@xs4all.nl>


> On 2 Jun 2016, at 12:41, MAURICE Jean - externe <jean-externe.maurice at edf.fr> wrote:
> 
> I am (still) translating long R scripts to FORTRAN to improve speed. My client deals with river's flow.
> 
> He has datas for each day of a week, we need to 'disaggregate' them to an hourly base (is that clear ?) . In R, he uses function td of library tempdisagg with the 'denton-cholette' algorithm. I would like to translate this function in FORTRAN.
> 
> I searched for denton-cholette on internet but only found 'mathematical answers' I am not able to understand.
> 
> I would like to have some  informations about this function :
>  Is it only a 'wrapper' to a C or Fortran library or is it a true R function ?
>  Is the source (R, Fortran, C, ...) available somewhere ?
> 

It is R.
Source of the tempdisagg package can be found on CRAN: https://cran.r-project.org
Follow the link "Packages" and  then "Table of available packages, sorted by name".

Direct address for tempdisagg: https://cran.r-project.org/web/packages/tempdisagg/index.html
The source for the full package  will be in the .tar.gz file.

Berend Hasselman

> Thanks in advance for all information you can give me !
> Jean in France
> 
> PS please can you send a copy of your response directly to my address 'jean-externe.maurice at edf.fr'
> 

Done automatically if one uses Reply to All?


From jean-externe.maurice at edf.fr  Thu Jun  2 13:21:16 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Thu, 2 Jun 2016 11:21:16 +0000
Subject: [R] translating function td of package tempdisagg to FORTRAN
In-Reply-To: <F189753D-BB43-462D-8F96-625AD802F2D9@xs4all.nl>
References: <4ad30546f70b49969462ef8bae4489b2@NOEINTPEXMU007.NEOPROD.EDF.FR>
	<F189753D-BB43-462D-8F96-625AD802F2D9@xs4all.nl>
Message-ID: <109e37815df64261a87913f40ad43318@NOEINTPEXMU007.NEOPROD.EDF.FR>

Ouaouh !

Thanks a lot
Jean
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From h.wickham at gmail.com  Thu Jun  2 13:32:12 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 2 Jun 2016 07:32:12 -0400
Subject: [R] httr package syntax (PUT)
In-Reply-To: <CALVRum4dY=oeURQ7qTw9gPtx-DWPh=cMfHzX==tJtPbhAikD+A@mail.gmail.com>
References: <CALVRum4dY=oeURQ7qTw9gPtx-DWPh=cMfHzX==tJtPbhAikD+A@mail.gmail.com>
Message-ID: <CABdHhvFhh-xcbneUOD96RygboFrhMV0AU6MwuiP4wu2P=3sm2w@mail.gmail.com>

On Wed, Jun 1, 2016 at 7:16 PM, Jared Rodecker <jared.rodecker at gmail.com> wrote:
> Greetings fellow R users.
>
> I'm struggling with the syntax of submitting a PUT request
>
> I'm trying to insert a few PUT requests into some legacy R code that I have
> that performs daily ETL on a small database. These requests will add users
> to an email mailing list in MailChimp.
>
>
> I have been able to get my GET requests formatted into syntax that R
> (specifically the httr package) accepts:
>
> GET("
> https://us10.api.mailchimp.com/3.0/lists/list_id_XXXXX/members/MEMBER_HASH_#######",
> query = list(apikey = 'XXXXXXXXXXXXXX'))
>
>
> However when I try to do something similar for PUT requests this simple
> syntax isn't working - you can't just pass the API KEY and/or requested
> parameters directly through the URL. I get a 401 error if I use the same
> syntax I used for GET.
>
>
> I believe that I need to use the CONFIG option to pass the API key (either
> using AUTHENTICATE or ADD_HEADERS) and the requested parameters in the BODY
> to get the PUT request to work but I can't get the syntax to work - this
> gives a 400 error:
>
>
> auth <- authenticate("anystring", "XXXXXXXXXXXXXX", type = "basic")
>
> parms <- '[{"email_address" : "some_user at domain.com", "status_if_new" :
> "subscribed"}]'
>
> PUT("
> https://us10.api.mailchimp.com/3.0/lists/list_id_XXXXX/members/MEMBER_HASH_#######
> ",config=auth,body=parms,encode="json")
>
>
> If anyone can point me to a more flushed out example that would be
> amazing...but even just some tips on how to get more info on my error
> message to help me troubleshoot my syntax would also be a big help.  I've
> also been trying to get httpput (from the RCurl package) but also
> struggling with the syntax there.

If you use verbose() you should be able to see what the problem is -
httr does the json encoding for you. You want:

params <- list(email_address = "some_user at domain.com", status_if_new =
"subscribed")
PUT("https://us10.api.mailchimp.com/3.0/lists/list_id_XXXXX/members/MEMBER_HASH_#######",
   config = auth,
   body = params,
   encode = "json"
)

Hadley

-- 
http://hadley.nz


From jfox at mcmaster.ca  Thu Jun  2 14:01:15 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 2 Jun 2016 12:01:15 +0000
Subject: [R] SEM GFI
In-Reply-To: <234506459.2505773.1464802919535.JavaMail.yahoo@mail.yahoo.com>
References: <1103804586.1954135.1464719331934.JavaMail.yahoo.ref@mail.yahoo.com>
	<1103804586.1954135.1464719331934.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbTp+0uDC1YDxF-LgDsvcEx_69BU=Nc+BBqMMZnP9j3t9Q@mail.gmail.com>
	<234506459.2505773.1464802919535.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810FA703C@FHSDB2D11-2.csu.mcmaster.ca>

Dear Vinay and Burt,

I didn't see Vinay's original posting -- sorry about that.

Vinay: There's still not enough information here to tell why the results are different, and posting in HTML makes the code very hard to read. 

To elaborate slightly: You don't provide the data, so it's not possible to replicate your results. You also don't show the command or results from SAS, so it's not possible to know how the results differ. Your original message seems to imply that the results are identical accept for the value of GFI and one coefficient standard error. That seems unlikely. My guess: you inadvertently fit different models in SAS and sem.

Additionally, you'd probably find it easier, and less error prone, to specify the model in sem() using specifyEquations() rather than specifyModel(), as the message printed by the latter tells you.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of VINAY
> KULKARNI via R-help
> Sent: June 1, 2016 1:42 PM
> To: Bert Gunter <bgunter.4567 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] SEM GFI
> 
> Hi,
> Please find below the code:
> Thanks,Vinay
> >library(sem)?>data1=read.csv("data_1.csv")?>corr=cor(data1)
> >model1<-specifyModel()brand1_Pric_ind????->
> >Val_brand1,lamb1,NADist_brand1???????->
> >Val_brand1,lamb2,NAbrand1_like_me?????->
> >Val_brand1,lamb3,NAbrand2_Def_Drink -
> >???Val_brand1,lamb4,NAbrand2_Like
> >-> brand2_Def_Drink,lamb5,NAbrand2_Pleasure ->
> >brand2_Def_Drink,lamb6,NAbrand1_Like ->
> >brand1_like_me,lamb7,NAbrand1_Love ->
> >brand1_like_me,lamb8,NAbrand1_P4WC ->
> brand1_Like,lamb9,NAbrand1_P4WC
> >-> brand1_Love,lamb10,NAbrand1_Energy ->
> >brand1_P4WC,lamb11,NAbrand1_Different ->
> >brand1_P4WC,lamb12,NAbrand1_Pric_ind <->
> >brand1_Pric_ind,the1,NADist_brand1 <->
> >Dist_brand1,the2,NAbrand1_like_me??<->
> >brand1_like_me,the3,NAbrand2_Def_Drink <->
> >brand2_Def_Drink,the4,NAbrand2_Like <->
> >brand2_Like,the5,NAbrand2_Pleasure <->
> >brand2_Pleasure,the6,NAbrand1_Like <-> brand1_Like,the7,NAbrand1_Love
> ><-> brand1_Love,the8,NAbrand1_P4WC <->
> brand1_P4WC,the9,NAbrand1_Energy
> ><-> brand1_Energy,the10,NAbrand1_Different <->
> >brand1_Different,the11,NAbrand1_like_me??<->
> >brand2_Def_Drink,the12,NAbrand1_Like <->
> brand1_Love,the13,NAVal_brand1
> ><-> Val_brand1,1,NA??> opt <- options(fit.indices = c("GFI", "AGFI",
> >"RMSEA", "NFI", "NNFI", "CFI", "RNI", "IFI", "SRMR", "AIC", "AICc",
> >"BIC", "CAIC"))?> sem.model1<-sem(model1,corr,36)
> > summary(sem.model1)
> 
> 
> 
> 
>       From: Bert Gunter <bgunter.4567 at gmail.com>
>  To: VINAY KULKARNI <vinaypkulkarni at yahoo.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
>  Sent: Wednesday, 1 June 2016 2:16 AM
>  Subject: Re: [R] SEM GFI
> 
> Probably impossible to answer without your following the posting guide and
> posting your code, etc.
> 
> Cheers,
> 
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, May 31, 2016 at 11:28 AM, VINAY KULKARNI via R-help <r-help at r-
> project.org> wrote:
> > Hi,
> > I am exactly replicating the SEM model which was done in SAS using Proc
> Calis in R.
> > Used sem package in R but not getting the GFI as same as in SAS
> > (approximately 15% difference) and also one link is insignificant but in SAS
> am getting significant.
> > Searched through online in different blogs but not able to get the solution.
> > Please let me know what might be the reason.
> > Thanks,Vinay
> >
> >
> >
> >? ? ? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From zadig_1 at excite.com  Thu Jun  2 14:47:48 2016
From: zadig_1 at excite.com (ce)
Date: Thu, 02 Jun 2016 08:47:48 -0400
Subject: [R] Making an if condition variable ?
Message-ID: <20160602084748.19465@web005.roc2.bluetie.com>


Thank you all for wisdom :)
Problem is that I change the condition often and then I forget it. I wanted to put it at the beginning of the program with the other parameters so I wouldn't miss it. 

ce


-----Original Message-----
From: "Rainer M Krug" [Rainer at krugs.de]
Date: 06/02/2016 04:00 AM
To: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
CC: r-help at r-project.org
Subject: Re: Making an if condition variable ?

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:

> Beware of getting too "meta" in your programming... it is rarely worth
> it. Just write the code and move on with life. That is the beauty of a
> scripting language.

+1

I think this a very common pitfall (I know it from own experience...)
and I would say a candidate for a fortune?

Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982


From Rainer at krugs.de  Thu Jun  2 15:07:32 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 02 Jun 2016 15:07:32 +0200
Subject: [R] Making an if condition variable ?
In-Reply-To: <20160602084748.19465@web005.roc2.bluetie.com> (ce's message of
	"Thu, 02 Jun 2016 08:47:48 -0400")
References: <20160602084748.19465@web005.roc2.bluetie.com>
Message-ID: <m2eg8fviwb.fsf@krugs.de>

"ce" <zadig_1 at excite.com> writes:

> Thank you all for wisdom :)
> Problem is that I change the condition often and then I forget it. I
> wanted to put it at the beginning of the program with the other
> parameters so I wouldn't miss it.

In this case - why not use a function instead of the condition?

cond <- function(x){x>0}
and than

if (cond(4)) {...}

might be the easiest in this case?

or, more flexible,

cond <- function(...){x>0}

if (cond(x=3)) {...}

Cheers,

Rainer

>
> ce
>
>
> -----Original Message-----
> From: "Rainer M Krug" [Rainer at krugs.de]
> Date: 06/02/2016 04:00 AM
> To: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> CC: r-help at r-project.org
> Subject: Re: Making an if condition variable ?
>
> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:
>
>> Beware of getting too "meta" in your programming... it is rarely worth
>> it. Just write the code and move on with life. That is the beauty of a
>> scripting language.
>
> +1
>
> I think this a very common pitfall (I know it from own experience...)
> and I would say a candidate for a fortune?
>
> Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160602/0da30112/attachment.bin>

From jdnewmil at dcn.davis.ca.us  Thu Jun  2 16:12:20 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 02 Jun 2016 07:12:20 -0700
Subject: [R] Convert ncdf data to dataframe
In-Reply-To: <CAMLwc7Og1uQUqh_t=Dv5S4RDW4D=bZd2XNz9C+qDLvrO-eA3BQ@mail.gmail.com>
References: <CAMLwc7Og1uQUqh_t=Dv5S4RDW4D=bZd2XNz9C+qDLvrO-eA3BQ@mail.gmail.com>
Message-ID: <F633FF43-1E0D-496E-8AC0-ABEBE164EDB8@dcn.davis.ca.us>

The answer to your question is "yes".

You probably need to make your example reproducible by including (or referencing by URL) sample data if you want a more complete response. 
-- 
Sent from my phone. Please excuse my brevity.

On June 2, 2016 1:42:55 AM PDT, Miluji Sb <milujisb at gmail.com> wrote:
>Dear all,
>
>I have used the following code to read in a ncdf file
>
>library(chron)
>library(lattice)
>library(ncdf4)
>library(data.table)
>
>ncname <- ("/file_path")
>ncfname <- paste(ncname, ".nc", sep = "")
>dname <- "ssl"  # note: tmp means temperature (not temporary)
>
>ncin <- nc_open(ncfname)
>print(ncin)
>
>The attributes of the file are:
>
>     4 variables (excluding dimension variables):
>        double longitude[row]
>            long_name: longitude
>            units: degrees_east
>            standard_name: longitude
>        double latitude[row]
>            long_name: latitude
>            units: degrees_north
>            standard_name: latitude
>        double ssl[col,row]
>            long_name: storm surge level
>            units: m
>            _FillValue: -99999
>            scale_factor: 1
>            add_offset: 1
>        float RP[col]
>            long_name: return period
>            units: yr
>          Contents: The RPs have been estimated following the Peak Over
>Threshold Method (see reference below)
>            Starting date: 01-Dec-2009
>            End date: 30-Nov-2099 21:00:00
>     2 dimensions:
>        col  Size:8
>        row  Size:2242
>
>I would like to convert the data into a dataframe by longitude and
>latitude. Is that possible? Thank you!
>
>Sincerely,
>
>Milu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From zadig_1 at excite.com  Thu Jun  2 16:50:08 2016
From: zadig_1 at excite.com (ce)
Date: Thu, 02 Jun 2016 10:50:08 -0400
Subject: [R] Making an if condition variable ?
Message-ID: <20160602105008.28897@web004.roc2.bluetie.com>


well, not that simple. My original condition and changes are more complicated than I post in r-help for simplicity purposes . Original condition is something like :

 if (   a > 0  & ( b[1] > b[2] ) |  c == TRUE ) 

and I might change it to

if ( a == 0 &  ( b[1] < b[2] ) & d > 10 ) 

then I need to have a bunch of functions and I will forget which function I used. 

-----Original Message-----
From: "Rainer M Krug" [Rainer at krugs.de]
Date: 06/02/2016 09:08 AM
To: "ce" <zadig_1 at excite.com>
CC: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>, r-help at r-project.org
Subject: Re: Making an if condition variable ?

"ce" <zadig_1 at excite.com> writes:

> Thank you all for wisdom :)
> Problem is that I change the condition often and then I forget it. I
> wanted to put it at the beginning of the program with the other
> parameters so I wouldn't miss it.

In this case - why not use a function instead of the condition?

cond <- function(x){x>0}
and than

if (cond(4)) {...}

might be the easiest in this case?

or, more flexible,

cond <- function(...){x>0}

if (cond(x=3)) {...}

Cheers,

Rainer

>
> ce
>
>
> -----Original Message-----
> From: "Rainer M Krug" [Rainer at krugs.de]
> Date: 06/02/2016 04:00 AM
> To: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> CC: r-help at r-project.org
> Subject: Re: Making an if condition variable ?
>
> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:
>
>> Beware of getting too "meta" in your programming... it is rarely worth
>> it. Just write the code and move on with life. That is the beauty of a
>> scripting language.
>
> +1
>
> I think this a very common pitfall (I know it from own experience...)
> and I would say a candidate for a fortune?
>
> Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982


From macqueen1 at llnl.gov  Thu Jun  2 17:04:26 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 2 Jun 2016 15:04:26 +0000
Subject: [R] Convert ncdf data to dataframe
In-Reply-To: <CAMLwc7Og1uQUqh_t=Dv5S4RDW4D=bZd2XNz9C+qDLvrO-eA3BQ@mail.gmail.com>
References: <CAMLwc7Og1uQUqh_t=Dv5S4RDW4D=bZd2XNz9C+qDLvrO-eA3BQ@mail.gmail.com>
Message-ID: <D37597C6.17626E%macqueen1@llnl.gov>

There's a pretty good chance this question has been previously asked and
answered on the R-sig-geo mailing list (though I don't know for sure).

In addition, entering

  "R convert ncdf to data frame"

in a web search returned some possibilities, the first of which (for me)
was

  http://geog.uoregon.edu/bartlein/courses/geog607/Rmd/netCDF_01.htm

and partway down that page is an entry,

  "Get a single time slice of the data, create an R data frame, and write
a .csv file"

which does indeed have some examples of how to convert to a data frame.


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/2/16, 1:42 AM, "R-help on behalf of Miluji Sb"
<r-help-bounces at r-project.org on behalf of milujisb at gmail.com> wrote:

>Dear all,
>
>I have used the following code to read in a ncdf file
>
>library(chron)
>library(lattice)
>library(ncdf4)
>library(data.table)
>
>ncname <- ("/file_path")
>ncfname <- paste(ncname, ".nc", sep = "")
>dname <- "ssl"  # note: tmp means temperature (not temporary)
>
>ncin <- nc_open(ncfname)
>print(ncin)
>
>The attributes of the file are:
>
>     4 variables (excluding dimension variables):
>        double longitude[row]
>            long_name: longitude
>            units: degrees_east
>            standard_name: longitude
>        double latitude[row]
>            long_name: latitude
>            units: degrees_north
>            standard_name: latitude
>        double ssl[col,row]
>            long_name: storm surge level
>            units: m
>            _FillValue: -99999
>            scale_factor: 1
>            add_offset: 1
>        float RP[col]
>            long_name: return period
>            units: yr
>            Contents: The RPs have been estimated following the Peak Over
>Threshold Method (see reference below)
>            Starting date: 01-Dec-2009
>            End date: 30-Nov-2099 21:00:00
>     2 dimensions:
>        col  Size:8
>        row  Size:2242
>
>I would like to convert the data into a dataframe by longitude and
>latitude. Is that possible? Thank you!
>
>Sincerely,
>
>Milu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jun  2 17:07:38 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Jun 2016 08:07:38 -0700
Subject: [R] Making an if condition variable ?
In-Reply-To: <20160602105008.28897@web004.roc2.bluetie.com>
References: <20160602105008.28897@web004.roc2.bluetie.com>
Message-ID: <CAGxFJbS6J-kKJrAOj5LE+j_9G8BgrN8QAwuv+sr86-J2RzMGNQ@mail.gmail.com>

You need to rethink. You'll do better in the long -- and probably
short, too -- run working within the language's paradigms rather than
resisting them.

(It's not that R's paradigms are in any sense "the best"; other
languages have different paradigms and you would do better in those
languages with their paradigms rather than with R's).

For example, you could have a single function that returns the
conditional function of your choice by calling the overall function
with an appropriate keyword.  Etc.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 2, 2016 at 7:50 AM, ce <zadig_1 at excite.com> wrote:
>
> well, not that simple. My original condition and changes are more complicated than I post in r-help for simplicity purposes . Original condition is something like :
>
>  if (   a > 0  & ( b[1] > b[2] ) |  c == TRUE )
>
> and I might change it to
>
> if ( a == 0 &  ( b[1] < b[2] ) & d > 10 )
>
> then I need to have a bunch of functions and I will forget which function I used.
>
> -----Original Message-----
> From: "Rainer M Krug" [Rainer at krugs.de]
> Date: 06/02/2016 09:08 AM
> To: "ce" <zadig_1 at excite.com>
> CC: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>, r-help at r-project.org
> Subject: Re: Making an if condition variable ?
>
> "ce" <zadig_1 at excite.com> writes:
>
>> Thank you all for wisdom :)
>> Problem is that I change the condition often and then I forget it. I
>> wanted to put it at the beginning of the program with the other
>> parameters so I wouldn't miss it.
>
> In this case - why not use a function instead of the condition?
>
> cond <- function(x){x>0}
> and than
>
> if (cond(4)) {...}
>
> might be the easiest in this case?
>
> or, more flexible,
>
> cond <- function(...){x>0}
>
> if (cond(x=3)) {...}
>
> Cheers,
>
> Rainer
>
>>
>> ce
>>
>>
>> -----Original Message-----
>> From: "Rainer M Krug" [Rainer at krugs.de]
>> Date: 06/02/2016 04:00 AM
>> To: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>> CC: r-help at r-project.org
>> Subject: Re: Making an if condition variable ?
>>
>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:
>>
>>> Beware of getting too "meta" in your programming... it is rarely worth
>>> it. Just write the code and move on with life. That is the beauty of a
>>> scripting language.
>>
>> +1
>>
>> I think this a very common pitfall (I know it from own experience...)
>> and I would say a candidate for a fortune?
>>
>> Rainer
>
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j.hengelbrock at uke.de  Thu Jun  2 11:46:29 2016
From: j.hengelbrock at uke.de (Johannes Hengelbrock)
Date: Thu, 2 Jun 2016 11:46:29 +0200
Subject: [R] coxph: no convergence with completely tied data with
	'exact'-method
Message-ID: <58dada2e-c2e5-9017-49e0-235ff47a2468@uke.de>

Dear users,

I'm trying to estimate a conditional logistic model using the 
coxph()-function from the survival package. Somehow, the model does not 
converge if time is set to the same value for all observations:

     library(survival)
     set.seed(12345)
     n <- 3000
     a <- rbinom(n, 1, 0.5)
     b <- rbinom(n, 1, 0.5)
     coxph(formula = Surv(rep(1, 3000), a) ~ b, method = "exact")

Error in fitter(X, Y, strats, offset, init, control, weights = weights, 
: NA/NaN/Inf in foreign function call (arg 5) In addition: Warning 
message: In fitter(X, Y, strats, offset, init, control, weights = 
weights, :Ran out of iterations and did not converge

Changing iter.max does not help, aparently. Strangely, the exact same 
model converges in SAS.

I know that I could estimate the model differently (via glm), but I 
would like to understand why the model does converge in SAS but not in R.

Thanks,
Johannes

-- 
__________________________________________________________________
Johannes Hengelbrock
Universit?tsklinikum Hamburg-Eppendorf
Institut f. Medizinische Biometrie und Epidemiologie
Martinistr. 52, 20246 Hamburg

Tel. 040-7410-53517 / Fax: 040-7410-57790

mailto:j.hengelbrock at uke.de
https://www.uke.de/kliniken-institute/institute/medizinische-biometrie-und-epidemiologie/team/index.html
__________________________________________________________________

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From w1malik at gmail.com  Thu Jun  2 13:10:08 2016
From: w1malik at gmail.com (Waseem Ali)
Date: Thu, 2 Jun 2016 16:10:08 +0500
Subject: [R] FW: How to read multiple raster and serial correlation between
 series of rasters
In-Reply-To: <SNT151-W95DFBC94C5A64DB9BCC09DEB440@phx.gbl>
References: <SNT151-W95DFBC94C5A64DB9BCC09DEB440@phx.gbl>
Message-ID: <SNT151-W34862FD0FE44241E21C057EB580@phx.gbl>




Dear members,
With little effort in producing the code to read all nc files for Carbon dioxide variables I have produced the following code:
library(ncdf)ncfiles <- list.files("C:/site-download/AIRS/", pattern='\\.nc$', full.names = TRUE)ncfilesncfname <- ncfiles[1]ncfnamedname <- "mole_fraction_of_carbon_dioxide_in_free_troposphere"ncin <- open.ncdf(ncfname)print(ncin)lon <- get.var.ncdf(ncin, "Longitude")nlon <- dim(lon)head(lon)lat <- get.var.ncdf(ncin, "Latitude")nlat <- dim(lat)head(lat)print(c(nlon, nlat))co2array <- get.var.ncdf(ncin, "mole_fraction_of_carbon_dioxide_in_free_troposphere")fillvalue <- att.get.ncdf(ncin, "mole_fraction_of_carbon_dioxide_in_free_troposphere", "Missval")fillvalueco2array[co2array == fillvalue] <- NAlibrary(RColorBrewer)image(co2array, col = rev(brewer.pal(10, "RdBu")))grid <- expand.grid(lon = lon, lat = lat)lonlat <- expand.grid(lon, lat)lonlathead(lonlat)m <- 1co2.vec <- as.vector(co2array)length(co2.vec)co2.df01 <- data.frame(cbind(lonlat, co2.vec*1000000))names(co2.df01) <- c("lon", "lat", paste("co2", as.character(m), sep = "_"))head(na.omit(co2.df01), 20)csvfile <- "co20020901.csv"write.table(na.omit(co2.df01), csvfile, row.names = FALSE, sep = ",")With the help of this code I can dump the values of Carbon dioxide variables in latitude and longitude wise. sample of the csv file is as under:      lon  lat    co2_126  -117.5 89.5 381.802050   -57.5 89.5 373.8030147 -175.0 88.0 382.7285148 -172.5 88.0 373.6800152 -162.5 88.0 371.6560153 -160.0 88.0 373.4450154 -157.5 88.0 374.3705I need help to tune code to do this with iterative code for whole 120 raster to write it into csv file. Column names should be like as 200301, 200302....up to 200312. This starts from the January of 2003 till December of 2003 and so on for the next year.   My next task to do the same for LST variable retrievable from MODIS LST product of 0.05 degree resolution which is in hdf file formate [I am trying to write the code to interpret the variable ]. I want to resample it first to have on same spatial resolution as my first raster then write to the another csv file in the same way before. After writing it into the csv files I want to correlate the both variables and serial correlation. Please guide to do it using R or any other way to deal with the situations I have briefly explained. Also suggest for interpolation for carbon dioxide variable first to make the raster layer. It may have missing some values.
Waseem Ali 

From: w1malik at hotmail.com
To: r-help at r-project.org
Subject: How to real multiple raster and serial correlation between series of rasters
Date: Sun, 29 May 2016 23:39:18 +0500







Hi,
I have 120 raster (10 years) files
in tif format of one variable (say X1) and same numbers for second variables (Say
X2). Each raster consists the mean monthly values of corresponding variables. I
want to write a script in R which operates the following operations:

?        
First reads the one by one
raster from folder and save into the objects. 

?        
Resample/aggregate the both
raster over same spatial resolution 2? x 2.5?.

?        
After resampling the all
raster over same resolution, conversions of all raster to points by using the
rasterToPoint() function of raster library.

?        
After retrieving the same
monthly raster values (like month of January for X1 and X2) into data frame, I
want to compute regression and correlation values for all 120 raster for both
variables (X1 and X2) and save into the data frame.

Is there any way out to deal with
such task.


library(raster)

x <- list.files("C:/site-download/",
pattern = "*.tif", full.names = TRUE)

x1 <- raster(x1)

p <- as(x1, 'SpatialPixels')

plot(x1)

points(p)
Resultant figure has been attached for you for only x1 variable. I have also attached the X1 and X2 variable tif raster for January 2002 for computation purpose. I need to operate it through loop for reading all these rasters and computing the correlation of each pairs. My next step to compute the Lag -1 correlations which is Serial Correlation for both variables.
Waseem Ali 
 		 	   		  
 		 	   		  

From tea3rd at gmail.com  Thu Jun  2 17:36:59 2016
From: tea3rd at gmail.com (Thomas Adams)
Date: Thu, 2 Jun 2016 10:36:59 -0500
Subject: [R] Struggling trying to plot points on boxplot
Message-ID: <CAGxgkWh9GfpNN8DrORARpVi97T7qVZoNZhVm+pxdKcNOb9_0Dg@mail.gmail.com>

Hello all:

I've been beating my head on this for over a day and I have done a lot of
Google'ing with no luck.

I have generated a 'time-series' of boxplots (227), covering more than a
30-day period at 6-hour intervals, which summarize an ensemble forecast.
What I want to do is over-plot the observed values over a portion of the
forecast period to serve as a basis of comparison; so, there would be a
boxplot and a single point value plotted at each 6-hour interval.

The boxplots are generated:

zz<-boxplot(ens$value ~ ens$valid_time,xlab="Date/Time
(UTC)",ylab="Flow(cfs)",boxfill="cyan")

which works fine, but the observed points will not display using:

points(zz, obs$value,lty=3,lwd=1,col="red",pch=19)

I've tried many variations of the latter, where either nothing happens and
no error is returned or I have also gotten that x and y have different
lengths. I suspect I am using the wrong 'x' type. I have observation values
beginning with the first in the series of boxplots, which then end, with
the most recent ensemble forecast. So, I always expect the number of
observed values to be less than the number of boxplots. I have done this
previously, years ago, but can not find my notes and can not reconstruct
what I did.

Help is appreciated.

Regards,
Tom

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Jun  2 17:48:52 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 2 Jun 2016 11:48:52 -0400
Subject: [R] Struggling trying to plot points on boxplot
In-Reply-To: <CAGxgkWh9GfpNN8DrORARpVi97T7qVZoNZhVm+pxdKcNOb9_0Dg@mail.gmail.com>
References: <CAGxgkWh9GfpNN8DrORARpVi97T7qVZoNZhVm+pxdKcNOb9_0Dg@mail.gmail.com>
Message-ID: <CAM_vjukwZA_=UG7eGVg9a47bMMS19aF8pzf2LD2WE3gGte671Q@mail.gmail.com>

boxplot() turns the x variable into a factor, if it isn't already, so
the x axis is calibrated as seq_len(nvalues). Whatever you're trying
to do with using your boxplot object as the x variable in points won't
work: zz is a list of length 6.

There's an example in ?boxplot of adding points to a boxplot.

Without a reproducible example, it's impossible to give you working
code, but here's another example besides the one in ?boxplot:

zz <- boxplot(runif(100) ~ sample(c(4, 9, 15), size=100, replace=TRUE))
points(seq_len(3), c(.8, .82, .9), col="red", pch=2)

Notice that even though the boxplot labels are 4, 9, 15 the plot
coordinates are 1, 2, 3.

Sarah

On Thu, Jun 2, 2016 at 11:36 AM, Thomas Adams <tea3rd at gmail.com> wrote:
> Hello all:
>
> I've been beating my head on this for over a day and I have done a lot of
> Google'ing with no luck.
>
> I have generated a 'time-series' of boxplots (227), covering more than a
> 30-day period at 6-hour intervals, which summarize an ensemble forecast.
> What I want to do is over-plot the observed values over a portion of the
> forecast period to serve as a basis of comparison; so, there would be a
> boxplot and a single point value plotted at each 6-hour interval.
>
> The boxplots are generated:
>
> zz<-boxplot(ens$value ~ ens$valid_time,xlab="Date/Time
> (UTC)",ylab="Flow(cfs)",boxfill="cyan")
>
> which works fine, but the observed points will not display using:
>
> points(zz, obs$value,lty=3,lwd=1,col="red",pch=19)
>
> I've tried many variations of the latter, where either nothing happens and
> no error is returned or I have also gotten that x and y have different
> lengths. I suspect I am using the wrong 'x' type. I have observation values
> beginning with the first in the series of boxplots, which then end, with
> the most recent ensemble forecast. So, I always expect the number of
> observed values to be less than the number of boxplots. I have done this
> previously, years ago, but can not find my notes and can not reconstruct
> what I did.
>
> Help is appreciated.
>
> Regards,
> Tom


From rmh at temple.edu  Thu Jun  2 17:52:21 2016
From: rmh at temple.edu (RICHARD M. HEIBERGER)
Date: Thu, 2 Jun 2016 11:52:21 -0400
Subject: [R] Struggling trying to plot points on boxplot
In-Reply-To: <CAGxgkWh9GfpNN8DrORARpVi97T7qVZoNZhVm+pxdKcNOb9_0Dg@mail.gmail.com>
References: <CAGxgkWh9GfpNN8DrORARpVi97T7qVZoNZhVm+pxdKcNOb9_0Dg@mail.gmail.com>
Message-ID: <FF92DA68-5C38-4ADF-92FE-72B8B466B098@temple.edu>

something like this

points(zz[1:length(obs$value)], obs$value,lty=3,lwd=1,col="red",pch=19)

Sent from my iPhone

> On Jun 2, 2016, at 11:36, Thomas Adams <tea3rd at gmail.com> wrote:
> 
> points(zz, obs$value,lty=3,lwd=1,col="red",pch=19)


From wdunlap at tibco.com  Thu Jun  2 17:52:10 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 2 Jun 2016 08:52:10 -0700
Subject: [R] Struggling trying to plot points on boxplot
In-Reply-To: <CAGxgkWh9GfpNN8DrORARpVi97T7qVZoNZhVm+pxdKcNOb9_0Dg@mail.gmail.com>
References: <CAGxgkWh9GfpNN8DrORARpVi97T7qVZoNZhVm+pxdKcNOb9_0Dg@mail.gmail.com>
Message-ID: <CAF8bMcbQ58ZCd4KtK0CG0xcGgWcrFa1jymUiXQN175Uk8zTi+Q@mail.gmail.com>

Does using zz<-bxp(boxplot(data,plot=FALSE)) do what you want?  E.g.,

d <- transform(data.frame(t=1:15), x = sin(t)+log2(t), group =
paste("Group", t%/%4))
groupedX <- with(d, split(x, group))
zz <- bxp(boxplot(groupedX, plot=FALSE)) # bxp returns the x positions of
the boxes
points(col="blue", pch=15, zz, vapply(splitX, FUN=mean, FUN.VALUE=0))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 2, 2016 at 8:36 AM, Thomas Adams <tea3rd at gmail.com> wrote:

> Hello all:
>
> I've been beating my head on this for over a day and I have done a lot of
> Google'ing with no luck.
>
> I have generated a 'time-series' of boxplots (227), covering more than a
> 30-day period at 6-hour intervals, which summarize an ensemble forecast.
> What I want to do is over-plot the observed values over a portion of the
> forecast period to serve as a basis of comparison; so, there would be a
> boxplot and a single point value plotted at each 6-hour interval.
>
> The boxplots are generated:
>
> zz<-boxplot(ens$value ~ ens$valid_time,xlab="Date/Time
> (UTC)",ylab="Flow(cfs)",boxfill="cyan")
>
> which works fine, but the observed points will not display using:
>
> points(zz, obs$value,lty=3,lwd=1,col="red",pch=19)
>
> I've tried many variations of the latter, where either nothing happens and
> no error is returned or I have also gotten that x and y have different
> lengths. I suspect I am using the wrong 'x' type. I have observation values
> beginning with the first in the series of boxplots, which then end, with
> the most recent ensemble forecast. So, I always expect the number of
> observed values to be less than the number of boxplots. I have done this
> previously, years ago, but can not find my notes and can not reconstruct
> what I did.
>
> Help is appreciated.
>
> Regards,
> Tom
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lianoglou.steve at gene.com  Thu Jun  2 17:55:15 2016
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Thu, 2 Jun 2016 08:55:15 -0700
Subject: [R] Trouble getting rms::survplot(...,
	n.risk=TRUE) to behave properly
Message-ID: <CAHA9McPXy65FqwZ=Ncd86s+LcFg6WK36oZYjxB3E+SgrsCNZtQ@mail.gmail.com>

Hello foks,

I'm trying to plot the number of patients at-risk by setting the
`n.risk` parameter to `TRUE` in the rms::survplot function, however it
looks as if the numbers presented in the rows for each category are
just summing up the total number of patients at risk in all groups for
each timepoint -- which is to say that the numbers are equal in each
category down the rows, and they don't seem to be the numbers specific
to each group.

You can reproduce the observed behavior by simply running the code in
the Examples section of ?survplot, which I'll paste below for
convenience.

Is the error between the chair and the keyboard, here, or is this perhaps a bug?

=========== code ===========
library(rms)
n <- 1000
set.seed(731)
age <- 50 + 12*rnorm(n)
label(age) <- "Age"
sex <- factor(sample(c('Male','Female'), n, rep=TRUE, prob=c(.6, .4)))
cens <- 15*runif(n)
h <- .02*exp(.04*(age-50)+.8*(sex=='Female'))
dt <- -log(runif(n))/h
label(dt) <- 'Follow-up Time'
e <- ifelse(dt <= cens,1,0)
dt <- pmin(dt, cens)
units(dt) <- "Year"
dd <- datadist(age, sex)
options(datadist='dd')
S <- Surv(dt,e)

f <- cph(S ~ rcs(age,4) + sex, x=TRUE, y=TRUE)
survplot(f, sex, n.risk=TRUE)
===========

I'm using the latest version of rms (4.5-0) running on R 3.3.0-patched.

=== Output o sessionInfo() ===
R version 3.3.0 Patched (2016-05-26 r70671)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.4 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rms_4.5-0       SparseM_1.7     Hmisc_3.17-4    ggplot2_2.1.0
[5] Formula_1.2-1   survival_2.39-4 lattice_0.20-33

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.5         cluster_2.0.4       MASS_7.3-45
 [4] splines_3.3.0       munsell_0.4.3       colorspace_1.2-6
 [7] multcomp_1.4-5      plyr_1.8.3          nnet_7.3-12
[10] grid_3.3.0          data.table_1.9.6    gtable_0.2.0
[13] nlme_3.1-128        quantreg_5.24       TH.data_1.0-7
[16] latticeExtra_0.6-28 MatrixModels_0.4-1  polspline_1.1.12
[19] Matrix_1.2-6        gridExtra_2.2.1     RColorBrewer_1.1-2
[22] codetools_0.2-14    acepack_1.3-3.3     rpart_4.1-10
[25] sandwich_2.3-4      scales_0.4.0        mvtnorm_1.0-5
[28] foreign_0.8-66      chron_2.3-47        zoo_1.7-13
===========================


Thanks,
-steve


-- 
Steve Lianoglou
Computational Biologist
Genentech


From f.harrell at vanderbilt.edu  Thu Jun  2 17:59:25 2016
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Thu, 2 Jun 2016 10:59:25 -0500
Subject: [R] Trouble getting rms::survplot(...,
	n.risk=TRUE) to behave properly
In-Reply-To: <CAHA9McPXy65FqwZ=Ncd86s+LcFg6WK36oZYjxB3E+SgrsCNZtQ@mail.gmail.com>
References: <CAHA9McPXy65FqwZ=Ncd86s+LcFg6WK36oZYjxB3E+SgrsCNZtQ@mail.gmail.com>
Message-ID: <CAMO-wTYvYRynq2GJye=ZacsFJ0w3CdBgN=WBisSbDBBKBU7n-w@mail.gmail.com>

This happens when you have not strat variables in the model.


------------------------------
Frank E Harrell Jr      Professor and Chairman      School of Medicine

Department of *Biostatistics*      *Vanderbilt University*

On Thu, Jun 2, 2016 at 10:55 AM, Steve Lianoglou <lianoglou.steve at gene.com>
wrote:

> Hello foks,
>
> I'm trying to plot the number of patients at-risk by setting the
> `n.risk` parameter to `TRUE` in the rms::survplot function, however it
> looks as if the numbers presented in the rows for each category are
> just summing up the total number of patients at risk in all groups for
> each timepoint -- which is to say that the numbers are equal in each
> category down the rows, and they don't seem to be the numbers specific
> to each group.
>
> You can reproduce the observed behavior by simply running the code in
> the Examples section of ?survplot, which I'll paste below for
> convenience.
>
> Is the error between the chair and the keyboard, here, or is this perhaps
> a bug?
>
> =========== code ===========
> library(rms)
> n <- 1000
> set.seed(731)
> age <- 50 + 12*rnorm(n)
> label(age) <- "Age"
> sex <- factor(sample(c('Male','Female'), n, rep=TRUE, prob=c(.6, .4)))
> cens <- 15*runif(n)
> h <- .02*exp(.04*(age-50)+.8*(sex=='Female'))
> dt <- -log(runif(n))/h
> label(dt) <- 'Follow-up Time'
> e <- ifelse(dt <= cens,1,0)
> dt <- pmin(dt, cens)
> units(dt) <- "Year"
> dd <- datadist(age, sex)
> options(datadist='dd')
> S <- Surv(dt,e)
>
> f <- cph(S ~ rcs(age,4) + sex, x=TRUE, y=TRUE)
> survplot(f, sex, n.risk=TRUE)
> ===========
>
> I'm using the latest version of rms (4.5-0) running on R 3.3.0-patched.
>
> === Output o sessionInfo() ===
> R version 3.3.0 Patched (2016-05-26 r70671)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.4 (El Capitan)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rms_4.5-0       SparseM_1.7     Hmisc_3.17-4    ggplot2_2.1.0
> [5] Formula_1.2-1   survival_2.39-4 lattice_0.20-33
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.5         cluster_2.0.4       MASS_7.3-45
>  [4] splines_3.3.0       munsell_0.4.3       colorspace_1.2-6
>  [7] multcomp_1.4-5      plyr_1.8.3          nnet_7.3-12
> [10] grid_3.3.0          data.table_1.9.6    gtable_0.2.0
> [13] nlme_3.1-128        quantreg_5.24       TH.data_1.0-7
> [16] latticeExtra_0.6-28 MatrixModels_0.4-1  polspline_1.1.12
> [19] Matrix_1.2-6        gridExtra_2.2.1     RColorBrewer_1.1-2
> [22] codetools_0.2-14    acepack_1.3-3.3     rpart_4.1-10
> [25] sandwich_2.3-4      scales_0.4.0        mvtnorm_1.0-5
> [28] foreign_0.8-66      chron_2.3-47        zoo_1.7-13
> ===========================
>
>
> Thanks,
> -steve
>
>
> --
> Steve Lianoglou
> Computational Biologist
> Genentech
>

	[[alternative HTML version deleted]]


From lianoglou.steve at gene.com  Thu Jun  2 18:21:16 2016
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Thu, 2 Jun 2016 09:21:16 -0700
Subject: [R] Trouble getting rms::survplot(...,
	n.risk=TRUE) to behave properly
In-Reply-To: <CAMO-wTYvYRynq2GJye=ZacsFJ0w3CdBgN=WBisSbDBBKBU7n-w@mail.gmail.com>
References: <CAHA9McPXy65FqwZ=Ncd86s+LcFg6WK36oZYjxB3E+SgrsCNZtQ@mail.gmail.com>
	<CAMO-wTYvYRynq2GJye=ZacsFJ0w3CdBgN=WBisSbDBBKBU7n-w@mail.gmail.com>
Message-ID: <CAHA9McNgeouDTvxTf4hbtHddiZ47+fqs9OpcAeY4sE7+jX84PA@mail.gmail.com>

Ah!

Sorry ... should have dug deeper into the examples section to notice that.

Thank you for the quick reply,
-steve


On Thu, Jun 2, 2016 at 8:59 AM, Frank Harrell <f.harrell at vanderbilt.edu> wrote:
> This happens when you have not strat variables in the model.
>
>
> ------------------------------
> Frank E Harrell Jr      Professor and Chairman      School of Medicine
>
> Department of *Biostatistics*      *Vanderbilt University*
>
> On Thu, Jun 2, 2016 at 10:55 AM, Steve Lianoglou <lianoglou.steve at gene.com>
> wrote:
>
>> Hello foks,
>>
>> I'm trying to plot the number of patients at-risk by setting the
>> `n.risk` parameter to `TRUE` in the rms::survplot function, however it
>> looks as if the numbers presented in the rows for each category are
>> just summing up the total number of patients at risk in all groups for
>> each timepoint -- which is to say that the numbers are equal in each
>> category down the rows, and they don't seem to be the numbers specific
>> to each group.
>>
>> You can reproduce the observed behavior by simply running the code in
>> the Examples section of ?survplot, which I'll paste below for
>> convenience.
>>
>> Is the error between the chair and the keyboard, here, or is this perhaps
>> a bug?
>>
>> =========== code ===========
>> library(rms)
>> n <- 1000
>> set.seed(731)
>> age <- 50 + 12*rnorm(n)
>> label(age) <- "Age"
>> sex <- factor(sample(c('Male','Female'), n, rep=TRUE, prob=c(.6, .4)))
>> cens <- 15*runif(n)
>> h <- .02*exp(.04*(age-50)+.8*(sex=='Female'))
>> dt <- -log(runif(n))/h
>> label(dt) <- 'Follow-up Time'
>> e <- ifelse(dt <= cens,1,0)
>> dt <- pmin(dt, cens)
>> units(dt) <- "Year"
>> dd <- datadist(age, sex)
>> options(datadist='dd')
>> S <- Surv(dt,e)
>>
>> f <- cph(S ~ rcs(age,4) + sex, x=TRUE, y=TRUE)
>> survplot(f, sex, n.risk=TRUE)
>> ===========
>>
>> I'm using the latest version of rms (4.5-0) running on R 3.3.0-patched.
>>
>> === Output o sessionInfo() ===
>> R version 3.3.0 Patched (2016-05-26 r70671)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.11.4 (El Capitan)
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] rms_4.5-0       SparseM_1.7     Hmisc_3.17-4    ggplot2_2.1.0
>> [5] Formula_1.2-1   survival_2.39-4 lattice_0.20-33
>>
>> loaded via a namespace (and not attached):
>>  [1] Rcpp_0.12.5         cluster_2.0.4       MASS_7.3-45
>>  [4] splines_3.3.0       munsell_0.4.3       colorspace_1.2-6
>>  [7] multcomp_1.4-5      plyr_1.8.3          nnet_7.3-12
>> [10] grid_3.3.0          data.table_1.9.6    gtable_0.2.0
>> [13] nlme_3.1-128        quantreg_5.24       TH.data_1.0-7
>> [16] latticeExtra_0.6-28 MatrixModels_0.4-1  polspline_1.1.12
>> [19] Matrix_1.2-6        gridExtra_2.2.1     RColorBrewer_1.1-2
>> [22] codetools_0.2-14    acepack_1.3-3.3     rpart_4.1-10
>> [25] sandwich_2.3-4      scales_0.4.0        mvtnorm_1.0-5
>> [28] foreign_0.8-66      chron_2.3-47        zoo_1.7-13
>> ===========================
>>
>>
>> Thanks,
>> -steve
>>
>>
>> --
>> Steve Lianoglou
>> Computational Biologist
>> Genentech
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Steve Lianoglou
Computational Biologist
Genentech


From tea3rd at gmail.com  Thu Jun  2 20:07:14 2016
From: tea3rd at gmail.com (Thomas Adams)
Date: Thu, 2 Jun 2016 13:07:14 -0500
Subject: [R] Struggling trying to plot points on boxplot
In-Reply-To: <CAF8bMcbQ58ZCd4KtK0CG0xcGgWcrFa1jymUiXQN175Uk8zTi+Q@mail.gmail.com>
References: <CAGxgkWh9GfpNN8DrORARpVi97T7qVZoNZhVm+pxdKcNOb9_0Dg@mail.gmail.com>
	<CAF8bMcbQ58ZCd4KtK0CG0xcGgWcrFa1jymUiXQN175Uk8zTi+Q@mail.gmail.com>
Message-ID: <CAGxgkWjqDL=yruHxO80jMvH7Uu-3uALA_coiJhiEg3KL-EJxVA@mail.gmail.com>

Bill,

Thank you!! With some tweaking, this approach was exactly what I needed.
Previously, I had been using bxp and had my code for it, but my data was
structured completely differently from what I have now. I figured something
like groupedX <- with(d, split(x, group)) existed, but how to find it??
This was the key for me and it's so powerful!

Thanks to all for the suggestions!

Tom

On Thu, Jun 2, 2016 at 10:52 AM, William Dunlap <wdunlap at tibco.com> wrote:

> Does using zz<-bxp(boxplot(data,plot=FALSE)) do what you want?  E.g.,
>
> d <- transform(data.frame(t=1:15), x = sin(t)+log2(t), group =
> paste("Group", t%/%4))
> groupedX <- with(d, split(x, group))
> zz <- bxp(boxplot(groupedX, plot=FALSE)) # bxp returns the x positions of
> the boxes
> points(col="blue", pch=15, zz, vapply(splitX, FUN=mean, FUN.VALUE=0))
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Jun 2, 2016 at 8:36 AM, Thomas Adams <tea3rd at gmail.com> wrote:
>
>> Hello all:
>>
>> I've been beating my head on this for over a day and I have done a lot of
>> Google'ing with no luck.
>>
>> I have generated a 'time-series' of boxplots (227), covering more than a
>> 30-day period at 6-hour intervals, which summarize an ensemble forecast.
>> What I want to do is over-plot the observed values over a portion of the
>> forecast period to serve as a basis of comparison; so, there would be a
>> boxplot and a single point value plotted at each 6-hour interval.
>>
>> The boxplots are generated:
>>
>> zz<-boxplot(ens$value ~ ens$valid_time,xlab="Date/Time
>> (UTC)",ylab="Flow(cfs)",boxfill="cyan")
>>
>> which works fine, but the observed points will not display using:
>>
>> points(zz, obs$value,lty=3,lwd=1,col="red",pch=19)
>>
>> I've tried many variations of the latter, where either nothing happens and
>> no error is returned or I have also gotten that x and y have different
>> lengths. I suspect I am using the wrong 'x' type. I have observation
>> values
>> beginning with the first in the series of boxplots, which then end, with
>> the most recent ensemble forecast. So, I always expect the number of
>> observed values to be less than the number of boxplots. I have done this
>> previously, years ago, but can not find my notes and can not reconstruct
>> what I did.
>>
>> Help is appreciated.
>>
>> Regards,
>> Tom
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Thomas E Adams, III
2330 Jack Warner PKWY, #334
Tuscaloosa, AL 35401

1 (513) 739-9512 (cell)

	[[alternative HTML version deleted]]


From ebs15242 at gmail.com  Thu Jun  2 20:22:11 2016
From: ebs15242 at gmail.com (Ed Siefker)
Date: Thu, 2 Jun 2016 13:22:11 -0500
Subject: [R] reading data into nested frames
Message-ID: <CALRb-oc--GXjneN+2+HOF2DmoG_XSjrvzF5JSV2UO3_n5uLCQw@mail.gmail.com>

I have many data files named like this:

E11.5-021415-dko-1-1-masked-bottom-area.tsv
E11.5-021415-dko-1-1-masked-top-area.tsv
E11.5-021415-dko-1-2-masked-bottom-area.tsv
E11.5-021415-dko-1-2-masked-top-area.tsv
E11.5-021415-dko-1-3-masked-bottom-area.tsv
E11.5-021415-dko-1-3-masked-top-area.tsv

age-date-genotype-num-slicenum-filler-position-data

An individual sample is an age-date-geno-num, each sample has two
parts, and is composed of around 10 slices.  Each row of the tsv is an
area which will be summed for the total area.

What I want is a dataframe, with a row for each sample and a column
for bottom and top.  Under bottom and top, I want each element to be a
dataframe with a row for each slice and a column for the area.

So I can lapply over this list of files, use strsplit to pull out the
slice num and put the area into the correct row of a dataframe easily
enough.  But I have a line for every datapoint, not sample, and there
would be a dataframe for each area.

How can I merge all the data for the slices into one data frame?  Does
this make sense?
Thanks
-Ed


From ulrik.stervbo at gmail.com  Thu Jun  2 21:56:31 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 02 Jun 2016 19:56:31 +0000
Subject: [R] reading data into nested frames
In-Reply-To: <CALRb-oc--GXjneN+2+HOF2DmoG_XSjrvzF5JSV2UO3_n5uLCQw@mail.gmail.com>
References: <CALRb-oc--GXjneN+2+HOF2DmoG_XSjrvzF5JSV2UO3_n5uLCQw@mail.gmail.com>
Message-ID: <CAKVAULNik8B6rjZXqO+rAa1to4=KztWO-BmBCCar+qbFhHfifA@mail.gmail.com>

Hi Ed,

I'm not sure I understand, but can't you rwad the files one by one and
create one data.frane using rbind?

Is easy to put do in a loop too.

Best wishes,

Ulrik

On Thu, 2 Jun 2016, 20:23 Ed Siefker, <ebs15242 at gmail.com> wrote:

> I have many data files named like this:
>
> E11.5-021415-dko-1-1-masked-bottom-area.tsv
> E11.5-021415-dko-1-1-masked-top-area.tsv
> E11.5-021415-dko-1-2-masked-bottom-area.tsv
> E11.5-021415-dko-1-2-masked-top-area.tsv
> E11.5-021415-dko-1-3-masked-bottom-area.tsv
> E11.5-021415-dko-1-3-masked-top-area.tsv
>
> age-date-genotype-num-slicenum-filler-position-data
>
> An individual sample is an age-date-geno-num, each sample has two
> parts, and is composed of around 10 slices.  Each row of the tsv is an
> area which will be summed for the total area.
>
> What I want is a dataframe, with a row for each sample and a column
> for bottom and top.  Under bottom and top, I want each element to be a
> dataframe with a row for each slice and a column for the area.
>
> So I can lapply over this list of files, use strsplit to pull out the
> slice num and put the area into the correct row of a dataframe easily
> enough.  But I have a line for every datapoint, not sample, and there
> would be a dataframe for each area.
>
> How can I merge all the data for the slices into one data frame?  Does
> this make sense?
> Thanks
> -Ed
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kmnanus at gmail.com  Thu Jun  2 18:39:33 2016
From: kmnanus at gmail.com (KMNanus)
Date: Thu, 2 Jun 2016 12:39:33 -0400
Subject: [R] Need help getting plotly to run on R
Message-ID: <946B6948-225F-4B19-8B77-D6A1EA325A20@gmail.com>

I signed up with plotly on their own site - https://plot.ly/ <https://plot.ly/> - and got a username and password.

When I installed the package in R, I got the following error msg - 
"Storing 'username' as the environment variable 'plotly_username'
Error in Sys.setenv(plotly_username = username) : 
  wrong length for argument?

So I called signup("knanus", "kmnanus at gmail.com?) and received :
Error: Aw, snap! Either you've already signed-up with this username or this username has been taken. If you think you've already signed up, you can view your API key at https://plot.ly/api/key and sign in:
>>> p <- plotly(username="knanus", key=api_key)

I called p<- plolty exactly as instructed above (I did not enter the api_key on this email for confidentiality) and received
Storing 'username' as the environment variable 'plotly_username'
Storing 'key' as the environment variable 'plotly_api_key'
Error in Sys.setenv(plotly_api_key = key) : object ?XXXXXXXXXX' not found

So I detached and deleted plotly from my library and tried - 

install.packages("devtools")
library(devtools)

I received the ?DONE? response, but when I called library(plotly) I received the same ?Storing ?username?? error msg as before.

What am I doing wrong?


Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From evan.cooch at gmail.com  Thu Jun  2 17:35:38 2016
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 2 Jun 2016 11:35:38 -0400
Subject: [R] problems compiling packages | 3.3.0 | Linux
Message-ID: <5750524A.4000006@gmail.com>

Updated my R install on my GNU/Linux boxes (running RHEL 6.xx), using 
latest from CRAN (i.e., not compiling from source), and while said 
upgrade seemed to go fine, am having all sorts of problems with getting 
some packages to compile (either during an initial install attempt, or 
upgrade to existing packages).

For example, if I try to update nlme, I get the following errors, which 
are pretty well fatal:

gcc: error: 
/builddir/build/BUILD/R-3.3.0/zlib-1.2.8/target/usr/lib64/libz.a: No 
such file or directory
gcc: error: 
/builddir/build/BUILD/R-3.3.0/bzip2-1.0.6/target/usr/lib64/libbz2.a: No 
such file or directory
gcc: error: 
/builddir/build/BUILD/R-3.3.0/xz-5.2.2/target/usr/lib64/liblzma.a: No 
such file or directory
gcc: error: 
/builddir/build/BUILD/R-3.3.0/pcre-8.38/target/usr/lib64/libpcre.a: No 
such file or directory
gcc: error: 
/builddir/build/BUILD/R-3.3.0/curl-7.48.0/target/usr/lib64/libcurl.a: No 
such file or directory


I think the clue is the version of the libs the installer seems to be 
looking for. For example, zlib-1.2.8. RHEL only supports zlib-1.2.3-29 
(RHEL, like most 'enterprise distros', is typically 1 step back from 
'bleeding edge').

Any way I can force R CMD (or some such) to use system libs, instead of 
looking for specific, newer versions? Or, any other suggestions?

Serious pain in the butt. R 3.2.5 was working perfectly -- upgrade 
pretty much gummed things up, as far as compiling some packages.

Thanks in advance.

p.s. wasn't sure if this should go to r-help, or r-packages.


From awadhwani at hortonworks.com  Thu Jun  2 22:40:44 2016
From: awadhwani at hortonworks.com (Arti Wadhwani)
Date: Thu, 2 Jun 2016 20:40:44 +0000
Subject: [R] R integration with Hive with Kerberos enabled
Message-ID: <9EDB3162-7316-4386-A14D-0BDA8A761450@hortonworks.com>

Hi,

I have a question regarding R integration with Hive in kerberized mode. Is it supported? It works fine without kerberos however fails with below error in a kerberized cluster:

java.lang.RuntimeException: org.apache.thrift.transport.TTransportException: Peer indicated failure: GSS initiate failed

Further debugging reveals : The R script uses common packages(rjdbc, rjava) which are not specific to any Hadoop distribution. We need to understand why R script does not read the ticket cache at run time.


Thanks,
Arti Wadhwani
Hortonworks, Inc.
Technical Support Engineer (India)



	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Jun  2 23:41:49 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 02 Jun 2016 16:41:49 -0500
Subject: [R] problems compiling packages | 3.3.0 | Linux
In-Reply-To: <5750524A.4000006@gmail.com>
References: <5750524A.4000006@gmail.com>
Message-ID: <3AFEC4B7-67C0-4538-B637-BD6481CA6FEC@me.com>

On Jun 2, 2016, at 10:35 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
> 
> Updated my R install on my GNU/Linux boxes (running RHEL 6.xx), using latest from CRAN (i.e., not compiling from source), and while said upgrade seemed to go fine, am having all sorts of problems with getting some packages to compile (either during an initial install attempt, or upgrade to existing packages).


Just for clarification, if you were NOT installing from source, you were NOT installing from CRAN. Precompiled RH RPM binaries of R have not been available from CRAN for quite some time.

Presumably you used 'yum' and were installing via the EPEL using their precompiled binary RPMs? Those would be configured for your specific RHEL distribution to have dependencies that are compatible.

The RPMS there would include both "base" R and the additional "recommended" packages, which are part of the default R distribution and includes nlme.

More below.

> 
> For example, if I try to update nlme, I get the following errors, which are pretty well fatal:
> 
> gcc: error: /builddir/build/BUILD/R-3.3.0/zlib-1.2.8/target/usr/lib64/libz.a: No such file or directory
> gcc: error: /builddir/build/BUILD/R-3.3.0/bzip2-1.0.6/target/usr/lib64/libbz2.a: No such file or directory
> gcc: error: /builddir/build/BUILD/R-3.3.0/xz-5.2.2/target/usr/lib64/liblzma.a: No such file or directory
> gcc: error: /builddir/build/BUILD/R-3.3.0/pcre-8.38/target/usr/lib64/libpcre.a: No such file or directory
> gcc: error: /builddir/build/BUILD/R-3.3.0/curl-7.48.0/target/usr/lib64/libcurl.a: No such file or directory
> 
> 
> I think the clue is the version of the libs the installer seems to be looking for. For example, zlib-1.2.8. RHEL only supports zlib-1.2.3-29 (RHEL, like most 'enterprise distros', is typically 1 step back from 'bleeding edge').
> 
> Any way I can force R CMD (or some such) to use system libs, instead of looking for specific, newer versions? Or, any other suggestions?
> 
> Serious pain in the butt. R 3.2.5 was working perfectly -- upgrade pretty much gummed things up, as far as compiling some packages.
> 
> Thanks in advance.
> 
> p.s. wasn't sure if this should go to r-help, or r-packages.


Neither one.

You should be posting to R-SIG-Fedora:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Please re-post there as both RH/Fedora users and the RH RPM maintainers read that list, should there be issues with the EPEL RPMs relative to dependencies.

Regards,

Marc Schwartz


From ross.chapman at ecogeonomix.com  Fri Jun  3 02:42:36 2016
From: ross.chapman at ecogeonomix.com (ross.chapman at ecogeonomix.com)
Date: Fri, 3 Jun 2016 10:42:36 +1000
Subject: [R] bnlearn cpquery
Message-ID: <00ea01d1bd30$d3031710$79094530$@ecogeonomix.com>

Hi all

 

I have created a Bayes network with 14 nodes  using the bnlearn package and
want to explore the conditional probabilities for specific node with a given
set of evidence using the cpquery() command.

 

I find that repeating the command gives very different results for the same
set of evidence.

 

Below are four examples of the same query that gives three very different
outputs.

 

> cpquery(expNetFitted, event=(out>=24), evidence=(RN>2900 & EST=="K1" &
SMG=="C" & BN>1000 & FRT>460 & HI>13 &FRT.1>450 & FRT.2>450 & RN.1 > 2500 &
RN.2 > 2400 &  HI.1>13 &  HI.2>13 & FFB.1 >19 & FFB.2 >20 ))

[1] 0.6

> cpquery(expNetFitted, event=(out>=24), evidence=(RN>2900 & EST=="K1" &
SMG=="C" & BN>1000 & FRT>460 & HI>13 &FRT.1>450 & FRT.2>450 & RN.1 > 2500 &
RN.2 > 2400 &  HI.1>13 &  HI.2>13 & FFB.1 >19 & FFB.2 >20 ))

[1] 0.1428571

> cpquery(expNetFitted, event=(out>=24), evidence=(RN>2900 & EST=="K1" &
SMG=="C" & BN>1000 & FRT>460 & HI>13 &FRT.1>450 & FRT.2>450 & RN.1 > 2500 &
RN.2 > 2400 &  HI.1>13 &  HI.2>13 & FFB.1 >19 & FFB.2 >20 ))

[1] 0.4285714

> cpquery(expNetFitted, event=(out>=24), evidence=(RN>2900 & EST=="K1" &
SMG=="C" & BN>1000 & FRT>460 & HI>13 &FRT.1>450 & FRT.2>450 & RN.1 > 2500 &
RN.2 > 2400 &  HI.1>13 &  HI.2>13 & FFB.1 >19 & FFB.2 >20 ))

[1] 0.1666667

Can you please advise me what is happening with these queries and why the
results is so variable and if there are other options for generating
conditional probabilities with bnlearn.

 

Thanks in advance.

 

Ross 


	[[alternative HTML version deleted]]


From sewashm at gmail.com  Fri Jun  3 04:04:47 2016
From: sewashm at gmail.com (Ashta)
Date: Thu, 2 Jun 2016 21:04:47 -0500
Subject: [R] not common records
Message-ID: <CADDFq33FvkiAq6pkznex3vyCoM_Dkw6FURyhU-J_O9pXNboDLQ@mail.gmail.com>

I have 2 data sets.  File1 and File2. Some records are common to both
data sets. For those common records I want get the difference between
d_x1z1= z1-x1   and d_x2z2= z2-x2.

File1<- data.frame(var = c(561,752,800,900),  x1= c(23,35,40,15), x2=
c(125,284,280,347))
File2<- data.frame(var = c(561,752,800,1001), z1= c(43,45,40,65), z2=
c(185,299,280,310))

Record  900      15    347   appears only in File1
Record   1001    65    310  appears only in File2

File3 should look like as follows

File3
var      x1     x2     z1    z2    d_x1z1   d_x2z2
561      23    125  43    165     20         40
752      35    284  45    299      8          15
800      40    280  40    280      0           0
900      15    347  NA   NA      NA       NA
1001     NA  NA   65    310     NA      NA

How do I get those record not common in both data sets ?
merge( File1,File2) gave me only for common "var"


From jdnewmil at dcn.davis.ca.us  Fri Jun  3 07:47:12 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 02 Jun 2016 22:47:12 -0700
Subject: [R] not common records
In-Reply-To: <CADDFq33FvkiAq6pkznex3vyCoM_Dkw6FURyhU-J_O9pXNboDLQ@mail.gmail.com>
References: <CADDFq33FvkiAq6pkznex3vyCoM_Dkw6FURyhU-J_O9pXNboDLQ@mail.gmail.com>
Message-ID: <F9766309-4665-4734-A0A6-33E5617F4D29@dcn.davis.ca.us>

?merge

Pay attention to the all-whatever parameters. 
-- 
Sent from my phone. Please excuse my brevity.

On June 2, 2016 7:04:47 PM PDT, Ashta <sewashm at gmail.com> wrote:
>I have 2 data sets.  File1 and File2. Some records are common to both
>data sets. For those common records I want get the difference between
>d_x1z1= z1-x1   and d_x2z2= z2-x2.
>
>File1<- data.frame(var = c(561,752,800,900),  x1= c(23,35,40,15), x2=
>c(125,284,280,347))
>File2<- data.frame(var = c(561,752,800,1001), z1= c(43,45,40,65), z2=
>c(185,299,280,310))
>
>Record  900      15    347   appears only in File1
>Record   1001    65    310  appears only in File2
>
>File3 should look like as follows
>
>File3
>var      x1     x2     z1    z2    d_x1z1   d_x2z2
>561      23    125  43    165     20         40
>752      35    284  45    299      8          15
>800      40    280  40    280      0           0
>900      15    347  NA   NA      NA       NA
>1001     NA  NA   65    310     NA      NA
>
>How do I get those record not common in both data sets ?
>merge( File1,File2) gave me only for common "var"
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From marco.scutari at gmail.com  Fri Jun  3 09:54:00 2016
From: marco.scutari at gmail.com (Marco Scutari)
Date: Fri, 3 Jun 2016 08:54:00 +0100
Subject: [R]  bnlearn cpquery
In-Reply-To: <00ea01d1bd30$d3031710$79094530$@ecogeonomix.com>
References: <00ea01d1bd30$d3031710$79094530$@ecogeonomix.com>
Message-ID: <CA+RJqXWUQj+g1Sum65OWyxnkKF7EmQEG4zjE6eu+5fh4TtpTSA@mail.gmail.com>

Dear Ross,

On Friday, 3 June 2016, <ross.chapman at ecogeonomix.com
<javascript:_e(%7B%7D,'cvml','ross.chapman at ecogeonomix.com');>> wrote:
>
> I find that repeating the command gives very different results for the
> same

set of evidence.


Some variability in the results is expected since they are Monte Carlo
estimates.

What is happening in your case is, I think, that your evidence has a very
low
probability (since it is so complex) and thus you need to generate more
particles
to obtain a reasonably precise estimate of that conditional probability.
For such
a small network cpquery() can easily generate, say, 10^7 particles in a few
seconds.

Can you please advise me what is happening with these queries and why the
> results is so variable and if there are other options for generating
> conditional probabilities with bnlearn.
>

For your query, the default logic sampling is the only option - likelihood
weighting
does not currently support unbounded intervals in the evidence.

Cheers,
    Marco


-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom

	[[alternative HTML version deleted]]


From teotjunk at hotmail.com  Fri Jun  3 10:00:35 2016
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Fri, 3 Jun 2016 16:00:35 +0800
Subject: [R] Cut Dates  into bins
Message-ID: <SNT152-W9562B7383245778A7B4E02DF590@phx.gbl>

I have two set of dates

2000-01-01

01/01/2000

The second one occurs weekly and the first one occurs in daily. I would like to bin the first set of dates into the second set of dates. What is the best way to do it?

I tried  converting both formats into numeric formats

DateBase=sort(as.numeric(as.POSIXlt(unique(Shipment$DateRequire),format="%Y-%m-%D",origin="1900-01-01")))

Compare=as.numeric(as.POSIXlt(SMA$TIME_DATE,format="%d/%m/%y",origin="01/01/1900"))

But the numeric numbers turned out to be very different.

Tjun Kiat


 		 	   		  
	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Jun  3 10:35:28 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 3 Jun 2016 10:35:28 +0200
Subject: [R] stats package
In-Reply-To: <CA+Lgt_rQCPK9XXPOxFdDQV5XdNVmai764nSC9eOukKqW2V0W4w@mail.gmail.com>
References: <CA+Lgt_rQCPK9XXPOxFdDQV5XdNVmai764nSC9eOukKqW2V0W4w@mail.gmail.com>
Message-ID: <22353.16720.249824.167343@stat.math.ethz.ch>

>>>>> Dariush Ashtab <ashtab.dariush at gmail.com>
>>>>>     on Thu, 2 Jun 2016 17:57:14 +0430 writes:

["accidentally" to R-core .. should have gone to R-help -- and
 hence answered here]
 
    > Dear R project I need stats package for optimization in
    > simulated annealing but i can not download.  please guide
    > me.

If you install R in any "normal way", it comes with 29 R
packages.

Inside, R, you get their names via

> rownames(installed.packages(.Library, priority=c("base","recommended")))
 [1] "base"       "boot"       "class"      "cluster"    "codetools" 
 [6] "compiler"   "datasets"   "foreign"    "graphics"   "grDevices" 
[11] "grid"       "KernSmooth" "lattice"    "MASS"       "Matrix"    
[16] "methods"    "mgcv"       "nlme"       "nnet"       "parallel"  
[21] "rpart"      "spatial"    "splines"    "stats"      "stats4"    
[26] "survival"   "tcltk"      "tools"      "utils"     
> 

A subset of  14  of these, the "base" ones, are bundled with R,
and entirely part of the source code of R, and hence cannot be 
installed separately :

> rownames(installed.packages(.Library, priority="base"))
 [1] "base"      "compiler"  "datasets"  "graphics"  "grDevices" "grid"     
 [7] "methods"   "parallel"  "splines"   "stats"     "stats4"    "tcltk"    
[13] "tools"     "utils"    

Package 'stats' is among these and even is among those packages
that are loaded and *attached* (to your "search path") by default,
when you start R.


    > Many thanks from any pointers,
    > Dariush

You are welcome,
Martin

Martin Maechler
ETH Zurich

    > -- 
    > Dariush Ashtab
    > ( MS.c in Environment Assessment & Planning )
    > Master Student , Department of Environment, Faculty of Natural Resources,
    > Tarbiat Modares University (T.M.U.), Noor, Iran.


From drjimlemon at gmail.com  Fri Jun  3 10:59:11 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Jun 2016 18:59:11 +1000
Subject: [R] Cut Dates into bins
In-Reply-To: <SNT152-W9562B7383245778A7B4E02DF590@phx.gbl>
References: <SNT152-W9562B7383245778A7B4E02DF590@phx.gbl>
Message-ID: <CA+8X3fUY-ayXwnWJHwStY+LdQkQ4XCoLTFTaUa+gAMzFzRoddw@mail.gmail.com>

Hi Tjun Kiat,
This seems to work:

daily_date<-as.Date(paste("2000-01",1:28,sep="-"),"%Y-%m-%d")
weekly_date<-as.Date(paste(c(1,8,15,22,28),"01/2000",sep="/"),
 "%d/%m/%Y")
cut(daily_date,breaks=weekly_date,include.lowest=TRUE,
 labels=paste("Week",1:4))

Jim


On Fri, Jun 3, 2016 at 6:00 PM, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:
> I have two set of dates
>
> 2000-01-01
>
> 01/01/2000
>
> The second one occurs weekly and the first one occurs in daily. I would like to bin the first set of dates into the second set of dates. What is the best way to do it?
>
> I tried  converting both formats into numeric formats
>
> DateBase=sort(as.numeric(as.POSIXlt(unique(Shipment$DateRequire),format="%Y-%m-%D",origin="1900-01-01")))
>
> Compare=as.numeric(as.POSIXlt(SMA$TIME_DATE,format="%d/%m/%y",origin="01/01/1900"))
>
> But the numeric numbers turned out to be very different.
>
> Tjun Kiat
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From judyoringe at naver.com  Fri Jun  3 11:09:22 2016
From: judyoringe at naver.com (Ahreum Lee)
Date: Fri, 3 Jun 2016 18:09:22 +0900 (KST)
Subject: [R] =?utf-8?q?Cluster_analysis_with_Weighted_attribute?=
Message-ID: <9b7c9c8f824ac72b1858bb85a839e99@cweb03.nm.nhnsystem.com>

 Hi! All.
 
I'm not much familiar with R. 
So I tried to find a R function or packages that could work with my problems. 
 
What  I wonder is, 
Whether there is any R function or package that includes the cluster analysis considering with the weighted attribute.
 
I saw several papers that dealt with the Attribute Value Weighting in K-Modes Clustering. 
?but I could not find the R function or packages related with this.  
 
We got the weight of each attributes by interviewing the experts. 
 
What we want to do is do cluster analysis regarding with those weighted value on the attributes.
 
 
Is there any suggestion for me?? 
It would be much appreciated ! 
 
Thanks for your interest on my question! 
 
? 
 
 

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Jun  3 12:42:30 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 3 Jun 2016 10:42:30 +0000
Subject: [R] Cut Dates  into bins
In-Reply-To: <SNT152-W9562B7383245778A7B4E02DF590@phx.gbl>
References: <SNT152-W9562B7383245778A7B4E02DF590@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502DC5F@SRVEXCHMBX.precheza.cz>

Hi

you either made typo in your post or in your real evaluation of your dates.

> d1 <- strptime("2000-01-01", format="%Y-%m-%d")
> d2 <- strptime("01/01/2000", format ="%d/%m/%Y")
> d1==d2
[1] TRUE
>
However, I am not sure why you fiddle with as.numeric and what do you mean by bin dates.

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of TJUN KIAT
> TEO
> Sent: Friday, June 3, 2016 10:01 AM
> To: r-help at r-project.org
> Subject: [R] Cut Dates into bins
>
> I have two set of dates
>
> 2000-01-01
>
> 01/01/2000
>
> The second one occurs weekly and the first one occurs in daily. I would like to
> bin the first set of dates into the second set of dates. What is the best way to
> do it?
>
> I tried  converting both formats into numeric formats
>
> DateBase=sort(as.numeric(as.POSIXlt(unique(Shipment$DateRequire),form
> at="%Y-%m-%D",origin="1900-01-01")))
>
> Compare=as.numeric(as.POSIXlt(SMA$TIME_DATE,format="%d/%m/%y",ori
> gin="01/01/1900"))
>
> But the numeric numbers turned out to be very different.
>
> Tjun Kiat
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jhernandezcabrera at gmail.com  Fri Jun  3 13:03:09 2016
From: jhernandezcabrera at gmail.com (Juan Andres Hernandez)
Date: Fri, 3 Jun 2016 12:03:09 +0100
Subject: [R] Something weird
Message-ID: <CAL79i+Qi3EfJwbHycXm3Gxn9_m2QBn+e5Z6RN0GKdyhADFHQZw@mail.gmail.com>

Can anybody explain me this weird result?
a=3
as.integer(a)
1] 3

a=(3/10)/0.1
a
[1] 3

as.integer(a)
[1] 2

Thank's in advance

Juan A Hern?ndez

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Fri Jun  3 13:17:14 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 03 Jun 2016 06:17:14 -0500
Subject: [R] Something weird
In-Reply-To: <CAL79i+Qi3EfJwbHycXm3Gxn9_m2QBn+e5Z6RN0GKdyhADFHQZw@mail.gmail.com>
References: <CAL79i+Qi3EfJwbHycXm3Gxn9_m2QBn+e5Z6RN0GKdyhADFHQZw@mail.gmail.com>
Message-ID: <3D8356D5-2CD6-4496-917A-37B8B591B698@me.com>


> On Jun 3, 2016, at 6:03 AM, Juan Andres Hernandez <jhernandezcabrera at gmail.com> wrote:
> 
> Can anybody explain me this weird result?
> a=3
> as.integer(a)
> 1] 3
> 
> a=(3/10)/0.1
> a
> [1] 3
> 
> as.integer(a)
> [1] 2
> 
> Thank's in advance
> 
> Juan A Hern?ndez


See:

  https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

Also, note that as per the Value section of ?as.integer:

  "Non-integral numeric values are truncated towards zero..."

> print((3/10) / 0.1, 20)
[1] 2.9999999999999995559

> (3/10) / 0.1 == 3
[1] FALSE


Regards,

Marc Schwartz


From evan.cooch at gmail.com  Fri Jun  3 15:35:24 2016
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 3 Jun 2016 09:35:24 -0400
Subject: [R] problems compiling packages | 3.3.0 | Linux
In-Reply-To: <3AFEC4B7-67C0-4538-B637-BD6481CA6FEC@me.com>
References: <5750524A.4000006@gmail.com>
	<3AFEC4B7-67C0-4538-B637-BD6481CA6FEC@me.com>
Message-ID: <2e43694a-1327-0900-ea9e-df3151ac4471@gmail.com>

OK -- thanks. I used to compile from source routinely, but could never 
get thee 'hand rolled' version of R to play nice with some external 
applications (specifically, jags, and openbugs).


On 6/2/2016 5:41 PM, Marc Schwartz wrote:
> On Jun 2, 2016, at 10:35 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
>> Updated my R install on my GNU/Linux boxes (running RHEL 6.xx), using latest from CRAN (i.e., not compiling from source), and while said upgrade seemed to go fine, am having all sorts of problems with getting some packages to compile (either during an initial install attempt, or upgrade to existing packages).
>
> Just for clarification, if you were NOT installing from source, you were NOT installing from CRAN. Precompiled RH RPM binaries of R have not been available from CRAN for quite some time.
>
> Presumably you used 'yum' and were installing via the EPEL using their precompiled binary RPMs? Those would be configured for your specific RHEL distribution to have dependencies that are compatible.
>
> The RPMS there would include both "base" R and the additional "recommended" packages, which are part of the default R distribution and includes nlme.
>
> More below.
>
>> For example, if I try to update nlme, I get the following errors, which are pretty well fatal:
>>
>> gcc: error: /builddir/build/BUILD/R-3.3.0/zlib-1.2.8/target/usr/lib64/libz.a: No such file or directory
>> gcc: error: /builddir/build/BUILD/R-3.3.0/bzip2-1.0.6/target/usr/lib64/libbz2.a: No such file or directory
>> gcc: error: /builddir/build/BUILD/R-3.3.0/xz-5.2.2/target/usr/lib64/liblzma.a: No such file or directory
>> gcc: error: /builddir/build/BUILD/R-3.3.0/pcre-8.38/target/usr/lib64/libpcre.a: No such file or directory
>> gcc: error: /builddir/build/BUILD/R-3.3.0/curl-7.48.0/target/usr/lib64/libcurl.a: No such file or directory
>>
>>
>> I think the clue is the version of the libs the installer seems to be looking for. For example, zlib-1.2.8. RHEL only supports zlib-1.2.3-29 (RHEL, like most 'enterprise distros', is typically 1 step back from 'bleeding edge').
>>
>> Any way I can force R CMD (or some such) to use system libs, instead of looking for specific, newer versions? Or, any other suggestions?
>>
>> Serious pain in the butt. R 3.2.5 was working perfectly -- upgrade pretty much gummed things up, as far as compiling some packages.
>>
>> Thanks in advance.
>>
>> p.s. wasn't sure if this should go to r-help, or r-packages.
>
> Neither one.
>
> You should be posting to R-SIG-Fedora:
>
>    https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>
> Please re-post there as both RH/Fedora users and the RH RPM maintainers read that list, should there be issues with the EPEL RPMs relative to dependencies.
>
> Regards,
>
> Marc Schwartz
>
>


From jfox at mcmaster.ca  Fri Jun  3 16:08:09 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Fri, 3 Jun 2016 14:08:09 +0000
Subject: [R] SEM GFI
In-Reply-To: <1876213547.3216914.1464933851421.JavaMail.yahoo@mail.yahoo.com>
References: <1103804586.1954135.1464719331934.JavaMail.yahoo.ref@mail.yahoo.com>
	<1103804586.1954135.1464719331934.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbTp+0uDC1YDxF-LgDsvcEx_69BU=Nc+BBqMMZnP9j3t9Q@mail.gmail.com>
	<234506459.2505773.1464802919535.JavaMail.yahoo@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC810FA703C@FHSDB2D11-2.csu.mcmaster.ca>
	<1741311959.2937401.1464877135643.JavaMail.yahoo@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC810FA70E8@FHSDB2D11-2.csu.mcmaster.ca>
	<1876213547.3216914.1464933851421.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810FA763C@FHSDB2D11-2.csu.mcmaster.ca>

Dear Vinay,

As you can see from the df for the model (i.e., LR chisquare), which is 39 in SAS and 52 using sem() in the sem package, you fit very different models in the two programs. It's consequently unremarkable that you got different results -- and not just for the GFI but for everything. The model you fit using sem() has many fewer parameters than the model fit in SAS. It's my guess that SAS automatically supplies more  variance/covariance parameters than sem() does; sem() would supply missing variance parameters, unless instructed not to do so, but not covariances.

BTW, I found it curious that proc calis in SAS apparently accepts sem()-like path model specification, including the (in sem() ) unnecessary NAs. Is this an example of convergent evolution?

I'm cc'ing this response to the r-help list, where you posed the original question, to keep readers of the list in the loop. That's useful if someone else experiences a similar problem.

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: VINAY KULKARNI [mailto:vinaypkulkarni at yahoo.com]
> Sent: June 3, 2016 2:04 AM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re: [R] SEM GFI
> 
> Hi Jon,
> 
> 
> Please find attached all the files in zip file.
> 
> 
> - SAS code and R code
> - data in csv format and correlation from SAS
> - SAS SEM output and R SEM output in one excel file
> 
> 
> Yes GFI is not matching and some of the parameter estimates are not matching.
> 
> I will try today using specifyEquations(), i think this way it is little bit
> complicated.
> 
> Thanks for your help!
> 
> Vinay
> 
> 
> ________________________________
> 
> From: "Fox, John" <jfox at mcmaster.ca>
> To: "vinaypkulkarni at yahoo.com" <vinaypkulkarni at yahoo.com>
> Sent: Thursday, 2 June 2016 8:39 PM
> Subject: RE: [R] SEM GFI
> 
> 
> Dear Vinay,
> 
> Yes, you can send me the .R file and the SAS file. Also send me the SAS output --
> I don't currently have SAS on my computer -- and the data. Don't paste
> anything into an email; send the files.
> 
> You also didn't address my observation about the results -- are all of the results
> the same except for the GFI and one standard error? Have you tried coding
> your model using specifyEquations()?
> 
> John
> 
> 
> 
> > -----Original Message-----
> > From: VINAY KULKARNI [mailto:vinaypkulkarni at yahoo.com
> <mailto:vinaypkulkarni at yahoo.com> ]
> > Sent: Thursday, June 2, 2016 10:19 AM
> > To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> >
> > Subject: RE: [R] SEM GFI
> >
> >
> > Hi Fox,
> > Thanks for your reply.
> > Please let me know if I can send the data ,both codes and both fit
> > indices directly to your email id.
> >
> > Data is in excel,if I paste the data directly in email it won't be clear
> > so.
> >
> > Thanks,
> > Vinay
> >
> > Sent from Yahoo Mail on Android
> > <https://overview.mail.yahoo.com/mobile/?.src=Android>
> >
> >
> >     On Thu, Jun 2, 2016 at 5:31 PM, Fox, John
> >     <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca> > wrote:
> >     Dear Vinay and Burt,
> >
> >     I didn't see Vinay's original posting -- sorry about that.
> >
> >     Vinay: There's still not enough information here to tell why the
> > results are different, and posting in HTML makes the code very hard to
> > read.
> >
> >     To elaborate slightly: You don't provide the data, so it's not
> > possible to replicate your results. You also don't show the command or
> > results from SAS, so it's not possible to know how the results differ.
> > Your original message seems to imply that the results are identical
> > accept for the value of GFI and one coefficient standard error. That
> > seems unlikely. My guess: you inadvertently fit different models in SAS
> > and sem.
> >
> >     Additionally, you'd probably find it easier, and less error prone,
> > to specify the model in sem() using specifyEquations() rather than
> > specifyModel(), as the message printed by the latter tells you.
> >
> >     I hope this helps,
> >     John
> >
> >     -----------------------------
> >     John Fox, Professor
> >     McMaster University
> >     Hamilton, Ontario
> >     Canada L8S 4M4
> >     Web: socserv.mcmaster.ca/jfox
> >
> >
> >
> >
> >     > -----Original Message-----
> >     > From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org>
> > <javascript:return> ] On Behalf Of VINAY
> >     > KULKARNI via R-help
> >     > Sent: June 1, 2016 1:42 PM
> >     > To: Bert Gunter <bgunter.4567 at gmail.com
> <mailto:bgunter.4567 at gmail.com>  <javascript:return> >
> >     > Cc: r-help at r-project.org <mailto:r-help at r-project.org>
> <javascript:return>
> >     > Subject: Re: [R] SEM GFI
> >     >
> >     > Hi,
> >     > Please find below the code:
> >     > Thanks,Vinay
> >     > >library(sem) >data1=read.csv("data_1.csv") >corr=cor(data1)
> >     > >model1<-specifyModel()brand1_Pric_ind    ->
> >     > >Val_brand1,lamb1,NADist_brand1      ->
> >     > >Val_brand1,lamb2,NAbrand1_like_me    ->
> >     > >Val_brand1,lamb3,NAbrand2_Def_Drink -
> >     > >  Val_brand1,lamb4,NAbrand2_Like
> >     > >-> brand2_Def_Drink,lamb5,NAbrand2_Pleasure ->
> >     > >brand2_Def_Drink,lamb6,NAbrand1_Like ->
> >     > >brand1_like_me,lamb7,NAbrand1_Love ->
> >     > >brand1_like_me,lamb8,NAbrand1_P4WC ->
> >     > brand1_Like,lamb9,NAbrand1_P4WC
> >     > >-> brand1_Love,lamb10,NAbrand1_Energy ->
> >     > >brand1_P4WC,lamb11,NAbrand1_Different ->
> >     > >brand1_P4WC,lamb12,NAbrand1_Pric_ind <->
> >     > >brand1_Pric_ind,the1,NADist_brand1 <->
> >     > >Dist_brand1,the2,NAbrand1_like_me  <->
> >     > >brand1_like_me,the3,NAbrand2_Def_Drink <->
> >     > >brand2_Def_Drink,the4,NAbrand2_Like <->
> >     > >brand2_Like,the5,NAbrand2_Pleasure <->
> >     > >brand2_Pleasure,the6,NAbrand1_Like <->
> > brand1_Like,the7,NAbrand1_Love
> >     > ><-> brand1_Love,the8,NAbrand1_P4WC <->
> >     > brand1_P4WC,the9,NAbrand1_Energy
> >     > ><-> brand1_Energy,the10,NAbrand1_Different <->
> >     > >brand1_Different,the11,NAbrand1_like_me  <->
> >     > >brand2_Def_Drink,the12,NAbrand1_Like <->
> >     > brand1_Love,the13,NAVal_brand1
> >     > ><-> Val_brand1,1,NA  > opt <- options(fit.indices = c("GFI",
> > "AGFI",
> >     > >"RMSEA", "NFI", "NNFI", "CFI", "RNI", "IFI", "SRMR", "AIC",
> > "AICc",
> >     > >"BIC", "CAIC")) > sem.model1<-sem(model1,corr,36)
> >     > > summary(sem.model1)
> >     >
> >     >
> >     >
> >     >
> >     >      From: Bert Gunter <bgunter.4567 at gmail.com
> <mailto:bgunter.4567 at gmail.com>
> > <javascript:return> >
> >     >  To: VINAY KULKARNI <vinaypkulkarni at yahoo.com
> <mailto:vinaypkulkarni at yahoo.com>  <javascript:return>
> > >
> >     > Cc: "r-help at r-project.org <mailto:r-help at r-project.org>
> <javascript:return> " <r-help at r- <mailto:r-help at r->
> > project.org <javascript:return> >
> >     >  Sent: Wednesday, 1 June 2016 2:16 AM
> >     >  Subject: Re: [R] SEM GFI
> >     >
> >     > Probably impossible to answer without your following the posting
> > guide and
> >     > posting your code, etc.
> >     >
> >     > Cheers,
> >     >
> >     > Bert
> >     > Bert Gunter
> >     >
> >     > "The trouble with having an open mind is that people keep coming
> > along and
> >     > sticking things into it."
> >     > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> > )
> >     >
> >     >
> >     > On Tue, May 31, 2016 at 11:28 AM, VINAY KULKARNI via R-help <r-
> > help at r- <mailto:help at r->  <javascript:return>
> >     > project.org> wrote:
> >     > > Hi,
> >     > > I am exactly replicating the SEM model which was done in SAS
> > using Proc
> >     > Calis in R.
> >     > > Used sem package in R but not getting the GFI as same as in SAS
> >     > > (approximately 15% difference) and also one link is
> > insignificant but in SAS
> >     > am getting significant.
> >     > > Searched through online in different blogs but not able to get
> > the solution.
> >     > > Please let me know what might be the reason.
> >     > > Thanks,Vinay
> >     > >
> >     > >
> >     > >
> >     > >        [[alternative HTML version deleted]]
> >     > >
> >     > > ______________________________________________
> >     > > R-help at r-project.org <mailto:R-help at r-project.org>
> <javascript:return>  mailing list -- To
> > UNSUBSCRIBE and more, see
> >     > > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > > PLEASE do read the posting guide
> >     > > http://www.R-project.org/posting-guide.html
> >     > > and provide commented, minimal, self-contained, reproducible
> > code.
> >
> >     >
> >     >
> >     >
> >     >    [[alternative HTML version deleted]]
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org>  <javascript:return>
> mailing list -- To
> 
> > UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide http://www.R- <http://www.r-/>
> > project.org/posting-
> >     > guide.html
> >     > and provide commented, minimal, self-contained, reproducible
> > code.
> >
> 
> 
> 


From suparnabsws4 at gmail.com  Fri Jun  3 09:22:37 2016
From: suparnabsws4 at gmail.com (suparna biswas)
Date: Fri, 3 Jun 2016 12:52:37 +0530
Subject: [R] Request for help
Message-ID: <CAG1U7UuwZmjfawH_X7a2SfUDRo6-MaXFjdEXWtVpoLR+WEO6Mw@mail.gmail.com>

Dear Sir/Madam
                       Myself Suparna Biswas, a research scholar from the
department of Mathematical Sciences, Tezpur University, Assam, India. I am
working under the supervision of Dr. Santanu Dutta, Associate Professor,
Department of Mathematical Sciences, Tezpur University, Assam, India. My
research topic is "Estimation and Application of Risk Measure in Finance".

                        I mainly use the R software in my research work. I
want to convert all my code into a R package manually. I have gone through
the paper by Friedrich Leisch titled "Creating R Packages: A Tutorial. But
I am facing problem in writing help pages. The things mentioned in the
paper about help pages are not clear to me as I have never written help
pages before.

                        I will be obliged if you kindly help me in this
context. Thanking you.

-- 
With warm regards,
Suparna Biswas
Research Scholar
Department of Mathematical Sciences
Tezpur University

	[[alternative HTML version deleted]]


From Matthias.Weber at fntsoftware.com  Fri Jun  3 16:49:41 2016
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Fri, 3 Jun 2016 14:49:41 +0000
Subject: [R] sustring in dependence of values
Message-ID: <HE1PR07MB121215086744E55B8DA6A27190590@HE1PR07MB1212.eurprd07.prod.outlook.com>

Hello togehter,

maybe anyone can help me with a little problem.

I have the following column in an data.frame (called TEST)

      VERSION
1    abc (9.2 -> 10.0)
2    def (10.2 -> 11.0)
3    ghi (7.4 -> 8.4)
4    jkl (10.2 -> 10.4)
5    mno (8.1 -> 9.0)

I now need the code for the following result (I want the numbers "before/after" in a separate column. The solution look like this one:

      VERSION              FROM         TO
1    abc (9.2 -> 10.0)     9.2             10.0
2    def (10.2 -> 11.0)    10.2           11.0
3    ghi (7.4 -> 8.4)        7.4             8.4
4    jkl (10.2 -> 10.4)      10.2           10.4
5    mno (8.1 -> 9.0)      8.1             9.0

Maybe anyone can help me. The substring-code doesn't help me at the moment.

Best regards.

Mat


	[[alternative HTML version deleted]]


From shyam.kumar.basnet at slu.se  Fri Jun  3 17:22:12 2016
From: shyam.kumar.basnet at slu.se (Shyam Kumar Basnet)
Date: Fri, 3 Jun 2016 15:22:12 +0000
Subject: [R] kernel matching pursuit
Message-ID: <e0e93f0a4e8247c0b312ae451b05884f@EXCH2-1.slu.se>

Hi,

Do you know any R-package for Kernel matching using the propensity scores?

I really appreciate your help.

Thanks,
Shyam  Basnet
Sweden

	[[alternative HTML version deleted]]


From ebs15242 at gmail.com  Fri Jun  3 20:20:24 2016
From: ebs15242 at gmail.com (Ed Siefker)
Date: Fri, 3 Jun 2016 13:20:24 -0500
Subject: [R] merging dataframes in a list
Message-ID: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>

I have a list of data as follows.

> list(data.frame(name="sample1", red=20), data.frame(name="sample1", green=15), data.frame(name="sample2", red=10), data.frame(name="sample 2", green=30))
[[1]]
     name red
1 sample1  20

[[2]]
     name green
1 sample1    15

[[3]]
     name red
1 sample2  10

[[4]]
     name green
1 sample2    30


I would like to massage this into a data frame like this:

     name red green
1 sample1  20    15
2 sample2  10    30


I'm imagining I can use aggregate(mylist, by=samplenames, merge)
right?  But how do I get the list of samplenames?  How do I subset
each dataframe inside the list?


From bgunter.4567 at gmail.com  Fri Jun  3 20:27:29 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 3 Jun 2016 11:27:29 -0700
Subject: [R] Request for help
In-Reply-To: <CAG1U7UuwZmjfawH_X7a2SfUDRo6-MaXFjdEXWtVpoLR+WEO6Mw@mail.gmail.com>
References: <CAG1U7UuwZmjfawH_X7a2SfUDRo6-MaXFjdEXWtVpoLR+WEO6Mw@mail.gmail.com>
Message-ID: <CAGxFJbS0Uvj5BO3e4vx9_-go8vxDvnOtcP5kKKAUYuXtYX2vgA@mail.gmail.com>

See the "Writing R Extensions" manual that ships with R.

You might also want to consider Hadley Wickham's roxygen2 package,
which allows one to include the Help information as specially
formatted comments within the code files themselves. The package will
then generate the Help files from this info automagically.

Finally, google! -- there are many other tutorials on this on the web.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 3, 2016 at 12:22 AM, suparna biswas <suparnabsws4 at gmail.com> wrote:
> Dear Sir/Madam
>                        Myself Suparna Biswas, a research scholar from the
> department of Mathematical Sciences, Tezpur University, Assam, India. I am
> working under the supervision of Dr. Santanu Dutta, Associate Professor,
> Department of Mathematical Sciences, Tezpur University, Assam, India. My
> research topic is "Estimation and Application of Risk Measure in Finance".
>
>                         I mainly use the R software in my research work. I
> want to convert all my code into a R package manually. I have gone through
> the paper by Friedrich Leisch titled "Creating R Packages: A Tutorial. But
> I am facing problem in writing help pages. The things mentioned in the
> paper about help pages are not clear to me as I have never written help
> pages before.
>
>                         I will be obliged if you kindly help me in this
> context. Thanking you.
>
> --
> With warm regards,
> Suparna Biswas
> Research Scholar
> Department of Mathematical Sciences
> Tezpur University
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Jun  3 20:30:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 3 Jun 2016 11:30:34 -0700
Subject: [R] sustring in dependence of values
In-Reply-To: <HE1PR07MB121215086744E55B8DA6A27190590@HE1PR07MB1212.eurprd07.prod.outlook.com>
References: <HE1PR07MB121215086744E55B8DA6A27190590@HE1PR07MB1212.eurprd07.prod.outlook.com>
Message-ID: <CAGxFJbRCLX_N3Gj7zWMPB9TstGSLj4w-cErkhOrV28YapnHW+w@mail.gmail.com>

Use regular expressions:

?grep
?regexp

(The answer is simple, but I think it is worthwhile to learn about
this on your own. Others may disagree and supply you the exact
answer).

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 3, 2016 at 7:49 AM, Matthias Weber
<Matthias.Weber at fntsoftware.com> wrote:
> Hello togehter,
>
> maybe anyone can help me with a little problem.
>
> I have the following column in an data.frame (called TEST)
>
>       VERSION
> 1    abc (9.2 -> 10.0)
> 2    def (10.2 -> 11.0)
> 3    ghi (7.4 -> 8.4)
> 4    jkl (10.2 -> 10.4)
> 5    mno (8.1 -> 9.0)
>
> I now need the code for the following result (I want the numbers "before/after" in a separate column. The solution look like this one:
>
>       VERSION              FROM         TO
> 1    abc (9.2 -> 10.0)     9.2             10.0
> 2    def (10.2 -> 11.0)    10.2           11.0
> 3    ghi (7.4 -> 8.4)        7.4             8.4
> 4    jkl (10.2 -> 10.4)      10.2           10.4
> 5    mno (8.1 -> 9.0)      8.1             9.0
>
> Maybe anyone can help me. The substring-code doesn't help me at the moment.
>
> Best regards.
>
> Mat
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From JLucke at ria.buffalo.edu  Fri Jun  3 20:33:02 2016
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Fri, 3 Jun 2016 14:33:02 -0400
Subject: [R] Request for help
In-Reply-To: <CAGxFJbS0Uvj5BO3e4vx9_-go8vxDvnOtcP5kKKAUYuXtYX2vgA@mail.gmail.com>
References: <CAG1U7UuwZmjfawH_X7a2SfUDRo6-MaXFjdEXWtVpoLR+WEO6Mw@mail.gmail.com>
	<CAGxFJbS0Uvj5BO3e4vx9_-go8vxDvnOtcP5kKKAUYuXtYX2vgA@mail.gmail.com>
Message-ID: <OF33F02E75.345C13AC-ON85257FC7.0065A516-85257FC7.0065E623@ria.buffalo.edu>

There is a video tutorial on the RStudio web site showing how to create R 
packages within RStudio.  Hadley Wickham also has a book on creating R 
packages.
 



Bert Gunter <bgunter.4567 at gmail.com> 
Sent by: "R-help" <r-help-bounces at r-project.org>
06/03/2016 02:27 PM

To
suparna biswas <suparnabsws4 at gmail.com>, 
cc
r-help <r-help at r-project.org>
Subject
Re: [R] Request for help






See the "Writing R Extensions" manual that ships with R.

You might also want to consider Hadley Wickham's roxygen2 package,
which allows one to include the Help information as specially
formatted comments within the code files themselves. The package will
then generate the Help files from this info automagically.

Finally, google! -- there are many other tutorials on this on the web.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 3, 2016 at 12:22 AM, suparna biswas <suparnabsws4 at gmail.com> 
wrote:
> Dear Sir/Madam
>                        Myself Suparna Biswas, a research scholar from 
the
> department of Mathematical Sciences, Tezpur University, Assam, India. I 
am
> working under the supervision of Dr. Santanu Dutta, Associate Professor,
> Department of Mathematical Sciences, Tezpur University, Assam, India. My
> research topic is "Estimation and Application of Risk Measure in 
Finance".
>
>                         I mainly use the R software in my research work. 
I
> want to convert all my code into a R package manually. I have gone 
through
> the paper by Friedrich Leisch titled "Creating R Packages: A Tutorial. 
But
> I am facing problem in writing help pages. The things mentioned in the
> paper about help pages are not clear to me as I have never written help
> pages before.
>
>                         I will be obliged if you kindly help me in this
> context. Thanking you.
>
> --
> With warm regards,
> Suparna Biswas
> Research Scholar
> Department of Mathematical Sciences
> Tezpur University
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Fri Jun  3 20:37:19 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 3 Jun 2016 11:37:19 -0700
Subject: [R] Request for help
In-Reply-To: <OF33F02E75.345C13AC-ON85257FC7.0065A516-85257FC7.0065E623@ria.buffalo.edu>
References: <CAG1U7UuwZmjfawH_X7a2SfUDRo6-MaXFjdEXWtVpoLR+WEO6Mw@mail.gmail.com>
	<CAGxFJbS0Uvj5BO3e4vx9_-go8vxDvnOtcP5kKKAUYuXtYX2vgA@mail.gmail.com>
	<OF33F02E75.345C13AC-ON85257FC7.0065A516-85257FC7.0065E623@ria.buffalo.edu>
Message-ID: <153DA298-6057-4F2E-BCCD-A15990C6E32A@noaa.gov>

Hi All:


> On Jun 3, 2016, at 11:33 AM, JLucke at ria.buffalo.edu wrote:
> 
> There is a video tutorial on the RStudio web site showing how to create R 
> packages within RStudio.  Hadley Wickham also has a book on creating R 
> packages.
> 


And I would add that Hadley has kindly put the book online, at http://r-pkgs.had.co.nz/intro.html

-Roy

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ebs15242 at gmail.com  Fri Jun  3 20:41:31 2016
From: ebs15242 at gmail.com (Ed Siefker)
Date: Fri, 3 Jun 2016 13:41:31 -0500
Subject: [R] merging dataframes in a list
In-Reply-To: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
References: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
Message-ID: <CALRb-ofkvjKEJL6NdnANoKfiQ9GG49AtDho_f89mkL3UNXJssA@mail.gmail.com>

I manually constructed the list of sample names and tried the
aggregate call I mentioned.
Merge works when called manually, but not when using aggregate.

> mylist <- list(data.frame(name="sample1", red=20), data.frame(name="sample1", green=15), data.frame(name="sample2", red=10), data.frame(na me="sample2", green=30))
>  names <- list("sample1", "sample1", "sample2", "sample2")
> merge(mylist[1], mylist[2])
     name red green
1 sample1  20    15
> merge(mylist[3], mylist[4])
     name red green
1 sample2  10    30
> aggregate(mylist, by=as.list(names), merge)
Error in as.data.frame(y) : argument "y" is missing, with no default

What's the right way to do this?

On Fri, Jun 3, 2016 at 1:20 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> I have a list of data as follows.
>
>> list(data.frame(name="sample1", red=20), data.frame(name="sample1", green=15), data.frame(name="sample2", red=10), data.frame(name="sample 2", green=30))
> [[1]]
>      name red
> 1 sample1  20
>
> [[2]]
>      name green
> 1 sample1    15
>
> [[3]]
>      name red
> 1 sample2  10
>
> [[4]]
>      name green
> 1 sample2    30
>
>
> I would like to massage this into a data frame like this:
>
>      name red green
> 1 sample1  20    15
> 2 sample2  10    30
>
>
> I'm imagining I can use aggregate(mylist, by=samplenames, merge)
> right?  But how do I get the list of samplenames?  How do I subset
> each dataframe inside the list?


From murdoch.duncan at gmail.com  Fri Jun  3 20:43:16 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 3 Jun 2016 14:43:16 -0400
Subject: [R] Request for help
In-Reply-To: <CAGxFJbS0Uvj5BO3e4vx9_-go8vxDvnOtcP5kKKAUYuXtYX2vgA@mail.gmail.com>
References: <CAG1U7UuwZmjfawH_X7a2SfUDRo6-MaXFjdEXWtVpoLR+WEO6Mw@mail.gmail.com>
	<CAGxFJbS0Uvj5BO3e4vx9_-go8vxDvnOtcP5kKKAUYuXtYX2vgA@mail.gmail.com>
Message-ID: <8432f800-9c34-70ec-3ab4-14fc2dec7c6d@gmail.com>

On 03/06/2016 2:27 PM, Bert Gunter wrote:
> See the "Writing R Extensions" manual that ships with R.
>
> You might also want to consider Hadley Wickham's roxygen2 package,
> which allows one to include the Help information as specially
> formatted comments within the code files themselves. The package will
> then generate the Help files from this info automagically.

roxygen2 certainly makes writing help pages easier for the package 
author, but I don't know of any packages that use it that have adequate 
help pages from a user perspective.  I'd be interested to hear of 
counterexamples.

My advice for the original question is to use RStudio for development 
with roxygen2 support turned off, because it has nice support for 
editing .Rd files.  Use prompt() to create skeleton .Rd files for 
functions after you've written them and built the package.  Edit the 
file following the instructions contained in it, doing lots of 
previewing to make sure it looks okay.  Run checks reasonably frequently 
to find your errors and omissions.

Duncan Murdoch



> Finally, google! -- there are many other tutorials on this on the web.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jun 3, 2016 at 12:22 AM, suparna biswas <suparnabsws4 at gmail.com> wrote:
>> Dear Sir/Madam
>>                        Myself Suparna Biswas, a research scholar from the
>> department of Mathematical Sciences, Tezpur University, Assam, India. I am
>> working under the supervision of Dr. Santanu Dutta, Associate Professor,
>> Department of Mathematical Sciences, Tezpur University, Assam, India. My
>> research topic is "Estimation and Application of Risk Measure in Finance".
>>
>>                         I mainly use the R software in my research work. I
>> want to convert all my code into a R package manually. I have gone through
>> the paper by Friedrich Leisch titled "Creating R Packages: A Tutorial. But
>> I am facing problem in writing help pages. The things mentioned in the
>> paper about help pages are not clear to me as I have never written help
>> pages before.
>>
>>                         I will be obliged if you kindly help me in this
>> context. Thanking you.
>>
>> --
>> With warm regards,
>> Suparna Biswas
>> Research Scholar
>> Department of Mathematical Sciences
>> Tezpur University
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Douglas.Federman at utoledo.edu  Fri Jun  3 20:55:01 2016
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Fri, 3 Jun 2016 18:55:01 +0000
Subject: [R] kernel matching pursuit
In-Reply-To: <e0e93f0a4e8247c0b312ae451b05884f@EXCH2-1.slu.se>
References: <e0e93f0a4e8247c0b312ae451b05884f@EXCH2-1.slu.se>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61B046ECD@msgdb20.utad.utoledo.edu>

This website might be of help: http://www.biostat.jhsph.edu/~estuart/propensityscoresoftware.html


confidential to sas, spss, stata, and sudaan users: heavy doses of those programs may cause statococcal infection.? time to transition to R.
-- Anthony Damico --

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shyam Kumar Basnet
Sent: Friday, June 03, 2016 11:22 AM
To: r-help at r-project.org
Subject: [R] kernel matching pursuit

Hi,

Do you know any R-package for Kernel matching using the propensity scores?

I really appreciate your help.

Thanks,
Shyam  Basnet
Sweden

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ebs15242 at gmail.com  Fri Jun  3 21:09:49 2016
From: ebs15242 at gmail.com (Ed Siefker)
Date: Fri, 3 Jun 2016 14:09:49 -0500
Subject: [R] merging dataframes in a list
In-Reply-To: <CALRb-ofkvjKEJL6NdnANoKfiQ9GG49AtDho_f89mkL3UNXJssA@mail.gmail.com>
References: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
	<CALRb-ofkvjKEJL6NdnANoKfiQ9GG49AtDho_f89mkL3UNXJssA@mail.gmail.com>
Message-ID: <CALRb-oeqGJ7D=-X_8-pBe3Dkxt6ubiRGJQtqf5qLy6N_hRWp+A@mail.gmail.com>

aggregate isn't really what I want.  Maybe tapply?  I still can't get
it to work.

> length(mylist)
[1] 4
> length(names)
[1] 4
> tapply(mylist, names, merge)
Error in tapply(mylist, names, merge) : arguments must have same length

I guess because a list isn't an atomic data type.  What function will
do the same on lists?  lapply doesn't have a 'by' argument.

On Fri, Jun 3, 2016 at 1:41 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> I manually constructed the list of sample names and tried the
> aggregate call I mentioned.
> Merge works when called manually, but not when using aggregate.
>
>> mylist <- list(data.frame(name="sample1", red=20), data.frame(name="sample1", green=15), data.frame(name="sample2", red=10), data.frame(na me="sample2", green=30))
>>  names <- list("sample1", "sample1", "sample2", "sample2")
>> merge(mylist[1], mylist[2])
>      name red green
> 1 sample1  20    15
>> merge(mylist[3], mylist[4])
>      name red green
> 1 sample2  10    30
>> aggregate(mylist, by=as.list(names), merge)
> Error in as.data.frame(y) : argument "y" is missing, with no default
>
> What's the right way to do this?
>
> On Fri, Jun 3, 2016 at 1:20 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
>> I have a list of data as follows.
>>
>>> list(data.frame(name="sample1", red=20), data.frame(name="sample1", green=15), data.frame(name="sample2", red=10), data.frame(name="sample 2", green=30))
>> [[1]]
>>      name red
>> 1 sample1  20
>>
>> [[2]]
>>      name green
>> 1 sample1    15
>>
>> [[3]]
>>      name red
>> 1 sample2  10
>>
>> [[4]]
>>      name green
>> 1 sample2    30
>>
>>
>> I would like to massage this into a data frame like this:
>>
>>      name red green
>> 1 sample1  20    15
>> 2 sample2  10    30
>>
>>
>> I'm imagining I can use aggregate(mylist, by=samplenames, merge)
>> right?  But how do I get the list of samplenames?  How do I subset
>> each dataframe inside the list?


From ruipbarradas at sapo.pt  Fri Jun  3 21:17:07 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 03 Jun 2016 20:17:07 +0100
Subject: [R] merging dataframes in a list
In-Reply-To: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
Message-ID: <20160603201707.Horde.VCS8dzCzP4dY8GNa2Q_A09a@mail.sapo.pt>

Hello,

Maybe something like the following.

lst <-
list(data.frame(name="sample1", red=20), data.frame(name="sample1",  
green=15), data.frame(name="sample2", red=10), data.frame(name="sample  
2", green=30))

fun <- function(DF){
?? ?data.frame(name = DF[, 1], color = colnames(DF)[2], colnum = DF[, 2])
}
lst2 <- lapply(lst, fun)

result <- do.call(rbind, lst2)
result

Hope this helps,

Rui Barradas

?

Citando Ed Siefker <ebs15242 at gmail.com>:

> I have a list of data as follows.
>> list(data.frame(name="sample1", red=20), data.frame(name="sample1",  
>> green=15), data.frame(name="sample2", red=10),  
>> data.frame(name="sample 2", green=30))
>
> [[1]]
> ? ? name red
> 1 sample1? 20
>
> [[2]]
> ? ? name green
> 1 sample1? ? 15
>
> [[3]]
> ? ? name red
> 1 sample2? 10
>
> [[4]]
> ? ? name green
> 1 sample2? ? 30
>
> I would like to massage this into a data frame like this:
>
> ? ? name red green
> 1 sample1? 20? ? 15
> 2 sample2? 10? ? 30
>
> I'm imagining I can use aggregate(mylist, by=samplenames, merge)
> right?? But how do I get the list of samplenames?? How do I subset
> each dataframe inside the list?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Jun  3 21:17:31 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 03 Jun 2016 19:17:31 +0000
Subject: [R] merging dataframes in a list
In-Reply-To: <CALRb-oeqGJ7D=-X_8-pBe3Dkxt6ubiRGJQtqf5qLy6N_hRWp+A@mail.gmail.com>
References: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
	<CALRb-ofkvjKEJL6NdnANoKfiQ9GG49AtDho_f89mkL3UNXJssA@mail.gmail.com>
	<CALRb-oeqGJ7D=-X_8-pBe3Dkxt6ubiRGJQtqf5qLy6N_hRWp+A@mail.gmail.com>
Message-ID: <CAKVAULPv3KAGOAhoRvFfi0=yia+ej_kxN_4jbgD0Kaf-s=LncA@mail.gmail.com>

You can use ldply in the plyr package to bind all the data.frames together
(a regular loop will also work). Afterwards you can summarise using ddply

Hope this helps
Ulrik

Ed Siefker <ebs15242 at gmail.com> schrieb am Fr., 3. Juni 2016 21:10:

> aggregate isn't really what I want.  Maybe tapply?  I still can't get
> it to work.
>
> > length(mylist)
> [1] 4
> > length(names)
> [1] 4
> > tapply(mylist, names, merge)
> Error in tapply(mylist, names, merge) : arguments must have same length
>
> I guess because a list isn't an atomic data type.  What function will
> do the same on lists?  lapply doesn't have a 'by' argument.
>
> On Fri, Jun 3, 2016 at 1:41 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> > I manually constructed the list of sample names and tried the
> > aggregate call I mentioned.
> > Merge works when called manually, but not when using aggregate.
> >
> >> mylist <- list(data.frame(name="sample1", red=20),
> data.frame(name="sample1", green=15), data.frame(name="sample2", red=10),
> data.frame(na me="sample2", green=30))
> >>  names <- list("sample1", "sample1", "sample2", "sample2")
> >> merge(mylist[1], mylist[2])
> >      name red green
> > 1 sample1  20    15
> >> merge(mylist[3], mylist[4])
> >      name red green
> > 1 sample2  10    30
> >> aggregate(mylist, by=as.list(names), merge)
> > Error in as.data.frame(y) : argument "y" is missing, with no default
> >
> > What's the right way to do this?
> >
> > On Fri, Jun 3, 2016 at 1:20 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> >> I have a list of data as follows.
> >>
> >>> list(data.frame(name="sample1", red=20), data.frame(name="sample1",
> green=15), data.frame(name="sample2", red=10), data.frame(name="sample 2",
> green=30))
> >> [[1]]
> >>      name red
> >> 1 sample1  20
> >>
> >> [[2]]
> >>      name green
> >> 1 sample1    15
> >>
> >> [[3]]
> >>      name red
> >> 1 sample2  10
> >>
> >> [[4]]
> >>      name green
> >> 1 sample2    30
> >>
> >>
> >> I would like to massage this into a data frame like this:
> >>
> >>      name red green
> >> 1 sample1  20    15
> >> 2 sample2  10    30
> >>
> >>
> >> I'm imagining I can use aggregate(mylist, by=samplenames, merge)
> >> right?  But how do I get the list of samplenames?  How do I subset
> >> each dataframe inside the list?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Fri Jun  3 21:27:36 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 03 Jun 2016 20:27:36 +0100
Subject: [R] merging dataframes in a list
In-Reply-To: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
Message-ID: <20160603202736.Horde.1AeXywTJP3wJwDQeaVCBZSR@mail.sapo.pt>

Hello,

Sorry, forget my first answer, I misunderstood what you wanted.
Let's try again.

First of all you have a typo in your second sample2, you wrote 'sample  
2' with a space.
Now try this.

fun2 <- function(n){
?? ?merge(lst[[n]], lst[[n + 1]])
}

N <- which(seq_along(lst) %% 2 == 1)
lst2 <- lapply(N, fun2)

result <- do.call(rbind, lst2)
result

Hope this helps,

Rui Barradas

?

Citando Ed Siefker <ebs15242 at gmail.com>:

> I have a list of data as follows.
>> list(data.frame(name="sample1", red=20), data.frame(name="sample1",  
>> green=15), data.frame(name="sample2", red=10),  
>> data.frame(name="sample 2", green=30))
>
> [[1]]
> ? ? name red
> 1 sample1? 20
>
> [[2]]
> ? ? name green
> 1 sample1? ? 15
>
> [[3]]
> ? ? name red
> 1 sample2? 10
>
> [[4]]
> ? ? name green
> 1 sample2? ? 30
>
> I would like to massage this into a data frame like this:
>
> ? ? name red green
> 1 sample1? 20? ? 15
> 2 sample2? 10? ? 30
>
> I'm imagining I can use aggregate(mylist, by=samplenames, merge)
> right?? But how do I get the list of samplenames?? How do I subset
> each dataframe inside the list?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From ebs15242 at gmail.com  Fri Jun  3 22:02:13 2016
From: ebs15242 at gmail.com (Ed Siefker)
Date: Fri, 3 Jun 2016 15:02:13 -0500
Subject: [R] merging dataframes in a list
In-Reply-To: <CAKVAULPv3KAGOAhoRvFfi0=yia+ej_kxN_4jbgD0Kaf-s=LncA@mail.gmail.com>
References: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
	<CALRb-ofkvjKEJL6NdnANoKfiQ9GG49AtDho_f89mkL3UNXJssA@mail.gmail.com>
	<CALRb-oeqGJ7D=-X_8-pBe3Dkxt6ubiRGJQtqf5qLy6N_hRWp+A@mail.gmail.com>
	<CAKVAULPv3KAGOAhoRvFfi0=yia+ej_kxN_4jbgD0Kaf-s=LncA@mail.gmail.com>
Message-ID: <CALRb-of-XOhe7q8ks0dsyFXeALkuZ_dAcZsfwSaSBUiWTRrAEQ@mail.gmail.com>

Thanks, ldply got me a data frame straight away.  But it filled empty
spaces with NA and merge no longer works.

> ldply(mylist)
     name red green
1 sample1  20    NA
2 sample1  NA    15
3 sample2  10    NA
4 sample2  NA    30
> mydf <- ldply(mylist)
> merge(mydf[1,],mydf[2,])
[1] name  red   green
<0 rows> (or 0-length row.names)
> merge(mydf[1,],mydf[2,], by=1)
     name red.x green.x red.y green.y
1 sample1    20      NA    NA      15


How do I merge dataframes with NA?

On Fri, Jun 3, 2016 at 2:17 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> You can use ldply in the plyr package to bind all the data.frames together
> (a regular loop will also work). Afterwards you can summarise using ddply
>
> Hope this helps
> Ulrik
>
>
> Ed Siefker <ebs15242 at gmail.com> schrieb am Fr., 3. Juni 2016 21:10:
>>
>> aggregate isn't really what I want.  Maybe tapply?  I still can't get
>> it to work.
>>
>> > length(mylist)
>> [1] 4
>> > length(names)
>> [1] 4
>> > tapply(mylist, names, merge)
>> Error in tapply(mylist, names, merge) : arguments must have same length
>>
>> I guess because a list isn't an atomic data type.  What function will
>> do the same on lists?  lapply doesn't have a 'by' argument.
>>
>> On Fri, Jun 3, 2016 at 1:41 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
>> > I manually constructed the list of sample names and tried the
>> > aggregate call I mentioned.
>> > Merge works when called manually, but not when using aggregate.
>> >
>> >> mylist <- list(data.frame(name="sample1", red=20),
>> >> data.frame(name="sample1", green=15), data.frame(name="sample2", red=10),
>> >> data.frame(na me="sample2", green=30))
>> >>  names <- list("sample1", "sample1", "sample2", "sample2")
>> >> merge(mylist[1], mylist[2])
>> >      name red green
>> > 1 sample1  20    15
>> >> merge(mylist[3], mylist[4])
>> >      name red green
>> > 1 sample2  10    30
>> >> aggregate(mylist, by=as.list(names), merge)
>> > Error in as.data.frame(y) : argument "y" is missing, with no default
>> >
>> > What's the right way to do this?
>> >
>> > On Fri, Jun 3, 2016 at 1:20 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
>> >> I have a list of data as follows.
>> >>
>> >>> list(data.frame(name="sample1", red=20), data.frame(name="sample1",
>> >>> green=15), data.frame(name="sample2", red=10), data.frame(name="sample 2",
>> >>> green=30))
>> >> [[1]]
>> >>      name red
>> >> 1 sample1  20
>> >>
>> >> [[2]]
>> >>      name green
>> >> 1 sample1    15
>> >>
>> >> [[3]]
>> >>      name red
>> >> 1 sample2  10
>> >>
>> >> [[4]]
>> >>      name green
>> >> 1 sample2    30
>> >>
>> >>
>> >> I would like to massage this into a data frame like this:
>> >>
>> >>      name red green
>> >> 1 sample1  20    15
>> >> 2 sample2  10    30
>> >>
>> >>
>> >> I'm imagining I can use aggregate(mylist, by=samplenames, merge)
>> >> right?  But how do I get the list of samplenames?  How do I subset
>> >> each dataframe inside the list?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Jun  4 00:12:23 2016
From: sewashm at gmail.com (Ashta)
Date: Fri, 3 Jun 2016 17:12:23 -0500
Subject: [R] not common records
In-Reply-To: <F9766309-4665-4734-A0A6-33E5617F4D29@dcn.davis.ca.us>
References: <CADDFq33FvkiAq6pkznex3vyCoM_Dkw6FURyhU-J_O9pXNboDLQ@mail.gmail.com>
	<F9766309-4665-4734-A0A6-33E5617F4D29@dcn.davis.ca.us>
Message-ID: <CADDFq33KH77aE2Lwa11xPtDLmJUsJmkCpxuNq9E1iKHnmAc9yw@mail.gmail.com>

Thank you Jeff. Solved.

On Fri, Jun 3, 2016 at 12:47 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> ?merge
>
> Pay attention to the all-whatever parameters.
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 2, 2016 7:04:47 PM PDT, Ashta <sewashm at gmail.com> wrote:
>>
>> I have 2 data sets.  File1 and File2. Some records are common to both
>> data sets. For those common records I want get the difference between
>> d_x1z1= z1-x1   and d_x2z2= z2-x2.
>>
>> File1<- data.frame(var = c(561,752,800,900),  x1= c(23,35,40,15), x2=
>> c(125,284,280,347))
>> File2<- data.frame(var = c(561,752,800,1001), z1= c(43,45,40,65), z2=
>> c(185,299,280,310))
>>
>> Record  900      15    347   appears only in File1
>> Record   1001    65    310  appears only in File2
>>
>> File3 should look like as follows
>>
>> File3
>> var      x1     x2     z1    z2    d_x1z1   d_x2z2
>> 561      23    125  43    165     20         40
>> 752      35    284  45    299      8          15
>> 800      40    280  40    280      0           0
>> 900      15    347  NA   NA      NA       NA
>> 1001     NA  NA   65    310     NA      NA
>>
>> How do I get those record not common in both data sets ?
>> merge(
>> File1,File2) gave me only for common "var"
>>
>> ________________________________
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From michael.weber.1 at uni-jena.de  Fri Jun  3 20:19:55 2016
From: michael.weber.1 at uni-jena.de (Michael Weber)
Date: Fri, 03 Jun 2016 20:19:55 +0200
Subject: [R] Plot half filled circle utf pch
Message-ID: <322520b7392d981993605b4a74d8c6aa2c5e73853229415581@webmail.uni-jena.de>


Dear R users,

I have been using R for several years and really appreciate all the  
developments which have been done. Maybe you can help me with the  
following problem:

I would like to plot full circles together with half circles in the  
same plot. Unfortunately, the size of the different UTF symbols is not  
equal

plot(range(1,2),type="n")
points(rep(1,2),rep(1,2),pch=c("\u25CB","\u25D3"),col=c("black","blue"))

I could change the cex value for each pch but I am looking for a more  
elegant solution.

Thanks for your help,
Michael


From drjimlemon at gmail.com  Sat Jun  4 06:45:10 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 4 Jun 2016 14:45:10 +1000
Subject: [R] Plot half filled circle utf pch
In-Reply-To: <322520b7392d981993605b4a74d8c6aa2c5e73853229415581@webmail.uni-jena.de>
References: <322520b7392d981993605b4a74d8c6aa2c5e73853229415581@webmail.uni-jena.de>
Message-ID: <CA+8X3fUsyiFtMCs++LPUfb69mSuSW0o0LYFYY2CmjVkSvz7XwA@mail.gmail.com>

Hi Michael,
Have a look at my.symbols in the TeachingDemos package.

Jim


On Sat, Jun 4, 2016 at 4:19 AM, Michael Weber
<michael.weber.1 at uni-jena.de> wrote:
>
> Dear R users,
>
> I have been using R for several years and really appreciate all the
> developments which have been done. Maybe you can help me with the following
> problem:
>
> I would like to plot full circles together with half circles in the same
> plot. Unfortunately, the size of the different UTF symbols is not equal
>
> plot(range(1,2),type="n")
> points(rep(1,2),rep(1,2),pch=c("\u25CB","\u25D3"),col=c("black","blue"))
>
> I could change the cex value for each pch but I am looking for a more
> elegant solution.
>
> Thanks for your help,
> Michael
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Sat Jun  4 09:09:12 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sat, 4 Jun 2016 12:39:12 +0530
Subject: [R] Error from Rcmdr when trying to make a density plot
Message-ID: <CAC8=1eqHAyJGZJAAKwipmJ86wcMa3f-9EX=f83d=9yO6JqkRdQ@mail.gmail.com>

Dear all,

I am new to using Rcmdr. From the menu I chose the following : -

data(Anscombe, package="car")

densityPlot( ~ income, data=Anscombe, bw="SJ", adjust=1, kernel="gaussian")


This gave me the following error:-

[1] NOTE: R Commander Version 2.2-0: Sat Jun 4 12:32:09 2016
[2] NOTE:
Rcmdr Version 2.2-0
[3] NOTE: The dataset Anscombe has 51 rows and 4 columns.
[4] ERROR:
could not find function "model.frame"


My session details are :-

> sessionInfo()
R version 3.3.0 (2016-05-03)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 15.10

locale:
 [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
 [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
 [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN LC_IDENTIFICATION=C

attached base packages:
[1] splines   utils     grDevices base

other attached packages:
[1] Rcmdr_2.2-0     RcmdrMisc_1.0-3 sandwich_2.3-3  car_2.0-26

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.0         tcltk2_1.2-11       nloptr_1.0.4
 [4] RColorBrewer_1.1-2  plyr_1.8.3          tools_3.3.0
 [7] methods_3.3.0       class_7.3-13        rpart_4.1-10
[10] digest_0.6.8        lme4_1.1-8          gtable_0.1.2
[13] nlme_3.1-122        lattice_0.20-33     mgcv_1.8-7
[16] Matrix_1.2-2        parallel_3.3.0      SparseM_1.7
[19] proto_0.3-10        gridExtra_2.0.0     e1071_1.6-7
[22] stringr_0.6.2       cluster_2.0.3       graphics_3.3.0
[25] stats_3.3.0         grid_3.3.0          nnet_7.3-10
[28] tcltk_3.3.0         readxl_0.1.0        survival_2.38-3
[31] foreign_0.8-66      latticeExtra_0.6-26 minqa_1.2.4
[34] Formula_1.2-1       ggplot2_1.0.1       reshape2_1.4
[37] Hmisc_3.16-0        scales_0.2.5        MASS_7.3-43
[40] abind_1.4-3         pbkrtest_0.4-2      colorspace_1.2-4
[43] quantreg_5.11       acepack_1.3-3.3     munsell_0.4.2
[46] zoo_1.7-12
>
Many thanks,
Ashim

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Jun  4 11:20:47 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 4 Jun 2016 11:20:47 +0200
Subject: [R] Error from Rcmdr when trying to make a density plot
In-Reply-To: <CAC8=1eqHAyJGZJAAKwipmJ86wcMa3f-9EX=f83d=9yO6JqkRdQ@mail.gmail.com>
References: <CAC8=1eqHAyJGZJAAKwipmJ86wcMa3f-9EX=f83d=9yO6JqkRdQ@mail.gmail.com>
Message-ID: <E43CEC83-55A6-4DCF-807C-C8AEBCBCB45B@gmail.com>


> On 04 Jun 2016, at 09:09 , Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> 
[...]

> [4] ERROR:
> could not find function "model.frame"
> 
> 
> My session details are :-
> 
>> sessionInfo()
> [...]
> attached base packages:
> [1] splines   utils     grDevices base

Looks like you somehow managed to detach (or not attach) the stats package. Don't...

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ashimkapoor at gmail.com  Sat Jun  4 11:32:57 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sat, 4 Jun 2016 15:02:57 +0530
Subject: [R] Error from Rcmdr when trying to make a density plot
In-Reply-To: <E43CEC83-55A6-4DCF-807C-C8AEBCBCB45B@gmail.com>
References: <CAC8=1eqHAyJGZJAAKwipmJ86wcMa3f-9EX=f83d=9yO6JqkRdQ@mail.gmail.com>
	<E43CEC83-55A6-4DCF-807C-C8AEBCBCB45B@gmail.com>
Message-ID: <CAC8=1erYxNTdSHMGd=LLnf7AY5e_kYN-Nn7cn9KPyuA=9eUJLw@mail.gmail.com>

Dear Peter,

Many thanks.

Now when i do :-

library(stats)
data(Anscombe, package="car")
densityPlot( ~ income, data=Anscombe, bw="SJ", adjust=1, kernel="gaussian")


I get the output of rug on the x axis but not kernel density graph.
Also I get :-
[1] NOTE: R Commander Version 2.2-0: Sat Jun 4 14:58:57 2016
[2] NOTE:
Rcmdr Version 2.2-0
[3] NOTE: The dataset Anscombe has 51 rows and 4 columns.
[4] ERROR:
could not find function "grid"

Best Regards,
Ashim

On Sat, Jun 4, 2016 at 2:50 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 04 Jun 2016, at 09:09 , Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> [...]
>
> > [4] ERROR:
> > could not find function "model.frame"
> >
> >
> > My session details are :-
> >
> >> sessionInfo()
> > [...]
> > attached base packages:
> > [1] splines   utils     grDevices base
>
> Looks like you somehow managed to detach (or not attach) the stats
> package. Don't...
>
> -pd
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Sat Jun  4 13:28:22 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Sat, 04 Jun 2016 11:28:22 +0000
Subject: [R] Johannes Hengelbrock <j.hengelbrock@uke.de>
Message-ID: <519743$38ql95@ironport10.mayo.edu>

I'm traveling so chasing this down more fully will wait until I get home.   Four points.

1. This is an edge case.  You will notice that if you add "subset=1:100" to the coxph call that the function works perfectly.  You have to get up to 1000 or so before it fails.

2. The  exact partial likelihood of Cox is referred to as "exact" by coxph and as "discrete" by SAS phreg.  What phreg calls 'exact' is the exact marginal likelihood of Prentice.   I don't know which of these you were using in SAS so can't verify that "phreg works".

3. The computations and memory for the exact calculation go up phenomenally with the number of ties.   It is a sum over  n choose d terms,  if there were 10 events out of 200 at risk this is a sum over all ways to choose 10 subjects out of 200 which is approx 2e16 terms.  Your example requires all choices of 1541 out of 3000, which I would expect to take somewhere near age-of-the-universe seconds to compute.   The code uses a clever nested compuation due to Gail et al which will cut that time down to infinity/10.

4. This example drove coxph into a memory fault, I suspect.  I will certainly look into patching that once I get home.  (There is a check for this but it  must have a flaw).  My sympathy is for your plight is low, however.  I  can't conceive of the real data problem where someone would actually need to compute this awful likelihood.  1541 events tied at the same time?   Or even more to imagine a case where I would need it badly enough to wait a lifetime for the answer.  The Efron approximation is pretty darn good for cases like this, and it is fast.

Terry Therneau

---------------------------------------------------

Dear users,

I'm trying to estimate a conditional logistic model using the
coxph()-function from the survival package. Somehow, the model does not
converge if time is set to the same value for all observations:

     library(survival)
     set.seed(12345)
     n <- 3000
     a <- rbinom(n, 1, 0.5)
     b <- rbinom(n, 1, 0.5)
     coxph(formula = Surv(rep(1, 3000), a) ~ b, method = "exact")

Error in fitter(X, Y, strats, offset, init, control, weights = weights,
: NA/NaN/Inf in foreign function call (arg 5) In addition: Warning
message: In fitter(X, Y, strats, offset, init, control, weights =
weights, :Ran out of iterations and did not converge

Changing iter.max does not help, aparently. Strangely, the exact same
model converges in SAS.

I know that I could estimate the model differently (via glm), but I
would like to understand why the model does converge in SAS but not in R.

Thanks,
Johannes

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sat Jun  4 15:07:27 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 4 Jun 2016 14:07:27 +0100
Subject: [R] Request for help
In-Reply-To: <CAG1U7UuwZmjfawH_X7a2SfUDRo6-MaXFjdEXWtVpoLR+WEO6Mw@mail.gmail.com>
References: <CAG1U7UuwZmjfawH_X7a2SfUDRo6-MaXFjdEXWtVpoLR+WEO6Mw@mail.gmail.com>
Message-ID: <84ce9d33-ac39-6214-8335-b95e6334ddb5@dewey.myzen.co.uk>

Dear Suparna

You do not say whether the problem is (a) creating a help page to start 
with (b) understanding how to edit it afterwards. If the former then 
Duncan's advice to use prompt (or package.skeleton if you have not got 
anything set up yet) is good advice. If (b) then try it and post again 
with specific questions about what you cannot get to work.

It does take some learning but it really, really is worth it, trust us.

On 03/06/2016 08:22, suparna biswas wrote:
> Dear Sir/Madam
>                        Myself Suparna Biswas, a research scholar from the
> department of Mathematical Sciences, Tezpur University, Assam, India. I am
> working under the supervision of Dr. Santanu Dutta, Associate Professor,
> Department of Mathematical Sciences, Tezpur University, Assam, India. My
> research topic is "Estimation and Application of Risk Measure in Finance".
>
>                         I mainly use the R software in my research work. I
> want to convert all my code into a R package manually. I have gone through
> the paper by Friedrich Leisch titled "Creating R Packages: A Tutorial. But
> I am facing problem in writing help pages. The things mentioned in the
> paper about help pages are not clear to me as I have never written help
> pages before.
>
>                         I will be obliged if you kindly help me in this
> context. Thanking you.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jfox at mcmaster.ca  Sat Jun  4 15:11:53 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 4 Jun 2016 13:11:53 +0000
Subject: [R] Error from Rcmdr when trying to make a density plot
In-Reply-To: <CAC8=1erYxNTdSHMGd=LLnf7AY5e_kYN-Nn7cn9KPyuA=9eUJLw@mail.gmail.com>
References: <CAC8=1eqHAyJGZJAAKwipmJ86wcMa3f-9EX=f83d=9yO6JqkRdQ@mail.gmail.com>
	<E43CEC83-55A6-4DCF-807C-C8AEBCBCB45B@gmail.com>
	<CAC8=1erYxNTdSHMGd=LLnf7AY5e_kYN-Nn7cn9KPyuA=9eUJLw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810FA7A79@FHSDB2D11-2.csu.mcmaster.ca>

Dear Ashim,

The grid() function is in the base R graphics package and should be attached to the search path (along with stats and some other standard packages).  Close your R session and try again.

 If the problem persists, make sure that you don't have a saved workspace that's being loaded every time R starts. If so, you'll see a message to this effect when R start up, and you should delete the file, named .RData, with the saved workspace. To find out where this file resides, type the command getwd() at the R > prompt. Then close R and try again.

If you still have this problem, reinstall R and the Rcmdr package.

I'm afraid that I'm unavailable for the rest of the day and so if you have a follow-up question, I won't be able to answer it in a timely manner.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> Kapoor
> Sent: June 4, 2016 5:33 AM
> To: peter dalgaard <pdalgd at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Error from Rcmdr when trying to make a density plot
> 
> Dear Peter,
> 
> Many thanks.
> 
> Now when i do :-
> 
> library(stats)
> data(Anscombe, package="car")
> densityPlot( ~ income, data=Anscombe, bw="SJ", adjust=1, kernel="gaussian")
> 
> 
> I get the output of rug on the x axis but not kernel density graph.
> Also I get :-
> [1] NOTE: R Commander Version 2.2-0: Sat Jun 4 14:58:57 2016 [2] NOTE:
> Rcmdr Version 2.2-0
> [3] NOTE: The dataset Anscombe has 51 rows and 4 columns.
> [4] ERROR:
> could not find function "grid"
> 
> Best Regards,
> Ashim
> 
> On Sat, Jun 4, 2016 at 2:50 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> >
> > > On 04 Jun 2016, at 09:09 , Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> > >
> > [...]
> >
> > > [4] ERROR:
> > > could not find function "model.frame"
> > >
> > >
> > > My session details are :-
> > >
> > >> sessionInfo()
> > > [...]
> > > attached base packages:
> > > [1] splines   utils     grDevices base
> >
> > Looks like you somehow managed to detach (or not attach) the stats
> > package. Don't...
> >
> > -pd
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School Solbjerg Plads 3,
> > 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Sat Jun  4 15:48:40 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sat, 4 Jun 2016 19:18:40 +0530
Subject: [R] Error from Rcmdr when trying to make a density plot
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810FA7A79@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAC8=1eqHAyJGZJAAKwipmJ86wcMa3f-9EX=f83d=9yO6JqkRdQ@mail.gmail.com>
	<E43CEC83-55A6-4DCF-807C-C8AEBCBCB45B@gmail.com>
	<CAC8=1erYxNTdSHMGd=LLnf7AY5e_kYN-Nn7cn9KPyuA=9eUJLw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810FA7A79@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAC8=1eoROXmU5vdKVsH8zy6K7n0rFhRhsjSicYuLE8W1px6YiQ@mail.gmail.com>

Dear Sir,

When I start R and type in library("Rcmdr") I do not face this problem.
Only when I click on Rcmdr from Ubuntu interface I get the above mentioned
error.

I tried to find the .RData file but I could not find it in the path
returned by getwd().

For the time being I am content with typing R and then starting Rcmdr ( at
least then I can explore Rcmdr's toolbox).

Many thanks,
Ashim

On Sat, Jun 4, 2016 at 6:41 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Ashim,
>
> The grid() function is in the base R graphics package and should be
> attached to the search path (along with stats and some other standard
> packages).  Close your R session and try again.
>
>  If the problem persists, make sure that you don't have a saved workspace
> that's being loaded every time R starts. If so, you'll see a message to
> this effect when R start up, and you should delete the file, named .RData,
> with the saved workspace. To find out where this file resides, type the
> command getwd() at the R > prompt. Then close R and try again.
>
> If you still have this problem, reinstall R and the Rcmdr package.
>
> I'm afraid that I'm unavailable for the rest of the day and so if you have
> a follow-up question, I won't be able to answer it in a timely manner.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> > Kapoor
> > Sent: June 4, 2016 5:33 AM
> > To: peter dalgaard <pdalgd at gmail.com>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Error from Rcmdr when trying to make a density plot
> >
> > Dear Peter,
> >
> > Many thanks.
> >
> > Now when i do :-
> >
> > library(stats)
> > data(Anscombe, package="car")
> > densityPlot( ~ income, data=Anscombe, bw="SJ", adjust=1,
> kernel="gaussian")
> >
> >
> > I get the output of rug on the x axis but not kernel density graph.
> > Also I get :-
> > [1] NOTE: R Commander Version 2.2-0: Sat Jun 4 14:58:57 2016 [2] NOTE:
> > Rcmdr Version 2.2-0
> > [3] NOTE: The dataset Anscombe has 51 rows and 4 columns.
> > [4] ERROR:
> > could not find function "grid"
> >
> > Best Regards,
> > Ashim
> >
> > On Sat, Jun 4, 2016 at 2:50 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> >
> > >
> > > > On 04 Jun 2016, at 09:09 , Ashim Kapoor <ashimkapoor at gmail.com>
> > wrote:
> > > >
> > > [...]
> > >
> > > > [4] ERROR:
> > > > could not find function "model.frame"
> > > >
> > > >
> > > > My session details are :-
> > > >
> > > >> sessionInfo()
> > > > [...]
> > > > attached base packages:
> > > > [1] splines   utils     grDevices base
> > >
> > > Looks like you somehow managed to detach (or not attach) the stats
> > > package. Don't...
> > >
> > > -pd
> > >
> > > --
> > > Peter Dalgaard, Professor,
> > > Center for Statistics, Copenhagen Business School Solbjerg Plads 3,
> > > 2000 Frederiksberg, Denmark
> > > Phone: (+45)38153501
> > > Office: A 4.23
> > > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sat Jun  4 19:11:23 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 4 Jun 2016 13:11:23 -0400
Subject: [R] merging dataframes in a list
In-Reply-To: <CALRb-of-XOhe7q8ks0dsyFXeALkuZ_dAcZsfwSaSBUiWTRrAEQ@mail.gmail.com>
References: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
	<CALRb-ofkvjKEJL6NdnANoKfiQ9GG49AtDho_f89mkL3UNXJssA@mail.gmail.com>
	<CALRb-oeqGJ7D=-X_8-pBe3Dkxt6ubiRGJQtqf5qLy6N_hRWp+A@mail.gmail.com>
	<CAKVAULPv3KAGOAhoRvFfi0=yia+ej_kxN_4jbgD0Kaf-s=LncA@mail.gmail.com>
	<CALRb-of-XOhe7q8ks0dsyFXeALkuZ_dAcZsfwSaSBUiWTRrAEQ@mail.gmail.com>
Message-ID: <CAAxdm-4FceruPPy9+Eyhx33+UpDEmqVy-kNo-2cX1gJzutFMuw@mail.gmail.com>

Here is how you can to it with tidyr:

> x <-  list(data.frame(name="sample1", red=20)
+     , data.frame(name="sample1", green=15)
+     , data.frame(name="sample2", red=10)
+     , data.frame(name="sample2", green=30)
+     )
> library(dplyr)
> library(tidyr)
>
> # convert to 'name, type, value'; assumes dataframe with 2 variables
> x.conv <- lapply(x, function(df){
+     data.frame(name = as.character(df$name)
+         , type = names(df)[2L]  # use 'red'/'green' as indicators
+         , value = df[[2]]
+         , stringsAsFactors = FALSE
+         )
+     })
> print(x.conv)
[[1]]
     name type value
1 sample1  red    20
[[2]]
     name  type value
1 sample1 green    15
[[3]]
     name type value
1 sample2  red    10
[[4]]
     name  type value
1 sample2 green    30
>
> x.conv <- bind_rows(x.conv)  # create single dataframe
> print(x.conv)
Source: local data frame [4 x 3]
     name  type value
    (chr) (chr) (dbl)
1 sample1   red    20
2 sample1 green    15
3 sample2   red    10
4 sample2 green    30
>
> # create output
> spread(x.conv, type, value)  # uses tidyr 'spread'
Source: local data frame [2 x 3]
     name green   red
    (chr) (dbl) (dbl)
1 sample1    15    20
2 sample2    30    10
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Jun 3, 2016 at 4:02 PM, Ed Siefker <ebs15242 at gmail.com> wrote:

> Thanks, ldply got me a data frame straight away.  But it filled empty
> spaces with NA and merge no longer works.
>
> > ldply(mylist)
>      name red green
> 1 sample1  20    NA
> 2 sample1  NA    15
> 3 sample2  10    NA
> 4 sample2  NA    30
> > mydf <- ldply(mylist)
> > merge(mydf[1,],mydf[2,])
> [1] name  red   green
> <0 rows> (or 0-length row.names)
> > merge(mydf[1,],mydf[2,], by=1)
>      name red.x green.x red.y green.y
> 1 sample1    20      NA    NA      15
>
>
> How do I merge dataframes with NA?
>
> On Fri, Jun 3, 2016 at 2:17 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
> > You can use ldply in the plyr package to bind all the data.frames
> together
> > (a regular loop will also work). Afterwards you can summarise using ddply
> >
> > Hope this helps
> > Ulrik
> >
> >
> > Ed Siefker <ebs15242 at gmail.com> schrieb am Fr., 3. Juni 2016 21:10:
> >>
> >> aggregate isn't really what I want.  Maybe tapply?  I still can't get
> >> it to work.
> >>
> >> > length(mylist)
> >> [1] 4
> >> > length(names)
> >> [1] 4
> >> > tapply(mylist, names, merge)
> >> Error in tapply(mylist, names, merge) : arguments must have same length
> >>
> >> I guess because a list isn't an atomic data type.  What function will
> >> do the same on lists?  lapply doesn't have a 'by' argument.
> >>
> >> On Fri, Jun 3, 2016 at 1:41 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> >> > I manually constructed the list of sample names and tried the
> >> > aggregate call I mentioned.
> >> > Merge works when called manually, but not when using aggregate.
> >> >
> >> >> mylist <- list(data.frame(name="sample1", red=20),
> >> >> data.frame(name="sample1", green=15), data.frame(name="sample2",
> red=10),
> >> >> data.frame(na me="sample2", green=30))
> >> >>  names <- list("sample1", "sample1", "sample2", "sample2")
> >> >> merge(mylist[1], mylist[2])
> >> >      name red green
> >> > 1 sample1  20    15
> >> >> merge(mylist[3], mylist[4])
> >> >      name red green
> >> > 1 sample2  10    30
> >> >> aggregate(mylist, by=as.list(names), merge)
> >> > Error in as.data.frame(y) : argument "y" is missing, with no default
> >> >
> >> > What's the right way to do this?
> >> >
> >> > On Fri, Jun 3, 2016 at 1:20 PM, Ed Siefker <ebs15242 at gmail.com>
> wrote:
> >> >> I have a list of data as follows.
> >> >>
> >> >>> list(data.frame(name="sample1", red=20), data.frame(name="sample1",
> >> >>> green=15), data.frame(name="sample2", red=10),
> data.frame(name="sample 2",
> >> >>> green=30))
> >> >> [[1]]
> >> >>      name red
> >> >> 1 sample1  20
> >> >>
> >> >> [[2]]
> >> >>      name green
> >> >> 1 sample1    15
> >> >>
> >> >> [[3]]
> >> >>      name red
> >> >> 1 sample2  10
> >> >>
> >> >> [[4]]
> >> >>      name green
> >> >> 1 sample2    30
> >> >>
> >> >>
> >> >> I would like to massage this into a data frame like this:
> >> >>
> >> >>      name red green
> >> >> 1 sample1  20    15
> >> >> 2 sample2  10    30
> >> >>
> >> >>
> >> >> I'm imagining I can use aggregate(mylist, by=samplenames, merge)
> >> >> right?  But how do I get the list of samplenames?  How do I subset
> >> >> each dataframe inside the list?
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sat Jun  4 19:28:52 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sat, 4 Jun 2016 22:58:52 +0530
Subject: [R] String match
Message-ID: <CA+dpOJnWk+rgwneHW1+w_k223Vza9vzUs43VwOkpHTKsH-UMiw@mail.gmail.com>

Hi again,

I am facing trouble to match a vector strings. Let say I have below
full string vector

WhereToLook = c("ultracemco.bo.openam"   ,  "ultracemco.bo.higham"
,"ultracemco.bo.lowam"   ,   "ultracemco.bo.closeam"   ,
"ultracemco.bo.volumeam"   ,"ultracemco.bo.adjustedam")

WhatToLook = c("volume", "close")

Basically I need to find the positions of WhatToLook in WhereToLook.
So my code goes as below :

> pmatch(tolower(colnames(WhereToLook)), WhatToLook)
integer(0)


Although I was expecting my code would point 5 & 4 respectively.

Appreciate if someone points as correct code for above case.

Thanks,


From sharma23shonam at gmail.com  Sat Jun  4 10:07:54 2016
From: sharma23shonam at gmail.com (shonam sharma)
Date: Sat, 4 Jun 2016 13:37:54 +0530
Subject: [R]  what is the code for trend free prewhitening trend analysis
Message-ID: <CAE3Sv1DvGOQWywmOjnnO1koRgFhxBMJ0Dn0O=7ajeoq_fJE+OA@mail.gmail.com>

Dear all,

I am new to R studio. I have installed zyp package in R
I want to run trend free prewhitening trend analysis

Kindly tell me the code for the same




-- 
with  regards

Shonam sharma
JRF at Indian school of mines
Dhanbad-826004
Email : sharma23shonam at gmail.com

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From gmoyeyemi at gmail.com  Sat Jun  4 18:01:41 2016
From: gmoyeyemi at gmail.com (Gafar Matanmi Oyeyemi)
Date: Sat, 4 Jun 2016 17:01:41 +0100
Subject: [R] which function
Message-ID: <CAFcbP-DjS=jtyjF4zijo4qadQRV0=_hyDcGwdho8BL9k3K68+A@mail.gmail.com>

Dear,
I need help on which.min and  which.max. functions. Is there a function to
fetch me the point that in vector that gives median value such like the
commands for minimum and maximum values.
Thanks.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Jun  4 19:46:03 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 04 Jun 2016 10:46:03 -0700
Subject: [R] which function
In-Reply-To: <CAFcbP-DjS=jtyjF4zijo4qadQRV0=_hyDcGwdho8BL9k3K68+A@mail.gmail.com>
References: <CAFcbP-DjS=jtyjF4zijo4qadQRV0=_hyDcGwdho8BL9k3K68+A@mail.gmail.com>
Message-ID: <76736244-DB80-4975-BBBB-DF32DF8BC5F3@dcn.davis.ca.us>

The median is not always a member of the data set. What do you really want? 

I for one would want people to follow the guidance in the footer on every email on this mailing list. 
-- 
Sent from my phone. Please excuse my brevity.

On June 4, 2016 9:01:41 AM PDT, Gafar Matanmi Oyeyemi <gmoyeyemi at gmail.com> wrote:
>Dear,
>I need help on which.min and  which.max. functions. Is there a function
>to
>fetch me the point that in vector that gives median value such like the
>commands for minimum and maximum values.
>Thanks.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sat Jun  4 20:20:01 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 4 Jun 2016 14:20:01 -0400
Subject: [R] String match
In-Reply-To: <CA+dpOJnWk+rgwneHW1+w_k223Vza9vzUs43VwOkpHTKsH-UMiw@mail.gmail.com>
References: <CA+dpOJnWk+rgwneHW1+w_k223Vza9vzUs43VwOkpHTKsH-UMiw@mail.gmail.com>
Message-ID: <CAAxdm-4+mELTHkdzpCBc7hBQQcn8SDK9+5G013hgh5r0qYcB5A@mail.gmail.com>

try this:

> WhereToLook = c("ultracemco.bo.openam"   ,  "ultracemco.bo.higham"
+  ,"ultracemco.bo.lowam"   ,   "ultracemco.bo.closeam"   ,
+  "ultracemco.bo.volumeam"   ,"ultracemco.bo.adjustedam")
>
>  WhatToLook = c("volume", "close")
>
> # create pattern match
> pat <- paste(WhatToLook, collapse = "|")
> grep(pat, WhereToLook)
[1] 4 5




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Jun 4, 2016 at 1:28 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi again,
>
> I am facing trouble to match a vector strings. Let say I have below
> full string vector
>
> WhereToLook = c("ultracemco.bo.openam"   ,  "ultracemco.bo.higham"
> ,"ultracemco.bo.lowam"   ,   "ultracemco.bo.closeam"   ,
> "ultracemco.bo.volumeam"   ,"ultracemco.bo.adjustedam")
>
> WhatToLook = c("volume", "close")
>
> Basically I need to find the positions of WhatToLook in WhereToLook.
> So my code goes as below :
>
> > pmatch(tolower(colnames(WhereToLook)), WhatToLook)
> integer(0)
>
>
> Although I was expecting my code would point 5 & 4 respectively.
>
> Appreciate if someone points as correct code for above case.
>
> Thanks,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Sat Jun  4 20:44:50 2016
From: santosh2005 at gmail.com (Santosh)
Date: Sat, 4 Jun 2016 11:44:50 -0700
Subject: [R] Application of "merge" and "within"
In-Reply-To: <7252E1E4-94D9-42FE-8F2A-267E340A375B@gmail.com>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
	<f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
	<7252E1E4-94D9-42FE-8F2A-267E340A375B@gmail.com>
Message-ID: <CAN_e6Xu5X_J2o6z+t4g1OGQJ5nsSNdQVoG7nhqgQ6OUUUp50mQ@mail.gmail.com>

Thanks so much.. I will try that.. and keep you posted..

on a different note.. using the above examples.. after adding a new column
is blank.. summarizing a null column causes errors.. (like min(NULL) or
min(NA) etc.. to avoid that I was trying the following code..

within(q, as.data.frame(as.matrix(apply($DATA,2,function(x)
{require(gtools);x1 <- ifelse(invalid(x),0,x);return(x1)}))))

For some reason, the above code is not working.. any ideas on converting
NAs/blanks to 0 using apply in within? or any other similar method?

Thanks so much.. I appreciate your help!!

Regards,
Santosh


On Wed, Jun 1, 2016 at 1:45 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> Notice that within-group processing is intended. I'd try
>
> > first <- function(x)x[1]
> > s  <- within(q, {bl <- ave(b, paste(G,a), FUN=first); db <- b - bl})
>
> Or perhaps
>
> q <- within(q, Ga <- paste(G,a))
> tbl <- with(q, tapply(b, Ga, first))
> s <- within(q, {bl <- tbl[Ga]; db <- b - bl})
>
> -pd
>
>
> On 28 May 2016, at 22:53 , Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 27/05/2016 7:00 PM, Santosh wrote:
> >> Dear Rxperts!
> >>
> >> Is there a way to compute relative values.. using within().. function?
> >>
> >> Any assistance/suggestions are highly welcome!!
> >> Thanks again,
> >> Santosh...
> >> ___________________________________________________________________
> >> A sample dataset and the computation "outside" within()  function is
> shown..
> >>
> >> q <- data.frame(GL = rep(paste("G",1:3,sep = ""),each = 50),
> >>                G  = rep(1:3,each = 50),
> >>                D = rep(paste("D",1:5,sep = ""),each = 30),
> >>                a = rep(1:15,each = 10),
> >>                t = rep(seq(10),15),
> >>                b = round(runif(150,10,20)))
> >> r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
> >> names(r)[3] <- "bl"
> >> s <- merge(q,r)
> >> s$db <- s$b-s$bl
> >>
> >>> head(s,5)
> >>    G  a GL  D  t  b bl db
> >> 1   1  1 G1 D1  1 13 13  0
> >> 2   1  1 G1 D1  2 16 13  3
> >> 3   1  1 G1 D1  3 19 13  6
> >> 4   1  1 G1 D1  4 12 13 -1
> >> 5   1  1 G1 D1  5 19 13  6
> >
> > Just use
> >
> > s <- within(s, db <- b - bl)
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>

	[[alternative HTML version deleted]]


From jcpayne at uw.edu  Sat Jun  4 20:59:16 2016
From: jcpayne at uw.edu (J Payne)
Date: Sat, 04 Jun 2016 11:59:16 -0700
Subject: [R] system() command not working
Message-ID: <CB883FB0-102A-49FC-80FD-A350DE708B55@uw.edu>

I?ve posted this question on StackExchange at http://stackoverflow.com/questions/37604466/r-system-not-working-with-modis-reprojection-tool, but haven?t received any replies. ?I?m hoping that someone who understands the operation of the R system() command can help.? 

 

I have a command that works when typed into the Terminal on a Mac (OSX El Cap), but exactly the same command fails when called from R using `system()`. 

?

I am trying to batch-process MODIS satellite files using a small program called the MODIS Reprojection Tool (https://lpdaac.usgs.gov/tools/modis_reprojection_tool).? My software is all up to date.

 

This is a simple example in which I mosaic two files.? The names of the two files are in a text input file called `input.list`.? The command just tells the `mrtmosaic` routine where to find the input list and where to put the output. 

 

This command works correctly in the Terminal:? 

 

??? /Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf

 

However, if I put exactly the same string into a variable and run it from R (using RStudio), it fails:? 

 

??? comstring<-"/Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf"? 

????system(comstring)

 

>Warning: gctp_call : Environmental Variable Not Found:?? 

????MRT_DATA_DIR nor MRTDATADIR not defined

??? Error: GetInputGeoCornerMosaic : General Processing Error converting lat/long coordinates to input projection coordinates.? 

????Fatal Error, Terminating...

 

The strange thing is that the system knows what the environment variables are.? In the terminal, the command

`echo $MRT_DATA_DIR`

shows the correct directory: /Applications/Modis_Reprojection_Tool/data

 

I don't see why it would have trouble finding the variables from an `R system()` call when it has no trouble in the Terminal.? I'm very stumped!? 

 

 

 


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Jun  4 22:07:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 4 Jun 2016 13:07:43 -0700
Subject: [R] what is the code for trend free prewhitening trend analysis
In-Reply-To: <CAE3Sv1DvGOQWywmOjnnO1koRgFhxBMJ0Dn0O=7ajeoq_fJE+OA@mail.gmail.com>
References: <CAE3Sv1DvGOQWywmOjnnO1koRgFhxBMJ0Dn0O=7ajeoq_fJE+OA@mail.gmail.com>
Message-ID: <CAGxFJbQZgNqeAKNRZiWak_pncfR6XrZdYWkjOoZU5w975+6S+g@mail.gmail.com>

Please refer to the posting guide (below) to learn how to post
questions to this list.

In particular, we do not generally write your code for you.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jun 4, 2016 at 1:07 AM, shonam sharma <sharma23shonam at gmail.com> wrote:
> Dear all,
>
> I am new to R studio. I have installed zyp package in R
> I want to run trend free prewhitening trend analysis
>
> Kindly tell me the code for the same
>
>
>
>
> --
> with  regards
>
> Shonam sharma
> JRF at Indian school of mines
> Dhanbad-826004
> Email : sharma23shonam at gmail.com
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Sat Jun  4 22:12:27 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 4 Jun 2016 13:12:27 -0700
Subject: [R] system() command not working
In-Reply-To: <CB883FB0-102A-49FC-80FD-A350DE708B55@uw.edu>
References: <CB883FB0-102A-49FC-80FD-A350DE708B55@uw.edu>
Message-ID: <C79A52EE-CAF6-4546-B9B3-8459B06EF3B1@noaa.gov>

Hi John:

When El Capitan first came out there was a discussion in the  R-SIg-Mac  list about environmental variables not being passed down to applications  (not just R abut in general).  I believe a work around was suggested, but I would search the archives for that.

So what is happening, when you run from the command line, the variables   MRT_DATA_DIR and MRTDATADIR which are defined somewhere in your environment are found in the terminal, but when the same command is run from the application they are not being found.  I would search the R-SIg-Mac archive or post to that list, because i can?t remember what the work around was for it.

HTH,

-Roy

> On Jun 4, 2016, at 11:59 AM, J Payne <jcpayne at uw.edu> wrote:
> 
> I?ve posted this question on StackExchange at http://stackoverflow.com/questions/37604466/r-system-not-working-with-modis-reprojection-tool, but haven?t received any replies.  I?m hoping that someone who understands the operation of the R system() command can help.  
> 
> 
> 
> I have a command that works when typed into the Terminal on a Mac (OSX El Cap), but exactly the same command fails when called from R using `system()`. 
> 
>  
> 
> I am trying to batch-process MODIS satellite files using a small program called the MODIS Reprojection Tool (https://lpdaac.usgs.gov/tools/modis_reprojection_tool).  My software is all up to date.
> 
> 
> 
> This is a simple example in which I mosaic two files.  The names of the two files are in a text input file called `input.list`.  The command just tells the `mrtmosaic` routine where to find the input list and where to put the output. 
> 
> 
> 
> This command works correctly in the Terminal:  
> 
> 
> 
>     /Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf
> 
> 
> 
> However, if I put exactly the same string into a variable and run it from R (using RStudio), it fails:  
> 
> 
> 
>     comstring<-"/Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf"  
> 
>     system(comstring)
> 
> 
> 
>> Warning: gctp_call : Environmental Variable Not Found:   
> 
>     MRT_DATA_DIR nor MRTDATADIR not defined
> 
>     Error: GetInputGeoCornerMosaic : General Processing Error converting lat/long coordinates to input projection coordinates.  
> 
>     Fatal Error, Terminating...
> 
> 
> 
> The strange thing is that the system knows what the environment variables are.  In the terminal, the command
> 
> `echo $MRT_DATA_DIR`
> 
> shows the correct directory: /Applications/Modis_Reprojection_Tool/data
> 
> 
> 
> I don't see why it would have trouble finding the variables from an `R system()` call when it has no trouble in the Terminal.  I'm very stumped!  
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From bgunter.4567 at gmail.com  Sat Jun  4 22:15:39 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 4 Jun 2016 13:15:39 -0700
Subject: [R] String match
In-Reply-To: <CA+dpOJnWk+rgwneHW1+w_k223Vza9vzUs43VwOkpHTKsH-UMiw@mail.gmail.com>
References: <CA+dpOJnWk+rgwneHW1+w_k223Vza9vzUs43VwOkpHTKsH-UMiw@mail.gmail.com>
Message-ID: <CAGxFJbRJDnyWYUbkZ55pFekgtTzzAyfRRwU3z6Yb2REGhk8e2Q@mail.gmail.com>

Please (re)-read the Help file for pmatch, which says:

... " (A partial match occurs if the whole of the element of x matches
the beginning of the element of table.) "

This is clearly not your situation. One approach (there may be others
depending on what your detailed situation actually is) is to use
regular expressions:

?regexp   ?regexpr

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jun 4, 2016 at 10:28 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I am facing trouble to match a vector strings. Let say I have below
> full string vector
>
> WhereToLook = c("ultracemco.bo.openam"   ,  "ultracemco.bo.higham"
> ,"ultracemco.bo.lowam"   ,   "ultracemco.bo.closeam"   ,
> "ultracemco.bo.volumeam"   ,"ultracemco.bo.adjustedam")
>
> WhatToLook = c("volume", "close")
>
> Basically I need to find the positions of WhatToLook in WhereToLook.
> So my code goes as below :
>
>> pmatch(tolower(colnames(WhereToLook)), WhatToLook)
> integer(0)
>
>
> Although I was expecting my code would point 5 & 4 respectively.
>
> Appreciate if someone points as correct code for above case.
>
> Thanks,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Sat Jun  4 22:43:16 2016
From: rmh at temple.edu (RICHARD M. HEIBERGER)
Date: Sat, 4 Jun 2016 16:43:16 -0400
Subject: [R] Johannes Hengelbrock <j.hengelbrock@uke.de>
In-Reply-To: <519743$38ql95@ironport10.mayo.edu>
References: <519743$38ql95@ironport10.mayo.edu>
Message-ID: <E8C5C5FD-574B-4392-8512-D62C0B495379@temple.edu>

fortune candidate

Your example requires all choices of 1541 out of 3000, which I would expect to take somewhere near age-of-the-universe seconds to compute.   The code uses a clever nested compuation due to Gail et al which will cut that time down to infinity/10.

Sent from my iPhone

> On Jun 4, 2016, at 07:28, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:
> 
> Your example requires all choices of 1541 out of 3000, which I would expect to take somewhere near age-of-the-universe seconds to compute.   The code uses a clever nested compuation due to Gail et al which will cut that time down to infinity/10.


From drjimlemon at gmail.com  Sun Jun  5 01:57:09 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 5 Jun 2016 09:57:09 +1000
Subject: [R] which function
In-Reply-To: <CAFcbP-DjS=jtyjF4zijo4qadQRV0=_hyDcGwdho8BL9k3K68+A@mail.gmail.com>
References: <CAFcbP-DjS=jtyjF4zijo4qadQRV0=_hyDcGwdho8BL9k3K68+A@mail.gmail.com>
Message-ID: <CA+8X3fV+8uzz9OOjE7ppiY7zSWndTEASvuDZicsTeS0xatnc1g@mail.gmail.com>

Hi Gafar,
As Jeff has pointed out, the median value may not exist within the
dataset. However, this function will give you either the position of
the value that is the median, or the position of the two closest
values if none equal the median. Be aware that this function may fall
victim to the "indistinguishable difference" problem (FAQ 7.31).

which.median<-function(x) {
 xmed<-median(x)
 if(any(xmed==x)) {
  wmed<-which(xmed==x)
 } else {
  fw<-which.min(abs(xmed-x))
  rw<-1+length(x)-which.min(abs(xmed-rev(x)))
  if(fw==rw) {
   wmed<-fw
  } else {
   wmed<-c(fw,rw)
  }
 }
 return(wmed)
}

Jim


On Sun, Jun 5, 2016 at 2:01 AM, Gafar Matanmi Oyeyemi
<gmoyeyemi at gmail.com> wrote:
> Dear,
> I need help on which.min and  which.max. functions. Is there a function to
> fetch me the point that in vector that gives median value such like the
> commands for minimum and maximum values.
> Thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Sun Jun  5 12:28:46 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 5 Jun 2016 12:28:46 +0200
Subject: [R] system() command not working
In-Reply-To: <C79A52EE-CAF6-4546-B9B3-8459B06EF3B1@noaa.gov>
References: <CB883FB0-102A-49FC-80FD-A350DE708B55@uw.edu>
	<C79A52EE-CAF6-4546-B9B3-8459B06EF3B1@noaa.gov>
Message-ID: <A4D3949B-C60C-46AB-BA96-9E8A6906A46A@xs4all.nl>


> On 4 Jun 2016, at 22:12, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Hi John:
> 
> When El Capitan first came out there was a discussion in the  R-SIg-Mac  list about environmental variables not being passed down to applications  (not just R abut in general).  I believe a work around was suggested, but I would search the archives for that.
> 
> So what is happening, when you run from the command line, the variables   MRT_DATA_DIR and MRTDATADIR which are defined somewhere in your environment are found in the terminal, but when the same command is run from the application they are not being found.  I would search the R-SIg-Mac archive or post to that list, because i can?t remember what the work around was for it.
> 

I can't find the discussion on R-SIG-Mac list. But you can try this:

MRT_DATA_DIR=<whatever> open -a Rstudio

or  

MRT_DATA_DIR=<whatever> open -a R

Try it and see what happens.
It may even be possible to put something in .Rprofile  setting your environment variables.

Berend Hasselman

> HTH,
> 
> -Roy
> 
>> On Jun 4, 2016, at 11:59 AM, J Payne <jcpayne at uw.edu> wrote:
>> 
>> I?ve posted this question on StackExchange at http://stackoverflow.com/questions/37604466/r-system-not-working-with-modis-reprojection-tool, but haven?t received any replies.  I?m hoping that someone who understands the operation of the R system() command can help.  
>> 
>> 
>> 
>> I have a command that works when typed into the Terminal on a Mac (OSX El Cap), but exactly the same command fails when called from R using `system()`. 
>> 
>> 
>> 
>> I am trying to batch-process MODIS satellite files using a small program called the MODIS Reprojection Tool (https://lpdaac.usgs.gov/tools/modis_reprojection_tool).  My software is all up to date.
>> 
>> 
>> 
>> This is a simple example in which I mosaic two files.  The names of the two files are in a text input file called `input.list`.  The command just tells the `mrtmosaic` routine where to find the input list and where to put the output. 
>> 
>> 
>> 
>> This command works correctly in the Terminal:  
>> 
>> 
>> 
>>    /Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf
>> 
>> 
>> 
>> However, if I put exactly the same string into a variable and run it from R (using RStudio), it fails:  
>> 
>> 
>> 
>>    comstring<-"/Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf"  
>> 
>>    system(comstring)
>> 
>> 
>> 
>>> Warning: gctp_call : Environmental Variable Not Found:   
>> 
>>    MRT_DATA_DIR nor MRTDATADIR not defined
>> 
>>    Error: GetInputGeoCornerMosaic : General Processing Error converting lat/long coordinates to input projection coordinates.  
>> 
>>    Fatal Error, Terminating...
>> 
>> 
>> 
>> The strange thing is that the system knows what the environment variables are.  In the terminal, the command
>> 
>> `echo $MRT_DATA_DIR`
>> 
>> shows the correct directory: /Applications/Modis_Reprojection_Tool/data
>> 
>> 
>> 
>> I don't see why it would have trouble finding the variables from an `R system()` call when it has no trouble in the Terminal.  I'm very stumped!  
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From esawiek at gmail.com  Sun Jun  5 14:53:41 2016
From: esawiek at gmail.com (Ek Esawi)
Date: Sun, 5 Jun 2016 08:53:41 -0400
Subject: [R] Reading and converting time data via read.table
Message-ID: <CA+ZkTxsDR3J7=MK2Y9qBgsoandQ9YgQ8FnszBnOtz3yy5159Bw@mail.gmail.com>

Hi All--



I am relatively new to R. I am reading a csv file via read.table (MyFile).
The data types in the file are date, string, integer, and time. I was able
to read all the data and manipulated correctly except time, e.g., 12:30. I
used as.Date to convert date and string and integer were easily done. I
could not figure out how to convert the time data correctly. I tried chron
but w/o success and I read that POSIXlt and POSIXct work only for date and
time (e.g. 01/02/1999, 12:30:20). I did not try the lubridate package. Is
there a way to read time data without date attached to it like mine?



I am grateful for any help and thanks in advance?EKE



Here is an example of my data when read into R via read.table



                AA          Date         Name     T1          T2
N1

1              312171  7/1/1995       OF      13:37      1:43         123

	[[alternative HTML version deleted]]


From senranjitbd at yahoo.com  Sun Jun  5 11:23:18 2016
From: senranjitbd at yahoo.com (Ranjit Sen)
Date: Sun, 5 Jun 2016 09:23:18 +0000 (UTC)
Subject: [R] Fw: i  need to install  "Rclimdex"........Senior Scientists ,
	BARI
In-Reply-To: <1247776845.5443371.1465115059884.JavaMail.yahoo@mail.yahoo.com>
References: <1247776845.5443371.1465115059884.JavaMail.yahoo.ref@mail.yahoo.com>
	<1247776845.5443371.1465115059884.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <857231499.5534300.1465118598807.JavaMail.yahoo@mail.yahoo.com>



   
Dear Sir:
This is Dr Ranjit Sen, Senior Scientific Officer, Soil Science Division, Bangladesh Agricultural Research Institute(BARI). For my research on climatic variability and extreme events of climate of Bangladesh, I need to install the ?Rclimdex software from R in my computer.?
I would be highly grateful to you if you help me in this regard such as how to get it as well as how to install in my computer.
With thank and very best regards.

Sincerely,Dr Ranjit Sen,?Senior Scientific Officer,?Soil Science Division,?Bangladesh Agricultural Research Institute(BARI).


  
	[[alternative HTML version deleted]]


From senranjitbd at yahoo.com  Sun Jun  5 12:28:35 2016
From: senranjitbd at yahoo.com (Ranjit Sen)
Date: Sun, 5 Jun 2016 10:28:35 +0000 (UTC)
Subject: [R] Fw: i  need to install  "Rclimdex"........Senior Scientists ,
	BARI
In-Reply-To: <1247776845.5443371.1465115059884.JavaMail.yahoo@mail.yahoo.com>
References: <1247776845.5443371.1465115059884.JavaMail.yahoo.ref@mail.yahoo.com>
	<1247776845.5443371.1465115059884.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1208296895.5450968.1465122515157.JavaMail.yahoo@mail.yahoo.com>



     
----- Forwarded Message -----
 From: Ranjit Sen <senranjitbd at yahoo.com>
 To: "CRAN at R-project.org" <CRAN at R-project.org> 
 Sent: Sunday, June 5, 2016 2:24 PM
 Subject: i need to install "Rclimdex"........Senior Scientists ,BARI
   
Dear Sir:This is Dr Ranjit Sen, Senior Scientific Officer, Soil Science Division, Bangladesh Agricultural Research Institute(BARI). For my research on climatic variability and extreme events of climate of Bangladesh, I need to install the ?Rclimdex software from R in my computer.?
I would be highly grateful to you if you help me in this regard such as how to get it as well as how to install in my computer.
With thank and very best regards.

Sincerely,Dr Ranjit Sen,?Senior Scientific Officer,?Soil Science Division,?Bangladesh Agricultural Research Institute(BARI).


  
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sun Jun  5 15:25:48 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 5 Jun 2016 09:25:48 -0400
Subject: [R] Fw: i need to install "Rclimdex"........Senior Scientists ,
	BARI
In-Reply-To: <857231499.5534300.1465118598807.JavaMail.yahoo@mail.yahoo.com>
References: <1247776845.5443371.1465115059884.JavaMail.yahoo.ref@mail.yahoo.com>
	<1247776845.5443371.1465115059884.JavaMail.yahoo@mail.yahoo.com>
	<857231499.5534300.1465118598807.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAM_vjumFPGWNFmmrPCAP5M2hxQ-ODzyeknCFTyMXQzFH22=NYQ@mail.gmail.com>

The RClimDex website has instructions for obtaining and installing
this package, and for obtaining and installing R if you also need to
do that:
http://etccdi.pacificclimate.org/software.shtml

You must follow those directions, as the necessary first step is
obtaining a download password from the maintainers.

Sarah

On Sun, Jun 5, 2016 at 5:23 AM, Ranjit Sen via R-help
<r-help at r-project.org> wrote:
>
>
>
> Dear Sir:
> This is Dr Ranjit Sen, Senior Scientific Officer, Soil Science Division, Bangladesh Agricultural Research Institute(BARI). For my research on climatic variability and extreme events of climate of Bangladesh, I need to install the  Rclimdex software from R in my computer.
> I would be highly grateful to you if you help me in this regard such as how to get it as well as how to install in my computer.
> With thank and very best regards.
>
> Sincerely,Dr Ranjit Sen, Senior Scientific Officer, Soil Science Division, Bangladesh Agricultural Research Institute(BARI).
>
>


From neal at walfield.org  Sun Jun  5 15:53:50 2016
From: neal at walfield.org (Neal H. Walfield)
Date: Sun, 05 Jun 2016 15:53:50 +0200
Subject: [R] detecting if a variable has changed
Message-ID: <87fusrwxld.wl-neal@walfield.org>

Hi,

I have a huge list.  Normally it is sorted, but I want to be able to
add elements to it without having to use any special interfaces and
then sort it on demand.  My idea is to use something like weak
references combined with attributes.  Consider:

  # Initialization.
  l = as.list(1:10)
  # Note that it is sorted.
  attr(l, 'sorted') = weakref(l)

  # Modify the list.
  l = append(l, 1:3)

  # Check if the list is still sorted.  (I use identical here, but it
  # probably too heavy weight: I just need to compare the addresses.)
  if (! identical(l, attr(l, 'sorted'))) {
    l = sort(unlist(l))
    attr(l, 'sorted') = weakref(l)
  }
  # Do operation that requires sorted list.
  ...

This is obviously a toy example.  I'm not actually sorting integers
and I may use a matrix instead of a list.

I've read:

  http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
  http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html

As far as I can tell, weakrefs are only available via the C API.  Is
there a way to do what I want in R without resorting to C code?  Is
what I want to do better achieved using something other than weakrefs?

Thanks!

:) Neal


From wdunlap at tibco.com  Sun Jun  5 18:47:11 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 5 Jun 2016 09:47:11 -0700
Subject: [R] detecting if a variable has changed
In-Reply-To: <87fusrwxld.wl-neal@walfield.org>
References: <87fusrwxld.wl-neal@walfield.org>
Message-ID: <CAF8bMcb3+4PLBvETfQUWArWuAp5R8RoLNjyN+nHXv2MxeuOz0g@mail.gmail.com>

I don't know what you mean by "without having to use any special
interfaces", but "reference classes" will do what I think you want.  E.g.,
the following makes a class called 'SortedNumeric' that only sorts the
vector when you want to get its value, not when you append values.  It
stores the sorted vector so it does not get resorted each time you ask for
it.

SortedNumeric <- setRefClass("sortedNumeric",
            fields = list(
                fData = "numeric",
                fIsUnsorted = "logical"),
            methods = list(
                initialize = function(Data = numeric(), isUnsorted = TRUE) {
                    fData <<- Data
                    stopifnot(is.logical(isUnsorted),
                              length(isUnsorted)==1,
                              !is.na(isUnsorted))
                    fIsUnsorted <<- isUnsorted
                },
                getData = function() {
                    if (isUnsorted) {
                        fData <<- sort(fData)
                        fIsUnsorted <<- FALSE
                    }
                    fData
                },
                appendData = function(newEntries) {
                    fData <<- c(fData, newEntries)
                    fIsUnsorted <<- TRUE
                }
            ))

Use it as:

> x <- SortedNumeric$new()
> x$appendData(c(4,2,5))
> x$appendData(c(1,8,9))
> x
Reference class object of class "sortedNumeric"
Field "fData":
[1] 4 2 5 1 8 9
Field "fIsUnsorted":
[1] TRUE
> x$getData()
[1] 1 2 4 5 8 9
> x
Reference class object of class "sortedNumeric"
Field "fData":
[1] 1 2 4 5 8 9
Field "fIsUnsorted":
[1] FALSE


Outside of base R, I think the R6 package gives another approach to this.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org> wrote:

> Hi,
>
> I have a huge list.  Normally it is sorted, but I want to be able to
> add elements to it without having to use any special interfaces and
> then sort it on demand.  My idea is to use something like weak
> references combined with attributes.  Consider:
>
>   # Initialization.
>   l = as.list(1:10)
>   # Note that it is sorted.
>   attr(l, 'sorted') = weakref(l)
>
>   # Modify the list.
>   l = append(l, 1:3)
>
>   # Check if the list is still sorted.  (I use identical here, but it
>   # probably too heavy weight: I just need to compare the addresses.)
>   if (! identical(l, attr(l, 'sorted'))) {
>     l = sort(unlist(l))
>     attr(l, 'sorted') = weakref(l)
>   }
>   # Do operation that requires sorted list.
>   ...
>
> This is obviously a toy example.  I'm not actually sorting integers
> and I may use a matrix instead of a list.
>
> I've read:
>
>   http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>   http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>
> As far as I can tell, weakrefs are only available via the C API.  Is
> there a way to do what I want in R without resorting to C code?  Is
> what I want to do better achieved using something other than weakrefs?
>
> Thanks!
>
> :) Neal
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neal at walfield.org  Sun Jun  5 18:51:03 2016
From: neal at walfield.org (Neal H. Walfield)
Date: Sun, 05 Jun 2016 18:51:03 +0200
Subject: [R] detecting if a variable has changed
In-Reply-To: <CAF8bMcb3+4PLBvETfQUWArWuAp5R8RoLNjyN+nHXv2MxeuOz0g@mail.gmail.com>
References: <87fusrwxld.wl-neal@walfield.org>
	<CAF8bMcb3+4PLBvETfQUWArWuAp5R8RoLNjyN+nHXv2MxeuOz0g@mail.gmail.com>
Message-ID: <87eg8bwpe0.wl-neal@walfield.org>

Hi,

This looks more or less what I'm looking for!  Thanks!

:) Neal

On Sun, 05 Jun 2016 18:47:11 +0200,
William Dunlap wrote:
> 
> [1  <text/plain; UTF-8 (7bit)>]
> [2  <text/html; UTF-8 (quoted-printable)>]
> I don't know what you mean by "without having to use any special
> interfaces", but "reference classes" will do what I think you want.
> E.g., the following makes a class called 'SortedNumeric' that only
> sorts the vector when you want to get its value, not when you append
> values. It stores the sorted vector so it does not get resorted each
> time you ask for it.
> 
> SortedNumeric <- setRefClass("sortedNumeric",
> fields = list(
> fData = "numeric",
> fIsUnsorted = "logical"),
> methods = list(
> initialize = function(Data = numeric(), isUnsorted = TRUE) {
> fData <<- Data
> stopifnot(is.logical(isUnsorted),
> length(isUnsorted)==1,
> !is.na(isUnsorted))
> fIsUnsorted <<- isUnsorted
> },
> getData = function() {
> if (isUnsorted) {
> fData <<- sort(fData)
> fIsUnsorted <<- FALSE
> }
> fData
> },
> appendData = function(newEntries) {
> fData <<- c(fData, newEntries)
> fIsUnsorted <<- TRUE
> }
> ))
> 
> Use it as:
> 
>     
>     
>     > x <- SortedNumeric$new()
>     
>     
>     > x$appendData(c(4,2,5))
>     
>     
>     > x$appendData(c(1,8,9))
>     
>     
>     > x
>     
>     
>     Reference class object of class "sortedNumeric"
>     
>     
>     Field "fData":
>     
>     
>     [1] 4 2 5 1 8 9
>     
>     
>     Field "fIsUnsorted":
>     
>     
>     [1] TRUE
>     
>     
>     > x$getData()
>     
>     
>     [1] 1 2 4 5 8 9
>     
>     
>     > x
>     
>     
>     Reference class object of class "sortedNumeric"
>     
>     
>     Field "fData":
>     
>     
>     [1] 1 2 4 5 8 9
>     
>     
>     Field "fIsUnsorted":
>     
>     
>     [1] FALSE
> 
> Outside of base R, I think the R6 package gives another approach to
> this.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org>
> wrote:
> 
>     Hi,
>     
>     I have a huge list. Normally it is sorted, but I want to be able
>     to
>     add elements to it without having to use any special interfaces
>     and
>     then sort it on demand. My idea is to use something like weak
>     references combined with attributes. Consider:
>     
>     # Initialization.
>     l = as.list(1:10)
>     # Note that it is sorted.
>     attr(l, 'sorted') = weakref(l)
>     
>     # Modify the list.
>     l = append(l, 1:3)
>     
>     # Check if the list is still sorted. (I use identical here, but it
>     # probably too heavy weight: I just need to compare the
>     addresses.)
>     if (! identical(l, attr(l, 'sorted'))) {
>     l = sort(unlist(l))
>     attr(l, 'sorted') = weakref(l)
>     }
>     # Do operation that requires sorted list.
>     ...
>     
>     This is obviously a toy example. I'm not actually sorting integers
>     and I may use a matrix instead of a list.
>     
>     I've read:
>     
>     http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>     http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>     
>     As far as I can tell, weakrefs are only available via the C API.
>     Is
>     there a way to do what I want in R without resorting to C code? Is
>     what I want to do better achieved using something other than
>     weakrefs?
>     
>     Thanks!
>     
>     :) Neal
>     
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>     
>


From bgunter.4567 at gmail.com  Sun Jun  5 19:34:38 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 5 Jun 2016 10:34:38 -0700
Subject: [R] detecting if a variable has changed
In-Reply-To: <CAF8bMcb3+4PLBvETfQUWArWuAp5R8RoLNjyN+nHXv2MxeuOz0g@mail.gmail.com>
References: <87fusrwxld.wl-neal@walfield.org>
	<CAF8bMcb3+4PLBvETfQUWArWuAp5R8RoLNjyN+nHXv2MxeuOz0g@mail.gmail.com>
Message-ID: <CAGxFJbRyovfMv5MG-fz-BnJ4ehNwd2xHG6ccKYUQ4kKzvnRNJQ@mail.gmail.com>

This help thread suggested a question to me:

Is there a function in some package that efficiently (I.e. O(log(n)) )
inserts a single new element into the correct location in an
already-sorted vector? My assumption here is that doing it via sort()
is inefficient, but maybe that is incorrect. Please correct me if so.

I realize that it would be straightforward to write such a function,
but I just wondered if it already exists. My google & rseek searches
did not succeed, but maybe I used the wrong keywords.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 5, 2016 at 9:47 AM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> I don't know what you mean by "without having to use any special
> interfaces", but "reference classes" will do what I think you want.  E.g.,
> the following makes a class called 'SortedNumeric' that only sorts the
> vector when you want to get its value, not when you append values.  It
> stores the sorted vector so it does not get resorted each time you ask for
> it.
>
> SortedNumeric <- setRefClass("sortedNumeric",
>             fields = list(
>                 fData = "numeric",
>                 fIsUnsorted = "logical"),
>             methods = list(
>                 initialize = function(Data = numeric(), isUnsorted = TRUE) {
>                     fData <<- Data
>                     stopifnot(is.logical(isUnsorted),
>                               length(isUnsorted)==1,
>                               !is.na(isUnsorted))
>                     fIsUnsorted <<- isUnsorted
>                 },
>                 getData = function() {
>                     if (isUnsorted) {
>                         fData <<- sort(fData)
>                         fIsUnsorted <<- FALSE
>                     }
>                     fData
>                 },
>                 appendData = function(newEntries) {
>                     fData <<- c(fData, newEntries)
>                     fIsUnsorted <<- TRUE
>                 }
>             ))
>
> Use it as:
>
>> x <- SortedNumeric$new()
>> x$appendData(c(4,2,5))
>> x$appendData(c(1,8,9))
>> x
> Reference class object of class "sortedNumeric"
> Field "fData":
> [1] 4 2 5 1 8 9
> Field "fIsUnsorted":
> [1] TRUE
>> x$getData()
> [1] 1 2 4 5 8 9
>> x
> Reference class object of class "sortedNumeric"
> Field "fData":
> [1] 1 2 4 5 8 9
> Field "fIsUnsorted":
> [1] FALSE
>
>
> Outside of base R, I think the R6 package gives another approach to this.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org> wrote:
>
>> Hi,
>>
>> I have a huge list.  Normally it is sorted, but I want to be able to
>> add elements to it without having to use any special interfaces and
>> then sort it on demand.  My idea is to use something like weak
>> references combined with attributes.  Consider:
>>
>>   # Initialization.
>>   l = as.list(1:10)
>>   # Note that it is sorted.
>>   attr(l, 'sorted') = weakref(l)
>>
>>   # Modify the list.
>>   l = append(l, 1:3)
>>
>>   # Check if the list is still sorted.  (I use identical here, but it
>>   # probably too heavy weight: I just need to compare the addresses.)
>>   if (! identical(l, attr(l, 'sorted'))) {
>>     l = sort(unlist(l))
>>     attr(l, 'sorted') = weakref(l)
>>   }
>>   # Do operation that requires sorted list.
>>   ...
>>
>> This is obviously a toy example.  I'm not actually sorting integers
>> and I may use a matrix instead of a list.
>>
>> I've read:
>>
>>   http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>>   http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>>
>> As far as I can tell, weakrefs are only available via the C API.  Is
>> there a way to do what I want in R without resorting to C code?  Is
>> what I want to do better achieved using something other than weakrefs?
>>
>> Thanks!
>>
>> :) Neal
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neal at walfield.org  Sun Jun  5 19:44:29 2016
From: neal at walfield.org (Neal H. Walfield)
Date: Sun, 05 Jun 2016 19:44:29 +0200
Subject: [R] detecting if a variable has changed
In-Reply-To: <CAGxFJbRyovfMv5MG-fz-BnJ4ehNwd2xHG6ccKYUQ4kKzvnRNJQ@mail.gmail.com>
References: <87fusrwxld.wl-neal@walfield.org>
	<CAF8bMcb3+4PLBvETfQUWArWuAp5R8RoLNjyN+nHXv2MxeuOz0g@mail.gmail.com>
	<CAGxFJbRyovfMv5MG-fz-BnJ4ehNwd2xHG6ccKYUQ4kKzvnRNJQ@mail.gmail.com>
Message-ID: <87d1nvwmwy.wl-neal@walfield.org>

On Sun, 05 Jun 2016 19:34:38 +0200,
Bert Gunter wrote:
> This help thread suggested a question to me:
> 
> Is there a function in some package that efficiently (I.e. O(log(n)) )
> inserts a single new element into the correct location in an
> already-sorted vector? My assumption here is that doing it via sort()
> is inefficient, but maybe that is incorrect. Please correct me if so.

I think data.table will do this if the the column is marked
appropriately.

> I realize that it would be straightforward to write such a function,
> but I just wondered if it already exists. My google & rseek searches
> did not succeed, but maybe I used the wrong keywords.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Jun 5, 2016 at 9:47 AM, William Dunlap via R-help
> <r-help at r-project.org> wrote:
> > I don't know what you mean by "without having to use any special
> > interfaces", but "reference classes" will do what I think you want.  E.g.,
> > the following makes a class called 'SortedNumeric' that only sorts the
> > vector when you want to get its value, not when you append values.  It
> > stores the sorted vector so it does not get resorted each time you ask for
> > it.
> >
> > SortedNumeric <- setRefClass("sortedNumeric",
> >             fields = list(
> >                 fData = "numeric",
> >                 fIsUnsorted = "logical"),
> >             methods = list(
> >                 initialize = function(Data = numeric(), isUnsorted = TRUE) {
> >                     fData <<- Data
> >                     stopifnot(is.logical(isUnsorted),
> >                               length(isUnsorted)==1,
> >                               !is.na(isUnsorted))
> >                     fIsUnsorted <<- isUnsorted
> >                 },
> >                 getData = function() {
> >                     if (isUnsorted) {
> >                         fData <<- sort(fData)
> >                         fIsUnsorted <<- FALSE
> >                     }
> >                     fData
> >                 },
> >                 appendData = function(newEntries) {
> >                     fData <<- c(fData, newEntries)
> >                     fIsUnsorted <<- TRUE
> >                 }
> >             ))
> >
> > Use it as:
> >
> >> x <- SortedNumeric$new()
> >> x$appendData(c(4,2,5))
> >> x$appendData(c(1,8,9))
> >> x
> > Reference class object of class "sortedNumeric"
> > Field "fData":
> > [1] 4 2 5 1 8 9
> > Field "fIsUnsorted":
> > [1] TRUE
> >> x$getData()
> > [1] 1 2 4 5 8 9
> >> x
> > Reference class object of class "sortedNumeric"
> > Field "fData":
> > [1] 1 2 4 5 8 9
> > Field "fIsUnsorted":
> > [1] FALSE
> >
> >
> > Outside of base R, I think the R6 package gives another approach to this.
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org> wrote:
> >
> >> Hi,
> >>
> >> I have a huge list.  Normally it is sorted, but I want to be able to
> >> add elements to it without having to use any special interfaces and
> >> then sort it on demand.  My idea is to use something like weak
> >> references combined with attributes.  Consider:
> >>
> >>   # Initialization.
> >>   l = as.list(1:10)
> >>   # Note that it is sorted.
> >>   attr(l, 'sorted') = weakref(l)
> >>
> >>   # Modify the list.
> >>   l = append(l, 1:3)
> >>
> >>   # Check if the list is still sorted.  (I use identical here, but it
> >>   # probably too heavy weight: I just need to compare the addresses.)
> >>   if (! identical(l, attr(l, 'sorted'))) {
> >>     l = sort(unlist(l))
> >>     attr(l, 'sorted') = weakref(l)
> >>   }
> >>   # Do operation that requires sorted list.
> >>   ...
> >>
> >> This is obviously a toy example.  I'm not actually sorting integers
> >> and I may use a matrix instead of a list.
> >>
> >> I've read:
> >>
> >>   http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
> >>   http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
> >>
> >> As far as I can tell, weakrefs are only available via the C API.  Is
> >> there a way to do what I want in R without resorting to C code?  Is
> >> what I want to do better achieved using something other than weakrefs?
> >>
> >> Thanks!
> >>
> >> :) Neal
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From Ted.Harding at wlandres.net  Sun Jun  5 20:01:14 2016
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sun, 05 Jun 2016 19:01:14 +0100 (BST)
Subject: [R] detecting if a variable has changed
In-Reply-To: <87d1nvwmwy.wl-neal@walfield.org>
Message-ID: <XFMail.20160605190114.Ted.Harding@wlandres.net>

Surely it is straightforward, since the vector (say 'X') is already sorted?

Example (raw code with explicit example):

set.seed(54321)
X <- sort(runif(10))
# X ## The initial sorted vector
# [1] 0.04941009 0.17669234 0.20913493 0.21651016 0.27439354
# [6] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110

y <- runif(1)
# y ## The new value to be inserted
[1] 0.1366424

Y <- c(X[X<=y],y,X[X>y]) ## Now insert y into X:
Y
[1] 0.04941009 0.13664239 0.17669234 0.20913493 0.21651016 0.27439354
[7] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110

## And there it is at Y[2]

Easy to make such a function!
Best wishes to all,
Ted.

On 05-Jun-2016 17:44:29 Neal H. Walfield wrote:
> On Sun, 05 Jun 2016 19:34:38 +0200,
> Bert Gunter wrote:
>> This help thread suggested a question to me:
>> 
>> Is there a function in some package that efficiently (I.e. O(log(n)) )
>> inserts a single new element into the correct location in an
>> already-sorted vector? My assumption here is that doing it via sort()
>> is inefficient, but maybe that is incorrect. Please correct me if so.
> 
> I think data.table will do this if the the column is marked
> appropriately.
> 
>> I realize that it would be straightforward to write such a function,
>> but I just wondered if it already exists. My google & rseek searches
>> did not succeed, but maybe I used the wrong keywords.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Sun, Jun 5, 2016 at 9:47 AM, William Dunlap via R-help
>> <r-help at r-project.org> wrote:
>> > I don't know what you mean by "without having to use any special
>> > interfaces", but "reference classes" will do what I think you want.  E.g.,
>> > the following makes a class called 'SortedNumeric' that only sorts the
>> > vector when you want to get its value, not when you append values.  It
>> > stores the sorted vector so it does not get resorted each time you ask for
>> > it.
>> >
>> > SortedNumeric <- setRefClass("sortedNumeric",
>> >             fields = list(
>> >                 fData = "numeric",
>> >                 fIsUnsorted = "logical"),
>> >             methods = list(
>> >                 initialize = function(Data = numeric(), isUnsorted = TRUE)
>> >                 {
>> >                     fData <<- Data
>> >                     stopifnot(is.logical(isUnsorted),
>> >                               length(isUnsorted)==1,
>> >                               !is.na(isUnsorted))
>> >                     fIsUnsorted <<- isUnsorted
>> >                 },
>> >                 getData = function() {
>> >                     if (isUnsorted) {
>> >                         fData <<- sort(fData)
>> >                         fIsUnsorted <<- FALSE
>> >                     }
>> >                     fData
>> >                 },
>> >                 appendData = function(newEntries) {
>> >                     fData <<- c(fData, newEntries)
>> >                     fIsUnsorted <<- TRUE
>> >                 }
>> >             ))
>> >
>> > Use it as:
>> >
>> >> x <- SortedNumeric$new()
>> >> x$appendData(c(4,2,5))
>> >> x$appendData(c(1,8,9))
>> >> x
>> > Reference class object of class "sortedNumeric"
>> > Field "fData":
>> > [1] 4 2 5 1 8 9
>> > Field "fIsUnsorted":
>> > [1] TRUE
>> >> x$getData()
>> > [1] 1 2 4 5 8 9
>> >> x
>> > Reference class object of class "sortedNumeric"
>> > Field "fData":
>> > [1] 1 2 4 5 8 9
>> > Field "fIsUnsorted":
>> > [1] FALSE
>> >
>> >
>> > Outside of base R, I think the R6 package gives another approach to this.
>> >
>> >
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com
>> >
>> > On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org>
>> > wrote:
>> >
>> >> Hi,
>> >>
>> >> I have a huge list.  Normally it is sorted, but I want to be able to
>> >> add elements to it without having to use any special interfaces and
>> >> then sort it on demand.  My idea is to use something like weak
>> >> references combined with attributes.  Consider:
>> >>
>> >>   # Initialization.
>> >>   l = as.list(1:10)
>> >>   # Note that it is sorted.
>> >>   attr(l, 'sorted') = weakref(l)
>> >>
>> >>   # Modify the list.
>> >>   l = append(l, 1:3)
>> >>
>> >>   # Check if the list is still sorted.  (I use identical here, but it
>> >>   # probably too heavy weight: I just need to compare the addresses.)
>> >>   if (! identical(l, attr(l, 'sorted'))) {
>> >>     l = sort(unlist(l))
>> >>     attr(l, 'sorted') = weakref(l)
>> >>   }
>> >>   # Do operation that requires sorted list.
>> >>   ...
>> >>
>> >> This is obviously a toy example.  I'm not actually sorting integers
>> >> and I may use a matrix instead of a list.
>> >>
>> >> I've read:
>> >>
>> >>   http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>> >>   http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>> >>
>> >> As far as I can tell, weakrefs are only available via the C API.  Is
>> >> there a way to do what I want in R without resorting to C code?  Is
>> >> what I want to do better achieved using something other than weakrefs?
>> >>
>> >> Thanks!
>> >>
>> >> :) Neal
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 05-Jun-2016  Time: 19:01:10
This message was sent by XFMail


From bgunter.4567 at gmail.com  Sun Jun  5 20:13:15 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 5 Jun 2016 11:13:15 -0700
Subject: [R] detecting if a variable has changed
In-Reply-To: <XFMail.20160605190114.Ted.Harding@wlandres.net>
References: <87d1nvwmwy.wl-neal@walfield.org>
	<XFMail.20160605190114.Ted.Harding@wlandres.net>
Message-ID: <CAGxFJbShgYUVSs2O8GPtWE9MxBEaRRXoVU=mPHvzH2-VxAruGw@mail.gmail.com>

Nope, Ted. I asked for  a O(log(n)) solution, not an O(n) one.

I will check out the data.table package, as suggested.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 5, 2016 at 11:01 AM, Ted Harding <Ted.Harding at wlandres.net> wrote:
> Surely it is straightforward, since the vector (say 'X') is already sorted?
>
> Example (raw code with explicit example):
>
> set.seed(54321)
> X <- sort(runif(10))
> # X ## The initial sorted vector
> # [1] 0.04941009 0.17669234 0.20913493 0.21651016 0.27439354
> # [6] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>
> y <- runif(1)
> # y ## The new value to be inserted
> [1] 0.1366424
>
> Y <- c(X[X<=y],y,X[X>y]) ## Now insert y into X:
> Y
> [1] 0.04941009 0.13664239 0.17669234 0.20913493 0.21651016 0.27439354
> [7] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>
> ## And there it is at Y[2]
>
> Easy to make such a function!
> Best wishes to all,
> Ted.
>
> On 05-Jun-2016 17:44:29 Neal H. Walfield wrote:
>> On Sun, 05 Jun 2016 19:34:38 +0200,
>> Bert Gunter wrote:
>>> This help thread suggested a question to me:
>>>
>>> Is there a function in some package that efficiently (I.e. O(log(n)) )
>>> inserts a single new element into the correct location in an
>>> already-sorted vector? My assumption here is that doing it via sort()
>>> is inefficient, but maybe that is incorrect. Please correct me if so.
>>
>> I think data.table will do this if the the column is marked
>> appropriately.
>>
>>> I realize that it would be straightforward to write such a function,
>>> but I just wondered if it already exists. My google & rseek searches
>>> did not succeed, but maybe I used the wrong keywords.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sun, Jun 5, 2016 at 9:47 AM, William Dunlap via R-help
>>> <r-help at r-project.org> wrote:
>>> > I don't know what you mean by "without having to use any special
>>> > interfaces", but "reference classes" will do what I think you want.  E.g.,
>>> > the following makes a class called 'SortedNumeric' that only sorts the
>>> > vector when you want to get its value, not when you append values.  It
>>> > stores the sorted vector so it does not get resorted each time you ask for
>>> > it.
>>> >
>>> > SortedNumeric <- setRefClass("sortedNumeric",
>>> >             fields = list(
>>> >                 fData = "numeric",
>>> >                 fIsUnsorted = "logical"),
>>> >             methods = list(
>>> >                 initialize = function(Data = numeric(), isUnsorted = TRUE)
>>> >                 {
>>> >                     fData <<- Data
>>> >                     stopifnot(is.logical(isUnsorted),
>>> >                               length(isUnsorted)==1,
>>> >                               !is.na(isUnsorted))
>>> >                     fIsUnsorted <<- isUnsorted
>>> >                 },
>>> >                 getData = function() {
>>> >                     if (isUnsorted) {
>>> >                         fData <<- sort(fData)
>>> >                         fIsUnsorted <<- FALSE
>>> >                     }
>>> >                     fData
>>> >                 },
>>> >                 appendData = function(newEntries) {
>>> >                     fData <<- c(fData, newEntries)
>>> >                     fIsUnsorted <<- TRUE
>>> >                 }
>>> >             ))
>>> >
>>> > Use it as:
>>> >
>>> >> x <- SortedNumeric$new()
>>> >> x$appendData(c(4,2,5))
>>> >> x$appendData(c(1,8,9))
>>> >> x
>>> > Reference class object of class "sortedNumeric"
>>> > Field "fData":
>>> > [1] 4 2 5 1 8 9
>>> > Field "fIsUnsorted":
>>> > [1] TRUE
>>> >> x$getData()
>>> > [1] 1 2 4 5 8 9
>>> >> x
>>> > Reference class object of class "sortedNumeric"
>>> > Field "fData":
>>> > [1] 1 2 4 5 8 9
>>> > Field "fIsUnsorted":
>>> > [1] FALSE
>>> >
>>> >
>>> > Outside of base R, I think the R6 package gives another approach to this.
>>> >
>>> >
>>> > Bill Dunlap
>>> > TIBCO Software
>>> > wdunlap tibco.com
>>> >
>>> > On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org>
>>> > wrote:
>>> >
>>> >> Hi,
>>> >>
>>> >> I have a huge list.  Normally it is sorted, but I want to be able to
>>> >> add elements to it without having to use any special interfaces and
>>> >> then sort it on demand.  My idea is to use something like weak
>>> >> references combined with attributes.  Consider:
>>> >>
>>> >>   # Initialization.
>>> >>   l = as.list(1:10)
>>> >>   # Note that it is sorted.
>>> >>   attr(l, 'sorted') = weakref(l)
>>> >>
>>> >>   # Modify the list.
>>> >>   l = append(l, 1:3)
>>> >>
>>> >>   # Check if the list is still sorted.  (I use identical here, but it
>>> >>   # probably too heavy weight: I just need to compare the addresses.)
>>> >>   if (! identical(l, attr(l, 'sorted'))) {
>>> >>     l = sort(unlist(l))
>>> >>     attr(l, 'sorted') = weakref(l)
>>> >>   }
>>> >>   # Do operation that requires sorted list.
>>> >>   ...
>>> >>
>>> >> This is obviously a toy example.  I'm not actually sorting integers
>>> >> and I may use a matrix instead of a list.
>>> >>
>>> >> I've read:
>>> >>
>>> >>   http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>>> >>   http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>>> >>
>>> >> As far as I can tell, weakrefs are only available via the C API.  Is
>>> >> there a way to do what I want in R without resorting to C code?  Is
>>> >> what I want to do better achieved using something other than weakrefs?
>>> >>
>>> >> Thanks!
>>> >>
>>> >> :) Neal
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 05-Jun-2016  Time: 19:01:10
> This message was sent by XFMail
> -------------------------------------------------


From chalabi.elahe at yahoo.de  Sun Jun  5 20:29:55 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sun, 5 Jun 2016 18:29:55 +0000 (UTC)
Subject: [R] Training set in Self organizing Map
In-Reply-To: <0CEE53E2-705F-4B84-B0DC-BA4E0BD984A0@dcn.davis.ca.us>
References: <267730348.5184682.1464791970799.JavaMail.yahoo.ref@mail.yahoo.com>
	<267730348.5184682.1464791970799.JavaMail.yahoo@mail.yahoo.com>
	<0CEE53E2-705F-4B84-B0DC-BA4E0BD984A0@dcn.davis.ca.us>
Message-ID: <956481472.388809.1465151395062.JavaMail.yahoo@mail.yahoo.com>

Hi Jeff,
Thanks for your reply. My df contains Protocols and their Parameters and I want to use SOM to see if I can find some clusters in customor's using protocols. Some of these Parameters are factors and some are numeric. I want to make a subset of some protocols and give them to SOM as training set and keep some for test set. is it possible to have also those factors in training set of SOM?


    
    $ Protocol          : Factor w/ 132 levels "_unknown","A5. SAG TSE T2 FS",..: 5
    $ BR                : int  320 320 384 384 384 320 256 320 384 38
    $ BW                : int  150 150 191 191 98 150 150 150 
    $ COUNTRY           : Factor w/ 35 levels "AE","AT","AU",..: 10 10 
    $ FSM               : Factor w/ 2 levels "strong","weak": 2 2 


On Wednesday, June 1, 2016 7:59 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:



You did not send  sample of your data, using dput. Before doing that,  I suggest peeling apart your troublesome line of code yourself:

str( as.matrix( scale( subdf ) ) )
str( scale( subdf ) )
str( subdf )

And then think about what the scale function does. Does it make sense to ask it to scale character or factor data? Could you perhaps exclude some of the columns that don't belong in the scaled data? 
-- 
Sent from my phone. Please excuse my brevity.


On June 1, 2016 7:39:30 AM PDT, "ch.elahe via R-help" <r-help at r-project.org> wrote:
Hi all,
>I want to use Self Organizing Map in R for my data. I want my training set to be the following subset of my data:
>
>
>subdf=subset(df,Country%in%c("US","FR"))
>next I should change this subset to a matrix but I get the following error:
>
>data_train_matrix=as.matrix(scale(subdf))
>error in colMeans(x,na.rm=TRUE):'x' must be numeric
>
>Can anyone help me to solve that?
>Thanks for any help
>Elahe
>
>
>________________________________
>
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From jcpayne at uw.edu  Sun Jun  5 20:45:52 2016
From: jcpayne at uw.edu (J Payne)
Date: Sun, 05 Jun 2016 11:45:52 -0700
Subject: [R] system() command not working
In-Reply-To: <C79A52EE-CAF6-4546-B9B3-8459B06EF3B1@noaa.gov>
References: <CB883FB0-102A-49FC-80FD-A350DE708B55@uw.edu>
	<C79A52EE-CAF6-4546-B9B3-8459B06EF3B1@noaa.gov>
Message-ID: <2C45C000-1474-453D-95BA-0025AF5AFCE6@uw.edu>

Thanks very much Roy!  I will post to R-Sig-Mac.  I browsed their archives but didn?t see anything about the issue ? I might have missed something, though.  

John


On 6/4/16, 1:12 PM, "Roy Mendelssohn - NOAA Federal" <roy.mendelssohn at noaa.gov> wrote:

>Hi John:
>
>When El Capitan first came out there was a discussion in the  R-SIg-Mac  list about environmental variables not being passed down to applications  (not just R abut in general).  I believe a work around was suggested, but I would search the archives for that.
>
>So what is happening, when you run from the command line, the variables   MRT_DATA_DIR and MRTDATADIR which are defined somewhere in your environment are found in the terminal, but when the same command is run from the application they are not being found.  I would search the R-SIg-Mac archive or post to that list, because i can?t remember what the work around was for it.
>
>HTH,
>
>-Roy
>
>> On Jun 4, 2016, at 11:59 AM, J Payne <jcpayne at uw.edu> wrote:
>> 
>> I?ve posted this question on StackExchange at http://stackoverflow.com/questions/37604466/r-system-not-working-with-modis-reprojection-tool, but haven?t received any replies.  I?m hoping that someone who understands the operation of the R system() command can help.  
>> 
>> 
>> 
>> I have a command that works when typed into the Terminal on a Mac (OSX El Cap), but exactly the same command fails when called from R using `system()`. 
>> 
>>  
>> 
>> I am trying to batch-process MODIS satellite files using a small program called the MODIS Reprojection Tool (https://lpdaac.usgs.gov/tools/modis_reprojection_tool).  My software is all up to date.
>> 
>> 
>> 
>> This is a simple example in which I mosaic two files.  The names of the two files are in a text input file called `input.list`.  The command just tells the `mrtmosaic` routine where to find the input list and where to put the output. 
>> 
>> 
>> 
>> This command works correctly in the Terminal:  
>> 
>> 
>> 
>>     /Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf
>> 
>> 
>> 
>> However, if I put exactly the same string into a variable and run it from R (using RStudio), it fails:  
>> 
>> 
>> 
>>     comstring<-"/Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf"  
>> 
>>     system(comstring)
>> 
>> 
>> 
>>> Warning: gctp_call : Environmental Variable Not Found:   
>> 
>>     MRT_DATA_DIR nor MRTDATADIR not defined
>> 
>>     Error: GetInputGeoCornerMosaic : General Processing Error converting lat/long coordinates to input projection coordinates.  
>> 
>>     Fatal Error, Terminating...
>> 
>> 
>> 
>> The strange thing is that the system knows what the environment variables are.  In the terminal, the command
>> 
>> `echo $MRT_DATA_DIR`
>> 
>> shows the correct directory: /Applications/Modis_Reprojection_Tool/data
>> 
>> 
>> 
>> I don't see why it would have trouble finding the variables from an `R system()` call when it has no trouble in the Terminal.  I'm very stumped!  
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>**********************
>"The contents of this message do not reflect any position of the U.S. Government or NOAA."
>**********************
>Roy Mendelssohn
>Supervisory Operations Research Analyst
>NOAA/NMFS
>Environmental Research Division
>Southwest Fisheries Science Center
>***Note new address and phone***
>110 Shaffer Road
>Santa Cruz, CA 95060
>Phone: (831)-420-3666
>Fax: (831) 420-3980
>e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
>"Old age and treachery will overcome youth and skill."
>"From those who have been given much, much will be expected" 
>"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>


From Ted.Harding at wlandres.net  Sun Jun  5 21:49:15 2016
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sun, 05 Jun 2016 20:49:15 +0100 (BST)
Subject: [R] detecting if a variable has changed
In-Reply-To: <CAGxFJbShgYUVSs2O8GPtWE9MxBEaRRXoVU=mPHvzH2-VxAruGw@mail.gmail.com>
Message-ID: <XFMail.20160605204915.Ted.Harding@wlandres.net>

Ah, perhaps I'm beginning to undertstand the question!
Presumably the issue is that evaluating X[X<=y] takes O(n) time,
where n = length(X), and similarly X[X>y]. 

So I suppose that one needs to be looking at some procedure for
a "bisecting" search for the largest r such that X[r] <= y, which
would then be O(log2(n)).

Perhaps not altogether straightforward to program, but straqightforward
in concept!

Apologies for misunderstanding.
Ted.

On 05-Jun-2016 18:13:15 Bert Gunter wrote:
> Nope, Ted. I asked for  a O(log(n)) solution, not an O(n) one.
> 
> I will check out the data.table package, as suggested.
> 
> -- Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Jun 5, 2016 at 11:01 AM, Ted Harding <Ted.Harding at wlandres.net>
> wrote:
>> Surely it is straightforward, since the vector (say 'X') is already sorted?
>>
>> Example (raw code with explicit example):
>>
>> set.seed(54321)
>> X <- sort(runif(10))
>> # X ## The initial sorted vector
>> # [1] 0.04941009 0.17669234 0.20913493 0.21651016 0.27439354
>> # [6] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>>
>> y <- runif(1)
>> # y ## The new value to be inserted
>> [1] 0.1366424
>>
>> Y <- c(X[X<=y],y,X[X>y]) ## Now insert y into X:
>> Y
>> [1] 0.04941009 0.13664239 0.17669234 0.20913493 0.21651016 0.27439354
>> [7] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>>
>> ## And there it is at Y[2]
>>
>> Easy to make such a function!
>> Best wishes to all,
>> Ted.
>>
>> On 05-Jun-2016 17:44:29 Neal H. Walfield wrote:
>>> On Sun, 05 Jun 2016 19:34:38 +0200,
>>> Bert Gunter wrote:
>>>> This help thread suggested a question to me:
>>>>
>>>> Is there a function in some package that efficiently (I.e. O(log(n)) )
>>>> inserts a single new element into the correct location in an
>>>> already-sorted vector? My assumption here is that doing it via sort()
>>>> is inefficient, but maybe that is incorrect. Please correct me if so.
>>>
>>> I think data.table will do this if the the column is marked
>>> appropriately.
>>>
>>>> I realize that it would be straightforward to write such a function,
>>>> but I just wondered if it already exists. My google & rseek searches
>>>> did not succeed, but maybe I used the wrong keywords.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Sun, Jun 5, 2016 at 9:47 AM, William Dunlap via R-help
>>>> <r-help at r-project.org> wrote:
>>>> > I don't know what you mean by "without having to use any special
>>>> > interfaces", but "reference classes" will do what I think you want. 
>>>> > E.g.,
>>>> > the following makes a class called 'SortedNumeric' that only sorts the
>>>> > vector when you want to get its value, not when you append values.  It
>>>> > stores the sorted vector so it does not get resorted each time you ask
>>>> > for
>>>> > it.
>>>> >
>>>> > SortedNumeric <- setRefClass("sortedNumeric",
>>>> >             fields = list(
>>>> >                 fData = "numeric",
>>>> >                 fIsUnsorted = "logical"),
>>>> >             methods = list(
>>>> >                 initialize = function(Data = numeric(), isUnsorted =
>>>> >                 TRUE)
>>>> >                 {
>>>> >                     fData <<- Data
>>>> >                     stopifnot(is.logical(isUnsorted),
>>>> >                               length(isUnsorted)==1,
>>>> >                               !is.na(isUnsorted))
>>>> >                     fIsUnsorted <<- isUnsorted
>>>> >                 },
>>>> >                 getData = function() {
>>>> >                     if (isUnsorted) {
>>>> >                         fData <<- sort(fData)
>>>> >                         fIsUnsorted <<- FALSE
>>>> >                     }
>>>> >                     fData
>>>> >                 },
>>>> >                 appendData = function(newEntries) {
>>>> >                     fData <<- c(fData, newEntries)
>>>> >                     fIsUnsorted <<- TRUE
>>>> >                 }
>>>> >             ))
>>>> >
>>>> > Use it as:
>>>> >
>>>> >> x <- SortedNumeric$new()
>>>> >> x$appendData(c(4,2,5))
>>>> >> x$appendData(c(1,8,9))
>>>> >> x
>>>> > Reference class object of class "sortedNumeric"
>>>> > Field "fData":
>>>> > [1] 4 2 5 1 8 9
>>>> > Field "fIsUnsorted":
>>>> > [1] TRUE
>>>> >> x$getData()
>>>> > [1] 1 2 4 5 8 9
>>>> >> x
>>>> > Reference class object of class "sortedNumeric"
>>>> > Field "fData":
>>>> > [1] 1 2 4 5 8 9
>>>> > Field "fIsUnsorted":
>>>> > [1] FALSE
>>>> >
>>>> >
>>>> > Outside of base R, I think the R6 package gives another approach to
>>>> > this.
>>>> >
>>>> >
>>>> > Bill Dunlap
>>>> > TIBCO Software
>>>> > wdunlap tibco.com
>>>> >
>>>> > On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org>
>>>> > wrote:
>>>> >
>>>> >> Hi,
>>>> >>
>>>> >> I have a huge list.  Normally it is sorted, but I want to be able to
>>>> >> add elements to it without having to use any special interfaces and
>>>> >> then sort it on demand.  My idea is to use something like weak
>>>> >> references combined with attributes.  Consider:
>>>> >>
>>>> >>   # Initialization.
>>>> >>   l = as.list(1:10)
>>>> >>   # Note that it is sorted.
>>>> >>   attr(l, 'sorted') = weakref(l)
>>>> >>
>>>> >>   # Modify the list.
>>>> >>   l = append(l, 1:3)
>>>> >>
>>>> >>   # Check if the list is still sorted.  (I use identical here, but it
>>>> >>   # probably too heavy weight: I just need to compare the addresses.)
>>>> >>   if (! identical(l, attr(l, 'sorted'))) {
>>>> >>     l = sort(unlist(l))
>>>> >>     attr(l, 'sorted') = weakref(l)
>>>> >>   }
>>>> >>   # Do operation that requires sorted list.
>>>> >>   ...
>>>> >>
>>>> >> This is obviously a toy example.  I'm not actually sorting integers
>>>> >> and I may use a matrix instead of a list.
>>>> >>
>>>> >> I've read:
>>>> >>
>>>> >>   http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>>>> >>   http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>>>> >>
>>>> >> As far as I can tell, weakrefs are only available via the C API.  Is
>>>> >> there a way to do what I want in R without resorting to C code?  Is
>>>> >> what I want to do better achieved using something other than weakrefs?
>>>> >>
>>>> >> Thanks!
>>>> >>
>>>> >> :) Neal
>>>> >>
>>>> >> ______________________________________________
>>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >> PLEASE do read the posting guide
>>>> >> http://www.R-project.org/posting-guide.html
>>>> >> and provide commented, minimal, self-contained, reproducible code.
>>>> >>
>>>> >
>>>> >         [[alternative HTML version deleted]]
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide
>>>> > http://www.R-project.org/posting-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> -------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>> Date: 05-Jun-2016  Time: 19:01:10
>> This message was sent by XFMail
>> -------------------------------------------------
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 05-Jun-2016  Time: 20:49:12
This message was sent by XFMail


From jcpayne at uw.edu  Sun Jun  5 22:17:55 2016
From: jcpayne at uw.edu (J Payne)
Date: Sun, 05 Jun 2016 13:17:55 -0700
Subject: [R] system() command not working
In-Reply-To: <A4D3949B-C60C-46AB-BA96-9E8A6906A46A@xs4all.nl>
References: <CB883FB0-102A-49FC-80FD-A350DE708B55@uw.edu>
	<C79A52EE-CAF6-4546-B9B3-8459B06EF3B1@noaa.gov>
	<A4D3949B-C60C-46AB-BA96-9E8A6906A46A@xs4all.nl>
Message-ID: <37BD05A3-7066-49E4-A434-5E5A580E8D02@uw.edu>

Thanks Berend, that?s super useful.  In summary, here is what I found:

The problem (if I understand correctly) is that R was not passing environment variables to OSX El Capitan successfully.  In any case:

These do not work:
1. Setting the environment variable in my .bash_profile (for example ?MTR_DATA_DIR="/Applications/MRT/data"); or 
2. Adding the same environment variable to .Rprofile in my home directory.

These do work (hooray!):
3. Changing the environment variable using Sys.setenv(MRT_DATA_DIR="/Applications/MRT/data") inside R at the R command line; or
4. Typing ?MRT_DATA_DIR="/Applications/MRT/data" open -a Rstudio? in the Terminal.  This latter method is an effective workaround and wonderful to have in my bag of tricks, but is slightly clumsier since I have to remember to open RStudio this way  each time.  

I?m very grateful to you and Roy for your help.

John

On 6/5/16, 3:28 AM, "Berend Hasselman" <bhh at xs4all.nl> wrote:

>
>> On 4 Jun 2016, at 22:12, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>> 
>> Hi John:
>> 
>> When El Capitan first came out there was a discussion in the  R-SIg-Mac  list about environmental variables not being passed down to applications  (not just R abut in general).  I believe a work around was suggested, but I would search the archives for that.
>> 
>> So what is happening, when you run from the command line, the variables   MRT_DATA_DIR and MRTDATADIR which are defined somewhere in your environment are found in the terminal, but when the same command is run from the application they are not being found.  I would search the R-SIg-Mac archive or post to that list, because i can?t remember what the work around was for it.
>> 
>
>I can't find the discussion on R-SIG-Mac list. But you can try this:
>
>MRT_DATA_DIR=<whatever> open -a Rstudio
>
>or  
>
>MRT_DATA_DIR=<whatever> open -a R
>
>Try it and see what happens.
>It may even be possible to put something in .Rprofile  setting your environment variables.
>
>Berend Hasselman
>
>> HTH,
>> 
>> -Roy
>> 
>>> On Jun 4, 2016, at 11:59 AM, J Payne <jcpayne at uw.edu> wrote:
>>> 
>>> I?ve posted this question on StackExchange at http://stackoverflow.com/questions/37604466/r-system-not-working-with-modis-reprojection-tool, but haven?t received any replies.  I?m hoping that someone who understands the operation of the R system() command can help.  
>>> 
>>> 
>>> 
>>> I have a command that works when typed into the Terminal on a Mac (OSX El Cap), but exactly the same command fails when called from R using `system()`. 
>>> 
>>> 
>>> 
>>> I am trying to batch-process MODIS satellite files using a small program called the MODIS Reprojection Tool (https://lpdaac.usgs.gov/tools/modis_reprojection_tool).  My software is all up to date.
>>> 
>>> 
>>> 
>>> This is a simple example in which I mosaic two files.  The names of the two files are in a text input file called `input.list`.  The command just tells the `mrtmosaic` routine where to find the input list and where to put the output. 
>>> 
>>> 
>>> 
>>> This command works correctly in the Terminal:  
>>> 
>>> 
>>> 
>>>    /Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf
>>> 
>>> 
>>> 
>>> However, if I put exactly the same string into a variable and run it from R (using RStudio), it fails:  
>>> 
>>> 
>>> 
>>>    comstring<-"/Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf"  
>>> 
>>>    system(comstring)
>>> 
>>> 
>>> 
>>>> Warning: gctp_call : Environmental Variable Not Found:   
>>> 
>>>    MRT_DATA_DIR nor MRTDATADIR not defined
>>> 
>>>    Error: GetInputGeoCornerMosaic : General Processing Error converting lat/long coordinates to input projection coordinates.  
>>> 
>>>    Fatal Error, Terminating...
>>> 
>>> 
>>> 
>>> The strange thing is that the system knows what the environment variables are.  In the terminal, the command
>>> 
>>> `echo $MRT_DATA_DIR`
>>> 
>>> shows the correct directory: /Applications/Modis_Reprojection_Tool/data
>>> 
>>> 
>>> 
>>> I don't see why it would have trouble finding the variables from an `R system()` call when it has no trouble in the Terminal.  I'm very stumped!  
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new address and phone***
>> 110 Shaffer Road
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected" 
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jcpayne at uw.edu  Sun Jun  5 22:51:41 2016
From: jcpayne at uw.edu (J Payne)
Date: Sun, 05 Jun 2016 13:51:41 -0700
Subject: [R] system() command not working
In-Reply-To: <37BD05A3-7066-49E4-A434-5E5A580E8D02@uw.edu>
References: <CB883FB0-102A-49FC-80FD-A350DE708B55@uw.edu>
	<C79A52EE-CAF6-4546-B9B3-8459B06EF3B1@noaa.gov>
	<A4D3949B-C60C-46AB-BA96-9E8A6906A46A@xs4all.nl>
	<37BD05A3-7066-49E4-A434-5E5A580E8D02@uw.edu>
Message-ID: <829D923C-9336-45A1-8CDC-9B498C81D7C9@uw.edu>


I forgot to add that setting the environment variable in .Renviron in my home directory *also* works.  I have updated my question on Stackoverflow to include these answers.

John

On 6/5/16, 1:17 PM, "J Payne" <jcpayne at uw.edu> wrote:

>Thanks Berend, that?s super useful.  In summary, here is what I found:
>
>The problem (if I understand correctly) is that R was not passing environment variables to OSX El Capitan successfully.  In any case:
>
>These do not work:
>1. Setting the environment variable in my .bash_profile (for example ?MTR_DATA_DIR="/Applications/MRT/data"); or 
>2. Adding the same environment variable to .Rprofile in my home directory.
>
>These do work (hooray!):
>3. Changing the environment variable using Sys.setenv(MRT_DATA_DIR="/Applications/MRT/data") inside R at the R command line; or
>4. Typing ?MRT_DATA_DIR="/Applications/MRT/data" open -a Rstudio? in the Terminal.  This latter method is an effective workaround and wonderful to have in my bag of tricks, but is slightly clumsier since I have to remember to open RStudio this way  each time.  
>
>I?m very grateful to you and Roy for your help.
>
>John
>
>On 6/5/16, 3:28 AM, "Berend Hasselman" <bhh at xs4all.nl> wrote:
>
>>
>>> On 4 Jun 2016, at 22:12, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>>> 
>>> Hi John:
>>> 
>>> When El Capitan first came out there was a discussion in the  R-SIg-Mac  list about environmental variables not being passed down to applications  (not just R abut in general).  I believe a work around was suggested, but I would search the archives for that.
>>> 
>>> So what is happening, when you run from the command line, the variables   MRT_DATA_DIR and MRTDATADIR which are defined somewhere in your environment are found in the terminal, but when the same command is run from the application they are not being found.  I would search the R-SIg-Mac archive or post to that list, because i can?t remember what the work around was for it.
>>> 
>>
>>I can't find the discussion on R-SIG-Mac list. But you can try this:
>>
>>MRT_DATA_DIR=<whatever> open -a Rstudio
>>
>>or  
>>
>>MRT_DATA_DIR=<whatever> open -a R
>>
>>Try it and see what happens.
>>It may even be possible to put something in .Rprofile  setting your environment variables.
>>
>>Berend Hasselman
>>
>>> HTH,
>>> 
>>> -Roy
>>> 
>>>> On Jun 4, 2016, at 11:59 AM, J Payne <jcpayne at uw.edu> wrote:
>>>> 
>>>> I?ve posted this question on StackExchange at http://stackoverflow.com/questions/37604466/r-system-not-working-with-modis-reprojection-tool, but haven?t received any replies.  I?m hoping that someone who understands the operation of the R system() command can help.  
>>>> 
>>>> 
>>>> 
>>>> I have a command that works when typed into the Terminal on a Mac (OSX El Cap), but exactly the same command fails when called from R using `system()`. 
>>>> 
>>>> 
>>>> 
>>>> I am trying to batch-process MODIS satellite files using a small program called the MODIS Reprojection Tool (https://lpdaac.usgs.gov/tools/modis_reprojection_tool).  My software is all up to date.
>>>> 
>>>> 
>>>> 
>>>> This is a simple example in which I mosaic two files.  The names of the two files are in a text input file called `input.list`.  The command just tells the `mrtmosaic` routine where to find the input list and where to put the output. 
>>>> 
>>>> 
>>>> 
>>>> This command works correctly in the Terminal:  
>>>> 
>>>> 
>>>> 
>>>>    /Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf
>>>> 
>>>> 
>>>> 
>>>> However, if I put exactly the same string into a variable and run it from R (using RStudio), it fails:  
>>>> 
>>>> 
>>>> 
>>>>    comstring<-"/Applications/Modis_Reprojection_Tool/bin/mrtmosaic -i ~/temp/input.list -o ~/temp/output.hdf"  
>>>> 
>>>>    system(comstring)
>>>> 
>>>> 
>>>> 
>>>>> Warning: gctp_call : Environmental Variable Not Found:   
>>>> 
>>>>    MRT_DATA_DIR nor MRTDATADIR not defined
>>>> 
>>>>    Error: GetInputGeoCornerMosaic : General Processing Error converting lat/long coordinates to input projection coordinates.  
>>>> 
>>>>    Fatal Error, Terminating...
>>>> 
>>>> 
>>>> 
>>>> The strange thing is that the system knows what the environment variables are.  In the terminal, the command
>>>> 
>>>> `echo $MRT_DATA_DIR`
>>>> 
>>>> shows the correct directory: /Applications/Modis_Reprojection_Tool/data
>>>> 
>>>> 
>>>> 
>>>> I don't see why it would have trouble finding the variables from an `R system()` call when it has no trouble in the Terminal.  I'm very stumped!  
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new address and phone***
>>> 110 Shaffer Road
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>>> 
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected" 
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From drjimlemon at gmail.com  Mon Jun  6 00:17:21 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 6 Jun 2016 08:17:21 +1000
Subject: [R] Reading and converting time data via read.table
In-Reply-To: <CA+ZkTxsDR3J7=MK2Y9qBgsoandQ9YgQ8FnszBnOtz3yy5159Bw@mail.gmail.com>
References: <CA+ZkTxsDR3J7=MK2Y9qBgsoandQ9YgQ8FnszBnOtz3yy5159Bw@mail.gmail.com>
Message-ID: <CA+8X3fWDgW+BQ90dOjN1qj3QVXaVvpjZ+BTN0un=Bg7GPTQRnw@mail.gmail.com>

Hi EKE,
Your problem may be that the date strings are being read as a factor.
Try using stringsAsFactors=FALSE when you read the data in. Another
way is to convert your dates to strings when passing to as.Date:

as.Date(as.character(mydf$Date),"%m/%d/%Y")

Jim


On Sun, Jun 5, 2016 at 10:53 PM, Ek Esawi <esawiek at gmail.com> wrote:
> Hi All--
>
>
>
> I am relatively new to R. I am reading a csv file via read.table (MyFile).
> The data types in the file are date, string, integer, and time. I was able
> to read all the data and manipulated correctly except time, e.g., 12:30. I
> used as.Date to convert date and string and integer were easily done. I
> could not figure out how to convert the time data correctly. I tried chron
> but w/o success and I read that POSIXlt and POSIXct work only for date and
> time (e.g. 01/02/1999, 12:30:20). I did not try the lubridate package. Is
> there a way to read time data without date attached to it like mine?
>
>
>
> I am grateful for any help and thanks in advance?EKE
>
>
>
> Here is an example of my data when read into R via read.table
>
>
>
>                 AA          Date         Name     T1          T2
> N1
>
> 1              312171  7/1/1995       OF      13:37      1:43         123
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kpmainali at gmail.com  Mon Jun  6 00:35:17 2016
From: kpmainali at gmail.com (Kumar Mainali)
Date: Sun, 5 Jun 2016 18:35:17 -0400
Subject: [R] dissolve tiny polygons to others with
	unionSpatialPolygons{maptools}
Message-ID: <CABK368iX8Qa7ferBcpsdcvQu4cWxWHGuNTPYHD=SKBTgpjJ0XA@mail.gmail.com>

I am trying to use unionSpatialPolygons() of maptools to eliminate sliver
in species range. I want to dissolve tiny sliver polygons in a shapefile to
bigger polygons as "Eliminate (Data Management)" of ArcMap does. Whereas I
can dissolve polygons that have identical features in the argument "IDs", I
cannot dissolve tiny polygons based on some threshold in area. In fact, the
argument "threshold" has no effect in the output.

?Input data is available here: ?
https://www.dropbox.com/sh/a0x5bbo9u60y7is/AAB6RjXHFQKZv-i-t4JclF3ba?dl=0

p.ranges <- shapefile{raster}
(IDs <- p.ranges$style_id)
library(maptools)
unionSpatialPolygons(p.ranges, IDs = IDs, threshold = 1.5)

?-- Kumar Mainali
Postdoctoral Associate
Department of Biology
University of Maryland, College Park


?

	[[alternative HTML version deleted]]


From todojo at gmail.com  Sun Jun  5 21:45:36 2016
From: todojo at gmail.com (Douglas Johnson)
Date: Sun, 5 Jun 2016 15:45:36 -0400
Subject: [R] How to specify a data frame column using command line arg?
Message-ID: <CAEKTc2OOsyWaCy=RxFSMWrMjg_OxJhAZfKYubGwSCUDKjpt=iw@mail.gmail.com>

I'm guessing this is trivial but I've spent two hours searching and reading
FAQ, tutorial, introductory and 'idiom' documents and haven't found a
solution. All I want to do is select a data frame column at run time using
a command line arg. For example, the "test.csv" file contains:

a,b,c
1,2,3
4,5,6
7,8,9

If I run "test.r a", I get [1,4,7].
If I run "test.r b", I get [2,5,8].

Here's sample code -- how I map args[1] to column/vector 'a' or 'b' or 'c'?

args <- commandArgs(trailingOnly=T)

adl1<-read.csv(file="test.csv",head=T,sep=",")

adl1$SOME-MAGIC-FUNCTION-OR-SYMBOL(args[1])


All I'm really trying to do is generate a bunch of scatter plots of column
'x' vs. 'y' without writing a separate program for each pair.


Thanks,


Doug



-- 
http://www.dojopico.org <http://dojopico.org>

	[[alternative HTML version deleted]]


From nick.tulli.95 at gmail.com  Sun Jun  5 21:51:35 2016
From: nick.tulli.95 at gmail.com (Nick Tulli)
Date: Sun, 5 Jun 2016 15:51:35 -0400
Subject: [R] find longest consecutive streak in double
Message-ID: <CAONpAsogo1-O_ZPxP0W0M4QkuRVoEEq0jZhgGU9WmPESyond=A@mail.gmail.com>

Hey guys. Learning R after gaining a background in Python this year,
and I'm translating my Python projects to R now. This is the first
time I'm posting to the mailing list.

Essentially, I have 92 data points in one double that I created from a
netcdf file. Those 92 data points represent a measurement from a
location over the course of three months. From there I've calculated
the median value of the data, which is 8.534281. My goal here is to
test each data point to see if it exceeds the median value, and, next,
calculate the longest streak of days in the 92-day span in which the
data exceeded the median value.

To achieve this in Python, I've created the following function, where
q is a vector of length 92 and q_JJA_median is, of course, the median
value of the dataset.
######################################
def consecutive(q, q_JJA_median):
    is_consecutive = 0
    n = 0
    array_exceed = []
    for i in range(len(q)):
        if q[i] > q_JJA_median:
            n+=1
            is_consecutive = 1
        else:
            if is_consecutive:
                array_exceed.append(n)
                n = 0
                is_consecutive = 0
    if q[i] > q_JJA_median:
        array_exceed.append(n)
    if len(array_exceed) == 0:
        array_exceed = 0
    if type(array_exceed) is int:
        array_exceed = [0]
    return array_exceed
#######################################

Here is my work thus far written for R:
#######################################
is_consecutive = 0
n = 0
array_exceed <- c()
for (i in q) {
  if (i > q_JJA_median) {
    n = n + 1
    is_consecutive = is_consecutive + 1
  }
  else {
    if (is_consecutive) {
      append(array_exceed, n)
      n <- 0
      is_consecutive <- 0
    }
  }
  if (i > q_JJA_median) {
    append(array_exceed,n)
  }
}
#######################################

My code written for R has been changed and manipulated many times, and
none of my attempts have been successful. I'm still new to the syntax
of the R language, so my problem very well could be a product of my
lack of experience.

Additionally, I read on a forum post that using the append function
can be slower than many other options. Is this true? If so, how can I
circumvent that issue?

Thank you!


From sacios at hotmail.it  Mon Jun  6 01:38:58 2016
From: sacios at hotmail.it (Sachin Kuruvithadam)
Date: Sun, 5 Jun 2016 23:38:58 +0000
Subject: [R] Estimating gumbel copula parameter
Message-ID: <DB4PR06MB068563F964E17ED3B5DEB64AB75B0@DB4PR06MB0685.eurprd06.prod.outlook.com>

Hi all. I'm a R newbie, so please bear with me.

I'm fitting nine log losses series (log returns multiplied by -1, so that I have losses on the right and returns on the left) using copulas. My project in more detail:
1) I've filtered the residuals using univariate ARMA-GARCH models, and standardized them dividing by sigma, so that now I have standardized residuals with mean 0 and variance 1 (rugarch package).
2) I modeled the residuals using the generalized pareto distribution family, for all nine series I'm using upper and lower thresholds equal to 0.95 and 0.05 quantiles respectively (spd package).
3) After turning the standardized residuals to their uniform margins using pspd, I'm fitting a Gumbel copula which has upper tail dependence since I'm focusing on losses which are on the right (copula package).
Next part of the work: i) I want to estimate a time-varying Gumbel parameter; ii) given predicted parameter, simulate copula realizations; iii) using the inverse marginal distributions, turn these realizations into standardized residuals; iv) compute returns using ARMA-GARCH specification, convert into simple returns, compute return of equally weighted portfolio and estimate/backtest value at risk and expected shortfall.

Being done with first 2 steps, now I want to estimate a time varying Gumbel. So I'm trying to extract the parameter with a moving window of 500 observations to get an idea of how the time series looks like.

My code looks like this:
theta <- c()
for (i in 1:3345)
{
  theta[i]=summary(fitCopula(gumbel.cop,standardized[i:(i+499),], method="ml"))$coefficients[1]
}

where standardized is a matrix with 9 columns, each with the uniform margin between 0 and 1. So I want to estimate 3345 theta using a window of 500 observations, from theta_1 (obs. 1 to 500) to theta_3345 (obs. 3345 to 4344). However, while running this code, I get:

Error in optim(start, loglikCopula, lower = lower, upper = upper, method = method,  :
  valore iniziale in 'vmmin' non finito

where the last sentence can be translated with "initial value in "vmmin" not finite".

What is this error due to? How can I fix this in the command? It runs for the first 1339 estimates (which I've obtained), but from i=1340 this message shows up and I have NA as estimated value.


Any help is appreciated. Thanks.

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Mon Jun  6 03:15:00 2016
From: esawiek at gmail.com (Ek Esawi)
Date: Sun, 5 Jun 2016 21:15:00 -0400
Subject: [R] Reading and converting time data via read.table
Message-ID: <CA+ZkTxvQhyuW8V1zqhujY4PbuNY=PLb-GTVX3QPYev7ziO7iWg@mail.gmail.com>

Thanks Jim!



The problem is not date data. The problem is time. I figured out that I can
use chron library and then use this expression times(paste0(t2, ":00"))
because my time data are not h:m:s, only h;m.

The problem I am trying to figure out is how to implement [times(paste0(t2,
":00"))] on colclasses so that the whole table is converted to correct time
format which later can be manipulated


Thanks again--EK.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun  6 04:32:29 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 6 Jun 2016 12:32:29 +1000
Subject: [R] find longest consecutive streak in double
In-Reply-To: <CAONpAsogo1-O_ZPxP0W0M4QkuRVoEEq0jZhgGU9WmPESyond=A@mail.gmail.com>
References: <CAONpAsogo1-O_ZPxP0W0M4QkuRVoEEq0jZhgGU9WmPESyond=A@mail.gmail.com>
Message-ID: <CA+8X3fVZY+608k6iKxg5atQ_WG-6qATtOMR62x3fHfuG--MyEg@mail.gmail.com>

Hi Nick,
I think you want to get the maximum run length:

jja<-runif(92,0,16)
med_jja<-median(jja)
med_jja
[1] 7.428935
# get a logical vector of values greater than the median
jja_plus_med<-jja > med_jja
# now get the length of runs
runs_jja_plus_med<-rle(jja_plus_med)
# finally find the maximum run length
max(runs_jja_plus_med$lengths)
[1] 5

Jim


On Mon, Jun 6, 2016 at 5:51 AM, Nick Tulli <nick.tulli.95 at gmail.com> wrote:
> Hey guys. Learning R after gaining a background in Python this year,
> and I'm translating my Python projects to R now. This is the first
> time I'm posting to the mailing list.
>
> Essentially, I have 92 data points in one double that I created from a
> netcdf file. Those 92 data points represent a measurement from a
> location over the course of three months. From there I've calculated
> the median value of the data, which is 8.534281. My goal here is to
> test each data point to see if it exceeds the median value, and, next,
> calculate the longest streak of days in the 92-day span in which the
> data exceeded the median value.
>
> To achieve this in Python, I've created the following function, where
> q is a vector of length 92 and q_JJA_median is, of course, the median
> value of the dataset.
> ######################################
> def consecutive(q, q_JJA_median):
>     is_consecutive = 0
>     n = 0
>     array_exceed = []
>     for i in range(len(q)):
>         if q[i] > q_JJA_median:
>             n+=1
>             is_consecutive = 1
>         else:
>             if is_consecutive:
>                 array_exceed.append(n)
>                 n = 0
>                 is_consecutive = 0
>     if q[i] > q_JJA_median:
>         array_exceed.append(n)
>     if len(array_exceed) == 0:
>         array_exceed = 0
>     if type(array_exceed) is int:
>         array_exceed = [0]
>     return array_exceed
> #######################################
>
> Here is my work thus far written for R:
> #######################################
> is_consecutive = 0
> n = 0
> array_exceed <- c()
> for (i in q) {
>   if (i > q_JJA_median) {
>     n = n + 1
>     is_consecutive = is_consecutive + 1
>   }
>   else {
>     if (is_consecutive) {
>       append(array_exceed, n)
>       n <- 0
>       is_consecutive <- 0
>     }
>   }
>   if (i > q_JJA_median) {
>     append(array_exceed,n)
>   }
> }
> #######################################
>
> My code written for R has been changed and manipulated many times, and
> none of my attempts have been successful. I'm still new to the syntax
> of the R language, so my problem very well could be a product of my
> lack of experience.
>
> Additionally, I read on a forum post that using the append function
> can be slower than many other options. Is this true? If so, how can I
> circumvent that issue?
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Jun  6 04:44:26 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 6 Jun 2016 12:44:26 +1000
Subject: [R] How to specify a data frame column using command line arg?
In-Reply-To: <CAEKTc2OOsyWaCy=RxFSMWrMjg_OxJhAZfKYubGwSCUDKjpt=iw@mail.gmail.com>
References: <CAEKTc2OOsyWaCy=RxFSMWrMjg_OxJhAZfKYubGwSCUDKjpt=iw@mail.gmail.com>
Message-ID: <CA+8X3fURHDR1xezV7s=wDc0mHU_ZMGEcYVtFf=VDhNaHb9Z+FQ@mail.gmail.com>

Hi Doug,
I think this will work for you:

adl1<-read.csv("test.csv")
adl1[,"a"]
[1] 1 4 7

so, adl1[,args[1]] should get you the column that you pass as the
first argument.

Jim


On Mon, Jun 6, 2016 at 5:45 AM, Douglas Johnson <todojo at gmail.com> wrote:
> I'm guessing this is trivial but I've spent two hours searching and reading
> FAQ, tutorial, introductory and 'idiom' documents and haven't found a
> solution. All I want to do is select a data frame column at run time using
> a command line arg. For example, the "test.csv" file contains:
>
> a,b,c
> 1,2,3
> 4,5,6
> 7,8,9
>
> If I run "test.r a", I get [1,4,7].
> If I run "test.r b", I get [2,5,8].
>
> Here's sample code -- how I map args[1] to column/vector 'a' or 'b' or 'c'?
>
> args <- commandArgs(trailingOnly=T)
>
> adl1<-read.csv(file="test.csv",head=T,sep=",")
>
> adl1$SOME-MAGIC-FUNCTION-OR-SYMBOL(args[1])
>
>
> All I'm really trying to do is generate a bunch of scatter plots of column
> 'x' vs. 'y' without writing a separate program for each pair.
>
>
> Thanks,
>
>
> Doug
>
>
>
> --
> http://www.dojopico.org <http://dojopico.org>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Jun  6 05:20:07 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 5 Jun 2016 23:20:07 -0400
Subject: [R] detecting if a variable has changed
In-Reply-To: <CAGxFJbShgYUVSs2O8GPtWE9MxBEaRRXoVU=mPHvzH2-VxAruGw@mail.gmail.com>
References: <87d1nvwmwy.wl-neal@walfield.org>
	<XFMail.20160605190114.Ted.Harding@wlandres.net>
	<CAGxFJbShgYUVSs2O8GPtWE9MxBEaRRXoVU=mPHvzH2-VxAruGw@mail.gmail.com>
Message-ID: <80a72f7f-c1de-c52d-79fd-c53447ed6e97@gmail.com>

On 05/06/2016 2:13 PM, Bert Gunter wrote:
> Nope, Ted. I asked for  a O(log(n)) solution, not an O(n) one.

I don't think that's possible with a numeric vector.  Inserting an entry 
at a random location is an O(n) operation, since you need to move all 
following values out of the way.

Duncan Murdoch

>
> I will check out the data.table package, as suggested.
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Jun 5, 2016 at 11:01 AM, Ted Harding <Ted.Harding at wlandres.net> wrote:
>> Surely it is straightforward, since the vector (say 'X') is already sorted?
>>
>> Example (raw code with explicit example):
>>
>> set.seed(54321)
>> X <- sort(runif(10))
>> # X ## The initial sorted vector
>> # [1] 0.04941009 0.17669234 0.20913493 0.21651016 0.27439354
>> # [6] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>>
>> y <- runif(1)
>> # y ## The new value to be inserted
>> [1] 0.1366424
>>
>> Y <- c(X[X<=y],y,X[X>y]) ## Now insert y into X:
>> Y
>> [1] 0.04941009 0.13664239 0.17669234 0.20913493 0.21651016 0.27439354
>> [7] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>>
>> ## And there it is at Y[2]
>>
>> Easy to make such a function!
>> Best wishes to all,
>> Ted.
>>
>> On 05-Jun-2016 17:44:29 Neal H. Walfield wrote:
>>> On Sun, 05 Jun 2016 19:34:38 +0200,
>>> Bert Gunter wrote:
>>>> This help thread suggested a question to me:
>>>>
>>>> Is there a function in some package that efficiently (I.e. O(log(n)) )
>>>> inserts a single new element into the correct location in an
>>>> already-sorted vector? My assumption here is that doing it via sort()
>>>> is inefficient, but maybe that is incorrect. Please correct me if so.
>>>
>>> I think data.table will do this if the the column is marked
>>> appropriately.
>>>
>>>> I realize that it would be straightforward to write such a function,
>>>> but I just wondered if it already exists. My google & rseek searches
>>>> did not succeed, but maybe I used the wrong keywords.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Sun, Jun 5, 2016 at 9:47 AM, William Dunlap via R-help
>>>> <r-help at r-project.org> wrote:
>>>>> I don't know what you mean by "without having to use any special
>>>>> interfaces", but "reference classes" will do what I think you want.  E.g.,
>>>>> the following makes a class called 'SortedNumeric' that only sorts the
>>>>> vector when you want to get its value, not when you append values.  It
>>>>> stores the sorted vector so it does not get resorted each time you ask for
>>>>> it.
>>>>>
>>>>> SortedNumeric <- setRefClass("sortedNumeric",
>>>>>             fields = list(
>>>>>                 fData = "numeric",
>>>>>                 fIsUnsorted = "logical"),
>>>>>             methods = list(
>>>>>                 initialize = function(Data = numeric(), isUnsorted = TRUE)
>>>>>                 {
>>>>>                     fData <<- Data
>>>>>                     stopifnot(is.logical(isUnsorted),
>>>>>                               length(isUnsorted)==1,
>>>>>                               !is.na(isUnsorted))
>>>>>                     fIsUnsorted <<- isUnsorted
>>>>>                 },
>>>>>                 getData = function() {
>>>>>                     if (isUnsorted) {
>>>>>                         fData <<- sort(fData)
>>>>>                         fIsUnsorted <<- FALSE
>>>>>                     }
>>>>>                     fData
>>>>>                 },
>>>>>                 appendData = function(newEntries) {
>>>>>                     fData <<- c(fData, newEntries)
>>>>>                     fIsUnsorted <<- TRUE
>>>>>                 }
>>>>>             ))
>>>>>
>>>>> Use it as:
>>>>>
>>>>>> x <- SortedNumeric$new()
>>>>>> x$appendData(c(4,2,5))
>>>>>> x$appendData(c(1,8,9))
>>>>>> x
>>>>> Reference class object of class "sortedNumeric"
>>>>> Field "fData":
>>>>> [1] 4 2 5 1 8 9
>>>>> Field "fIsUnsorted":
>>>>> [1] TRUE
>>>>>> x$getData()
>>>>> [1] 1 2 4 5 8 9
>>>>>> x
>>>>> Reference class object of class "sortedNumeric"
>>>>> Field "fData":
>>>>> [1] 1 2 4 5 8 9
>>>>> Field "fIsUnsorted":
>>>>> [1] FALSE
>>>>>
>>>>>
>>>>> Outside of base R, I think the R6 package gives another approach to this.
>>>>>
>>>>>
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>> On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org>
>>>>> wrote:
>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I have a huge list.  Normally it is sorted, but I want to be able to
>>>>>> add elements to it without having to use any special interfaces and
>>>>>> then sort it on demand.  My idea is to use something like weak
>>>>>> references combined with attributes.  Consider:
>>>>>>
>>>>>>   # Initialization.
>>>>>>   l = as.list(1:10)
>>>>>>   # Note that it is sorted.
>>>>>>   attr(l, 'sorted') = weakref(l)
>>>>>>
>>>>>>   # Modify the list.
>>>>>>   l = append(l, 1:3)
>>>>>>
>>>>>>   # Check if the list is still sorted.  (I use identical here, but it
>>>>>>   # probably too heavy weight: I just need to compare the addresses.)
>>>>>>   if (! identical(l, attr(l, 'sorted'))) {
>>>>>>     l = sort(unlist(l))
>>>>>>     attr(l, 'sorted') = weakref(l)
>>>>>>   }
>>>>>>   # Do operation that requires sorted list.
>>>>>>   ...
>>>>>>
>>>>>> This is obviously a toy example.  I'm not actually sorting integers
>>>>>> and I may use a matrix instead of a list.
>>>>>>
>>>>>> I've read:
>>>>>>
>>>>>>   http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>>>>>>   http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>>>>>>
>>>>>> As far as I can tell, weakrefs are only available via the C API.  Is
>>>>>> there a way to do what I want in R without resorting to C code?  Is
>>>>>> what I want to do better achieved using something other than weakrefs?
>>>>>>
>>>>>> Thanks!
>>>>>>
>>>>>> :) Neal
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> -------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>> Date: 05-Jun-2016  Time: 19:01:10
>> This message was sent by XFMail
>> -------------------------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Mon Jun  6 07:02:00 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 6 Jun 2016 15:02:00 +1000
Subject: [R] How to specify a data frame column using command line arg?
In-Reply-To: <CAEKTc2MRYQSi45QO_X57gK6eyeJdwzhVyCEDSEbxB5q+wXBU_g@mail.gmail.com>
References: <CAEKTc2OOsyWaCy=RxFSMWrMjg_OxJhAZfKYubGwSCUDKjpt=iw@mail.gmail.com>
	<CA+8X3fURHDR1xezV7s=wDc0mHU_ZMGEcYVtFf=VDhNaHb9Z+FQ@mail.gmail.com>
	<CAEKTc2MRYQSi45QO_X57gK6eyeJdwzhVyCEDSEbxB5q+wXBU_g@mail.gmail.com>
Message-ID: <CA+8X3fXURF=PrG_9RjJEw57XpyGeKvA+WWjAYvQwB0T2VpG1cw@mail.gmail.com>

Yes, I see what you want. I can't run this myself as my work computer
runs Windows and insists on starting Statistica when I run an R file
in batch mode. What about:

plot(adl1[,args[1]],adl1[,args[2]])

I just noticed that you are plotting in ggplot, so this won't help. Maybe:

aes(x=args[1], y=args[2])

?

Jim


On Mon, Jun 6, 2016 at 1:29 PM, Douglas Johnson <todojo at gmail.com> wrote:
> Hi Jim,
>
> Thanks for the quick reply. I was trying to be clear but I think maybe the
> example was too simple. What I really have is a csv file with lots of
> columns (let's say 26) with a header (say a,b,c,d,e,,,,,z). I want to
> generate lots of scatter plots -- 'a' vs. 'b' and 'd' vs 'j' and so on and
> so on. I don't want to create a separate program for every combination of
> columns -- that would be hundreds of programs. I just want one program that
> takes three args --
> 1) the csv file name
> 2) the name of the 'x-axis' column (e.g. 'd')
> 3) the name of the 'y-asix' column (e.g. 'j')
>
> so can run:
>
> scatter_plot.r sample01.csv a b
> scatter_plot.r sample01.csv d j
> .....
>
> I can't figure out how to get  the column names from the args[] to the
> aes(x=?????, y=?????).
> There must be some kind of indirect  reference or eval() or substitute()
> operator in R but I can't find it.
>
> Anyway, thanks for taking a shot at this.
>
> Best,
>
> doug
>
>
>
>
> On Sun, Jun 5, 2016 at 10:44 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Doug,
>> I think this will work for you:
>>
>> adl1<-read.csv("test.csv")
>> adl1[,"a"]
>> [1] 1 4 7
>>
>> so, adl1[,args[1]] should get you the column that you pass as the
>> first argument.
>>
>> Jim
>>
>>
>> On Mon, Jun 6, 2016 at 5:45 AM, Douglas Johnson <todojo at gmail.com> wrote:
>> > I'm guessing this is trivial but I've spent two hours searching and
>> > reading
>> > FAQ, tutorial, introductory and 'idiom' documents and haven't found a
>> > solution. All I want to do is select a data frame column at run time
>> > using
>> > a command line arg. For example, the "test.csv" file contains:
>> >
>> > a,b,c
>> > 1,2,3
>> > 4,5,6
>> > 7,8,9
>> >
>> > If I run "test.r a", I get [1,4,7].
>> > If I run "test.r b", I get [2,5,8].
>> >
>> > Here's sample code -- how I map args[1] to column/vector 'a' or 'b' or
>> > 'c'?
>> >
>> > args <- commandArgs(trailingOnly=T)
>> >
>> > adl1<-read.csv(file="test.csv",head=T,sep=",")
>> >
>> > adl1$SOME-MAGIC-FUNCTION-OR-SYMBOL(args[1])
>> >
>> >
>> > All I'm really trying to do is generate a bunch of scatter plots of
>> > column
>> > 'x' vs. 'y' without writing a separate program for each pair.
>> >
>> >
>> > Thanks,
>> >
>> >
>> > Doug
>> >
>> >
>> >
>> > --
>> > http://www.dojopico.org <http://dojopico.org>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> http://www.dojopico.org


From michu.kom at gmail.com  Mon Jun  6 09:38:08 2016
From: michu.kom at gmail.com (Michu Kom)
Date: Mon, 6 Jun 2016 09:38:08 +0200
Subject: [R] Knitr R - how to draw plot exactly at place of plot function
 call in output document?
Message-ID: <CAEJSOqi96Qt6O5qhZbTE5ax8GPNoC31t5vN_gjFgGazhbiDFvQ@mail.gmail.com>

My R script run with Knitr generates a statistic summary of electrode pairs
accompanied with plots. The problem is that knitr does not render plots in
correct sections. In section for pair A knitr do not wait for plot and
start to evaluate code for output summary for pair B. So in section B knitr
places plot from section A among printed output summary for pair B.

My function analizePair calculates some statistics and print them out. I
call a ezPlot function inside analizePair function.

knitr::opts_chunk$set(fig.show = 'asis') # 'hold' option is not proper
for my needs
for(pair in pairsLabels)
    {
        print("----------")
        print("Analysing single pair of electrodes...")
        print("----------")
        print(pair)

        analizePair(pairLabel = pair)

        print("----------")
        print("Analysing pair finished.")
        print("----------")
    }

I also tried to put Sys.sleep(2) after analizePair, but it do not solve the
problem.

How to force knitr/R to wait until plot is generated and put before
starting next section (next iteration of for loop) ?

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Jun  6 09:46:06 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 6 Jun 2016 09:46:06 +0200
Subject: [R] detecting if a variable has changed
In-Reply-To: <80a72f7f-c1de-c52d-79fd-c53447ed6e97@gmail.com>
References: <87d1nvwmwy.wl-neal@walfield.org>
	<XFMail.20160605190114.Ted.Harding@wlandres.net>
	<CAGxFJbShgYUVSs2O8GPtWE9MxBEaRRXoVU=mPHvzH2-VxAruGw@mail.gmail.com>
	<80a72f7f-c1de-c52d-79fd-c53447ed6e97@gmail.com>
Message-ID: <2BC3B8EA-F90A-45CB-B969-D3CB0F00D530@gmail.com>


> On 06 Jun 2016, at 05:20 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 05/06/2016 2:13 PM, Bert Gunter wrote:
>> Nope, Ted. I asked for  a O(log(n)) solution, not an O(n) one.
> 
> I don't think that's possible with a numeric vector.  Inserting an entry at a random location is an O(n) operation, since you need to move all following values out of the way.

Yep. To do better, you probably need a different storage format (like a binary tree) or specialized hardware - single-instruction/multiple-data architecture devices come to mind. 

-pd

> 
> Duncan Murdoch
> 
>> 
>> I will check out the data.table package, as suggested.
>> 
>> -- Bert
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Sun, Jun 5, 2016 at 11:01 AM, Ted Harding <Ted.Harding at wlandres.net> wrote:
>>> Surely it is straightforward, since the vector (say 'X') is already sorted?
>>> 
>>> Example (raw code with explicit example):
>>> 
>>> set.seed(54321)
>>> X <- sort(runif(10))
>>> # X ## The initial sorted vector
>>> # [1] 0.04941009 0.17669234 0.20913493 0.21651016 0.27439354
>>> # [6] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>>> 
>>> y <- runif(1)
>>> # y ## The new value to be inserted
>>> [1] 0.1366424
>>> 
>>> Y <- c(X[X<=y],y,X[X>y]) ## Now insert y into X:
>>> Y
>>> [1] 0.04941009 0.13664239 0.17669234 0.20913493 0.21651016 0.27439354
>>> [7] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>>> 
>>> ## And there it is at Y[2]
>>> 
>>> Easy to make such a function!
>>> Best wishes to all,
>>> Ted.
>>> 
>>> On 05-Jun-2016 17:44:29 Neal H. Walfield wrote:
>>>> On Sun, 05 Jun 2016 19:34:38 +0200,
>>>> Bert Gunter wrote:
>>>>> This help thread suggested a question to me:
>>>>> 
>>>>> Is there a function in some package that efficiently (I.e. O(log(n)) )
>>>>> inserts a single new element into the correct location in an
>>>>> already-sorted vector? My assumption here is that doing it via sort()
>>>>> is inefficient, but maybe that is incorrect. Please correct me if so.
>>>> 
>>>> I think data.table will do this if the the column is marked
>>>> appropriately.
>>>> 
>>>>> I realize that it would be straightforward to write such a function,
>>>>> but I just wondered if it already exists. My google & rseek searches
>>>>> did not succeed, but maybe I used the wrong keywords.
>>>>> 
>>>>> Cheers,
>>>>> Bert
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> 
>>>>> On Sun, Jun 5, 2016 at 9:47 AM, William Dunlap via R-help
>>>>> <r-help at r-project.org> wrote:
>>>>>> I don't know what you mean by "without having to use any special
>>>>>> interfaces", but "reference classes" will do what I think you want.  E.g.,
>>>>>> the following makes a class called 'SortedNumeric' that only sorts the
>>>>>> vector when you want to get its value, not when you append values.  It
>>>>>> stores the sorted vector so it does not get resorted each time you ask for
>>>>>> it.
>>>>>> 
>>>>>> SortedNumeric <- setRefClass("sortedNumeric",
>>>>>>            fields = list(
>>>>>>                fData = "numeric",
>>>>>>                fIsUnsorted = "logical"),
>>>>>>            methods = list(
>>>>>>                initialize = function(Data = numeric(), isUnsorted = TRUE)
>>>>>>                {
>>>>>>                    fData <<- Data
>>>>>>                    stopifnot(is.logical(isUnsorted),
>>>>>>                              length(isUnsorted)==1,
>>>>>>                              !is.na(isUnsorted))
>>>>>>                    fIsUnsorted <<- isUnsorted
>>>>>>                },
>>>>>>                getData = function() {
>>>>>>                    if (isUnsorted) {
>>>>>>                        fData <<- sort(fData)
>>>>>>                        fIsUnsorted <<- FALSE
>>>>>>                    }
>>>>>>                    fData
>>>>>>                },
>>>>>>                appendData = function(newEntries) {
>>>>>>                    fData <<- c(fData, newEntries)
>>>>>>                    fIsUnsorted <<- TRUE
>>>>>>                }
>>>>>>            ))
>>>>>> 
>>>>>> Use it as:
>>>>>> 
>>>>>>> x <- SortedNumeric$new()
>>>>>>> x$appendData(c(4,2,5))
>>>>>>> x$appendData(c(1,8,9))
>>>>>>> x
>>>>>> Reference class object of class "sortedNumeric"
>>>>>> Field "fData":
>>>>>> [1] 4 2 5 1 8 9
>>>>>> Field "fIsUnsorted":
>>>>>> [1] TRUE
>>>>>>> x$getData()
>>>>>> [1] 1 2 4 5 8 9
>>>>>>> x
>>>>>> Reference class object of class "sortedNumeric"
>>>>>> Field "fData":
>>>>>> [1] 1 2 4 5 8 9
>>>>>> Field "fIsUnsorted":
>>>>>> [1] FALSE
>>>>>> 
>>>>>> 
>>>>>> Outside of base R, I think the R6 package gives another approach to this.
>>>>>> 
>>>>>> 
>>>>>> Bill Dunlap
>>>>>> TIBCO Software
>>>>>> wdunlap tibco.com
>>>>>> 
>>>>>> On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org>
>>>>>> wrote:
>>>>>> 
>>>>>>> Hi,
>>>>>>> 
>>>>>>> I have a huge list.  Normally it is sorted, but I want to be able to
>>>>>>> add elements to it without having to use any special interfaces and
>>>>>>> then sort it on demand.  My idea is to use something like weak
>>>>>>> references combined with attributes.  Consider:
>>>>>>> 
>>>>>>>  # Initialization.
>>>>>>>  l = as.list(1:10)
>>>>>>>  # Note that it is sorted.
>>>>>>>  attr(l, 'sorted') = weakref(l)
>>>>>>> 
>>>>>>>  # Modify the list.
>>>>>>>  l = append(l, 1:3)
>>>>>>> 
>>>>>>>  # Check if the list is still sorted.  (I use identical here, but it
>>>>>>>  # probably too heavy weight: I just need to compare the addresses.)
>>>>>>>  if (! identical(l, attr(l, 'sorted'))) {
>>>>>>>    l = sort(unlist(l))
>>>>>>>    attr(l, 'sorted') = weakref(l)
>>>>>>>  }
>>>>>>>  # Do operation that requires sorted list.
>>>>>>>  ...
>>>>>>> 
>>>>>>> This is obviously a toy example.  I'm not actually sorting integers
>>>>>>> and I may use a matrix instead of a list.
>>>>>>> 
>>>>>>> I've read:
>>>>>>> 
>>>>>>>  http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>>>>>>>  http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>>>>>>> 
>>>>>>> As far as I can tell, weakrefs are only available via the C API.  Is
>>>>>>> there a way to do what I want in R without resorting to C code?  Is
>>>>>>> what I want to do better achieved using something other than weakrefs?
>>>>>>> 
>>>>>>> Thanks!
>>>>>>> 
>>>>>>> :) Neal
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>> 
>>>>>>        [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> -------------------------------------------------
>>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>>> Date: 05-Jun-2016  Time: 19:01:10
>>> This message was sent by XFMail
>>> -------------------------------------------------
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ulrik.stervbo at gmail.com  Mon Jun  6 10:04:21 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 06 Jun 2016 08:04:21 +0000
Subject: [R] Knitr R - how to draw plot exactly at place of plot
 function call in output document?
In-Reply-To: <CAEJSOqi96Qt6O5qhZbTE5ax8GPNoC31t5vN_gjFgGazhbiDFvQ@mail.gmail.com>
References: <CAEJSOqi96Qt6O5qhZbTE5ax8GPNoC31t5vN_gjFgGazhbiDFvQ@mail.gmail.com>
Message-ID: <CAKVAULPhdUMdrU4Gk+pJ5w=YCB=+pg7+zTG6cWG6Bmgy0B-AhA@mail.gmail.com>

Hi Michu,

What document type do you generate? I usually make just html and have no
problems. If you create a pdf, please remember this is done through LaTeX
and your problem could arise from the floats of LaTeX.

For other output I have no idea.

Hope this helps
Ulrik

Michu Kom <michu.kom at gmail.com> schrieb am Mo., 6. Juni 2016 09:41:

> My R script run with Knitr generates a statistic summary of electrode pairs
> accompanied with plots. The problem is that knitr does not render plots in
> correct sections. In section for pair A knitr do not wait for plot and
> start to evaluate code for output summary for pair B. So in section B knitr
> places plot from section A among printed output summary for pair B.
>
> My function analizePair calculates some statistics and print them out. I
> call a ezPlot function inside analizePair function.
>
> knitr::opts_chunk$set(fig.show = 'asis') # 'hold' option is not proper
> for my needs
> for(pair in pairsLabels)
>     {
>         print("----------")
>         print("Analysing single pair of electrodes...")
>         print("----------")
>         print(pair)
>
>         analizePair(pairLabel = pair)
>
>         print("----------")
>         print("Analysing pair finished.")
>         print("----------")
>     }
>
> I also tried to put Sys.sleep(2) after analizePair, but it do not solve the
> problem.
>
> How to force knitr/R to wait until plot is generated and put before
> starting next section (next iteration of for loop) ?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Jun  6 12:18:26 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 6 Jun 2016 10:18:26 +0000
Subject: [R] Reading and converting time data via read.table
In-Reply-To: <CA+ZkTxsDR3J7=MK2Y9qBgsoandQ9YgQ8FnszBnOtz3yy5159Bw@mail.gmail.com>
References: <CA+ZkTxsDR3J7=MK2Y9qBgsoandQ9YgQ8FnszBnOtz3yy5159Bw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502DFEC@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ek Esawi
> Sent: Sunday, June 5, 2016 2:54 PM
> To: r-help at r-project.org
> Subject: [R] Reading and converting time data via read.table
>
> Hi All--
>
>
>
> I am relatively new to R. I am reading a csv file via read.table (MyFile).
> The data types in the file are date, string, integer, and time. I was able to
> read all the data and manipulated correctly except time, e.g., 12:30. I used
> as.Date to convert date and string and integer were easily done. I could not
> figure out how to convert the time data correctly. I tried chron but w/o
> success and I read that POSIXlt and POSIXct work only for date and time (e.g.

If you used strptime for converting your datae/time value you can tune it by format to be able to read differently formated data.


> strptime("01/02/1999, 12:30:20", format="%d/%m/%Y, %H:%M:%S")
[1] "1999-02-01 12:30:20 CET"
> strptime("01/02/1999, 12:30", format="%d/%m/%Y, %H:%M")
[1] "1999-02-01 12:30:00 CET"
> strptime("01/02/1999, 12", format="%d/%m/%Y, %H")
[1] "1999-02-01 12:00:00 CET"
>

> str(strptime("01/02/1999, 12", format="%d/%m/%Y, %H"))
 POSIXlt[1:1], format: "1999-02-01 12:00:00"
>

Regards
Petr


> 01/02/1999, 12:30:20). I did not try the lubridate package. Is there a way to
> read time data without date attached to it like mine?
>
>
>
> I am grateful for any help and thanks in advance?EKE
>
>
>
> Here is an example of my data when read into R via read.table
>
>
>
>                 AA          Date         Name     T1          T2
> N1
>
> 1              312171  7/1/1995       OF      13:37      1:43         123
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From istazahn at gmail.com  Mon Jun  6 13:22:10 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 6 Jun 2016 07:22:10 -0400
Subject: [R] How to specify a data frame column using command line arg?
In-Reply-To: <CA+8X3fXURF=PrG_9RjJEw57XpyGeKvA+WWjAYvQwB0T2VpG1cw@mail.gmail.com>
References: <CAEKTc2OOsyWaCy=RxFSMWrMjg_OxJhAZfKYubGwSCUDKjpt=iw@mail.gmail.com>
	<CA+8X3fURHDR1xezV7s=wDc0mHU_ZMGEcYVtFf=VDhNaHb9Z+FQ@mail.gmail.com>
	<CAEKTc2MRYQSi45QO_X57gK6eyeJdwzhVyCEDSEbxB5q+wXBU_g@mail.gmail.com>
	<CA+8X3fXURF=PrG_9RjJEw57XpyGeKvA+WWjAYvQwB0T2VpG1cw@mail.gmail.com>
Message-ID: <CA+vqiLFwZv37YotwY+G3kqDXbKhwv-0-YHQx+DR5Hs6VJseMEg@mail.gmail.com>

Hi Doug,

ggplot lets you map variables to aesthetics in a few different ways,
including passing to variable names as strings to aes_string. See
?aes_string for details.

Best,
Ista
On Jun 6, 2016 1:03 AM, "Jim Lemon" <drjimlemon at gmail.com> wrote:

> Yes, I see what you want. I can't run this myself as my work computer
> runs Windows and insists on starting Statistica when I run an R file
> in batch mode. What about:
>
> plot(adl1[,args[1]],adl1[,args[2]])
>
> I just noticed that you are plotting in ggplot, so this won't help. Maybe:
>
> aes(x=args[1], y=args[2])
>
> ?
>
> Jim
>
>
> On Mon, Jun 6, 2016 at 1:29 PM, Douglas Johnson <todojo at gmail.com> wrote:
> > Hi Jim,
> >
> > Thanks for the quick reply. I was trying to be clear but I think maybe
> the
> > example was too simple. What I really have is a csv file with lots of
> > columns (let's say 26) with a header (say a,b,c,d,e,,,,,z). I want to
> > generate lots of scatter plots -- 'a' vs. 'b' and 'd' vs 'j' and so on
> and
> > so on. I don't want to create a separate program for every combination of
> > columns -- that would be hundreds of programs. I just want one program
> that
> > takes three args --
> > 1) the csv file name
> > 2) the name of the 'x-axis' column (e.g. 'd')
> > 3) the name of the 'y-asix' column (e.g. 'j')
> >
> > so can run:
> >
> > scatter_plot.r sample01.csv a b
> > scatter_plot.r sample01.csv d j
> > .....
> >
> > I can't figure out how to get  the column names from the args[] to the
> > aes(x=?????, y=?????).
> > There must be some kind of indirect  reference or eval() or substitute()
> > operator in R but I can't find it.
> >
> > Anyway, thanks for taking a shot at this.
> >
> > Best,
> >
> > doug
> >
> >
> >
> >
> > On Sun, Jun 5, 2016 at 10:44 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Doug,
> >> I think this will work for you:
> >>
> >> adl1<-read.csv("test.csv")
> >> adl1[,"a"]
> >> [1] 1 4 7
> >>
> >> so, adl1[,args[1]] should get you the column that you pass as the
> >> first argument.
> >>
> >> Jim
> >>
> >>
> >> On Mon, Jun 6, 2016 at 5:45 AM, Douglas Johnson <todojo at gmail.com>
> wrote:
> >> > I'm guessing this is trivial but I've spent two hours searching and
> >> > reading
> >> > FAQ, tutorial, introductory and 'idiom' documents and haven't found a
> >> > solution. All I want to do is select a data frame column at run time
> >> > using
> >> > a command line arg. For example, the "test.csv" file contains:
> >> >
> >> > a,b,c
> >> > 1,2,3
> >> > 4,5,6
> >> > 7,8,9
> >> >
> >> > If I run "test.r a", I get [1,4,7].
> >> > If I run "test.r b", I get [2,5,8].
> >> >
> >> > Here's sample code -- how I map args[1] to column/vector 'a' or 'b' or
> >> > 'c'?
> >> >
> >> > args <- commandArgs(trailingOnly=T)
> >> >
> >> > adl1<-read.csv(file="test.csv",head=T,sep=",")
> >> >
> >> > adl1$SOME-MAGIC-FUNCTION-OR-SYMBOL(args[1])
> >> >
> >> >
> >> > All I'm really trying to do is generate a bunch of scatter plots of
> >> > column
> >> > 'x' vs. 'y' without writing a separate program for each pair.
> >> >
> >> >
> >> > Thanks,
> >> >
> >> >
> >> > Doug
> >> >
> >> >
> >> >
> >> > --
> >> > http://www.dojopico.org <http://dojopico.org>
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > http://www.dojopico.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Mon Jun  6 14:29:30 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 6 Jun 2016 14:29:30 +0200
Subject: [R] Merging variables
Message-ID: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>

Hi All,

I merged two datasets:

ds_merge1 <- merge(x = ds_bw_customer_4_match, y = 
ds_zww_customer_4_match,
  by.x = "customer", by.y = "customer",
  all.x = TRUE, all.y = FALSE)

R created a new dataset with the variables customer.x and customer.y. I 
would like to merge these two variable back together. I wrote a little 
function (code can be run) for it:

-- cut --

customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
ds_test <- data.frame(customer.x, customer.y, stringsAsFactors = FALSE)

t_merge_variables <-
  function(dataset,
           var1,
           var2,
           merged_var) {
 
    # Initialize
    dataset[[merged_var]] = rep(NA, nrow(dataset))
    dataset[["mismatch"]] = rep(NA, nrow(dataset))
 
    for (i in 1:nrow(dataset)) {
 
      # Check 1: var1 missing, var2 missing
      if (is.na(dataset[[i, var1]]) &
          is.na(dataset[[i, var2]])) {
        dataset[["mismatch"]] <- 1  # var1 & var2 are missing
 
      # Check 2: var1 filled, var2 missing
      } else if (!is.na(dataset[[i, var1]]) &
                 is.na(dataset[[i, var2]])) {
        dataset[[i, merged_var]] <- dataset[[i, var1]]
        dataset[["mismatch"]] <- 0
 
      # Check 3: var1 missing, var2 filled
      } else if (is.na(dataset[[i, var1]]) &
                 !is.na(dataset[i, var2])) {
        dataset[[i, merged_var]] <- dataset[[i, var2]]
        dataset[["mismatch"]] <-  0
 
      # Check 4: var1 == var2
      } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
      dataset[[i, merged_var]] <- dataset[[i, var1]]
      dataset[["mismatch"]] <- 0

      # Leftover: var1 != var2
      } else {
        dataset[[i, merged_var]] <- NA
        dataset[["mismatch"]] <- 2  # var1 != var2
      }  # end if
    }  # end for
    return(dataset)
}

ds_var_merge1 <- t_merge_variables(dataset = ds_test,
  var1 = "customer.x",
  var2 = "customer.y",
  merged_var = "customer")

ds_var_merge1

-- cut --

It is executed without error but delivers the wrong values in the variable 
"mismatch". This variable is always 1 although it should be NA, 1 or 2 
respectively.

Can you tell me why the variable is not correctly set?

Kind regards

Georg


From changrong.ge at gmail.com  Mon Jun  6 07:07:15 2016
From: changrong.ge at gmail.com (Changrong Ge)
Date: Mon, 6 Jun 2016 07:07:15 +0200
Subject: [R] How to specify a data frame column using command line arg?
In-Reply-To: <CA+NGhb=3pzArFXLorfmfqhn0vaQoYy2gAcyYNg-qNpaWGbn+cQ@mail.gmail.com>
References: <CAEKTc2OOsyWaCy=RxFSMWrMjg_OxJhAZfKYubGwSCUDKjpt=iw@mail.gmail.com>
	<CA+NGhb=3pzArFXLorfmfqhn0vaQoYy2gAcyYNg-qNpaWGbn+cQ@mail.gmail.com>
Message-ID: <CA+NGhbkGSfpx+H9iTu5iJLXQYPvv5Rn2op8LO0u=m73yw+67nQ@mail.gmail.com>

>
> Hi,
>     I have recently made similar scatter plot.
>     Suppose you have a data frame "data.csv" and the first column is not
> what you want to plot but rather something informative such as ID, Class,
> Group, etc which might not be your case (but would be very nice if you want
> to color your scatter plots or add cutoff line, etc). The code below would
> work well by printing out figures for all possible column i vs column j.
>
> for(i in names(data[,-1])){
> for(j in names(data[,-1])){
>
> png(paste(i," vs " ,j,".png", sep=""), width=4, height=6, units="in",
> res=300)
>
> plot(data[,i],data[,j],xlab=i,ylab=j,log="xy",pch=16)
>
>
> dev.off()
> print(c(i,j))
> }
> }
>
> Good luck
> Changrong
>
> On Sun, Jun 5, 2016 at 9:45 PM, Douglas Johnson <todojo at gmail.com> wrote:
>
>> I'm guessing this is trivial but I've spent two hours searching and
>> reading
>> FAQ, tutorial, introductory and 'idiom' documents and haven't found a
>> solution. All I want to do is select a data frame column at run time using
>> a command line arg. For example, the "test.csv" file contains:
>>
>> a,b,c
>> 1,2,3
>> 4,5,6
>> 7,8,9
>>
>> If I run "test.r a", I get [1,4,7].
>> If I run "test.r b", I get [2,5,8].
>>
>> Here's sample code -- how I map args[1] to column/vector 'a' or 'b' or
>> 'c'?
>>
>> args <- commandArgs(trailingOnly=T)
>>
>> adl1<-read.csv(file="test.csv",head=T,sep=",")
>>
>> adl1$SOME-MAGIC-FUNCTION-OR-SYMBOL(args[1])
>>
>>
>> All I'm really trying to do is generate a bunch of scatter plots of column
>> 'x' vs. 'y' without writing a separate program for each pair.
>>
>>
>> Thanks,
>>
>>
>> Doug
>>
>>
>>
>> --
>> http://www.dojopico.org <http://dojopico.org>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
>
> Changrong Ge, PhD
>
> Division of Medical Inflammation Research
> Department of Medical Biochemistry and Biophysics (MBB)
> Karolinska Institutet
> Scheeles v?g 2, B2 Plan 4
> SE-171 77 Stockholm
> Sweden
> Tel:  +46-8-524 86337 ,   Mobile: +46-(0)76-2878 029
> Fax: +46-8-524 87750 ,  Email: changrong.ge at ki.se <changrong at dbb.su.se>
>  or changrong.ge at gmail.com
>
>


-- 

Changrong Ge, PhD

Division of Medical Inflammation Research
Department of Medical Biochemistry and Biophysics (MBB)
Karolinska Institutet
Scheeles v?g 2, B2 Plan 4
SE-171 77 Stockholm
Sweden
Tel:  +46-8-524 86337 ,   Mobile: +46-(0)76-2878 029
Fax: +46-8-524 87750 ,  Email: changrong.ge at ki.se <changrong at dbb.su.se> or
changrong.ge at gmail.com

	[[alternative HTML version deleted]]


From elisadicristina at gmail.com  Mon Jun  6 14:18:56 2016
From: elisadicristina at gmail.com (Elisa Di Cristina)
Date: Mon, 6 Jun 2016 14:18:56 +0200
Subject: [R] BootChainLadder problem
Message-ID: <FEEA222ECFFF4726B295BDB24B0E1FC7@u32uPC>



I am using ChainLadder package for statistical analysis of a run-off triangle with I=17 and J=14. When I use BootChainLadder() it appears on R console "Number of origin periods has to be equal or greater then the number of development periods". But I have origin periods greater then development periods! I tried to add other arguments and to change the number of simulation (R argument) but it appears the same error ever. Could someone help me, please?
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Jun  6 14:48:11 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Jun 2016 08:48:11 -0400
Subject: [R] Merging variables
In-Reply-To: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
Message-ID: <D65DA83B-96A7-4646-B053-1115F5950408@comcast.net>

You loop through each

Sent from my iPhone

> On Jun 6, 2016, at 8:29 AM, G.Maubach at weinwolf.de wrote:
> 
> Hi All,
> 
> I merged two datasets:
> 
> ds_merge1 <- merge(x = ds_bw_customer_4_match, y = 
> ds_zww_customer_4_match,
>  by.x = "customer", by.y = "customer",
>  all.x = TRUE, all.y = FALSE)
> 
> R created a new dataset with the variables customer.x and customer.y. I 
> would like to merge these two variable back together. I wrote a little 
> function (code can be run) for it:
> 
> -- cut --
> 
> customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> ds_test <- data.frame(customer.x, customer.y, stringsAsFactors = FALSE)
> 
> t_merge_variables <-
>  function(dataset,
>           var1,
>           var2,
>           merged_var) {
> 
>    # Initialize
>    dataset[[merged_var]] = rep(NA, nrow(dataset))
>    dataset[["mismatch"]] = rep(NA, nrow(dataset))
> 
>    for (i in 1:nrow(dataset)) {
> 
>      # Check 1: var1 missing, var2 missing
>      if (is.na(dataset[[i, var1]]) &
>          is.na(dataset[[i, var2]])) {
>        dataset[["mismatch"]] <- 1  # var1 & var2 are missing
> 
>      # Check 2: var1 filled, var2 missing
>      } else if (!is.na(dataset[[i, var1]]) &
>                 is.na(dataset[[i, var2]])) {
>        dataset[[i, merged_var]] <- dataset[[i, var1]]
>        dataset[["mismatch"]] <- 0
> 
>      # Check 3: var1 missing, var2 filled
>      } else if (is.na(dataset[[i, var1]]) &
>                 !is.na(dataset[i, var2])) {
>        dataset[[i, merged_var]] <- dataset[[i, var2]]
>        dataset[["mismatch"]] <-  0
> 
>      # Check 4: var1 == var2
>      } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
>      dataset[[i, merged_var]] <- dataset[[i, var1]]
>      dataset[["mismatch"]] <- 0
> 
>      # Leftover: var1 != var2
>      } else {
>        dataset[[i, merged_var]] <- NA
>        dataset[["mismatch"]] <- 2  # var1 != var2
>      }  # end if
>    }  # end for
>    return(dataset)
> }
> 
> ds_var_merge1 <- t_merge_variables(dataset = ds_test,
>  var1 = "customer.x",
>  var2 = "customer.y",
>  merged_var = "customer")
> 
> ds_var_merge1
> 
> -- cut --
> 
> It is executed without error but delivers the wrong values in the variable 
> "mismatch". This variable is always 1 although it should be NA, 1 or 2 
> respectively.
> 
> Can you tell me why the variable is not correctly set?
> 
> Kind regards
> 
> Georg
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Jun  6 14:51:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Jun 2016 08:51:01 -0400
Subject: [R] Merging variables
In-Reply-To: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
Message-ID: <66859881-1B4B-4589-A9A5-A574D75F1DCA@comcast.net>

You loop through each row but during each iteration you assign a value to the entire "mismatch" column. The last value assigned was 1.

Sent from my iPhone

> On Jun 6, 2016, at 8:29 AM, G.Maubach at weinwolf.de wrote:
> 
> Hi All,
> 
> I merged two datasets:
> 
> ds_merge1 <- merge(x = ds_bw_customer_4_match, y = 
> ds_zww_customer_4_match,
>  by.x = "customer", by.y = "customer",
>  all.x = TRUE, all.y = FALSE)
> 
> R created a new dataset with the variables customer.x and customer.y. I 
> would like to merge these two variable back together. I wrote a little 
> function (code can be run) for it:
> 
> -- cut --
> 
> customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> ds_test <- data.frame(customer.x, customer.y, stringsAsFactors = FALSE)
> 
> t_merge_variables <-
>  function(dataset,
>           var1,
>           var2,
>           merged_var) {
> 
>    # Initialize
>    dataset[[merged_var]] = rep(NA, nrow(dataset))
>    dataset[["mismatch"]] = rep(NA, nrow(dataset))
> 
>    for (i in 1:nrow(dataset)) {
> 
>      # Check 1: var1 missing, var2 missing
>      if (is.na(dataset[[i, var1]]) &
>          is.na(dataset[[i, var2]])) {
>        dataset[["mismatch"]] <- 1  # var1 & var2 are missing
> 
>      # Check 2: var1 filled, var2 missing
>      } else if (!is.na(dataset[[i, var1]]) &
>                 is.na(dataset[[i, var2]])) {
>        dataset[[i, merged_var]] <- dataset[[i, var1]]
>        dataset[["mismatch"]] <- 0
> 
>      # Check 3: var1 missing, var2 filled
>      } else if (is.na(dataset[[i, var1]]) &
>                 !is.na(dataset[i, var2])) {
>        dataset[[i, merged_var]] <- dataset[[i, var2]]
>        dataset[["mismatch"]] <-  0
> 
>      # Check 4: var1 == var2
>      } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
>      dataset[[i, merged_var]] <- dataset[[i, var1]]
>      dataset[["mismatch"]] <- 0
> 
>      # Leftover: var1 != var2
>      } else {
>        dataset[[i, merged_var]] <- NA
>        dataset[["mismatch"]] <- 2  # var1 != var2
>      }  # end if
>    }  # end for
>    return(dataset)
> }
> 
> ds_var_merge1 <- t_merge_variables(dataset = ds_test,
>  var1 = "customer.x",
>  var2 = "customer.y",
>  merged_var = "customer")
> 
> ds_var_merge1
> 
> -- cut --
> 
> It is executed without error but delivers the wrong values in the variable 
> "mismatch". This variable is always 1 although it should be NA, 1 or 2 
> respectively.
> 
> Can you tell me why the variable is not correctly set?
> 
> Kind regards
> 
> Georg
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Jun  6 15:05:22 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 6 Jun 2016 13:05:22 +0000
Subject: [R] Merging variables
In-Reply-To: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502E0C7@SRVEXCHMBX.precheza.cz>

Hi

Not sure if this is the most effective or general solution but

Here you get 2 if the value is same in both columns, 1 if it is only in one column and the other is NA and 0 if there is mismatch of values.
temp <- (ds_test[,2] %in% ds_test[,1])+(ds_test[,1] %in% ds_test[,2])

here you get 0 if the value is same or if there is mismatch, 1 if NA is in first column, 2 if it is in second and 3 if in both.
temp2 <- (is.na(ds_test[,2])+2*is.na(ds_test[,1]))

and with combination you get 1 if you want value from first column, 2 if from second, 4 if they are both NA, and -1 if there is mismatch.
temp2 + temp - 1

You could then construct ifelse command to select proper value.

Regards
Petr


> ds_test
  customer.x customer.y
1     Miller     Miller
2      Smith       <NA>
3       <NA>        Doe
4       Bird       Fish
5       <NA>       <NA>
> ds_test+temp
Error in FUN(left, right) : non-numeric argument to binary operator
> (is.na(ds_test[,1])+2*is.na(ds_test[,2]))+temp
[1] 2 3 2 0 5
> (is.na(ds_test[,1])+2*is.na(ds_test[,2]))+temp-2
[1]  0  1  0 -2  3
> (is.na(ds_test[,1])+2*is.na(ds_test[,2]))+temp-1
[1]  1  2  1 -1  4
> is.na(ds_test[,2])+2*is.na(ds_test[,1])
[1] 0 1 2 0 3
> (is.na(ds_test[,2])+2*is.na(ds_test[,1]))+temp-1
[1]  1  1  2 -1  4
> (is.na(ds_test[,2])+2*is.na(ds_test[,1]))+temp-1

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Monday, June 6, 2016 2:30 PM
> To: r-help at r-project.org
> Subject: [R] Merging variables
>
> Hi All,
>
> I merged two datasets:
>
> ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> ds_zww_customer_4_match,
>   by.x = "customer", by.y = "customer",
>   all.x = TRUE, all.y = FALSE)
>
> R created a new dataset with the variables customer.x and customer.y. I
> would like to merge these two variable back together. I wrote a little function
> (code can be run) for it:
>
> -- cut --
>
> customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> ds_test <- data.frame(customer.x, customer.y, stringsAsFactors = FALSE)
>
> t_merge_variables <-
>   function(dataset,
>            var1,
>            var2,
>            merged_var) {
>
>     # Initialize
>     dataset[[merged_var]] = rep(NA, nrow(dataset))
>     dataset[["mismatch"]] = rep(NA, nrow(dataset))
>
>     for (i in 1:nrow(dataset)) {
>
>       # Check 1: var1 missing, var2 missing
>       if (is.na(dataset[[i, var1]]) &
>           is.na(dataset[[i, var2]])) {
>         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
>
>       # Check 2: var1 filled, var2 missing
>       } else if (!is.na(dataset[[i, var1]]) &
>                  is.na(dataset[[i, var2]])) {
>         dataset[[i, merged_var]] <- dataset[[i, var1]]
>         dataset[["mismatch"]] <- 0
>
>       # Check 3: var1 missing, var2 filled
>       } else if (is.na(dataset[[i, var1]]) &
>                  !is.na(dataset[i, var2])) {
>         dataset[[i, merged_var]] <- dataset[[i, var2]]
>         dataset[["mismatch"]] <-  0
>
>       # Check 4: var1 == var2
>       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
>       dataset[[i, merged_var]] <- dataset[[i, var1]]
>       dataset[["mismatch"]] <- 0
>
>       # Leftover: var1 != var2
>       } else {
>         dataset[[i, merged_var]] <- NA
>         dataset[["mismatch"]] <- 2  # var1 != var2
>       }  # end if
>     }  # end for
>     return(dataset)
> }
>
> ds_var_merge1 <- t_merge_variables(dataset = ds_test,
>   var1 = "customer.x",
>   var2 = "customer.y",
>   merged_var = "customer")
>
> ds_var_merge1
>
> -- cut --
>
> It is executed without error but delivers the wrong values in the variable
> "mismatch". This variable is always 1 although it should be NA, 1 or 2
> respectively.
>
> Can you tell me why the variable is not correctly set?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Roger.Bivand at nhh.no  Mon Jun  6 15:24:01 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 6 Jun 2016 15:24:01 +0200
Subject: [R] dissolve tiny polygons to others with
 unionSpatialPolygons{maptools}
In-Reply-To: <CABK368iX8Qa7ferBcpsdcvQu4cWxWHGuNTPYHD=SKBTgpjJ0XA@mail.gmail.com>
References: <CABK368iX8Qa7ferBcpsdcvQu4cWxWHGuNTPYHD=SKBTgpjJ0XA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1606061516010.10035@reclus.nhh.no>

On Mon, 6 Jun 2016, Kumar Mainali wrote:

> I am trying to use unionSpatialPolygons() of maptools to eliminate sliver
> in species range. I want to dissolve tiny sliver polygons in a shapefile to
> bigger polygons as "Eliminate (Data Management)" of ArcMap does. Whereas I
> can dissolve polygons that have identical features in the argument "IDs", I
> cannot dissolve tiny polygons based on some threshold in area. In fact, the
> argument "threshold" has no effect in the output.

Indeed, threshold is not passed through, it was used when the function 
used gpclib rather than rgeos; I'm minded to deprecate 
maptools::unionSpatialPolygons anyway. Note that the data are in 
geographical coordinates, which may very well not be appropriate for the 
topological operations you are trying to do. Use rgeos::gUnaryUnion 
instead, and refer to this thread:

https://stat.ethz.ch/pipermail/r-sig-geo/2015-November/023667.html

for using rgeos::set_RGEOS_polyThreshold() and friends. They do not, 
however, try to guess which of the polygons neighbouring the sliver should 
get the extra area, so you'll have to think that through yourself.

Googling for lists:R-sig-geo dissolve slivers gets a fair number of hits.

There is always also the upstream question of where the slivers came from, 
and whether the resolution is not in the earlier process - generate a map 
without slivers that says exactly what you mean, rather than fudging it 
afterwards.

Roger

>
> ?Input data is available here: ?
> https://www.dropbox.com/sh/a0x5bbo9u60y7is/AAB6RjXHFQKZv-i-t4JclF3ba?dl=0
>
> p.ranges <- shapefile{raster}
> (IDs <- p.ranges$style_id)
> library(maptools)
> unionSpatialPolygons(p.ranges, IDs = IDs, threshold = 1.5)
>
> ?-- Kumar Mainali
> Postdoctoral Associate
> Department of Biology
> University of Maryland, College Park
>
>
> ?
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From lists at dewey.myzen.co.uk  Mon Jun  6 15:45:52 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 6 Jun 2016 14:45:52 +0100
Subject: [R] Merging variables
In-Reply-To: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
Message-ID: <08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>

X-Originating-<%= hostname %>-IP: [217.155.205.190]

Dear Georg

I find it a bit surprising that you end up with customer.x and 
customer.y. Can you share with us a toy example of two data.frames which 
exhibit this behaviour?

On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I merged two datasets:
>
> ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> ds_zww_customer_4_match,
>   by.x = "customer", by.y = "customer",
>   all.x = TRUE, all.y = FALSE)
>
> R created a new dataset with the variables customer.x and customer.y. I
> would like to merge these two variable back together. I wrote a little
> function (code can be run) for it:
>
> -- cut --
>
> customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> ds_test <- data.frame(customer.x, customer.y, stringsAsFactors = FALSE)
>
> t_merge_variables <-
>   function(dataset,
>            var1,
>            var2,
>            merged_var) {
>
>     # Initialize
>     dataset[[merged_var]] = rep(NA, nrow(dataset))
>     dataset[["mismatch"]] = rep(NA, nrow(dataset))
>
>     for (i in 1:nrow(dataset)) {
>
>       # Check 1: var1 missing, var2 missing
>       if (is.na(dataset[[i, var1]]) &
>           is.na(dataset[[i, var2]])) {
>         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
>
>       # Check 2: var1 filled, var2 missing
>       } else if (!is.na(dataset[[i, var1]]) &
>                  is.na(dataset[[i, var2]])) {
>         dataset[[i, merged_var]] <- dataset[[i, var1]]
>         dataset[["mismatch"]] <- 0
>
>       # Check 3: var1 missing, var2 filled
>       } else if (is.na(dataset[[i, var1]]) &
>                  !is.na(dataset[i, var2])) {
>         dataset[[i, merged_var]] <- dataset[[i, var2]]
>         dataset[["mismatch"]] <-  0
>
>       # Check 4: var1 == var2
>       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
>       dataset[[i, merged_var]] <- dataset[[i, var1]]
>       dataset[["mismatch"]] <- 0
>
>       # Leftover: var1 != var2
>       } else {
>         dataset[[i, merged_var]] <- NA
>         dataset[["mismatch"]] <- 2  # var1 != var2
>       }  # end if
>     }  # end for
>     return(dataset)
> }
>
> ds_var_merge1 <- t_merge_variables(dataset = ds_test,
>   var1 = "customer.x",
>   var2 = "customer.y",
>   merged_var = "customer")
>
> ds_var_merge1
>
> -- cut --
>
> It is executed without error but delivers the wrong values in the variable
> "mismatch". This variable is always 1 although it should be NA, 1 or 2
> respectively.
>
> Can you tell me why the variable is not correctly set?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter.4567 at gmail.com  Mon Jun  6 16:52:20 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Jun 2016 07:52:20 -0700
Subject: [R] detecting if a variable has changed
In-Reply-To: <80a72f7f-c1de-c52d-79fd-c53447ed6e97@gmail.com>
References: <87d1nvwmwy.wl-neal@walfield.org>
	<XFMail.20160605190114.Ted.Harding@wlandres.net>
	<CAGxFJbShgYUVSs2O8GPtWE9MxBEaRRXoVU=mPHvzH2-VxAruGw@mail.gmail.com>
	<80a72f7f-c1de-c52d-79fd-c53447ed6e97@gmail.com>
Message-ID: <CAGxFJbQ5WWKTwT11s9Ng9VR7ot+v69pgwW_Ko=0vmA8Q=FbXVA@mail.gmail.com>

Oh, good point! I was thinking only of the comparisons to identify the
insertion location.

--Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 5, 2016 at 8:20 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 05/06/2016 2:13 PM, Bert Gunter wrote:
>>
>> Nope, Ted. I asked for  a O(log(n)) solution, not an O(n) one.
>
>
> I don't think that's possible with a numeric vector.  Inserting an entry at
> a random location is an O(n) operation, since you need to move all following
> values out of the way.
>
> Duncan Murdoch
>
>>
>> I will check out the data.table package, as suggested.
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Jun 5, 2016 at 11:01 AM, Ted Harding <Ted.Harding at wlandres.net>
>> wrote:
>>>
>>> Surely it is straightforward, since the vector (say 'X') is already
>>> sorted?
>>>
>>> Example (raw code with explicit example):
>>>
>>> set.seed(54321)
>>> X <- sort(runif(10))
>>> # X ## The initial sorted vector
>>> # [1] 0.04941009 0.17669234 0.20913493 0.21651016 0.27439354
>>> # [6] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>>>
>>> y <- runif(1)
>>> # y ## The new value to be inserted
>>> [1] 0.1366424
>>>
>>> Y <- c(X[X<=y],y,X[X>y]) ## Now insert y into X:
>>> Y
>>> [1] 0.04941009 0.13664239 0.17669234 0.20913493 0.21651016 0.27439354
>>> [7] 0.34161241 0.37165878 0.42900782 0.49843042 0.86636110
>>>
>>> ## And there it is at Y[2]
>>>
>>> Easy to make such a function!
>>> Best wishes to all,
>>> Ted.
>>>
>>> On 05-Jun-2016 17:44:29 Neal H. Walfield wrote:
>>>>
>>>> On Sun, 05 Jun 2016 19:34:38 +0200,
>>>> Bert Gunter wrote:
>>>>>
>>>>> This help thread suggested a question to me:
>>>>>
>>>>> Is there a function in some package that efficiently (I.e. O(log(n)) )
>>>>> inserts a single new element into the correct location in an
>>>>> already-sorted vector? My assumption here is that doing it via sort()
>>>>> is inefficient, but maybe that is incorrect. Please correct me if so.
>>>>
>>>>
>>>> I think data.table will do this if the the column is marked
>>>> appropriately.
>>>>
>>>>> I realize that it would be straightforward to write such a function,
>>>>> but I just wondered if it already exists. My google & rseek searches
>>>>> did not succeed, but maybe I used the wrong keywords.
>>>>>
>>>>> Cheers,
>>>>> Bert
>>>>>
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Sun, Jun 5, 2016 at 9:47 AM, William Dunlap via R-help
>>>>> <r-help at r-project.org> wrote:
>>>>>>
>>>>>> I don't know what you mean by "without having to use any special
>>>>>> interfaces", but "reference classes" will do what I think you want.
>>>>>> E.g.,
>>>>>> the following makes a class called 'SortedNumeric' that only sorts the
>>>>>> vector when you want to get its value, not when you append values.  It
>>>>>> stores the sorted vector so it does not get resorted each time you ask
>>>>>> for
>>>>>> it.
>>>>>>
>>>>>> SortedNumeric <- setRefClass("sortedNumeric",
>>>>>>             fields = list(
>>>>>>                 fData = "numeric",
>>>>>>                 fIsUnsorted = "logical"),
>>>>>>             methods = list(
>>>>>>                 initialize = function(Data = numeric(), isUnsorted =
>>>>>> TRUE)
>>>>>>                 {
>>>>>>                     fData <<- Data
>>>>>>                     stopifnot(is.logical(isUnsorted),
>>>>>>                               length(isUnsorted)==1,
>>>>>>                               !is.na(isUnsorted))
>>>>>>                     fIsUnsorted <<- isUnsorted
>>>>>>                 },
>>>>>>                 getData = function() {
>>>>>>                     if (isUnsorted) {
>>>>>>                         fData <<- sort(fData)
>>>>>>                         fIsUnsorted <<- FALSE
>>>>>>                     }
>>>>>>                     fData
>>>>>>                 },
>>>>>>                 appendData = function(newEntries) {
>>>>>>                     fData <<- c(fData, newEntries)
>>>>>>                     fIsUnsorted <<- TRUE
>>>>>>                 }
>>>>>>             ))
>>>>>>
>>>>>> Use it as:
>>>>>>
>>>>>>> x <- SortedNumeric$new()
>>>>>>> x$appendData(c(4,2,5))
>>>>>>> x$appendData(c(1,8,9))
>>>>>>> x
>>>>>>
>>>>>> Reference class object of class "sortedNumeric"
>>>>>> Field "fData":
>>>>>> [1] 4 2 5 1 8 9
>>>>>> Field "fIsUnsorted":
>>>>>> [1] TRUE
>>>>>>>
>>>>>>> x$getData()
>>>>>>
>>>>>> [1] 1 2 4 5 8 9
>>>>>>>
>>>>>>> x
>>>>>>
>>>>>> Reference class object of class "sortedNumeric"
>>>>>> Field "fData":
>>>>>> [1] 1 2 4 5 8 9
>>>>>> Field "fIsUnsorted":
>>>>>> [1] FALSE
>>>>>>
>>>>>>
>>>>>> Outside of base R, I think the R6 package gives another approach to
>>>>>> this.
>>>>>>
>>>>>>
>>>>>> Bill Dunlap
>>>>>> TIBCO Software
>>>>>> wdunlap tibco.com
>>>>>>
>>>>>> On Sun, Jun 5, 2016 at 6:53 AM, Neal H. Walfield <neal at walfield.org>
>>>>>> wrote:
>>>>>>
>>>>>>> Hi,
>>>>>>>
>>>>>>> I have a huge list.  Normally it is sorted, but I want to be able to
>>>>>>> add elements to it without having to use any special interfaces and
>>>>>>> then sort it on demand.  My idea is to use something like weak
>>>>>>> references combined with attributes.  Consider:
>>>>>>>
>>>>>>>   # Initialization.
>>>>>>>   l = as.list(1:10)
>>>>>>>   # Note that it is sorted.
>>>>>>>   attr(l, 'sorted') = weakref(l)
>>>>>>>
>>>>>>>   # Modify the list.
>>>>>>>   l = append(l, 1:3)
>>>>>>>
>>>>>>>   # Check if the list is still sorted.  (I use identical here, but it
>>>>>>>   # probably too heavy weight: I just need to compare the addresses.)
>>>>>>>   if (! identical(l, attr(l, 'sorted'))) {
>>>>>>>     l = sort(unlist(l))
>>>>>>>     attr(l, 'sorted') = weakref(l)
>>>>>>>   }
>>>>>>>   # Do operation that requires sorted list.
>>>>>>>   ...
>>>>>>>
>>>>>>> This is obviously a toy example.  I'm not actually sorting integers
>>>>>>> and I may use a matrix instead of a list.
>>>>>>>
>>>>>>> I've read:
>>>>>>>
>>>>>>>   http://www.hep.by/gnu/r-patched/r-exts/R-exts_122.html
>>>>>>>   http://homepage.stat.uiowa.edu/~luke/R/references/weakfinex.html
>>>>>>>
>>>>>>> As far as I can tell, weakrefs are only available via the C API.  Is
>>>>>>> there a way to do what I want in R without resorting to C code?  Is
>>>>>>> what I want to do better achieved using something other than
>>>>>>> weakrefs?
>>>>>>>
>>>>>>> Thanks!
>>>>>>>
>>>>>>> :) Neal
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> -------------------------------------------------
>>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>>> Date: 05-Jun-2016  Time: 19:01:10
>>> This message was sent by XFMail
>>> -------------------------------------------------
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From hannah.hlx at gmail.com  Mon Jun  6 16:57:35 2016
From: hannah.hlx at gmail.com (li li)
Date: Mon, 6 Jun 2016 10:57:35 -0400
Subject: [R] multcomp package
Message-ID: <CAHLnndbpu0dX4jFXqSevkcGB26H3yh8p2VpcJZWeYpc6KgC6ag@mail.gmail.com>

Hi all,
  After fitting a random slope and random intercept model using lme
function, I want
to test whether each of the fixed slopes is equal to zero (The output of
model is below).
Can this be done (testing each individual slope) using multcomp package?
  Thanks much for the help.
   Hanna

> summary(mod1)Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352

Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014time
0.07010  0.250983 57  0.279301  0.7810
method2:time -0.12616  0.360585 57 -0.349877  0.7277
method3:time -0.08010  0.251105 57 -0.318999  0.7509
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874

Number of Observations: 69
Number of Groups: 7 >

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Jun  6 17:04:42 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 6 Jun 2016 15:04:42 +0000
Subject: [R] Merging variables
In-Reply-To: <08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502E188@SRVEXCHMBX.precheza.cz>

Hi Michael

it is simple

set.seed(111)
let=sample(letters[1:10],6, replace=T)
dat1<-data.frame(let=let, customer=sample(1:10,6, replace=T))
let=sample(letters[1:10],6, replace=T)
dat2<-data.frame(let=let, customer=sample(1:10,6, replace=T))
merge(dat1, dat2, by.x="let", by.y="let", all=T)

Of course you could add customer variable to by parameter but sometimes it is necessary to leave it out. When you have two sets of analytical results and you have 2 variables operator but you want to merge those sets e.g. by date/hour of analysis.

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Dewey
> Sent: Monday, June 6, 2016 3:46 PM
> To: G.Maubach at weinwolf.de; r-help at r-project.org
> Subject: Re: [R] Merging variables
>
> X-Originating-<%= hostname %>-IP: [217.155.205.190]
>
> Dear Georg
>
> I find it a bit surprising that you end up with customer.x and customer.y. Can
> you share with us a toy example of two data.frames which exhibit this
> behaviour?
>
> On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
> > Hi All,
> >
> > I merged two datasets:
> >
> > ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> > ds_zww_customer_4_match,
> >   by.x = "customer", by.y = "customer",
> >   all.x = TRUE, all.y = FALSE)
> >
> > R created a new dataset with the variables customer.x and customer.y.
> > I would like to merge these two variable back together. I wrote a
> > little function (code can be run) for it:
> >
> > -- cut --
> >
> > customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> > customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> > ds_test <- data.frame(customer.x, customer.y, stringsAsFactors =
> > FALSE)
> >
> > t_merge_variables <-
> >   function(dataset,
> >            var1,
> >            var2,
> >            merged_var) {
> >
> >     # Initialize
> >     dataset[[merged_var]] = rep(NA, nrow(dataset))
> >     dataset[["mismatch"]] = rep(NA, nrow(dataset))
> >
> >     for (i in 1:nrow(dataset)) {
> >
> >       # Check 1: var1 missing, var2 missing
> >       if (is.na(dataset[[i, var1]]) &
> >           is.na(dataset[[i, var2]])) {
> >         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
> >
> >       # Check 2: var1 filled, var2 missing
> >       } else if (!is.na(dataset[[i, var1]]) &
> >                  is.na(dataset[[i, var2]])) {
> >         dataset[[i, merged_var]] <- dataset[[i, var1]]
> >         dataset[["mismatch"]] <- 0
> >
> >       # Check 3: var1 missing, var2 filled
> >       } else if (is.na(dataset[[i, var1]]) &
> >                  !is.na(dataset[i, var2])) {
> >         dataset[[i, merged_var]] <- dataset[[i, var2]]
> >         dataset[["mismatch"]] <-  0
> >
> >       # Check 4: var1 == var2
> >       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
> >       dataset[[i, merged_var]] <- dataset[[i, var1]]
> >       dataset[["mismatch"]] <- 0
> >
> >       # Leftover: var1 != var2
> >       } else {
> >         dataset[[i, merged_var]] <- NA
> >         dataset[["mismatch"]] <- 2  # var1 != var2
> >       }  # end if
> >     }  # end for
> >     return(dataset)
> > }
> >
> > ds_var_merge1 <- t_merge_variables(dataset = ds_test,
> >   var1 = "customer.x",
> >   var2 = "customer.y",
> >   merged_var = "customer")
> >
> > ds_var_merge1
> >
> > -- cut --
> >
> > It is executed without error but delivers the wrong values in the
> > variable "mismatch". This variable is always 1 although it should be
> > NA, 1 or 2 respectively.
> >
> > Can you tell me why the variable is not correctly set?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bgunter.4567 at gmail.com  Mon Jun  6 17:06:32 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Jun 2016 08:06:32 -0700
Subject: [R] find longest consecutive streak in double
In-Reply-To: <CA+8X3fVZY+608k6iKxg5atQ_WG-6qATtOMR62x3fHfuG--MyEg@mail.gmail.com>
References: <CAONpAsogo1-O_ZPxP0W0M4QkuRVoEEq0jZhgGU9WmPESyond=A@mail.gmail.com>
	<CA+8X3fVZY+608k6iKxg5atQ_WG-6qATtOMR62x3fHfuG--MyEg@mail.gmail.com>
Message-ID: <CAGxFJbShP46XTRrMP7XtR1L5BDLOWYUw+3mCV+EyRemHdPXK4g@mail.gmail.com>

Yes, see ?rle, as Jim indicated.

Just wanted to add that there is an rpy2 package that enables you to
use R within python, which may mean that you do not need to translate
your python code. Or at least not all of it.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 5, 2016 at 7:32 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Nick,
> I think you want to get the maximum run length:
>
> jja<-runif(92,0,16)
> med_jja<-median(jja)
> med_jja
> [1] 7.428935
> # get a logical vector of values greater than the median
> jja_plus_med<-jja > med_jja
> # now get the length of runs
> runs_jja_plus_med<-rle(jja_plus_med)
> # finally find the maximum run length
> max(runs_jja_plus_med$lengths)
> [1] 5
>
> Jim
>
>
> On Mon, Jun 6, 2016 at 5:51 AM, Nick Tulli <nick.tulli.95 at gmail.com> wrote:
>> Hey guys. Learning R after gaining a background in Python this year,
>> and I'm translating my Python projects to R now. This is the first
>> time I'm posting to the mailing list.
>>
>> Essentially, I have 92 data points in one double that I created from a
>> netcdf file. Those 92 data points represent a measurement from a
>> location over the course of three months. From there I've calculated
>> the median value of the data, which is 8.534281. My goal here is to
>> test each data point to see if it exceeds the median value, and, next,
>> calculate the longest streak of days in the 92-day span in which the
>> data exceeded the median value.
>>
>> To achieve this in Python, I've created the following function, where
>> q is a vector of length 92 and q_JJA_median is, of course, the median
>> value of the dataset.
>> ######################################
>> def consecutive(q, q_JJA_median):
>>     is_consecutive = 0
>>     n = 0
>>     array_exceed = []
>>     for i in range(len(q)):
>>         if q[i] > q_JJA_median:
>>             n+=1
>>             is_consecutive = 1
>>         else:
>>             if is_consecutive:
>>                 array_exceed.append(n)
>>                 n = 0
>>                 is_consecutive = 0
>>     if q[i] > q_JJA_median:
>>         array_exceed.append(n)
>>     if len(array_exceed) == 0:
>>         array_exceed = 0
>>     if type(array_exceed) is int:
>>         array_exceed = [0]
>>     return array_exceed
>> #######################################
>>
>> Here is my work thus far written for R:
>> #######################################
>> is_consecutive = 0
>> n = 0
>> array_exceed <- c()
>> for (i in q) {
>>   if (i > q_JJA_median) {
>>     n = n + 1
>>     is_consecutive = is_consecutive + 1
>>   }
>>   else {
>>     if (is_consecutive) {
>>       append(array_exceed, n)
>>       n <- 0
>>       is_consecutive <- 0
>>     }
>>   }
>>   if (i > q_JJA_median) {
>>     append(array_exceed,n)
>>   }
>> }
>> #######################################
>>
>> My code written for R has been changed and manipulated many times, and
>> none of my attempts have been successful. I'm still new to the syntax
>> of the R language, so my problem very well could be a product of my
>> lack of experience.
>>
>> Additionally, I read on a forum post that using the append function
>> can be slower than many other options. Is this true? If so, how can I
>> circumvent that issue?
>>
>> Thank you!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Mon Jun  6 17:07:53 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 6 Jun 2016 17:07:53 +0200
Subject: [R] Trouble with (Very) Simple Clustering
Message-ID: <20160606150719.GA4559@localhost.localdomain>

Dear All,
I am doing something extremly basic (and I do not claim at all there
is no other way to achieve the same): I have a list of numbers and I
would like to split them up into clusters.
This is what I do: I see each number as a 1D vector and I calculate
the euclidean distance between them.
I get a distance matrix which I then feed to a hierarchical clustering
algorithm.
For instance consider the following snippet


#########################################################
data_mat<-structure(c(50.1361524639595, 48.2314746179241, 30.3803078462882,
29.2679787220381, 25.5125237513957, 22.9052912406594,
21.3890604699407,
15.5680557012965, 15.322981489303, 8.36693180374788, 7.23530025890675,
6.51469907237986, 5.42861828441895, 4.61986804112007,
4.33660782487196,
3.89915821225882, 3.67394875259037, 2.32719820674605,
1.88489249113792,
1.62276579528843, 1.56048239182126, 1.49722163565454,
1.32492151010636,
1.28216249552147, 1.272235253501, 0.734274800585336,
0.326949583587343,
0.318777047947951), .Dim = c(28L, 1L), .Dimnames = list(c("EE",
"LV", "RO", "BG", "SK", "CY", "LT", "MT", "PL", "NL", "EL", "PT",
"CZ", "SE", "UK", "LU", "HR", "DK", "AT", "SI", "IE", "ES", "FI",
"FR", "DE", "IT", "HU", "BE"), NULL))



distMatrix <- dist(data_mat)

n_clus<-5 ## I arbitrarily choose to have 5 clusters

hc <- hclust(distMatrix , method="ward.D2")



groups <- cutree(hc, k=n_clus) # cut tree into 5 clusters

pdf("cluster1.pdf")
plot(hc, labels = , hang = -1, main="Mobility to Business",
 yaxt='n' , ann=FALSE
  )
  rect.hclust(hc, k=n_clus, border="red")
  dev.off()

######################################################

which gives me very reasonable results.

Now, I would like to be able to find the optimal number of cluster on
the same data.

Based on what I found

http://www.sigmath.es.osaka-u.ac.jp/shimo-lab/prog/pvclust/

http://www.statmethods.net/advstats/cluster.html

pvclust is a sensible way to go. However, when I try to use it on my
data, I get an error

> fit <- pvclust(t(data_mat),
> method.hclust="ward.D2",method.dist="euclidean")
Error in FUN(X[[i]], ...) : invalid scale parameter(r)


does anybody understand what is my mistake?
Many thanks

Lorenzo


From G.Maubach at weinwolf.de  Mon Jun  6 17:27:49 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 6 Jun 2016 17:27:49 +0200
Subject: [R] Antwort: RE:  Merging variables
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502E0C7@SRVEXCHMBX.precheza.cz>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502E0C7@SRVEXCHMBX.precheza.cz>
Message-ID: <OFB7DCD9D5.872EA965-ONC1257FCA.00516279-C1257FCA.0054F404@lotus.hawesko.de>

Hi David,
Hi Petr,

many thanks for your help. With your hints I got the idea how I could do 
it and I came up with this solution:

-- cut --

#-------------------------------------------------------------------------------
# Module        : t_merge_variables.R
# Author        : Georg Maubach
# Date          : 2016-06-06
# Update        : 2016-06-06
# Description   : Merge two variables
# Source System : R 3.2.5 (64 Bit)
# Target System : R 3.2.5 (64 Bit)
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#--------1---------2---------3---------4---------5---------6---------7---------8

t_module_name = "t_merge_variables.R"
t_version = "2016-06-06"

cat(
  paste0("\n",
         t_module_name, " (Version: ", t_version, ")", "\n", "\n",
         "This software comes with ABSOLUTELY NO WARRANTY.",
         "\n", "\n"))

# If do_test is not defined globally define it here locally by 
un-commenting it
# Switch t_do_test to TRUE to run test
t_do_test <- FALSE

# [ Function Defintion 
]--------------------------------------------------------
t_merge_variables <-
  function(dataset,
           var1,
           var2,
           merged_var) {
    # Merges two variables with identical, different or missing values
    #
    # Args:
    #  dataset (data frame, data table):
    #    Object with dimnames, e.g. data frame, data table.
    #  var1 (character):
    #    Variable 1 to be merged.
    #  var2 (character):
    #    Variable 2 to be merged.
    #  merged_var (class based on input variable, coercion done if 
possible):
    #    Variable with the merged variables var1 and var2.
    #
    # Operation:
    #   Var1 and var2 are merged like follows:
    #   if var1 == var2: merged_var <- var1
    #   if var1 != var2: merged_var <- -900 (-900 = indicating mismatch)
    #   if var1 is filled & var2 is missing: merged_var <- var1
    #   if var1 is missing & var2 is filled: merged_var <- var2
    #   if var1 is missing & var2 is filled: merged_var <- -999
    #                                        (-999 = indicating NA)
    #
    # Returns:
    #   Original dataset and variable given in "merged_var" will be added.
    #
    # Error handling:
    #   None.
    #
    # Credits: 
    #   https://www.mail-archive.com/r-help at r-project.org/msg236012.html
 
    # Initialize
    dataset[merged_var] = rep(NA, nrow(dataset))

    dataset[merged_var] <-
      # Check 1: var1 missing, var2 missing
      ifelse(is.na(dataset[, var1]) & is.na(dataset[, var2]), 
        # then
        dataset[[merged_var]] <- 0,
        # Check 2: var1 filled, var2 missing
        ifelse(!is.na(dataset[, var1]) & is.na(dataset[, var2]),
          # then
          dataset[[merged_var]] <- dataset[, var1],
          # Check 3: var1 missing, var2 filled
          ifelse(is.na(dataset[ , var1]) & !is.na(dataset[, var2]),
            # then
            dataset[[merged_var]] <- dataset[ , var2],
            # Check 4: var1 == var2
            ifelse(dataset[, var1] == dataset[, var2],
              # then: use var1
              dataset[[merged_var]] <- dataset[, var1],
              #Leftover: var1 != var2
              dataset[merged_var] <- 1))))
 
    return(dataset)
}

# [ Test Defintion 
]------------------------------------------------------------
t_test <- function(do_test = FALSE) {
  if (do_test == TRUE) {
    cat("\n", "\n", "Test function t_count_na()", "\n", "\n")
 
    # Example dataset
    customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
    customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
    ds_test <-
      data.frame(customer.x, customer.y, stringsAsFactors = FALSE)
 
    # Call function
    ds_merge <- t_merge_variables(
      dataset = ds_test,
      var1 = "customer.x",
      var2 = "customer.y",
      merged_var = "customer"
    )
 
    # Dataset after function call
    ds_merge
  }
}

# [ Test Run 
]------------------------------------------------------------------
t_test(do_test = t_do_test)

# [ Clean up 
]------------------------------------------------------------------
rm("t_do_test", "t_module_name", "t_version", "t_test")

# EOF

-- cut --

It delivers the customer name if there is one or they match. If they don't 
match it delivers 1. If both are missing it delivers 0.

This solution is for my applications sufficient.

Many thanks again for your help and giving me the ideas to solve my data 
transformation task.

Kind regards

Georg





Von:    PIKAL Petr <petr.pikal at precheza.cz>
An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, 
"r-help at r-project.org" <r-help at r-project.org>, 
Datum:  06.06.2016 15:04
Betreff:        RE: [R] Merging variables



Hi

Not sure if this is the most effective or general solution but

Here you get 2 if the value is same in both columns, 1 if it is only in 
one column and the other is NA and 0 if there is mismatch of values.
temp <- (ds_test[,2] %in% ds_test[,1])+(ds_test[,1] %in% ds_test[,2])

here you get 0 if the value is same or if there is mismatch, 1 if NA is in 
first column, 2 if it is in second and 3 if in both.
temp2 <- (is.na(ds_test[,2])+2*is.na(ds_test[,1]))

and with combination you get 1 if you want value from first column, 2 if 
from second, 4 if they are both NA, and -1 if there is mismatch.
temp2 + temp - 1

You could then construct ifelse command to select proper value.

Regards
Petr


> ds_test
  customer.x customer.y
1     Miller     Miller
2      Smith       <NA>
3       <NA>        Doe
4       Bird       Fish
5       <NA>       <NA>
> ds_test+temp
Error in FUN(left, right) : non-numeric argument to binary operator
> (is.na(ds_test[,1])+2*is.na(ds_test[,2]))+temp
[1] 2 3 2 0 5
> (is.na(ds_test[,1])+2*is.na(ds_test[,2]))+temp-2
[1]  0  1  0 -2  3
> (is.na(ds_test[,1])+2*is.na(ds_test[,2]))+temp-1
[1]  1  2  1 -1  4
> is.na(ds_test[,2])+2*is.na(ds_test[,1])
[1] 0 1 2 0 3
> (is.na(ds_test[,2])+2*is.na(ds_test[,1]))+temp-1
[1]  1  1  2 -1  4
> (is.na(ds_test[,2])+2*is.na(ds_test[,1]))+temp-1

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Monday, June 6, 2016 2:30 PM
> To: r-help at r-project.org
> Subject: [R] Merging variables
>
> Hi All,
>
> I merged two datasets:
>
> ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> ds_zww_customer_4_match,
>   by.x = "customer", by.y = "customer",
>   all.x = TRUE, all.y = FALSE)
>
> R created a new dataset with the variables customer.x and customer.y. I
> would like to merge these two variable back together. I wrote a little 
function
> (code can be run) for it:
>
> -- cut --
>
> customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> ds_test <- data.frame(customer.x, customer.y, stringsAsFactors = FALSE)
>
> t_merge_variables <-
>   function(dataset,
>            var1,
>            var2,
>            merged_var) {
>
>     # Initialize
>     dataset[[merged_var]] = rep(NA, nrow(dataset))
>     dataset[["mismatch"]] = rep(NA, nrow(dataset))
>
>     for (i in 1:nrow(dataset)) {
>
>       # Check 1: var1 missing, var2 missing
>       if (is.na(dataset[[i, var1]]) &
>           is.na(dataset[[i, var2]])) {
>         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
>
>       # Check 2: var1 filled, var2 missing
>       } else if (!is.na(dataset[[i, var1]]) &
>                  is.na(dataset[[i, var2]])) {
>         dataset[[i, merged_var]] <- dataset[[i, var1]]
>         dataset[["mismatch"]] <- 0
>
>       # Check 3: var1 missing, var2 filled
>       } else if (is.na(dataset[[i, var1]]) &
>                  !is.na(dataset[i, var2])) {
>         dataset[[i, merged_var]] <- dataset[[i, var2]]
>         dataset[["mismatch"]] <-  0
>
>       # Check 4: var1 == var2
>       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
>       dataset[[i, merged_var]] <- dataset[[i, var1]]
>       dataset[["mismatch"]] <- 0
>
>       # Leftover: var1 != var2
>       } else {
>         dataset[[i, merged_var]] <- NA
>         dataset[["mismatch"]] <- 2  # var1 != var2
>       }  # end if
>     }  # end for
>     return(dataset)
> }
>
> ds_var_merge1 <- t_merge_variables(dataset = ds_test,
>   var1 = "customer.x",
>   var2 = "customer.y",
>   merged_var = "customer")
>
> ds_var_merge1
>
> -- cut --
>
> It is executed without error but delivers the wrong values in the 
variable
> "mismatch". This variable is always 1 although it should be NA, 1 or 2
> respectively.
>
> Can you tell me why the variable is not correctly set?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter 
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization 
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.


From dcarlson at tamu.edu  Mon Jun  6 17:52:18 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 6 Jun 2016 15:52:18 +0000
Subject: [R] How to specify a data frame column using command line arg?
In-Reply-To: <CA+NGhbkGSfpx+H9iTu5iJLXQYPvv5Rn2op8LO0u=m73yw+67nQ@mail.gmail.com>
References: <CAEKTc2OOsyWaCy=RxFSMWrMjg_OxJhAZfKYubGwSCUDKjpt=iw@mail.gmail.com>
	<CA+NGhb=3pzArFXLorfmfqhn0vaQoYy2gAcyYNg-qNpaWGbn+cQ@mail.gmail.com>
	<CA+NGhbkGSfpx+H9iTu5iJLXQYPvv5Rn2op8LO0u=m73yw+67nQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D73760C@mb02.ads.tamu.edu>

Looking at your overall goal to plot multiple columns, you can use a simple loop with expand.grid():

> set.seed(42)
> adl1 <- matrix(sample.int(9),  3, 3)
> colnames(adl1) <- letters[1:3]
> lbls <- colnames(adl1)
> 
> ncols <- ncol(adl1)
> colnos <- as.matrix(expand.grid(1:ncols, 1:ncols))
> colnos <- colnos[colnos[, 1] < colnos[, 2], ] # Eliminate redundant combinations
> colnos
     Var1 Var2
[1,]    1    2
[2,]    1    3
[3,]    2    3
> 
> for (i in seq_len(nrow(colnos))) {
+      plot(adl1[, colnos[i, ]], xlab=lbls[colnos[i, 1]], 
+           ylab=lbls[colnos[i, 2]])
+ }

Plots all of the unique plots. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Changrong Ge
Sent: Monday, June 6, 2016 12:07 AM
To: Douglas Johnson
Cc: r-help at r-project.org
Subject: Re: [R] How to specify a data frame column using command line arg?

>
> Hi,
>     I have recently made similar scatter plot.
>     Suppose you have a data frame "data.csv" and the first column is not
> what you want to plot but rather something informative such as ID, Class,
> Group, etc which might not be your case (but would be very nice if you want
> to color your scatter plots or add cutoff line, etc). The code below would
> work well by printing out figures for all possible column i vs column j.
>
> for(i in names(data[,-1])){
> for(j in names(data[,-1])){
>
> png(paste(i," vs " ,j,".png", sep=""), width=4, height=6, units="in",
> res=300)
>
> plot(data[,i],data[,j],xlab=i,ylab=j,log="xy",pch=16)
>
>
> dev.off()
> print(c(i,j))
> }
> }
>
> Good luck
> Changrong
>
> On Sun, Jun 5, 2016 at 9:45 PM, Douglas Johnson <todojo at gmail.com> wrote:
>
>> I'm guessing this is trivial but I've spent two hours searching and
>> reading
>> FAQ, tutorial, introductory and 'idiom' documents and haven't found a
>> solution. All I want to do is select a data frame column at run time using
>> a command line arg. For example, the "test.csv" file contains:
>>
>> a,b,c
>> 1,2,3
>> 4,5,6
>> 7,8,9
>>
>> If I run "test.r a", I get [1,4,7].
>> If I run "test.r b", I get [2,5,8].
>>
>> Here's sample code -- how I map args[1] to column/vector 'a' or 'b' or
>> 'c'?
>>
>> args <- commandArgs(trailingOnly=T)
>>
>> adl1<-read.csv(file="test.csv",head=T,sep=",")
>>
>> adl1$SOME-MAGIC-FUNCTION-OR-SYMBOL(args[1])
>>
>>
>> All I'm really trying to do is generate a bunch of scatter plots of column
>> 'x' vs. 'y' without writing a separate program for each pair.
>>
>>
>> Thanks,
>>
>>
>> Doug
>>
>>
>>
>> --
>> http://www.dojopico.org <http://dojopico.org>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
>
> Changrong Ge, PhD
>
> Division of Medical Inflammation Research
> Department of Medical Biochemistry and Biophysics (MBB)
> Karolinska Institutet
> Scheeles v?g 2, B2 Plan 4
> SE-171 77 Stockholm
> Sweden
> Tel:  +46-8-524 86337 ,   Mobile: +46-(0)76-2878 029
> Fax: +46-8-524 87750 ,  Email: changrong.ge at ki.se <changrong at dbb.su.se>
>  or changrong.ge at gmail.com
>
>


-- 

Changrong Ge, PhD

Division of Medical Inflammation Research
Department of Medical Biochemistry and Biophysics (MBB)
Karolinska Institutet
Scheeles v?g 2, B2 Plan 4
SE-171 77 Stockholm
Sweden
Tel:  +46-8-524 86337 ,   Mobile: +46-(0)76-2878 029
Fax: +46-8-524 87750 ,  Email: changrong.ge at ki.se <changrong at dbb.su.se> or
changrong.ge at gmail.com

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From macqueen1 at llnl.gov  Mon Jun  6 18:34:26 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 6 Jun 2016 16:34:26 +0000
Subject: [R] merging dataframes in a list
In-Reply-To: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
References: <CALRb-ofMFVy07EzF8-RDHYhZfiJuPxthpb+tSidh79-de-wU-g@mail.gmail.com>
Message-ID: <D37AF35B.179185%macqueen1@llnl.gov>

I would probably do it this way,

tmp <- list(data.frame(name="sample1", red=20),
            data.frame(name="sample1", green=15),
            data.frame(name="sample2", red=10),
            data.frame(name="sample2", green=30))

fun1 <- function(df) data.frame(name=df$name, color=names(df)[2],
value=df[[2]])

tmp1 <- lapply(tmp,fun1)

tmp2 <- do.call(rbind,tmp1)

tmp3 <- reshape(tmp2, idvar='name', timevar='color', direction='wide')

This does the job, except for the extraneous "value." [and they can easily
be removed using gsub()].

Whether or not it will work for a more general case, I don't know.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/3/16, 11:20 AM, "R-help on behalf of Ed Siefker"
<r-help-bounces at r-project.org on behalf of ebs15242 at gmail.com> wrote:

>I have a list of data as follows.
>
>> list(data.frame(name="sample1", red=20), data.frame(name="sample1",
>>green=15), data.frame(name="sample2", red=10), data.frame(name="sample
>>2", green=30))
>[[1]]
>     name red
>1 sample1  20
>
>[[2]]
>     name green
>1 sample1    15
>
>[[3]]
>     name red
>1 sample2  10
>
>[[4]]
>     name green
>1 sample2    30
>
>
>I would like to massage this into a data frame like this:
>
>     name red green
>1 sample1  20    15
>2 sample2  10    30
>
>
>I'm imagining I can use aggregate(mylist, by=samplenames, merge)
>right?  But how do I get the list of samplenames?  How do I subset
>each dataframe inside the list?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Jun  6 18:54:28 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 6 Jun 2016 16:54:28 +0000
Subject: [R] Trouble with (Very) Simple Clustering
In-Reply-To: <20160606150719.GA4559@localhost.localdomain>
References: <20160606150719.GA4559@localhost.localdomain>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D737680@mb02.ads.tamu.edu>

I think your problem is that pvclust looks for clusters between variables and you have only one variable. When you transpose data_mat, you have a single row and dist cannot calculate a distance matrix on a single row:

> dist(t(data_mat))
dist(0)

I was going to suggest package NbClust since there is no need to transpose the data, but it fails as well. I did discover that Mclust() in package mclust works:

> library(mclust)
> Mclust(data_mat)
'Mclust' model object:
 best model: univariate, unequal variance (V) with 3 components

Looking at the density plot suggests 3 groups as well:

> plot(density(data_mat))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lorenzo Isella
Sent: Monday, June 6, 2016 10:08 AM
To: r-help at r-project.org
Subject: [R] Trouble with (Very) Simple Clustering

Dear All,
I am doing something extremly basic (and I do not claim at all there
is no other way to achieve the same): I have a list of numbers and I
would like to split them up into clusters.
This is what I do: I see each number as a 1D vector and I calculate
the euclidean distance between them.
I get a distance matrix which I then feed to a hierarchical clustering
algorithm.
For instance consider the following snippet


#########################################################
data_mat<-structure(c(50.1361524639595, 48.2314746179241, 30.3803078462882,
29.2679787220381, 25.5125237513957, 22.9052912406594,
21.3890604699407,
15.5680557012965, 15.322981489303, 8.36693180374788, 7.23530025890675,
6.51469907237986, 5.42861828441895, 4.61986804112007,
4.33660782487196,
3.89915821225882, 3.67394875259037, 2.32719820674605,
1.88489249113792,
1.62276579528843, 1.56048239182126, 1.49722163565454,
1.32492151010636,
1.28216249552147, 1.272235253501, 0.734274800585336,
0.326949583587343,
0.318777047947951), .Dim = c(28L, 1L), .Dimnames = list(c("EE",
"LV", "RO", "BG", "SK", "CY", "LT", "MT", "PL", "NL", "EL", "PT",
"CZ", "SE", "UK", "LU", "HR", "DK", "AT", "SI", "IE", "ES", "FI",
"FR", "DE", "IT", "HU", "BE"), NULL))



distMatrix <- dist(data_mat)

n_clus<-5 ## I arbitrarily choose to have 5 clusters

hc <- hclust(distMatrix , method="ward.D2")



groups <- cutree(hc, k=n_clus) # cut tree into 5 clusters

pdf("cluster1.pdf")
plot(hc, labels = , hang = -1, main="Mobility to Business",
 yaxt='n' , ann=FALSE
  )
  rect.hclust(hc, k=n_clus, border="red")
  dev.off()

######################################################

which gives me very reasonable results.

Now, I would like to be able to find the optimal number of cluster on
the same data.

Based on what I found

http://www.sigmath.es.osaka-u.ac.jp/shimo-lab/prog/pvclust/

http://www.statmethods.net/advstats/cluster.html

pvclust is a sensible way to go. However, when I try to use it on my
data, I get an error

> fit <- pvclust(t(data_mat),
> method.hclust="ward.D2",method.dist="euclidean")
Error in FUN(X[[i]], ...) : invalid scale parameter(r)


does anybody understand what is my mistake?
Many thanks

Lorenzo

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kpmainali at gmail.com  Mon Jun  6 20:12:14 2016
From: kpmainali at gmail.com (Kumar Mainali)
Date: Mon, 6 Jun 2016 14:12:14 -0400
Subject: [R] dissolve tiny polygons to others with
	unionSpatialPolygons{maptools}
In-Reply-To: <alpine.LFD.2.20.1606061516010.10035@reclus.nhh.no>
References: <CABK368iX8Qa7ferBcpsdcvQu4cWxWHGuNTPYHD=SKBTgpjJ0XA@mail.gmail.com>
	<alpine.LFD.2.20.1606061516010.10035@reclus.nhh.no>
Message-ID: <CABK368jVuK+xJLhJb6LWZC0_Dc9J0ZAKqxWrPULfYj06HAx7AA@mail.gmail.com>

Thank you, Roger. I cannot fix the upstream processes to eliminate
generation of these problems. So, I need to deal with the data I got.
I tried various online resources including
https://gist.github.com/mstrimas/1b4a4b93a9d4a158bce4 and tried:
setScales()
set_RGEOS_dropSlivers(TRUE)
set_RGEOS_polyThreshold()

before performing:
gUnaryUnion(p.ranges, id=NULL)

This eliminates the slivers but it also dissolves ALL the polygons to get a
single polygon. That is not something I wanted. I would like to dissolve
only the tiny polygons to the neighboring bigger ones.

Any help is very much appreciated!

?

Postdoctoral Associate
Department of Biology
University of Maryland, College Park

On Mon, Jun 6, 2016 at 9:24 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Mon, 6 Jun 2016, Kumar Mainali wrote:
>
> I am trying to use unionSpatialPolygons() of maptools to eliminate sliver
>> in species range. I want to dissolve tiny sliver polygons in a shapefile
>> to
>> bigger polygons as "Eliminate (Data Management)" of ArcMap does. Whereas I
>> can dissolve polygons that have identical features in the argument "IDs",
>> I
>> cannot dissolve tiny polygons based on some threshold in area. In fact,
>> the
>> argument "threshold" has no effect in the output.
>>
>
> Indeed, threshold is not passed through, it was used when the function
> used gpclib rather than rgeos; I'm minded to deprecate
> maptools::unionSpatialPolygons anyway. Note that the data are in
> geographical coordinates, which may very well not be appropriate for the
> topological operations you are trying to do. Use rgeos::gUnaryUnion
> instead, and refer to this thread:
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2015-November/023667.html
>
> for using rgeos::set_RGEOS_polyThreshold() and friends. They do not,
> however, try to guess which of the polygons neighbouring the sliver should
> get the extra area, so you'll have to think that through yourself.
>
> Googling for lists:R-sig-geo dissolve slivers gets a fair number of hits.
>
> There is always also the upstream question of where the slivers came from,
> and whether the resolution is not in the earlier process - generate a map
> without slivers that says exactly what you mean, rather than fudging it
> afterwards.
>
> Roger
>
>
>> ?Input data is available here: ?
>> https://www.dropbox.com/sh/a0x5bbo9u60y7is/AAB6RjXHFQKZv-i-t4JclF3ba?dl=0
>>
>> p.ranges <- shapefile{raster}
>> (IDs <- p.ranges$style_id)
>> library(maptools)
>> unionSpatialPolygons(p.ranges, IDs = IDs, threshold = 1.5)
>>
>> ?-- Kumar Mainali
>> Postdoctoral Associate
>> Department of Biology
>> University of Maryland, College Park
>>
>>
>> ?
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> http://depsy.org/person/434412

	[[alternative HTML version deleted]]


From epalmery at cns.umass.edu  Mon Jun  6 17:07:57 2016
From: epalmery at cns.umass.edu (Evan Palmer-Young)
Date: Mon, 6 Jun 2016 11:07:57 -0400
Subject: [R] [R-sig-ME] multcomp package
In-Reply-To: <CAHLnndbpu0dX4jFXqSevkcGB26H3yh8p2VpcJZWeYpc6KgC6ag@mail.gmail.com>
References: <CAHLnndbpu0dX4jFXqSevkcGB26H3yh8p2VpcJZWeYpc6KgC6ag@mail.gmail.com>
Message-ID: <CAAge6+54jWsBjJ_hr5=72T4X_HJ8joytCMOomKPx4-FhB8fnNw@mail.gmail.com>

Hanna,
If you are interested in whether effect of time varies across individuals,
why don't you fit a model with the predictors (time*individual) as fixed
effects rather than random?

On Mon, Jun 6, 2016 at 10:57 AM, li li <hannah.hlx at gmail.com> wrote:

> Hi all,
>   After fitting a random slope and random intercept model using lme
> function, I want
> to test whether each of the fixed slopes is equal to zero (The output of
> model is below).
> Can this be done (testing each individual slope) using multcomp package?
>   Thanks much for the help.
>    Hanna
>
> > summary(mod1)Linear mixed-effects model fit by REML
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Department of Biology
221 Morrill Science Center
611 North Pleasant St
Amherst MA 01003
https://sites.google.com/a/cornell.edu/evan-palmer-young/

	[[alternative HTML version deleted]]


From lid.zigh at gmail.com  Mon Jun  6 22:38:43 2016
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Mon, 6 Jun 2016 15:38:43 -0500
Subject: [R] replace NAs in each column of a matrix with 0 or 1 or 2 with
	specific proportion
Message-ID: <CAMqbV1C2DO9HDF5+jj_18U6uD3XcJ0_OtF=XtnDAVyqBFZiH_Q@mail.gmail.com>

Hello specialist,

I have a matrix in which there are NA,0,1 and 2 in each columns.
I wanna replace NAs with special proportion of 0,1 or 2 !
for example in df<- matric(df, nrow=50, ncol=100)

If in one column the number of NAs = 10 , # of 0=50 , #of 1=25  and # of
2=15
I want to replace  5 of 10 NAs with 0 , 3 NAs with 1 and 2 NAs with 2!


I've already calculated the proportion of 0, 1 and 2 for each column, just
I don't know how to replace the number of NAs with these number (0,1,2) and
specific proportion?

Thank you very much in advance

	[[alternative HTML version deleted]]


From wwwhsd at gmail.com  Mon Jun  6 23:30:32 2016
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Mon, 6 Jun 2016 18:30:32 -0300
Subject: [R] replace NAs in each column of a matrix with 0 or 1 or 2
 with specific proportion
In-Reply-To: <CAMqbV1C2DO9HDF5+jj_18U6uD3XcJ0_OtF=XtnDAVyqBFZiH_Q@mail.gmail.com>
References: <CAMqbV1C2DO9HDF5+jj_18U6uD3XcJ0_OtF=XtnDAVyqBFZiH_Q@mail.gmail.com>
Message-ID: <CAPvBnPG6McNv=cPx2NxUB-sxFSDa1waKVRMPBmDJp9pSHyzEMQ@mail.gmail.com>

Maybe you can use something like this

In this way, almost your proportion of 0, 1 and 2 will be maintained

m <- matrix(sample(c(NA, 0:2), size = 50*100, replace = TRUE), nrow = 50,
ncol = 100)
trunc(prop.table(apply(m, 2, table), 2) * colSums(is.na(m)), 0)
m[is.na(m)] <- unlist(apply(trunc(prop.table(apply(m, 2, table), 2) *
colSums(is.na(m)), 0), 2, rep, x = 0:2))

On Mon, Jun 6, 2016 at 5:38 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:

> Hello specialist,
>
> I have a matrix in which there are NA,0,1 and 2 in each columns.
> I wanna replace NAs with special proportion of 0,1 or 2 !
> for example in df<- matric(df, nrow=50, ncol=100)
>
> If in one column the number of NAs = 10 , # of 0=50 , #of 1=25  and # of
> 2=15
> I want to replace  5 of 10 NAs with 0 , 3 NAs with 1 and 2 NAs with 2!
>
>
> I've already calculated the proportion of 0, 1 and 2 for each column, just
> I don't know how to replace the number of NAs with these number (0,1,2) and
> specific proportion?
>
> Thank you very much in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Henrique Dallazuanna
Curitiba-Paran?-Brasil
25? 25' 40" S 49? 16' 22" O

	[[alternative HTML version deleted]]


From nidal.alhuniti at gmail.com  Tue Jun  7 00:25:45 2016
From: nidal.alhuniti at gmail.com (nidal.alhuniti at gmail.com)
Date: Mon, 6 Jun 2016 18:25:45 -0400
Subject: [R] R programmer/developer part time job
Message-ID: <CAEa9M90mv8Vepda=wh=X=DporrtsLAfdSiYixZntqmJ3RO-4VA@mail.gmail.com>

AstraZeneca, a leading pharmaceutical company, has an exciting opportunity
for an R-developer within its Quantitative Clinical Pharmacology (QCP)
group. The position is a 6-12 month contract position which will integrate
R programming knowledge, capabilities and prowess towards pharmacometric
analysis objectives.



The position is located in Waltham, Massachusetts (outside Boston).



The candidate will engage and contribute their programming expertise
towards meaningful pharmacometric industrialization projects. This includes
the development and implementation of state-of-the-art infrastructure
tools, applications and processes that will directly facilitate
cutting-edge pharmacometric modeling research towards bettering the health
well-being of individuals.



The candidate will be exposed to project related activities to help him/her
develop an understanding of Clinical Pharmacology?s role in drug
development.



Education, Experience and Knowledge

?             MS. or PhD in a relevant technical discipline, such as
machine learning, computer science, physics, engineering, mathematics,
statistics, or related field, or 3+ years of experience in a relevant role.

?             Expert knowledge of R (expert R coding and programming
practices; ability to design and write functions).

?             Demonstrated leadership experience preferred.



Specific Skills

?             Experience in building R packages, good understanding of S3
and S4 methods, and knowledge of generics R work as well as R environments.

?             Experience in making advanced reproducible report using
Sweave and knitr including tables, graphs and literate programming.

?             Proficiency with other scientific computer language such as
MATLAB, Python and rJava.

?             Expertise with the C++ programming language.

?             Strong knowledge of computer science practices; strong
technical aptitude.



Other Skills

?             Ability to work within a cross-functional teams with strong
interpersonal abilities.

?             Strong written and verbal communication skills.

?             Strong customer service orientation.

?             Solid analytical capability; ability to exercise sound
judgment.

?             Strong attention to detail.

?             Strong organization and prioritization skills; ability to
perform multiple tasks and meet deadlines.

?             Proficiency in Microsoft Office software.



Required experience:

?             3+ years of experience in a relevant role.: 3 years

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun  7 01:17:14 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Jun 2016 16:17:14 -0700
Subject: [R] replace NAs in each column of a matrix with 0 or 1 or 2
 with specific proportion
In-Reply-To: <CAMqbV1C2DO9HDF5+jj_18U6uD3XcJ0_OtF=XtnDAVyqBFZiH_Q@mail.gmail.com>
References: <CAMqbV1C2DO9HDF5+jj_18U6uD3XcJ0_OtF=XtnDAVyqBFZiH_Q@mail.gmail.com>
Message-ID: <CAGxFJbT1mk6aEAsgufoQAu4fHG-OpKtT8K3f91CV=UrznLj0DA@mail.gmail.com>

Sidenote:

When you do imputation in this way all your inference (error
estimates, goodness of fit, confidence intervals, etc.) will be wrong
and misleading, as you are creating "information" from nothing.

If this comment is irrelevant, please ignore.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 6, 2016 at 1:38 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> Hello specialist,
>
> I have a matrix in which there are NA,0,1 and 2 in each columns.
> I wanna replace NAs with special proportion of 0,1 or 2 !
> for example in df<- matric(df, nrow=50, ncol=100)
>
> If in one column the number of NAs = 10 , # of 0=50 , #of 1=25  and # of
> 2=15
> I want to replace  5 of 10 NAs with 0 , 3 NAs with 1 and 2 NAs with 2!
>
>
> I've already calculated the proportion of 0, 1 and 2 for each column, just
> I don't know how to replace the number of NAs with these number (0,1,2) and
> specific proportion?
>
> Thank you very much in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Jun  7 01:19:50 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Jun 2016 16:19:50 -0700
Subject: [R] R programmer/developer part time job
In-Reply-To: <CAEa9M90mv8Vepda=wh=X=DporrtsLAfdSiYixZntqmJ3RO-4VA@mail.gmail.com>
References: <CAEa9M90mv8Vepda=wh=X=DporrtsLAfdSiYixZntqmJ3RO-4VA@mail.gmail.com>
Message-ID: <CAGxFJbT9O5513F0RCu1e5rFE=St0+U4MPkuM09HU--t_wNL+EQ@mail.gmail.com>

This should be posted on the r-sig-jobs email list.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 6, 2016 at 3:25 PM,  <nidal.alhuniti at gmail.com> wrote:
> AstraZeneca, a leading pharmaceutical company, has an exciting opportunity
> for an R-developer within its Quantitative Clinical Pharmacology (QCP)
> group. The position is a 6-12 month contract position which will integrate
> R programming knowledge, capabilities and prowess towards pharmacometric
> analysis objectives.
>
>
>
> The position is located in Waltham, Massachusetts (outside Boston).
>
>
>
> The candidate will engage and contribute their programming expertise
> towards meaningful pharmacometric industrialization projects. This includes
> the development and implementation of state-of-the-art infrastructure
> tools, applications and processes that will directly facilitate
> cutting-edge pharmacometric modeling research towards bettering the health
> well-being of individuals.
>
>
>
> The candidate will be exposed to project related activities to help him/her
> develop an understanding of Clinical Pharmacology?s role in drug
> development.
>
>
>
> Education, Experience and Knowledge
>
> ?             MS. or PhD in a relevant technical discipline, such as
> machine learning, computer science, physics, engineering, mathematics,
> statistics, or related field, or 3+ years of experience in a relevant role.
>
> ?             Expert knowledge of R (expert R coding and programming
> practices; ability to design and write functions).
>
> ?             Demonstrated leadership experience preferred.
>
>
>
> Specific Skills
>
> ?             Experience in building R packages, good understanding of S3
> and S4 methods, and knowledge of generics R work as well as R environments.
>
> ?             Experience in making advanced reproducible report using
> Sweave and knitr including tables, graphs and literate programming.
>
> ?             Proficiency with other scientific computer language such as
> MATLAB, Python and rJava.
>
> ?             Expertise with the C++ programming language.
>
> ?             Strong knowledge of computer science practices; strong
> technical aptitude.
>
>
>
> Other Skills
>
> ?             Ability to work within a cross-functional teams with strong
> interpersonal abilities.
>
> ?             Strong written and verbal communication skills.
>
> ?             Strong customer service orientation.
>
> ?             Solid analytical capability; ability to exercise sound
> judgment.
>
> ?             Strong attention to detail.
>
> ?             Strong organization and prioritization skills; ability to
> perform multiple tasks and meet deadlines.
>
> ?             Proficiency in Microsoft Office software.
>
>
>
> Required experience:
>
> ?             3+ years of experience in a relevant role.: 3 years
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Tue Jun  7 05:29:10 2016
From: hannah.hlx at gmail.com (li li)
Date: Mon, 6 Jun 2016 23:29:10 -0400
Subject: [R] [R-sig-ME] multcomp package
In-Reply-To: <048c61a6-fbea-321f-e853-2b236cdf1ed7@hsr.it>
References: <CAHLnndbpu0dX4jFXqSevkcGB26H3yh8p2VpcJZWeYpc6KgC6ag@mail.gmail.com>
	<048c61a6-fbea-321f-e853-2b236cdf1ed7@hsr.it>
Message-ID: <CAHLnndbtTUrBL4z8HeubnA35q-o3NPh6O7K=if3VZAo6i1a3TA@mail.gmail.com>

Thanks Evan and Gabriel for the reply. I think it might help me make the
question clearer if I show the data and the model here (I actually asked
questions related to this data before but I still need some help). The data
looks like the following:

   response individual time method
1    102.9          3    0      3
2    103.0          3    3      3
3    103.0          3    6      3
4    102.8          3    9      3
5    102.2          3   12      3
6    102.5          3   15      3
7    103.0          3   18      3
8    102.0          3   24      3
9    102.8          1    0      3
10   102.7          1    3      3
11   103.0          1    6      3
12   102.2          1    9      3
13   103.0          1   12      3
14   102.8          1   15      3
15   102.8          1   18      3
16   102.9          1   24      3
17   102.2          2    0      3
18   102.6          2    3      3
19   103.4          2    6      3
20   102.3          2    9      3
21   101.3          2   12      3
22   102.1          2   15      3
23   102.1          2   18      3
24   102.2          2   24      3
25   102.7          4    0      3
26   102.3          4    3      3
27   102.6          4    6      3
28   102.7          4    9      3
29   102.8          4   12      3
30   102.5          5    0      3
31   102.4          5    3      3
32   102.1          5    6      3
33   102.3          6    0      3
34   102.3          6    3      3
35   101.9          7    0      3
36   102.0          7    3      3
37   107.4          3    0      1
38   101.3          3   12      1
39    92.8          3   15      1
40    73.7          3   18      1
41   104.7          3   24      1
42    92.6          1    0      1
43   101.9          1   12      1
44   106.3          1   15      1
45   104.1          1   18      1
46    95.6          1   24      1
47    79.8          2    0      1
48    89.7          2   12      1
49    97.0          2   15      1
50   108.4          2   18      1
51   103.5          2   24      1
52    96.4          4    0      1
53    89.3          4   12      1
54   112.6          5    0      1
55    93.3          6    0      1
56    99.6          7    0      1
57   109.5          3    0      2
58    98.5          3   12      2
59   103.5          3   24      2
60   113.5          1    0      2
61    94.5          1   12      2
62    88.5          1   24      2
63    99.5          2    0      2
64    97.5          2   12      2
65    98.5          2   24      2
66   103.5          4    0      2
67    89.5          5    0      2
68    87.5          6    0      2
69    82.5          7    0      2



I used the following random intercept and random slope model for this data.

Denote as y_ijk the response value from *j*th individual within *i*th
method at time point *k*. Assume the following model for y_ijk:

      y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk


Here alpha_0 is the grand mean;
          tau_i is the fixed effect for ith method;
          a_j(i) is random intercept corresponding to the *j*th individual
within *i*th method, assumed to be common for all three methods;
          beta_i is the fixed slope corresponding to the ith method;
          b_j(i) is the random slope corresponding to jth individual for
the ith method, assumed to be common for all three methods;
          T_k is the time corresponding to y_ijk;
          e_ijk is the residual.

Here I used the following specification for the lme function

mod1 <- lme(fixed= reponse ~ method*time, random=~ 1 +time | individual,
data=one, weights= varIdent(form=~1|method),
            control = lmeControl(opt = "optim"))

I did not add the method in random effects  because here I assumed common
random slope for all three methods.

This model is used to initially check whether there fixed slopes are equal.
I wanted to further evaluate whether each fixed slope (beta_1, beta_2 and
beta 3) is significantly different from zero. I was hoping to evaluate this
based on the same model.

The output is as follows. Does the highlighted part below already gives the
result for testing beta_1=0; beta_2=0 and beta_3=0?

Thanks very much.
   Hanna

> summary(mod1)Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352

Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953
Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014time
0.07010  0.250983 57  0.279301  0.7810
method2:time -0.12616  0.360585 57 -0.349877  0.7277
method3:time -0.08010  0.251105 57 -0.318999  0.7509
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874

Number of Observations: 69
Number of Groups: 7










2016-06-06 11:21 GMT-04:00 Gabriel Baud-Bovy <baud-bovy.gabriel at hsr.it>:

> On 06/06/2016 4:57 PM, li li wrote:
>
> Hi all,
>   After fitting a random slope and random intercept model using lme
> function, I want
> to test whether each of the fixed slopes is equal to zero (The output of
> model is below).
> Can this be done (testing each individual slope) using multcomp package?
>
> I don't understand what you mean by testing individual slope ?
>
> For the fixed effects, you might test whether there is a method, time or
> interaction
> effect using one of the methods described below
>
> For the randome effects, according to your model specification, the time
> dependency might vary for each individual. the sd for the time
> (0.0001841179)
> is small.  You might want to test whether to include randome slope  by
> doing a LRT
> between a model with it and another model without.
>
> Whay not include method in the random effects ?
>
> Gabriel
>
>   Thanks much for the help.
>    Hanna
>
> To get p values:
>
>
> http://stats.stackexchange.com/questions/118416/getting-p-value-with-mixed-effect-with-lme4-package
>
>
> http://mindingthebrain.blogspot.it/2014/02/three-ways-to-get-parameter-specific-p.html
>
> Using lmerTest package
> https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf
>
> or using mixed in afex package
> http://rpackages.ianhowson.com/cran/afex/man/mixed.html
>
> both use pbkrtest packages
> https://cran.r-project.org/web/packages/pbkrtest/pbkrtest.pdf
>
> a faq
> http://glmm.wikidot.com/faq
>
>
>
>
> summary(mod1)Linear mixed-effects model fit by REML
>
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .
>
>
>
>
> --
> ---------------------------------------------------------------------
> Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
> UHSR University                       (+39) 02 2643 3429 (laboratory)
> via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
> 20132 Milan, Italy               fax: (+39) 02 2643 4892
> ---------------------------------------------------------------------
>
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Jun  7 07:51:36 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 07 Jun 2016 05:51:36 +0000
Subject: [R] Knitr R - how to draw plot exactly at place of plot
 function call in output document?
In-Reply-To: <CAEJSOqgpEbAHs-kzksqkCJ6tdmx2LS5VYRF=Kg_4TAo3QabzuQ@mail.gmail.com>
References: <CAEJSOqi96Qt6O5qhZbTE5ax8GPNoC31t5vN_gjFgGazhbiDFvQ@mail.gmail.com>
	<CAKVAULPhdUMdrU4Gk+pJ5w=YCB=+pg7+zTG6cWG6Bmgy0B-AhA@mail.gmail.com>
	<CAEJSOqgpEbAHs-kzksqkCJ6tdmx2LS5VYRF=Kg_4TAo3QabzuQ@mail.gmail.com>
Message-ID: <CAKVAULMhB-AQP9jh5MEjtSMq364EqYxJ+jc-8MEuqSHCRjXzug@mail.gmail.com>

Hi Michu,

it is not I problem I am familiar with, sorry. Maybe someone else on this
list or at the knirt google group can help you further.

Best,
Ulrik

On Mon, 6 Jun 2016 at 10:36 Michu Kom <michu.kom at gmail.com> wrote:

> Hello,
>
> HTML looks much nicer :) ... but still problem is not solved :/ still
> having mixed sections and plots.
>
> Thank you for your advice,
> Michu
>
> 2016-06-06 10:04 GMT+02:00 Ulrik Stervbo <ulrik.stervbo at gmail.com>:
>
>> Hi Michu,
>>
>> What document type do you generate? I usually make just html and have no
>> problems. If you create a pdf, please remember this is done through LaTeX
>> and your problem could arise from the floats of LaTeX.
>>
>> For other output I have no idea.
>>
>> Hope this helps
>> Ulrik
>>
>> Michu Kom <michu.kom at gmail.com> schrieb am Mo., 6. Juni 2016 09:41:
>>
>>> My R script run with Knitr generates a statistic summary of electrode
>>> pairs
>>> accompanied with plots. The problem is that knitr does not render plots
>>> in
>>> correct sections. In section for pair A knitr do not wait for plot and
>>> start to evaluate code for output summary for pair B. So in section B
>>> knitr
>>> places plot from section A among printed output summary for pair B.
>>>
>>> My function analizePair calculates some statistics and print them out. I
>>> call a ezPlot function inside analizePair function.
>>>
>>> knitr::opts_chunk$set(fig.show = 'asis') # 'hold' option is not proper
>>> for my needs
>>> for(pair in pairsLabels)
>>>     {
>>>         print("----------")
>>>         print("Analysing single pair of electrodes...")
>>>         print("----------")
>>>         print(pair)
>>>
>>>         analizePair(pairLabel = pair)
>>>
>>>         print("----------")
>>>         print("Analysing pair finished.")
>>>         print("----------")
>>>     }
>>>
>>> I also tried to put Sys.sleep(2) after analizePair, but it do not solve
>>> the
>>> problem.
>>>
>>> How to force knitr/R to wait until plot is generated and put before
>>> starting next section (next iteration of for loop) ?
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue Jun  7 08:18:51 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 7 Jun 2016 08:18:51 +0200
Subject: [R] Antwort: Re:  Merging variables
In-Reply-To: <08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
Message-ID: <OF7CB676EC.936B8ED0-ONC1257FCB.00228C15-C1257FCB.0022AF89@lotus.hawesko.de>

Hi Michael,

yes, I was astonished about this behaviour either. I have worked with SPSS 
a lot - and that works different.

I would like to share some of my data. Can you tell me how I can dump a 
dataset in a way that I can post it here as text?

Kind regards

Georg




Von:    Michael Dewey <lists at dewey.myzen.co.uk>
An:     G.Maubach at weinwolf.de, r-help at r-project.org, 
Datum:  06.06.2016 15:45
Betreff:        Re: [R] Merging variables



X-Originating-<%= hostname %>-IP: [217.155.205.190]

Dear Georg

I find it a bit surprising that you end up with customer.x and 
customer.y. Can you share with us a toy example of two data.frames which 
exhibit this behaviour?

On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I merged two datasets:
>
> ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> ds_zww_customer_4_match,
>   by.x = "customer", by.y = "customer",
>   all.x = TRUE, all.y = FALSE)
>
> R created a new dataset with the variables customer.x and customer.y. I
> would like to merge these two variable back together. I wrote a little
> function (code can be run) for it:
>
> -- cut --
>
> customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> ds_test <- data.frame(customer.x, customer.y, stringsAsFactors = FALSE)
>
> t_merge_variables <-
>   function(dataset,
>            var1,
>            var2,
>            merged_var) {
>
>     # Initialize
>     dataset[[merged_var]] = rep(NA, nrow(dataset))
>     dataset[["mismatch"]] = rep(NA, nrow(dataset))
>
>     for (i in 1:nrow(dataset)) {
>
>       # Check 1: var1 missing, var2 missing
>       if (is.na(dataset[[i, var1]]) &
>           is.na(dataset[[i, var2]])) {
>         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
>
>       # Check 2: var1 filled, var2 missing
>       } else if (!is.na(dataset[[i, var1]]) &
>                  is.na(dataset[[i, var2]])) {
>         dataset[[i, merged_var]] <- dataset[[i, var1]]
>         dataset[["mismatch"]] <- 0
>
>       # Check 3: var1 missing, var2 filled
>       } else if (is.na(dataset[[i, var1]]) &
>                  !is.na(dataset[i, var2])) {
>         dataset[[i, merged_var]] <- dataset[[i, var2]]
>         dataset[["mismatch"]] <-  0
>
>       # Check 4: var1 == var2
>       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
>       dataset[[i, merged_var]] <- dataset[[i, var1]]
>       dataset[["mismatch"]] <- 0
>
>       # Leftover: var1 != var2
>       } else {
>         dataset[[i, merged_var]] <- NA
>         dataset[["mismatch"]] <- 2  # var1 != var2
>       }  # end if
>     }  # end for
>     return(dataset)
> }
>
> ds_var_merge1 <- t_merge_variables(dataset = ds_test,
>   var1 = "customer.x",
>   var2 = "customer.y",
>   merged_var = "customer")
>
> ds_var_merge1
>
> -- cut --
>
> It is executed without error but delivers the wrong values in the 
variable
> "mismatch". This variable is always 1 although it should be NA, 1 or 2
> respectively.
>
> Can you tell me why the variable is not correctly set?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From G.Maubach at weinwolf.de  Tue Jun  7 08:35:18 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 7 Jun 2016 08:35:18 +0200
Subject: [R] Antwort: RE:  Merging variables
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502E188@SRVEXCHMBX.precheza.cz>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502E188@SRVEXCHMBX.precheza.cz>
Message-ID: <OFCB0DB885.91677ABF-ONC1257FCB.00234166-C1257FCB.00243162@lotus.hawesko.de>

Hi Petr,

I would like to describe the data situation in brief:

I have an business warehouse dataset (referred to as BW data) containing 
sales and an ERP  customer master data dataset with additional information 
(referred to as ERP data). Though customer IDs and customer names are 
identical due to the fact that the business warehouse data is derived from 
the ERP data.  Due to selection criteria the BW data contains slightly 
more customers than the ERP data. So customer names and all other 
information is missing in the ERP data for some cases of the BW data.  If 
I merge those by customer ID variable customer names are duplicated using 
customer.x and customer.y as variable names.

As both fields contains the same contents I would have expected R to merge 
this into one variable, e. g. customer. But this is not the case.

Can I adjust the below given merge statement - which looks almost the same 
in my script - that R does the merge of the variables if they are 
identical automatically?

This is my code using left join:

-- cut --

ds_merge1 <- merge(x = ds_bw_customer_4_match, y = 
ds_erp_customer_4_match,
  by.x = "CustID", by.y = "CustID",
  all.x = TRUE, all.y = FALSE)

-- cut --

Kind regards

Georg




Von:    PIKAL Petr <petr.pikal at precheza.cz>
An:     Michael Dewey <lists at dewey.myzen.co.uk>, "G.Maubach at weinwolf.de" 
<G.Maubach at weinwolf.de>, "r-help at r-project.org" <r-help at r-project.org>, 
Datum:  06.06.2016 17:04
Betreff:        RE: [R] Merging variables



Hi Michael

it is simple

set.seed(111)
let=sample(letters[1:10],6, replace=T)
dat1<-data.frame(let=let, customer=sample(1:10,6, replace=T))
let=sample(letters[1:10],6, replace=T)
dat2<-data.frame(let=let, customer=sample(1:10,6, replace=T))
merge(dat1, dat2, by.x="let", by.y="let", all=T)

Of course you could add customer variable to by parameter but sometimes it 
is necessary to leave it out. When you have two sets of analytical results 
and you have 2 variables operator but you want to merge those sets e.g. by 
date/hour of analysis.

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Dewey
> Sent: Monday, June 6, 2016 3:46 PM
> To: G.Maubach at weinwolf.de; r-help at r-project.org
> Subject: Re: [R] Merging variables
>
> X-Originating-<%= hostname %>-IP: [217.155.205.190]
>
> Dear Georg
>
> I find it a bit surprising that you end up with customer.x and 
customer.y. Can
> you share with us a toy example of two data.frames which exhibit this
> behaviour?
>
> On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
> > Hi All,
> >
> > I merged two datasets:
> >
> > ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> > ds_zww_customer_4_match,
> >   by.x = "customer", by.y = "customer",
> >   all.x = TRUE, all.y = FALSE)
> >
> > R created a new dataset with the variables customer.x and customer.y.
> > I would like to merge these two variable back together. I wrote a
> > little function (code can be run) for it:
> >
> > -- cut --
> >
> > customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> > customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> > ds_test <- data.frame(customer.x, customer.y, stringsAsFactors =
> > FALSE)
> >
> > t_merge_variables <-
> >   function(dataset,
> >            var1,
> >            var2,
> >            merged_var) {
> >
> >     # Initialize
> >     dataset[[merged_var]] = rep(NA, nrow(dataset))
> >     dataset[["mismatch"]] = rep(NA, nrow(dataset))
> >
> >     for (i in 1:nrow(dataset)) {
> >
> >       # Check 1: var1 missing, var2 missing
> >       if (is.na(dataset[[i, var1]]) &
> >           is.na(dataset[[i, var2]])) {
> >         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
> >
> >       # Check 2: var1 filled, var2 missing
> >       } else if (!is.na(dataset[[i, var1]]) &
> >                  is.na(dataset[[i, var2]])) {
> >         dataset[[i, merged_var]] <- dataset[[i, var1]]
> >         dataset[["mismatch"]] <- 0
> >
> >       # Check 3: var1 missing, var2 filled
> >       } else if (is.na(dataset[[i, var1]]) &
> >                  !is.na(dataset[i, var2])) {
> >         dataset[[i, merged_var]] <- dataset[[i, var2]]
> >         dataset[["mismatch"]] <-  0
> >
> >       # Check 4: var1 == var2
> >       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
> >       dataset[[i, merged_var]] <- dataset[[i, var1]]
> >       dataset[["mismatch"]] <- 0
> >
> >       # Leftover: var1 != var2
> >       } else {
> >         dataset[[i, merged_var]] <- NA
> >         dataset[["mismatch"]] <- 2  # var1 != var2
> >       }  # end if
> >     }  # end for
> >     return(dataset)
> > }
> >
> > ds_var_merge1 <- t_merge_variables(dataset = ds_test,
> >   var1 = "customer.x",
> >   var2 = "customer.y",
> >   merged_var = "customer")
> >
> > ds_var_merge1
> >
> > -- cut --
> >
> > It is executed without error but delivers the wrong values in the
> > variable "mismatch". This variable is always 1 although it should be
> > NA, 1 or 2 respectively.
> >
> > Can you tell me why the variable is not correctly set?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter 
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization 
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.


From stefano.sofia at regione.marche.it  Tue Jun  7 08:55:01 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Tue, 7 Jun 2016 06:55:01 +0000
Subject: [R] evaluate the daily mean with date in "POSIXct" "POSIXt" class
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBB705D@ESINO.regionemarche.intra>

Dear R-list users,
I have the following data frame, called MteBove:

posix_date    snow    temp
...
2010-01-20 23:30:00 45 NA
2010-01-02 00:30:00 10-2.7
2010-01-20 03:00:00 45 NA
2010-01-20 03:30:00 44 NA
2010-01-20 04:00:00 44 NA
2010-01-20 04:30:00 44 NA
2010-01-20 05:00:00 44 NA
2010-01-20 05:30:00 45 NA
2010-01-20 06:00:00 44 NA
2010-01-20 06:30:00 45 NA
...

> sapply(MteBove, class)
gives
$posix_date
[1] "POSIXct" "POSIXt"

$snow
[1] "numeric"

$temp
[1] "numeric"

There are semi-hourly data (i.e. 48 data each day) from the first of November to the first of May of each Winter season, and I need the daily mean for snow and temp.
First I created a subset for each Winter season
I tried to create a new column with only the day, like

> MteBove$day <- trunc(MteBove$posix_date, "days")

and then

> list_days <- unique(MteBove$day)
> means <- rapply(list_days, function(x) mean(MteBove[MteBove$day == x, ], na.rm=T))

with the following result:
[1] "means IS"
  sec   min  hour  mday   mon  year  wday  yday isdst
   NA    NA    NA    NA    NA    NA    NA    NA    NA

I tried some changes always in this direction, with no success.
Is there an efficient way to do that?
Could somebody give me an hint about it?

Thank you for your attention and your help
Stefano Sofia


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Jun  7 09:39:21 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 7 Jun 2016 17:39:21 +1000
Subject: [R] evaluate the daily mean with date in "POSIXct" "POSIXt"
	class
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBB705D@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBB705D@ESINO.regionemarche.intra>
Message-ID: <CA+8X3fXc2Qb08O51pdPuYBisEfQhuHOOpGeapUJmnc6kYj7H3Q@mail.gmail.com>

Hi Stefano,
I might be missing something, but try this:

MteBove<-read.table(text="posix_date  posix_time  snow    temp
 2010-01-19 23:30:00 45 NA
 2010-01-20 00:30:00 10 2.7
 2010-01-20 03:00:00 45 NA
 2010-01-20 03:30:00 44 NA
 2010-01-20 04:00:00 44 NA
 2010-01-20 04:30:00 44 NA
 2010-01-20 05:00:00 44 NA
 2010-01-20 05:30:00 45 NA
 2010-01-20 06:00:00 44 NA
 2010-01-20 06:30:00 45 NA
 2010-01-20 23:30:00 45 NA
 2010-01-21 00:30:00 10 2.7
 2010-01-21 03:00:00 45 NA
 2010-01-21 03:30:00 44 NA
 2010-01-21 04:00:00 44 NA
 2010-01-21 04:30:00 44 NA
 2010-01-21 05:00:00 44 NA
 2010-01-21 05:30:00 45 NA
 2010-01-21 06:00:00 44 NA
 2010-01-21 06:30:00 45 NA",
 header=TRUE)
MteBove$day<-as.Date(MteBove$posix_date,"%Y-%m-%d")
by(MteBove$snow,MteBove$day,mean)

and if you have NA values, add na.rm=TRUE to the last line.

Jim


On Tue, Jun 7, 2016 at 4:55 PM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-list users,
> I have the following data frame, called MteBove:
>
> posix_date    snow    temp
> ...
> 2010-01-20 23:30:00 45 NA
> 2010-01-02 00:30:00 10-2.7
> 2010-01-20 03:00:00 45 NA
> 2010-01-20 03:30:00 44 NA
> 2010-01-20 04:00:00 44 NA
> 2010-01-20 04:30:00 44 NA
> 2010-01-20 05:00:00 44 NA
> 2010-01-20 05:30:00 45 NA
> 2010-01-20 06:00:00 44 NA
> 2010-01-20 06:30:00 45 NA
> ...
>
>> sapply(MteBove, class)
> gives
> $posix_date
> [1] "POSIXct" "POSIXt"
>
> $snow
> [1] "numeric"
>
> $temp
> [1] "numeric"
>
> There are semi-hourly data (i.e. 48 data each day) from the first of November to the first of May of each Winter season, and I need the daily mean for snow and temp.
> First I created a subset for each Winter season
> I tried to create a new column with only the day, like
>
>> MteBove$day <- trunc(MteBove$posix_date, "days")
>
> and then
>
>> list_days <- unique(MteBove$day)
>> means <- rapply(list_days, function(x) mean(MteBove[MteBove$day == x, ], na.rm=T))
>
> with the following result:
> [1] "means IS"
>   sec   min  hour  mday   mon  year  wday  yday isdst
>    NA    NA    NA    NA    NA    NA    NA    NA    NA
>
> I tried some changes always in this direction, with no success.
> Is there an efficient way to do that?
> Could somebody give me an hint about it?
>
> Thank you for your attention and your help
> Stefano Sofia
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Jun  7 13:00:29 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 7 Jun 2016 11:00:29 +0000
Subject: [R] Antwort: RE:  Merging variables
In-Reply-To: <OFCB0DB885.91677ABF-ONC1257FCB.00234166-C1257FCB.00243162@lotus.hawesko.de>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502E188@SRVEXCHMBX.precheza.cz>
	<OFCB0DB885.91677ABF-ONC1257FCB.00234166-C1257FCB.00243162@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502F2FA@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: G.Maubach at weinwolf.de [mailto:G.Maubach at weinwolf.de]
> Sent: Tuesday, June 7, 2016 8:35 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: Michael Dewey <lists at dewey.myzen.co.uk>; r-help at r-project.org
> Subject: Antwort: RE: [R] Merging variables
>
> Hi Petr,
>
> I would like to describe the data situation in brief:
>
> I have an business warehouse dataset (referred to as BW data) containing
> sales and an ERP  customer master data dataset with additional information
> (referred to as ERP data). Though customer IDs and customer names are
> identical due to the fact that the business warehouse data is derived from
> the ERP data.  Due to selection criteria the BW data contains slightly more
> customers than the ERP data. So customer names and all other information is
> missing in the ERP data for some cases of the BW data.  If I merge those by
> customer ID variable customer names are duplicated using customer.x and
> customer.y as variable names.
>
> As both fields contains the same contents I would have expected R to merge
> this into one variable, e. g. customer. But this is not the case.
>
> Can I adjust the below given merge statement - which looks almost the same
> in my script - that R does the merge of the variables if they are identical
> automatically?
>
> This is my code using left join:
>
> -- cut --
>
> ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> ds_erp_customer_4_match,
>   by.x = "CustID", by.y = "CustID",
>   all.x = TRUE, all.y = FALSE)


you could use by.x=c("CustId", "customer"), by.y=c("CustId", "customer")

This shall give you merged data both on customer id and customer name.

Regards
Petr

>
> -- cut --
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    PIKAL Petr <petr.pikal at precheza.cz>
> An:     Michael Dewey <lists at dewey.myzen.co.uk>,
> "G.Maubach at weinwolf.de"
> <G.Maubach at weinwolf.de>, "r-help at r-project.org" <r-help at r-
> project.org>,
> Datum:  06.06.2016 17:04
> Betreff:        RE: [R] Merging variables
>
>
>
> Hi Michael
>
> it is simple
>
> set.seed(111)
> let=sample(letters[1:10],6, replace=T)
> dat1<-data.frame(let=let, customer=sample(1:10,6, replace=T))
> let=sample(letters[1:10],6, replace=T)
> dat2<-data.frame(let=let, customer=sample(1:10,6, replace=T))
> merge(dat1, dat2, by.x="let", by.y="let", all=T)
>
> Of course you could add customer variable to by parameter but sometimes it
> is necessary to leave it out. When you have two sets of analytical results
> and you have 2 variables operator but you want to merge those sets e.g. by
> date/hour of analysis.
>
> Regards
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> > Dewey
> > Sent: Monday, June 6, 2016 3:46 PM
> > To: G.Maubach at weinwolf.de; r-help at r-project.org
> > Subject: Re: [R] Merging variables
> >
> > X-Originating-<%= hostname %>-IP: [217.155.205.190]
> >
> > Dear Georg
> >
> > I find it a bit surprising that you end up with customer.x and
> customer.y. Can
> > you share with us a toy example of two data.frames which exhibit this
> > behaviour?
> >
> > On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
> > > Hi All,
> > >
> > > I merged two datasets:
> > >
> > > ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> > > ds_zww_customer_4_match,
> > >   by.x = "customer", by.y = "customer",
> > >   all.x = TRUE, all.y = FALSE)
> > >
> > > R created a new dataset with the variables customer.x and customer.y.
> > > I would like to merge these two variable back together. I wrote a
> > > little function (code can be run) for it:
> > >
> > > -- cut --
> > >
> > > customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> > > customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> > > ds_test <- data.frame(customer.x, customer.y, stringsAsFactors =
> > > FALSE)
> > >
> > > t_merge_variables <-
> > >   function(dataset,
> > >            var1,
> > >            var2,
> > >            merged_var) {
> > >
> > >     # Initialize
> > >     dataset[[merged_var]] = rep(NA, nrow(dataset))
> > >     dataset[["mismatch"]] = rep(NA, nrow(dataset))
> > >
> > >     for (i in 1:nrow(dataset)) {
> > >
> > >       # Check 1: var1 missing, var2 missing
> > >       if (is.na(dataset[[i, var1]]) &
> > >           is.na(dataset[[i, var2]])) {
> > >         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
> > >
> > >       # Check 2: var1 filled, var2 missing
> > >       } else if (!is.na(dataset[[i, var1]]) &
> > >                  is.na(dataset[[i, var2]])) {
> > >         dataset[[i, merged_var]] <- dataset[[i, var1]]
> > >         dataset[["mismatch"]] <- 0
> > >
> > >       # Check 3: var1 missing, var2 filled
> > >       } else if (is.na(dataset[[i, var1]]) &
> > >                  !is.na(dataset[i, var2])) {
> > >         dataset[[i, merged_var]] <- dataset[[i, var2]]
> > >         dataset[["mismatch"]] <-  0
> > >
> > >       # Check 4: var1 == var2
> > >       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
> > >       dataset[[i, merged_var]] <- dataset[[i, var1]]
> > >       dataset[["mismatch"]] <- 0
> > >
> > >       # Leftover: var1 != var2
> > >       } else {
> > >         dataset[[i, merged_var]] <- NA
> > >         dataset[["mismatch"]] <- 2  # var1 != var2
> > >       }  # end if
> > >     }  # end for
> > >     return(dataset)
> > > }
> > >
> > > ds_var_merge1 <- t_merge_variables(dataset = ds_test,
> > >   var1 = "customer.x",
> > >   var2 = "customer.y",
> > >   merged_var = "customer")
> > >
> > > ds_var_merge1
> > >
> > > -- cut --
> > >
> > > It is executed without error but delivers the wrong values in the
> > > variable "mismatch". This variable is always 1 although it should be
> > > NA, 1 or 2 respectively.
> > >
> > > Can you tell me why the variable is not correctly set?
> > >
> > > Kind regards
> > >
> > > Georg
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From petr.pikal at precheza.cz  Tue Jun  7 13:12:22 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 7 Jun 2016 11:12:22 +0000
Subject: [R] Antwort: Re:  Merging variables
In-Reply-To: <OF7CB676EC.936B8ED0-ONC1257FCB.00228C15-C1257FCB.0022AF89@lotus.hawesko.de>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
	<OF7CB676EC.936B8ED0-ONC1257FCB.00228C15-C1257FCB.0022AF89@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502F332@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Tuesday, June 7, 2016 8:19 AM
> To: Michael Dewey <lists at dewey.myzen.co.uk>
> Cc: r-help at r-project.org
> Subject: [R] Antwort: Re: Merging variables
>
> Hi Michael,
>
> yes, I was astonished about this behaviour either. I have worked with SPSS a
> lot - and that works different.

If you want to join two data frames by common names you can use use

merge(dat1, dat2, ....)

without specifing by. From help page:

By default the data frames are merged on the columns with names they both have, but separate specifications of the columns can be given by by.x and by.y. The rows in the two data frames that match on the specified columns are extracted, and joined together.

>
> I would like to share some of my data. Can you tell me how I can dump a
> dataset in a way that I can post it here as text?

copy result of dput directly to your mail

dput(dat)
structure(list(hz = c(0, 25, 50), vykon = c(0, 11.6, 22.6)), .Names = c("hz",
"vykon"), row.names = c(NA, -3L), class = "data.frame")

We can use

dat <- structure(list(hz = c(0, 25, 50), vykon = c(0, 11.6, 22.6)), .Names = c("hz",
"vykon"), row.names = c(NA, -3L), class = "data.frame")

to reconstruct the object.

Regards
Petr

>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Michael Dewey <lists at dewey.myzen.co.uk>
> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:  06.06.2016 15:45
> Betreff:        Re: [R] Merging variables
>
>
>
> X-Originating-<%= hostname %>-IP: [217.155.205.190]
>
> Dear Georg
>
> I find it a bit surprising that you end up with customer.x and customer.y. Can
> you share with us a toy example of two data.frames which exhibit this
> behaviour?
>
> On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
> > Hi All,
> >
> > I merged two datasets:
> >
> > ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> > ds_zww_customer_4_match,
> >   by.x = "customer", by.y = "customer",
> >   all.x = TRUE, all.y = FALSE)
> >
> > R created a new dataset with the variables customer.x and customer.y.
> > I would like to merge these two variable back together. I wrote a
> > little function (code can be run) for it:
> >
> > -- cut --
> >
> > customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> > customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> > ds_test <- data.frame(customer.x, customer.y, stringsAsFactors =
> > FALSE)
> >
> > t_merge_variables <-
> >   function(dataset,
> >            var1,
> >            var2,
> >            merged_var) {
> >
> >     # Initialize
> >     dataset[[merged_var]] = rep(NA, nrow(dataset))
> >     dataset[["mismatch"]] = rep(NA, nrow(dataset))
> >
> >     for (i in 1:nrow(dataset)) {
> >
> >       # Check 1: var1 missing, var2 missing
> >       if (is.na(dataset[[i, var1]]) &
> >           is.na(dataset[[i, var2]])) {
> >         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
> >
> >       # Check 2: var1 filled, var2 missing
> >       } else if (!is.na(dataset[[i, var1]]) &
> >                  is.na(dataset[[i, var2]])) {
> >         dataset[[i, merged_var]] <- dataset[[i, var1]]
> >         dataset[["mismatch"]] <- 0
> >
> >       # Check 3: var1 missing, var2 filled
> >       } else if (is.na(dataset[[i, var1]]) &
> >                  !is.na(dataset[i, var2])) {
> >         dataset[[i, merged_var]] <- dataset[[i, var2]]
> >         dataset[["mismatch"]] <-  0
> >
> >       # Check 4: var1 == var2
> >       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
> >       dataset[[i, merged_var]] <- dataset[[i, var1]]
> >       dataset[["mismatch"]] <- 0
> >
> >       # Leftover: var1 != var2
> >       } else {
> >         dataset[[i, merged_var]] <- NA
> >         dataset[["mismatch"]] <- 2  # var1 != var2
> >       }  # end if
> >     }  # end for
> >     return(dataset)
> > }
> >
> > ds_var_merge1 <- t_merge_variables(dataset = ds_test,
> >   var1 = "customer.x",
> >   var2 = "customer.y",
> >   merged_var = "customer")
> >
> > ds_var_merge1
> >
> > -- cut --
> >
> > It is executed without error but delivers the wrong values in the
> variable
> > "mismatch". This variable is always 1 although it should be NA, 1 or 2
> > respectively.
> >
> > Can you tell me why the variable is not correctly set?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From HDoran at air.org  Tue Jun  7 15:06:10 2016
From: HDoran at air.org (Doran, Harold)
Date: Tue, 7 Jun 2016 13:06:10 +0000
Subject: [R] Faster Multivariate Normal
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686012BC5B3C1@DC1VEX10MB01.air.org>

I am computing a complex multidimensional integral (4 dimensions) using Gauss-legendre and am looking to optimize one piece of code that is currently very expensive. The integral is evaluated for K individuals in my data and once this piece is computed it can be stored and recycled over all K individuals. Once this piece is stored, the integral can be computed in about 1.3 minutes using R for each individual.

Because the integral has multiple dimensions, the number of nodes grows exponentially such that I require q^4 total nodes and experimentation is showing I need no fewer than 40 per dimension. At each of these, I need to compute the density of the multivariate normal at all q^4 nodes and store it. This is very expensive and I wonder if there is a way to improve the computational time to be faster?

Below is just a reproducible toy example (not using legendre nodes) to illustrate the issue. The final line is what I am wondering about to see if it can be improved in terms of computational time.

Thank you
Harold

library(mvtnorm)
### Create parameters for MVN
mu <- c(0,0,0,0)
cov <- matrix(.2, ncol= 4,nrow=4)
diag(cov) <- 1
sigma <- as.matrix(cov)

### Create nodes and expand to 4 dimensions for quadrature
dm  <- length(mu)
gh  <- seq(-4, 4, length.out = 10)
n <- length(gh)
idx <- as.matrix(expand.grid(rep(list(1:n),dm)))

### Compute density, this is expensive
adjFactor <- sapply(1:nrow(idx), function(i) dmvnorm(gh[idx[i,]], mean = mu, sigma = sigma))


	[[alternative HTML version deleted]]


From stefano.sofia at regione.marche.it  Tue Jun  7 16:34:42 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Tue, 7 Jun 2016 14:34:42 +0000
Subject: [R] evaluate the daily mean with date in "POSIXct" "POSIXt"
 class
In-Reply-To: <CA+8X3fXc2Qb08O51pdPuYBisEfQhuHOOpGeapUJmnc6kYj7H3Q@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F3DBB705D@ESINO.regionemarche.intra>,
	<CA+8X3fXc2Qb08O51pdPuYBisEfQhuHOOpGeapUJmnc6kYj7H3Q@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBB7200@ESINO.regionemarche.intra>

Thank you Jim,
you gave me the right hint.

Stefano
________________________________________
Da: Jim Lemon [drjimlemon at gmail.com]
Inviato: marted? 7 giugno 2016 9.39
A: Stefano Sofia
Cc: r-help at r-project.org
Oggetto: Re: [R] evaluate the daily mean with date in "POSIXct" "POSIXt" class

Hi Stefano,
I might be missing something, but try this:

MteBove<-read.table(text="posix_date  posix_time  snow    temp
 2010-01-19 23:30:00 45 NA
 2010-01-20 00:30:00 10 2.7
 2010-01-20 03:00:00 45 NA
 2010-01-20 03:30:00 44 NA
 2010-01-20 04:00:00 44 NA
 2010-01-20 04:30:00 44 NA
 2010-01-20 05:00:00 44 NA
 2010-01-20 05:30:00 45 NA
 2010-01-20 06:00:00 44 NA
 2010-01-20 06:30:00 45 NA
 2010-01-20 23:30:00 45 NA
 2010-01-21 00:30:00 10 2.7
 2010-01-21 03:00:00 45 NA
 2010-01-21 03:30:00 44 NA
 2010-01-21 04:00:00 44 NA
 2010-01-21 04:30:00 44 NA
 2010-01-21 05:00:00 44 NA
 2010-01-21 05:30:00 45 NA
 2010-01-21 06:00:00 44 NA
 2010-01-21 06:30:00 45 NA",
 header=TRUE)
MteBove$day<-as.Date(MteBove$posix_date,"%Y-%m-%d")
by(MteBove$snow,MteBove$day,mean)

and if you have NA values, add na.rm=TRUE to the last line.

Jim


On Tue, Jun 7, 2016 at 4:55 PM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-list users,
> I have the following data frame, called MteBove:
>
> posix_date    snow    temp
> ...
> 2010-01-20 23:30:00 45 NA
> 2010-01-02 00:30:00 10-2.7
> 2010-01-20 03:00:00 45 NA
> 2010-01-20 03:30:00 44 NA
> 2010-01-20 04:00:00 44 NA
> 2010-01-20 04:30:00 44 NA
> 2010-01-20 05:00:00 44 NA
> 2010-01-20 05:30:00 45 NA
> 2010-01-20 06:00:00 44 NA
> 2010-01-20 06:30:00 45 NA
> ...
>
>> sapply(MteBove, class)
> gives
> $posix_date
> [1] "POSIXct" "POSIXt"
>
> $snow
> [1] "numeric"
>
> $temp
> [1] "numeric"
>
> There are semi-hourly data (i.e. 48 data each day) from the first of November to the first of May of each Winter season, and I need the daily mean for snow and temp.
> First I created a subset for each Winter season
> I tried to create a new column with only the day, like
>
>> MteBove$day <- trunc(MteBove$posix_date, "days")
>
> and then
>
>> list_days <- unique(MteBove$day)
>> means <- rapply(list_days, function(x) mean(MteBove[MteBove$day == x, ], na.rm=T))
>
> with the following result:
> [1] "means IS"
>   sec   min  hour  mday   mon  year  wday  yday isdst
>    NA    NA    NA    NA    NA    NA    NA    NA    NA
>
> I tried some changes always in this direction, with no success.
> Is there an efficient way to do that?
> Could somebody give me an hint about it?
>
> Thank you for your attention and your help
> Stefano Sofia
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.


From murdoch.duncan at gmail.com  Tue Jun  7 16:43:44 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 7 Jun 2016 10:43:44 -0400
Subject: [R] Faster Multivariate Normal
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686012BC5B3C1@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686012BC5B3C1@DC1VEX10MB01.air.org>
Message-ID: <cb9a69c7-d491-ca6d-c088-74d9656baeff@gmail.com>

On 07/06/2016 9:06 AM, Doran, Harold wrote:
> I am computing a complex multidimensional integral (4 dimensions) using Gauss-legendre and am looking to optimize one piece of code that is currently very expensive. The integral is evaluated for K individuals in my data and once this piece is computed it can be stored and recycled over all K individuals. Once this piece is stored, the integral can be computed in about 1.3 minutes using R for each individual.
>
> Because the integral has multiple dimensions, the number of nodes grows exponentially such that I require q^4 total nodes and experimentation is showing I need no fewer than 40 per dimension. At each of these, I need to compute the density of the multivariate normal at all q^4 nodes and store it. This is very expensive and I wonder if there is a way to improve the computational time to be faster?
>
> Below is just a reproducible toy example (not using legendre nodes) to illustrate the issue. The final line is what I am wondering about to see if it can be improved in terms of computational time.

I'd vectorize rather than using sapply (which is really a long loop). 
Try to put all the values into rows of a single matrix and just make one 
call to dmvnorm.

Duncan Murdoch

> Thank you
> Harold
>
> library(mvtnorm)
> ### Create parameters for MVN
> mu <- c(0,0,0,0)
> cov <- matrix(.2, ncol= 4,nrow=4)
> diag(cov) <- 1
> sigma <- as.matrix(cov)
>
> ### Create nodes and expand to 4 dimensions for quadrature
> dm  <- length(mu)
> gh  <- seq(-4, 4, length.out = 10)
> n <- length(gh)
> idx <- as.matrix(expand.grid(rep(list(1:n),dm)))
>
> ### Compute density, this is expensive
> adjFactor <- sapply(1:nrow(idx), function(i) dmvnorm(gh[idx[i,]], mean = mu, sigma = sigma))
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From HDoran at air.org  Tue Jun  7 19:19:53 2016
From: HDoran at air.org (Doran, Harold)
Date: Tue, 7 Jun 2016 17:19:53 +0000
Subject: [R] Faster Multivariate Normal
In-Reply-To: <cb9a69c7-d491-ca6d-c088-74d9656baeff@gmail.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686012BC5B3C1@DC1VEX10MB01.air.org>
	<cb9a69c7-d491-ca6d-c088-74d9656baeff@gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686012BC5BBAE@DC1VEX10MB01.air.org>

Thanks, Duncan. Not sure I follow, however. The call to dmvnorm(), in this instance, takes in a 4 x 1 vector of nodes (in addition to the mean and covariances matrices), such as in the example below which uses the original sample code.

That vector of nodes changes for each iteration of the loop within the sapply(). 

> i=1
> dmvnorm(gh[idx[i,]], mean = mu, sigma = sigma)
[1] 5.768404e-11
> i=2
> dmvnorm(gh[idx[i,]], mean = mu, sigma = sigma)
[1] 3.455385e-10

I too would prefer to vectorize, but I'm not seeing how one call would work in this instance?


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Tuesday, June 07, 2016 10:44 AM
To: Doran, Harold <HDoran at air.org>; r-help at r-project.org
Subject: Re: [R] Faster Multivariate Normal

On 07/06/2016 9:06 AM, Doran, Harold wrote:
> I am computing a complex multidimensional integral (4 dimensions) using Gauss-legendre and am looking to optimize one piece of code that is currently very expensive. The integral is evaluated for K individuals in my data and once this piece is computed it can be stored and recycled over all K individuals. Once this piece is stored, the integral can be computed in about 1.3 minutes using R for each individual.
>
> Because the integral has multiple dimensions, the number of nodes grows exponentially such that I require q^4 total nodes and experimentation is showing I need no fewer than 40 per dimension. At each of these, I need to compute the density of the multivariate normal at all q^4 nodes and store it. This is very expensive and I wonder if there is a way to improve the computational time to be faster?
>
> Below is just a reproducible toy example (not using legendre nodes) to illustrate the issue. The final line is what I am wondering about to see if it can be improved in terms of computational time.

I'd vectorize rather than using sapply (which is really a long loop). 
Try to put all the values into rows of a single matrix and just make one call to dmvnorm.

Duncan Murdoch

> Thank you
> Harold
>
> library(mvtnorm)
> ### Create parameters for MVN
> mu <- c(0,0,0,0)
> cov <- matrix(.2, ncol= 4,nrow=4)
> diag(cov) <- 1
> sigma <- as.matrix(cov)
>
> ### Create nodes and expand to 4 dimensions for quadrature dm  <- 
> length(mu) gh  <- seq(-4, 4, length.out = 10) n <- length(gh) idx <- 
> as.matrix(expand.grid(rep(list(1:n),dm)))
>
> ### Compute density, this is expensive adjFactor <- 
> sapply(1:nrow(idx), function(i) dmvnorm(gh[idx[i,]], mean = mu, sigma 
> = sigma))
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From munjalpatel85 at gmail.com  Tue Jun  7 18:08:29 2016
From: munjalpatel85 at gmail.com (Munjal Patel)
Date: Tue, 7 Jun 2016 12:08:29 -0400
Subject: [R] Power Calculation: Binomial Proportions (2 sided exact test for
	equivalence)
Message-ID: <CAOWjiK-j4Jh7Rk=1PeqMpaSB2+QUFVeKRTRZwRyhAe4oc5wvgQ@mail.gmail.com>

Dear R-Sig-teaching users,
I am an intermediate level R user.

I am performing the power calculations for the Binomial proportions (2
sided).
I want to find the Power using the Exact test for the Equivalence of
Binomial proportions.
I do have the SAS code which is generating the Power for me but i am unable
to find the Similar code in R.
I need help for finding the similar computation in R.

My SAS code.

proc power;
onesamplefreq test = equiv_exact
alpha = 0.05
proportion = 0.30
lower = 0.2
upper = 0.4
ntotal = 500
power = .;
run;

Can somebody helkp me by providing the R code for the similar calculation ?
Thank you.

MJ

	[[alternative HTML version deleted]]


From munjalpatel85 at gmail.com  Tue Jun  7 18:26:50 2016
From: munjalpatel85 at gmail.com (Munjal Patel)
Date: Tue, 7 Jun 2016 12:26:50 -0400
Subject: [R] Power Calculation:2-sided exact equivalence test for Binomial
	Proportions
Message-ID: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>

Dear R-Users,
I am an intermediate level R user.

I am performing the power calculations for the Binomial proportions (2
sided).
I want to find the Power using the Exact test for the Equivalence of
Binomial proportions.
I do have the SAS code which is generating the Power for me but i am unable
to find the Similar code in R.
I need help for finding the similar computation in R.

My SAS code.

proc power;
onesamplefreq test = equiv_exact
alpha = 0.05
proportion = 0.30
lower = 0.2
upper = 0.4
ntotal = 500
power = .;
run;

Can somebody help me by providing the R code for the similar calculation ?
Thank you.

MJ

	[[alternative HTML version deleted]]


From cadeb at usgs.gov  Tue Jun  7 20:42:29 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Tue, 7 Jun 2016 12:42:29 -0600
Subject: [R] Power Calculation:2-sided exact equivalence test for
	Binomial Proportions
In-Reply-To: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>
References: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>
Message-ID: <CAM5M9BR7Ry6SbzcXy3U14HWhY6WtbbBjgb=fxx4queJAqYZ4qw@mail.gmail.com>

MJ:  I think the EnvStats package has various power functions for binomial
applications (also confidence interval half-widths).
Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Tue, Jun 7, 2016 at 10:26 AM, Munjal Patel <munjalpatel85 at gmail.com>
wrote:

> Dear R-Users,
> I am an intermediate level R user.
>
> I am performing the power calculations for the Binomial proportions (2
> sided).
> I want to find the Power using the Exact test for the Equivalence of
> Binomial proportions.
> I do have the SAS code which is generating the Power for me but i am unable
> to find the Similar code in R.
> I need help for finding the similar computation in R.
>
> My SAS code.
>
> proc power;
> onesamplefreq test = equiv_exact
> alpha = 0.05
> proportion = 0.30
> lower = 0.2
> upper = 0.4
> ntotal = 500
> power = .;
> run;
>
> Can somebody help me by providing the R code for the similar calculation ?
> Thank you.
>
> MJ
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From leonardof at leonardof.med.br  Tue Jun  7 20:44:30 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Tue, 07 Jun 2016 15:44:30 -0300
Subject: [R] Power Calculation: Binomial Proportions (2 sided exact test
 for equivalence)
In-Reply-To: <CAOWjiK-j4Jh7Rk=1PeqMpaSB2+QUFVeKRTRZwRyhAe4oc5wvgQ@mail.gmail.com>
References: <CAOWjiK-j4Jh7Rk=1PeqMpaSB2+QUFVeKRTRZwRyhAe4oc5wvgQ@mail.gmail.com>
Message-ID: <1465325070.1050608.630775801.220D0313@webmail.messagingengine.com>

Em Ter 7 jun. 2016, ?s 13:08, Munjal Patel escreveu:
> Dear R-Sig-teaching users,
> I am an intermediate level R user.

You posted both emails to the same mailing list.

Please remember that "cross-posting is considered to be impolite" and
that "you should configure your e-mail software in such a way as to send
only plain text": https://www.r-project.org/mail.html

Best regards, 

Leonardo Ferreira Fontenelle, MD, MPH

PhD candidate, Federal University of Pelotas
Professor of Medicine, Vila Velha University
Legislative consultant, Municipal Chamber of Vit?ria


From bgunter.4567 at gmail.com  Tue Jun  7 20:49:20 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Jun 2016 11:49:20 -0700
Subject: [R] Power Calculation:2-sided exact equivalence test for
	Binomial Proportions
In-Reply-To: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>
References: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>
Message-ID: <CAGxFJbT-wEaAZ_ZAFaV2fXyVAUk1yDKDFV1jXaG1EXuKXxs3ig@mail.gmail.com>

Please search before posting, and if your search fails to get what you
want, tell us why.

I got what appeared to be many relevant hits  on rseek.org using the search term
"binomial exact power computations" .


-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 7, 2016 at 9:26 AM, Munjal  Patel <munjalpatel85 at gmail.com> wrote:
> Dear R-Users,
> I am an intermediate level R user.
>
> I am performing the power calculations for the Binomial proportions (2
> sided).
> I want to find the Power using the Exact test for the Equivalence of
> Binomial proportions.
> I do have the SAS code which is generating the Power for me but i am unable
> to find the Similar code in R.
> I need help for finding the similar computation in R.
>
> My SAS code.
>
> proc power;
> onesamplefreq test = equiv_exact
> alpha = 0.05
> proportion = 0.30
> lower = 0.2
> upper = 0.4
> ntotal = 500
> power = .;
> run;
>
> Can somebody help me by providing the R code for the similar calculation ?
> Thank you.
>
> MJ
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From leonardof at leonardof.med.br  Tue Jun  7 20:50:42 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Tue, 07 Jun 2016 15:50:42 -0300
Subject: [R] Power Calculation:2-sided exact equivalence test for
 Binomial Proportions
In-Reply-To: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>
References: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>
Message-ID: <1465325442.1052671.630784457.2836BAFF@webmail.messagingengine.com>

Em Ter 7 jun. 2016, ?s 13:26, Munjal Patel escreveu:
> Dear R-Users,
> I am an intermediate level R user.
> 
> I am performing the power calculations for the Binomial proportions (2
> sided).
> I want to find the Power using the Exact test for the Equivalence of
> Binomial proportions.
> I do have the SAS code which is generating the Power for me but i am
> unable
> to find the Similar code in R.
> I need help for finding the similar computation in R.
> 

I'm not a statistician, and I have never hear of power calculation using
exact test. On the other hand, with hundreds of observations on each
group, does it matter? Maybe you could simply use power.prop.test(),
from the loaded-by-default package "stats".

Of course, you could look for packages about proportions or binomial in
CRAN, or set up a simulation.

Hope that helps,

Leonardo Ferreira Fontenelle, MD, MPH

PhD candidate, Federal University of Pelotas
Professor of Medicine, Vila Velha University
Legislative consultant, Municipal Chamber of Vit?ria


From davidsmi at microsoft.com  Tue Jun  7 23:00:01 2016
From: davidsmi at microsoft.com (David Smith)
Date: Tue, 7 Jun 2016 21:00:01 +0000
Subject: [R] Revolutions blog: May 2016 roundup
Message-ID: <DM2PR0301MB0848B37CB1F18BAED32CB64FC85D0@DM2PR0301MB0848.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of May:

A 3-part tutorial on principal components regression in R: part 1
(http://blog.revolutionanalytics.com/2016/05/principal-components-tutorial.html); part 2
(http://blog.revolutionanalytics.com/2016/05/principal-components-regression-part-2.html); part 3
(http://blog.revolutionanalytics.com/2016/05/principal-components-regression-in-r-part-3.html).

Implications of the fact that in R, names have objects (and not vice-versa):
http://blog.revolutionanalytics.com/2016/05/an-object-has-no-name.html

Highlights of the R/Finance 2016 conference: http://blog.revolutionanalytics.com/2016/05/r-finance-2016.html

A template for predicting maintenance events for aircraft engines, using R:
http://blog.revolutionanalytics.com/2016/05/predictive-maintenance-r-code.html

The "feather" package for fast data exchange between Python and R, now on CRAN:
http://blog.revolutionanalytics.com/2016/05/feather-package.html

Microsoft R Open 3.2.5 now available:
http://blog.revolutionanalytics.com/2016/05/microsoft-r-open-325-now-available.html

There are now R user groups in 223 cities and 55 countries:
http://blog.revolutionanalytics.com/2016/05/user-groups-and-r-awareness.html

A preview of Spark 2.0 and the updated SparkR package:
http://blog.revolutionanalytics.com/2016/05/spark-20-to-include-more-r-models.html

All the documentation for Microsoft R Server is now available to everyone, online:
http://blog.revolutionanalytics.com/2016/05/microsoft-r-server-documentation.html

The most popular (and controversial) ingredients in pasta carbonara, visualized with R:
http://blog.revolutionanalytics.com/2016/05/whats-in-pasta-carbonara.html

Joseph Rickert's guidelines for identifying the best R packages:
http://blog.revolutionanalytics.com/2016/05/good-r-packages.html

"Effective Graphs with Microsoft R Open", a free e-book, is available for download:
http://blog.revolutionanalytics.com/2016/05/e-book-effective-graphs.html

Estimating demand for bike rentals in Washington, DC with R:
http://blog.revolutionanalytics.com/2016/05/bike-rental-demand.html

R Tools for Visual Studio 0.3 now available:
http://blog.revolutionanalytics.com/2016/05/r-tools-for-visual-studio-30-now-available.html

A brief summary of the changes and new features in R 3.3.0:
http://blog.revolutionanalytics.com/2016/05/r-330-now-available.html

A tutorial on installing R packages on a firewalled SQL Server instance:
http://blog.revolutionanalytics.com/2016/05/minicran-sql-server.html

How to train gradient-boosted trees with Microsoft R Server:
http://blog.revolutionanalytics.com/2016/05/build-a-gradient-boosted-trees-model-with-mrs.html

Reproducing results in Efron's 1987 paper "Logistic Regression, Survival Analysis, and the Kaplan-Meier Curve"
using R: http://blog.revolutionanalytics.com/2016/04/reading-efron-with-r-1.html

General interest stories (not related to R) in the past month included: the history of Japan
(http://blog.revolutionanalytics.com/2016/05/history-of-japan.html), a magnet machine
(http://blog.revolutionanalytics.com/2016/05/magnet-machine.html), an audio-visual history of the Billboard Top 5
(http://blog.revolutionanalytics.com/2016/05/because-its-friday-the-time-travelling-jukebox.html), and roads to Romes
(http://blog.revolutionanalytics.com/2016/05/because-its-friday-the-roads-to-rome.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the
updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html
If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From esawiek at gmail.com  Wed Jun  8 00:26:08 2016
From: esawiek at gmail.com (Ek Esawi)
Date: Tue, 7 Jun 2016 18:26:08 -0400
Subject: [R] Reading and converting time data via read.table
Message-ID: <CA+ZkTxsJ3uwP6zrP0fDk7=VOEX8Y=VKkGeteSQ7mdFoQcTaYkw@mail.gmail.com>

Thanks Petr!



I am still unable to come up with a conversion formula/trick to convert my
time data to POSIXlt which then can be used in read.table. Below are again
a few lines from my file. Since as you see there are several columns of
time data ONLY (no date), I am hoping that there is a way to convert the
time columns to POSIXlt or chron in the read.table statement. I was able to
use as.Date in the read.table to convert the dates.


Thanks-EK



       O         Date      Name     Time     Inter     Dura      Prep     Hht
     Pred

1 312171  7/1/1995     Old-1   13:37     1:43     4:42       13:16   162
13:19

2 358237 5/25/1993    Old-2   12:22     1:31     4:16       12:03   160
12:13

3 339971 7/17/1994    Old-3   15:54     1:23     4:36       15:43   160
 15:51

	[[alternative HTML version deleted]]


From teotjunk at hotmail.com  Wed Jun  8 04:44:21 2016
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Wed, 8 Jun 2016 10:44:21 +0800
Subject: [R] Cut Dates into bins
In-Reply-To: <CA+8X3fUY-ayXwnWJHwStY+LdQkQ4XCoLTFTaUa+gAMzFzRoddw@mail.gmail.com>
References: <SNT152-W9562B7383245778A7B4E02DF590@phx.gbl>,
	<CA+8X3fUY-ayXwnWJHwStY+LdQkQ4XCoLTFTaUa+gAMzFzRoddw@mail.gmail.com>
Message-ID: <SNT152-W54BEAB5F8D7AC0EEFFEB36DF5E0@phx.gbl>


It does not seem to work for me. I will show you exactly my data format

SMA$TIME_DATE
"28/9/2014"  "17/6/2014"  "19/9/2014"  "17/1/2015"  "13/1/2015"  "21/10/2014"


Shipment$DateRequire
 "2014-06-09" "2014-06-16" "2014-06-16" "2014-06-16" "2014-06-17" "2014-06-23"

What I would like to do is the cut the first set of dates into the second set of dates







> From: drjimlemon at gmail.com
> Date: Fri, 3 Jun 2016 18:59:11 +1000
> Subject: Re: [R] Cut Dates into bins
> To: teotjunk at hotmail.com
> CC: r-help at r-project.org
> 
> Hi Tjun Kiat,
> This seems to work:
> 
> daily_date<-as.Date(paste("2000-01",1:28,sep="-"),"%Y-%m-%d")
> weekly_date<-as.Date(paste(c(1,8,15,22,28),"01/2000",sep="/"),
>  "%d/%m/%Y")
> cut(daily_date,breaks=weekly_date,include.lowest=TRUE,
>  labels=paste("Week",1:4))
> 
> Jim
> 
> 
> On Fri, Jun 3, 2016 at 6:00 PM, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:
> > I have two set of dates
> >
> > 2000-01-01
> >
> > 01/01/2000
> >
> > The second one occurs weekly and the first one occurs in daily. I would like to bin the first set of dates into the second set of dates. What is the best way to do it?
> >
> > I tried  converting both formats into numeric formats
> >
> > DateBase=sort(as.numeric(as.POSIXlt(unique(Shipment$DateRequire),format="%Y-%m-%D",origin="1900-01-01")))
> >
> > Compare=as.numeric(as.POSIXlt(SMA$TIME_DATE,format="%d/%m/%y",origin="01/01/1900"))
> >
> > But the numeric numbers turned out to be very different.
> >
> > Tjun Kiat
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Wed Jun  8 04:45:53 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Tue, 7 Jun 2016 21:45:53 -0500
Subject: [R] Reading and converting time data via read.table
In-Reply-To: <CA+ZkTxsJ3uwP6zrP0fDk7=VOEX8Y=VKkGeteSQ7mdFoQcTaYkw@mail.gmail.com>
References: <CA+ZkTxsJ3uwP6zrP0fDk7=VOEX8Y=VKkGeteSQ7mdFoQcTaYkw@mail.gmail.com>
Message-ID: <f521ef75-9ef4-9b17-0207-25e09ef4b297@effectivedefense.org>

       Have you considered asNumericDF in the Ecfun package?  This can 
convert to a date-time column into POSIXct -- not POSIXlt -- using the 
POSIX argument to identify the POSIX columns and format to provide the 
"format" argument for as.POSIXct.


       I suggest you try the R-Forge version: install.packages("Ecfun", 
repos="http://R-Forge.R-project.org").  If I recall correctly, the 
R-Forge version works the same as the CRAN version for POSIX but fixes a 
subtle bug for Dates.


       Hope this helps.
       Spencer Graves


p.s.  If anyone knows a better way to do this, I'm interested.


On 6/7/2016 5:26 PM, Ek Esawi wrote:
> Thanks Petr!
>
>
>
> I am still unable to come up with a conversion formula/trick to convert my
> time data to POSIXlt which then can be used in read.table. Below are again
> a few lines from my file. Since as you see there are several columns of
> time data ONLY (no date), I am hoping that there is a way to convert the
> time columns to POSIXlt or chron in the read.table statement. I was able to
> use as.Date in the read.table to convert the dates.
>
>
> Thanks-EK
>
>
>
>         O         Date      Name     Time     Inter     Dura      Prep     Hht
>       Pred
>
> 1 312171  7/1/1995     Old-1   13:37     1:43     4:42       13:16   162
> 13:19
>
> 2 358237 5/25/1993    Old-2   12:22     1:31     4:16       12:03   160
> 12:13
>
> 3 339971 7/17/1994    Old-3   15:54     1:23     4:36       15:43   160
>   15:51
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Jun  8 08:37:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 07 Jun 2016 23:37:50 -0700
Subject: [R] Faster Multivariate Normal
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686012BC5BBAE@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686012BC5B3C1@DC1VEX10MB01.air.org>
	<cb9a69c7-d491-ca6d-c088-74d9656baeff@gmail.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD686012BC5BBAE@DC1VEX10MB01.air.org>
Message-ID: <BCCFD764-0AA5-405E-8E05-F767D36F08EF@dcn.davis.ca.us>

The help file ?dmvnorm is your friend. Read about "x".

ghv <- matrix( gh[ as.vector( idx ) ], ncol = dm )
adjFactor2 <- dmvnorm( ghv, mean = mu, sigma = sigma )
-- 
Sent from my phone. Please excuse my brevity.

On June 7, 2016 10:19:53 AM PDT, "Doran, Harold" <HDoran at air.org> wrote:
>Thanks, Duncan. Not sure I follow, however. The call to dmvnorm(), in
>this instance, takes in a 4 x 1 vector of nodes (in addition to the
>mean and covariances matrices), such as in the example below which uses
>the original sample code.
>
>That vector of nodes changes for each iteration of the loop within the
>sapply(). 
>
>> i=1
>> dmvnorm(gh[idx[i,]], mean = mu, sigma = sigma)
>[1] 5.768404e-11
>> i=2
>> dmvnorm(gh[idx[i,]], mean = mu, sigma = sigma)
>[1] 3.455385e-10
>
>I too would prefer to vectorize, but I'm not seeing how one call would
>work in this instance?
>
>
>-----Original Message-----
>From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
>Sent: Tuesday, June 07, 2016 10:44 AM
>To: Doran, Harold <HDoran at air.org>; r-help at r-project.org
>Subject: Re: [R] Faster Multivariate Normal
>
>On 07/06/2016 9:06 AM, Doran, Harold wrote:
>> I am computing a complex multidimensional integral (4 dimensions)
>using Gauss-legendre and am looking to optimize one piece of code that
>is currently very expensive. The integral is evaluated for K
>individuals in my data and once this piece is computed it can be stored
>and recycled over all K individuals. Once this piece is stored, the
>integral can be computed in about 1.3 minutes using R for each
>individual.
>>
>> Because the integral has multiple dimensions, the number of nodes
>grows exponentially such that I require q^4 total nodes and
>experimentation is showing I need no fewer than 40 per dimension. At
>each of these, I need to compute the density of the multivariate normal
>at all q^4 nodes and store it. This is very expensive and I wonder if
>there is a way to improve the computational time to be faster?
>>
>> Below is just a reproducible toy example (not using legendre nodes)
>to illustrate the issue. The final line is what I am wondering about to
>see if it can be improved in terms of computational time.
>
>I'd vectorize rather than using sapply (which is really a long loop). 
>Try to put all the values into rows of a single matrix and just make
>one call to dmvnorm.
>
>Duncan Murdoch
>
>> Thank you
>> Harold
>>
>> library(mvtnorm)
>> ### Create parameters for MVN
>> mu <- c(0,0,0,0)
>> cov <- matrix(.2, ncol= 4,nrow=4)
>> diag(cov) <- 1
>> sigma <- as.matrix(cov)
>>
>> ### Create nodes and expand to 4 dimensions for quadrature dm  <- 
>> length(mu) gh  <- seq(-4, 4, length.out = 10) n <- length(gh) idx <- 
>> as.matrix(expand.grid(rep(list(1:n),dm)))
>>
>> ### Compute density, this is expensive adjFactor <- 
>> sapply(1:nrow(idx), function(i) dmvnorm(gh[idx[i,]], mean = mu, sigma
>
>> = sigma))
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Wed Jun  8 07:59:55 2016
From: esawiek at gmail.com (Ek Esawi)
Date: Wed, 8 Jun 2016 01:59:55 -0400
Subject: [R] Reading and converting time data via read.table
Message-ID: <CA+ZkTxvdP==mc9NR9eHi_K0r0K8poEMzF7fXOyRwG_ZPQn4W8g@mail.gmail.com>

Thanks for the responses i received from David and Spencer. As for the
package Ecfun, i looked at it briefly, but it's long and i am new to R; so
this just adds to my confusion. David suggested the sub function which i
will try and see what i get.i s

As i said earlier i have no problems reading dates w/o time and i was able
to produce a function that can be included in colClasses to reformat date
correctly and convert them to class date. i even stumbled on a way to
convert my time data to time class via the chron package. Here is what i
did  times(paste0(t1, ":00")) where t1 is the first element of the column
named Time. The problem i have now is how to incorporate this
function/command into the colClasses in read.table so that i don't have to
convert every entry in each column, one at a time.

Thank you for the help. EK

	[[alternative HTML version deleted]]


From adriens_cachan at yahoo.fr  Wed Jun  8 08:54:45 2016
From: adriens_cachan at yahoo.fr (BONACHE Adrien)
Date: Wed, 8 Jun 2016 06:54:45 +0000 (UTC)
Subject: [R] Power Calculation: Binomial Proportions (2 sided exact test
 for	equivalence)
In-Reply-To: <CAOWjiK-j4Jh7Rk=1PeqMpaSB2+QUFVeKRTRZwRyhAe4oc5wvgQ@mail.gmail.com>
References: <CAOWjiK-j4Jh7Rk=1PeqMpaSB2+QUFVeKRTRZwRyhAe4oc5wvgQ@mail.gmail.com>
Message-ID: <566861077.279036.1465368885843.JavaMail.yahoo@mail.yahoo.com>

Dear Munjal,
You should use the pwr package with the following code :library(pwr)
# lower
pwr.2p.test(h =ES.h(0.3, 0.2), n = 500, sig.level = 0.05, power = NULL, alternative = c("two.sided"))#upperpwr.2p.test(h =ES.h(0.3, 0.4), n = 500, sig.level = 0.05, power = NULL, alternative = c("two.sided"))
Maybe you could use G*power :Lower case 1-beta = 0.9557076Upper one 1-beta= 0.9134817
Hope this help,
Adrien Bonache.

      De?: Munjal Patel <munjalpatel85 at gmail.com>
 ??: r-help at r-project.org 
 Envoy? le : Mardi 7 juin 2016 18h08
 Objet?: [R] Power Calculation: Binomial Proportions (2 sided exact test for equivalence)
   
Dear R-Sig-teaching users,
I am an intermediate level R user.

I am performing the power calculations for the Binomial proportions (2
sided).
I want to find the Power using the Exact test for the Equivalence of
Binomial proportions.
I do have the SAS code which is generating the Power for me but i am unable
to find the Similar code in R.
I need help for finding the similar computation in R.

My SAS code.

proc power;
onesamplefreq test = equiv_exact
alpha = 0.05
proportion = 0.30
lower = 0.2
upper = 0.4
ntotal = 500
power = .;
run;

Can somebody helkp me by providing the R code for the similar calculation ?
Thank you.

MJ

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From adriens_cachan at yahoo.fr  Wed Jun  8 08:58:22 2016
From: adriens_cachan at yahoo.fr (BONACHE Adrien)
Date: Wed, 8 Jun 2016 06:58:22 +0000 (UTC)
Subject: [R] Power Calculation:2-sided exact equivalence test for
 Binomial	Proportions
In-Reply-To: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>
References: <CAOWjiK8s+e1VbnJhpytJLzDPXYe+Rv_sk-qgXC+A9zrL=5hLXw@mail.gmail.com>
Message-ID: <1712173897.281705.1465369102595.JavaMail.yahoo@mail.yahoo.com>

Hi again,
In fact the pwr package do not provide exact test power. So you should definitely use g*power.
Sincerely,
Adrien.

      De?: Munjal Patel <munjalpatel85 at gmail.com>
 ??: r-help at r-project.org 
 Envoy? le : Mardi 7 juin 2016 18h26
 Objet?: [R] Power Calculation:2-sided exact equivalence test for Binomial Proportions
   
Dear R-Users,
I am an intermediate level R user.

I am performing the power calculations for the Binomial proportions (2
sided).
I want to find the Power using the Exact test for the Equivalence of
Binomial proportions.
I do have the SAS code which is generating the Power for me but i am unable
to find the Similar code in R.
I need help for finding the similar computation in R.

My SAS code.

proc power;
onesamplefreq test = equiv_exact
alpha = 0.05
proportion = 0.30
lower = 0.2
upper = 0.4
ntotal = 500
power = .;
run;

Can somebody help me by providing the R code for the similar calculation ?
Thank you.

MJ

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jun  8 09:47:50 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 8 Jun 2016 17:47:50 +1000
Subject: [R] Cut Dates into bins
In-Reply-To: <SNT152-W54BEAB5F8D7AC0EEFFEB36DF5E0@phx.gbl>
References: <SNT152-W9562B7383245778A7B4E02DF590@phx.gbl>
	<CA+8X3fUY-ayXwnWJHwStY+LdQkQ4XCoLTFTaUa+gAMzFzRoddw@mail.gmail.com>
	<SNT152-W54BEAB5F8D7AC0EEFFEB36DF5E0@phx.gbl>
Message-ID: <CA+8X3fUdfjyU5KqmX62-dcyRnE2J49UWe4asB4mV29NHVz1sUA@mail.gmail.com>

Hi Tjun Kiat,
The following examples work for me. One uses the dates you have
specified, adding one weekly date to cover the range of your daily
dates, otherwise you will generate NAs. The second defines weekly
breaks for a year and then simulates daily dates throughout that year.
Remember that your weekly dates must span the range of daily dates.

SMA<-list()
# weekly dates with a date added to cover the range of daily dates
SMA$TIME_DATE<-c("1/6/2014","28/9/2014","17/6/2014","19/9/2014",
 "17/1/2015","13/1/2015","21/10/2014")
weekly_date<-as.Date(SMA$TIME_DATE,"%d/%m/%Y")
Shipment<-list()
# these are the daily dates
Shipment$DateRequire<-c("2014-06-09","2014-06-16","2014-06-16",
 "2014-06-16","2014-06-17","2014-06-23")
daily_date<-as.Date(Shipment$DateRequire,"%Y-%m-%d")
table(cut(daily_date,breaks=weekly_date,include.lowest=TRUE,
 labels=paste("Week",1:6,sep=" ")))

# here's an example with more dates over a full year
daily_date<-as.Date(paste("2000",1:12,sample(1:28,52,TRUE),sep="-"),
 "%Y-%m-%d")
weekly_date<-seq(as.Date("01/01/2000","%d/%m/%Y"),
 as.Date("31/12/2000","%d/%m/%Y"),by=7)
# no table here as it would be fairly long
cut(daily_date,breaks=weekly_date,include.lowest=TRUE,
 labels=paste("Week",1:52,sep=" "))

Jim


On Wed, Jun 8, 2016 at 12:44 PM, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:
>
> It does not seem to work for me. I will show you exactly my data format
>
> SMA$TIME_DATE
>
> "28/9/2014"  "17/6/2014"  "19/9/2014"  "17/1/2015"  "13/1/2015"
> "21/10/2014"
>
>
> Shipment$DateRequire
>
>  "2014-06-09" "2014-06-16" "2014-06-16" "2014-06-16" "2014-06-17"
> "2014-06-23"
>
> What I would like to do is the cut the first set of dates into the second
> set of dates
>
>
>
>
>
>
>
>> From: drjimlemon at gmail.com
>> Date: Fri, 3 Jun 2016 18:59:11 +1000
>> Subject: Re: [R] Cut Dates into bins
>> To: teotjunk at hotmail.com
>> CC: r-help at r-project.org
>
>>
>> Hi Tjun Kiat,
>> This seems to work:
>>
>> daily_date<-as.Date(paste("2000-01",1:28,sep="-"),"%Y-%m-%d")
>> weekly_date<-as.Date(paste(c(1,8,15,22,28),"01/2000",sep="/"),
>> "%d/%m/%Y")
>> cut(daily_date,breaks=weekly_date,include.lowest=TRUE,
>> labels=paste("Week",1:4))
>>
>> Jim
>>
>>
>> On Fri, Jun 3, 2016 at 6:00 PM, TJUN KIAT TEO <teotjunk at hotmail.com>
>> wrote:
>> > I have two set of dates
>> >
>> > 2000-01-01
>> >
>> > 01/01/2000
>> >
>> > The second one occurs weekly and the first one occurs in daily. I would
>> > like to bin the first set of dates into the second set of dates. What is the
>> > best way to do it?
>> >
>> > I tried converting both formats into numeric formats
>> >
>> >
>> > DateBase=sort(as.numeric(as.POSIXlt(unique(Shipment$DateRequire),format="%Y-%m-%D",origin="1900-01-01")))
>> >
>> >
>> > Compare=as.numeric(as.POSIXlt(SMA$TIME_DATE,format="%d/%m/%y",origin="01/01/1900"))
>> >
>> > But the numeric numbers turned out to be very different.
>> >
>> > Tjun Kiat
>> >
>> >
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Jun  8 11:44:58 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 8 Jun 2016 09:44:58 +0000
Subject: [R] Reading and converting time data via read.table
In-Reply-To: <CA+ZkTxsJ3uwP6zrP0fDk7=VOEX8Y=VKkGeteSQ7mdFoQcTaYkw@mail.gmail.com>
References: <CA+ZkTxsJ3uwP6zrP0fDk7=VOEX8Y=VKkGeteSQ7mdFoQcTaYkw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502F95F@SRVEXCHMBX.precheza.cz>

Hi

I am rather confused. If you have data in some external file, (csv, txt, tab delimited), you can read it by corresponding read.* command to data.frame object. I did not know about conversion to POSIX directly by reading an object (it does not mean there is none).

After you read your data you can concatenate some variables to a character by paste.

e.g.

tmp <- paste("7/1/1995", "13:37", sep=" ")
or
dat1 <- paste(Date, Time, sep=" ")

and you can use properly formated strptime to convert values to POSIX

strptime(tmp, format="%d/%m/%Y %H:%M")

Regards
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ek Esawi
> Sent: Wednesday, June 8, 2016 12:26 AM
> To: r-help at r-project.org
> Subject: Re: [R] Reading and converting time data via read.table
>
> Thanks Petr!
>
>
>
> I am still unable to come up with a conversion formula/trick to convert my
> time data to POSIXlt which then can be used in read.table. Below are again a
> few lines from my file. Since as you see there are several columns of time
> data ONLY (no date), I am hoping that there is a way to convert the time
> columns to POSIXlt or chron in the read.table statement. I was able to use
> as.Date in the read.table to convert the dates.
>
>
> Thanks-EK
>
>
>
>        O         Date      Name     Time     Inter     Dura      Prep     Hht
>      Pred
>
> 1 312171  7/1/1995     Old-1   13:37     1:43     4:42       13:16   162
> 13:19
>
> 2 358237 5/25/1993    Old-2   12:22     1:31     4:16       12:03   160
> 12:13
>
> 3 339971 7/17/1994    Old-3   15:54     1:23     4:36       15:43   160
>  15:51
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ebi91-Christian at web.de  Wed Jun  8 11:43:26 2016
From: ebi91-Christian at web.de (Christian Eberhardt)
Date: Wed, 8 Jun 2016 11:43:26 +0200
Subject: [R] Regulized Matrix Factorization
Message-ID: <trinity-4cef99de-97ac-4a06-b037-9305dc8af3b6-1465379006178@3capp-webde-bs32>

A non-text attachment was scrubbed...
Name: Zielfunktion.PNG
Type: image/png
Size: 7249 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160608/62936c41/attachment.png>

From Servet.Ahmet.Cizmeli at USherbrooke.ca  Wed Jun  8 14:24:14 2016
From: Servet.Ahmet.Cizmeli at USherbrooke.ca (=?UTF-8?Q?Servet_Ahmet_=C3=87izmeli?=)
Date: Wed, 08 Jun 2016 08:24:14 -0400
Subject: [R] UUIDgenerate() withn a s4 class produces the same uuid at each
 instance
Message-ID: <dbe49137e82e909b10e24a9639017c62@courriel-fec.usherbrooke.ca>

 

Hello 

When I create a new instance of an S4 class in R, I would like the newly
created object to have a unique id field. I try to achieve it through
UUIDgenerate() from the uuid package. The problem is that I obtain the
same UUID at every new object instance : 

library(uuid)
setClass("C",
 representation=representation(
 id = "character"
 ),
 prototype = prototype(
 id = UUIDgenerate(use.time = TRUE))
 )

 new("C")

An object of class "C" Slot "id": [1]
"1e07d7c2-2d71-11e6-b5e1-e1f59d8ccf09" 

new("C")

An object of class "C" Slot "id": [1]
"1e07d7c2-2d71-11e6-b5e1-e1f59d8ccf09" 

new("C")

An object of class "C" Slot "id": [1]
"1e07d7c2-2d71-11e6-b5e1-e1f59d8ccf09" 

Calling UUIDgenerate() successively at the R command line produces
different UUIDS each time. 

Where do I go wrong? 

Thanks 

Servet 

 
	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed Jun  8 15:55:46 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 8 Jun 2016 15:55:46 +0200
Subject: [R] Antwort: RE:  Antwort: Re:  Merging variables
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502F332@SRVEXCHMBX.precheza.cz>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
	<OF7CB676EC.936B8ED0-ONC1257FCB.00228C15-C1257FCB.0022AF89@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502F332@SRVEXCHMBX.precheza.cz>
Message-ID: <OF5A118756.13A96171-ONC1257FCC.004BF927-C1257FCC.004C84D8@lotus.hawesko.de>

Hi Petr,

thanks for your reply.

I prepared little example for you:

-- cut --

ds_temp_1 <-
  structure(list(
    CustId = c(1001, 1002, 1003, 1004, 1005, 1006),
    CustName = c("Miller", "Smith", "Doe", "White", "Black",
                 "Nobody"),
    sales = c(100, 500, 300, 50, 700, 10)
  ),
  .Names = c("CustId",
             "CustName", "sales"), row.names = c(NA, 6L), class = 
"data.frame")

ds_temp_2 <-
  structure(
    list(
      CustId = c(1001, 1002, 1003),
      CustName = c("Miller",
                   "Smith", "Doe"),
      CustGroup = c(1, 2, 3)
    ),
    .Names = c("CustId",
               "CustName", "CustGroup"),
    row.names = c(NA, 3L),
    class = "data.frame"
  )

ds_merge <- merge(ds_temp_1, ds_temp_2,
                  by.x = "CustId", all.x = TRUE,
                  by.y = "CustId", all.y = FALSE)

ds_merge

-- cut --

which gives

ds_merge
  CustId CustName.x sales CustName.y CustGroup
1   1001     Miller   100     Miller         1
2   1002      Smith   500      Smith         2
3   1003        Doe   300        Doe         3
4   1004      White    50       <NA>        NA
5   1005      Black   700       <NA>        NA
6   1006     Nobody    10       <NA>        NA

where CustName is split into CustName.x and CustName.y.

What I would like to have is:

ds_merge
  CustId CustName   sales  CustGroup
1   1001     Miller   100          1
2   1002      Smith   500          2
3   1003        Doe   300          3
4   1004      White    50         NA
5   1005      Black   700         NA
6   1006     Nobody    10         NA

That is CustName in a single variable cause the values within that 
variable are identical. I guess because of NA for some cases in ds_temp_2 
R generates CustName.x and CustName.y.

Is there a simple way of merging a dataset and having R return a single 
variable is the values are identical or missing in either one of the 
datasets?

Kind regards

Georg





Von:    PIKAL Petr <petr.pikal at precheza.cz>
An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, 
Kopie:  "r-help at r-project.org" <r-help at r-project.org>
Datum:  07.06.2016 13:11
Betreff:        RE: [R] Antwort: Re:  Merging variables



Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Tuesday, June 7, 2016 8:19 AM
> To: Michael Dewey <lists at dewey.myzen.co.uk>
> Cc: r-help at r-project.org
> Subject: [R] Antwort: Re: Merging variables
>
> Hi Michael,
>
> yes, I was astonished about this behaviour either. I have worked with 
SPSS a
> lot - and that works different.

If you want to join two data frames by common names you can use use

merge(dat1, dat2, ....)

without specifing by. From help page:

By default the data frames are merged on the columns with names they both 
have, but separate specifications of the columns can be given by by.x and 
by.y. The rows in the two data frames that match on the specified columns 
are extracted, and joined together.

>
> I would like to share some of my data. Can you tell me how I can dump a
> dataset in a way that I can post it here as text?

copy result of dput directly to your mail

dput(dat)
structure(list(hz = c(0, 25, 50), vykon = c(0, 11.6, 22.6)), .Names = 
c("hz",
"vykon"), row.names = c(NA, -3L), class = "data.frame")

We can use

dat <- structure(list(hz = c(0, 25, 50), vykon = c(0, 11.6, 22.6)), .Names 
= c("hz",
"vykon"), row.names = c(NA, -3L), class = "data.frame")

to reconstruct the object.

Regards
Petr

>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Michael Dewey <lists at dewey.myzen.co.uk>
> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:  06.06.2016 15:45
> Betreff:        Re: [R] Merging variables
>
>
>
> X-Originating-<%= hostname %>-IP: [217.155.205.190]
>
> Dear Georg
>
> I find it a bit surprising that you end up with customer.x and 
customer.y. Can
> you share with us a toy example of two data.frames which exhibit this
> behaviour?
>
> On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
> > Hi All,
> >
> > I merged two datasets:
> >
> > ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> > ds_zww_customer_4_match,
> >   by.x = "customer", by.y = "customer",
> >   all.x = TRUE, all.y = FALSE)
> >
> > R created a new dataset with the variables customer.x and customer.y.
> > I would like to merge these two variable back together. I wrote a
> > little function (code can be run) for it:
> >
> > -- cut --
> >
> > customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> > customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> > ds_test <- data.frame(customer.x, customer.y, stringsAsFactors =
> > FALSE)
> >
> > t_merge_variables <-
> >   function(dataset,
> >            var1,
> >            var2,
> >            merged_var) {
> >
> >     # Initialize
> >     dataset[[merged_var]] = rep(NA, nrow(dataset))
> >     dataset[["mismatch"]] = rep(NA, nrow(dataset))
> >
> >     for (i in 1:nrow(dataset)) {
> >
> >       # Check 1: var1 missing, var2 missing
> >       if (is.na(dataset[[i, var1]]) &
> >           is.na(dataset[[i, var2]])) {
> >         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
> >
> >       # Check 2: var1 filled, var2 missing
> >       } else if (!is.na(dataset[[i, var1]]) &
> >                  is.na(dataset[[i, var2]])) {
> >         dataset[[i, merged_var]] <- dataset[[i, var1]]
> >         dataset[["mismatch"]] <- 0
> >
> >       # Check 3: var1 missing, var2 filled
> >       } else if (is.na(dataset[[i, var1]]) &
> >                  !is.na(dataset[i, var2])) {
> >         dataset[[i, merged_var]] <- dataset[[i, var2]]
> >         dataset[["mismatch"]] <-  0
> >
> >       # Check 4: var1 == var2
> >       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
> >       dataset[[i, merged_var]] <- dataset[[i, var1]]
> >       dataset[["mismatch"]] <- 0
> >
> >       # Leftover: var1 != var2
> >       } else {
> >         dataset[[i, merged_var]] <- NA
> >         dataset[["mismatch"]] <- 2  # var1 != var2
> >       }  # end if
> >     }  # end for
> >     return(dataset)
> > }
> >
> > ds_var_merge1 <- t_merge_variables(dataset = ds_test,
> >   var1 = "customer.x",
> >   var2 = "customer.y",
> >   merged_var = "customer")
> >
> > ds_var_merge1
> >
> > -- cut --
> >
> > It is executed without error but delivers the wrong values in the
> variable
> > "mismatch". This variable is always 1 although it should be NA, 1 or 2
> > respectively.
> >
> > Can you tell me why the variable is not correctly set?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter 
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization 
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.


From btupper at bigelow.org  Wed Jun  8 16:22:06 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 8 Jun 2016 10:22:06 -0400
Subject: [R] UUIDgenerate() withn a s4 class produces the same uuid at
	each instance
In-Reply-To: <dbe49137e82e909b10e24a9639017c62@courriel-fec.usherbrooke.ca>
References: <dbe49137e82e909b10e24a9639017c62@courriel-fec.usherbrooke.ca>
Message-ID: <11589805-D98C-4A68-B3B0-55B98FF3AE73@bigelow.org>

Hi,

I think your issue is that in the absence of an explicit 'initialize' method the value of id is assigned when you define the class prototype.  All subsequent new instances will use that very same prototype value defined when you first defined the class.  That's in the help for ?new, "The function new begins by copying the prototype object from the class definition."  Read on in the details section to learn more about 'initialize'.

To get a new id for each new object instance you can define an 'initialize' method.

setMethod("initialize",
          "C",
          function(.Object){
              .Object at id = UUIDgenerate(use.time = TRUE)
              .Object
          })

> new("C")
An object of class "C"
Slot "id":
[1] "f5e87504-2d83-11e6-9dcb-685b35bcefe9"

> new("C")
An object of class "C"
Slot "id":
[1] "f73cf010-2d83-11e6-9dcb-685b35bcefe9"

> new("C")
An object of class "C"
Slot "id":
[1] "f8321f22-2d83-11e6-9dcb-685b35bcefe9"

> new("C")
An object of class "C"
Slot "id":
[1] "f96e3c90-2d83-11e6-9dcb-685b35bcefe9"


There may be other ways to achieve the same outcome.   Caveat... I handy with Reference Classes (see ?setRefClass) but have only recently exploring S4 classes.

Cheers,
Ben

> On Jun 8, 2016, at 8:24 AM, Servet Ahmet ?izmeli <Servet.Ahmet.Cizmeli at USherbrooke.ca> wrote:
> 
> 
> 
> Hello 
> 
> When I create a new instance of an S4 class in R, I would like the newly
> created object to have a unique id field. I try to achieve it through
> UUIDgenerate() from the uuid package. The problem is that I obtain the
> same UUID at every new object instance : 
> 
> library(uuid)
> setClass("C",
> representation=representation(
> id = "character"
> ),
> prototype = prototype(
> id = UUIDgenerate(use.time = TRUE))
> )
> 
> new("C")
> 
> An object of class "C" Slot "id": [1]
> "1e07d7c2-2d71-11e6-b5e1-e1f59d8ccf09" 
> 
> new("C")
> 
> An object of class "C" Slot "id": [1]
> "1e07d7c2-2d71-11e6-b5e1-e1f59d8ccf09" 
> 
> new("C")
> 
> An object of class "C" Slot "id": [1]
> "1e07d7c2-2d71-11e6-b5e1-e1f59d8ccf09" 
> 
> Calling UUIDgenerate() successively at the R command line produces
> different UUIDS each time. 
> 
> Where do I go wrong? 
> 
> Thanks 
> 
> Servet 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Report Gulf of Maine jellyfish sightings to jellyfish at bigelow.org or tweet them to #MaineJellies -- include date, time, and location, as well as any descriptive information such as size or type.  Learn more at https://www.bigelow.org/research/srs/nick-record/nick-record-laboratory/mainejellies/


From marc_schwartz at me.com  Wed Jun  8 16:44:46 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 08 Jun 2016 09:44:46 -0500
Subject: [R] Antwort: RE:  Antwort: Re:  Merging variables
In-Reply-To: <OF5A118756.13A96171-ONC1257FCC.004BF927-C1257FCC.004C84D8@lotus.hawesko.de>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
	<OF7CB676EC.936B8ED0-ONC1257FCB.00228C15-C1257FCB.0022AF89@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502F332@SRVEXCHMBX.precheza.cz>
	<OF5A118756.13A96171-ONC1257FCC.004BF927-C1257FCC.004C84D8@lotus.hawesko.de>
Message-ID: <98683F27-3E05-4BE3-9B39-7F243E4818D0@me.com>

Hi,

Sorry for jumping in late here, but the issue is that you are only specifying "CustId" as the key column to merge (join) on. 

Thus, other columns in the two data frames that may have the same name, as is the case with "CustName", have the default suffix as defined by the argument 'suffixes', appended to the column names to make them unique in the resultant data frame. You cannot have two columns with the same name in a data frame.

The description of the 'suffixes' argument, which defaults to c(".x",".y"), is:

"a character vector of length 2 specifying the suffixes to be used for making unique the names of columns in the result which not used for merging (appearing in by etc)."


If you were to use:

 merge(ds_temp_1, ds_temp_2, by = c("CustId", "CustName"), all.x = TRUE)
  CustId CustName sales CustGroup
1   1001   Miller   100         1
2   1002    Smith   500         2
3   1003      Doe   300         3
4   1004    White    50        NA
5   1005    Black   700        NA
6   1006   Nobody    10        NA


where you do the join on both columns, your issue is resolved.

That, of course, presumes that the combination of CustId and CustName are uniquely associated with each other.

Regards,

Marc Schwartz

> On Jun 8, 2016, at 8:55 AM, G.Maubach at weinwolf.de wrote:
> 
> Hi Petr,
> 
> thanks for your reply.
> 
> I prepared little example for you:
> 
> -- cut --
> 
> ds_temp_1 <-
>  structure(list(
>    CustId = c(1001, 1002, 1003, 1004, 1005, 1006),
>    CustName = c("Miller", "Smith", "Doe", "White", "Black",
>                 "Nobody"),
>    sales = c(100, 500, 300, 50, 700, 10)
>  ),
>  .Names = c("CustId",
>             "CustName", "sales"), row.names = c(NA, 6L), class = 
> "data.frame")
> 
> ds_temp_2 <-
>  structure(
>    list(
>      CustId = c(1001, 1002, 1003),
>      CustName = c("Miller",
>                   "Smith", "Doe"),
>      CustGroup = c(1, 2, 3)
>    ),
>    .Names = c("CustId",
>               "CustName", "CustGroup"),
>    row.names = c(NA, 3L),
>    class = "data.frame"
>  )
> 
> ds_merge <- merge(ds_temp_1, ds_temp_2,
>                  by.x = "CustId", all.x = TRUE,
>                  by.y = "CustId", all.y = FALSE)
> 
> ds_merge
> 
> -- cut --
> 
> which gives
> 
> ds_merge
>  CustId CustName.x sales CustName.y CustGroup
> 1   1001     Miller   100     Miller         1
> 2   1002      Smith   500      Smith         2
> 3   1003        Doe   300        Doe         3
> 4   1004      White    50       <NA>        NA
> 5   1005      Black   700       <NA>        NA
> 6   1006     Nobody    10       <NA>        NA
> 
> where CustName is split into CustName.x and CustName.y.
> 
> What I would like to have is:
> 
> ds_merge
>  CustId CustName   sales  CustGroup
> 1   1001     Miller   100          1
> 2   1002      Smith   500          2
> 3   1003        Doe   300          3
> 4   1004      White    50         NA
> 5   1005      Black   700         NA
> 6   1006     Nobody    10         NA
> 
> That is CustName in a single variable cause the values within that 
> variable are identical. I guess because of NA for some cases in ds_temp_2 
> R generates CustName.x and CustName.y.
> 
> Is there a simple way of merging a dataset and having R return a single 
> variable is the values are identical or missing in either one of the 
> datasets?
> 
> Kind regards
> 
> Georg
> 
> 
> 
> 
> 
> Von:    PIKAL Petr <petr.pikal at precheza.cz>
> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, 
> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
> Datum:  07.06.2016 13:11
> Betreff:        RE: [R] Antwort: Re:  Merging variables
> 
> 
> 
> Hi
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> G.Maubach at weinwolf.de
>> Sent: Tuesday, June 7, 2016 8:19 AM
>> To: Michael Dewey <lists at dewey.myzen.co.uk>
>> Cc: r-help at r-project.org
>> Subject: [R] Antwort: Re: Merging variables
>> 
>> Hi Michael,
>> 
>> yes, I was astonished about this behaviour either. I have worked with 
> SPSS a
>> lot - and that works different.
> 
> If you want to join two data frames by common names you can use use
> 
> merge(dat1, dat2, ....)
> 
> without specifing by. From help page:
> 
> By default the data frames are merged on the columns with names they both 
> have, but separate specifications of the columns can be given by by.x and 
> by.y. The rows in the two data frames that match on the specified columns 
> are extracted, and joined together.
> 
>> 
>> I would like to share some of my data. Can you tell me how I can dump a
>> dataset in a way that I can post it here as text?
> 
> copy result of dput directly to your mail
> 
> dput(dat)
> structure(list(hz = c(0, 25, 50), vykon = c(0, 11.6, 22.6)), .Names = 
> c("hz",
> "vykon"), row.names = c(NA, -3L), class = "data.frame")
> 
> We can use
> 
> dat <- structure(list(hz = c(0, 25, 50), vykon = c(0, 11.6, 22.6)), .Names 
> = c("hz",
> "vykon"), row.names = c(NA, -3L), class = "data.frame")
> 
> to reconstruct the object.
> 
> Regards
> Petr
> 
>> 
>> Kind regards
>> 
>> Georg
>> 
>> 
>> 
>> 
>> Von:    Michael Dewey <lists at dewey.myzen.co.uk>
>> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
>> Datum:  06.06.2016 15:45
>> Betreff:        Re: [R] Merging variables
>> 
>> 
>> 
>> X-Originating-<%= hostname %>-IP: [217.155.205.190]
>> 
>> Dear Georg
>> 
>> I find it a bit surprising that you end up with customer.x and 
> customer.y. Can
>> you share with us a toy example of two data.frames which exhibit this
>> behaviour?
>> 
>> On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
>>> Hi All,
>>> 
>>> I merged two datasets:
>>> 
>>> ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
>>> ds_zww_customer_4_match,
>>>  by.x = "customer", by.y = "customer",
>>>  all.x = TRUE, all.y = FALSE)
>>> 
>>> R created a new dataset with the variables customer.x and customer.y.
>>> I would like to merge these two variable back together. I wrote a
>>> little function (code can be run) for it:
>>> 
>>> -- cut --
>>> 
>>> customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
>>> customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
>>> ds_test <- data.frame(customer.x, customer.y, stringsAsFactors =
>>> FALSE)
>>> 
>>> t_merge_variables <-
>>>  function(dataset,
>>>           var1,
>>>           var2,
>>>           merged_var) {
>>> 
>>>    # Initialize
>>>    dataset[[merged_var]] = rep(NA, nrow(dataset))
>>>    dataset[["mismatch"]] = rep(NA, nrow(dataset))
>>> 
>>>    for (i in 1:nrow(dataset)) {
>>> 
>>>      # Check 1: var1 missing, var2 missing
>>>      if (is.na(dataset[[i, var1]]) &
>>>          is.na(dataset[[i, var2]])) {
>>>        dataset[["mismatch"]] <- 1  # var1 & var2 are missing
>>> 
>>>      # Check 2: var1 filled, var2 missing
>>>      } else if (!is.na(dataset[[i, var1]]) &
>>>                 is.na(dataset[[i, var2]])) {
>>>        dataset[[i, merged_var]] <- dataset[[i, var1]]
>>>        dataset[["mismatch"]] <- 0
>>> 
>>>      # Check 3: var1 missing, var2 filled
>>>      } else if (is.na(dataset[[i, var1]]) &
>>>                 !is.na(dataset[i, var2])) {
>>>        dataset[[i, merged_var]] <- dataset[[i, var2]]
>>>        dataset[["mismatch"]] <-  0
>>> 
>>>      # Check 4: var1 == var2
>>>      } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
>>>      dataset[[i, merged_var]] <- dataset[[i, var1]]
>>>      dataset[["mismatch"]] <- 0
>>> 
>>>      # Leftover: var1 != var2
>>>      } else {
>>>        dataset[[i, merged_var]] <- NA
>>>        dataset[["mismatch"]] <- 2  # var1 != var2
>>>      }  # end if
>>>    }  # end for
>>>    return(dataset)
>>> }
>>> 
>>> ds_var_merge1 <- t_merge_variables(dataset = ds_test,
>>>  var1 = "customer.x",
>>>  var2 = "customer.y",
>>>  merged_var = "customer")
>>> 
>>> ds_var_merge1
>>> 
>>> -- cut --
>>> 
>>> It is executed without error but delivers the wrong values in the
>> variable
>>> "mismatch". This variable is always 1 although it should be NA, 1 or 2
>>> respectively.
>>> 
>>> Can you tell me why the variable is not correctly set?
>>> 
>>> Kind regards
>>> 
>>> Georg


From j.logsdon at quantex-research.com  Wed Jun  8 18:41:50 2016
From: j.logsdon at quantex-research.com (John Logsdon)
Date: Wed, 8 Jun 2016 17:41:50 +0100
Subject: [R] apply and cousins
Message-ID: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>

Folks

Is there any way to get the row index into apply as a variable?

I want a function to do some sums on a small subset of some very long
vectors, rolling through the whole vectors.

apply(X,1,function {do something}, other arguments)

seems to be the way to do it.

The subset I want is the most recent set of measurements only - perhaps a
couple of hundred out of millions - but I can't see how to index each
value.  The ultimate output should be a matrix of results the length of
the input vector.  But to do the sum I need to access the current row
number.

It is easy in a loop but that will take ages. Is there any vectorised
apply-like solution to this?

Or does apply etc only operate on each row at a time, independently of
other rows?


Best wishes

John

John Logsdon
Quantex Research Ltd
+44 161 445 4951/+44 7717758675


From wdunlap at tibco.com  Wed Jun  8 18:50:37 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 8 Jun 2016 09:50:37 -0700
Subject: [R] apply and cousins
In-Reply-To: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>
References: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>
Message-ID: <CAF8bMcbZHGSWxwFgxR1eyxQtSAYikCU5V_c9gpVOWNuvV6ysqg@mail.gmail.com>

>It is easy in a loop but that will take ages. Is there any vectorised
>apply-like solution to this?

If you showed the loop that takes ages, along with small inputs for
it (and an indication of how to expand those small inputs to big ones),
someone might be able to show you some code that does the
same thing in less time.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jun 8, 2016 at 9:41 AM, John Logsdon <j.logsdon at quantex-research.com
> wrote:

> Folks
>
> Is there any way to get the row index into apply as a variable?
>
> I want a function to do some sums on a small subset of some very long
> vectors, rolling through the whole vectors.
>
> apply(X,1,function {do something}, other arguments)
>
> seems to be the way to do it.
>
> The subset I want is the most recent set of measurements only - perhaps a
> couple of hundred out of millions - but I can't see how to index each
> value.  The ultimate output should be a matrix of results the length of
> the input vector.  But to do the sum I need to access the current row
> number.
>
> It is easy in a loop but that will take ages. Is there any vectorised
> apply-like solution to this?
>
> Or does apply etc only operate on each row at a time, independently of
> other rows?
>
>
> Best wishes
>
> John
>
> John Logsdon
> Quantex Research Ltd
> +44 161 445 4951/+44 7717758675
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun  8 18:59:52 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 08 Jun 2016 09:59:52 -0700
Subject: [R] Knitr R - how to draw plot exactly at place of plot
	function call in output document?
In-Reply-To: <CAKVAULMhB-AQP9jh5MEjtSMq364EqYxJ+jc-8MEuqSHCRjXzug@mail.gmail.com>
References: <CAEJSOqi96Qt6O5qhZbTE5ax8GPNoC31t5vN_gjFgGazhbiDFvQ@mail.gmail.com>
	<CAKVAULPhdUMdrU4Gk+pJ5w=YCB=+pg7+zTG6cWG6Bmgy0B-AhA@mail.gmail.com>
	<CAEJSOqgpEbAHs-kzksqkCJ6tdmx2LS5VYRF=Kg_4TAo3QabzuQ@mail.gmail.com>
	<CAKVAULMhB-AQP9jh5MEjtSMq364EqYxJ+jc-8MEuqSHCRjXzug@mail.gmail.com>
Message-ID: <DEC1853C-92A3-4015-A20D-DDC689FF8C76@dcn.davis.ca.us>

I would echo the suggestion that the knitr Google group or stackexchange.com would be better than this list for this question.  I also suggest that you look at http://yihui.name/knitr/demo/child/ and make a reproducible example if you decide to ask for more help in one of those forums. 
-- 
Sent from my phone. Please excuse my brevity.

On June 6, 2016 10:51:36 PM PDT, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>Hi Michu,
>
>it is not I problem I am familiar with, sorry. Maybe someone else on
>this
>list or at the knirt google group can help you further.
>
>Best,
>Ulrik
>
>On Mon, 6 Jun 2016 at 10:36 Michu Kom <michu.kom at gmail.com> wrote:
>
>> Hello,
>>
>> HTML looks much nicer :) ... but still problem is not solved :/ still
>> having mixed sections and plots.
>>
>> Thank you for your advice,
>> Michu
>>
>> 2016-06-06 10:04 GMT+02:00 Ulrik Stervbo <ulrik.stervbo at gmail.com>:
>>
>>> Hi Michu,
>>>
>>> What document type do you generate? I usually make just html and
>have no
>>> problems. If you create a pdf, please remember this is done through
>LaTeX
>>> and your problem could arise from the floats of LaTeX.
>>>
>>> For other output I have no idea.
>>>
>>> Hope this helps
>>> Ulrik
>>>
>>> Michu Kom <michu.kom at gmail.com> schrieb am Mo., 6. Juni 2016 09:41:
>>>
>>>> My R script run with Knitr generates a statistic summary of
>electrode
>>>> pairs
>>>> accompanied with plots. The problem is that knitr does not render
>plots
>>>> in
>>>> correct sections. In section for pair A knitr do not wait for plot
>and
>>>> start to evaluate code for output summary for pair B. So in section
>B
>>>> knitr
>>>> places plot from section A among printed output summary for pair B.
>>>>
>>>> My function analizePair calculates some statistics and print them
>out. I
>>>> call a ezPlot function inside analizePair function.
>>>>
>>>> knitr::opts_chunk$set(fig.show = 'asis') # 'hold' option is not
>proper
>>>> for my needs
>>>> for(pair in pairsLabels)
>>>>     {
>>>>         print("----------")
>>>>         print("Analysing single pair of electrodes...")
>>>>         print("----------")
>>>>         print(pair)
>>>>
>>>>         analizePair(pairLabel = pair)
>>>>
>>>>         print("----------")
>>>>         print("Analysing pair finished.")
>>>>         print("----------")
>>>>     }
>>>>
>>>> I also tried to put Sys.sleep(2) after analizePair, but it do not
>solve
>>>> the
>>>> problem.
>>>>
>>>> How to force knitr/R to wait until plot is generated and put before
>>>> starting next section (next iteration of for loop) ?
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jun  8 19:13:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 8 Jun 2016 10:13:47 -0700
Subject: [R] apply and cousins
In-Reply-To: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>
References: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>
Message-ID: <CAGxFJbTamw6c=utKvW_U30KC05ZiUO7vRX6g-fGxwhEk1ViScg@mail.gmail.com>

John:

1. Please read and follow the posting guide. In particular, provide a
small reproducible example so that we know what your data and looping
code look like.

2. apply-type commands are *not* vectorized; they are disguised loops
that may or may not offer any speedup over explicit loops.

3. A guess at a possible strategy is to convert character date-time
data to POSIXct dates using as.POSITct and then just choose those rows
with the maximum value . e.g.

x[x==max(x)]

These operations *are* vectorized.

However, this guess might be completely useless with your unspecified
data, so beware.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 8, 2016 at 9:41 AM, John Logsdon
<j.logsdon at quantex-research.com> wrote:
> Folks
>
> Is there any way to get the row index into apply as a variable?
>
> I want a function to do some sums on a small subset of some very long
> vectors, rolling through the whole vectors.
>
> apply(X,1,function {do something}, other arguments)
>
> seems to be the way to do it.
>
> The subset I want is the most recent set of measurements only - perhaps a
> couple of hundred out of millions - but I can't see how to index each
> value.  The ultimate output should be a matrix of results the length of
> the input vector.  But to do the sum I need to access the current row
> number.
>
> It is easy in a loop but that will take ages. Is there any vectorised
> apply-like solution to this?
>
> Or does apply etc only operate on each row at a time, independently of
> other rows?
>
>
> Best wishes
>
> John
>
> John Logsdon
> Quantex Research Ltd
> +44 161 445 4951/+44 7717758675
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Wed Jun  8 19:20:38 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 8 Jun 2016 17:20:38 +0000
Subject: [R] Reading and converting time data via read.table
In-Reply-To: <CA+ZkTxsDR3J7=MK2Y9qBgsoandQ9YgQ8FnszBnOtz3yy5159Bw@mail.gmail.com>
References: <CA+ZkTxsDR3J7=MK2Y9qBgsoandQ9YgQ8FnszBnOtz3yy5159Bw@mail.gmail.com>
Message-ID: <D37D9F6A.17AC38%macqueen1@llnl.gov>

As far as I know, base R does not have a class for storing times that are
not associated with a date, and recognizing that they are times. That
being the case, I don't think there is a way to convert them to some sort
of time class while reading them into R using read.table(). I would read
them into R as character strings, and then convert them (it would take
only a few extra lines of code). How you convert them depends on the next
question, which is:

What do you need to do with those times?

For example, are T1 and T2 the times associated with two events that both
occurred on the specified Date? If that is the case, I would probably form
two POSIXct variables by combining the Date with T1 and the Date with T2.
Or, do you just need to be able to sort your data by T1, or by T2? Or do
you need to calculate the time differences (such as T2-T1) to get the
number of minutes between those two times?

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/5/16, 5:53 AM, "R-help on behalf of Ek Esawi"
<r-help-bounces at r-project.org on behalf of esawiek at gmail.com> wrote:

>Hi All--
>
>
>
>I am relatively new to R. I am reading a csv file via read.table (MyFile).
>The data types in the file are date, string, integer, and time. I was able
>to read all the data and manipulated correctly except time, e.g., 12:30. I
>used as.Date to convert date and string and integer were easily done. I
>could not figure out how to convert the time data correctly. I tried chron
>but w/o success and I read that POSIXlt and POSIXct work only for date and
>time (e.g. 01/02/1999, 12:30:20). I did not try the lubridate package. Is
>there a way to read time data without date attached to it like mine?
>
>
>
>I am grateful for any help and thanks in advance?EKE
>
>
>
>Here is an example of my data when read into R via read.table
>
>
>
>                AA          Date         Name     T1          T2
>N1
>
>1              312171  7/1/1995       OF      13:37      1:43         123
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Wed Jun  8 19:37:01 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 8 Jun 2016 17:37:01 +0000
Subject: [R] apply and cousins
In-Reply-To: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>
References: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>
Message-ID: <D37DA3AC.17AC7A%macqueen1@llnl.gov>

Hopefully Bert and William won't be offended if I more or less summarize:

Are you assuming a loop will take ages, or have you actually tested it? I
wouldn't assume a loop will take ages, or that it will take much longer
than apply().

What's wrong with

  apply( X[ {logical expression } , ] , 1, function {do something} )

?

Where the logical expression identifies (by row index or any other method)
which rows you need to work on. I would expect it to be faster to subset
the rows first, rather than test for inclusion at every iteration within a
loop.

Also, if the data is acquired in such a way that you can know that the
most recent set of measurements is the last n rows, then tail(X,n) might
be good. For example,

> foo <- matrix(1:20, ncol=2)
> foo
      [,1] [,2]
 [1,]    1   11
 [2,]    2   12
 [3,]    3   13
 [4,]    4   14
 [5,]    5   15
 [6,]    6   16
 [7,]    7   17
 [8,]    8   18
 [9,]    9   19
[10,]   10   20
> tail(foo,4)
      [,1] [,2]
 [7,]    7   17
 [8,]    8   18
 [9,]    9   19
[10,]   10   20


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/8/16, 9:41 AM, "R-help on behalf of John Logsdon"
<r-help-bounces at r-project.org on behalf of j.logsdon at quantex-research.com>
wrote:

>Folks
>
>Is there any way to get the row index into apply as a variable?
>
>I want a function to do some sums on a small subset of some very long
>vectors, rolling through the whole vectors.
>
>apply(X,1,function {do something}, other arguments)
>
>seems to be the way to do it.
>
>The subset I want is the most recent set of measurements only - perhaps a
>couple of hundred out of millions - but I can't see how to index each
>value.  The ultimate output should be a matrix of results the length of
>the input vector.  But to do the sum I need to access the current row
>number.
>
>It is easy in a loop but that will take ages. Is there any vectorised
>apply-like solution to this?
>
>Or does apply etc only operate on each row at a time, independently of
>other rows?
>
>
>Best wishes
>
>John
>
>John Logsdon
>Quantex Research Ltd
>+44 161 445 4951/+44 7717758675
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Jun  8 19:57:26 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 08 Jun 2016 10:57:26 -0700
Subject: [R] Reading and converting time data via read.table
In-Reply-To: <D37D9F6A.17AC38%macqueen1@llnl.gov>
References: <CA+ZkTxsDR3J7=MK2Y9qBgsoandQ9YgQ8FnszBnOtz3yy5159Bw@mail.gmail.com>
	<D37D9F6A.17AC38%macqueen1@llnl.gov>
Message-ID: <43C818F4-AC10-4860-8FD7-3221027B6980@dcn.davis.ca.us>

The canonical way to store times is as difftime vectors.  However, there is no simple way to import e.g. HH:MM data directly into such vectors, so you need to embed such times into a longer string that includes a fixed date. After conversion to POSIXct you can subtract the fixed date to get the difftime values.

It is also possible to let the conversion to POSIXct pick "today" by default, but you can sometimes get into trouble if you subtract out "today" on a different day, so I wouldn't recommend it. 

You also may encounter difficulty with daylight savings in this process... but that usually requires knowing a bit more about your data, and if you are already working with time only data you may not be able to fix such problems anyway. 
-- 
Sent from my phone. Please excuse my brevity.

On June 8, 2016 10:20:38 AM PDT, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>As far as I know, base R does not have a class for storing times that
>are
>not associated with a date, and recognizing that they are times. That
>being the case, I don't think there is a way to convert them to some
>sort
>of time class while reading them into R using read.table(). I would
>read
>them into R as character strings, and then convert them (it would take
>only a few extra lines of code). How you convert them depends on the
>next
>question, which is:
>
>What do you need to do with those times?
>
>For example, are T1 and T2 the times associated with two events that
>both
>occurred on the specified Date? If that is the case, I would probably
>form
>two POSIXct variables by combining the Date with T1 and the Date with
>T2.
>Or, do you just need to be able to sort your data by T1, or by T2? Or
>do
>you need to calculate the time differences (such as T2-T1) to get the
>number of minutes between those two times?
>
>-Don
>
>-- 
>Don MacQueen
>
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>
>
>
>
>
>On 6/5/16, 5:53 AM, "R-help on behalf of Ek Esawi"
><r-help-bounces at r-project.org on behalf of esawiek at gmail.com> wrote:
>
>>Hi All--
>>
>>
>>
>>I am relatively new to R. I am reading a csv file via read.table
>(MyFile).
>>The data types in the file are date, string, integer, and time. I was
>able
>>to read all the data and manipulated correctly except time, e.g.,
>12:30. I
>>used as.Date to convert date and string and integer were easily done.
>I
>>could not figure out how to convert the time data correctly. I tried
>chron
>>but w/o success and I read that POSIXlt and POSIXct work only for date
>and
>>time (e.g. 01/02/1999, 12:30:20). I did not try the lubridate package.
>Is
>>there a way to read time data without date attached to it like mine?
>>
>>
>>
>>I am grateful for any help and thanks in advance?EKE
>>
>>
>>
>>Here is an example of my data when read into R via read.table
>>
>>
>>
>>                AA          Date         Name     T1          T2
>>N1
>>
>>1              312171  7/1/1995       OF      13:37      1:43        
>123
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From joonas.isoketo at houston-analytics.com  Wed Jun  8 20:31:31 2016
From: joonas.isoketo at houston-analytics.com (Joonas Isoketo)
Date: Wed, 8 Jun 2016 18:31:31 +0000
Subject: [R] Tree plot with percentages and hierarchies
Message-ID: <DB5PR0101MB15899FE67D65276242A79F9AC25E0@DB5PR0101MB1589.eurprd01.prod.exchangelabs.com>

Hi,

I have the following problem:

I want to visualize distributions of a few varibles in a specific order with a help of tree figure. Above of all is "Action x" and that happens for two (or n) reasons: "Reason 1" 50 % and "Reason 2" 50 %.
Further, "Reason 1" happens for two (or n) subreasons: "Subreason 11" (75 %) and "Subreason 12" (25 %). And further, "Subreason 11" happens for two (or n) subsubreason "SubSubreason 111" etc.

Every time when parent node splits to its childs, the sum of child node's percentages should be 100 %.

I am very pleaseful if someone could help me with this! If the plot cannot be made "on the fly", also instructions of custom tree helps (hard coded values).

Here is the test data:

Level_0 = c("Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X")
Level_1 = c("Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2")
Level_2 = c("Subreason 11", "Subreason 11", "Subreason 11", "Subreason 11", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 22", "Subreason 22")
Level_3 = c("Subsubreason 111", "Subsubreason 111", "Subsubreason 111", "Subsubreason 112", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 222", "Subsubreason 222")

Levels = data.frame(Level_0 = Level_0, Level_1 = Level_1, Level_2 = Level_2, Level_3 = Level_3)



Best regards,

Joonas Isoketo




	[[alternative HTML version deleted]]


From vivek4 at mail.usf.edu  Wed Jun  8 16:13:13 2016
From: vivek4 at mail.usf.edu (Vivek Singh)
Date: Wed, 8 Jun 2016 10:13:13 -0400
Subject: [R] R getting "Killed" while running VAR model
In-Reply-To: <377df3ac-38e3-9e64-c516-4c5e6f900b38@statistik.tu-dortmund.de>
References: <CAJGK8=-AW81ypB_cZsO55XCXfk9+uNL26fv0UyjubUZpeLpBAQ@mail.gmail.com>
	<377df3ac-38e3-9e64-c516-4c5e6f900b38@statistik.tu-dortmund.de>
Message-ID: <CAJGK8=8Nid4R-DjxrKzGk6XTkgffOX+S84i26-03N8yitt7sTg@mail.gmail.com>

I am using *R version 3.0.2* (2013-09-25) on Ubuntu desktop (*Ubuntu
14.04.4 LTS*). I am running *var model *on a matrix with 199 columns and
604800 rows. The server has 12 core and 32GB of memory. When the model is
running, i checked CPU and Memory consumption using 'htop' linux command. I
observe all the cores are being used and memory memory usage is on average
17GB out of 32GB. After running the model for about an hour, the system
kills the R process. Following the output:

*> library("vars")*
*> vmodel=VAR(only_variables_without_missing, p = 1, type ="both")*
*Killed*

Please help.



Regards,

Vivek Kumar Singh

PhD student,
Information Systems Decision Sciences,
MUMA College of Business,
USF
Phone- (813) 5809131
Web: http://vivek4.myweb.usf.edu/

On Tue, May 31, 2016 at 4:41 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

> Wild guess: You have huge and high dimensional VAR models, i.e. the
> matrices get huge and you use huge amounts of memory and you use more than
> what is available physically. The operating system protects itself by
> killing processes in such a case...
>
> Best,
> Uwe Ligges
>
>
>
> On 31.05.2016 20:29, Vivek Singh wrote:
>
>> Hi,
>>
>> I am using VARS (vector autoregressive model). The process gets killed
>> after running for sometime. Following is the output of R.
>>
>> vivek at isds-research:~/cloudAuction/padding/panel$ cat var.Rout
>>
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>   Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> [Previously saved workspace restored]
>>
>> data=read.csv("output1.csv")
>>> attach(data)
>>> only_variables= subset(data, select=c(-date,-hour,-minute,-sec))
>>>
>>> library("vars")
>>>
>> Loading required package: MASS
>> Loading required package: strucchange
>> Loading required package: zoo
>>
>> Attaching package: ?zoo?
>>
>> The following objects are masked from ?package:base?:
>>
>>     as.Date, as.Date.numeric
>>
>> Loading required package: sandwich
>> Loading required package: urca
>> Loading required package: lmtest
>>
>>> summary(VAR(only_variables, p = 1, type ="both"))
>>>
>> *Killed*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From vivek4 at mail.usf.edu  Wed Jun  8 16:51:00 2016
From: vivek4 at mail.usf.edu (Vivek Singh)
Date: Wed, 8 Jun 2016 10:51:00 -0400
Subject: [R] R getting "Killed" while running VAR model
In-Reply-To: <CAJGK8=8Nid4R-DjxrKzGk6XTkgffOX+S84i26-03N8yitt7sTg@mail.gmail.com>
References: <CAJGK8=-AW81ypB_cZsO55XCXfk9+uNL26fv0UyjubUZpeLpBAQ@mail.gmail.com>
	<377df3ac-38e3-9e64-c516-4c5e6f900b38@statistik.tu-dortmund.de>
	<CAJGK8=8Nid4R-DjxrKzGk6XTkgffOX+S84i26-03N8yitt7sTg@mail.gmail.com>
Message-ID: <CAJGK8=-CoBqNohg+31YUgv_ghirLq1WqXfp-ACG0+zEGLW4kmg@mail.gmail.com>

I checked the issue on different forums like stackoverflow. The issue is
related to Out Of Memory (OOM) linux feature which kills processes that
consume large memory and swap. I started to monitor the memory and swap
consumption while VAR model was running. The R consumed all 32 GB of RAM
memory and then 20 GB of swap. I have only 32GB of RAM and 20GB of swap in
my server. Then the R was killed.

So, i have two queries:

1. Is there a way to limit the amount of memory used by R so that it runs
for longer time?

2. Is it some sort of inefficiency of garbage collector in R?



Regards,

Vivek Kumar Singh

PhD student,
Information Systems Decision Sciences,
MUMA College of Business,
USF
Phone- (813) 5809131
Web: http://vivek4.myweb.usf.edu/

On Wed, Jun 8, 2016 at 10:13 AM, Vivek Singh <vivek4 at mail.usf.edu> wrote:

> I am using *R version 3.0.2* (2013-09-25) on Ubuntu desktop (*Ubuntu
> 14.04.4 LTS*). I am running *var model *on a matrix with 199 columns and
> 604800 rows. The server has 12 core and 32GB of memory. When the model is
> running, i checked CPU and Memory consumption using 'htop' linux command. I
> observe all the cores are being used and memory memory usage is on average
> 17GB out of 32GB. After running the model for about an hour, the system
> kills the R process. Following the output:
>
> *> library("vars")*
> *> vmodel=VAR(only_variables_without_missing, p = 1, type ="both")*
> *Killed*
>
> Please help.
>
>
>
> Regards,
>
> Vivek Kumar Singh
>
> PhD student,
> Information Systems Decision Sciences,
> MUMA College of Business,
> USF
> Phone- (813) 5809131
> Web: http://vivek4.myweb.usf.edu/
>
> On Tue, May 31, 2016 at 4:41 PM, Uwe Ligges <
> ligges at statistik.tu-dortmund.de> wrote:
>
>> Wild guess: You have huge and high dimensional VAR models, i.e. the
>> matrices get huge and you use huge amounts of memory and you use more than
>> what is available physically. The operating system protects itself by
>> killing processes in such a case...
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>> On 31.05.2016 20:29, Vivek Singh wrote:
>>
>>> Hi,
>>>
>>> I am using VARS (vector autoregressive model). The process gets killed
>>> after running for sometime. Following is the output of R.
>>>
>>> vivek at isds-research:~/cloudAuction/padding/panel$ cat var.Rout
>>>
>>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>>> Copyright (C) 2013 The R Foundation for Statistical Computing
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>
>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>> You are welcome to redistribute it under certain conditions.
>>> Type 'license()' or 'licence()' for distribution details.
>>>
>>>   Natural language support but running in an English locale
>>>
>>> R is a collaborative project with many contributors.
>>> Type 'contributors()' for more information and
>>> 'citation()' on how to cite R or R packages in publications.
>>>
>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>> 'help.start()' for an HTML browser interface to help.
>>> Type 'q()' to quit R.
>>>
>>> [Previously saved workspace restored]
>>>
>>> data=read.csv("output1.csv")
>>>> attach(data)
>>>> only_variables= subset(data, select=c(-date,-hour,-minute,-sec))
>>>>
>>>> library("vars")
>>>>
>>> Loading required package: MASS
>>> Loading required package: strucchange
>>> Loading required package: zoo
>>>
>>> Attaching package: ?zoo?
>>>
>>> The following objects are masked from ?package:base?:
>>>
>>>     as.Date, as.Date.numeric
>>>
>>> Loading required package: sandwich
>>> Loading required package: urca
>>> Loading required package: lmtest
>>>
>>>> summary(VAR(only_variables, p = 1, type ="both"))
>>>>
>>> *Killed*
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jun  8 22:03:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 8 Jun 2016 13:03:53 -0700
Subject: [R] Tree plot with percentages and hierarchies
In-Reply-To: <DB5PR0101MB15899FE67D65276242A79F9AC25E0@DB5PR0101MB1589.eurprd01.prod.exchangelabs.com>
References: <DB5PR0101MB15899FE67D65276242A79F9AC25E0@DB5PR0101MB1589.eurprd01.prod.exchangelabs.com>
Message-ID: <CAGxFJbQgftsGwfCqRJ=Y2GAVp1-f09o6K4UVG8VWzFsXpXN4JA@mail.gmail.com>

I am not really sure what you want, but it sounds like you want the
"rpart" package (which is part of the standard R distribution).

If that won't do, check the machine learning task view here:
https://cran.r-project.org/web/views/MachineLearning.html

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 8, 2016 at 11:31 AM, Joonas Isoketo
<joonas.isoketo at houston-analytics.com> wrote:
> Hi,
>
> I have the following problem:
>
> I want to visualize distributions of a few varibles in a specific order with a help of tree figure. Above of all is "Action x" and that happens for two (or n) reasons: "Reason 1" 50 % and "Reason 2" 50 %.
> Further, "Reason 1" happens for two (or n) subreasons: "Subreason 11" (75 %) and "Subreason 12" (25 %). And further, "Subreason 11" happens for two (or n) subsubreason "SubSubreason 111" etc.
>
> Every time when parent node splits to its childs, the sum of child node's percentages should be 100 %.
>
> I am very pleaseful if someone could help me with this! If the plot cannot be made "on the fly", also instructions of custom tree helps (hard coded values).
>
> Here is the test data:
>
> Level_0 = c("Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X")
> Level_1 = c("Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2")
> Level_2 = c("Subreason 11", "Subreason 11", "Subreason 11", "Subreason 11", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 22", "Subreason 22")
> Level_3 = c("Subsubreason 111", "Subsubreason 111", "Subsubreason 111", "Subsubreason 112", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 222", "Subsubreason 222")
>
> Levels = data.frame(Level_0 = Level_0, Level_1 = Level_1, Level_2 = Level_2, Level_3 = Level_3)
>
>
>
> Best regards,
>
> Joonas Isoketo
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Jun  8 23:41:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 08 Jun 2016 14:41:09 -0700
Subject: [R] R getting "Killed" while running VAR model
In-Reply-To: <CAJGK8=-CoBqNohg+31YUgv_ghirLq1WqXfp-ACG0+zEGLW4kmg@mail.gmail.com>
References: <CAJGK8=-AW81ypB_cZsO55XCXfk9+uNL26fv0UyjubUZpeLpBAQ@mail.gmail.com>
	<377df3ac-38e3-9e64-c516-4c5e6f900b38@statistik.tu-dortmund.de>
	<CAJGK8=8Nid4R-DjxrKzGk6XTkgffOX+S84i26-03N8yitt7sTg@mail.gmail.com>
	<CAJGK8=-CoBqNohg+31YUgv_ghirLq1WqXfp-ACG0+zEGLW4kmg@mail.gmail.com>
Message-ID: <22151629-3BAA-450D-9562-E9C9FB089224@dcn.davis.ca.us>

1. Don't allocate it. 

2. If it was, would it make a difference? 

Seriously, some algorithms need more memory than others, and some packages are more wasteful than others. R is not monolithic... sometimes you just have to roll up your sleeves or buy more memory. 
-- 
Sent from my phone. Please excuse my brevity.

On June 8, 2016 7:51:00 AM PDT, Vivek Singh <vivek4 at mail.usf.edu> wrote:
>I checked the issue on different forums like stackoverflow. The issue
>is
>related to Out Of Memory (OOM) linux feature which kills processes that
>consume large memory and swap. I started to monitor the memory and swap
>consumption while VAR model was running. The R consumed all 32 GB of
>RAM
>memory and then 20 GB of swap. I have only 32GB of RAM and 20GB of swap
>in
>my server. Then the R was killed.
>
>So, i have two queries:
>
>1. Is there a way to limit the amount of memory used by R so that it
>runs
>for longer time?
>
>2. Is it some sort of inefficiency of garbage collector in R?
>
>
>
>Regards,
>
>Vivek Kumar Singh
>
>PhD student,
>Information Systems Decision Sciences,
>MUMA College of Business,
>USF
>Phone- (813) 5809131
>Web: http://vivek4.myweb.usf.edu/
>
>On Wed, Jun 8, 2016 at 10:13 AM, Vivek Singh <vivek4 at mail.usf.edu>
>wrote:
>
>> I am using *R version 3.0.2* (2013-09-25) on Ubuntu desktop (*Ubuntu
>> 14.04.4 LTS*). I am running *var model *on a matrix with 199 columns
>and
>> 604800 rows. The server has 12 core and 32GB of memory. When the
>model is
>> running, i checked CPU and Memory consumption using 'htop' linux
>command. I
>> observe all the cores are being used and memory memory usage is on
>average
>> 17GB out of 32GB. After running the model for about an hour, the
>system
>> kills the R process. Following the output:
>>
>> *> library("vars")*
>> *> vmodel=VAR(only_variables_without_missing, p = 1, type ="both")*
>> *Killed*
>>
>> Please help.
>>
>>
>>
>> Regards,
>>
>> Vivek Kumar Singh
>>
>> PhD student,
>> Information Systems Decision Sciences,
>> MUMA College of Business,
>> USF
>> Phone- (813) 5809131
>> Web: http://vivek4.myweb.usf.edu/
>>
>> On Tue, May 31, 2016 at 4:41 PM, Uwe Ligges <
>> ligges at statistik.tu-dortmund.de> wrote:
>>
>>> Wild guess: You have huge and high dimensional VAR models, i.e. the
>>> matrices get huge and you use huge amounts of memory and you use
>more than
>>> what is available physically. The operating system protects itself
>by
>>> killing processes in such a case...
>>>
>>> Best,
>>> Uwe Ligges
>>>
>>>
>>>
>>> On 31.05.2016 20:29, Vivek Singh wrote:
>>>
>>>> Hi,
>>>>
>>>> I am using VARS (vector autoregressive model). The process gets
>killed
>>>> after running for sometime. Following is the output of R.
>>>>
>>>> vivek at isds-research:~/cloudAuction/padding/panel$ cat var.Rout
>>>>
>>>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>>>> Copyright (C) 2013 The R Foundation for Statistical Computing
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>>
>>>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>>>> You are welcome to redistribute it under certain conditions.
>>>> Type 'license()' or 'licence()' for distribution details.
>>>>
>>>>   Natural language support but running in an English locale
>>>>
>>>> R is a collaborative project with many contributors.
>>>> Type 'contributors()' for more information and
>>>> 'citation()' on how to cite R or R packages in publications.
>>>>
>>>> Type 'demo()' for some demos, 'help()' for on-line help, or
>>>> 'help.start()' for an HTML browser interface to help.
>>>> Type 'q()' to quit R.
>>>>
>>>> [Previously saved workspace restored]
>>>>
>>>> data=read.csv("output1.csv")
>>>>> attach(data)
>>>>> only_variables= subset(data, select=c(-date,-hour,-minute,-sec))
>>>>>
>>>>> library("vars")
>>>>>
>>>> Loading required package: MASS
>>>> Loading required package: strucchange
>>>> Loading required package: zoo
>>>>
>>>> Attaching package: ?zoo?
>>>>
>>>> The following objects are masked from ?package:base?:
>>>>
>>>>     as.Date, as.Date.numeric
>>>>
>>>> Loading required package: sandwich
>>>> Loading required package: urca
>>>> Loading required package: lmtest
>>>>
>>>>> summary(VAR(only_variables, p = 1, type ="both"))
>>>>>
>>>> *Killed*
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Jun  9 00:39:43 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 9 Jun 2016 08:39:43 +1000
Subject: [R] Tree plot with percentages and hierarchies
In-Reply-To: <CAGxFJbQgftsGwfCqRJ=Y2GAVp1-f09o6K4UVG8VWzFsXpXN4JA@mail.gmail.com>
References: <DB5PR0101MB15899FE67D65276242A79F9AC25E0@DB5PR0101MB1589.eurprd01.prod.exchangelabs.com>
	<CAGxFJbQgftsGwfCqRJ=Y2GAVp1-f09o6K4UVG8VWzFsXpXN4JA@mail.gmail.com>
Message-ID: <CA+8X3fUpOBZsb2FjjcS_1tFT4QoV9vsX5An0gEO421OC+F+MWg@mail.gmail.com>

Hi Joonas,
It is easy to display hierarchic classification using either the
plot.dendrite or sizetree functions (plotrix). At the moment, they
will only display counts, not percentages. It would not be too
difficult to reprogram either one to display percentages. Here are
examples with shortened category names (you'll see why):

Level_0 = c("Action X", "Action X", "Action X", "Action X", "Action
X", "Action X", "Action X", "Action X", "Action X", "Action X",
"Action X", "Action X", "Action X", "Action X", "Action X", "Action
X", "Action X", "Action X", "Action X", "Action X")
Level_1 = c("R1", "R1", "R1", "R1", "R1", "R1", "R1", "R1", "R1",
"R1", "R2", "R2", "R2", "R2", "R2", "R2", "R2", "R2", "R2", "R2")
Level_2 = c("Subr11", "Subr11", "Subr11", "Subr11", "Subr12",
"Subr12", "Subr12", "Subr12", "Subr12", "Subr12", "Subr21", "Subr21",
"Subr21", "Subr21", "Subr21", "Subr21", "Subr21", "Subr21", "Subr22",
"Subr22")
Level_3 = c("Subsubr111", "Subsubr111", "Subsubr111", "Subsubr112",
"Subsubr121", "Subsubr121", "Subsubr121", "Subsubr121", "Subsubr121",
"Subsubr121", "Subsubr221", "Subsubr221", "Subsubr221", "Subsubr221",
"Subsubr221", "Subsubr221", "Subsubr221", "Subsubr221", "Subsubr222",
"Subsubr222")

Levels = data.frame(Level_0 = Level_0, Level_1 = Level_1, Level_2 =
Level_2, Level_3 = Level_3)

library(plotrix)
plot.dendrite(Levels)
sizetree(Levels)

Jim


On Thu, Jun 9, 2016 at 6:03 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I am not really sure what you want, but it sounds like you want the
> "rpart" package (which is part of the standard R distribution).
>
> If that won't do, check the machine learning task view here:
> https://cran.r-project.org/web/views/MachineLearning.html
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Jun 8, 2016 at 11:31 AM, Joonas Isoketo
> <joonas.isoketo at houston-analytics.com> wrote:
>> Hi,
>>
>> I have the following problem:
>>
>> I want to visualize distributions of a few varibles in a specific order with a help of tree figure. Above of all is "Action x" and that happens for two (or n) reasons: "Reason 1" 50 % and "Reason 2" 50 %.
>> Further, "Reason 1" happens for two (or n) subreasons: "Subreason 11" (75 %) and "Subreason 12" (25 %). And further, "Subreason 11" happens for two (or n) subsubreason "SubSubreason 111" etc.
>>
>> Every time when parent node splits to its childs, the sum of child node's percentages should be 100 %.
>>
>> I am very pleaseful if someone could help me with this! If the plot cannot be made "on the fly", also instructions of custom tree helps (hard coded values).
>>
>> Here is the test data:
>>
>> Level_0 = c("Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X")
>> Level_1 = c("Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2")
>> Level_2 = c("Subreason 11", "Subreason 11", "Subreason 11", "Subreason 11", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 22", "Subreason 22")
>> Level_3 = c("Subsubreason 111", "Subsubreason 111", "Subsubreason 111", "Subsubreason 112", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 222", "Subsubreason 222")
>>
>> Levels = data.frame(Level_0 = Level_0, Level_1 = Level_1, Level_2 = Level_2, Level_3 = Level_3)
>>
>>
>>
>> Best regards,
>>
>> Joonas Isoketo
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From awadhwani at hortonworks.com  Thu Jun  9 00:57:47 2016
From: awadhwani at hortonworks.com (Arti Wadhwani)
Date: Wed, 8 Jun 2016 22:57:47 +0000
Subject: [R] R integration with Hive with Kerberos enabled
In-Reply-To: <9EDB3162-7316-4386-A14D-0BDA8A761450@hortonworks.com>
References: <9EDB3162-7316-4386-A14D-0BDA8A761450@hortonworks.com>
Message-ID: <1ADA3AF2-BA5C-4EDE-B0FF-6B75BB10BE86@hortonworks.com>

Does anyone have any insight on this?


Regards,
Arti Wadhwani

From: default <awadhwani at hortonworks.com<mailto:awadhwani at hortonworks.com>>
Date: Thursday, June 2, 2016 at 1:40 PM
To: "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: R integration with Hive with Kerberos enabled

Hi,

I have a question regarding R integration with Hive in kerberized mode. Is it supported? It works fine without kerberos however fails with below error in a kerberized cluster:

java.lang.RuntimeException: org.apache.thrift.transport.TTransportException: Peer indicated failure: GSS initiate failed

Further debugging reveals : The R script uses common packages(rjdbc, rjava) which are not specific to any Hadoop distribution. We need to understand why R script does not read the ticket cache at run time.


Thanks,
Arti Wadhwani
Hortonworks, Inc.
Technical Support Engineer (India)



	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Jun  9 01:13:37 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 9 Jun 2016 09:13:37 +1000
Subject: [R] apply and cousins
In-Reply-To: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>
References: <15ecfa61e76825dde59cb654e7229bad.squirrel@quantex.zedcore.com>
Message-ID: <CA+8X3fUvbU9JuZiyKduW37X9cydEmrkX_FqtYhZ9b5bczivofw@mail.gmail.com>

Hi John,
With due respect to the other respondents, here is something that might help:

# get a vector of values
foo<-rnorm(100)
# get a vector of increasing indices (aka your "recent" values)
bar<-sort(sample(1:100,40))
# write a function to "clump" the adjacent index values
clump_adj_int<-function(x) {
 index_list<-list(x[1])
 list_index<-1
 for(i in 2:length(x)) {
  if(x[i]==x[i-1]+1)
   index_list[[list_index]]<-c(index_list[[list_index]],x[i])
  else {
   list_index<-list_index+1
   index_list[[list_index]]<-x[i]
  }
 }
 return(index_list)
}
index_clumps<-clump_adj_int(bar)
# write another function to sum the values
sum_subsets<-function(indices,vector) return(sum(vector[indices],na.rm=TRUE))
# now "apply" the function to the list of indices
lapply(index_clumps,sum_subsets,foo)

Jim


On Thu, Jun 9, 2016 at 2:41 AM, John Logsdon
<j.logsdon at quantex-research.com> wrote:
> Folks
>
> Is there any way to get the row index into apply as a variable?
>
> I want a function to do some sums on a small subset of some very long
> vectors, rolling through the whole vectors.
>
> apply(X,1,function {do something}, other arguments)
>
> seems to be the way to do it.
>
> The subset I want is the most recent set of measurements only - perhaps a
> couple of hundred out of millions - but I can't see how to index each
> value.  The ultimate output should be a matrix of results the length of
> the input vector.  But to do the sum I need to access the current row
> number.
>
> It is easy in a loop but that will take ages. Is there any vectorised
> apply-like solution to this?
>
> Or does apply etc only operate on each row at a time, independently of
> other rows?
>
>
> Best wishes
>
> John
>
> John Logsdon
> Quantex Research Ltd
> +44 161 445 4951/+44 7717758675
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From david.howell at uvm.edu  Thu Jun  9 01:14:15 2016
From: david.howell at uvm.edu (David Howell)
Date: Wed, 8 Jun 2016 17:14:15 -0600
Subject: [R] Problem loading aplpack library
In-Reply-To: <mailman.9.1465380002.31060.r-help@r-project.org>
References: <mailman.9.1465380002.31060.r-help@r-project.org>
Message-ID: <a41f2b8f-cda6-b856-5a51-565e77d693e1@uvm.edu>

I am having trouble running aplpack on my Mac. It will run on my PC, but 
the Mac gives an error message. Below is the result that I obtained.  It 
seems to install fine--see below--but I can't load the library.


  > install.packages("aplpack")
trying URL 
'http://cran.rstudio.com/bin/macosx/contrib/3.1/aplpack_1.3.0.tgz'
Content type 'application/x-gzip' length 3157548 bytes (3.0 Mb)
opened URL
==================================================
downloaded 3.0 Mb


The downloaded binary packages are in
/var/folders/6m/t4wvnh9x39500z_rh3p5jlk00000gp/T//Rtmp26I5Ej/downloaded_packages

  > library(aplpack)
Loading required package: tcltk
xcrun: error: invalid active developer path 
(/Library/Developer/CommandLineTools), missing xcrun at: 
/Library/Developer/CommandLineTools/usr/bin/xcrun

It looks as if it has a problem with tcltk. I can install tcltk2, but 
when I try to install tcltk it tells me "package not found. Is that the 
problem that aplpack is having when it tries to load the library?

Any suggestions?


From dmck at u.washington.edu  Wed Jun  8 22:09:32 2016
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 8 Jun 2016 13:09:32 -0700
Subject: [R] Tree plot with percentages and hierarchies
In-Reply-To: <CAGxFJbQgftsGwfCqRJ=Y2GAVp1-f09o6K4UVG8VWzFsXpXN4JA@mail.gmail.com>
References: <DB5PR0101MB15899FE67D65276242A79F9AC25E0@DB5PR0101MB1589.eurprd01.prod.exchangelabs.com>
	<CAGxFJbQgftsGwfCqRJ=Y2GAVp1-f09o6K4UVG8VWzFsXpXN4JA@mail.gmail.com>
Message-ID: <AC1E9209-C144-4B07-ACFC-04F541C219DE@u.washington.edu>


> On Jun 8, 2016, at 1:03 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I am not really sure what you want, but it sounds like you want the
> "rpart" package (which is part of the standard R distribution).

I?m not sure either, but do you want to fit a model (in which case Bert?s suggestion of ?rpart? is on target), or just visualize an existing tree structure?  In the latter case presentation software
may be the best option.

> 
> If that won't do, check the machine learning task view here:
> https://cran.r-project.org/web/views/MachineLearning.html
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Jun 8, 2016 at 11:31 AM, Joonas Isoketo
> <joonas.isoketo at houston-analytics.com> wrote:
>> Hi,
>> 
>> I have the following problem:
>> 
>> I want to visualize distributions of a few varibles in a specific order with a help of tree figure. Above of all is "Action x" and that happens for two (or n) reasons: "Reason 1" 50 % and "Reason 2" 50 %.
>> Further, "Reason 1" happens for two (or n) subreasons: "Subreason 11" (75 %) and "Subreason 12" (25 %). And further, "Subreason 11" happens for two (or n) subsubreason "SubSubreason 111" etc.
>> 
>> Every time when parent node splits to its childs, the sum of child node's percentages should be 100 %.
>> 
>> I am very pleaseful if someone could help me with this! If the plot cannot be made "on the fly", also instructions of custom tree helps (hard coded values).
>> 
>> Here is the test data:
>> 
>> Level_0 = c("Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X")
>> Level_1 = c("Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2")
>> Level_2 = c("Subreason 11", "Subreason 11", "Subreason 11", "Subreason 11", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 22", "Subreason 22")
>> Level_3 = c("Subsubreason 111", "Subsubreason 111", "Subsubreason 111", "Subsubreason 112", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", "Subsubreason 222", "Subsubreason 222")
>> 
>> Levels = data.frame(Level_0 = Level_0, Level_1 = Level_1, Level_2 = Level_2, Level_3 = Level_3)
>> 
>> 
>> 
>> Best regards,
>> 
>> Joonas Isoketo
>> 
>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




From david.howell at uvm.edu  Thu Jun  9 01:09:30 2016
From: david.howell at uvm.edu (David Howell)
Date: Wed, 8 Jun 2016 17:09:30 -0600
Subject: [R] R-help Digest, Vol 160, Issue 8
In-Reply-To: <mailman.9.1465380002.31060.r-help@r-project.org>
References: <mailman.9.1465380002.31060.r-help@r-project.org>
Message-ID: <defa7eca-563f-c397-04a1-955b9aa0c0d3@uvm.edu>

I am having trouble running aplpack on my Mac. It will run on my PC, but 
the Mac gives an error message. Below is the result that I obtained.  It 
seems to install fine--see below--but I can't load the library.


 > install.packages("aplpack")
trying URL 
'http://cran.rstudio.com/bin/macosx/contrib/3.1/aplpack_1.3.0.tgz'
Content type 'application/x-gzip' length 3157548 bytes (3.0 Mb)
opened URL
==================================================
downloaded 3.0 Mb


The downloaded binary packages are in
/var/folders/6m/t4wvnh9x39500z_rh3p5jlk00000gp/T//Rtmp26I5Ej/downloaded_packages

 > library(aplpack)
Loading required package: tcltk
xcrun: error: invalid active developer path 
(/Library/Developer/CommandLineTools), missing xcrun at: 
/Library/Developer/CommandLineTools/usr/bin/xcrun

It looks as if it has a problem with tcltk. I can install tcltk2, but 
when I try to install tcltk it tells me "package not found.) Is that the 
problem that aplpack is having when it tries to load the library?

Any suggestions?


From paolo.letizia at gmail.com  Thu Jun  9 02:40:10 2016
From: paolo.letizia at gmail.com (Paolo Letizia)
Date: Wed, 8 Jun 2016 20:40:10 -0400
Subject: [R] Importing data from a text file with no separator
Message-ID: <CAOgs+Ox82v_cJQC-JNzaqjjuRfR7==62pQ4+ca+=_9OBMsCE0Q@mail.gmail.com>

I have row data in a text file, where each row consists of 22 numerical
characters. Each row consists of three different column but there is no
separator. Specifically, the first two characters of the raw represent  the
first column of data, the subsequent 8 characters represent the second
column of data and the last 12 characters represent the third column of
data. An example follows:

row data:
1003061490000000011608

The first two characters, "10", is the column "Regime"; the subsequent 8
characters, "03061490", is the column "Industry", and the last 12
characters, "000000011608", is the column dollar value. How do I import the
column data into R without having any separator in the text file?
Thanks for your help, Paolo.

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Thu Jun  9 06:53:43 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Thu, 9 Jun 2016 07:53:43 +0300
Subject: [R] Importing data from a text file with no separator
In-Reply-To: <CAOgs+Ox82v_cJQC-JNzaqjjuRfR7==62pQ4+ca+=_9OBMsCE0Q@mail.gmail.com>
References: <CAOgs+Ox82v_cJQC-JNzaqjjuRfR7==62pQ4+ca+=_9OBMsCE0Q@mail.gmail.com>
Message-ID: <CAJ=0CtCqc=XMum4iO9WEyk0sAXZHdXnGos6fUvME4nt8CssANw@mail.gmail.com>

See:
?read.fwf

Example:
> ff <- tempfile()
> cat(file = ff, "1003061490000000011608", "1003061490000000011608", sep =
"\n")

> read.fwf(ff, widths = c(2,8,10), colClasses = "character")
  V1       V2         V3
1 10 03061490 0000000116
2 10 03061490 0000000116

> unlink(ff)

Hth,
Adrian


On Thu, Jun 9, 2016 at 3:40 AM, Paolo Letizia <paolo.letizia at gmail.com>
wrote:

> I have row data in a text file, where each row consists of 22 numerical
> characters. Each row consists of three different column but there is no
> separator. Specifically, the first two characters of the raw represent  the
> first column of data, the subsequent 8 characters represent the second
> column of data and the last 12 characters represent the third column of
> data. An example follows:
>
> row data:
> 1003061490000000011608
>
> The first two characters, "10", is the column "Regime"; the subsequent 8
> characters, "03061490", is the column "Industry", and the last 12
> characters, "000000011608", is the column dollar value. How do I import the
> column data into R without having any separator in the text file?
> Thanks for your help, Paolo.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From joonas.isoketo at houston-analytics.com  Thu Jun  9 07:39:21 2016
From: joonas.isoketo at houston-analytics.com (Joonas Isoketo)
Date: Thu, 9 Jun 2016 05:39:21 +0000
Subject: [R] Tree plot with percentages and hierarchies
In-Reply-To: <CA+8X3fUpOBZsb2FjjcS_1tFT4QoV9vsX5An0gEO421OC+F+MWg@mail.gmail.com>
References: <DB5PR0101MB15899FE67D65276242A79F9AC25E0@DB5PR0101MB1589.eurprd01.prod.exchangelabs.com>
	<CAGxFJbQgftsGwfCqRJ=Y2GAVp1-f09o6K4UVG8VWzFsXpXN4JA@mail.gmail.com>
	<CA+8X3fUpOBZsb2FjjcS_1tFT4QoV9vsX5An0gEO421OC+F+MWg@mail.gmail.com>
Message-ID: <DB5PR0101MB15896EBC098E1D7D689220EEC25F0@DB5PR0101MB1589.eurprd01.prod.exchangelabs.com>

Hi,

super, that was exactly what I needed! Thanks!

Best regards,

Joonas Isoketo 



-----Alkuper?inen viesti-----
L?hett?j?: Jim Lemon [mailto:drjimlemon at gmail.com] 
L?hetetty: 9. kes?kuutata 2016 1:40
Kopio: Joonas Isoketo <joonas.isoketo at houston-analytics.com>; r-help at r-project.org
Aihe: Re: [R] Tree plot with percentages and hierarchies

Hi Joonas,
It is easy to display hierarchic classification using either the plot.dendrite or sizetree functions (plotrix). At the moment, they will only display counts, not percentages. It would not be too difficult to reprogram either one to display percentages. Here are examples with shortened category names (you'll see why):

Level_0 = c("Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X", "Action X")
Level_1 = c("R1", "R1", "R1", "R1", "R1", "R1", "R1", "R1", "R1", "R1", "R2", "R2", "R2", "R2", "R2", "R2", "R2", "R2", "R2", "R2")
Level_2 = c("Subr11", "Subr11", "Subr11", "Subr11", "Subr12", "Subr12", "Subr12", "Subr12", "Subr12", "Subr12", "Subr21", "Subr21", "Subr21", "Subr21", "Subr21", "Subr21", "Subr21", "Subr21", "Subr22",
"Subr22")
Level_3 = c("Subsubr111", "Subsubr111", "Subsubr111", "Subsubr112", "Subsubr121", "Subsubr121", "Subsubr121", "Subsubr121", "Subsubr121", "Subsubr121", "Subsubr221", "Subsubr221", "Subsubr221", "Subsubr221", "Subsubr221", "Subsubr221", "Subsubr221", "Subsubr221", "Subsubr222",
"Subsubr222")

Levels = data.frame(Level_0 = Level_0, Level_1 = Level_1, Level_2 = Level_2, Level_3 = Level_3)

library(plotrix)
plot.dendrite(Levels)
sizetree(Levels)

Jim


On Thu, Jun 9, 2016 at 6:03 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I am not really sure what you want, but it sounds like you want the 
> "rpart" package (which is part of the standard R distribution).
>
> If that won't do, check the machine learning task view here:
> https://cran.r-project.org/web/views/MachineLearning.html
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Jun 8, 2016 at 11:31 AM, Joonas Isoketo 
> <joonas.isoketo at houston-analytics.com> wrote:
>> Hi,
>>
>> I have the following problem:
>>
>> I want to visualize distributions of a few varibles in a specific order with a help of tree figure. Above of all is "Action x" and that happens for two (or n) reasons: "Reason 1" 50 % and "Reason 2" 50 %.
>> Further, "Reason 1" happens for two (or n) subreasons: "Subreason 11" (75 %) and "Subreason 12" (25 %). And further, "Subreason 11" happens for two (or n) subsubreason "SubSubreason 111" etc.
>>
>> Every time when parent node splits to its childs, the sum of child node's percentages should be 100 %.
>>
>> I am very pleaseful if someone could help me with this! If the plot cannot be made "on the fly", also instructions of custom tree helps (hard coded values).
>>
>> Here is the test data:
>>
>> Level_0 = c("Action X", "Action X", "Action X", "Action X", "Action 
>> X", "Action X", "Action X", "Action X", "Action X", "Action X", 
>> "Action X", "Action X", "Action X", "Action X", "Action X", "Action 
>> X", "Action X", "Action X", "Action X", "Action X")
>> Level_1 = c("Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 
>> 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", "Reason 1", 
>> "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2", "Reason 
>> 2", "Reason 2", "Reason 2", "Reason 2", "Reason 2")
>> Level_2 = c("Subreason 11", "Subreason 11", "Subreason 11", 
>> "Subreason 11", "Subreason 12", "Subreason 12", "Subreason 12", 
>> "Subreason 12", "Subreason 12", "Subreason 12", "Subreason 21", 
>> "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 21", 
>> "Subreason 21", "Subreason 21", "Subreason 21", "Subreason 22", 
>> "Subreason 22")
>> Level_3 = c("Subsubreason 111", "Subsubreason 111", "Subsubreason 
>> 111", "Subsubreason 112", "Subsubreason 121", "Subsubreason 121", 
>> "Subsubreason 121", "Subsubreason 121", "Subsubreason 121", 
>> "Subsubreason 121", "Subsubreason 221", "Subsubreason 221", 
>> "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", 
>> "Subsubreason 221", "Subsubreason 221", "Subsubreason 221", 
>> "Subsubreason 222", "Subsubreason 222")
>>
>> Levels = data.frame(Level_0 = Level_0, Level_1 = Level_1, Level_2 = 
>> Level_2, Level_3 = Level_3)
>>
>>
>>
>> Best regards,
>>
>> Joonas Isoketo
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From sethshashi at rediffmail.com  Thu Jun  9 08:52:57 2016
From: sethshashi at rediffmail.com (SHASHI SETH)
Date: 9 Jun 2016 06:52:57 -0000
Subject: [R] =?utf-8?q?Error=3A___missing_value_where_TRUE/FALSE_needed?=
Message-ID: <20160609065257.31548.qmail@f5mail-224-118.rediffmail.com>

Hi, 



I am getting the following error:

Error in if ((sum > 0 && sums1 > 0 && sums2 > 0) != NA) { : 

missing value where TRUE/FALSE needed





I have including my code below for your review:



fitness_1_data 
	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu Jun  9 09:16:59 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 09 Jun 2016 07:16:59 +0000
Subject: [R] Error: missing value where TRUE/FALSE needed
In-Reply-To: <20160609065257.31548.qmail@f5mail-224-118.rediffmail.com>
References: <20160609065257.31548.qmail@f5mail-224-118.rediffmail.com>
Message-ID: <CAKVAULOSLvfurQ5xKO8RE=SWf1FzSe9H4FFGA7_uqGSz-rn3Yw@mail.gmail.com>

Dear Shashi,

I don't see any code, but I will take a guess anyway:

The error tells you that you try to compare a boolean with something that
is not (TRUE or FALSE cannot be compared to NA).

HTH
Ulrik

On Thu, 9 Jun 2016 at 08:55 SHASHI SETH <sethshashi at rediffmail.com> wrote:

> Hi,
>
>
>
> I am getting the following error:
>
> Error in if ((sum > 0 && sums1 > 0 && sums2 > 0) != NA) { :
>
> missing value where TRUE/FALSE needed
>
>
>
>
>
> I have including my code below for your review:
>
>
>
> fitness_1_data
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Jun  9 09:47:38 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 9 Jun 2016 07:47:38 +0000
Subject: [R] Antwort: RE:  Antwort: Re:  Merging variables
In-Reply-To: <OF5A118756.13A96171-ONC1257FCC.004BF927-C1257FCC.004C84D8@lotus.hawesko.de>
References: <OF94473979.6E2A2401-ONC1257FCA.003D0AAB-C1257FCA.0044A097@lotus.hawesko.de>
	<08b28d87-7851-0854-5a7a-7f3082772db2@dewey.myzen.co.uk>
	<OF7CB676EC.936B8ED0-ONC1257FCB.00228C15-C1257FCB.0022AF89@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C502F332@SRVEXCHMBX.precheza.cz>
	<OF5A118756.13A96171-ONC1257FCC.004BF927-C1257FCC.004C84D8@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502FBCE@SRVEXCHMBX.precheza.cz>

Hi

Thanks for example.

see in line


> -----Original Message-----
> From: G.Maubach at weinwolf.de [mailto:G.Maubach at weinwolf.de]
> Sent: Wednesday, June 8, 2016 3:56 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: Antwort: RE: [R] Antwort: Re: Merging variables
>
> Hi Petr,
>
> thanks for your reply.
>
> I prepared little example for you:
>
> -- cut --
>
> ds_temp_1 <-
>   structure(list(
>     CustId = c(1001, 1002, 1003, 1004, 1005, 1006),
>     CustName = c("Miller", "Smith", "Doe", "White", "Black",
>                  "Nobody"),
>     sales = c(100, 500, 300, 50, 700, 10)
>   ),
>   .Names = c("CustId",
>              "CustName", "sales"), row.names = c(NA, 6L), class =
> "data.frame")
>
> ds_temp_2 <-
>   structure(
>     list(
>       CustId = c(1001, 1002, 1003),
>       CustName = c("Miller",
>                    "Smith", "Doe"),
>       CustGroup = c(1, 2, 3)
>     ),
>     .Names = c("CustId",
>                "CustName", "CustGroup"),
>     row.names = c(NA, 3L),
>     class = "data.frame"
>   )
>
> ds_merge <- merge(ds_temp_1, ds_temp_2,
>                   by.x = "CustId", all.x = TRUE,
>                   by.y = "CustId", all.y = FALSE)
>
> ds_merge
>
> -- cut --
>
> which gives
>
> ds_merge
>   CustId CustName.x sales CustName.y CustGroup
> 1   1001     Miller   100     Miller         1
> 2   1002      Smith   500      Smith         2
> 3   1003        Doe   300        Doe         3
> 4   1004      White    50       <NA>        NA
> 5   1005      Black   700       <NA>        NA
> 6   1006     Nobody    10       <NA>        NA
>
> where CustName is split into CustName.x and CustName.y.
>
> What I would like to have is:
>
> ds_merge
>   CustId CustName   sales  CustGroup
> 1   1001     Miller   100          1
> 2   1002      Smith   500          2
> 3   1003        Doe   300          3
> 4   1004      White    50         NA
> 5   1005      Black   700         NA
> 6   1006     Nobody    10         NA
>
> That is CustName in a single variable cause the values within that variable are
> identical. I guess because of NA for some cases in ds_temp_2 R generates
> CustName.x and CustName.y.

Do not guess, try or read help page. The behavior is due to fact that ***you** restricted merge only on cust id and resulting data frame cannot have columns with the same names.

ds_merge <- merge(ds_temp_1, ds_temp_2, all.x = TRUE, all.y = FALSE)

Regards
Petr

>
> Is there a simple way of merging a dataset and having R return a single
> variable is the values are identical or missing in either one of the datasets?
>
> Kind regards
>
> Georg
>
>
>
>
>
> Von:    PIKAL Petr <petr.pikal at precheza.cz>
> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
> Datum:  07.06.2016 13:11
> Betreff:        RE: [R] Antwort: Re:  Merging variables
>
>
>
> Hi
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > G.Maubach at weinwolf.de
> > Sent: Tuesday, June 7, 2016 8:19 AM
> > To: Michael Dewey <lists at dewey.myzen.co.uk>
> > Cc: r-help at r-project.org
> > Subject: [R] Antwort: Re: Merging variables
> >
> > Hi Michael,
> >
> > yes, I was astonished about this behaviour either. I have worked with
> SPSS a
> > lot - and that works different.
>
> If you want to join two data frames by common names you can use use
>
> merge(dat1, dat2, ....)
>
> without specifing by. From help page:
>
> By default the data frames are merged on the columns with names they both
> have, but separate specifications of the columns can be given by by.x and
> by.y. The rows in the two data frames that match on the specified columns
> are extracted, and joined together.
>
> >
> > I would like to share some of my data. Can you tell me how I can dump
> > a dataset in a way that I can post it here as text?
>
> copy result of dput directly to your mail
>
> dput(dat)
> structure(list(hz = c(0, 25, 50), vykon = c(0, 11.6, 22.6)), .Names = c("hz",
> "vykon"), row.names = c(NA, -3L), class = "data.frame")
>
> We can use
>
> dat <- structure(list(hz = c(0, 25, 50), vykon = c(0, 11.6, 22.6)), .Names =
> c("hz", "vykon"), row.names = c(NA, -3L), class = "data.frame")
>
> to reconstruct the object.
>
> Regards
> Petr
>
> >
> > Kind regards
> >
> > Georg
> >
> >
> >
> >
> > Von:    Michael Dewey <lists at dewey.myzen.co.uk>
> > An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> > Datum:  06.06.2016 15:45
> > Betreff:        Re: [R] Merging variables
> >
> >
> >
> > X-Originating-<%= hostname %>-IP: [217.155.205.190]
> >
> > Dear Georg
> >
> > I find it a bit surprising that you end up with customer.x and
> customer.y. Can
> > you share with us a toy example of two data.frames which exhibit this
> > behaviour?
> >
> > On 06/06/2016 13:29, G.Maubach at weinwolf.de wrote:
> > > Hi All,
> > >
> > > I merged two datasets:
> > >
> > > ds_merge1 <- merge(x = ds_bw_customer_4_match, y =
> > > ds_zww_customer_4_match,
> > >   by.x = "customer", by.y = "customer",
> > >   all.x = TRUE, all.y = FALSE)
> > >
> > > R created a new dataset with the variables customer.x and customer.y.
> > > I would like to merge these two variable back together. I wrote a
> > > little function (code can be run) for it:
> > >
> > > -- cut --
> > >
> > > customer.x <- c("Miller", "Smith", NA,    "Bird", NA)
> > > customer.y <- c("Miller",  NA,     "Doe", "Fish", NA)
> > > ds_test <- data.frame(customer.x, customer.y, stringsAsFactors =
> > > FALSE)
> > >
> > > t_merge_variables <-
> > >   function(dataset,
> > >            var1,
> > >            var2,
> > >            merged_var) {
> > >
> > >     # Initialize
> > >     dataset[[merged_var]] = rep(NA, nrow(dataset))
> > >     dataset[["mismatch"]] = rep(NA, nrow(dataset))
> > >
> > >     for (i in 1:nrow(dataset)) {
> > >
> > >       # Check 1: var1 missing, var2 missing
> > >       if (is.na(dataset[[i, var1]]) &
> > >           is.na(dataset[[i, var2]])) {
> > >         dataset[["mismatch"]] <- 1  # var1 & var2 are missing
> > >
> > >       # Check 2: var1 filled, var2 missing
> > >       } else if (!is.na(dataset[[i, var1]]) &
> > >                  is.na(dataset[[i, var2]])) {
> > >         dataset[[i, merged_var]] <- dataset[[i, var1]]
> > >         dataset[["mismatch"]] <- 0
> > >
> > >       # Check 3: var1 missing, var2 filled
> > >       } else if (is.na(dataset[[i, var1]]) &
> > >                  !is.na(dataset[i, var2])) {
> > >         dataset[[i, merged_var]] <- dataset[[i, var2]]
> > >         dataset[["mismatch"]] <-  0
> > >
> > >       # Check 4: var1 == var2
> > >       } else if (dataset[[i, var1]] == dataset[[i, var2]]) {
> > >       dataset[[i, merged_var]] <- dataset[[i, var1]]
> > >       dataset[["mismatch"]] <- 0
> > >
> > >       # Leftover: var1 != var2
> > >       } else {
> > >         dataset[[i, merged_var]] <- NA
> > >         dataset[["mismatch"]] <- 2  # var1 != var2
> > >       }  # end if
> > >     }  # end for
> > >     return(dataset)
> > > }
> > >
> > > ds_var_merge1 <- t_merge_variables(dataset = ds_test,
> > >   var1 = "customer.x",
> > >   var2 = "customer.y",
> > >   merged_var = "customer")
> > >
> > > ds_var_merge1
> > >
> > > -- cut --
> > >
> > > It is executed without error but delivers the wrong values in the
> > variable
> > > "mismatch". This variable is always 1 although it should be NA, 1 or
> > > 2 respectively.
> > >
> > > Can you tell me why the variable is not correctly set?
> > >
> > > Kind regards
> > >
> > > Georg
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen?
> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze
> sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a
> to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost
> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender.
> Delete the contents of this e-mail with all attachments and its copies from
> your system.
> If you are not the intended recipient of this e-mail, you are not authorized to
> use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance
> of the offer on the part of the recipient containing any amendment or
> variation.
> - the sender insists on that the respective contract is concluded only upon an
> express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into
> any contracts on behalf of the company except for cases in which he/she is
> expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of
> the person represented by the recipient.
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From friendly at yorku.ca  Wed Jun  8 16:58:49 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 8 Jun 2016 10:58:49 -0400
Subject: [R] [R-pkgs] New versions of heplots, candisc,
	mvinfluence and matlib on CRAN
Message-ID: <055c2148-f8ba-f4ba-4dbc-85c7e38bc49c@yorku.ca>

# New versions of heplots, candisc, mvinfluence and matlib on CRAN
# ----------------------------------------------------------------

New versions of my packages designed for visualization of multivariate
linear models have recently been submitted to CRAN. The matlib package
also contains some plot methods for vector diagrams representing linear
algebra concepts in multivariate statistical methods.

## heplots
## -------

Devel URL: https://r-forge.r-project.org/projects/heplots/
Issue tracker: https://r-forge.r-project.org/tracker/?group_id=24

Provides HE plot and other functions for visualizing hypothesis
tests in multivariate linear models. HE plots represent sums-of-squares-and-
products matrices for linear hypotheses and for error using ellipses (in two
dimensions) and ellipsoids (in three dimensions).

Version 1.3-0 (2016-06-03)

o In cqplot(), pch, col, and cex can now be vectors
o Bump version, prepare for release

Version 1.2-1 (2016-05-19)

o in coefplot.mlm(), now pass `label.pos` to label.ellipse()
o added Mahalanobis() for classical and robust squared distances; handles
   missing data gracefully and provides a confidence envelope
o added SocialCog data [Thx: Leah Hartman]
o added cqplot() of Mahalanobis distances as a plot method for an mlm 
and for multivariate data

Version 1.2-0 (2016-04-27)

o covEllipses() extended to more than two variables, giving a 
scatterplot matrix plot
o plot.boxM() now can plot other measures of the eigenvalues of the 
covariance matrices,
   useful for understanding the properties of the test.
o added bartlettTests() for a collection of univariate Bartlett tests
o added leveneTests() for a collection of univariate Levene tests
o added NeuroCog data, a simple one-way MANOVA [Thx: Leah Hartman]
o label.ellipse() now uses a much more flexible `label.pos` argument for 
positioning the
   text labels used in heplot() and friends.

## candisc
## -------

Devel URL: https://r-forge.r-project.org/projects/candisc/

Functions for computing and visualizing generalized canonical discriminant
analyses and canonical correlation analysis for a multivariate linear model.
Traditional canonical discriminant analysis is restricted to a one-way 
'MANOVA'
design and is equivalent to canonical correlation analysis between a set of
quantitative response variables and a set of dummy variables coded from the
factor variable. The 'candisc' package generalizes this to higher-way 
'MANOVA'
designs for all factors in a multivariate linear model, computing canonical
scores and vectors for each term. The graphic functions provide low-rank 
(1D,
2D, 3D) visualizations of terms in an 'mlm' via the 'plot.candisc' and
'heplot.candisc' methods. Related plots are now provided for canonical
correlation analysis when all predictors are quantitative.

Changes in version 0.7-1 (2016-05-23)

   o respect var.lwd in 2D plot.candisc()
   o heplot.candisc() gets a rev.axes argument to reverse the axes and a 
var.pos
     argument to position  variable labels
   o vectors() now produces nicer arrow head a la matlib::vectors()
   o added var.pos argument to plot.candisc
   o allow to suppress likelihood ratio tests in print.candisc

Changes in version 0.7-0 (2016-04-25)

   o Added Wine data -- three cultivars with a very simple canonical 
structure
   o Added ellipses to plot.candisc(); enhanced candisc.Rd documentation
   o Added varOrder() for effect ordering in MLMs-- permutations of 
variables
     according to various criteria for scatterplot matrices, etc.
   o plot.candisc() gets a var.labels argument
   o added method="colmean" and descending=T/F to varOrder()
   o plot.candisc() gets a rev.axes argument
   o fixed imports() in NAMESPACE for CRAN checks


## mvinfluence
## -----------

Devel URL: https://r-forge.r-project.org/projects/mvinfluence/

Computes regression deletion diagnostics for multivariate linear models and
provides some associated diagnostic plots. The diagnostic measures 
include hat-
values (leverages), generalized Cook's distance, and generalized squared
'studentized' residuals. Several types of plots to detect influential
observations are provided.

Version 0.8 (2016-06-02)

o Fixed problems for CRAN: NAMESPACE, Rd files
o Added more examples to Rd files
o Added infIndexPlot for index plots of diagnostic measures
o Fixed buglet in influencePlot re: rownames of result

## matlib
## ------

Devel URL: https://github.com/friendly/matlib
Issue tracker: https://github.com/friendly/matlib/issues

A collection of matrix functions for teaching and learning matrix
linear algebra as used in multivariate statistical methods. These 
functions are
mainly for tutorial purposes in learning matrix algebra ideas using R. 
In some
cases, functions are provided for concepts available elsewhere in R, but 
where
the function call or name is not obvious. In other cases, functions are 
provided
to show or demonstrate an algorithm. In addition, a collection of 
functions are
provided for drawing vector diagrams in 2D and 3D, e.g., regvec() and 
regvec2d()
for vector diagrams for the vector space representation of a 
two-variable regression
model, plotEqn() and plotEqn3d() for diagrams of linear equations of the 
form
A x = b.

matlib 0.7.3

- Changed gaussianElimination() by defining local ERO functions to make 
the algorithm clearer;
   in verbose mode, show each ERO.
- Added a draw argument to `vectors3d()` and `arrows3d()`, which 
defaults to TRUE.
   If FALSE, just returns returns the "reg.length" to help in scaling.
- Small cosmetic changes to regvec3d().
- Added a `showEig` function to draw eigenvectors superimposed on a 
dataEllipse [MF]

matlib 0.7.2

   - added argument `error.sphere` to `plot.regvec3d()` [JF]
   - remove use of `lengths()` in `corner()` to avoid R version dependency



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From Keith.Jewell at campdenbri.co.uk  Thu Jun  9 10:57:45 2016
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Thu, 9 Jun 2016 09:57:45 +0100
Subject: [R] expand.model.frame issue
Message-ID: <njbb29$irq$1@ger.gmane.org>

Following on from a stackoverflow question "Why does this simple 
function calling `lm(..., subset)` fail?"
<http://stackoverflow.com/questions/37326815>
----------
myfun <- function(form., data., subs.) lm(form., data., subs.)
myfun(mpg ~ cyl + hp, mtcars, TRUE)
## Error in eval(expr, envir, enclos) : object 'subs.' not found
---------

The answer to the stated question was in ?lm "If not found in data, the 
variables are taken from environment(formula), typically the environment 
from which lm is called"; the environment of the formula (mpg ~ cyl + 
hp) does not contain 'subs.'. A fix is quite straightforward, set the 
environment of the formula to that of the function, which does contain 
'subs.'. There are multiple ways of doing that, this works but to me 
seems a bit "clunky":
---------------
myfun <- function(form., data., subs.) lm(as.formula(deparse(form.)), 
data., subs.)
myfun(mpg ~ cyl + hp, mtcars, TRUE)
--------------
To me this seems more elegant, but then I have no taste :-}
----------
myfun <- function(form., data., subs.){
   environment(form.) <- environment()
   lm(form., data., subs.)}
myfun(mpg ~ cyl + hp, mtcars, TRUE)
----------

But the OP went on to consider `expand.model.frame` e.g.
-------------
myfun <- function(form., data., subs.){
   environment(form.) <- environment()
   model <- lm(form., data., subs.)
   print(ls(envir = environment(formula(model))))
   expand.model.frame(model, ~drat)}
myfun(mpg ~ cyl + hp, mtcars, TRUE)
## [1] "data." "form." "model" "subs."
## Error in eval(expr, envir, enclos) : object 'subs.' not found
-------------

myfun can be fixed by (e.g.) avoiding the subset argument of lm
------------
myfun <- function(form., data., subs.){
   environment(form.) <- environment()
   model <- lm(form., data.[subs.,])
   expand.model.frame(model, ~drat)}
myfun(mpg ~ cyl + hp, mtcars, TRUE)
------------
... but this message is about the apparent inconsistency between the 
behaviour of expand.model.frame and the help text which says:
?expand.model.frame:
-----------------------
Usage

expand.model.frame(model, extras,
                    envir = environment(formula(model)),
                    na.expand = FALSE)
<snip>
envir	an environment to evaluate things in
---------------------

In the example of the `expand.model.frame` issue above the result of the 
'ls()' clearly shows that 'subs.' is in that environment, but 
expand.model.frame fails to find it.

Am I misunderstanding?
Or is there an error in the help text?
Or is there a bug in expand.model.frame?

=====================
I don't think this is relevant, but for completeness
 > sessionInfo()
R version 3.3.0 (2016-05-03)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows Server 2008 R2 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United 
Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C 

[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] graphics  grDevices datasets  stats     tcltk     utils     tools 
   methods   base

other attached packages:
  [1] CBRIutils_1.0   stringr_1.0.0   svSocket_0.9-57 TinnR_1.0-5 
R2HTML_2.3.1    Hmisc_3.17-4    ggplot2_2.1.0
  [8] Formula_1.2-1   survival_2.39-4 lattice_0.20-33

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.5         magrittr_1.5        cluster_2.0.4 
splines_3.3.0       devtools_1.11.1
  [6] munsell_0.4.3       colorspace_1.2-6    plyr_1.8.3 
nnet_7.3-12         grid_3.3.0
[11] data.table_1.9.6    gtable_0.2.0        latticeExtra_0.6-28 
withr_1.0.1         svMisc_0.9-70
[16] digest_0.6.9        Matrix_1.2-6        gridExtra_2.2.1 
RColorBrewer_1.1-2  acepack_1.3-3.3
[21] rpart_4.1-10        memoise_1.0.0       stringi_1.1.1 
scales_0.4.0        foreign_0.8-66
[26] chron_2.3-47


From stefano.sofia at regione.marche.it  Thu Jun  9 12:22:55 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 9 Jun 2016 10:22:55 +0000
Subject: [R] create an empty data frame and then fill in it
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBB74BA@ESINO.regionemarche.intra>

Dear R list users,
sorry for this simple question, but I already spent many efforts to solve it.

I create an empty data frame called df_year like

df_year <- data.frame(day=as.Date(character()), hs_MteBove=integer(), hs_MtePrata=integer(), hs_Pintura=integer(), hs_Pizzo=integer(), hs_Sassotetto=integer(), hs_Sibilla=integer(), stringsAsFactors=FALSE)

and then I start to fill in it with

df_year$day <- seq(as.Date("2004-11-01-00-00","%Y-%m-%d"), as.Date("2005-05-01-00-00","%Y-%m-%d"), by="day")

but I get the following error:
"replacement has 182 rows, data has 0"

Where is my silly mistake?

Thank you for your help
Stefano


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Jun  9 12:36:11 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 9 Jun 2016 06:36:11 -0400
Subject: [R] create an empty data frame and then fill in it
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBB74BA@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBB74BA@ESINO.regionemarche.intra>
Message-ID: <fcc2e0a0-ce0a-5e79-dcc8-fde40d39b24f@gmail.com>

On 09/06/2016 6:22 AM, Stefano Sofia wrote:
> Dear R list users,
> sorry for this simple question, but I already spent many efforts to solve it.
>
> I create an empty data frame called df_year like
>
> df_year <- data.frame(day=as.Date(character()), hs_MteBove=integer(), hs_MtePrata=integer(), hs_Pintura=integer(), hs_Pizzo=integer(), hs_Sassotetto=integer(), hs_Sibilla=integer(), stringsAsFactors=FALSE)
>
> and then I start to fill in it with
>
> df_year$day <- seq(as.Date("2004-11-01-00-00","%Y-%m-%d"), as.Date("2005-05-01-00-00","%Y-%m-%d"), by="day")
>
> but I get the following error:
> "replacement has 182 rows, data has 0"
>
> Where is my silly mistake?

Your dataframe has 0 rows, so you can't put a 182 row vector into the 
first column.

Unlike vectors, dataframes won't grow if you make assignments beyond the 
end of the rows.

There are at least a couple of solutions:

1.  Don't create columns until you have data ready for them.

You can wait to create the dataframe until your "day" column is ready:

df_year <- data.frame(day = seq(...))

As you compute other columns of the same length, you can add them, e.g.

df_year$hs_MteBove <- ...

2.  Create your columns with the right length from the beginning:

df_year <- data.frame(day = rep(as.Date(NA), 182), ...)

I don't like this solution as much.

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu Jun  9 12:36:18 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 9 Jun 2016 06:36:18 -0400
Subject: [R] create an empty data frame and then fill in it
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBB74BA@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBB74BA@ESINO.regionemarche.intra>
Message-ID: <adf330db-5413-dd5b-f43c-44492ffa4ca9@gmail.com>

On 09/06/2016 6:22 AM, Stefano Sofia wrote:
> Dear R list users,
> sorry for this simple question, but I already spent many efforts to solve it.
>
> I create an empty data frame called df_year like
>
> df_year <- data.frame(day=as.Date(character()), hs_MteBove=integer(), hs_MtePrata=integer(), hs_Pintura=integer(), hs_Pizzo=integer(), hs_Sassotetto=integer(), hs_Sibilla=integer(), stringsAsFactors=FALSE)
>
> and then I start to fill in it with
>
> df_year$day <- seq(as.Date("2004-11-01-00-00","%Y-%m-%d"), as.Date("2005-05-01-00-00","%Y-%m-%d"), by="day")
>
> but I get the following error:
> "replacement has 182 rows, data has 0"
>
> Where is my silly mistake?

Your dataframe has 0 rows, so you can't put a 182 row vector into the 
first column.

Unlike vectors, dataframes won't grow if you make assignments beyond the 
end of the rows.

There are at least a couple of solutions:

1.  Don't create columns until you have data ready for them.

You can wait to create the dataframe until your "day" column is ready:

df_year <- data.frame(day = seq(...))

As you compute other columns of the same length, you can add them, e.g.

df_year$hs_MteBove <- ...

2.  Create your columns with the right length from the beginning:

df_year <- data.frame(day = rep(as.Date(NA), 182), ...)

I don't like this solution as much.

Duncan Murdoch


From Douglas.Federman at utoledo.edu  Thu Jun  9 14:56:01 2016
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Thu, 9 Jun 2016 12:56:01 +0000
Subject: [R] Importing data from a text file with no separator
In-Reply-To: <CAOgs+Ox82v_cJQC-JNzaqjjuRfR7==62pQ4+ca+=_9OBMsCE0Q@mail.gmail.com>
References: <CAOgs+Ox82v_cJQC-JNzaqjjuRfR7==62pQ4+ca+=_9OBMsCE0Q@mail.gmail.com>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61B04E104@msgdb20.utad.utoledo.edu>

?read.fwf

There is a data import/export document on cran.r-project.org 



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paolo Letizia
Sent: Wednesday, June 08, 2016 8:40 PM
To: r-help at r-project.org
Subject: [R] Importing data from a text file with no separator

I have row data in a text file, where each row consists of 22 numerical characters. Each row consists of three different column but there is no separator. Specifically, the first two characters of the raw represent  the first column of data, the subsequent 8 characters represent the second column of data and the last 12 characters represent the third column of data. An example follows:

row data:
1003061490000000011608

The first two characters, "10", is the column "Regime"; the subsequent 8 characters, "03061490", is the column "Industry", and the last 12 characters, "000000011608", is the column dollar value. How do I import the column data into R without having any separator in the text file?
Thanks for your help, Paolo.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Jun  9 15:10:24 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 9 Jun 2016 09:10:24 -0400
Subject: [R] Importing data from a text file with no separator
In-Reply-To: <F1065E5D886F4D429259CDEAE3F83CB61B04E104@msgdb20.utad.utoledo.edu>
References: <CAOgs+Ox82v_cJQC-JNzaqjjuRfR7==62pQ4+ca+=_9OBMsCE0Q@mail.gmail.com>
	<F1065E5D886F4D429259CDEAE3F83CB61B04E104@msgdb20.utad.utoledo.edu>
Message-ID: <56f1876a-1d20-0172-8484-d4a035ee003e@gmail.com>

On 09/06/2016 8:56 AM, Federman, Douglas wrote:
> ?read.fwf
>
> There is a data import/export document on cran.r-project.org

And included with R distributions.  It's one of the manuals, and will be 
accessible via the help menu in front ends that have one.

Duncan Murdoch

>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paolo Letizia
> Sent: Wednesday, June 08, 2016 8:40 PM
> To: r-help at r-project.org
> Subject: [R] Importing data from a text file with no separator
>
> I have row data in a text file, where each row consists of 22 numerical characters. Each row consists of three different column but there is no separator. Specifically, the first two characters of the raw represent  the first column of data, the subsequent 8 characters represent the second column of data and the last 12 characters represent the third column of data. An example follows:
>
> row data:
> 1003061490000000011608
>
> The first two characters, "10", is the column "Regime"; the subsequent 8 characters, "03061490", is the column "Industry", and the last 12 characters, "000000011608", is the column dollar value. How do I import the column data into R without having any separator in the text file?
> Thanks for your help, Paolo.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Thu Jun  9 15:53:47 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 9 Jun 2016 13:53:47 +0000
Subject: [R] Error:   missing value where TRUE/FALSE needed
In-Reply-To: <20160609065257.31548.qmail@f5mail-224-118.rediffmail.com>
References: <20160609065257.31548.qmail@f5mail-224-118.rediffmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810FA901D@FHSDB2D11-2.csu.mcmaster.ca>

Dear Shashi Seth,

The principal problem here is that the "argument" to if() must be logical, while comparing anything to NA always produces NA. The proper way to test for NA is with is.na(). 

There's potentially something more subtle going on here, however, which is that even if some of the elements of the logical expression in the "call" to if() are NA, the expression may evaluate to FALSE (but never to TRUE) if the non-NA elements imply that it is FALSE. Consider the following examples:

> TRUE && FALSE && NA  # FALSE regardless of the value of the last element
[1] FALSE

> TRUE && TRUE && NA  # truth depends on the value of the last element
[1] NA

> (TRUE && FALSE && NA) != NA
[1] NA

> (TRUE && TRUE && NA) != NA
[1] NA

> is.na(TRUE && FALSE && NA)
[1] FALSE

> is.na(TRUE && TRUE && NA)
[1] TRUE

I hope that this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of SHASHI SETH
> Sent: June 9, 2016 2:53 AM
> To: R-help at r-project.org
> Subject: [R] Error: missing value where TRUE/FALSE needed
> 
> Hi,
> 
> 
> 
> I am getting the following error:
> 
> Error in if ((sum > 0 && sums1 > 0 && sums2 > 0) != NA) { :
> 
> missing value where TRUE/FALSE needed
> 
> 
> 
> 
> 
> I have including my code below for your review:
> 
> 
> 
> fitness_1_data
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tom at maladmin.com  Thu Jun  9 16:00:27 2016
From: tom at maladmin.com (Tom Wright)
Date: Thu, 9 Jun 2016 10:00:27 -0400
Subject: [R] Problem loading aplpack library
In-Reply-To: <a41f2b8f-cda6-b856-5a51-565e77d693e1@uvm.edu>
References: <mailman.9.1465380002.31060.r-help@r-project.org>
	<a41f2b8f-cda6-b856-5a51-565e77d693e1@uvm.edu>
Message-ID: <CAKmUXV-hC_7AS4S4Z_C9GuLkHcGMswNWULT7C5o31iA3MVfwhw@mail.gmail.com>

Assuming you are on a mac this link may be of assistance:
http://tips.tutorialhorizon.com/2015/10/01/xcrun-error-invalid-active-developer-path-library-developer-commandline-tools-missing-xcrun/

On Wed, Jun 8, 2016 at 7:14 PM, David Howell <david.howell at uvm.edu> wrote:
> I am having trouble running aplpack on my Mac. It will run on my PC, but the
> Mac gives an error message. Below is the result that I obtained.  It seems
> to install fine--see below--but I can't load the library.
>
>
>  > install.packages("aplpack")
> trying URL
> 'http://cran.rstudio.com/bin/macosx/contrib/3.1/aplpack_1.3.0.tgz'
> Content type 'application/x-gzip' length 3157548 bytes (3.0 Mb)
> opened URL
> ==================================================
> downloaded 3.0 Mb
>
>
> The downloaded binary packages are in
> /var/folders/6m/t4wvnh9x39500z_rh3p5jlk00000gp/T//Rtmp26I5Ej/downloaded_packages
>
>  > library(aplpack)
> Loading required package: tcltk
> xcrun: error: invalid active developer path
> (/Library/Developer/CommandLineTools), missing xcrun at:
> /Library/Developer/CommandLineTools/usr/bin/xcrun
>
> It looks as if it has a problem with tcltk. I can install tcltk2, but when I
> try to install tcltk it tells me "package not found. Is that the problem
> that aplpack is having when it tries to load the library?
>
> Any suggestions?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Thu Jun  9 16:20:09 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 09 Jun 2016 09:20:09 -0500
Subject: [R] Problem loading aplpack library
In-Reply-To: <CAKmUXV-hC_7AS4S4Z_C9GuLkHcGMswNWULT7C5o31iA3MVfwhw@mail.gmail.com>
References: <mailman.9.1465380002.31060.r-help@r-project.org>
	<a41f2b8f-cda6-b856-5a51-565e77d693e1@uvm.edu>
	<CAKmUXV-hC_7AS4S4Z_C9GuLkHcGMswNWULT7C5o31iA3MVfwhw@mail.gmail.com>
Message-ID: <4097219F-BF64-4776-9A9F-805D9835B61F@me.com>

Hi,

First, since David is reporting an issue on OS X, this should be posted to R-SIG-Mac:

  https://stat.ethz.ch/mailman/listinfo/r-sig-mac

Second, he is installing a binary version of the package and XCode should not be required in that setting.

There are a variety of warnings related to that package on CRAN:

  https://cran.r-project.org/web/checks/check_results_aplpack.html

Since they are warnings and not errors, that is presumably a low enough hurdle to enable the package to be released on CRAN, but the package author should really be working on resolving them. That being said, the package has not been updated since September of 2014, so unless it is updated at some point soon-ish, it may end up being orphaned and/or archived, depending upon CRAN policies.

FWIW, I did try to install the package on my Mac, running R 3.3.0 under El Capitan and had no issues, either with the install or loading the package.

It might be prudent for David to consider removing his R installation completely and install R 3.3.0 from scratch, along with XQuartz after installing R, which was just recently updated to 2.7.9.

David appears to be running R 3.1.x based upon the CRAN path being used below, so installing the latest stable version of R would be prudent.

Lastly, tclck is part of the base R distribution and does not need to be installed separately. That is why David is not finding it when trying to install it. It is already installed.

tcltk2 is a third party CRAN package and is not indicated as being a dependency for aplpack.

Regards,

Marc Schwartz


> On Jun 9, 2016, at 9:00 AM, Tom Wright <tom at maladmin.com> wrote:
> 
> Assuming you are on a mac this link may be of assistance:
> http://tips.tutorialhorizon.com/2015/10/01/xcrun-error-invalid-active-developer-path-library-developer-commandline-tools-missing-xcrun/
> 
> On Wed, Jun 8, 2016 at 7:14 PM, David Howell <david.howell at uvm.edu> wrote:
>> I am having trouble running aplpack on my Mac. It will run on my PC, but the
>> Mac gives an error message. Below is the result that I obtained.  It seems
>> to install fine--see below--but I can't load the library.
>> 
>> 
>>> install.packages("aplpack")
>> trying URL
>> 'http://cran.rstudio.com/bin/macosx/contrib/3.1/aplpack_1.3.0.tgz'
>> Content type 'application/x-gzip' length 3157548 bytes (3.0 Mb)
>> opened URL
>> ==================================================
>> downloaded 3.0 Mb
>> 
>> 
>> The downloaded binary packages are in
>> /var/folders/6m/t4wvnh9x39500z_rh3p5jlk00000gp/T//Rtmp26I5Ej/downloaded_packages
>> 
>>> library(aplpack)
>> Loading required package: tcltk
>> xcrun: error: invalid active developer path
>> (/Library/Developer/CommandLineTools), missing xcrun at:
>> /Library/Developer/CommandLineTools/usr/bin/xcrun
>> 
>> It looks as if it has a problem with tcltk. I can install tcltk2, but when I
>> try to install tcltk it tells me "package not found. Is that the problem
>> that aplpack is having when it tries to load the library?
>> 
>> Any suggestions?


From j.logsdon at quantex-research.com  Thu Jun  9 18:36:31 2016
From: j.logsdon at quantex-research.com (John Logsdon)
Date: Thu, 9 Jun 2016 17:36:31 +0100
Subject: [R] apply and cousins
Message-ID: <a97133bc7ab87b624a0e1dc12e99955f.squirrel@quantex.zedcore.com>

Thanks Jim and others (and sorry Jim - an early version of this slipped
into your inbox :))

Apologies for not giving some concrete code - I was trying to explain in
words.

What I need to do is to fit a simple linear model to successive sections
of a long matrix.

So far, the best solution I have come up with uses apply twice:

Generate some data in a 100000*3 matrix:

N = 100000
Z = cbind(1:N,cumsum(rnorm(N,1,0.01)),rnorm(N,1.2,0.1)) #

where the first column is an index, the second a monotonic increasing
value representing time and the third just the measurements I want to
process.

Then write a function dVals1:

dVals1 = function(Y,DD,dT){which.min((Y[2] - dT) > DD[,2])))

which will identify the first row where the time is greater than current
time - dT.

So to identify the start of the data (say) 10 units before for each row,
we use apply and prepended this as a column to the array for later use:

ZZ = cbind(apply(Z,1,dVals1,Z,10),Z)

There may be some cases, particularly at the start, where later values are
extracted because the minimum returned by which.min is 1.

I now have start and finish pointers for each position so can proceed to
fit a simple linear model with the following function:

dVals2=function(D2,DD){
  if((D2[2]-D2[1])<10){return(rep(0,2))} # reject short examples
  DX=DD[D2[1]:D2[2],]
  Res=as.vector(lm(DX[,3]~DX[,2])$coefficients)
  return(Res)
}

which returns 2 0's either if there are fewer than 10 values, otherwise it
returns the intercept and slope calculated over the specified range.

Applying this to the whole data by:

t(apply(ZZ,1,dVals2,DD=ZZ))

does the job I think returning the results as an N * 2 matrix.

> Hi John,
> With due respect to the other respondents, here is something that might
help:
>
> # get a vector of values
> foo<-rnorm(100)
> # get a vector of increasing indices (aka your "recent" values)
> bar<-sort(sample(1:100,40))
> # write a function to "clump" the adjacent index values
> clump_adj_int<-function(x) {
>  index_list<-list(x[1])
>  list_index<-1
>  for(i in 2:length(x)) {
>   if(x[i]==x[i-1]+1)
>    index_list[[list_index]]<-c(index_list[[list_index]],x[i])
>   else {
>    list_index<-list_index+1
>    index_list[[list_index]]<-x[i]
>   }
>  }
>  return(index_list)
> }
> index_clumps<-clump_adj_int(bar)
> # write another function to sum the values
> sum_subsets<-function(indices,vector)
> return(sum(vector[indices],na.rm=TRUE))
> # now "apply" the function to the list of indices
> lapply(index_clumps,sum_subsets,foo)
>
> Jim
>
>
> On Thu, Jun 9, 2016 at 2:41 AM, John Logsdon
> <j.logsdon at quantex-research.com> wrote:
>> Folks
>>
>> Is there any way to get the row index into apply as a variable?
>>
>> I want a function to do some sums on a small subset of some very long
vectors, rolling through the whole vectors.
>>
>> apply(X,1,function {do something}, other arguments)
>>
>> seems to be the way to do it.
>>
>> The subset I want is the most recent set of measurements only - perhaps a
>> couple of hundred out of millions - but I can't see how to index each
value.  The ultimate output should be a matrix of results the length of
the input vector.  But to do the sum I need to access the current row
number.
>>
>> It is easy in a loop but that will take ages. Is there any vectorised
apply-like solution to this?
>>
>> Or does apply etc only operate on each row at a time, independently of
other rows?
>>
>>
>> Best wishes
>>
>> John
>>
>> John Logsdon
>> Quantex Research Ltd
>> +44 161 445 4951/+44 7717758675
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


Best wishes

John

John Logsdon
Quantex Research Ltd
+44 161 445 4951/+44 7717758675



Best wishes

John

John Logsdon
Quantex Research Ltd
+44 161 445 4951/+44 7717758675


From esawiek at gmail.com  Thu Jun  9 07:40:00 2016
From: esawiek at gmail.com (Ek Esawi)
Date: Thu, 9 Jun 2016 01:40:00 -0400
Subject: [R] Reading and converting time data via read.table
Message-ID: <CA+ZkTxtAO=Rku4q+CmLd+ccbg+iTsaixh1sc_BCwyhDkx4P+1Q@mail.gmail.com>

Thank you Jeff and Don. As I stated on my original posting that I am
relatively new to R. After a few weeks of searching and reading I have come
to the same point that Don made which is base R doesn?t have a class for
time only. I explored the chron and lubridate packages and even looked at Ecfun
package; the latter is too long and I did not have time to experiment with
it. I think the lubridate package might be useful for this; but again I did
not want to get into many packages. So I tried chron using the times
function that produced what I want. Indeed as Don said, I could not figure
out how to use it in a read.table; so I had already decided to do what Don
suggested which is read them as character then convert them one vector at a
time to time class.



What do I need this stuff for? Well, I published a paper 6 months ago where
I had to deal with time data and needed to convert and manipulate time
data. I did all that work in Excel and it took too long; so I want to learn
R for future research and use the same data using R.



I agree with Jeff?s comments. In fact, I learned most of them the hard way
by trial and error and realized that it?s difficult to separate time and
date using POSIXct and POSIXlt.



Thanks again----EK

	[[alternative HTML version deleted]]


From yucaizhongxue at outlook.com  Thu Jun  9 10:00:21 2016
From: yucaizhongxue at outlook.com (=?gb2312?B?1twgv8nOwA==?=)
Date: Thu, 9 Jun 2016 08:00:21 +0000
Subject: [R] problem: the id of the data set
Message-ID: <A69791E0-7A02-486E-8CA0-B4376A61788C@outlook.com>

I got the dataset after merge two old one .The  id of the column isn?t  just the number of the column.So when I identify some obs,I got the figure 28000(though my obs is only 6000).So it causes the trouble to remove these obs in the dataset.I wander how to make the id of the merged dataset in a right order.Or what could I do when I did identify the id of the outliner(but not the number of the column it belongs to ) when I need to remove those obs.
Thanks for your time.

From marceloperlin at gmail.com  Thu Jun  9 16:24:03 2016
From: marceloperlin at gmail.com (Marcelo Perlin)
Date: Thu, 9 Jun 2016 11:24:03 -0300
Subject: [R] About identification of CRAN CHECK machines in logs
Message-ID: <CANMhtdxg3vRLmv4si5edyexHmdgyOxAtExz8YbAXdOJ2xFm-Sw@mail.gmail.com>

Hi,

I recently released two packages (RndTexExams and GetTDData) in CRAN and
I'm trying to track the number of downloads and location of users.

I wrote a simple script to download and analyze the log files in http://cran
-logs.rstudio.com.
I realized, however, that during the release of a new version of the
packages there is a spike in the number of downloads. I believe that the
CRAN checks are included in the number of installations of the package in
the log files.

I see from the log files the existence of column "ip_id", which sets a
daily unique id for each new ip. My question is, can CRAN set the ip_id of
the CRAN machines to a fixed value so that we can filter only "real" users
out of the data? Can anyone see any other way around it?


Thanks.

-- 
Marcelo Perlin
Professor Adjunto | Escola de Administra??o
Universidade Federal do Rio Grande do Sul
Rua Washington Luiz, 855 | 90010-460| Porto Alegre RS| Brasil
Tel.: (51) 3308-3303 | www.ea.ufrgs.br
http://lattes.cnpq.br/3262699324398819
https://sites.google.com/site/marceloperlin/

	[[alternative HTML version deleted]]


From himani.rana at gmail.com  Thu Jun  9 17:19:00 2016
From: himani.rana at gmail.com (Himani)
Date: Thu, 9 Jun 2016 10:19:00 -0500
Subject: [R] R install on AIX 7
Message-ID: <CAMrs3zPp5sStZuJwEOKzXE77aN7k1-aLifHcMfaCYipDVQAcpw@mail.gmail.com>

Hi,
I am trying to install R on AIX 7, could you please refer me to any
document which i can refer to. My ultimate goal is to integrate R with
microstrategy and my microstrategy server is on AIX 7, so i need to have R
installed over there before i can install integration pack.

Any suggestions please.

Thanks
Himani

	[[alternative HTML version deleted]]


From ayyappach at gmail.com  Thu Jun  9 19:19:15 2016
From: ayyappach at gmail.com (Ayyappa Chaturvedula)
Date: Thu, 9 Jun 2016 12:19:15 -0500
Subject: [R] VIM package
Message-ID: <CAL8Tui5GH-A6NcdX=49Djkk=HHB0ckAfNks7BqFuS_+GbY0Y_w@mail.gmail.com>

Dear R users,
I am trying to use VIM (Visualization and Imputation of Missing Values)
package in R.  When I try to install the VIM library (library(VIM)), I am
getting this: Error in library(VIM) : there is no package called ?VIM?. I
appreciate any comments on this problem.
Regards,
Ayyappa

	[[alternative HTML version deleted]]


From tom at maladmin.com  Thu Jun  9 19:26:00 2016
From: tom at maladmin.com (Tom Wright)
Date: Thu, 9 Jun 2016 13:26:00 -0400
Subject: [R] VIM package
In-Reply-To: <CAL8Tui5GH-A6NcdX=49Djkk=HHB0ckAfNks7BqFuS_+GbY0Y_w@mail.gmail.com>
References: <CAL8Tui5GH-A6NcdX=49Djkk=HHB0ckAfNks7BqFuS_+GbY0Y_w@mail.gmail.com>
Message-ID: <CAKmUXV8bcO0HAES6Ne+3Nmut+q-o2o2xtEevp_tDkH6y+1z0+Q@mail.gmail.com>

Did you install the package before loading it?
install.packages("VIM")

On Thu, Jun 9, 2016 at 1:19 PM, Ayyappa Chaturvedula
<ayyappach at gmail.com> wrote:
> Dear R users,
> I am trying to use VIM (Visualization and Imputation of Missing Values)
> package in R.  When I try to install the VIM library (library(VIM)), I am
> getting this: Error in library(VIM) : there is no package called ?VIM?. I
> appreciate any comments on this problem.
> Regards,
> Ayyappa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Jun  9 19:30:03 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 9 Jun 2016 13:30:03 -0400
Subject: [R] R install on AIX 7
In-Reply-To: <CAMrs3zPp5sStZuJwEOKzXE77aN7k1-aLifHcMfaCYipDVQAcpw@mail.gmail.com>
References: <CAMrs3zPp5sStZuJwEOKzXE77aN7k1-aLifHcMfaCYipDVQAcpw@mail.gmail.com>
Message-ID: <9fa00397-b4be-30e7-9885-1362756b406d@gmail.com>

On 09/06/2016 11:19 AM, Himani wrote:
> Hi,
> I am trying to install R on AIX 7, could you please refer me to any
> document which i can refer to.

The R Installation and Administration manual (distributed with R) seems 
like the place to start.  It doesn't mention AIX 7 but does go up to AIX 
6.2.  It also mentions an "R on AIX" project; I don't know if that is 
still active.

Duncan Murdoch

> My ultimate goal is to integrate R with
> microstrategy and my microstrategy server is on AIX 7, so i need to have R
> installed over there before i can install integration pack.
>
> Any suggestions please.
>
> Thanks
> Himani
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Jun  9 19:30:55 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 9 Jun 2016 10:30:55 -0700
Subject: [R] Reading and converting time data via read.table
In-Reply-To: <CA+ZkTxtAO=Rku4q+CmLd+ccbg+iTsaixh1sc_BCwyhDkx4P+1Q@mail.gmail.com>
References: <CA+ZkTxtAO=Rku4q+CmLd+ccbg+iTsaixh1sc_BCwyhDkx4P+1Q@mail.gmail.com>
Message-ID: <CAF8bMcYUt+_50zehgH9FZY25BogFWm865HXOHDc0DfLPRvheEQ@mail.gmail.com>

>In fact, I learned most of them the hard way
>by trial and error and realized that it?s difficult to separate time and
>date using POSIXct and POSIXlt.

It is difficult to separate time from data in real life as well.  The most
common problem is when your time zone switches between 'daylight
savings' ('summer') and 'standard' ('winter') each spring and fall.

You can attach your time to a fake date and arrange to only print the
time portion, but since you have a date, use it.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jun 8, 2016 at 10:40 PM, Ek Esawi <esawiek at gmail.com> wrote:

> Thank you Jeff and Don. As I stated on my original posting that I am
> relatively new to R. After a few weeks of searching and reading I have come
> to the same point that Don made which is base R doesn?t have a class for
> time only. I explored the chron and lubridate packages and even looked at
> Ecfun
> package; the latter is too long and I did not have time to experiment with
> it. I think the lubridate package might be useful for this; but again I did
> not want to get into many packages. So I tried chron using the times
> function that produced what I want. Indeed as Don said, I could not figure
> out how to use it in a read.table; so I had already decided to do what Don
> suggested which is read them as character then convert them one vector at a
> time to time class.
>
>
>
> What do I need this stuff for? Well, I published a paper 6 months ago where
> I had to deal with time data and needed to convert and manipulate time
> data. I did all that work in Excel and it took too long; so I want to learn
> R for future research and use the same data using R.
>
>
>
> I agree with Jeff?s comments. In fact, I learned most of them the hard way
> by trial and error and realized that it?s difficult to separate time and
> date using POSIXct and POSIXlt.
>
>
>
> Thanks again----EK
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Thu Jun  9 19:42:39 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 9 Jun 2016 18:42:39 +0100
Subject: [R] problem: the id of the data set
In-Reply-To: <A69791E0-7A02-486E-8CA0-B4376A61788C@outlook.com>
References: <A69791E0-7A02-486E-8CA0-B4376A61788C@outlook.com>
Message-ID: <231d4df7-bcd9-dcbf-262a-9e2b20bc703a@dewey.myzen.co.uk>

Perhaps I do not understand you correctly but why not create a variable 
for the id before you merge?

On 09/06/2016 09:00, ? ?? wrote:
> I got the dataset after merge two old one .The  id of the column isn?t  just the number of the column.So when I identify some obs,I got the figure 28000(though my obs is only 6000).So it causes the trouble to remove these obs in the dataset.I wander how to make the id of the merged dataset in a right order.Or what could I do when I did identify the id of the outliner(but not the number of the column it belongs to ) when I need to remove those obs.
> Thanks for your time.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ulrik.stervbo at gmail.com  Thu Jun  9 21:29:28 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 09 Jun 2016 19:29:28 +0000
Subject: [R] problem: the id of the data set
In-Reply-To: <231d4df7-bcd9-dcbf-262a-9e2b20bc703a@dewey.myzen.co.uk>
References: <A69791E0-7A02-486E-8CA0-B4376A61788C@outlook.com>
	<231d4df7-bcd9-dcbf-262a-9e2b20bc703a@dewey.myzen.co.uk>
Message-ID: <CAKVAULMZ7mtqakrukZv3nphtSJO2bt-WFnFm7X+SZ7CvaeFi6g@mail.gmail.com>

How do you merge the two data.frames? Could it be that you make an outer
join?

HTH
Ulrik

On Thu, 9 Jun 2016 at 19:45 Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Perhaps I do not understand you correctly but why not create a variable
> for the id before you merge?
>
> On 09/06/2016 09:00, ? ?? wrote:
> > I got the dataset after merge two old one .The  id of the column isn?t
> just the number of the column.So when I identify some obs,I got the figure
> 28000(though my obs is only 6000).So it causes the trouble to remove these
> obs in the dataset.I wander how to make the id of the merged dataset in a
> right order.Or what could I do when I did identify the id of the
> outliner(but not the number of the column it belongs to ) when I need to
> remove those obs.
> > Thanks for your time.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Thu Jun  9 22:50:13 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 9 Jun 2016 20:50:13 +0000
Subject: [R] problem: the id of the data set
In-Reply-To: <231d4df7-bcd9-dcbf-262a-9e2b20bc703a@dewey.myzen.co.uk>
References: <A69791E0-7A02-486E-8CA0-B4376A61788C@outlook.com>
	<231d4df7-bcd9-dcbf-262a-9e2b20bc703a@dewey.myzen.co.uk>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27663096AC80@WAXMXOLYMB025.WAX.wa.lcl>

We really need a reproducible example.  Otherwise, we can only guess what the starting point was, how the merge was done, what the expected result was, and how the obtained result differed from the expected result.

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> On 09/06/2016 09:00, ? ?? wrote:
> > I got the dataset after merge two old one .The  id of the column isn?t  just
> the number of the column.So when I identify some obs,I got the figure
> 28000(though my obs is only 6000).So it causes the trouble to remove these
> obs in the dataset.I wander how to make the id of the merged dataset in a
> right order.Or what could I do when I did identify the id of the outliner(but
> not the number of the column it belongs to ) when I need to remove those
> obs.
> > Thanks for your time.

From h.wickham at gmail.com  Thu Jun  9 23:18:31 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 9 Jun 2016 16:18:31 -0500
Subject: [R] About identification of CRAN CHECK machines in logs
In-Reply-To: <CANMhtdxg3vRLmv4si5edyexHmdgyOxAtExz8YbAXdOJ2xFm-Sw@mail.gmail.com>
References: <CANMhtdxg3vRLmv4si5edyexHmdgyOxAtExz8YbAXdOJ2xFm-Sw@mail.gmail.com>
Message-ID: <CABdHhvFrMN71pijg1nB+a_1LH_1HSLisq4cb8VGwPBdAx60cvw@mail.gmail.com>

On Thu, Jun 9, 2016 at 9:24 AM, Marcelo Perlin <marceloperlin at gmail.com> wrote:
> Hi,
>
> I recently released two packages (RndTexExams and GetTDData) in CRAN and
> I'm trying to track the number of downloads and location of users.
>
> I wrote a simple script to download and analyze the log files in http://cran
> -logs.rstudio.com.
> I realized, however, that during the release of a new version of the
> packages there is a spike in the number of downloads. I believe that the
> CRAN checks are included in the number of installations of the package in
> the log files.

I don't think that's true. Why would CRAN be installing the package
from a mirror?

Hadley

-- 
http://hadley.nz


From jax200 at gmail.com  Thu Jun  9 22:44:52 2016
From: jax200 at gmail.com (jax200)
Date: Thu, 9 Jun 2016 13:44:52 -0700
Subject: [R] New installation
Message-ID: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>

Hi

I'm starting off with both R and Linux Mint.  During a recent R course, I
had multiple difficulties with installing updates needed for the course.

As such, I'd like to hit the restart button with fresh installs of Linux
and R.  I would appreciate your help with which Linux platform works best
with R, and how to go about getting all the updates installed for both
programs.

Many thanks,  Jack

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun 10 00:46:04 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 9 Jun 2016 15:46:04 -0700
Subject: [R] New installation
In-Reply-To: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
References: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
Message-ID: <CAGxFJbR471Rj=3stgcdzDvdUbeefZGePR-PeEbB0y2AKyBoY8w@mail.gmail.com>

I suggest that you post to the r-sig-debian list instead of here. I
think you are more likely to get good answers to your query there.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 9, 2016 at 1:44 PM, jax200 <jax200 at gmail.com> wrote:
> Hi
>
> I'm starting off with both R and Linux Mint.  During a recent R course, I
> had multiple difficulties with installing updates needed for the course.
>
> As such, I'd like to hit the restart button with fresh installs of Linux
> and R.  I would appreciate your help with which Linux platform works best
> with R, and how to go about getting all the updates installed for both
> programs.
>
> Many thanks,  Jack
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Fri Jun 10 01:08:10 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 9 Jun 2016 19:08:10 -0400
Subject: [R] New installation
In-Reply-To: <CAGxFJbR471Rj=3stgcdzDvdUbeefZGePR-PeEbB0y2AKyBoY8w@mail.gmail.com>
References: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
	<CAGxFJbR471Rj=3stgcdzDvdUbeefZGePR-PeEbB0y2AKyBoY8w@mail.gmail.com>
Message-ID: <CA+vqiLFh7CzNqJC_Xz5YFTXo1w2onkSJQnCBsyJ7iNNiWKW-1A@mail.gmail.com>

Perhaps r-sig-debian is more appropriate, though it is not clear to me that
a debian based linux is in fact the best for running R. Of course "best" is
not clearly defined here, but I highly recommend Archlinux.

Best,
Ista
On Jun 9, 2016 6:47 PM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:

> I suggest that you post to the r-sig-debian list instead of here. I
> think you are more likely to get good answers to your query there.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 9, 2016 at 1:44 PM, jax200 <jax200 at gmail.com> wrote:
> > Hi
> >
> > I'm starting off with both R and Linux Mint.  During a recent R course, I
> > had multiple difficulties with installing updates needed for the course.
> >
> > As such, I'd like to hit the restart button with fresh installs of Linux
> > and R.  I would appreciate your help with which Linux platform works best
> > with R, and how to go about getting all the updates installed for both
> > programs.
> >
> > Many thanks,  Jack
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Fri Jun 10 01:41:42 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Fri, 10 Jun 2016 02:41:42 +0300
Subject: [R] Non-negative matrix factorization for term documnt matrix
In-Reply-To: <DUB125-W4DA8E8879CDC6FD60DFE7B35F0@phx.gbl>
References: <DUB125-W4DA8E8879CDC6FD60DFE7B35F0@phx.gbl>
Message-ID: <DUB125-W73E57762084E941D4E671EB35F0@phx.gbl>




?
?Dear group,
?kindly how can I apply Non-negative matrix factorization for term document matrix in R. ?Please if you any link to guide or tutorial send it.
? thanks in advance
?
? Ragia
??
 		 	   		  

From NordlDJ at dshs.wa.gov  Fri Jun 10 01:51:50 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 9 Jun 2016 23:51:50 +0000
Subject: [R] Non-negative matrix factorization for term documnt matrix
In-Reply-To: <DUB125-W73E57762084E941D4E671EB35F0@phx.gbl>
References: <DUB125-W4DA8E8879CDC6FD60DFE7B35F0@phx.gbl>
	<DUB125-W73E57762084E941D4E671EB35F0@phx.gbl>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27663096AD7F@WAXMXOLYMB025.WAX.wa.lcl>

A quick Google search suggests that the package, NMF, might be of help.


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ragia .
> Sent: Thursday, June 09, 2016 4:42 PM
> To: r-help at r-project.org
> Subject: [R] Non-negative matrix factorization for term documnt matrix
> 
> 
> 
> 
> 
> ?Dear group,
> ?kindly how can I apply Non-negative matrix factorization for term document
> matrix in R. ?Please if you any link to guide or tutorial send it.
> ? thanks in advance
> 
> ? Ragia
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From leonardof at leonardof.med.br  Fri Jun 10 01:54:16 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Thu, 09 Jun 2016 20:54:16 -0300
Subject: [R] New installation
In-Reply-To: <CA+vqiLFh7CzNqJC_Xz5YFTXo1w2onkSJQnCBsyJ7iNNiWKW-1A@mail.gmail.com>
References: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
	<CAGxFJbR471Rj=3stgcdzDvdUbeefZGePR-PeEbB0y2AKyBoY8w@mail.gmail.com>
	<CA+vqiLFh7CzNqJC_Xz5YFTXo1w2onkSJQnCBsyJ7iNNiWKW-1A@mail.gmail.com>
Message-ID: <1465516456.214873.633309809.52F4C9FD@webmail.messagingengine.com>

I have tried many Linux distributions before, and never looked back
after switching for Arch Linux. It is one of the best distributions with
regard to having an up to date but still reasonably stable system. Other
options are Fedora  Rawhide (there's a Fedora SIG mailing list) or
Debian Sid (as others mentioned, there's a Debian SIG mailing list), but
I don't know how dependable those versions are.

Leonardo Ferreira Fontenelle
Former GNOME translator

Em Qui 9 jun. 2016, ?s 20:08, Ista Zahn escreveu:
> Perhaps r-sig-debian is more appropriate, though it is not clear to me
> that
> a debian based linux is in fact the best for running R. Of course "best"
> is
> not clearly defined here, but I highly recommend Archlinux.
> 
> Best,
> Ista
> On Jun 9, 2016 6:47 PM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:
> 
> > I suggest that you post to the r-sig-debian list instead of here. I
> > think you are more likely to get good answers to your query there.
> >
> > Cheers,
> > Bert
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Thu, Jun 9, 2016 at 1:44 PM, jax200 <jax200 at gmail.com> wrote:
> > > Hi
> > >
> > > I'm starting off with both R and Linux Mint.  During a recent R course, I
> > > had multiple difficulties with installing updates needed for the course.
> > >
> > > As such, I'd like to hit the restart button with fresh installs of Linux
> > > and R.  I would appreciate your help with which Linux platform works best
> > > with R, and how to go about getting all the updates installed for both
> > > programs.
> > >
> > > Many thanks,  Jack
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From clint at ecy.wa.gov  Fri Jun 10 02:25:46 2016
From: clint at ecy.wa.gov (Clint Bowman)
Date: Thu, 9 Jun 2016 17:25:46 -0700 (PDT)
Subject: [R] New installation
In-Reply-To: <1465516456.214873.633309809.52F4C9FD@webmail.messagingengine.com>
References: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
	<CAGxFJbR471Rj=3stgcdzDvdUbeefZGePR-PeEbB0y2AKyBoY8w@mail.gmail.com>
	<CA+vqiLFh7CzNqJC_Xz5YFTXo1w2onkSJQnCBsyJ7iNNiWKW-1A@mail.gmail.com>
	<1465516456.214873.633309809.52F4C9FD@webmail.messagingengine.com>
Message-ID: <alpine.LRH.2.20.1606091724070.1083@aeolus.ecy.wa.gov>

I "experiment" with the Fedora distribution at home but am very satisfied 
with the Scientific Linux distribution here at work--I'm currently using 
SL7.2.

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 9 Jun 2016, Leonardo Ferreira Fontenelle wrote:

> I have tried many Linux distributions before, and never looked back
> after switching for Arch Linux. It is one of the best distributions with
> regard to having an up to date but still reasonably stable system. Other
> options are Fedora  Rawhide (there's a Fedora SIG mailing list) or
> Debian Sid (as others mentioned, there's a Debian SIG mailing list), but
> I don't know how dependable those versions are.
>
> Leonardo Ferreira Fontenelle
> Former GNOME translator
>
> Em Qui 9 jun. 2016, ?s 20:08, Ista Zahn escreveu:
>> Perhaps r-sig-debian is more appropriate, though it is not clear to me
>> that
>> a debian based linux is in fact the best for running R. Of course "best"
>> is
>> not clearly defined here, but I highly recommend Archlinux.
>> 
>> Best,
>> Ista
>> On Jun 9, 2016 6:47 PM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:
>> 
>> > I suggest that you post to the r-sig-debian list instead of here. I
>> > think you are more likely to get good answers to your query there.
>> >
>> > Cheers,
>> > Bert
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> > and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Thu, Jun 9, 2016 at 1:44 PM, jax200 <jax200 at gmail.com> wrote:
>> > > Hi
>> > >
>> > > I'm starting off with both R and Linux Mint.  During a recent R course, I
>> > > had multiple difficulties with installing updates needed for the course.
>> > >
>> > > As such, I'd like to hit the restart button with fresh installs of Linux
>> > > and R.  I would appreciate your help with which Linux platform works best
>> > > with R, and how to go about getting all the updates installed for both
>> > > programs.
>> > >
>> > > Many thanks,  Jack
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From xavier.sumba93 at ucuenca.ec  Fri Jun 10 00:27:55 2016
From: xavier.sumba93 at ucuenca.ec (FRANCISCO XAVIER SUMBA TORAL)
Date: Thu, 9 Jun 2016 17:27:55 -0500
Subject: [R]  Visualize Sparse Matrix.
Message-ID: <6BAD2DF3-D978-4C70-B547-B78CCFC8DBD3@ucuenca.ec>

Hi,

First of all, sorry for my question it could be so basic for a common user in R, but I am starting with this new environment.

I have done a clustering job and I would like to visualize my vectors. I have a matrix of TF-IDF weights of 4602 x 1817. I store the values in a CSV file. How can I visualize my vectors in a 2D-space?

After that, I execute a clustering algorithm and I got a label for each cluster. How can I visualize my vectors resulting base on a color or figure for each cluster? 

This is the code that I am having trying to accomplish my graphs:

data <- read.csv(pathFile,header = FALSE, sep = ",?)
dMatrix <- matrix(unlist(data), ncol = 4602, byrow = TRUE) # Use a matrix to use melt.
# Graph my data
ggplot(melt(dMatrix), aes(Var1,Var2, fill=value)) + geom_raster() + scale_fill_gradient2(low='red', high=?black', mid=?white') + theme_bw() + xlab("x1") + ylab("x2")


Cheers.
	[[alternative HTML version deleted]]


From santosh2005 at gmail.com  Fri Jun 10 08:23:31 2016
From: santosh2005 at gmail.com (Santosh)
Date: Thu, 9 Jun 2016 23:23:31 -0700
Subject: [R] Application of "merge" and "within"
In-Reply-To: <7252E1E4-94D9-42FE-8F2A-267E340A375B@gmail.com>
References: <CAN_e6XtOQ97qnmEw_bhthw+Sy_g7y98VLfiaw2ga0nTWZ=rkDw@mail.gmail.com>
	<f4bc3443-6e82-e70e-8a4f-fa2a03fb14b8@gmail.com>
	<7252E1E4-94D9-42FE-8F2A-267E340A375B@gmail.com>
Message-ID: <CAN_e6XuwtmV7O5uODrmvmJwNJJWMkk+A9vkFwD6_34jHC_PqUA@mail.gmail.com>

Hi Peter and others..
In the code from Peter..(reproduced below for convenience..)
....
> first <- function(x)x[1]
> s  <- within(q, {bl <- ave(b, paste(G,a), FUN=first); db <- b - bl})
....

is there a reason behind that 'ave' used in the above code?
is there way to perform a multi-column sort in within?

Thanks so much..
Santosh

On Wed, Jun 1, 2016 at 1:45 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> Notice that within-group processing is intended. I'd try
>
> > first <- function(x)x[1]
> > s  <- within(q, {bl <- ave(b, paste(G,a), FUN=first); db <- b - bl})
>
> Or perhaps
>
> q <- within(q, Ga <- paste(G,a))
> tbl <- with(q, tapply(b, Ga, first))
> s <- within(q, {bl <- tbl[Ga]; db <- b - bl})
>
> -pd
>
>
> On 28 May 2016, at 22:53 , Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 27/05/2016 7:00 PM, Santosh wrote:
> >> Dear Rxperts!
> >>
> >> Is there a way to compute relative values.. using within().. function?
> >>
> >> Any assistance/suggestions are highly welcome!!
> >> Thanks again,
> >> Santosh...
> >> ___________________________________________________________________
> >> A sample dataset and the computation "outside" within()  function is
> shown..
> >>
> >> q <- data.frame(GL = rep(paste("G",1:3,sep = ""),each = 50),
> >>                G  = rep(1:3,each = 50),
> >>                D = rep(paste("D",1:5,sep = ""),each = 30),
> >>                a = rep(1:15,each = 10),
> >>                t = rep(seq(10),15),
> >>                b = round(runif(150,10,20)))
> >> r <- subset(q,!duplicated(paste(G,a)),sel=c(G,a,b))
> >> names(r)[3] <- "bl"
> >> s <- merge(q,r)
> >> s$db <- s$b-s$bl
> >>
> >>> head(s,5)
> >>    G  a GL  D  t  b bl db
> >> 1   1  1 G1 D1  1 13 13  0
> >> 2   1  1 G1 D1  2 16 13  3
> >> 3   1  1 G1 D1  3 19 13  6
> >> 4   1  1 G1 D1  4 12 13 -1
> >> 5   1  1 G1 D1  5 19 13  6
> >
> > Just use
> >
> > s <- within(s, db <- b - bl)
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Fri Jun 10 08:58:14 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 10 Jun 2016 08:58:14 +0200
Subject: [R] New installation
In-Reply-To: <alpine.LRH.2.20.1606091724070.1083@aeolus.ecy.wa.gov> (Clint
	Bowman's message of "Thu, 9 Jun 2016 17:25:46 -0700 (PDT)")
References: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
	<CAGxFJbR471Rj=3stgcdzDvdUbeefZGePR-PeEbB0y2AKyBoY8w@mail.gmail.com>
	<CA+vqiLFh7CzNqJC_Xz5YFTXo1w2onkSJQnCBsyJ7iNNiWKW-1A@mail.gmail.com>
	<1465516456.214873.633309809.52F4C9FD@webmail.messagingengine.com>
	<alpine.LRH.2.20.1606091724070.1083@aeolus.ecy.wa.gov>
Message-ID: <m2shwlpm2h.fsf@krugs.de>

Clint Bowman <clint at ecy.wa.gov> writes:

I am really wondering, why nobody mentioned Ubuntu so far?

Ubuntu is a really nice distro, I never had problems with it, many
programs are available for Ubuntu, and it is build on Debian
(stable). Don't worry about Unity Window manager - there are many other
options available (Xubuntu being one of the better known ones - Ubuntu
just packed with a different Windows Manager).

If you are new to Linux, I would really suggest Ubuntu.

Cheers,

Rainer

> I "experiment" with the Fedora distribution at home but am very
> satisfied with the Scientific Linux distribution here at work--I'm
> currently using SL7.2.
>
> Clint Bowman			INTERNET:	clint at ecy.wa.gov
> Air Quality Modeler		INTERNET:	clint at math.utah.edu
> Department of Ecology		VOICE:		(360) 407-6815
> PO Box 47600			FAX:		(360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
> On Thu, 9 Jun 2016, Leonardo Ferreira Fontenelle wrote:
>
>> I have tried many Linux distributions before, and never looked back
>> after switching for Arch Linux. It is one of the best distributions with
>> regard to having an up to date but still reasonably stable system. Other
>> options are Fedora  Rawhide (there's a Fedora SIG mailing list) or
>> Debian Sid (as others mentioned, there's a Debian SIG mailing list), but
>> I don't know how dependable those versions are.
>>
>> Leonardo Ferreira Fontenelle
>> Former GNOME translator
>>
>> Em Qui 9 jun. 2016, ?s 20:08, Ista Zahn escreveu:
>>> Perhaps r-sig-debian is more appropriate, though it is not clear to me
>>> that
>>> a debian based linux is in fact the best for running R. Of course "best"
>>> is
>>> not clearly defined here, but I highly recommend Archlinux.
>>>
>>> Best,
>>> Ista
>>> On Jun 9, 2016 6:47 PM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:
>>>
>>> > I suggest that you post to the r-sig-debian list instead of here. I
>>> > think you are more likely to get good answers to your query there.
>>> >
>>> > Cheers,
>>> > Bert
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming along
>>> > and sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Thu, Jun 9, 2016 at 1:44 PM, jax200 <jax200 at gmail.com> wrote:
>>> > > Hi
>>> > >
>>> > > I'm starting off with both R and Linux Mint.  During a recent R course, I
>>> > > had multiple difficulties with installing updates needed for the course.
>>> > >
>>> > > As such, I'd like to hit the restart button with fresh installs of Linux
>>> > > and R.  I would appreciate your help with which Linux platform works best
>>> > > with R, and how to go about getting all the updates installed for both
>>> > > programs.
>>> > >
>>> > > Many thanks,  Jack
>>> > >
>>> > >         [[alternative HTML version deleted]]
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160610/7e8c614c/attachment.bin>

From farzana.akbari2013 at gmail.com  Fri Jun 10 09:44:10 2016
From: farzana.akbari2013 at gmail.com (farzana akbari)
Date: Thu, 9 Jun 2016 21:44:10 -1000
Subject: [R] FEAR package
Message-ID: <CAL3rq9j5N5gpW2WHMyvpAuw_cCAfuE7LApKPrFvbi8jjaRGvew@mail.gmail.com>

in the name of God


hi

 I'm installing  FEAR package   in  R x64 3.2.4    but  for loading it


Error : .on Attach failed in attach Namespace() for 'FEAR', details:
  call: detach("package:FEAR")
  error: invalid 'name' argument
Error: package or namespace load failed for ?FEAR?



what should I do?

Best regards

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Jun 10 11:36:20 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 10 Jun 2016 09:36:20 +0000
Subject: [R] FEAR package
In-Reply-To: <CAL3rq9j5N5gpW2WHMyvpAuw_cCAfuE7LApKPrFvbi8jjaRGvew@mail.gmail.com>
References: <CAL3rq9j5N5gpW2WHMyvpAuw_cCAfuE7LApKPrFvbi8jjaRGvew@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502FEF9@SRVEXCHMBX.precheza.cz>

Hi

you should not post in HTML (although it did not matter in this case)
you should describe the way how you did install FEAR - I found that the installation process is a bit more complicated than installation of standard CRAN packages.

But first
you should contact the author about availability of package for newer R versions, as on the web page is mentioned that the package is compatible with R 3.0.1  or R 3.1.0 and you are using R 3.2.4.

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of farzana
> akbari
> Sent: Friday, June 10, 2016 9:44 AM
> To: R-help at r-project.org
> Subject: [R] FEAR package
>
> in the name of God
>
>
> hi
>
>  I'm installing  FEAR package   in  R x64 3.2.4    but  for loading it
>
>
> Error : .on Attach failed in attach Namespace() for 'FEAR', details:
>   call: detach("package:FEAR")
>   error: invalid 'name' argument
> Error: package or namespace load failed for ?FEAR?
>
>
>
> what should I do?
>
> Best regards
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Fri Jun 10 11:39:08 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 10 Jun 2016 19:39:08 +1000
Subject: [R] Visualize Sparse Matrix.
In-Reply-To: <6BAD2DF3-D978-4C70-B547-B78CCFC8DBD3@ucuenca.ec>
References: <6BAD2DF3-D978-4C70-B547-B78CCFC8DBD3@ucuenca.ec>
Message-ID: <CA+8X3fUygaVZwuur0_krcSnTBLCN_ZZLtnFQ0WoSfUzYm0JLfQ@mail.gmail.com>

Hi Francisco,
I tried this just to see if it would work. It did, after a while.

wtmat<-matrix(rnorm(4602*1817),nrow=4602)
library(plotrix)
x11(width=5,height=13)
color2D.matplot(wtmat,c(1,1,0),c(0,1,0),0,border=FALSE)

Jim

On Fri, Jun 10, 2016 at 8:27 AM, FRANCISCO XAVIER SUMBA TORAL
<xavier.sumba93 at ucuenca.ec> wrote:
> Hi,
>
> First of all, sorry for my question it could be so basic for a common user in R, but I am starting with this new environment.
>
> I have done a clustering job and I would like to visualize my vectors. I have a matrix of TF-IDF weights of 4602 x 1817. I store the values in a CSV file. How can I visualize my vectors in a 2D-space?
>
> After that, I execute a clustering algorithm and I got a label for each cluster. How can I visualize my vectors resulting base on a color or figure for each cluster?
>
> This is the code that I am having trying to accomplish my graphs:
>
> data <- read.csv(pathFile,header = FALSE, sep = ",?)
> dMatrix <- matrix(unlist(data), ncol = 4602, byrow = TRUE) # Use a matrix to use melt.
> # Graph my data
> ggplot(melt(dMatrix), aes(Var1,Var2, fill=value)) + geom_raster() + scale_fill_gradient2(low='red', high=?black', mid=?white') + theme_bw() + xlab("x1") + ylab("x2")
>
>
> Cheers.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stefano.sofia at regione.marche.it  Fri Jun 10 12:45:43 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Fri, 10 Jun 2016 10:45:43 +0000
Subject: [R] create an empty data frame and then fill in it (and then
 evaluate the mean of semi-hourly data for each day)
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBB763F@ESINO.regionemarche.intra>

Thank you for your answer. Very clear.
(I don't like the second solution either.)
Let me then ask a final question.
From an initial data frame with semi-hourly data (df_snow, with two columns, data_POSIX of type "POSIXct" "POSIXt" and snow of type "numeric"), I need to evaluate the mean of for each day.

data_POSIX snow
2004-11-01 00:00:00 50
2004-11-01 00:30:00 55
2004-11-01 01:00:00 60
...

I first created a new column of type "Date"
df_snow$day <- as.Date(df_snow$data_POSIX,"%Y-%m-%d")

then I created a new data frame called df_snow_day to store the mean of data grouped by day:
list_days <- unique(df_snow$day)
df_snow_day <- data.frame(day=list_days)

Finally I applied lapply in this way:
df_snow_day$snow <- lapply(df_snow_day$day, function(x) round(mean(df_snow$snow[df_snow$day == x], na.rm=T)))

This does not work. I do not understand why the class of df_snow_day$snow is of type list either:

       day snow
NA    <NA>       NULL
NA.1  <NA>       NULL
NA.2  <NA>       NULL

Where is my mistake?

Thank you for all your help
Stefano


_____________________________________________

Da: Duncan Murdoch [murdoch.duncan at gmail.com]
Inviato: gioved? 9 giugno 2016 12.36
A: Stefano Sofia; r-help at r-project.org
Oggetto: Re: [R] create an empty data frame and then fill in it

On 09/06/2016 6:22 AM, Stefano Sofia wrote:
> Dear R list users,
> sorry for this simple question, but I already spent many efforts to solve it.
>
> I create an empty data frame called df_year like
>
> df_year <- data.frame(day=as.Date(character()), hs_MteBove=integer(), hs_MtePrata=integer(), hs_Pintura=integer(), hs_Pizzo=integer(), hs_Sassotetto=integer(), hs_Sibilla=integer(), stringsAsFactors=FALSE)
>
> and then I start to fill in it with
>
> df_year$day <- seq(as.Date("2004-11-01-00-00","%Y-%m-%d"), as.Date("2005-05-01-00-00","%Y-%m-%d"), by="day")
>
> but I get the following error:
> "replacement has 182 rows, data has 0"
>
> Where is my silly mistake?

Your dataframe has 0 rows, so you can't put a 182 row vector into the
first column.

Unlike vectors, dataframes won't grow if you make assignments beyond the
end of the rows.

There are at least a couple of solutions:

1.  Don't create columns until you have data ready for them.

You can wait to create the dataframe until your "day" column is ready:

df_year <- data.frame(day = seq(...))

As you compute other columns of the same length, you can add them, e.g.

df_year$hs_MteBove <- ...

2.  Create your columns with the right length from the beginning:

df_year <- data.frame(day = rep(as.Date(NA), 182), ...)

I don't like this solution as much.

Duncan Murdoch


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

From petr.pikal at precheza.cz  Fri Jun 10 12:56:03 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 10 Jun 2016 10:56:03 +0000
Subject: [R] create an empty data frame and then fill in it (and then
 evaluate the mean of semi-hourly data for each day)
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBB763F@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBB763F@ESINO.regionemarche.intra>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502FF99@SRVEXCHMBX.precheza.cz>

Hi Sofia

df_snow_day  <- aggregate(df_snow$snow, list(df_snow$day), mean, na.rm=TRUE)

should give you automagically required data frame.

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Stefano
> Sofia
> Sent: Friday, June 10, 2016 12:46 PM
> To: Duncan Murdoch <murdoch.duncan at gmail.com>; r-help at r-project.org
> Subject: Re: [R] create an empty data frame and then fill in it (and then
> evaluate the mean of semi-hourly data for each day)
>
> Thank you for your answer. Very clear.
> (I don't like the second solution either.) Let me then ask a final question.
> From an initial data frame with semi-hourly data (df_snow, with two
> columns, data_POSIX of type "POSIXct" "POSIXt" and snow of type
> "numeric"), I need to evaluate the mean of for each day.
>
> data_POSIX snow
> 2004-11-01 00:00:00 50
> 2004-11-01 00:30:00 55
> 2004-11-01 01:00:00 60
> ...
>
> I first created a new column of type "Date"
> df_snow$day <- as.Date(df_snow$data_POSIX,"%Y-%m-%d")
>
> then I created a new data frame called df_snow_day to store the mean of
> data grouped by day:
> list_days <- unique(df_snow$day)
> df_snow_day <- data.frame(day=list_days)
>
> Finally I applied lapply in this way:
> df_snow_day$snow <- lapply(df_snow_day$day, function(x)
> round(mean(df_snow$snow[df_snow$day == x], na.rm=T)))
>
> This does not work. I do not understand why the class of df_snow_day$snow
> is of type list either:
>
>        day snow
> NA    <NA>       NULL
> NA.1  <NA>       NULL
> NA.2  <NA>       NULL
>
> Where is my mistake?
>
> Thank you for all your help
> Stefano
>
>
> _____________________________________________
>
> Da: Duncan Murdoch [murdoch.duncan at gmail.com]
> Inviato: gioved? 9 giugno 2016 12.36
> A: Stefano Sofia; r-help at r-project.org
> Oggetto: Re: [R] create an empty data frame and then fill in it
>
> On 09/06/2016 6:22 AM, Stefano Sofia wrote:
> > Dear R list users,
> > sorry for this simple question, but I already spent many efforts to solve it.
> >
> > I create an empty data frame called df_year like
> >
> > df_year <- data.frame(day=as.Date(character()), hs_MteBove=integer(),
> > hs_MtePrata=integer(), hs_Pintura=integer(), hs_Pizzo=integer(),
> > hs_Sassotetto=integer(), hs_Sibilla=integer(), stringsAsFactors=FALSE)
> >
> > and then I start to fill in it with
> >
> > df_year$day <- seq(as.Date("2004-11-01-00-00","%Y-%m-%d"),
> > as.Date("2005-05-01-00-00","%Y-%m-%d"), by="day")
> >
> > but I get the following error:
> > "replacement has 182 rows, data has 0"
> >
> > Where is my silly mistake?
>
> Your dataframe has 0 rows, so you can't put a 182 row vector into the first
> column.
>
> Unlike vectors, dataframes won't grow if you make assignments beyond the
> end of the rows.
>
> There are at least a couple of solutions:
>
> 1.  Don't create columns until you have data ready for them.
>
> You can wait to create the dataframe until your "day" column is ready:
>
> df_year <- data.frame(day = seq(...))
>
> As you compute other columns of the same length, you can add them, e.g.
>
> df_year$hs_MteBove <- ...
>
> 2.  Create your columns with the right length from the beginning:
>
> df_year <- data.frame(day = rep(as.Date(NA), 182), ...)
>
> I don't like this solution as much.
>
> Duncan Murdoch
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione Marche
> possono contenere informazioni confidenziali e con privilegi legali. Se non si ?
> il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo
> messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al
> mittente ed eliminarlo completamente dal sistema del proprio computer. Ai
> sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed
> urgenza, la risposta al presente messaggio di posta elettronica pu? essere
> visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain. E-mail
> messages to clients of Regione Marche may contain information that is
> confidential and legally privileged. Please do not read, copy, forward, or store
> this message unless you are an intended recipient of it. If you have received
> this message in error, please forward it to the sender and delete it
> completely from your computer system.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Fri Jun 10 13:03:26 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Jun 2016 07:03:26 -0400
Subject: [R] create an empty data frame and then fill in it (and then
 evaluate the mean of semi-hourly data for each day)
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBB763F@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBB763F@ESINO.regionemarche.intra>
Message-ID: <6001c5a4-51d1-68f9-c876-339161bf47b8@gmail.com>

On 10/06/2016 6:45 AM, Stefano Sofia wrote:
> Thank you for your answer. Very clear.
> (I don't like the second solution either.)
> Let me then ask a final question.
> From an initial data frame with semi-hourly data (df_snow, with two columns, data_POSIX of type "POSIXct" "POSIXt" and snow of type "numeric"), I need to evaluate the mean of for each day.
>
> data_POSIX snow
> 2004-11-01 00:00:00 50
> 2004-11-01 00:30:00 55
> 2004-11-01 01:00:00 60
> ...
>
> I first created a new column of type "Date"
> df_snow$day <- as.Date(df_snow$data_POSIX,"%Y-%m-%d")
>
> then I created a new data frame called df_snow_day to store the mean of data grouped by day:
> list_days <- unique(df_snow$day)
> df_snow_day <- data.frame(day=list_days)
>
> Finally I applied lapply in this way:
> df_snow_day$snow <- lapply(df_snow_day$day, function(x) round(mean(df_snow$snow[df_snow$day == x], na.rm=T)))
>
> This does not work. I do not understand why the class of df_snow_day$snow is of type list either:

lapply() returns a list.  Petr's solution is probably better, but you 
could likely get what you want using vapply() instead:

df_snow_day$snow <- vapply(df_snow_day$day, function(x) 
round(mean(df_snow$snow[df_snow$day == x], na.rm=T)), 0)

The 0 at the end is an example of the numeric function result you want, 
so that vapply() knows to create a numeric vector.

Duncan Murdoch

>
>        day snow
> NA    <NA>       NULL
> NA.1  <NA>       NULL
> NA.2  <NA>       NULL
>
> Where is my mistake?
>
> Thank you for all your help
> Stefano
>
>
> _____________________________________________
>
> Da: Duncan Murdoch [murdoch.duncan at gmail.com]
> Inviato: gioved? 9 giugno 2016 12.36
> A: Stefano Sofia; r-help at r-project.org
> Oggetto: Re: [R] create an empty data frame and then fill in it
>
> On 09/06/2016 6:22 AM, Stefano Sofia wrote:
>> Dear R list users,
>> sorry for this simple question, but I already spent many efforts to solve it.
>>
>> I create an empty data frame called df_year like
>>
>> df_year <- data.frame(day=as.Date(character()), hs_MteBove=integer(), hs_MtePrata=integer(), hs_Pintura=integer(), hs_Pizzo=integer(), hs_Sassotetto=integer(), hs_Sibilla=integer(), stringsAsFactors=FALSE)
>>
>> and then I start to fill in it with
>>
>> df_year$day <- seq(as.Date("2004-11-01-00-00","%Y-%m-%d"), as.Date("2005-05-01-00-00","%Y-%m-%d"), by="day")
>>
>> but I get the following error:
>> "replacement has 182 rows, data has 0"
>>
>> Where is my silly mistake?
>
> Your dataframe has 0 rows, so you can't put a 182 row vector into the
> first column.
>
> Unlike vectors, dataframes won't grow if you make assignments beyond the
> end of the rows.
>
> There are at least a couple of solutions:
>
> 1.  Don't create columns until you have data ready for them.
>
> You can wait to create the dataframe until your "day" column is ready:
>
> df_year <- data.frame(day = seq(...))
>
> As you compute other columns of the same length, you can add them, e.g.
>
> df_year$hs_MteBove <- ...
>
> 2.  Create your columns with the right length from the beginning:
>
> df_year <- data.frame(day = rep(as.Date(NA), 182), ...)
>
> I don't like this solution as much.
>
> Duncan Murdoch
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>


From chalabi.elahe at yahoo.de  Fri Jun 10 15:14:21 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Fri, 10 Jun 2016 13:14:21 +0000 (UTC)
Subject: [R] save rgl.sphere plot
References: <1030458600.1560832.1465564461448.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1030458600.1560832.1465564461448.JavaMail.yahoo@mail.yahoo.com>

Hi all 
I have generated a 3D interactive rgl.sphere but I don't know how to save it to be viewed also interactive(being able to rotate it and do zoom-in and out). Does anyone know how should I save it?
Thanks for any help!
Elahe


From h.wickham at gmail.com  Fri Jun 10 15:32:33 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 10 Jun 2016 08:32:33 -0500
Subject: [R] About identification of CRAN CHECK machines in logs
In-Reply-To: <CANMhtdwu_zVROLAj3nsYV3FgY8oYngVUpPdpUm8DA8j48J_xKw@mail.gmail.com>
References: <CANMhtdxg3vRLmv4si5edyexHmdgyOxAtExz8YbAXdOJ2xFm-Sw@mail.gmail.com>
	<CABdHhvFrMN71pijg1nB+a_1LH_1HSLisq4cb8VGwPBdAx60cvw@mail.gmail.com>
	<CANMhtdwu_zVROLAj3nsYV3FgY8oYngVUpPdpUm8DA8j48J_xKw@mail.gmail.com>
Message-ID: <CABdHhvFJbESgCru6NZ=ERrY3NVTBptKQP8_tUNKcogCg196x8g@mail.gmail.com>

On Fri, Jun 10, 2016 at 8:27 AM, Marcelo Perlin <marceloperlin at gmail.com> wrote:
> I don't know Hadley. But you can see evidence of "something" systematically
> installing the packages in the log data. From my two CRAN packages I noticed
> a high correlation in the number of downloads.
>
> Try the following script, which will pick 5 random packages from CRAN and
> calculate the correlation matrix between their differenced number of
> downloads. To avoid spurious correlations,  I removed the weekends since we
> can expect some seasonality and also the zero entries. Its crude, I know,
> but it does shows some positive associations between the number of
> installations of the packages.

Which is not at all surprising:

* there are very strong seasonal patterns
* there are big jumps after releases of new versions of R
* some people like to have all packages installed locally

This is an intrinsic problem with download data. There's no way to
tell if a downloader is really using your package or not.

Hadley

-- 
http://hadley.nz


From zadig_1 at excite.com  Fri Jun 10 15:33:37 2016
From: zadig_1 at excite.com (ce)
Date: Fri, 10 Jun 2016 09:33:37 -0400
Subject: [R] New installation
Message-ID: <20160610093337.19163@web003.roc2.bluetie.com>

I use opensuse linux with R , no problems, easy to install, added R repositories . 

-----Original Message-----
From: "jax200" [jax200 at gmail.com]
Date: 06/09/2016 06:00 PM
To: r-help at r-project.org
Subject: [R] New installation

Hi

I'm starting off with both R and Linux Mint.  During a recent R course, I
had multiple difficulties with installing updates needed for the course.

As such, I'd like to hit the restart button with fresh installs of Linux
and R.  I would appreciate your help with which Linux platform works best
with R, and how to go about getting all the updates installed for both
programs.

Many thanks,  Jack

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Jun 10 15:55:05 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 10 Jun 2016 06:55:05 -0700
Subject: [R] New installation
In-Reply-To: <20160610093337.19163@web003.roc2.bluetie.com>
References: <20160610093337.19163@web003.roc2.bluetie.com>
Message-ID: <B3C2090D-5C96-495F-85B5-2F753BFA670F@dcn.davis.ca.us>

Re this thread: Please stop with the "my favorite Linux" messages. If you have concrete direction as to why R is well supported (preferably links to detailed instructions), that could be construed as "R-help", but "I like it" is unlikely to be useful to an inexperienced user.
-- 
Sent from my phone. Please excuse my brevity.

On June 10, 2016 6:33:37 AM PDT, ce <zadig_1 at excite.com> wrote:
>I use opensuse linux with R , no problems, easy to install, added R
>repositories . 
>
>-----Original Message-----
>From: "jax200" [jax200 at gmail.com]
>Date: 06/09/2016 06:00 PM
>To: r-help at r-project.org
>Subject: [R] New installation
>
>Hi
>
>I'm starting off with both R and Linux Mint.  During a recent R course,
>I
>had multiple difficulties with installing updates needed for the
>course.
>
>As such, I'd like to hit the restart button with fresh installs of
>Linux
>and R.  I would appreciate your help with which Linux platform works
>best
>with R, and how to go about getting all the updates installed for both
>programs.
>
>Many thanks,  Jack
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 10 16:13:41 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 10 Jun 2016 10:13:41 -0400
Subject: [R] save rgl.sphere plot
In-Reply-To: <1030458600.1560832.1465564461448.JavaMail.yahoo@mail.yahoo.com>
References: <1030458600.1560832.1465564461448.JavaMail.yahoo.ref@mail.yahoo.com>
	<1030458600.1560832.1465564461448.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6572AFB5-1C8D-40E6-9B2E-CB72D756F028@comcast.net>

http://stackoverflow.com/questions/7663982/r-using-rgl-to-generate-3d-rotatable-plots-that-can-be-viewed-in-a-web-browser

Sent from my iPhone

> On Jun 10, 2016, at 9:14 AM, ch.elahe via R-help <r-help at r-project.org> wrote:
> 
> Hi all 
> I have generated a 3D interactive rgl.sphere but I don't know how to save it to be viewed also interactive(being able to rotate it and do zoom-in and out). Does anyone know how should I save it?
> Thanks for any help!
> Elahe
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marceloperlin at gmail.com  Fri Jun 10 15:27:05 2016
From: marceloperlin at gmail.com (Marcelo Perlin)
Date: Fri, 10 Jun 2016 10:27:05 -0300
Subject: [R] About identification of CRAN CHECK machines in logs
In-Reply-To: <CABdHhvFrMN71pijg1nB+a_1LH_1HSLisq4cb8VGwPBdAx60cvw@mail.gmail.com>
References: <CANMhtdxg3vRLmv4si5edyexHmdgyOxAtExz8YbAXdOJ2xFm-Sw@mail.gmail.com>
	<CABdHhvFrMN71pijg1nB+a_1LH_1HSLisq4cb8VGwPBdAx60cvw@mail.gmail.com>
Message-ID: <CANMhtdwu_zVROLAj3nsYV3FgY8oYngVUpPdpUm8DA8j48J_xKw@mail.gmail.com>

I don't know Hadley. But you can see evidence of "something" systematically
installing the packages in the log data. From my two CRAN packages I
noticed a high correlation in the number of downloads.

Try the following script, which will pick 5 random packages from CRAN and
calculate the correlation matrix between their differenced number of
downloads. To avoid spurious correlations,  I removed the weekends since we
can expect some seasonality and also the zero entries. Its crude, I know,
but it does shows some positive associations between the number of
installations of the packages.

If not CRAN, who/what is downloading this packages and how can I set it
apart from the actual user installations?

Many thanks!

____
# get packages
df <- as.data.frame(available.packages())

# choose 5 random
idx <- sample(seq(nrow(df)))[1:5]
df<- df[idx,]

my.pkgs <- as.character(df$Package)

#my.pkgs <- c('RndTexExams','GetTDData')

dl.df <- cranlogs::cran_downloads(my.pkgs, from = '2015-01-01', to =
Sys.Date())

# remove zeros entries
dl.df$count[dl.df$count==0] <- NA

# remove weekends
dl.df$sat.sun <- as.POSIXlt(dl.df$date)$wday
dl.df <- dplyr::filter(dl.df, sat.sun != 0, sat.sun != 6)

# to wide (for corr)
dl.df <- tidyr::spread(dl.df, key = package,value = count)

# remove na
dl.df <- dl.df[complete.cases(dl.df), ]

diff.mat <- diff(as.matrix(dl.df[,3:ncol(dl.df)]))
cor(diff.mat)

___

On Thu, Jun 9, 2016 at 6:18 PM, Hadley Wickham <h.wickham at gmail.com> wrote:

> On Thu, Jun 9, 2016 at 9:24 AM, Marcelo Perlin <marceloperlin at gmail.com>
> wrote:
> > Hi,
> >
> > I recently released two packages (RndTexExams and GetTDData) in CRAN and
> > I'm trying to track the number of downloads and location of users.
> >
> > I wrote a simple script to download and analyze the log files in
> http://cran
> > -logs.rstudio.com.
> > I realized, however, that during the release of a new version of the
> > packages there is a spike in the number of downloads. I believe that the
> > CRAN checks are included in the number of installations of the package in
> > the log files.
>
> I don't think that's true. Why would CRAN be installing the package
> from a mirror?
>
> Hadley
>
> --
> http://hadley.nz
>



-- 
Marcelo Perlin
Professor Adjunto | Escola de Administra??o
Universidade Federal do Rio Grande do Sul
Rua Washington Luiz, 855 | 90010-460| Porto Alegre RS| Brasil
Tel.: (51) 3308-3303 | www.ea.ufrgs.br
http://lattes.cnpq.br/3262699324398819
https://sites.google.com/site/marceloperlin/

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Jun 10 16:17:46 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Jun 2016 10:17:46 -0400
Subject: [R] save rgl.sphere plot
In-Reply-To: <1030458600.1560832.1465564461448.JavaMail.yahoo@mail.yahoo.com>
References: <1030458600.1560832.1465564461448.JavaMail.yahoo.ref@mail.yahoo.com>
	<1030458600.1560832.1465564461448.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <cdeb7f90-bd4d-ea5d-794d-bc401c8ffbbb@gmail.com>

On 10/06/2016 9:14 AM, ch.elahe via R-help wrote:
> Hi all
> I have generated a 3D interactive rgl.sphere but I don't know how to save it to be viewed also interactive(being able to rotate it and do zoom-in and out). Does anyone know how should I save it?
> Thanks for any help!

I'd recommend using knitr and rglwidget.  For example, put this in 
example.Rmd:



---
title: "Example"
author: "Duncan Murdoch"
date: "June 10, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
options(rgl.useNULL = TRUE)
library(rgl)
library(rglwidget)
xyz <- matrix(rnorm(30), ncol = 3)
spheres3d(xyz, col = 1:10)
rglwidget()
```


and then in RStudio, click on "knit HTML".  If you don't use RStudio, 
you can run

rmarkdown::render("example.Rmd")

and then view the "example.html" file in your browser.

Duncan Murdoch


From wdunlap at tibco.com  Fri Jun 10 17:01:00 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 10 Jun 2016 08:01:00 -0700
Subject: [R] create an empty data frame and then fill in it (and then
 evaluate the mean of semi-hourly data for each day)
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBB763F@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBB763F@ESINO.regionemarche.intra>
Message-ID: <CAF8bMcZysX7iAL6iBf1sSf6dATQq6HGcM4E8td2qx1Q1JeP15g@mail.gmail.com>

Finally I applied lapply in this way:
df_snow_day$snow <- lapply(df_snow_day$day, function(x)
round(mean(df_snow$snow[df_snow$day == x], na.rm=T))

This does not work. I do not understand why the class of df_snow_day$snow
is of type list either:


lapply()'s output is always a list.

            I first created a new column of type "Date"
            df_snow$day <- as.Date(df_snow$data_POSIX,"%Y-%m-%d")

If 'date_POSIX' is of class "POSIXct" that line gives a warning because
the second argument to as.Data.POSIXct is the time zone ('tz').
Perhaps your data_POSIX column is really character.  I made my df_snow
as follows:

txt <- c("data_POSIX\tsnow",
  "2004-11-01 00:00:00\t50",
  "2004-11-01 00:30:00\t55",
 "2004-11-01 01:00:00\t60")
df_snow <- read.table(sep="\t", text=txt,header=TRUE,
colClasses=c("POSIXct","numeric"))
str(df_snow)
'data.frame':   3 obs. of  2 variables:
 $ data_POSIX: POSIXct, format: "2004-11-01 00:00:00" ...
 $ snow      : num  50 55 60

and as.Date gave:
   > as.Date(df_snow$data_POSIX,"%Y-%m-%d")
   [1] "2004-11-01" "2004-11-01" "2004-11-01"
   Warning message:
   In as.POSIXlt.POSIXct(x, tz = tz) : unknown timezone '%Y-%m-%d'

Also, converting POSIXct objects to Date objects is usually the wrong
thing to do, as the time zone in the POSIXct object is ignored (I think UTC
is assumed):
  > ct <- as.POSIXct(sprintf("2016-%02d-%02d %02d:%02d", 2:5, 22:25, 15:18,
45:48), tz="US/Pacific")
  > data.frame(ct,as.Date(ct)) # note day-of-month mismatches
                     ct as.Date.ct.
  1 2016-02-22 15:45:00  2016-02-22
  2 2016-03-23 16:46:00  2016-03-23
  3 2016-04-24 17:47:00  2016-04-25
  4 2016-05-25 18:48:00  2016-05-26
You can convert to a POSIXlt object and pull out the day-of-month
or day-of-year
  > as.POSIXlt(ct)$mday
  [1] 22 23 24 25
  > as.POSIXlt(ct)$yday
  [1]  52  82 114 145
I can never remember which helper functions are available
for this sort of thing.  Many people like the ones in the lubridate
package.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 10, 2016 at 3:45 AM, Stefano Sofia <
stefano.sofia at regione.marche.it> wrote:

> Thank you for your answer. Very clear.
> (I don't like the second solution either.)
> Let me then ask a final question.
> From an initial data frame with semi-hourly data (df_snow, with two
> columns, data_POSIX of type "POSIXct" "POSIXt" and snow of type "numeric"),
> I need to evaluate the mean of for each day.
>
> data_POSIX snow
> 2004-11-01 00:00:00 50
> 2004-11-01 00:30:00 55
> 2004-11-01 01:00:00 60
> ...
>
> I first created a new column of type "Date"
> df_snow$day <- as.Date(df_snow$data_POSIX,"%Y-%m-%d")
>
> then I created a new data frame called df_snow_day to store the mean of
> data grouped by day:
> list_days <- unique(df_snow$day)
> df_snow_day <- data.frame(day=list_days)
>
> Finally I applied lapply in this way:
> df_snow_day$snow <- lapply(df_snow_day$day, function(x)
> round(mean(df_snow$snow[df_snow$day == x], na.rm=T)))
>
> This does not work. I do not understand why the class of df_snow_day$snow
> is of type list either:
>
>        day snow
> NA    <NA>       NULL
> NA.1  <NA>       NULL
> NA.2  <NA>       NULL
>
> Where is my mistake?
>
> Thank you for all your help
> Stefano
>
>
> _____________________________________________
>
> Da: Duncan Murdoch [murdoch.duncan at gmail.com]
> Inviato: gioved? 9 giugno 2016 12.36
> A: Stefano Sofia; r-help at r-project.org
> Oggetto: Re: [R] create an empty data frame and then fill in it
>
> On 09/06/2016 6:22 AM, Stefano Sofia wrote:
> > Dear R list users,
> > sorry for this simple question, but I already spent many efforts to
> solve it.
> >
> > I create an empty data frame called df_year like
> >
> > df_year <- data.frame(day=as.Date(character()), hs_MteBove=integer(),
> hs_MtePrata=integer(), hs_Pintura=integer(), hs_Pizzo=integer(),
> hs_Sassotetto=integer(), hs_Sibilla=integer(), stringsAsFactors=FALSE)
> >
> > and then I start to fill in it with
> >
> > df_year$day <- seq(as.Date("2004-11-01-00-00","%Y-%m-%d"),
> as.Date("2005-05-01-00-00","%Y-%m-%d"), by="day")
> >
> > but I get the following error:
> > "replacement has 182 rows, data has 0"
> >
> > Where is my silly mistake?
>
> Your dataframe has 0 rows, so you can't put a 182 row vector into the
> first column.
>
> Unlike vectors, dataframes won't grow if you make assignments beyond the
> end of the rows.
>
> There are at least a couple of solutions:
>
> 1.  Don't create columns until you have data ready for them.
>
> You can wait to create the dataframe until your "day" column is ready:
>
> df_year <- data.frame(day = seq(...))
>
> As you compute other columns of the same length, you can add them, e.g.
>
> df_year$hs_MteBove <- ...
>
> 2.  Create your columns with the right length from the beginning:
>
> df_year <- data.frame(day = rep(as.Date(NA), 182), ...)
>
> I don't like this solution as much.
>
> Duncan Murdoch
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From leonardof at leonardof.med.br  Fri Jun 10 18:54:13 2016
From: leonardof at leonardof.med.br (Leonardo Fontenelle)
Date: Fri, 10 Jun 2016 13:54:13 -0300
Subject: [R] New installation
In-Reply-To: <m2shwlpm2h.fsf@krugs.de>
References: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
	<CAGxFJbR471Rj=3stgcdzDvdUbeefZGePR-PeEbB0y2AKyBoY8w@mail.gmail.com>
	<CA+vqiLFh7CzNqJC_Xz5YFTXo1w2onkSJQnCBsyJ7iNNiWKW-1A@mail.gmail.com>
	<1465516456.214873.633309809.52F4C9FD@webmail.messagingengine.com>
	<alpine.LRH.2.20.1606091724070.1083@aeolus.ecy.wa.gov>
	<m2shwlpm2h.fsf@krugs.de>
Message-ID: <1465577653.1844383.633994305.58D1735D@webmail.messagingengine.com>

Em Sex 10 jun. 2016, ?s 03:58, Rainer M Krug escreveu:
> Clint Bowman <clint at ecy.wa.gov> writes:
> 
> I am really wondering, why nobody mentioned Ubuntu so far?
> 
> Ubuntu is a really nice distro, I never had problems with it, many
> programs are available for Ubuntu, and it is build on Debian
> (stable). Don't worry about Unity Window manager - there are many other
> options available (Xubuntu being one of the better known ones - Ubuntu
> just packed with a different Windows Manager).
> 
> If you are new to Linux, I would really suggest Ubuntu.

I believe any major Linux distribution will provide decent support for
R, and I agree there are plenty of reasons for preferring Ubuntu or
other Linux distributions over Arch Linux. The reason why I suggested
Arch Linux was how up to date the package is, because that was the
motivation of the original post.

R 3.3.0 was released by the R Core Team on 2016-05-03, and on 2016-05-04
it was available in Arch Linux's "testing" repository. On 2016-05-17,
after at least one week with no (packaging) bug reports, the package was
moved to the "extra". This is the usual rhythm. Don't be fooled by the
repository name, it is the repository for popular software like Firefox,
GNOME and LibreOffice, and it is maintained by official Arch Linux
developers / package maintainers. 

Hope that helps,

Leonardo Ferreira Fontenelle


From mathewanalytics at gmail.com  Fri Jun 10 18:14:49 2016
From: mathewanalytics at gmail.com (Abraham Mathew)
Date: Fri, 10 Jun 2016 09:14:49 -0700
Subject: [R] Merging two data frame with different lengths
Message-ID: <CABbYsteQEn6+WqNbMbHHzdM+mmyOkYYdqF=0+xHUj91bf_c=eg@mail.gmail.com>

So I have two data frames.

The first one is a reccomendation data frame and the second is a melted
list with a pairing of OpportunityId's and ProductId's. There are multiple
product id's per an opportunty id. What I want to do is merge based on
ProductId so that I can add the OpportunityId to the reccomendation data
frame.

> head(product_neighbours_orig[,1:3],2)           ProductId   Reccomendation_1   Reccomendation_2
1 01t30000001ik30AAA 01ta0000005SivAAAS 01ta0000005RQimAAG
2 01t30000001ik3vAAA 01t30000001ik5bAAA 01t30000001ikKPAAY>
head(pd_melt[,1:3],2)          OpportunityId          ProductId value
4826 0063000000bqUKlAAM 01t30000001ik3vAAA     0
9651 0063000000bqUKlAAM 01t30000001ik41AAA     0





Any suggestions?

-- 


*Abraham MathewData Ninja and Statistical Modeler*



*Minneapolis, MN720-648-0108 at abmathewksAnalytics_Blog
<https://mathewanalytics.wordpress.com/>*

	[[alternative HTML version deleted]]


From jwd at surewest.net  Fri Jun 10 19:45:48 2016
From: jwd at surewest.net (John Dougherty)
Date: Fri, 10 Jun 2016 10:45:48 -0700
Subject: [R] New installation
In-Reply-To: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
References: <CAN=BHS33ofUrPuB=B48H86MQs9su8xjboK9timJ62hAP7opBeg@mail.gmail.com>
Message-ID: <20160610104548.5eaea56b@draco>

On Thu, 9 Jun 2016 13:44:52 -0700
jax200 <jax200 at gmail.com> wrote:

> Hi
> 
> I'm starting off with both R and Linux Mint.  During a recent R
> course, I had multiple difficulties with installing updates needed
> for the course.
> 
> As such, I'd like to hit the restart button with fresh installs of
> Linux and R.  I would appreciate your help with which Linux platform
> works best with R, and how to go about getting all the updates
> installed for both programs.
> 
> Many thanks,  Jack
> 
Any Linux distribution is likely to work well with R.  The chief hick-up
is keeping you R release up to date.  Typical linux releases including
Ubuntu, Opensuse and Fedora R versions available through their system
updates all tend to lag behind the R release version available on CRAN.
Asking for help will inevitably result in responders asking about the R
version you used, and, if it is significantly older than the current
version, you will be asked to update R and retry your problem
procedure.  That means that you will probably want to handle updating R
manually to remain current rather than rely on the Linux release
updating system.

JDougherty


From xavier.sumba93 at ucuenca.ec  Fri Jun 10 19:29:24 2016
From: xavier.sumba93 at ucuenca.ec (FRANCISCO XAVIER SUMBA TORAL)
Date: Fri, 10 Jun 2016 12:29:24 -0500
Subject: [R] Visualize Sparse Matrix.
In-Reply-To: <CA+8X3fUygaVZwuur0_krcSnTBLCN_ZZLtnFQ0WoSfUzYm0JLfQ@mail.gmail.com>
References: <6BAD2DF3-D978-4C70-B547-B78CCFC8DBD3@ucuenca.ec>
	<CA+8X3fUygaVZwuur0_krcSnTBLCN_ZZLtnFQ0WoSfUzYm0JLfQ@mail.gmail.com>
Message-ID: <F0E0D076-92C1-4F54-9806-82C052726E6F@ucuenca.ec>

Hi Jim,

Thanks for your answer. 

I try your code example, but it is basically the same that I had it. I want to visualise my matrix something like this image: 




With the graphics that I already have is difficult to visualise my data. I am getting this results:

1) With my first code, I got this:



2) With Jim?s code. I got this: 



Ho can I make my graphs more observable as in the first figure? My graphs shows points as if my screen was dirty. 

Cheers.



> On Jun 10, 2016, at 04:39, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Francisco,
> I tried this just to see if it would work. It did, after a while.
> 
> wtmat<-matrix(rnorm(4602*1817),nrow=4602)
> library(plotrix)
> x11(width=5,height=13)
> color2D.matplot(wtmat,c(1,1,0),c(0,1,0),0,border=FALSE)
> 
> Jim
> 
> On Fri, Jun 10, 2016 at 8:27 AM, FRANCISCO XAVIER SUMBA TORAL
> <xavier.sumba93 at ucuenca.ec> wrote:
>> Hi,
>> 
>> First of all, sorry for my question it could be so basic for a common user in R, but I am starting with this new environment.
>> 
>> I have done a clustering job and I would like to visualize my vectors. I have a matrix of TF-IDF weights of 4602 x 1817. I store the values in a CSV file. How can I visualize my vectors in a 2D-space?
>> 
>> After that, I execute a clustering algorithm and I got a label for each cluster. How can I visualize my vectors resulting base on a color or figure for each cluster?
>> 
>> This is the code that I am having trying to accomplish my graphs:
>> 
>> data <- read.csv(pathFile,header = FALSE, sep = ",?)
>> dMatrix <- matrix(unlist(data), ncol = 4602, byrow = TRUE) # Use a matrix to use melt.
>> # Graph my data
>> ggplot(melt(dMatrix), aes(Var1,Var2, fill=value)) + geom_raster() + scale_fill_gradient2(low='red', high=?black', mid=?white') + theme_bw() + xlab("x1") + ylab("x2")
>> 
>> 
>> Cheers.
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From hokut1 at yahoo.com  Fri Jun 10 21:27:40 2016
From: hokut1 at yahoo.com (oslo)
Date: Fri, 10 Jun 2016 19:27:40 +0000 (UTC)
Subject: [R] summing up and cut off with looping
References: <610812658.868411.1465586860497.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <610812658.868411.1465586860497.JavaMail.yahoo@mail.yahoo.com>

Hi all;
I am quite new in R. I have tried write a loop to sum up a column and cut off when summation reach certain point. Here are a small example and my R codes.
Your helps are truly appreciated,
Oslo
file=AposA posB1 ? ? 92 ? ? 75 ? ? 124 ? ? 79 ? ? 13. ? ?.?. ? ?. ??
File=Bpos ?a ?b ? c ? ?4 ? .4 ?7 ?.82 ? .1 ?5 ?.47 ?.5 ?8 ?.321 ? .4 ?1 ?.113 ?.1 ?6 ?.1312 ?.2 ?11 .019 ? .3 ?12 .23. ? ?. ? . ?.. ? ?. ? . ?.
I would like to sum up the B$a column and cut off at 0.7 for the each row of intervals giving in file=A.For example the interval??at the first row in A$posA and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from the 1 to 9 in B$pos. And then I need to the same using the intervals in the second, third..... rows in A. Obviously my loop is wrong and ?does not work properly. Please help for my this first experience. ?Thanks.
Here are my codes
#sorting B$possort=B[order(B$pos),]
#Running loop
for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }

	[[alternative HTML version deleted]]


From hokut1 at yahoo.com  Fri Jun 10 21:38:52 2016
From: hokut1 at yahoo.com (oslo)
Date: Fri, 10 Jun 2016 19:38:52 +0000 (UTC)
Subject: [R] Fw:  summing up and cut off with looping
In-Reply-To: <610812658.868411.1465586860497.JavaMail.yahoo@mail.yahoo.com>
References: <610812658.868411.1465586860497.JavaMail.yahoo.ref@mail.yahoo.com>
	<610812658.868411.1465586860497.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <38938924.853038.1465587532703.JavaMail.yahoo@mail.yahoo.com>

I am so sorry that the data in my previous file was very mass;Here are my data sets
> A? posA posB1 ? ?1 ? ?92 ? ?2 ? ?73 ? ?5 ? 124 ? ?4 ? ?75 ? ?9 ? 13>?
? pos ? a ?b ? ?c1 ? 4 0.4 ?7 0.802 ? 2 0.1 ?5 0.403 ? 7 0.5 ?8 0.324 ? 1 0.4 ?1 0.105 ?13 0.1 ?6 0.136 ?12 0.2 11 0.017 ? 9 0.3 12 0.23>?
 Hi all;
I am quite new in R. I have tried write a loop to sum up a column and cut off when summation reach certain point. Here are a small example and my R codes.
Your helps are truly appreciated,
Oslo

I would like to sum up the B$a column and cut off at 0.7 for the each row of intervals giving in file=A.For example the interval??at the first row in A$posA and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from the 1 to 9 in B$pos. And then I need to the same using the intervals in the second, third..... rows in A. Obviously my loop is wrong and ?does not work properly. Please help for my this first experience. ?Thanks.

Here are my codes
#sorting B$possort=B[order(B$pos),]
#Running loop
for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun 10 21:44:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 10 Jun 2016 12:44:54 -0700
Subject: [R] summing up and cut off with looping
In-Reply-To: <610812658.868411.1465586860497.JavaMail.yahoo@mail.yahoo.com>
References: <610812658.868411.1465586860497.JavaMail.yahoo.ref@mail.yahoo.com>
	<610812658.868411.1465586860497.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTMWBftiDCF9rmN8z38vWz8zV53pWHhP9eZKRhr6PFZ=A@mail.gmail.com>

1. Please read the posting guide (link below) to learn how to post
understandable questions -- at least I was not able to understand. In
particular, post in plain text, not html, which tends to get mangled
as seemed to occur here.

2. Your first stop in learning R should be one of the many fine
tutorials available on the web or even the "Intro to R" tutorial that
ships with R.  In particular, indexing in R using logical expressions
appears relevant to your query. Here is an example of what can be done
along the lines that I think you asked about -- hope it helps.
Apologies if I have misunderstood. See also ?subset and ?cumsum .


> set.seed(1021)

> y <- runif(10)

> y
 [1] 0.36751828 0.08721951 0.08899027 0.38838635 0.33331978 0.72948251
 [7] 0.36669151 0.28457792 0.90614056 0.31832515

> y[cumsum(y) < 1.2]
[1] 0.36751828 0.08721951 0.08899027 0.38838635


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 10, 2016 at 12:27 PM, oslo via R-help <r-help at r-project.org> wrote:
> Hi all;
> I am quite new in R. I have tried write a loop to sum up a column and cut off when summation reach certain point. Here are a small example and my R codes.
> Your helps are truly appreciated,
> Oslo
> file=AposA posB1     92     75     124     79     13.    . .    .
> File=Bpos  a  b   c    4   .4  7  .82   .1  5  .47  .5  8  .321   .4  1  .113  .1  6  .1312  .2  11 .019   .3  12 .23.    .   .  ..    .   .  .
> I would like to sum up the B$a column and cut off at 0.7 for the each row of intervals giving in file=A.For example the interval  at the first row in A$posA and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from the 1 to 9 in B$pos. And then I need to the same using the intervals in the second, third..... rows in A. Obviously my loop is wrong and  does not work properly. Please help for my this first experience.  Thanks.
> Here are my codes
> #sorting B$possort=B[order(B$pos),]
> #Running loop
> for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hokut1 at yahoo.com  Fri Jun 10 21:58:48 2016
From: hokut1 at yahoo.com (oslo)
Date: Fri, 10 Jun 2016 19:58:48 +0000 (UTC)
Subject: [R] summing up and cut off with looping
In-Reply-To: <CAGxFJbTMWBftiDCF9rmN8z38vWz8zV53pWHhP9eZKRhr6PFZ=A@mail.gmail.com>
References: <610812658.868411.1465586860497.JavaMail.yahoo.ref@mail.yahoo.com>
	<610812658.868411.1465586860497.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbTMWBftiDCF9rmN8z38vWz8zV53pWHhP9eZKRhr6PFZ=A@mail.gmail.com>
Message-ID: <966327781.844143.1465588728784.JavaMail.yahoo@mail.yahoo.com>

Hi Brent;
I do appreciate for your helps and advice. I already registered online to learn R. Today my second day. I think I could not explain my problem precisely. I have two file called A and B. A has to columns say posA and posB the values of the first row in A are 1 and 9, and?the values of the second row in A 2 and 7. In file B however I have pos, a, b,c columns, for example.? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? pos a ? b ? ? c?The first row of ? ? ? ? ? ? ? ? ?B ? ?4 ? ? 0.4 ? ?0.80the second column of the B ? ? 2 ? ? 0.1 ? 0.40
The third column of ? ? ? ? ?B ? ?13 ? ?0.5 ? ?0.32?
So?I would like to sum up the B$a column and cut off at 0.7 for the each row of intervals giving in file=A. ?Once again thanks so much.
regards,
Oslo
Here are my codes
#sorting B$possort=B[order(B$pos),]
#Running loop
for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }

    On Friday, June 10, 2016 3:44 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
 

 1. Please read the posting guide (link below) to learn how to post
understandable questions -- at least I was not able to understand. In
particular, post in plain text, not html, which tends to get mangled
as seemed to occur here.

2. Your first stop in learning R should be one of the many fine
tutorials available on the web or even the "Intro to R" tutorial that
ships with R.? In particular, indexing in R using logical expressions
appears relevant to your query. Here is an example of what can be done
along the lines that I think you asked about -- hope it helps.
Apologies if I have misunderstood. See also ?subset and ?cumsum .


> set.seed(1021)

> y <- runif(10)

> y
 [1] 0.36751828 0.08721951 0.08899027 0.38838635 0.33331978 0.72948251
 [7] 0.36669151 0.28457792 0.90614056 0.31832515

> y[cumsum(y) < 1.2]
[1] 0.36751828 0.08721951 0.08899027 0.38838635


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 10, 2016 at 12:27 PM, oslo via R-help <r-help at r-project.org> wrote:
> Hi all;
> I am quite new in R. I have tried write a loop to sum up a column and cut off when summation reach certain point. Here are a small example and my R codes.
> Your helps are truly appreciated,
> Oslo
> file=AposA posB1? ? 92? ? 75? ? 124? ? 79? ? 13.? ? . .? ? .
> File=Bpos? a? b? c? ? 4? .4? 7? .82? .1? 5? .47? .5? 8? .321? .4? 1? .113? .1? 6? .1312? .2? 11 .019? .3? 12 .23.? ? .? .? ..? ? .? .? .
> I would like to sum up the B$a column and cut off at 0.7 for the each row of intervals giving in file=A.For example the interval? at the first row in A$posA and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from the 1 to 9 in B$pos. And then I need to the same using the intervals in the second, third..... rows in A. Obviously my loop is wrong and? does not work properly. Please help for my this first experience.? Thanks.
> Here are my codes
> #sorting B$possort=B[order(B$pos),]
> #Running loop
> for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From hokut1 at yahoo.com  Fri Jun 10 22:34:03 2016
From: hokut1 at yahoo.com (oslo)
Date: Fri, 10 Jun 2016 20:34:03 +0000 (UTC)
Subject: [R] summing up a column.
References: <31785661.876929.1465590843856.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>

Dear All;
I had difficulty to post a mail along with appropriate of data structure. I do sincerely apologize for multiple posting


I would like to sum up the B$a column and cut off at 0.7 for the each row of intervals giving in file=A.For example the interval??at the first row in A$posA and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from the 1 to 9 in B$pos. And then I need to the same using the intervals in the second, third..... rows in A. Obviously my loop is wrong and ?does not work properly. Please help for my this first experience. ?Regards
Here are my codes
#sorting B$possort=B[order(B$pos),]
#Running loop
for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }
Reply,?R
-------------- next part --------------
A non-text attachment was scrubbed...
Name: blob.jpg
Type: image/png
Size: 7564 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160610/0e63a506/attachment.png>

From jdnewmil at dcn.davis.ca.us  Fri Jun 10 23:02:12 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 10 Jun 2016 14:02:12 -0700
Subject: [R] summing up a column.
In-Reply-To: <31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>
References: <31785661.876929.1465590843856.JavaMail.yahoo.ref@mail.yahoo.com>
	<31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <FCDDB5B3-2D68-4BE7-AD53-4FB3AA9C2861@dcn.davis.ca.us>

Multiple posting happens when you are learning a new system, but reading the posting guide can keep the bleeding down. 

1) There is a no-homework policy on this list... different educational organizations have different standards for what is acceptable outside help, so you should be using the support offered by your instructor or educational institution. 

2) Once you have completed your course,  you CAN learn to post data with your code so that it is self-contained... that is,  reproducible on our vanilla R session. Using the dput function is one excellent strategy. 

3) This is not a problem that needs a loop... as Bert (not Bret) said, you can do this in one or two statements if you simply use basic logical indexing. If your instructor wants you to do it with a loop for sine reason then you really really should not be here... you should be talking to him/her.
-- 
Sent from my phone. Please excuse my brevity.

On June 10, 2016 1:34:03 PM PDT, oslo via R-help <r-help at r-project.org> wrote:
>Dear All;
>I had difficulty to post a mail along with appropriate of data
>structure. I do sincerely apologize for multiple posting
>
>
>I would like to sum up the B$a column and cut off at 0.7 for the each
>row of intervals giving in file=A.For example the interval??at the
>first row in A$posA and A$posB is 1 and 9. So, I need adding up the B$a
>and cut off B$a>.7 from the 1 to 9 in B$pos. And then I need to the
>same using the intervals in the second, third..... rows in A. Obviously
>my loop is wrong and ?does not work properly. Please help for my this
>first experience. ?Regards
>Here are my codes
>#sorting B$possort=B[order(B$pos),]
>#Running loop
>for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }
>Reply,?R
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From hokut1 at yahoo.com  Fri Jun 10 23:06:35 2016
From: hokut1 at yahoo.com (oslo)
Date: Fri, 10 Jun 2016 21:06:35 +0000 (UTC)
Subject: [R] summing up a column.
In-Reply-To: <FCDDB5B3-2D68-4BE7-AD53-4FB3AA9C2861@dcn.davis.ca.us>
References: <31785661.876929.1465590843856.JavaMail.yahoo.ref@mail.yahoo.com>
	<31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>
	<FCDDB5B3-2D68-4BE7-AD53-4FB3AA9C2861@dcn.davis.ca.us>
Message-ID: <764714753.876287.1465592795459.JavaMail.yahoo@mail.yahoo.com>

Jeff thanks for this. My question was job related. No from my course. I need finish a job for the place I work. I am so sorry for causing misunderstanding.
thanks,
Oslo 

    On Friday, June 10, 2016 5:02 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
 

 Multiple posting happens when you are learning a new system, but reading the posting guide can keep the bleeding down. 

1) There is a no-homework policy on this list... different educational organizations have different standards for what is acceptable outside help, so you should be using the support offered by your instructor or educational institution. 

2) Once you have completed your course, you CAN learn to post data with your code so that it is self-contained... that is, reproducible on our vanilla R session. Using the dput function is one excellent strategy. 

3) This is not a problem that needs a loop... as Bert (not Bret) said, you can do this in one or two statements if you simply use basic logical indexing. If your instructor wants you to do it with a loop for sine reason then you really really should not be here... you should be talking to him/her.
-- 
Sent from my phone. Please excuse my brevity.

On June 10, 2016 1:34:03 PM PDT, oslo via R-help <r-help at r-project.org> wrote:
Dear All;
I had difficulty to post a mail along with appropriate of data structure. I do sincerely apologize for multiple posting


I would like to sum up the B$a column and cut off at 0.7 for the each row of intervals giving in file=A.For example the interval??at the first row in A$posA and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from the 1 to 9 in B$pos. And then I need to the same using the intervals in the second, third..... rows in A. Obviously my loop is wrong and ?does not work properly. Please help for my this first experience. ?Regards
Here are my codes
#sorting B$possort=B[order(B$pos),]
#Running loop
for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }
Reply,?R
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From hokut1 at yahoo.com  Fri Jun 10 23:08:42 2016
From: hokut1 at yahoo.com (oslo)
Date: Fri, 10 Jun 2016 21:08:42 +0000 (UTC)
Subject: [R] summing up a column.
In-Reply-To: <764714753.876287.1465592795459.JavaMail.yahoo@mail.yahoo.com>
References: <31785661.876929.1465590843856.JavaMail.yahoo.ref@mail.yahoo.com>
	<31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>
	<FCDDB5B3-2D68-4BE7-AD53-4FB3AA9C2861@dcn.davis.ca.us>
	<764714753.876287.1465592795459.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <542840655.919423.1465592922434.JavaMail.yahoo@mail.yahoo.com>

Jeff;
?thanks for this. My question was job related. No from my course. I need finish a job for the place I work. I am so sorry for causing misunderstanding.
thanks,
Oslo 

    On Friday, June 10, 2016 5:08 PM, oslo via R-help <r-help at r-project.org> wrote:
 

 Jeff thanks for this. My question was job related. No from my course. I need finish a job for the place I work. I am so sorry for causing misunderstanding.
thanks,
Oslo 

? ? On Friday, June 10, 2016 5:02 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
 

 Multiple posting happens when you are learning a new system, but reading the posting guide can keep the bleeding down. 

1) There is a no-homework policy on this list... different educational organizations have different standards for what is acceptable outside help, so you should be using the support offered by your instructor or educational institution. 

2) Once you have completed your course, you CAN learn to post data with your code so that it is self-contained... that is, reproducible on our vanilla R session. Using the dput function is one excellent strategy. 

3) This is not a problem that needs a loop... as Bert (not Bret) said, you can do this in one or two statements if you simply use basic logical indexing. If your instructor wants you to do it with a loop for sine reason then you really really should not be here... you should be talking to him/her.
-- 
Sent from my phone. Please excuse my brevity.

On June 10, 2016 1:34:03 PM PDT, oslo via R-help <r-help at r-project.org> wrote:
Dear All;
I had difficulty to post a mail along with appropriate of data structure. I do sincerely apologize for multiple posting


I would like to sum up the B$a column and cut off at 0.7 for the each row of intervals giving in file=A.For example the interval??at the first row in A$posA and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from the 1 to 9 in B$pos. And then I need to the same using the intervals in the second, third..... rows in A. Obviously my loop is wrong and ?does not work properly. Please help for my this first experience. ?Regards
Here are my codes
#sorting B$possort=B[order(B$pos),]
#Running loop
for(i in 1:nrow(A)) {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } }
Reply,?R
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Sat Jun 11 00:42:44 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Sat, 11 Jun 2016 01:42:44 +0300
Subject: [R] Error nmf - Input matrix x contains at least one null or
 NA-filled row
In-Reply-To: <DUB125-W73E57762084E941D4E671EB35F0@phx.gbl>
References: <DUB125-W4DA8E8879CDC6FD60DFE7B35F0@phx.gbl>,
	<DUB125-W73E57762084E941D4E671EB35F0@phx.gbl>
Message-ID: <DUB125-W709D50498091857FB5B64CB3500@phx.gbl>

? Dear group,
? kindly I am trying to factorize document term matrix via NMF and got the following Error?
show up

Error: NMF::nmf - 2/2 fit(s) threw an error.
# Error(s) thrown:
? - run #1: NMF::nmf - Input matrix x contains at least one null or NA-filled row.

when I partition the matrix it works till I reached the last 10 rows ..they have a problem that I do not know

the fitting line is ??fit<-nmf((dtmm[90:100,]), 4, "lee", nrun=2)?
And
the matrix is 100 row ..so the last 10 rows that make the problem are as follows:
dtm.sample <- dput(dtmm[90:100,])
structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,?
0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,?
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
), .Dim = c(11L, 475L), .Dimnames = structure(list(Docs = c("90",?
"91", "92", "93", "94", "95", "96", "97", "98", "99", "100"),?
? ? Terms = c("???dawlah???", "????????????????????????????????????" ? ? ? ? ? ? ? ? ? ? ? ? ,?
? ? "????????????????????????????????????" ? ? ? ? ?, "abdullah",?
? ? "abo", "abu", "acc", "accept", "account", "actual", "administr",?
? ? "adnani", "advanc", "advic", "akh", "akhi", "alaykum", "aleppo",?
? ? "aljusiya", "allah", "allow", "almost", "alqaa", "alqaeda",?
? ? "alshabaab", "although", "ameen", "amisom", "amp", "anorsmte2sbtltsm8s8",?
? ? "anybodi", "apost", "aqap", "area", "armi", "aslm", "assad",?
? ? "asse", "attack", "attacksharvest", "audio", "avail", "??9th",?
? ? "baathist", "back", "baghdadi", "baiji", "bakeri", "barakallahu",?
? ? "battali", "battl", "bayah", "beat", "beehiv", "behalf",?
? ? "behind", "best", "biggest", "bless", "blood", "border",?
? ? "bought", "boy", "break", "brighten", "brother", "busi",?
? ? "bywith", "came", "cant", "capit", "carri", "chang", "channel",?
? ? "circl", "circumst", "citi", "citizen", "civilian", "claim",?
? ? "clarif", "clip", "collect", "comb", "come", "comment", "complet",?
? ? "confirm", "control", "countri", "countrysid", "crimin",?
? ? "cub", "currenc", "damascus", "dawah", "dawlah", "day", "death",?
? ? "declar", "definit", "dez1", "dialogu", "didnt", "disbeliev",?
? ? "dislik", "distribut", "divis", "doesnt", "doma", "downaqapth",?
? ? "download", "drastic", "???", "e58qi7sl7uu", "either", "els",?
? ? "encircl", "eng", "english", "enter", "etc", "ever", "everi",?
? ? "except", "face", "farrida", "fatih", "feekum", "fight",?
? ? "fighter", "finish", "first", "franc", "frontlin", "fsa",?
? ? "????", "general", "generat", "give", "god", "goe", "gold",?
? ? "great", "group", "half", "haqq", "harvest", "hasan", "hashd",?
? ? "hassan", "hazm", "hea", "headlock", "help", "hes", "hijrah",?
? ? "histori", "hiwar", "hold", "holi", "hom", "honey", "htt",?
? ? "ifnobodi", "imamah", "imarah", "impoant", "infight", "inshallah",?
? ? "integr", "intervenerad", "introduct", "iraq", "is2", "iseasi",?
? ? "islam", "islamicst", "isra", "jan13", "jannaal", "jannal",?
? ? "jawlani", "jazakallahu", "jihad", "job", "joedanianauthor",?
? ? "jordanian", "jurud", "just", "justic", "kid", "kill", "kilometr",?
? ? "knight", "know", "knw", "konkur", "kuffar", "kuwaiti", "lago",?
? ? "last", "leader", "leaflet", "leav", "lebanon", "lego", "let",?
? ? "libya", "like", "link", "live", "love", "made", "make",?
? ? "maqdisi", "march", "marea", "mari", "massiv", "may", "measur",?
? ? "meet", "messag", "militari", "militia", "missil", "mojahdin",?
? ? "mosqu", "mubahala", "muhajireen4", "muham", "mujahideen",?
? ? "murabit", "muslim", "nabi", "nam", "nasir", "nationalist",?
? ? "never", "new", "news", "nigeria", "nohaleppo", "noth", "noufaliy",?
? ? "now", "nusra", "occupi", "one", "ongo", "oni", "???", "????",?
? ? "?????????", "?????", "?????", "?????" ? ? , "????????",?
? ? "????", "??????", "??????" ? ? , "?????????", "????????",?
? ? "???????", "??????", "?????", "???????", "?????????????",?
? ? "?????", "??????", "??????????????", "???", "????", "????????????????????????????????????????????????????" ? ? ? ? ? ? ? ? ? ? ? ? ,?
? ? "????????????????" ? ? , "???????", "????", "????", "??????????",?
? ? "????????", "??????????", "??????????????", "?????????",?
? ? "???????????1436919", "??????????", "?????????", "??????????" ? ? ,?
? ? "????????", "??????????" ? ? , "?????????", "????????", "???????",?
? ? "?????????????????????", "????????", "??????????", "???????",?
? ? "??????", "?????????", "???", "?????", "??????", "????????",?
? ? "??????" ? ? , "????", "?????", "????????", "pa2condit",?
? ? "paicip", "palestinian", "pamphlet", "path", "peopl", "petraeus",?
? ? "photo", "pleas", "pls", "poor", "popular", "post", "power",?
? ? "previous", "promis", "provid", "punish", "qusayr", "raid",?
? ? "raqqa", "raqqah", "regard", "releas", "rememb", "repeat",?
? ? "repo", "respons", "returnofthegolddinar", "reveng", "rule",?
? ? "russia", "sacrific", "saddamistseven", "safavid", "sahawat",?
? ? "sake", "salamu", "salvat", "samra", "saudi", "save", "saw",?
? ? "say", "sayna", "scholar", "second", "secur", "see", "select",?
? ? "seri", "shami", "shar?", "share", "sheikh", "shiit", "side",?
? ? "sinai", "sister", "soldier", "somalia", "soon", "sooninshaallah",?
? ? "spill", "spread", "srf", "sta", "state", "statement", "still",?
? ? "sub", "subtitl", "sultan", "sunnisthey", "suppo", "suspend",?
? ? "syria", "syrian", "syriasheikh", "takbirrr", "take", "taken",?
? ? "takfir", "talk", "taoosi", "tear", "tell", "ten", "the3",?
? ? "today", "tomorrow", "took", "top", "toward", "town", "tptcosnakcqb7mrstftw",?
? ? "transcriptoh", "translat", "translation??", "tripoli", "true",?
? ? "truth", "tweet", "????????", "?????", "??????????????",?
? ? "???????????????", "????????", "????????", "?????????", "???????????",?
? ? "????????" ? ? , "???????", "?????????", "?????", "??????????????????" ? ? ,?
? ? "????", "????????" ? ? , "?????" ? ? , "??????????" ? ? ,?
? ? "??????????" ? ? , "????" ? ? , "??????" ? ? , "ukh", "ukhti",?
? ? "ulama", "umayyad", "??????", "????" ? ? , "updf", "use",?
? ? "ustrain", "????????", "???", "???", "?????", "?????", "???",?
? ? "vanish", "victori", "video", "videoeng", "videorejoic",?
? ? "videoth", "villag", "viral", "watch", "way", "week", "west",?
? ? "wilayat", "wilayatalfallujah", "wilayatalfurat", "wilayataljazirah",?
? ? "wilayatbarqah", "wilayatsalahuddin", "wilayatsayna", "wilayet",?
? ? "will", "wlaya", "wont", "word", "wuhayshi", "yarmouk", "yearsdayniil",?
? ? "yurkud", "zone", "zubayr")), .Names = c("Docs", "Terms")))

kindly I do not know why it do not work for those rwos?
example of working rows is the same matrix head

dtm.sample2 <- dput(head( dtmm))
structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,?
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,?
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(6L,?
475L), .Dimnames = structure(list(Docs = c("1", "2", "3", "4",?
"5", "6"), Terms = c("???dawlah???", "????????????????????????????????????" ? ? ? ? ? ? ? ? ? ? ? ? ,?
"????????????????????????????????????" ? ? ? ? ?, "abdullah",?
"abo", "abu", "acc", "accept", "account", "actual", "administr",?
"adnani", "advanc", "advic", "akh", "akhi", "alaykum", "aleppo",?
"aljusiya", "allah", "allow", "almost", "alqaa", "alqaeda", "alshabaab",?
"although", "ameen", "amisom", "amp", "anorsmte2sbtltsm8s8",?
"anybodi", "apost", "aqap", "area", "armi", "aslm", "assad",?
"asse", "attack", "attacksharvest", "audio", "avail", "??9th",?
"baathist", "back", "baghdadi", "baiji", "bakeri", "barakallahu",?
"battali", "battl", "bayah", "beat", "beehiv", "behalf", "behind",?
"best", "biggest", "bless", "blood", "border", "bought", "boy",?
"break", "brighten", "brother", "busi", "bywith", "came", "cant",?
"capit", "carri", "chang", "channel", "circl", "circumst", "citi",?
"citizen", "civilian", "claim", "clarif", "clip", "collect",?
"comb", "come", "comment", "complet", "confirm", "control", "countri",?
"countrysid", "crimin", "cub", "currenc", "damascus", "dawah",?
"dawlah", "day", "death", "declar", "definit", "dez1", "dialogu",?
"didnt", "disbeliev", "dislik", "distribut", "divis", "doesnt",?
"doma", "downaqapth", "download", "drastic", "???", "e58qi7sl7uu",?
"either", "els", "encircl", "eng", "english", "enter", "etc",?
"ever", "everi", "except", "face", "farrida", "fatih", "feekum",?
"fight", "fighter", "finish", "first", "franc", "frontlin", "fsa",?
"????", "general", "generat", "give", "god", "goe", "gold", "great",?
"group", "half", "haqq", "harvest", "hasan", "hashd", "hassan",?
"hazm", "hea", "headlock", "help", "hes", "hijrah", "histori",?
"hiwar", "hold", "holi", "hom", "honey", "htt", "ifnobodi", "imamah",?
"imarah", "impoant", "infight", "inshallah", "integr", "intervenerad",?
"introduct", "iraq", "is2", "iseasi", "islam", "islamicst", "isra",?
"jan13", "jannaal", "jannal", "jawlani", "jazakallahu", "jihad",?
"job", "joedanianauthor", "jordanian", "jurud", "just", "justic",?
"kid", "kill", "kilometr", "knight", "know", "knw", "konkur",?
"kuffar", "kuwaiti", "lago", "last", "leader", "leaflet", "leav",?
"lebanon", "lego", "let", "libya", "like", "link", "live", "love",?
"made", "make", "maqdisi", "march", "marea", "mari", "massiv",?
"may", "measur", "meet", "messag", "militari", "militia", "missil",?
"mojahdin", "mosqu", "mubahala", "muhajireen4", "muham", "mujahideen",?
"murabit", "muslim", "nabi", "nam", "nasir", "nationalist", "never",?
"new", "news", "nigeria", "nohaleppo", "noth", "noufaliy", "now",?
"nusra", "occupi", "one", "ongo", "oni", "???", "????", "?????????",?
"?????", "?????", "?????" ? ? , "????????", "????", "??????",?
"??????" ? ? , "?????????", "????????", "???????", "??????",?
"?????", "???????", "?????????????", "?????", "??????", "??????????????",?
"???", "????", "????????????????????????????????????????????????????" ? ? ? ? ? ? ? ? ? ? ? ? ,?
"????????????????" ? ? , "???????", "????", "????", "??????????",?
"????????", "??????????", "??????????????", "?????????", "???????????1436919",?
"??????????", "?????????", "??????????" ? ? , "????????", "??????????" ? ? ,?
"?????????", "????????", "???????", "?????????????????????",?
"????????", "??????????", "???????", "??????", "?????????", "???",?
"?????", "??????", "????????", "??????" ? ? , "????", "?????",?
"????????", "pa2condit", "paicip", "palestinian", "pamphlet",?
"path", "peopl", "petraeus", "photo", "pleas", "pls", "poor",?
"popular", "post", "power", "previous", "promis", "provid", "punish",?
"qusayr", "raid", "raqqa", "raqqah", "regard", "releas", "rememb",?
"repeat", "repo", "respons", "returnofthegolddinar", "reveng",?
"rule", "russia", "sacrific", "saddamistseven", "safavid", "sahawat",?
"sake", "salamu", "salvat", "samra", "saudi", "save", "saw",?
"say", "sayna", "scholar", "second", "secur", "see", "select",?
"seri", "shami", "shar?", "share", "sheikh", "shiit", "side",?
"sinai", "sister", "soldier", "somalia", "soon", "sooninshaallah",?
"spill", "spread", "srf", "sta", "state", "statement", "still",?
"sub", "subtitl", "sultan", "sunnisthey", "suppo", "suspend",?
"syria", "syrian", "syriasheikh", "takbirrr", "take", "taken",?
"takfir", "talk", "taoosi", "tear", "tell", "ten", "the3", "today",?
"tomorrow", "took", "top", "toward", "town", "tptcosnakcqb7mrstftw",?
"transcriptoh", "translat", "translation??", "tripoli", "true",?
"truth", "tweet", "????????", "?????", "??????????????", "???????????????",?
"????????", "????????", "?????????", "???????????", "????????" ? ? ,?
"???????", "?????????", "?????", "??????????????????" ? ? , "????",?
"????????" ? ? , "?????" ? ? , "??????????" ? ? , "??????????" ? ? ,?
"????" ? ? , "??????" ? ? , "ukh", "ukhti", "ulama", "umayyad",?
"??????", "????" ? ? , "updf", "use", "ustrain", "????????",?
"???", "???", "?????", "?????", "???", "vanish", "victori", "video",?
"videoeng", "videorejoic", "videoth", "villag", "viral", "watch",?
"way", "week", "west", "wilayat", "wilayatalfallujah", "wilayatalfurat",?
"wilayataljazirah", "wilayatbarqah", "wilayatsalahuddin", "wilayatsayna",?
"wilayet", "will", "wlaya", "wont", "word", "wuhayshi", "yarmouk",?
"yearsdayniil", "yurkud", "zone", "zubayr")), .Names = c("Docs",?
"Terms")))

?thanks in advance
Ragia 		 	   		  

From drjimlemon at gmail.com  Sat Jun 11 00:56:00 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 11 Jun 2016 08:56:00 +1000
Subject: [R] Visualize Sparse Matrix.
In-Reply-To: <F0E0D076-92C1-4F54-9806-82C052726E6F@ucuenca.ec>
References: <6BAD2DF3-D978-4C70-B547-B78CCFC8DBD3@ucuenca.ec>
	<CA+8X3fUygaVZwuur0_krcSnTBLCN_ZZLtnFQ0WoSfUzYm0JLfQ@mail.gmail.com>
	<F0E0D076-92C1-4F54-9806-82C052726E6F@ucuenca.ec>
Message-ID: <CA+8X3fVBFKmf7YWn-W1cdhXY_UNPVi8yaM5GrChvgyYYmc419g@mail.gmail.com>

Hi Francisco,
Your example plot shows me what you want to do (I think). I'm guessing that
you want to display the values in your matrix that are NOT zero or NA,
either colored in some way, or just in one color as the example. The
following example shows how to do both of these:

# wtmat<-matrix(rnorm(4602*1817),nrow=4602)
# use a smaller matrix to illustrate the principle
wtmat<-matrix(rnorm(46*18),nrow=46)
# make it "sparse" by taking out all small values
# in your case this may be changing all zero values to NS
wtmat[abs(wtmat)<1]<-NA
library(plotrix)
x11(width=5,height=13)
# display all values in the matrix
# colored as red->white (negative values), white (NA)
# and white->black (positive values)
color2D.matplot(wtmat,c(1,1,0),c(0,1,0),c(0,1,0),border=FALSE)
# now do a plot just showing values that are not NA
color2D.matplot(abs(wtmat),extremes=c(4,4),border=FALSE)

My original example also looked "dirty", albeit colorful, because there
were so many rectangles on it. With a PDF plot about 500mm high you can see
the individual rectangles in a matrix plot of your original dimensions.

Jim


On Sat, Jun 11, 2016 at 3:29 AM, FRANCISCO XAVIER SUMBA TORAL <
xavier.sumba93 at ucuenca.ec> wrote:

> Hi Jim,
>
> Thanks for your answer.
>
> I try your code example, but it is basically the same that I had it. I
> want to visualise my matrix something like this image:
>
> snipped
>

	[[alternative HTML version deleted]]


From j.bayat194 at gmail.com  Sat Jun 11 07:40:23 2016
From: j.bayat194 at gmail.com (javad bayat)
Date: Sat, 11 Jun 2016 10:10:23 +0430
Subject: [R] How to get bathymetry data using R
Message-ID: <CANTxAmLTRUqHA-1_n8S0pBd-2oB75Fod0vGj9G7SKOdkyUF-YQ@mail.gmail.com>

Dear R users;
I am searching for a package to extract bathymetry data from topography map
to produce the control file for CE-Qual-w2 model.
Is there anyone to know how to do it?
many thanks.

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Sat Jun 11 09:30:34 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 11 Jun 2016 07:30:34 +0000
Subject: [R] How to get bathymetry data using R
In-Reply-To: <CANTxAmLTRUqHA-1_n8S0pBd-2oB75Fod0vGj9G7SKOdkyUF-YQ@mail.gmail.com>
References: <CANTxAmLTRUqHA-1_n8S0pBd-2oB75Fod0vGj9G7SKOdkyUF-YQ@mail.gmail.com>
Message-ID: <CAAcGz98QPwQzvfH69oe8QkWG89q5uQfqpnHFw7Obj0dn16p3aA@mail.gmail.com>

On Sat, 11 Jun 2016 at 15:43 javad bayat <j.bayat194 at gmail.com> wrote:

> Dear R users;
> I am searching for a package to extract bathymetry data from topography map
> to produce the control file for CE-Qual-w2 model.
> Is there anyone to know how to do it?
> many thanks.
>
>
There are few things around but I highly recommend find your own data
source, suitable for your purpose - and reading it directly with the raster
package.  If anyone knows a reliable source I'd like to hear it.

As a global go-to I use Etopo1, but you may want some more detailed (like
Gebco 2014) or a non-global one. (I can't tell where you need this for or
what resolution would be suitable from what you've asked though).

(The best format when you get a choice generally is GeoTIFF, but it depends
who creates them. I tend to use the NetCDF files from Etopo).

Raster uses rgdal for many formats, but ncdf4 exclusively for NetCDF - if
it's not called "*.nc" you can get around that).

Cheers, Mike.



> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Sat Jun 11 13:27:50 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 11 Jun 2016 11:27:50 +0000
Subject: [R] AR1 model using ARIMA
Message-ID: <e988f50ad0f1400b9c9095e4197f2d4f@ex13-live-mbn1.ad.kent.ac.uk>

Dear R users,
I am trying to run a rolling window AR1 model by combining the rollapply() with the arima() function. Hence, my code looks as follows:

rollingarma<-rollapply(data,width=36,function(data) coef(arima(data,order=c(1,0,0))))
Error in arima(data, order = c(1, 0, 0)) :
  non-stationary AR part from CSS

However, what is wrong with my code?

Can I use the arma() function as alternative? In this case the code is


rollingarma<-rollapply(data,width=36,function(data) coef(arma(data,order=c(1,0),include.intercept = FALSE)))

There were 50 or more warnings (use warnings() to see the first 50)

> warnings()

Warning messages:

1: In optim(coef, err, gr = NULL, hessian = TRUE, ...) :

  one-dimensional optimization by Nelder-Mead is unreliable:

use "Brent" or optimize() directly

In this case, I get a warning message. How can I use Brent or optimize in this code?

Thanks for your support.

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Sat Jun 11 18:09:18 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 11 Jun 2016 09:09:18 -0700
Subject: [R] How to get bathymetry data using R
In-Reply-To: <CAAcGz98QPwQzvfH69oe8QkWG89q5uQfqpnHFw7Obj0dn16p3aA@mail.gmail.com>
References: <CANTxAmLTRUqHA-1_n8S0pBd-2oB75Fod0vGj9G7SKOdkyUF-YQ@mail.gmail.com>
	<CAAcGz98QPwQzvfH69oe8QkWG89q5uQfqpnHFw7Obj0dn16p3aA@mail.gmail.com>
Message-ID: <BF9A46D1-C4E8-4602-82AE-42207FE38BAF@noaa.gov>

Use the ?rerddap? package that accesses our ERDDAP server.  You can see the data available at:

http://upwell.pfeg.noaa.gov/erddap

In the search box type in ?bathymetry?.    You can subset as you want, using ?rerddap? you get back a netcdf file that is already read into your R workspace,  or you can write your own 2 lines of code  (since the URL completely defines the request) and get the data back in any number of file formats.  I don?t want to get into a format war, but for large gridded datasets like this I much prefer netcdf files.

If you have any questions at all about either the ?rerddap? package  (developed by the wonderful people at ROpenSci) or about our ERDDAP service, don?t hesitate to ask.

-Roy

> On Jun 11, 2016, at 12:30 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> 
> On Sat, 11 Jun 2016 at 15:43 javad bayat <j.bayat194 at gmail.com> wrote:
> 
>> Dear R users;
>> I am searching for a package to extract bathymetry data from topography map
>> to produce the control file for CE-Qual-w2 model.
>> Is there anyone to know how to do it?
>> many thanks.
>> 
>> 
> There are few things around but I highly recommend find your own data
> source, suitable for your purpose - and reading it directly with the raster
> package.  If anyone knows a reliable source I'd like to hear it.
> 
> As a global go-to I use Etopo1, but you may want some more detailed (like
> Gebco 2014) or a non-global one. (I can't tell where you need this for or
> what resolution would be suitable from what you've asked though).
> 
> (The best format when you get a choice generally is GeoTIFF, but it depends
> who creates them. I tend to use the NetCDF files from Etopo).
> 
> Raster uses rgdal for many formats, but ncdf4 exclusively for NetCDF - if
> it's not called "*.nc" you can get around that).
> 
> Cheers, Mike.
> 
> 
> 
>> --
>> Best Regards
>> Javad Bayat
>> M.Sc. Environment Engineering
>> Alternative Mail: bayat194 at yahoo.com
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> -- 
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From suparna.mitra.sm at gmail.com  Sat Jun 11 19:46:22 2016
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Sat, 11 Jun 2016 18:46:22 +0100
Subject: [R] Writing multiple adonis output from multiple list file in R
Message-ID: <CAFdg=fU_Vt2DBKoT0cujLn8U1vOXSZjPqKuAUePGgpGbGO-XPA@mail.gmail.com>

Hello R experts,
  I am trying to do adonis (vegan package) on multiple files using loop.
But I am having hard time in this.
Here is what I tried.

setwd("PATH")
files <- list.files(pattern = "[.]txt$")
ldf <- lapply(files, read.table, row.names=1)
str(ldf)
res <- lapply(ldf, summary)
 for (i in length(res))
{Addon[[i]]<-adonis(vegdist(t(ldf[[i]]))~Factor)
}
print(i)

But obviously this is not working.
Until the list it works fine. Also if I test with
print(adonis(vegdist(t(ldf[[1]]))~Factor)), this also provised correct
result.
But specifying the Addon[[i]], is something wrong. Please help,
Thanks a lot,
Mitra

	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Sat Jun 11 20:15:38 2016
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Sat, 11 Jun 2016 21:15:38 +0300
Subject: [R] problem in R2OpenBUGS
Message-ID: <CABLo8nGjijvOxUkftsq=1QJXGO+Jw9nHggnjPHfZ+S0ifphRiQ@mail.gmail.com>

Dear R- users

I have a problem in the R-code, i want to draw some plots in R,however,
when i write the following code the R-program stopped suddenly. The message
is  "R for WINDOWS GUI front-end has stopped working". How can i solve this
problem please?

## some plots
  samplesBgr("lam[1:6]") # plot the bgr statistics, and
  samplesAutoC("lam[1:6]", 1) # plot autocorrelations of 1st chain



Regards


-- 
Thanoon Y. Thanoon
PhD
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Jun 11 20:33:04 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Jun 2016 11:33:04 -0700
Subject: [R] problem in R2OpenBUGS
In-Reply-To: <CABLo8nGjijvOxUkftsq=1QJXGO+Jw9nHggnjPHfZ+S0ifphRiQ@mail.gmail.com>
References: <CABLo8nGjijvOxUkftsq=1QJXGO+Jw9nHggnjPHfZ+S0ifphRiQ@mail.gmail.com>
Message-ID: <BA9DF647-B7FC-42B1-823C-019370BB1EA3@dcn.davis.ca.us>

This is not a reproducible example, and posting in HTML format frequently corrupts R code so don't do it. 
-- 
Sent from my phone. Please excuse my brevity.

On June 11, 2016 11:15:38 AM PDT, thanoon younis <thanoon.younis80 at gmail.com> wrote:
>Dear R- users
>
>I have a problem in the R-code, i want to draw some plots in R,however,
>when i write the following code the R-program stopped suddenly. The
>message
>is  "R for WINDOWS GUI front-end has stopped working". How can i solve
>this
>problem please?
>
>## some plots
>  samplesBgr("lam[1:6]") # plot the bgr statistics, and
>  samplesAutoC("lam[1:6]", 1) # plot autocorrelations of 1st chain
>
>
>
>Regards
>
>
>-- 
>Thanoon Y. Thanoon
>PhD
>Department of Mathematical Sciences
>Faculty of Science
>University Technology Malaysia, UTM
>E.Mail: Thanoon.younis80 at gmail.com
>E.Mail: dawn_prayer80 at yahoo.com
>Facebook:Thanoon Younis AL-Shakerchy
>Twitter: Thanoon Alshakerchy
>H.P:00601127550205
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Sat Jun 11 20:36:58 2016
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Sat, 11 Jun 2016 21:36:58 +0300
Subject: [R] problem in R2OpenBUGS
In-Reply-To: <BA9DF647-B7FC-42B1-823C-019370BB1EA3@dcn.davis.ca.us>
References: <CABLo8nGjijvOxUkftsq=1QJXGO+Jw9nHggnjPHfZ+S0ifphRiQ@mail.gmail.com>
	<BA9DF647-B7FC-42B1-823C-019370BB1EA3@dcn.davis.ca.us>
Message-ID: <CABLo8nFUhoou+HshX5aXawWDOVMZiLp9Mg6ejf3fu6dsh8usAg@mail.gmail.com>

Thank you very much for your response, how can i solve this problem, i want
to draw at least BGR plots?


Regards

On 11 June 2016 at 21:33, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> This is not a reproducible example, and posting in HTML format frequently
> corrupts R code so don't do it.
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 11, 2016 11:15:38 AM PDT, thanoon younis <
> thanoon.younis80 at gmail.com> wrote:
>>
>> Dear R- users
>>
>> I have a problem in the R-code, i want to draw some plots in R,however,
>> when i write the following code the R-program stopped suddenly. The message
>> is  "R for WINDOWS GUI front-end has stopped working". How can i solve this
>> problem please?
>>
>> ## some plots
>>   samplesBgr("lam[1:6]") # plot the bgr statistics, and
>>   samplesAutoC("lam[1:6]", 1) # plot autocorrelations of 1st chain
>>
>>
>>
>> Regards
>>
>>


-- 
Thanoon Y. Thanoon
PhD
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From mike at hsm.org.uk  Sat Jun 11 21:29:24 2016
From: mike at hsm.org.uk (Mike Smith)
Date: Sat, 11 Jun 2016 20:29:24 +0100
Subject: [R] Creating mean TIF
Message-ID: <951301394.20160611202924@hsm.org.uk>

Hi

I import 16-bit TIFs (RGB) from a directory using the following code, then loop through adding each TIF before dividing by the total number of files to give an image of mean pixel values. Some quick questions:

-having checked pixel values, this does what I expect it to do in that it creates the mean for each RGB layer in each image. It is pretty quick, but is there a function that does this already (and would also do, for example, the median)?

-do all the calculations take place in 32 bit space?

-when I export the image either as 16 bits per pixel (or indeed 8) and then reimport the pixel values look like they might have been scaled. For example, below. Is writeTIFF doing something Im not aware of??
> m_image_tiff1[1,1,1]
[1] 0.9745098
> test_tiff[1,1,1]
[1] 0.06532387

Thanks very much!

mike



#Scan directory and store filenames in string, then count total files
files <- as.character(list.files(path="./mean/input/"))
n <- length(files)

#Use first TIF as loop file, then add all together
m_image_tiff <- readTIFF(paste("./mean/input/",files[1],sep=""))
for (i in 2:n){
  test<-paste("./mean/input/",files[i],sep="")
  tiff <- readTIFF(paste("./mean/input/",files[i],sep=""))
  m_image_tiff <- (tiff+m_image_tiff)
}

#Calculate mean and write TIF
m_image_tiff <- (m_image_tiff/n)
writeTIFF(m_image_tiff,"./mean/mean_tiff.tif",bits.per.sample=16L)
---
Mike Smith


From jdnewmil at dcn.davis.ca.us  Sat Jun 11 21:45:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Jun 2016 12:45:50 -0700
Subject: [R] problem in R2OpenBUGS
In-Reply-To: <CABLo8nFUhoou+HshX5aXawWDOVMZiLp9Mg6ejf3fu6dsh8usAg@mail.gmail.com>
References: <CABLo8nGjijvOxUkftsq=1QJXGO+Jw9nHggnjPHfZ+S0ifphRiQ@mail.gmail.com>
	<BA9DF647-B7FC-42B1-823C-019370BB1EA3@dcn.davis.ca.us>
	<CABLo8nFUhoou+HshX5aXawWDOVMZiLp9Mg6ejf3fu6dsh8usAg@mail.gmail.com>
Message-ID: <CCD5D069-88EC-4226-AC91-6D2A468F2592@dcn.davis.ca.us>

That is my point... we cannot see your problem on our computers because you have not given us sample data and code that does anything. For one thing, the samplesBgr function is part of the BRugs package, not the R2OpenBUGS package, so your subject line does not make sense.  For another, samplesBgr cannot do anything unless a BUGS model has been compiled, burned in, and run. 

Have you been able to run a known-good example like [1]? What is the output of the sessionInfo function just before you try to run samplesBgr?

[1] https://theoreticalecology.wordpress.com/setting-up-openbugs-and-r/
-- 
Sent from my phone. Please excuse my brevity.

On June 11, 2016 11:36:58 AM PDT, thanoon younis <thanoon.younis80 at gmail.com> wrote:
>Thank you very much for your response, how can i solve this problem, i
>want
>to draw at least BGR plots?
>
>
>Regards
>
>On 11 June 2016 at 21:33, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> This is not a reproducible example, and posting in HTML format
>frequently
>> corrupts R code so don't do it.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On June 11, 2016 11:15:38 AM PDT, thanoon younis <
>> thanoon.younis80 at gmail.com> wrote:
>>>
>>> Dear R- users
>>>
>>> I have a problem in the R-code, i want to draw some plots in
>R,however,
>>> when i write the following code the R-program stopped suddenly. The
>message
>>> is  "R for WINDOWS GUI front-end has stopped working". How can i
>solve this
>>> problem please?
>>>
>>> ## some plots
>>>   samplesBgr("lam[1:6]") # plot the bgr statistics, and
>>>   samplesAutoC("lam[1:6]", 1) # plot autocorrelations of 1st chain
>>>
>>>
>>>
>>> Regards
>>>
>>>
>
>
>-- 
>Thanoon Y. Thanoon
>PhD
>Department of Mathematical Sciences
>Faculty of Science
>University Technology Malaysia, UTM
>E.Mail: Thanoon.younis80 at gmail.com
>E.Mail: dawn_prayer80 at yahoo.com
>Facebook:Thanoon Younis AL-Shakerchy
>Twitter: Thanoon Alshakerchy
>H.P:00601127550205

	[[alternative HTML version deleted]]


From j.bayat194 at gmail.com  Sun Jun 12 04:57:40 2016
From: j.bayat194 at gmail.com (javad bayat)
Date: Sun, 12 Jun 2016 07:27:40 +0430
Subject: [R] How to get bathymetry data using R
In-Reply-To: <BF9A46D1-C4E8-4602-82AE-42207FE38BAF@noaa.gov>
References: <CANTxAmLTRUqHA-1_n8S0pBd-2oB75Fod0vGj9G7SKOdkyUF-YQ@mail.gmail.com>
	<CAAcGz98QPwQzvfH69oe8QkWG89q5uQfqpnHFw7Obj0dn16p3aA@mail.gmail.com>
	<BF9A46D1-C4E8-4602-82AE-42207FE38BAF@noaa.gov>
Message-ID: <CANTxAm+_59Kw2RC8gRPhhusQyyhbCBZbFftVL=363pE0Q-FGoQ@mail.gmail.com>

Dear all;
Many thanks for your answers but I think I should explain more. What I want
to do is extracting bathymetry data from topography or DEM for a model that
uses .npt format.
Is there a package to do such a thing?
Thanks.

On Sat, Jun 11, 2016 at 8:39 PM, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> Use the ?rerddap? package that accesses our ERDDAP server.  You can see
> the data available at:
>
> http://upwell.pfeg.noaa.gov/erddap
>
> In the search box type in ?bathymetry?.    You can subset as you want,
> using ?rerddap? you get back a netcdf file that is already read into your R
> workspace,  or you can write your own 2 lines of code  (since the URL
> completely defines the request) and get the data back in any number of file
> formats.  I don?t want to get into a format war, but for large gridded
> datasets like this I much prefer netcdf files.
>
> If you have any questions at all about either the ?rerddap? package
> (developed by the wonderful people at ROpenSci) or about our ERDDAP
> service, don?t hesitate to ask.
>
> -Roy
>
> > On Jun 11, 2016, at 12:30 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> >
> > On Sat, 11 Jun 2016 at 15:43 javad bayat <j.bayat194 at gmail.com> wrote:
> >
> >> Dear R users;
> >> I am searching for a package to extract bathymetry data from topography
> map
> >> to produce the control file for CE-Qual-w2 model.
> >> Is there anyone to know how to do it?
> >> many thanks.
> >>
> >>
> > There are few things around but I highly recommend find your own data
> > source, suitable for your purpose - and reading it directly with the
> raster
> > package.  If anyone knows a reliable source I'd like to hear it.
> >
> > As a global go-to I use Etopo1, but you may want some more detailed (like
> > Gebco 2014) or a non-global one. (I can't tell where you need this for or
> > what resolution would be suitable from what you've asked though).
> >
> > (The best format when you get a choice generally is GeoTIFF, but it
> depends
> > who creates them. I tend to use the NetCDF files from Etopo).
> >
> > Raster uses rgdal for many formats, but ncdf4 exclusively for NetCDF - if
> > it's not called "*.nc" you can get around that).
> >
> > Cheers, Mike.
> >
> >
> >
> >> --
> >> Best Regards
> >> Javad Bayat
> >> M.Sc. Environment Engineering
> >> Alternative Mail: bayat194 at yahoo.com
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> > --
> > Dr. Michael Sumner
> > Software and Database Engineer
> > Australian Antarctic Division
> > 203 Channel Highway
> > Kingston Tasmania 7050 Australia
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
>


-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From mohdsharaiah at gmail.com  Sun Jun 12 12:56:06 2016
From: mohdsharaiah at gmail.com (mohammad alsharaiah)
Date: Sun, 12 Jun 2016 22:56:06 +1200
Subject: [R] need help in using times delay in boolnet package
Message-ID: <CAFUx43xL5J0u39UMAg36Bj9L1R5P5_xGZ9f8vpRKmtkLFBL7yA@mail.gmail.com>

Hi,,
every one , im using Boolnet package inside R environment to create a
Boolean network.
i created a boolean network by using boolnet package and i need to apply
time delays on some of element in the network. For instance, i have
elements A, B, C  which they  need one time step to be active or in active,
and i have another set of elements in the same network such as K, L, G
which they need 3 time step for each to be active or inactive.

we can say  i have 2 classes of element . fast Boolean elements need one
time step to change their states and the other class element which need
more than one time step to change their states.

please can any one give me  a hand in this issue.

regards,



*Mohammad  *

	[[alternative HTML version deleted]]


From fotisfotiadis at gmail.com  Sun Jun 12 16:03:01 2016
From: fotisfotiadis at gmail.com (Fotis Fotiadis)
Date: Sun, 12 Jun 2016 17:03:01 +0300
Subject: [R] itsadug:: plot_smooth and plot_diff
Message-ID: <CAAO1NncVRe0O1VrBBUuJB_kA7GgZUwQKYXso+Acac-HykgK0JA@mail.gmail.com>

Hi all

I am using bam to analyse the data from my experiment.
It's a learning experiment, "acc" denotes accuracy and "cnd" denotes a
within-subjects variable (with two levels, "label" and "ideo")."Ctrial" is
centered trial (ranging from 1 to 288).

The model is:
bam(acc~ 1 + cnd + s(ctrial) + s(ctrial, sbj, bs = "fs", m = 1), data=data,
family=binomial)

The model doesn't include two different smooths (one for each condition)
since including two smooths does not result to a more parsimonious model,
according to following model comparison:
> compareML(m0.2, m1.2)
m0.2: acc ~ 1 + cnd + s(ctrial) + s(ctrial, sbj, bs = "fs", m = 1)

m1.2: acc ~ 1 + cnd + s(ctrial, by = cnd) + s(ctrial, sbj, bs = "fs",
    m = 1)

Chi-square test of fREML scores
-----
  Model    Score Edf Chisq    Df   p.value Sig.
1  m0.2 10183.31   6
2  m1.2 10173.33   8 9.975 2.000 4.654e-05  ***

AIC difference: -2.16, model m0.2 has lower AIC.


So, I'm trying to assess if there's a difference in accuracy between the
two conditions.

When using the plot_smooth function, the model predictions are the ones
shown in Fig.1.
The code used is:
plot_smooth(fm, view="ctrial",
cond=list(cnd="pseudo"),main="Model",xaxt="n",
xlab="Trial",ylab="Proportion Correct", lwd=2, las=2, rm.ranef=TRUE,
rug=FALSE, shade=T, col="red" )
plot_smooth(fm, view="ctrial", cond=list(cnd="ideo"), xaxt="n",
rm.ranef=TRUE, rug=FALSE, shade=T, col="blue", add=T , lty=2, lwd=2)
legend(x=0.8, y=1.5,legend=c('Label', 'Ideogram'),col=c('red', 'blue'),
lty=c(1,2), bty="n", lwd=2)

Since the 95% confidence intervals overlap, I would assume that there is no
difference in accuracy between the two conditions.

I am also using plot_diff to directly plot the difference:
plot_diff(fm, view="ctrial",comp=list(cnd=c("pseudo", "ideo")),
transform.view=dnrmlz,rm.ranef=T)
(dnrmlz is a simple function to de-normalize trial)

The output of the function is:
Summary:
* ctrial : numeric predictor; with 100 values ranging from -1.725936 to
1.725936.
* sbj : factor; set to the value(s): aggmpo96. (Might be canceled as random
effect, check below.)
* NOTE : The following random effects columns are canceled: s(ctrial,sbj)

* Note: x-values are transformed.
            Significant
1 0.759461 - 288.240539

So, it seems that accuracy in the label condition is higher compared to the
ideo condition throughout the experiment.
This result seems to contradict the previous one.

I am obviously misinterpreting something.
Any ideas on what am I doing wrong?

Thank you in advance for your time,
Fotis







-- 
PhD Candidate
Department of Philosophy and History of Science
University of Athens, Greece.
http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis

Notice: Please do not use this account for social networks invitations, for
sending chain-mails to me, or as it were a facebook account. Thank you for
respecting my privacy.

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fig1.png
Type: image/png
Size: 6837 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160612/d630b0d8/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fig2.png
Type: image/png
Size: 6915 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160612/d630b0d8/attachment-0001.png>

From bgunter.4567 at gmail.com  Sun Jun 12 16:50:38 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 12 Jun 2016 07:50:38 -0700
Subject: [R] itsadug:: plot_smooth and plot_diff
In-Reply-To: <CAAO1NncVRe0O1VrBBUuJB_kA7GgZUwQKYXso+Acac-HykgK0JA@mail.gmail.com>
References: <CAAO1NncVRe0O1VrBBUuJB_kA7GgZUwQKYXso+Acac-HykgK0JA@mail.gmail.com>
Message-ID: <CAGxFJbRs77M=wSqaU3TYC1uK-h6YzY-MgCaNxpV9OdFjN-xrsQ@mail.gmail.com>

To be clear, I know nothing about bam; I just wanted to correct a
statistical error:

"Since the 95% confidence intervals overlap, I would assume that there is no
difference in accuracy between the two conditions."

That is false. You need to look at a CI for the difference.

As you appear to be confused about the statistical issues, I suggest
you post on a statistical site like stats.stackexchange.com or consult
a local statistician.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 12, 2016 at 7:03 AM, Fotis Fotiadis <fotisfotiadis at gmail.com> wrote:
> Hi all
>
> I am using bam to analyse the data from my experiment.
> It's a learning experiment, "acc" denotes accuracy and "cnd" denotes a
> within-subjects variable (with two levels, "label" and "ideo")."Ctrial" is
> centered trial (ranging from 1 to 288).
>
> The model is:
> bam(acc~ 1 + cnd + s(ctrial) + s(ctrial, sbj, bs = "fs", m = 1), data=data,
> family=binomial)
>
> The model doesn't include two different smooths (one for each condition)
> since including two smooths does not result to a more parsimonious model,
> according to following model comparison:
>> compareML(m0.2, m1.2)
> m0.2: acc ~ 1 + cnd + s(ctrial) + s(ctrial, sbj, bs = "fs", m = 1)
>
> m1.2: acc ~ 1 + cnd + s(ctrial, by = cnd) + s(ctrial, sbj, bs = "fs",
>     m = 1)
>
> Chi-square test of fREML scores
> -----
>   Model    Score Edf Chisq    Df   p.value Sig.
> 1  m0.2 10183.31   6
> 2  m1.2 10173.33   8 9.975 2.000 4.654e-05  ***
>
> AIC difference: -2.16, model m0.2 has lower AIC.
>
>
> So, I'm trying to assess if there's a difference in accuracy between the
> two conditions.
>
> When using the plot_smooth function, the model predictions are the ones
> shown in Fig.1.
> The code used is:
> plot_smooth(fm, view="ctrial",
> cond=list(cnd="pseudo"),main="Model",xaxt="n",
> xlab="Trial",ylab="Proportion Correct", lwd=2, las=2, rm.ranef=TRUE,
> rug=FALSE, shade=T, col="red" )
> plot_smooth(fm, view="ctrial", cond=list(cnd="ideo"), xaxt="n",
> rm.ranef=TRUE, rug=FALSE, shade=T, col="blue", add=T , lty=2, lwd=2)
> legend(x=0.8, y=1.5,legend=c('Label', 'Ideogram'),col=c('red', 'blue'),
> lty=c(1,2), bty="n", lwd=2)
>
> Since the 95% confidence intervals overlap, I would assume that there is no
> difference in accuracy between the two conditions.
>
> I am also using plot_diff to directly plot the difference:
> plot_diff(fm, view="ctrial",comp=list(cnd=c("pseudo", "ideo")),
> transform.view=dnrmlz,rm.ranef=T)
> (dnrmlz is a simple function to de-normalize trial)
>
> The output of the function is:
> Summary:
> * ctrial : numeric predictor; with 100 values ranging from -1.725936 to
> 1.725936.
> * sbj : factor; set to the value(s): aggmpo96. (Might be canceled as random
> effect, check below.)
> * NOTE : The following random effects columns are canceled: s(ctrial,sbj)
>
> * Note: x-values are transformed.
>             Significant
> 1 0.759461 - 288.240539
>
> So, it seems that accuracy in the label condition is higher compared to the
> ideo condition throughout the experiment.
> This result seems to contradict the previous one.
>
> I am obviously misinterpreting something.
> Any ideas on what am I doing wrong?
>
> Thank you in advance for your time,
> Fotis
>
>
>
>
>
>
>
> --
> PhD Candidate
> Department of Philosophy and History of Science
> University of Athens, Greece.
> http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis
>
> Notice: Please do not use this account for social networks invitations, for
> sending chain-mails to me, or as it were a facebook account. Thank you for
> respecting my privacy.
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fahman_khan75 at yahoo.com  Sun Jun 12 03:06:20 2016
From: fahman_khan75 at yahoo.com (Fahman Khan)
Date: Sun, 12 Jun 2016 01:06:20 +0000 (UTC)
Subject: [R] Help: How to Convert Binary Data into Text Using R
References: <44876122.1463404.1465693580802.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <44876122.1463404.1465693580802.JavaMail.yahoo@mail.yahoo.com>

Good Evening,
Just started learning R and one of the task given to me is to convert Binary Data into text. I'm not sure what package i'm suppose to use. Can i get an idea of how i can convert binary into text.?
Regards,Fahman Khan
	[[alternative HTML version deleted]]


From lakhvera at yahoo.com  Sun Jun 12 04:44:44 2016
From: lakhvera at yahoo.com (Ahmed Raza)
Date: Sun, 12 Jun 2016 02:44:44 +0000 (UTC)
Subject: [R] PSM With Panel Data
References: <1835503898.1541096.1465699484280.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1835503898.1541096.1465699484280.JavaMail.yahoo@mail.yahoo.com>

Hi All,?
I have a panel data and I am applying Propensity Score Matching on it. I have multiple treatments (4 treatments). I have estimated the model on the full sample using the CBPS Package. However, I want to perform matching on yearly basis. After extensive search, I could not figure out that how I can do this. Any help in this regard will be much appreciated

With Best Regards,?
Ahmed Arif?
	[[alternative HTML version deleted]]


From bob at rudis.net  Sun Jun 12 18:40:34 2016
From: bob at rudis.net (boB Rudis)
Date: Sun, 12 Jun 2016 12:40:34 -0400
Subject: [R] Help: How to Convert Binary Data into Text Using R
In-Reply-To: <44876122.1463404.1465693580802.JavaMail.yahoo@mail.yahoo.com>
References: <44876122.1463404.1465693580802.JavaMail.yahoo.ref@mail.yahoo.com>
	<44876122.1463404.1465693580802.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJ4QxaOJXc4uraUh3LwaOu0N_iT7gSqwMH0YUJhTJ63FbUmSQw@mail.gmail.com>

Welcome to R and R-help!

It would help others help you if you provided a minimal example and
explained your situation with a bit more details. It's pretty vague as
it stands.

Base R has both a `readBin()` and `rawConnection()` functions (amongst
other tools for such things) and there are a few packages that also
help with reading "binary" data. But, without knowing more specifics,
that's about as much direction as any of us wld be able to give.

-Bob

On Sat, Jun 11, 2016 at 9:06 PM, Fahman Khan via R-help
<r-help at r-project.org> wrote:
> Good Evening,
> Just started learning R and one of the task given to me is to convert Binary Data into text. I'm not sure what package i'm suppose to use. Can i get an idea of how i can convert binary into text.
> Regards,Fahman Khan
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Jun 12 19:00:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 12 Jun 2016 10:00:22 -0700
Subject: [R] Help: How to Convert Binary Data into Text Using R
In-Reply-To: <44876122.1463404.1465693580802.JavaMail.yahoo@mail.yahoo.com>
References: <44876122.1463404.1465693580802.JavaMail.yahoo.ref@mail.yahoo.com>
	<44876122.1463404.1465693580802.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbSRTpPiD41QUUi6142XGDwL5oAyjDtN65w51rvHPCP15w@mail.gmail.com>

Suggestion: Before posting here, search! You are likely to get the
info you want a lot faster.

The rseek.org website is particularly helpful, but google, bing, etc.
are also typically useful. The phrase "read binary data" brought up
many hits on rseek, but as a Bob said, you may need to refine/clarify
your query to get what you want.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jun 11, 2016 at 6:06 PM, Fahman Khan via R-help
<r-help at r-project.org> wrote:
> Good Evening,
> Just started learning R and one of the task given to me is to convert Binary Data into text. I'm not sure what package i'm suppose to use. Can i get an idea of how i can convert binary into text.
> Regards,Fahman Khan
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From avcmd at orange.fr  Sun Jun 12 19:56:36 2016
From: avcmd at orange.fr (avcommande)
Date: Sun, 12 Jun 2016 19:56:36 +0200 (CEST)
Subject: [R] Help with function lmodel2
Message-ID: <1354777205.10261.1465754196640.JavaMail.www@wwinf1e31>





Hello everyone,

?

Does anybody know whether it's possible to calculate extract major axis regression residuals on the results of a major axis Model II regression done by lmodel2? 

Many thanks, 

Orca

?

Example?:

?

> data1 data1

??? SSTo? SSTp

1? 17.21 20.36

2? 19.61 20.19

3? 18.60 20.08

4? 18.76 19.71

5? 18.24 20.48

6? 19.10 20.56

7? 20.45 20.56

8? 18.68 19.71

9? 16.55 20.48

10 17.33 20.60

11 18.12 18.93

12 18.02 18.65

13 18.43 18.90

14 18.57 18.62

15 17.40 18.79

16 18.91 19.28

17 18.43 18.58

18 17.02 18.40

19 16.96 17.79

20 17.05 17.82

21 16.98 18.07

22 16.86 18.00

23 17.00 17.79

24 16.70 18.18

25 15.93 18.07

26 17.06 17.85

?

> Reg1<-lmodel2(SSTo~SSTp,data=data1,"interval","interval",99)

> Reg1

?

Model II regression

?

Call: lmodel2(formula = SSTo ~ SSTp, data = data1, range.y =

"interval", range.x = "interval", nperm = 99)

?

n = 26?? r = 0.5671202?? r-square = 0.3216254 

Parametric P-values:?? 2-tailed = 0.002517785??? 1-tailed = 0.001258892 

Angle between the two OLS regression lines = 30.86925 degrees

?

Permutation tests of OLS, MA, RMA slopes: 1-tailed, tail corresponding to sign

A permutation test of r is equivalent to a permutation test of the OLS slope

P-perm for SMA = NA because the SMA slope cannot be tested

?

Regression results

? Method Intercept???? Slope Angle (degrees) P-perm (1-tailed)

1??? OLS? 6.651441 0.5862273??????? 30.38000????????????? 0.01

2???? MA -2.397667 1.0601457??????? 46.67227????????????? 0.01

3??? SMA -1.892541 1.0336913??????? 45.94911??????????????? NA

4?? ?RMA? 3.144884 0.7698721??????? 37.59167????????????? 0.01

?

Confidence intervals

? Method 2.5%-Intercept 97.5%-Intercept 2.5%-Slope 97.5%-Slope

1??? OLS???? -0.2070452?????? 13.509927? 0.2275463?? 0.9449083

2???? MA??? -22.1054387??????? 7.308805? 0.5517999?? 2.0922780

3??? SMA???? -9.8957401??????? 3.801737? 0.7354715?? 1.4528336

4??? RMA???? -7.3480741?????? 11.432676? 0.3358252?? 1.3194076

?

Eigenvalues: 1.751428 0.4828554 

?

H statistic used for computing C.I. of MA: 0.09327046

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Sun Jun 12 22:14:51 2016
From: mak.hholly at gmail.com (greg holly)
Date: Sun, 12 Jun 2016 16:14:51 -0400
Subject: [R] two difficult loop
Message-ID: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>

Dear all;



I have two data sets, data=map and data=ref). A small part of each data set
are given below. Data map has more than 27 million and data ref has about
560 rows. Basically I need run two different task. My R codes for these
task are given below but they do not work properly.

I sincerely do appreciate your helps.


Regards,

Greg



Task 1)

For example, the first and second columns for row 1 in data ref are 29220
63933. So I need write an R code normally first look the first row in ref
(which they are 29220 and 63933) than summing the column of "map$rate" and
give the number of rows that >0.85. Then do the same for the second,
third....in ref. At the end I would like a table gave below (the results I
need). Please notice the all value specified in ref data file are exist in
map$reg column.



Task2)

Again example, the first and second columns for row 1 in data ref are 29220
63933. So I need write an R code give the minimum map$p for the 29220
-63933 intervals in map file. Than

do the same for the second, third....in ref.




#my attempt for the first question

temp<-map[order(map$reg, map$p),]

count<-1

temp<-unique(temp$reg

for(i in 1:length(ref) {

  for(j in 1:length(ref)

  {

temp1<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,]
& temp[cumsum(temp$rate)
>0.70,])

count=count+1

    }

}

#my attempt for the second question



temp<-map[order(map$reg, map$p),]

count<-1

temp<-unique(temp$reg

for(i in 1:length(ref) {

  for(j in 1:length(ref)

  {

temp2<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,])

output<-temp2[temp2$p==min(temp2$p),]

    }

}



Data sets


  Data= map

  reg   p      rate

 10276 0.700  3.867e-18

 71608 0.830  4.542e-16

 29220 0.430  1.948e-15

 99542 0.220  1.084e-15

 26441 0.880  9.675e-14

 95082 0.090  7.349e-13

 36169 0.480  9.715e-13

 55572 0.500  9.071e-12

 65255 0.300  1.688e-11

 51960 0.970  1.163e-10

 55652 0.388  3.750e-10

 63933 0.250  9.128e-10

 35170 0.720  7.355e-09

 06491 0.370  1.634e-08

 85508 0.470  1.057e-07

 86666 0.580  7.862e-07

 04758 0.810  9.501e-07

 06169 0.440  1.104e-06

 63933 0.750  2.624e-06

 41838 0.960  8.119e-06


 data=ref

  reg1         reg2

  29220     63933

  26441     41838

  06169     10276

  74806     92643

  73732     82451

  86042     93502

  85508     95082



       the results I need

     reg1      reg2 n

   29220   63933  12

   26441   41838   78

   06169 10276  125

   74806 92643   11

   73732 82451   47

   86042 93502   98

   85508 95082  219

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jun 13 00:36:52 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 12 Jun 2016 15:36:52 -0700
Subject: [R] two difficult loop
In-Reply-To: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
References: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
Message-ID: <CAGxFJbQr2HFVy7K-H5FFBVZT7K4G6=+-9nQL9Q3=BpQeB9UM8g@mail.gmail.com>

Greg:

I was not able to understand your task 1. Perhaps others can.

My understanding of your task 2 is that for each row of ref, you wish
to find all rows,of map such that the reg values in those rows fall
between the reg1 and reg2 values in ref (inclusive change <= to < if
you don't want the endpoints), and then you want the minimum map$p
values of all those rows. If that is correct, I believe this will do
it (but caution, untested, as you failed to provide data in a
convenient form, e.g. using dput() )

task2 <- with(map,vapply(seq_len(nrow(ref)),function(i)
min(p[ref[i,1]<=reg & reg <= ref[i,2] ]),0))


If my understanding is incorrect, please ignore both the above and the
following:


The "solution" I have given above seems inefficient, so others may be
able to significantly improve it if you find that it takes too long.
OTOH, my understanding of your specification is that you need to
search for all rows in map data frame that meet the criterion for each
row of ref, and without further information, I don't know how to do
this without just repeating the search 560 times.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 12, 2016 at 1:14 PM, greg holly <mak.hholly at gmail.com> wrote:
> Dear all;
>
>
>
> I have two data sets, data=map and data=ref). A small part of each data set
> are given below. Data map has more than 27 million and data ref has about
> 560 rows. Basically I need run two different task. My R codes for these
> task are given below but they do not work properly.
>
> I sincerely do appreciate your helps.
>
>
> Regards,
>
> Greg
>
>
>
> Task 1)
>
> For example, the first and second columns for row 1 in data ref are 29220
> 63933. So I need write an R code normally first look the first row in ref
> (which they are 29220 and 63933) than summing the column of "map$rate" and
> give the number of rows that >0.85. Then do the same for the second,
> third....in ref. At the end I would like a table gave below (the results I
> need). Please notice the all value specified in ref data file are exist in
> map$reg column.
>
>
>
> Task2)
>
> Again example, the first and second columns for row 1 in data ref are 29220
> 63933. So I need write an R code give the minimum map$p for the 29220
> -63933 intervals in map file. Than
>
> do the same for the second, third....in ref.
>
>
>
>
> #my attempt for the first question
>
> temp<-map[order(map$reg, map$p),]
>
> count<-1
>
> temp<-unique(temp$reg
>
> for(i in 1:length(ref) {
>
>   for(j in 1:length(ref)
>
>   {
>
> temp1<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,]
> & temp[cumsum(temp$rate)
>>0.70,])
>
> count=count+1
>
>     }
>
> }
>
> #my attempt for the second question
>
>
>
> temp<-map[order(map$reg, map$p),]
>
> count<-1
>
> temp<-unique(temp$reg
>
> for(i in 1:length(ref) {
>
>   for(j in 1:length(ref)
>
>   {
>
> temp2<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,])
>
> output<-temp2[temp2$p==min(temp2$p),]
>
>     }
>
> }
>
>
>
> Data sets
>
>
>   Data= map
>
>   reg   p      rate
>
>  10276 0.700  3.867e-18
>
>  71608 0.830  4.542e-16
>
>  29220 0.430  1.948e-15
>
>  99542 0.220  1.084e-15
>
>  26441 0.880  9.675e-14
>
>  95082 0.090  7.349e-13
>
>  36169 0.480  9.715e-13
>
>  55572 0.500  9.071e-12
>
>  65255 0.300  1.688e-11
>
>  51960 0.970  1.163e-10
>
>  55652 0.388  3.750e-10
>
>  63933 0.250  9.128e-10
>
>  35170 0.720  7.355e-09
>
>  06491 0.370  1.634e-08
>
>  85508 0.470  1.057e-07
>
>  86666 0.580  7.862e-07
>
>  04758 0.810  9.501e-07
>
>  06169 0.440  1.104e-06
>
>  63933 0.750  2.624e-06
>
>  41838 0.960  8.119e-06
>
>
>  data=ref
>
>   reg1         reg2
>
>   29220     63933
>
>   26441     41838
>
>   06169     10276
>
>   74806     92643
>
>   73732     82451
>
>   86042     93502
>
>   85508     95082
>
>
>
>        the results I need
>
>      reg1      reg2 n
>
>    29220   63933  12
>
>    26441   41838   78
>
>    06169 10276  125
>
>    74806 92643   11
>
>    73732 82451   47
>
>    86042 93502   98
>
>    85508 95082  219
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Jun 13 01:06:46 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 13 Jun 2016 09:06:46 +1000
Subject: [R] two difficult loop
In-Reply-To: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
References: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
Message-ID: <CA+8X3fVv_pBoSmnE2DS_KXHL9+cWe7-kLZSPOs03YK5_mo_8Pg@mail.gmail.com>

Hi Greg,
You've got a problem that you don't seem to have identified. Your
"reg" field in the "map" data frame can define at most 100000 unique
values. This means that each value will be repeated about 270 times.
Unless there are constraints you haven't mentioned, we would expect
that in 135 cases for each value, the values in each "ref" row will be
in the reverse order and the spans may overlap. I notice that you may
have tried to get around this by sorting the "map" data frame, but
then the order of the rows is different, and the number of rows
"between" any two values changes. Apart from this, it is almost
certain that the number of values of "p > 0.85" in the multiple runs
between each set of "ref" values will be different. It is possible to
perform both tasks that you mention, but only the second will yield an
unique or tied value for all of the cases. So your result data frame
will have an unspecified number of values for each row in "ref" for
the first task.

Jim


On Mon, Jun 13, 2016 at 6:14 AM, greg holly <mak.hholly at gmail.com> wrote:
> Dear all;
>
>
>
> I have two data sets, data=map and data=ref). A small part of each data set
> are given below. Data map has more than 27 million and data ref has about
> 560 rows. Basically I need run two different task. My R codes for these
> task are given below but they do not work properly.
>
> I sincerely do appreciate your helps.
>
>
> Regards,
>
> Greg
>
>
>
> Task 1)
>
> For example, the first and second columns for row 1 in data ref are 29220
> 63933. So I need write an R code normally first look the first row in ref
> (which they are 29220 and 63933) than summing the column of "map$rate" and
> give the number of rows that >0.85. Then do the same for the second,
> third....in ref. At the end I would like a table gave below (the results I
> need). Please notice the all value specified in ref data file are exist in
> map$reg column.
>
>
>
> Task2)
>
> Again example, the first and second columns for row 1 in data ref are 29220
> 63933. So I need write an R code give the minimum map$p for the 29220
> -63933 intervals in map file. Than
>
> do the same for the second, third....in ref.
>
>
>
>
> #my attempt for the first question
>
> temp<-map[order(map$reg, map$p),]
>
> count<-1
>
> temp<-unique(temp$reg
>
> for(i in 1:length(ref) {
>
>   for(j in 1:length(ref)
>
>   {
>
> temp1<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,]
> & temp[cumsum(temp$rate)
>>0.70,])
>
> count=count+1
>
>     }
>
> }
>
> #my attempt for the second question
>
>
>
> temp<-map[order(map$reg, map$p),]
>
> count<-1
>
> temp<-unique(temp$reg
>
> for(i in 1:length(ref) {
>
>   for(j in 1:length(ref)
>
>   {
>
> temp2<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,])
>
> output<-temp2[temp2$p==min(temp2$p),]
>
>     }
>
> }
>
>
>
> Data sets
>
>
>   Data= map
>
>   reg   p      rate
>
>  10276 0.700  3.867e-18
>
>  71608 0.830  4.542e-16
>
>  29220 0.430  1.948e-15
>
>  99542 0.220  1.084e-15
>
>  26441 0.880  9.675e-14
>
>  95082 0.090  7.349e-13
>
>  36169 0.480  9.715e-13
>
>  55572 0.500  9.071e-12
>
>  65255 0.300  1.688e-11
>
>  51960 0.970  1.163e-10
>
>  55652 0.388  3.750e-10
>
>  63933 0.250  9.128e-10
>
>  35170 0.720  7.355e-09
>
>  06491 0.370  1.634e-08
>
>  85508 0.470  1.057e-07
>
>  86666 0.580  7.862e-07
>
>  04758 0.810  9.501e-07
>
>  06169 0.440  1.104e-06
>
>  63933 0.750  2.624e-06
>
>  41838 0.960  8.119e-06
>
>
>  data=ref
>
>   reg1         reg2
>
>   29220     63933
>
>   26441     41838
>
>   06169     10276
>
>   74806     92643
>
>   73732     82451
>
>   86042     93502
>
>   85508     95082
>
>
>
>        the results I need
>
>      reg1      reg2 n
>
>    29220   63933  12
>
>    26441   41838   78
>
>    06169 10276  125
>
>    74806 92643   11
>
>    73732 82451   47
>
>    86042 93502   98
>
>    85508 95082  219
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mak.hholly at gmail.com  Mon Jun 13 04:35:36 2016
From: mak.hholly at gmail.com (greg holly)
Date: Sun, 12 Jun 2016 22:35:36 -0400
Subject: [R] two difficult loop
In-Reply-To: <CAM9Qe4gBctQDctAjPzoNBtXqj+fpQY3i1bqFrgEqs1WwWzQqbw@mail.gmail.com>
References: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
	<CAGxFJbQr2HFVy7K-H5FFBVZT7K4G6=+-9nQL9Q3=BpQeB9UM8g@mail.gmail.com>
	<CAM9Qe4gBctQDctAjPzoNBtXqj+fpQY3i1bqFrgEqs1WwWzQqbw@mail.gmail.com>
Message-ID: <CAM9Qe4giTr6tA2-hB5yhoUV_28=1RWBFhXLktj6LXz+Vy21Qkg@mail.gmail.com>

Hi Bert;

I do appreciate for this. I need check your codes on task2 tomorrow at my
office on the real data as I have difficulty (because a technical issue) to
remote connection. I am sure it will work well.

I am sorry that I was not able to explain my first question. Basically

Values in ref data represent the region of chromosome. I need choose these
regions in map (all regions values in ref data are exist in map data in the
first column -column map$reg). And then summing up the column "map$rate and
count the numbers that gives >0.85. For example, consider  the first row in
data ref. They are 29220   and  63933. After sorting the first column in
map then summing column "map$rate" only between 29220   to  63933 in sorted
map and cut off at >0.85. Then count how many rows in sorted map gives
>0.85. For example consider there are 38 rows between 29220   in  63933 in sorted
map$reg and only summing first 12 of them  gives>0.85. Then my answer is
going to be 12 for 29220   -  63933 in ref.

Thanks I lot for your patience.

Cheers,
Greg

On Sun, Jun 12, 2016 at 10:35 PM, greg holly <mak.hholly at gmail.com> wrote:

> Hi Bert;
>
> I do appreciate for this. I need check your codes on task2 tomorrow at my
> office on the real data as I have difficulty (because a technical issue) to
> remote connection. I am sure it will work well.
>
> I am sorry that I was not able to explain my first question. Basically
>
> Values in ref data represent the region of chromosome. I need choose these
> regions in map (all regions values in ref data are exist in map data in the
> first column -column map$reg). And then summing up the column "map$rate and
> count the numbers that gives >0.85. For example, consider  the first row in
> data ref. They are 29220   and  63933. After sorting the first column in
> map then summing column "map$rate" only between 29220   to  63933 in
> sorted map and cut off at >0.85. Then count how many rows in sorted map
> gives >0.85. For example consider there are 38 rows between 29220   in
>  63933 in sorted map$reg and only summing first 12 of them  gives>0.85.
> Then my answer is going to be 12 for 29220   -  63933 in ref.
>
> Thanks I lot for your patience.
>
> Cheers,
> Greg
>
> On Sun, Jun 12, 2016 at 6:36 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> Greg:
>>
>> I was not able to understand your task 1. Perhaps others can.
>>
>> My understanding of your task 2 is that for each row of ref, you wish
>> to find all rows,of map such that the reg values in those rows fall
>> between the reg1 and reg2 values in ref (inclusive change <= to < if
>> you don't want the endpoints), and then you want the minimum map$p
>> values of all those rows. If that is correct, I believe this will do
>> it (but caution, untested, as you failed to provide data in a
>> convenient form, e.g. using dput() )
>>
>> task2 <- with(map,vapply(seq_len(nrow(ref)),function(i)
>> min(p[ref[i,1]<=reg & reg <= ref[i,2] ]),0))
>>
>>
>> If my understanding is incorrect, please ignore both the above and the
>> following:
>>
>>
>> The "solution" I have given above seems inefficient, so others may be
>> able to significantly improve it if you find that it takes too long.
>> OTOH, my understanding of your specification is that you need to
>> search for all rows in map data frame that meet the criterion for each
>> row of ref, and without further information, I don't know how to do
>> this without just repeating the search 560 times.
>>
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Jun 12, 2016 at 1:14 PM, greg holly <mak.hholly at gmail.com> wrote:
>> > Dear all;
>> >
>> >
>> >
>> > I have two data sets, data=map and data=ref). A small part of each data
>> set
>> > are given below. Data map has more than 27 million and data ref has
>> about
>> > 560 rows. Basically I need run two different task. My R codes for these
>> > task are given below but they do not work properly.
>> >
>> > I sincerely do appreciate your helps.
>> >
>> >
>> > Regards,
>> >
>> > Greg
>> >
>> >
>> >
>> > Task 1)
>> >
>> > For example, the first and second columns for row 1 in data ref are
>> 29220
>> > 63933. So I need write an R code normally first look the first row in
>> ref
>> > (which they are 29220 and 63933) than summing the column of "map$rate"
>> and
>> > give the number of rows that >0.85. Then do the same for the second,
>> > third....in ref. At the end I would like a table gave below (the
>> results I
>> > need). Please notice the all value specified in ref data file are exist
>> in
>> > map$reg column.
>> >
>> >
>> >
>> > Task2)
>> >
>> > Again example, the first and second columns for row 1 in data ref are
>> 29220
>> > 63933. So I need write an R code give the minimum map$p for the 29220
>> > -63933 intervals in map file. Than
>> >
>> > do the same for the second, third....in ref.
>> >
>> >
>> >
>> >
>> > #my attempt for the first question
>> >
>> > temp<-map[order(map$reg, map$p),]
>> >
>> > count<-1
>> >
>> > temp<-unique(temp$reg
>> >
>> > for(i in 1:length(ref) {
>> >
>> >   for(j in 1:length(ref)
>> >
>> >   {
>> >
>> > temp1<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,]
>> > & temp[cumsum(temp$rate)
>> >>0.70,])
>> >
>> > count=count+1
>> >
>> >     }
>> >
>> > }
>> >
>> > #my attempt for the second question
>> >
>> >
>> >
>> > temp<-map[order(map$reg, map$p),]
>> >
>> > count<-1
>> >
>> > temp<-unique(temp$reg
>> >
>> > for(i in 1:length(ref) {
>> >
>> >   for(j in 1:length(ref)
>> >
>> >   {
>> >
>> > temp2<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,])
>> >
>> > output<-temp2[temp2$p==min(temp2$p),]
>> >
>> >     }
>> >
>> > }
>> >
>> >
>> >
>> > Data sets
>> >
>> >
>> >   Data= map
>> >
>> >   reg   p      rate
>> >
>> >  10276 0.700  3.867e-18
>> >
>> >  71608 0.830  4.542e-16
>> >
>> >  29220 0.430  1.948e-15
>> >
>> >  99542 0.220  1.084e-15
>> >
>> >  26441 0.880  9.675e-14
>> >
>> >  95082 0.090  7.349e-13
>> >
>> >  36169 0.480  9.715e-13
>> >
>> >  55572 0.500  9.071e-12
>> >
>> >  65255 0.300  1.688e-11
>> >
>> >  51960 0.970  1.163e-10
>> >
>> >  55652 0.388  3.750e-10
>> >
>> >  63933 0.250  9.128e-10
>> >
>> >  35170 0.720  7.355e-09
>> >
>> >  06491 0.370  1.634e-08
>> >
>> >  85508 0.470  1.057e-07
>> >
>> >  86666 0.580  7.862e-07
>> >
>> >  04758 0.810  9.501e-07
>> >
>> >  06169 0.440  1.104e-06
>> >
>> >  63933 0.750  2.624e-06
>> >
>> >  41838 0.960  8.119e-06
>> >
>> >
>> >  data=ref
>> >
>> >   reg1         reg2
>> >
>> >   29220     63933
>> >
>> >   26441     41838
>> >
>> >   06169     10276
>> >
>> >   74806     92643
>> >
>> >   73732     82451
>> >
>> >   86042     93502
>> >
>> >   85508     95082
>> >
>> >
>> >
>> >        the results I need
>> >
>> >      reg1      reg2 n
>> >
>> >    29220   63933  12
>> >
>> >    26441   41838   78
>> >
>> >    06169 10276  125
>> >
>> >    74806 92643   11
>> >
>> >    73732 82451   47
>> >
>> >    86042 93502   98
>> >
>> >    85508 95082  219
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Mon Jun 13 04:41:06 2016
From: mak.hholly at gmail.com (greg holly)
Date: Sun, 12 Jun 2016 22:41:06 -0400
Subject: [R] two difficult loop
In-Reply-To: <CA+8X3fVv_pBoSmnE2DS_KXHL9+cWe7-kLZSPOs03YK5_mo_8Pg@mail.gmail.com>
References: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
	<CA+8X3fVv_pBoSmnE2DS_KXHL9+cWe7-kLZSPOs03YK5_mo_8Pg@mail.gmail.com>
Message-ID: <CAM9Qe4ivcqw4NEONrjD0FO_49O=frLhwHw2WtoeHcsxnDkh8ZQ@mail.gmail.com>

Hi Jim;

Thanks so much for this info. I did not know this as I am very much new in
R, So do you think that, rather than using unique !duplicated would be
better to use?

Thanks in advance,

Greg

On Sun, Jun 12, 2016 at 7:06 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Greg,
> You've got a problem that you don't seem to have identified. Your
> "reg" field in the "map" data frame can define at most 100000 unique
> values. This means that each value will be repeated about 270 times.
> Unless there are constraints you haven't mentioned, we would expect
> that in 135 cases for each value, the values in each "ref" row will be
> in the reverse order and the spans may overlap. I notice that you may
> have tried to get around this by sorting the "map" data frame, but
> then the order of the rows is different, and the number of rows
> "between" any two values changes. Apart from this, it is almost
> certain that the number of values of "p > 0.85" in the multiple runs
> between each set of "ref" values will be different. It is possible to
> perform both tasks that you mention, but only the second will yield an
> unique or tied value for all of the cases. So your result data frame
> will have an unspecified number of values for each row in "ref" for
> the first task.
>
> Jim
>
>
> On Mon, Jun 13, 2016 at 6:14 AM, greg holly <mak.hholly at gmail.com> wrote:
> > Dear all;
> >
> >
> >
> > I have two data sets, data=map and data=ref). A small part of each data
> set
> > are given below. Data map has more than 27 million and data ref has about
> > 560 rows. Basically I need run two different task. My R codes for these
> > task are given below but they do not work properly.
> >
> > I sincerely do appreciate your helps.
> >
> >
> > Regards,
> >
> > Greg
> >
> >
> >
> > Task 1)
> >
> > For example, the first and second columns for row 1 in data ref are 29220
> > 63933. So I need write an R code normally first look the first row in ref
> > (which they are 29220 and 63933) than summing the column of "map$rate"
> and
> > give the number of rows that >0.85. Then do the same for the second,
> > third....in ref. At the end I would like a table gave below (the results
> I
> > need). Please notice the all value specified in ref data file are exist
> in
> > map$reg column.
> >
> >
> >
> > Task2)
> >
> > Again example, the first and second columns for row 1 in data ref are
> 29220
> > 63933. So I need write an R code give the minimum map$p for the 29220
> > -63933 intervals in map file. Than
> >
> > do the same for the second, third....in ref.
> >
> >
> >
> >
> > #my attempt for the first question
> >
> > temp<-map[order(map$reg, map$p),]
> >
> > count<-1
> >
> > temp<-unique(temp$reg
> >
> > for(i in 1:length(ref) {
> >
> >   for(j in 1:length(ref)
> >
> >   {
> >
> > temp1<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,]
> > & temp[cumsum(temp$rate)
> >>0.70,])
> >
> > count=count+1
> >
> >     }
> >
> > }
> >
> > #my attempt for the second question
> >
> >
> >
> > temp<-map[order(map$reg, map$p),]
> >
> > count<-1
> >
> > temp<-unique(temp$reg
> >
> > for(i in 1:length(ref) {
> >
> >   for(j in 1:length(ref)
> >
> >   {
> >
> > temp2<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,])
> >
> > output<-temp2[temp2$p==min(temp2$p),]
> >
> >     }
> >
> > }
> >
> >
> >
> > Data sets
> >
> >
> >   Data= map
> >
> >   reg   p      rate
> >
> >  10276 0.700  3.867e-18
> >
> >  71608 0.830  4.542e-16
> >
> >  29220 0.430  1.948e-15
> >
> >  99542 0.220  1.084e-15
> >
> >  26441 0.880  9.675e-14
> >
> >  95082 0.090  7.349e-13
> >
> >  36169 0.480  9.715e-13
> >
> >  55572 0.500  9.071e-12
> >
> >  65255 0.300  1.688e-11
> >
> >  51960 0.970  1.163e-10
> >
> >  55652 0.388  3.750e-10
> >
> >  63933 0.250  9.128e-10
> >
> >  35170 0.720  7.355e-09
> >
> >  06491 0.370  1.634e-08
> >
> >  85508 0.470  1.057e-07
> >
> >  86666 0.580  7.862e-07
> >
> >  04758 0.810  9.501e-07
> >
> >  06169 0.440  1.104e-06
> >
> >  63933 0.750  2.624e-06
> >
> >  41838 0.960  8.119e-06
> >
> >
> >  data=ref
> >
> >   reg1         reg2
> >
> >   29220     63933
> >
> >   26441     41838
> >
> >   06169     10276
> >
> >   74806     92643
> >
> >   73732     82451
> >
> >   86042     93502
> >
> >   85508     95082
> >
> >
> >
> >        the results I need
> >
> >      reg1      reg2 n
> >
> >    29220   63933  12
> >
> >    26441   41838   78
> >
> >    06169 10276  125
> >
> >    74806 92643   11
> >
> >    73732 82451   47
> >
> >    86042 93502   98
> >
> >    85508 95082  219
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun 13 09:19:13 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 13 Jun 2016 17:19:13 +1000
Subject: [R] two difficult loop
In-Reply-To: <CAM9Qe4giTr6tA2-hB5yhoUV_28=1RWBFhXLktj6LXz+Vy21Qkg@mail.gmail.com>
References: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
	<CAGxFJbQr2HFVy7K-H5FFBVZT7K4G6=+-9nQL9Q3=BpQeB9UM8g@mail.gmail.com>
	<CAM9Qe4gBctQDctAjPzoNBtXqj+fpQY3i1bqFrgEqs1WwWzQqbw@mail.gmail.com>
	<CAM9Qe4giTr6tA2-hB5yhoUV_28=1RWBFhXLktj6LXz+Vy21Qkg@mail.gmail.com>
Message-ID: <CA+8X3fUtMsA91FSkoM9hUuo6DUHFSxHcDcGLM8ivqXBHObRU+w@mail.gmail.com>

Hi Greg,
Okay, I have a better idea now of what you want. The problem of
multiple matches is still there, but here is a start:

# this data frame actually contains all the values in ref in the "reg" field
map<-read.table(text="reg p rate
 10276 0.700  3.867e-18
 71608 0.830  4.542e-16
 29220 0.430  1.948e-15
 99542 0.220  1.084e-15
 26441 0.880  9.675e-14
 95082 0.090  7.349e-13
 36169 0.480  9.715e-13
 55572 0.500  9.071e-12
 65255 0.300  1.688e-11
 51960 0.970  1.163e-10
 55652 0.388  3.750e-10
 63933 0.250  9.128e-10
 35170 0.720  7.355e-09
 06491 0.370  1.634e-08
 85508 0.470  1.057e-07
 86666 0.580  7.862e-07
 04758 0.810  9.501e-07
 06169 0.440  1.104e-06
 63933 0.750  2.624e-06
 41838 0.960  8.119e-06
 74806 0.810  9.501e-07
 92643 0.470  1.057e-07
 73732 0.090  7.349e-13
 82451 0.960  8.119e-06
 86042 0.480  9.715e-13
 93502 0.500  9.071e-12
 85508 0.370  1.634e-08
 95082 0.830  4.542e-16",
 header=TRUE)
# same as in your example
ref<-read.table(text="reg1 reg2
 29220     63933
 26441     41838
 06169     10276
 74806     92643
 73732     82451
 86042     93502
 85508     95082",
 header=TRUE)
# sort the "map" data frame
map2<-map[order(map$reg),]
# get a field for the counts
ref$n<-NA
# and a field for the minimum p values
ref$min_p<-NA
# get the number of rows in "ref"
nref<-dim(ref)[1]
for(i in 1:nref) {
 start<-which(map2$reg==ref$reg1[i])
 end<-which(map2$reg==ref$reg2[i])
 cat("start",start,"end",end,"\n")
 # get the range of matches
 regrange<-range(c(start,end))
 # convert this to a sequence spanning all matches
 allreg<-regrange[1]:regrange[2]
 ref$n[i]<-sum(map2$p[allreg] > 0.85)
 ref$min_p[i]<-min(map2$p[allreg])
}

This example uses the span from the first match of "reg1" to the last
match of "reg2". This may not be what you want, so let me know if
there are further constraints.

Jim

On Mon, Jun 13, 2016 at 12:35 PM, greg holly <mak.hholly at gmail.com> wrote:
> Hi Bert;
>
> I do appreciate for this. I need check your codes on task2 tomorrow at my
> office on the real data as I have difficulty (because a technical issue) to
> remote connection. I am sure it will work well.
>
> I am sorry that I was not able to explain my first question. Basically
>
> Values in ref data represent the region of chromosome. I need choose these
> regions in map (all regions values in ref data are exist in map data in the
> first column -column map$reg). And then summing up the column "map$rate and
> count the numbers that gives >0.85. For example, consider  the first row in
> data ref. They are 29220   and  63933. After sorting the first column in
> map then summing column "map$rate" only between 29220   to  63933 in sorted
> map and cut off at >0.85. Then count how many rows in sorted map gives
>>0.85. For example consider there are 38 rows between 29220   in  63933 in sorted
> map$reg and only summing first 12 of them  gives>0.85. Then my answer is
> going to be 12 for 29220   -  63933 in ref.
>
> Thanks I lot for your patience.
>
> Cheers,
> Greg
>
> On Sun, Jun 12, 2016 at 10:35 PM, greg holly <mak.hholly at gmail.com> wrote:
>
>> Hi Bert;
>>
>> I do appreciate for this. I need check your codes on task2 tomorrow at my
>> office on the real data as I have difficulty (because a technical issue) to
>> remote connection. I am sure it will work well.
>>
>> I am sorry that I was not able to explain my first question. Basically
>>
>> Values in ref data represent the region of chromosome. I need choose these
>> regions in map (all regions values in ref data are exist in map data in the
>> first column -column map$reg). And then summing up the column "map$rate and
>> count the numbers that gives >0.85. For example, consider  the first row in
>> data ref. They are 29220   and  63933. After sorting the first column in
>> map then summing column "map$rate" only between 29220   to  63933 in
>> sorted map and cut off at >0.85. Then count how many rows in sorted map
>> gives >0.85. For example consider there are 38 rows between 29220   in
>>  63933 in sorted map$reg and only summing first 12 of them  gives>0.85.
>> Then my answer is going to be 12 for 29220   -  63933 in ref.
>>
>> Thanks I lot for your patience.
>>
>> Cheers,
>> Greg
>>
>> On Sun, Jun 12, 2016 at 6:36 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> Greg:
>>>
>>> I was not able to understand your task 1. Perhaps others can.
>>>
>>> My understanding of your task 2 is that for each row of ref, you wish
>>> to find all rows,of map such that the reg values in those rows fall
>>> between the reg1 and reg2 values in ref (inclusive change <= to < if
>>> you don't want the endpoints), and then you want the minimum map$p
>>> values of all those rows. If that is correct, I believe this will do
>>> it (but caution, untested, as you failed to provide data in a
>>> convenient form, e.g. using dput() )
>>>
>>> task2 <- with(map,vapply(seq_len(nrow(ref)),function(i)
>>> min(p[ref[i,1]<=reg & reg <= ref[i,2] ]),0))
>>>
>>>
>>> If my understanding is incorrect, please ignore both the above and the
>>> following:
>>>
>>>
>>> The "solution" I have given above seems inefficient, so others may be
>>> able to significantly improve it if you find that it takes too long.
>>> OTOH, my understanding of your specification is that you need to
>>> search for all rows in map data frame that meet the criterion for each
>>> row of ref, and without further information, I don't know how to do
>>> this without just repeating the search 560 times.
>>>
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sun, Jun 12, 2016 at 1:14 PM, greg holly <mak.hholly at gmail.com> wrote:
>>> > Dear all;
>>> >
>>> >
>>> >
>>> > I have two data sets, data=map and data=ref). A small part of each data
>>> set
>>> > are given below. Data map has more than 27 million and data ref has
>>> about
>>> > 560 rows. Basically I need run two different task. My R codes for these
>>> > task are given below but they do not work properly.
>>> >
>>> > I sincerely do appreciate your helps.
>>> >
>>> >
>>> > Regards,
>>> >
>>> > Greg
>>> >
>>> >
>>> >
>>> > Task 1)
>>> >
>>> > For example, the first and second columns for row 1 in data ref are
>>> 29220
>>> > 63933. So I need write an R code normally first look the first row in
>>> ref
>>> > (which they are 29220 and 63933) than summing the column of "map$rate"
>>> and
>>> > give the number of rows that >0.85. Then do the same for the second,
>>> > third....in ref. At the end I would like a table gave below (the
>>> results I
>>> > need). Please notice the all value specified in ref data file are exist
>>> in
>>> > map$reg column.
>>> >
>>> >
>>> >
>>> > Task2)
>>> >
>>> > Again example, the first and second columns for row 1 in data ref are
>>> 29220
>>> > 63933. So I need write an R code give the minimum map$p for the 29220
>>> > -63933 intervals in map file. Than
>>> >
>>> > do the same for the second, third....in ref.
>>> >
>>> >
>>> >
>>> >
>>> > #my attempt for the first question
>>> >
>>> > temp<-map[order(map$reg, map$p),]
>>> >
>>> > count<-1
>>> >
>>> > temp<-unique(temp$reg
>>> >
>>> > for(i in 1:length(ref) {
>>> >
>>> >   for(j in 1:length(ref)
>>> >
>>> >   {
>>> >
>>> > temp1<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,]
>>> > & temp[cumsum(temp$rate)
>>> >>0.70,])
>>> >
>>> > count=count+1
>>> >
>>> >     }
>>> >
>>> > }
>>> >
>>> > #my attempt for the second question
>>> >
>>> >
>>> >
>>> > temp<-map[order(map$reg, map$p),]
>>> >
>>> > count<-1
>>> >
>>> > temp<-unique(temp$reg
>>> >
>>> > for(i in 1:length(ref) {
>>> >
>>> >   for(j in 1:length(ref)
>>> >
>>> >   {
>>> >
>>> > temp2<-if (temp[pos[i]==ref[ref$reg1,] & (temp[pos[j]==ref[ref$reg2,])
>>> >
>>> > output<-temp2[temp2$p==min(temp2$p),]
>>> >
>>> >     }
>>> >
>>> > }
>>> >
>>> >
>>> >
>>> > Data sets
>>> >
>>> >
>>> >   Data= map
>>> >
>>> >   reg   p      rate
>>> >
>>> >  10276 0.700  3.867e-18
>>> >
>>> >  71608 0.830  4.542e-16
>>> >
>>> >  29220 0.430  1.948e-15
>>> >
>>> >  99542 0.220  1.084e-15
>>> >
>>> >  26441 0.880  9.675e-14
>>> >
>>> >  95082 0.090  7.349e-13
>>> >
>>> >  36169 0.480  9.715e-13
>>> >
>>> >  55572 0.500  9.071e-12
>>> >
>>> >  65255 0.300  1.688e-11
>>> >
>>> >  51960 0.970  1.163e-10
>>> >
>>> >  55652 0.388  3.750e-10
>>> >
>>> >  63933 0.250  9.128e-10
>>> >
>>> >  35170 0.720  7.355e-09
>>> >
>>> >  06491 0.370  1.634e-08
>>> >
>>> >  85508 0.470  1.057e-07
>>> >
>>> >  86666 0.580  7.862e-07
>>> >
>>> >  04758 0.810  9.501e-07
>>> >
>>> >  06169 0.440  1.104e-06
>>> >
>>> >  63933 0.750  2.624e-06
>>> >
>>> >  41838 0.960  8.119e-06
>>> >
>>> >
>>> >  data=ref
>>> >
>>> >   reg1         reg2
>>> >
>>> >   29220     63933
>>> >
>>> >   26441     41838
>>> >
>>> >   06169     10276
>>> >
>>> >   74806     92643
>>> >
>>> >   73732     82451
>>> >
>>> >   86042     93502
>>> >
>>> >   85508     95082
>>> >
>>> >
>>> >
>>> >        the results I need
>>> >
>>> >      reg1      reg2 n
>>> >
>>> >    29220   63933  12
>>> >
>>> >    26441   41838   78
>>> >
>>> >    06169 10276  125
>>> >
>>> >    74806 92643   11
>>> >
>>> >    73732 82451   47
>>> >
>>> >    86042 93502   98
>>> >
>>> >    85508 95082  219
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Jun 13 14:05:29 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 13 Jun 2016 12:05:29 +0000
Subject: [R] summing up a column.
In-Reply-To: <542840655.919423.1465592922434.JavaMail.yahoo@mail.yahoo.com>
References: <31785661.876929.1465590843856.JavaMail.yahoo.ref@mail.yahoo.com>
	<31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>
	<FCDDB5B3-2D68-4BE7-AD53-4FB3AA9C2861@dcn.davis.ca.us>
	<764714753.876287.1465592795459.JavaMail.yahoo@mail.yahoo.com>
	<542840655.919423.1465592922434.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030449@SRVEXCHMBX.precheza.cz>

Ok.

Instead of explaining what you have, please send a result of

dput(B) and dput(A)

And set you mail client to send plain text mail otherwise your code is barely readable.

What do you want to do with printed values?

What is B? From this it seems that it is data frame but then you try to put sorted data frame into a data frame column.

B$possort=B[order(B$pos),]

With such code and data frame I get an error.

So please try to keep above mentioned when posting a query.

Regards
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of oslo via R-
> help
> Sent: Friday, June 10, 2016 11:09 PM
> To: oslo <oslo at yahoo.com>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>;
> oslo via R-help <r-help at r-project.org>; oslo <hokut1 at yahoo.com>
> Subject: Re: [R] summing up a column.
>
> Jeff;
>  thanks for this. My question was job related. No from my course. I need
> finish a job for the place I work. I am so sorry for causing misunderstanding.
> thanks,
> Oslo
>
>     On Friday, June 10, 2016 5:08 PM, oslo via R-help <r-help at r-project.org>
> wrote:
>
>
>  Jeff thanks for this. My question was job related. No from my course. I need
> finish a job for the place I work. I am so sorry for causing misunderstanding.
> thanks,
> Oslo
>
>     On Friday, June 10, 2016 5:02 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>
>
>  Multiple posting happens when you are learning a new system, but reading
> the posting guide can keep the bleeding down.
>
> 1) There is a no-homework policy on this list... different educational
> organizations have different standards for what is acceptable outside help,
> so you should be using the support offered by your instructor or educational
> institution.
>
> 2) Once you have completed your course, you CAN learn to post data with
> your code so that it is self-contained... that is, reproducible on our vanilla R
> session. Using the dput function is one excellent strategy.
>
> 3) This is not a problem that needs a loop... as Bert (not Bret) said, you can do
> this in one or two statements if you simply use basic logical indexing. If your
> instructor wants you to do it with a loop for sine reason then you really really
> should not be here... you should be talking to him/her.
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 10, 2016 1:34:03 PM PDT, oslo via R-help <r-help at r-project.org>
> wrote:
> Dear All;
> I had difficulty to post a mail along with appropriate of data structure. I do
> sincerely apologize for multiple posting
>
>
> I would like to sum up the B$a column and cut off at 0.7 for the each row of
> intervals giving in file=A.For example the interval  at the first row in A$posA
> and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from
> the 1 to 9 in B$pos. And then I need to the same using the intervals in the
> second, third..... rows in A. Obviously my loop is wrong and  does not work
> properly. Please help for my this first experience.  Regards Here are my
> codes #sorting B$possort=B[order(B$pos),] #Running loop for(i in 1:nrow(A))
> {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } } Reply, R R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Mon Jun 13 14:09:50 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 13 Jun 2016 12:09:50 +0000
Subject: [R] Merging two data frame with different lengths
In-Reply-To: <CABbYsteQEn6+WqNbMbHHzdM+mmyOkYYdqF=0+xHUj91bf_c=eg@mail.gmail.com>
References: <CABbYsteQEn6+WqNbMbHHzdM+mmyOkYYdqF=0+xHUj91bf_c=eg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50304A5@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Abraham
> Mathew
> Sent: Friday, June 10, 2016 6:15 PM
> To: r-help at r-project.org
> Subject: [R] Merging two data frame with different lengths
>
> So I have two data frames.
>
> The first one is a reccomendation data frame and the second is a melted list
> with a pairing of OpportunityId's and ProductId's. There are multiple product
> id's per an opportunty id. What I want to do is merge based on ProductId so
> that I can add the OpportunityId to the reccomendation data frame.
>
> > head(product_neighbours_orig[,1:3],2)           ProductId
> Reccomendation_1   Reccomendation_2
> 1 01t30000001ik30AAA 01ta0000005SivAAAS 01ta0000005RQimAAG
> 2 01t30000001ik3vAAA 01t30000001ik5bAAA 01t30000001ikKPAAY>
> head(pd_melt[,1:3],2)          OpportunityId          ProductId value
> 4826 0063000000bqUKlAAM 01t30000001ik3vAAA     0
> 9651 0063000000bqUKlAAM 01t30000001ik41AAA     0
>
>
>
>
>
> Any suggestions?
>

Suggestion 1 : Do not use HTML post, configure your mail client to send plain text emails
Suggestion 2 : merge(product_neighbours_orig, pd_melt, all = TRUE)

Regards
Petr


> --
>
>
> *Abraham MathewData Ninja and Statistical Modeler*
>
>
>
> *Minneapolis, MN720-648-0108 at abmathewksAnalytics_Blog
> <https://mathewanalytics.wordpress.com/>*
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From hokut1 at yahoo.com  Mon Jun 13 15:45:07 2016
From: hokut1 at yahoo.com (oslo)
Date: Mon, 13 Jun 2016 13:45:07 +0000 (UTC)
Subject: [R] summing up a column.
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030449@SRVEXCHMBX.precheza.cz>
References: <31785661.876929.1465590843856.JavaMail.yahoo.ref@mail.yahoo.com>
	<31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>
	<FCDDB5B3-2D68-4BE7-AD53-4FB3AA9C2861@dcn.davis.ca.us>
	<764714753.876287.1465592795459.JavaMail.yahoo@mail.yahoo.com>
	<542840655.919423.1465592922434.JavaMail.yahoo@mail.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030449@SRVEXCHMBX.precheza.cz>
Message-ID: <1670840319.1796223.1465825507940.JavaMail.yahoo@mail.yahoo.com>

Hi Petr;
Thanks so much. Here are the questions and the dput(A) and dput(B). Basicaly I have two questions;
> dput(A)structure(list(posA = c(1L, 2L, 5L, 4L, 9L), posB = c(9L, 7L,?12L, 7L, 13L)), .Names = c("posA", "posB"), class = "data.frame", row.names = c(NA,?-5L))> dput(B)structure(list(pos = c(4L, 2L, 7L, 1L, 13L, 12L, 9L), a = c(0.4,?0.1, 0.5, 0.4, 0.1, 0.2, 0.3), b = c(7L, 5L, 8L, 1L, 6L, 11L,?12L), c = c(0.8, 0.4, 0.32, 0.1, 0.13, 0.01, 0.23)), .Names = c("pos",?"a", "b", "c"), class = "data.frame", row.names = c(NA, -7L))
Q1) Values in A represent the region of chromosome. I need choose these regions in B (all region in A are exist in B in a single column) and then summing up the column "a in B and count the numbers that gives >0.7. For example, consider ?the first row in A. They are 1 and 9. After sorting the first column in B then summing column "a" only between 1 to 9 in sorted B and cut off at >0.7. Then count how many rows in sorted B gives >0.7. For example there are only 5 rows between 1 to 9 in sorted B and only summing first 2 of them ?gives>0.7 . Then my answer is going to be 2
Q2) What is the min value of B$a for given each intervals in A
Regards,
Oslo 

    On Monday, June 13, 2016 8:05 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
 

 Ok.

Instead of explaining what you have, please send a result of

dput(B) and dput(A)

And set you mail client to send plain text mail otherwise your code is barely readable.

What do you want to do with printed values?

What is B? From this it seems that it is data frame but then you try to put sorted data frame into a data frame column.

B$possort=B[order(B$pos),]

With such code and data frame I get an error.

So please try to keep above mentioned when posting a query.

Regards
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of oslo via R-
> help
> Sent: Friday, June 10, 2016 11:09 PM
> To: oslo <oslo at yahoo.com>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>;
> oslo via R-help <r-help at r-project.org>; oslo <hokut1 at yahoo.com>
> Subject: Re: [R] summing up a column.
>
> Jeff;
>? thanks for this. My question was job related. No from my course. I need
> finish a job for the place I work. I am so sorry for causing misunderstanding.
> thanks,
> Oslo
>
>? ? On Friday, June 10, 2016 5:08 PM, oslo via R-help <r-help at r-project.org>
> wrote:
>
>
>? Jeff thanks for this. My question was job related. No from my course. I need
> finish a job for the place I work. I am so sorry for causing misunderstanding.
> thanks,
> Oslo
>
>? ? On Friday, June 10, 2016 5:02 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>
>
>? Multiple posting happens when you are learning a new system, but reading
> the posting guide can keep the bleeding down.
>
> 1) There is a no-homework policy on this list... different educational
> organizations have different standards for what is acceptable outside help,
> so you should be using the support offered by your instructor or educational
> institution.
>
> 2) Once you have completed your course, you CAN learn to post data with
> your code so that it is self-contained... that is, reproducible on our vanilla R
> session. Using the dput function is one excellent strategy.
>
> 3) This is not a problem that needs a loop... as Bert (not Bret) said, you can do
> this in one or two statements if you simply use basic logical indexing. If your
> instructor wants you to do it with a loop for sine reason then you really really
> should not be here... you should be talking to him/her.
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 10, 2016 1:34:03 PM PDT, oslo via R-help <r-help at r-project.org>
> wrote:
> Dear All;
> I had difficulty to post a mail along with appropriate of data structure. I do
> sincerely apologize for multiple posting
>
>
> I would like to sum up the B$a column and cut off at 0.7 for the each row of
> intervals giving in file=A.For example the interval? at the first row in A$posA
> and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from
> the 1 to 9 in B$pos. And then I need to the same using the intervals in the
> second, third..... rows in A. Obviously my loop is wrong and? does not work
> properly. Please help for my this first experience.? Regards Here are my
> codes #sorting B$possort=B[order(B$pos),] #Running loop for(i in 1:nrow(A))
> {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } } Reply, R R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


  
	[[alternative HTML version deleted]]


From fotisfotiadis at gmail.com  Mon Jun 13 15:59:55 2016
From: fotisfotiadis at gmail.com (Fotis Fotiadis)
Date: Mon, 13 Jun 2016 16:59:55 +0300
Subject: [R] itsadug:: plot_smooth and plot_diff
In-Reply-To: <CAGxFJbRs77M=wSqaU3TYC1uK-h6YzY-MgCaNxpV9OdFjN-xrsQ@mail.gmail.com>
References: <CAAO1NncVRe0O1VrBBUuJB_kA7GgZUwQKYXso+Acac-HykgK0JA@mail.gmail.com>
	<CAGxFJbRs77M=wSqaU3TYC1uK-h6YzY-MgCaNxpV9OdFjN-xrsQ@mail.gmail.com>
Message-ID: <CAAO1Nnf0zUZrTwUhTJQbxf-LvB2uKtcV1A6sP7K7PYb9ks5UtA@mail.gmail.com>

Dear Bert,
Thank you for your response

Best,
Fotis

On Sun, Jun 12, 2016 at 5:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> To be clear, I know nothing about bam; I just wanted to correct a
> statistical error:
>
> "Since the 95% confidence intervals overlap, I would assume that there is
> no
> difference in accuracy between the two conditions."
>
> That is false. You need to look at a CI for the difference.
>
> As you appear to be confused about the statistical issues, I suggest
> you post on a statistical site like stats.stackexchange.com or consult
> a local statistician.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Jun 12, 2016 at 7:03 AM, Fotis Fotiadis <fotisfotiadis at gmail.com>
> wrote:
> > Hi all
> >
> > I am using bam to analyse the data from my experiment.
> > It's a learning experiment, "acc" denotes accuracy and "cnd" denotes a
> > within-subjects variable (with two levels, "label" and "ideo")."Ctrial"
> is
> > centered trial (ranging from 1 to 288).
> >
> > The model is:
> > bam(acc~ 1 + cnd + s(ctrial) + s(ctrial, sbj, bs = "fs", m = 1),
> data=data,
> > family=binomial)
> >
> > The model doesn't include two different smooths (one for each condition)
> > since including two smooths does not result to a more parsimonious model,
> > according to following model comparison:
> >> compareML(m0.2, m1.2)
> > m0.2: acc ~ 1 + cnd + s(ctrial) + s(ctrial, sbj, bs = "fs", m = 1)
> >
> > m1.2: acc ~ 1 + cnd + s(ctrial, by = cnd) + s(ctrial, sbj, bs = "fs",
> >     m = 1)
> >
> > Chi-square test of fREML scores
> > -----
> >   Model    Score Edf Chisq    Df   p.value Sig.
> > 1  m0.2 10183.31   6
> > 2  m1.2 10173.33   8 9.975 2.000 4.654e-05  ***
> >
> > AIC difference: -2.16, model m0.2 has lower AIC.
> >
> >
> > So, I'm trying to assess if there's a difference in accuracy between the
> > two conditions.
> >
> > When using the plot_smooth function, the model predictions are the ones
> > shown in Fig.1.
> > The code used is:
> > plot_smooth(fm, view="ctrial",
> > cond=list(cnd="pseudo"),main="Model",xaxt="n",
> > xlab="Trial",ylab="Proportion Correct", lwd=2, las=2, rm.ranef=TRUE,
> > rug=FALSE, shade=T, col="red" )
> > plot_smooth(fm, view="ctrial", cond=list(cnd="ideo"), xaxt="n",
> > rm.ranef=TRUE, rug=FALSE, shade=T, col="blue", add=T , lty=2, lwd=2)
> > legend(x=0.8, y=1.5,legend=c('Label', 'Ideogram'),col=c('red', 'blue'),
> > lty=c(1,2), bty="n", lwd=2)
> >
> > Since the 95% confidence intervals overlap, I would assume that there is
> no
> > difference in accuracy between the two conditions.
> >
> > I am also using plot_diff to directly plot the difference:
> > plot_diff(fm, view="ctrial",comp=list(cnd=c("pseudo", "ideo")),
> > transform.view=dnrmlz,rm.ranef=T)
> > (dnrmlz is a simple function to de-normalize trial)
> >
> > The output of the function is:
> > Summary:
> > * ctrial : numeric predictor; with 100 values ranging from -1.725936 to
> > 1.725936.
> > * sbj : factor; set to the value(s): aggmpo96. (Might be canceled as
> random
> > effect, check below.)
> > * NOTE : The following random effects columns are canceled: s(ctrial,sbj)
> >
> > * Note: x-values are transformed.
> >             Significant
> > 1 0.759461 - 288.240539
> >
> > So, it seems that accuracy in the label condition is higher compared to
> the
> > ideo condition throughout the experiment.
> > This result seems to contradict the previous one.
> >
> > I am obviously misinterpreting something.
> > Any ideas on what am I doing wrong?
> >
> > Thank you in advance for your time,
> > Fotis
> >
> >
> >
> >
> >
> >
> >
> > --
> > PhD Candidate
> > Department of Philosophy and History of Science
> > University of Athens, Greece.
> > http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis
> >
> > Notice: Please do not use this account for social networks invitations,
> for
> > sending chain-mails to me, or as it were a facebook account. Thank you
> for
> > respecting my privacy.
> >
> > <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> > Virus-free.
> > www.avast.com
> > <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> > <#DDB4FAA8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
PhD Candidate
Department of Philosophy and History of Science
University of Athens, Greece.
http://users.uoa.gr/~aprotopapas/LLL/en/members.html#fotisfotiadis

Notice: Please do not use this account for social networks invitations, for
sending chain-mails to me, or as it were a facebook account. Thank you for
respecting my privacy.

	[[alternative HTML version deleted]]


From mark.fingerle at brainlab.com  Mon Jun 13 10:47:43 2016
From: mark.fingerle at brainlab.com (Mark Fingerle)
Date: Mon, 13 Jun 2016 08:47:43 +0000
Subject: [R] Assign value to plot variable name (make.group functions)
Message-ID: <7e40e0efcc0847048b4831bf1d282453@despmsx02.brainlab.net>

Dear all,

In order to create plots comparing two measurements I am using the "xyplot" and "make.groups" functions (see script example below).
Now I would like to assign a value to the variable names in the plot. Meaning: In the beginning of my script I assign a name(value) to a variable (for example:  ID1 <- Name1). Now I would like to use this variable to name the plot variables.

Maybe easier to understand using an example:

Script:

pdf("REP_Chess.pdf")
scChess1=xyplot( x = ObjErrorX~Image, data=make.groups("ID1"=Chess1, "ID2"=Chess2),
             pch=16 ,main="Chess - Object Error X [mm]", auto.key=T, groups=which, scales=list(relation="free",
                                                                              y=list(rot=0), x=list(rot=45), abbreviate = TRUE),

print(scChess1, split=c(1,1,1,1), more=False)
dev.off()

I would like to assign a value to ID1, so that this value is shown on the plot labels after it is printed.
Something like : ID1 <- Name1 , and Name1 is shown in the plots.


Thank you very much in advance.

Cheers
Mark Fingerle



	[[alternative HTML version deleted]]


From dianxiangan32 at sina.cn  Mon Jun 13 15:22:42 2016
From: dianxiangan32 at sina.cn (RuiRui)
Date: Mon, 13 Jun 2016 21:22:42 +0800
Subject: [R] [R-sig-ME] multcomp package
Message-ID: <20160613132242.7401C6C0196@webmail.sinamail.sina.com.cn>

Hi,

It seems you want to test the fixed effect. So I think the related p-value is appropriate. I'm not sure...


--------------------------------


----- Original Message -----
From: li li <hannah.hlx at gmail.com>
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>, r-help <r-help at r-project.org>, epalmery at cns.umass.edu
Subject: Re: [R-sig-ME] multcomp package
Date: 2016-06-07 11:32


Thanks Evan and Gabriel for the reply. I think it might help me make the
question clearer if I show the data and the model here (I actually asked
questions related to this data before but I still need some help). The data
looks like the following:
   response individual time method
1    102.9          3    0      3
2    103.0          3    3      3
3    103.0          3    6      3
4    102.8          3    9      3
5    102.2          3   12      3
6    102.5          3   15      3
7    103.0          3   18      3
8    102.0          3   24      3
9    102.8          1    0      3
10   102.7          1    3      3
11   103.0          1    6      3
12   102.2          1    9      3
13   103.0          1   12      3
14   102.8          1   15      3
15   102.8          1   18      3
16   102.9          1   24      3
17   102.2          2    0      3
18   102.6          2    3      3
19   103.4          2    6      3
20   102.3          2    9      3
21   101.3          2   12      3
22   102.1          2   15      3
23   102.1          2   18      3
24   102.2          2   24      3
25   102.7          4    0      3
26   102.3          4    3      3
27   102.6          4    6      3
28   102.7          4    9      3
29   102.8          4   12      3
30   102.5          5    0      3
31   102.4          5    3      3
32   102.1          5    6      3
33   102.3          6    0      3
34   102.3          6    3      3
35   101.9          7    0      3
36   102.0          7    3      3
37   107.4          3    0      1
38   101.3          3   12      1
39    92.8          3   15      1
40    73.7          3   18      1
41   104.7          3   24      1
42    92.6          1    0      1
43   101.9          1   12      1
44   106.3          1   15      1
45   104.1          1   18      1
46    95.6          1   24      1
47    79.8          2    0      1
48    89.7          2   12      1
49    97.0          2   15      1
50   108.4          2   18      1
51   103.5          2   24      1
52    96.4          4    0      1
53    89.3          4   12      1
54   112.6          5    0      1
55    93.3          6    0      1
56    99.6          7    0      1
57   109.5          3    0      2
58    98.5          3   12      2
59   103.5          3   24      2
60   113.5          1    0      2
61    94.5          1   12      2
62    88.5          1   24      2
63    99.5          2    0      2
64    97.5          2   12      2
65    98.5          2   24      2
66   103.5          4    0      2
67    89.5          5    0      2
68    87.5          6    0      2
69    82.5          7    0      2
I used the following random intercept and random slope model for this data.
Denote as y_ijk the response value from *j*th individual within *i*th
method at time point *k*. Assume the following model for y_ijk:
      y_ijk= (alpha_0+ tau_i +a_j(i))+(beta_i+b_j(i)) T_k + e_ijk
Here alpha_0 is the grand mean;
          tau_i is the fixed effect for ith method;
          a_j(i) is random intercept corresponding to the *j*th individual
within *i*th method, assumed to be common for all three methods;
          beta_i is the fixed slope corresponding to the ith method;
          b_j(i) is the random slope corresponding to jth individual for
the ith method, assumed to be common for all three methods;
          T_k is the time corresponding to y_ijk;
          e_ijk is the residual.
Here I used the following specification for the lme function
mod1 <- lme(fixed= reponse ~ method*time, random=~ 1 +time | individual,
data=one, weights= varIdent(form=~1|method),
            control = lmeControl(opt = "optim"))
I did not add the method in random effects  because here I assumed common
random slope for all three methods.
This model is used to initially check whether there fixed slopes are equal.
I wanted to further evaluate whether each fixed slope (beta_1, beta_2 and
beta 3) is significantly different from zero. I was hoping to evaluate this
based on the same model.
The output is as follows. Does the highlighted part below already gives the
result for testing beta_1=0; beta_2=0 and beta_3=0?
Thanks very much.
   Hanna
> summary(mod1)Linear mixed-effects model fit by REML
 Data: one
       AIC      BIC    logLik
  304.4703 330.1879 -140.2352
Random effects:
 Formula: ~1 + time | individual
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.2487869075 (Intr)
time        0.0001841179 -0.056
Residual    0.3718305953
Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | method
 Parameter estimates:
       3        1        2
 1.00000 26.59750 24.74476
Fixed effects: reponse ~ method * time
                Value Std.Error DF   t-value p-value(Intercept)
96.65395  3.528586 57 27.391694  0.0000
method2       1.17851  4.856026 57  0.242689  0.8091
method3       5.87505  3.528617 57  1.664973  0.1014time
0.07010  0.250983 57  0.279301  0.7810
method2:time -0.12616  0.360585 57 -0.349877  0.7277
method3:time -0.08010  0.251105 57 -0.318999  0.7509
 Correlation:
             (Intr) methd2 methd3 time   mthd2:
method2      -0.726
method3      -0.999  0.726
time         -0.779  0.566  0.779
method2:time  0.542 -0.712 -0.542 -0.696
method3:time  0.778 -0.566 -0.779 -0.999  0.696
Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
Number of Observations: 69
Number of Groups: 7
2016-06-06 11:21 GMT-04:00 Gabriel Baud-Bovy <baud-bovy.gabriel at hsr.it>:
> On 06/06/2016 4:57 PM, li li wrote:
>
> Hi all,
>   After fitting a random slope and random intercept model using lme
> function, I want
> to test whether each of the fixed slopes is equal to zero (The output of
> model is below).
> Can this be done (testing each individual slope) using multcomp package?
>
> I don't understand what you mean by testing individual slope ?
>
> For the fixed effects, you might test whether there is a method, time or
> interaction
> effect using one of the methods described below
>
> For the randome effects, according to your model specification, the time
> dependency might vary for each individual. the sd for the time
> (0.0001841179)
> is small.  You might want to test whether to include randome slope  by
> doing a LRT
> between a model with it and another model without.
>
> Whay not include method in the random effects ?
>
> Gabriel
>
>   Thanks much for the help.
>    Hanna
>
> To get p values:
>
>
> http://stats.stackexchange.com/questions/118416/getting-p-value-with-mixed-effect-with-lme4-package
>
>
> http://mindingthebrain.blogspot.it/2014/02/three-ways-to-get-parameter-specific-p.html
>
> Using lmerTest package
> https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf
>
> or using mixed in afex package
> http://rpackages.ianhowson.com/cran/afex/man/mixed.html
>
> both use pbkrtest packages
> https://cran.r-project.org/web/packages/pbkrtest/pbkrtest.pdf
>
> a faq
> http://glmm.wikidot.com/faq
>
>
>
>
> summary(mod1)Linear mixed-effects model fit by REML
>
>  Data: one
>        AIC      BIC    logLik
>   304.4703 330.1879 -140.2352
>
> Random effects:
>  Formula: ~1 + time | individual
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 0.2487869075 (Intr)
> time        0.0001841179 -0.056
> Residual    0.3718305953
>
> Variance function:
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | method
>  Parameter estimates:
>        3        1        2
>  1.00000 26.59750 24.74476
> Fixed effects: reponse ~ method * time
>                 Value Std.Error DF   t-value p-value(Intercept)
> 96.65395  3.528586 57 27.391694  0.0000
> method2       1.17851  4.856026 57  0.242689  0.8091
> method3       5.87505  3.528617 57  1.664973  0.1014time
> 0.07010  0.250983 57  0.279301  0.7810
> method2:time -0.12616  0.360585 57 -0.349877  0.7277
> method3:time -0.08010  0.251105 57 -0.318999  0.7509
>  Correlation:
>              (Intr) methd2 methd3 time   mthd2:
> method2      -0.726
> method3      -0.999  0.726
> time         -0.779  0.566  0.779
> method2:time  0.542 -0.712 -0.542 -0.696
> method3:time  0.778 -0.566 -0.779 -0.999  0.696
>
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max
> -2.67575293 -0.51633192  0.06742723  0.59706762  2.81061874
>
> Number of Observations: 69
> Number of Groups: 7 >
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________R-sig-mixed-models at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .
>
>
>
>
> --
> ---------------------------------------------------------------------
> Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
> UHSR University                       (+39) 02 2643 3429 (laboratory)
> via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
> 20132 Milan, Italy               fax: (+39) 02 2643 4892
> ---------------------------------------------------------------------
>
>
	[[alternative HTML version deleted]]
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Mon Jun 13 16:29:07 2016
From: mak.hholly at gmail.com (greg holly)
Date: Mon, 13 Jun 2016 10:29:07 -0400
Subject: [R] two difficult loop
In-Reply-To: <CAM9Qe4hk2oY=NXS1jHBbHaQOu356ZFsNZmHNpmZsvWF4Zd_6AA@mail.gmail.com>
References: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
	<CAGxFJbQr2HFVy7K-H5FFBVZT7K4G6=+-9nQL9Q3=BpQeB9UM8g@mail.gmail.com>
	<CAM9Qe4gBctQDctAjPzoNBtXqj+fpQY3i1bqFrgEqs1WwWzQqbw@mail.gmail.com>
	<CAM9Qe4giTr6tA2-hB5yhoUV_28=1RWBFhXLktj6LXz+Vy21Qkg@mail.gmail.com>
	<CA+8X3fUtMsA91FSkoM9hUuo6DUHFSxHcDcGLM8ivqXBHObRU+w@mail.gmail.com>
	<CAM9Qe4hk2oY=NXS1jHBbHaQOu356ZFsNZmHNpmZsvWF4Zd_6AA@mail.gmail.com>
Message-ID: <CAM9Qe4iYaLZUWG+iSKEO6NfqSQWNA9O7okxzXAGJZbG16Q0dhw@mail.gmail.com>

Hi Jim;

I do apologize if bothering. I have run on the real data and here is the
error message I got:

Thanks,

Greg

start  end
Error in regrange[1]:regrange[2] : result would be too long a vector
In addition: Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf

On Mon, Jun 13, 2016 at 10:28 AM, greg holly <mak.hholly at gmail.com> wrote:

> Hi Jim;
>
> I do apologize if bothering. I have run on the real data and here is the
> error message I got:
>
> Thanks,
>
> Greg
>
> start  end
> Error in regrange[1]:regrange[2] : result would be too long a vector
> In addition: Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
>
>
> On Mon, Jun 13, 2016 at 3:19 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Greg,
>> Okay, I have a better idea now of what you want. The problem of
>> multiple matches is still there, but here is a start:
>>
>> # this data frame actually contains all the values in ref in the "reg"
>> field
>> map<-read.table(text="reg p rate
>>  10276 0.700  3.867e-18
>>  71608 0.830  4.542e-16
>>  29220 0.430  1.948e-15
>>  99542 0.220  1.084e-15
>>  26441 0.880  9.675e-14
>>  95082 0.090  7.349e-13
>>  36169 0.480  9.715e-13
>>  55572 0.500  9.071e-12
>>  65255 0.300  1.688e-11
>>  51960 0.970  1.163e-10
>>  55652 0.388  3.750e-10
>>  63933 0.250  9.128e-10
>>  35170 0.720  7.355e-09
>>  06491 0.370  1.634e-08
>>  85508 0.470  1.057e-07
>>  86666 0.580  7.862e-07
>>  04758 0.810  9.501e-07
>>  06169 0.440  1.104e-06
>>  63933 0.750  2.624e-06
>>  41838 0.960  8.119e-06
>>  74806 0.810  9.501e-07
>>  92643 0.470  1.057e-07
>>  73732 0.090  7.349e-13
>>  82451 0.960  8.119e-06
>>  86042 0.480  9.715e-13
>>  93502 0.500  9.071e-12
>>  85508 0.370  1.634e-08
>>  95082 0.830  4.542e-16",
>>  header=TRUE)
>> # same as in your example
>> ref<-read.table(text="reg1 reg2
>>  29220     63933
>>  26441     41838
>>  06169     10276
>>  74806     92643
>>  73732     82451
>>  86042     93502
>>  85508     95082",
>>  header=TRUE)
>> # sort the "map" data frame
>> map2<-map[order(map$reg),]
>> # get a field for the counts
>> ref$n<-NA
>> # and a field for the minimum p values
>> ref$min_p<-NA
>> # get the number of rows in "ref"
>> nref<-dim(ref)[1]
>> for(i in 1:nref) {
>>  start<-which(map2$reg==ref$reg1[i])
>>  end<-which(map2$reg==ref$reg2[i])
>>  cat("start",start,"end",end,"\n")
>>  # get the range of matches
>>  regrange<-range(c(start,end))
>>  # convert this to a sequence spanning all matches
>>  allreg<-regrange[1]:regrange[2]
>>  ref$n[i]<-sum(map2$p[allreg] > 0.85)
>>  ref$min_p[i]<-min(map2$p[allreg])
>> }
>>
>> This example uses the span from the first match of "reg1" to the last
>> match of "reg2". This may not be what you want, so let me know if
>> there are further constraints.
>>
>> Jim
>>
>> On Mon, Jun 13, 2016 at 12:35 PM, greg holly <mak.hholly at gmail.com>
>> wrote:
>> > Hi Bert;
>> >
>> > I do appreciate for this. I need check your codes on task2 tomorrow at
>> my
>> > office on the real data as I have difficulty (because a technical
>> issue) to
>> > remote connection. I am sure it will work well.
>> >
>> > I am sorry that I was not able to explain my first question. Basically
>> >
>> > Values in ref data represent the region of chromosome. I need choose
>> these
>> > regions in map (all regions values in ref data are exist in map data in
>> the
>> > first column -column map$reg). And then summing up the column "map$rate
>> and
>> > count the numbers that gives >0.85. For example, consider  the first
>> row in
>> > data ref. They are 29220   and  63933. After sorting the first column in
>> > map then summing column "map$rate" only between 29220   to  63933 in
>> sorted
>> > map and cut off at >0.85. Then count how many rows in sorted map gives
>> >>0.85. For example consider there are 38 rows between 29220   in  63933
>> in sorted
>> > map$reg and only summing first 12 of them  gives>0.85. Then my answer is
>> > going to be 12 for 29220   -  63933 in ref.
>> >
>> > Thanks I lot for your patience.
>> >
>> > Cheers,
>> > Greg
>> >
>> > On Sun, Jun 12, 2016 at 10:35 PM, greg holly <mak.hholly at gmail.com>
>> wrote:
>> >
>> >> Hi Bert;
>> >>
>> >> I do appreciate for this. I need check your codes on task2 tomorrow at
>> my
>> >> office on the real data as I have difficulty (because a technical
>> issue) to
>> >> remote connection. I am sure it will work well.
>> >>
>> >> I am sorry that I was not able to explain my first question. Basically
>> >>
>> >> Values in ref data represent the region of chromosome. I need choose
>> these
>> >> regions in map (all regions values in ref data are exist in map data
>> in the
>> >> first column -column map$reg). And then summing up the column
>> "map$rate and
>> >> count the numbers that gives >0.85. For example, consider  the first
>> row in
>> >> data ref. They are 29220   and  63933. After sorting the first column
>> in
>> >> map then summing column "map$rate" only between 29220   to  63933 in
>> >> sorted map and cut off at >0.85. Then count how many rows in sorted map
>> >> gives >0.85. For example consider there are 38 rows between 29220   in
>> >>  63933 in sorted map$reg and only summing first 12 of them  gives>0.85.
>> >> Then my answer is going to be 12 for 29220   -  63933 in ref.
>> >>
>> >> Thanks I lot for your patience.
>> >>
>> >> Cheers,
>> >> Greg
>> >>
>> >> On Sun, Jun 12, 2016 at 6:36 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> >> wrote:
>> >>
>> >>> Greg:
>> >>>
>> >>> I was not able to understand your task 1. Perhaps others can.
>> >>>
>> >>> My understanding of your task 2 is that for each row of ref, you wish
>> >>> to find all rows,of map such that the reg values in those rows fall
>> >>> between the reg1 and reg2 values in ref (inclusive change <= to < if
>> >>> you don't want the endpoints), and then you want the minimum map$p
>> >>> values of all those rows. If that is correct, I believe this will do
>> >>> it (but caution, untested, as you failed to provide data in a
>> >>> convenient form, e.g. using dput() )
>> >>>
>> >>> task2 <- with(map,vapply(seq_len(nrow(ref)),function(i)
>> >>> min(p[ref[i,1]<=reg & reg <= ref[i,2] ]),0))
>> >>>
>> >>>
>> >>> If my understanding is incorrect, please ignore both the above and the
>> >>> following:
>> >>>
>> >>>
>> >>> The "solution" I have given above seems inefficient, so others may be
>> >>> able to significantly improve it if you find that it takes too long.
>> >>> OTOH, my understanding of your specification is that you need to
>> >>> search for all rows in map data frame that meet the criterion for each
>> >>> row of ref, and without further information, I don't know how to do
>> >>> this without just repeating the search 560 times.
>> >>>
>> >>>
>> >>> Cheers,
>> >>> Bert
>> >>>
>> >>>
>> >>> Bert Gunter
>> >>>
>> >>> "The trouble with having an open mind is that people keep coming along
>> >>> and sticking things into it."
>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>
>> >>>
>> >>> On Sun, Jun 12, 2016 at 1:14 PM, greg holly <mak.hholly at gmail.com>
>> wrote:
>> >>> > Dear all;
>> >>> >
>> >>> >
>> >>> >
>> >>> > I have two data sets, data=map and data=ref). A small part of each
>> data
>> >>> set
>> >>> > are given below. Data map has more than 27 million and data ref has
>> >>> about
>> >>> > 560 rows. Basically I need run two different task. My R codes for
>> these
>> >>> > task are given below but they do not work properly.
>> >>> >
>> >>> > I sincerely do appreciate your helps.
>> >>> >
>> >>> >
>> >>> > Regards,
>> >>> >
>> >>> > Greg
>> >>> >
>> >>> >
>> >>> >
>> >>> > Task 1)
>> >>> >
>> >>> > For example, the first and second columns for row 1 in data ref are
>> >>> 29220
>> >>> > 63933. So I need write an R code normally first look the first row
>> in
>> >>> ref
>> >>> > (which they are 29220 and 63933) than summing the column of
>> "map$rate"
>> >>> and
>> >>> > give the number of rows that >0.85. Then do the same for the second,
>> >>> > third....in ref. At the end I would like a table gave below (the
>> >>> results I
>> >>> > need). Please notice the all value specified in ref data file are
>> exist
>> >>> in
>> >>> > map$reg column.
>> >>> >
>> >>> >
>> >>> >
>> >>> > Task2)
>> >>> >
>> >>> > Again example, the first and second columns for row 1 in data ref
>> are
>> >>> 29220
>> >>> > 63933. So I need write an R code give the minimum map$p for the
>> 29220
>> >>> > -63933 intervals in map file. Than
>> >>> >
>> >>> > do the same for the second, third....in ref.
>> >>> >
>> >>> >
>> >>> >
>> >>> >
>> >>> > #my attempt for the first question
>> >>> >
>> >>> > temp<-map[order(map$reg, map$p),]
>> >>> >
>> >>> > count<-1
>> >>> >
>> >>> > temp<-unique(temp$reg
>> >>> >
>> >>> > for(i in 1:length(ref) {
>> >>> >
>> >>> >   for(j in 1:length(ref)
>> >>> >
>> >>> >   {
>> >>> >
>> >>> > temp1<-if (temp[pos[i]==ref[ref$reg1,] &
>> (temp[pos[j]==ref[ref$reg2,]
>> >>> > & temp[cumsum(temp$rate)
>> >>> >>0.70,])
>> >>> >
>> >>> > count=count+1
>> >>> >
>> >>> >     }
>> >>> >
>> >>> > }
>> >>> >
>> >>> > #my attempt for the second question
>> >>> >
>> >>> >
>> >>> >
>> >>> > temp<-map[order(map$reg, map$p),]
>> >>> >
>> >>> > count<-1
>> >>> >
>> >>> > temp<-unique(temp$reg
>> >>> >
>> >>> > for(i in 1:length(ref) {
>> >>> >
>> >>> >   for(j in 1:length(ref)
>> >>> >
>> >>> >   {
>> >>> >
>> >>> > temp2<-if (temp[pos[i]==ref[ref$reg1,] &
>> (temp[pos[j]==ref[ref$reg2,])
>> >>> >
>> >>> > output<-temp2[temp2$p==min(temp2$p),]
>> >>> >
>> >>> >     }
>> >>> >
>> >>> > }
>> >>> >
>> >>> >
>> >>> >
>> >>> > Data sets
>> >>> >
>> >>> >
>> >>> >   Data= map
>> >>> >
>> >>> >   reg   p      rate
>> >>> >
>> >>> >  10276 0.700  3.867e-18
>> >>> >
>> >>> >  71608 0.830  4.542e-16
>> >>> >
>> >>> >  29220 0.430  1.948e-15
>> >>> >
>> >>> >  99542 0.220  1.084e-15
>> >>> >
>> >>> >  26441 0.880  9.675e-14
>> >>> >
>> >>> >  95082 0.090  7.349e-13
>> >>> >
>> >>> >  36169 0.480  9.715e-13
>> >>> >
>> >>> >  55572 0.500  9.071e-12
>> >>> >
>> >>> >  65255 0.300  1.688e-11
>> >>> >
>> >>> >  51960 0.970  1.163e-10
>> >>> >
>> >>> >  55652 0.388  3.750e-10
>> >>> >
>> >>> >  63933 0.250  9.128e-10
>> >>> >
>> >>> >  35170 0.720  7.355e-09
>> >>> >
>> >>> >  06491 0.370  1.634e-08
>> >>> >
>> >>> >  85508 0.470  1.057e-07
>> >>> >
>> >>> >  86666 0.580  7.862e-07
>> >>> >
>> >>> >  04758 0.810  9.501e-07
>> >>> >
>> >>> >  06169 0.440  1.104e-06
>> >>> >
>> >>> >  63933 0.750  2.624e-06
>> >>> >
>> >>> >  41838 0.960  8.119e-06
>> >>> >
>> >>> >
>> >>> >  data=ref
>> >>> >
>> >>> >   reg1         reg2
>> >>> >
>> >>> >   29220     63933
>> >>> >
>> >>> >   26441     41838
>> >>> >
>> >>> >   06169     10276
>> >>> >
>> >>> >   74806     92643
>> >>> >
>> >>> >   73732     82451
>> >>> >
>> >>> >   86042     93502
>> >>> >
>> >>> >   85508     95082
>> >>> >
>> >>> >
>> >>> >
>> >>> >        the results I need
>> >>> >
>> >>> >      reg1      reg2 n
>> >>> >
>> >>> >    29220   63933  12
>> >>> >
>> >>> >    26441   41838   78
>> >>> >
>> >>> >    06169 10276  125
>> >>> >
>> >>> >    74806 92643   11
>> >>> >
>> >>> >    73732 82451   47
>> >>> >
>> >>> >    86042 93502   98
>> >>> >
>> >>> >    85508 95082  219
>> >>> >
>> >>> >         [[alternative HTML version deleted]]
>> >>> >
>> >>> > ______________________________________________
>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> > PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> > and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jun 13 18:16:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 13 Jun 2016 09:16:45 -0700
Subject: [R] Assign value to plot variable name (make.group functions)
In-Reply-To: <7e40e0efcc0847048b4831bf1d282453@despmsx02.brainlab.net>
References: <7e40e0efcc0847048b4831bf1d282453@despmsx02.brainlab.net>
Message-ID: <CAGxFJbSdJc3X5FmHtZVicAXUXYxMQkDHg8GhzM+n=Cxz49253w@mail.gmail.com>

Mark:

I do not understand what you mean by plot labels, which generally mean
the x and y axis labels that can be given with xlab and ylab
parameters in the xyplot call. Clearly, however, this is not what you
mean. If you mean the labels in the key for the groups, you should
create the grouping factor with the level names you want and they will
be used in the key IIRC (you may have to explicitly create the key and
use its "text" component, as explained in the "key" portion of the
xyplot Help page) . If you want to put text labels of some sort in the
plot, then you should use a panel function that plots the data and
adds a panel.text() call to put text in the plot where you want it.

If none of these, maybe someone with better understanding than I can help.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 13, 2016 at 1:47 AM, Mark Fingerle
<mark.fingerle at brainlab.com> wrote:
> Dear all,
>
> In order to create plots comparing two measurements I am using the "xyplot" and "make.groups" functions (see script example below).
> Now I would like to assign a value to the variable names in the plot. Meaning: In the beginning of my script I assign a name(value) to a variable (for example:  ID1 <- Name1). Now I would like to use this variable to name the plot variables.
>
> Maybe easier to understand using an example:
>
> Script:
>
> pdf("REP_Chess.pdf")
> scChess1=xyplot( x = ObjErrorX~Image, data=make.groups("ID1"=Chess1, "ID2"=Chess2),
>              pch=16 ,main="Chess - Object Error X [mm]", auto.key=T, groups=which, scales=list(relation="free",
>                                                                               y=list(rot=0), x=list(rot=45), abbreviate = TRUE),
>
> print(scChess1, split=c(1,1,1,1), more=False)
> dev.off()
>
> I would like to assign a value to ID1, so that this value is shown on the plot labels after it is printed.
> Something like : ID1 <- Name1 , and Name1 is shown in the plots.
>
>
> Thank you very much in advance.
>
> Cheers
> Mark Fingerle
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fahman_khan75 at yahoo.com  Mon Jun 13 17:17:17 2016
From: fahman_khan75 at yahoo.com (Fahman Khan)
Date: Mon, 13 Jun 2016 15:17:17 +0000 (UTC)
Subject: [R] Binary Value into Text
References: <2021175489.2234979.1465831037404.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2021175489.2234979.1465831037404.JavaMail.yahoo@mail.yahoo.com>

I have written a following piece of code.?
> binaryFile <- file("sampleBinary.dat", 'rb')>readBin(binaryFile, character(), endian="little")

I'm getting a warning message that says?

Warning message:?In readBin(binaryFile, chracter(), endian="little") : incomplete string at end of file has been discarded

I did research on this topic but was still unable to solve.

My file contains the following binary values:?01101000 01100101 01101100 01101100 01101111 00001010 which is hello in text. I just want to convert this into text.?

Any help would be appreciated.
	[[alternative HTML version deleted]]


From huangh237 at mail2.sysu.edu.cn  Mon Jun 13 17:22:50 2016
From: huangh237 at mail2.sysu.edu.cn (=?utf-8?B?6buE5qGm?=)
Date: Mon, 13 Jun 2016 23:22:50 +0800
Subject: [R] Haplo.glm error: Failed to converge during EM-glm loop
Message-ID: <tencent_6DEEF68A7A116EA2580F6946@qq.com>

Hi all,


I used R package "haplo.stats" to see if the haplotype in my data has any effect on the trait, with the genotype, age, height and 

weight as the predictor and trait as the response. I used the following code:

 

fit.gaus <- haplo.glm(y ~ age + height + weight + geno.glm, family=gaussian, data=glm.data, na.action="na.geno.keep", x=TRUE, control=haplo.glm.control(haplo.freq.min=.02))

 

But R showed me this error:

 Warning message:

In haplo.glm(y ~ age + height + weight + geno.glm, family = gaussian,  :

  Failed to converge during EM-glm loop

 

What does it mean that failed to converge during EM-glm loop? I wonder if there is anything wrong with my command?

Thank you for your attention, I am looking forward to your reply.

 

Best.

 

Hua
	[[alternative HTML version deleted]]


From carlganz at ucla.edu  Mon Jun 13 19:45:49 2016
From: carlganz at ucla.edu (Ganz, Carl)
Date: Mon, 13 Jun 2016 17:45:49 +0000
Subject: [R] Using weights with truncreg
Message-ID: <A5A30F1D451F924B902DDE8063410E670EB899@EM1A.ad.ucla.edu>

Hello everyone,

I would like to use truncreg on survey data with weights, but so far as I can tell the weight parameter in truncreg is not working. I find that using weights does not actually change the output.

Here is a small reproducible example using the example in the documentation:

## simulate a data.frame
set.seed(1071)
n <- 10000
sigma <- 4
alpha <- 2
beta <- 1
x <- rnorm(n, mean = 0, sd = 2)
eps <- rnorm(n, sd = sigma)
y <- alpha + beta * x + eps
d <- data.frame(y = y, x = x)

## truncated response
d$yt <- ifelse(d$y > 1, d$y, NA)

## binary threshold response
d$yb <- factor(d$y > 0)

## censored response
d$yc <- pmax(1, d$y)

## random weight
wgt <- runif(10000,500,1500)
## unweighted
fm_trunc <- truncreg(yt ~ x, data = d, point = 1, direction = "left")
## weighted
fm_trunc_weighted <- truncreg(yt ~ x, data = d, weights = wgt, point = 1, direction = "left")

coef(fm_trunc_weighted)==coef(fm_trunc) # all equal

Am I misunderstanding how the weight parameter works for truncreg or is the weight parameter not working?

Kind Regards,
Carl

	[[alternative HTML version deleted]]


From xavier.sumba93 at ucuenca.ec  Mon Jun 13 20:07:14 2016
From: xavier.sumba93 at ucuenca.ec (FRANCISCO XAVIER SUMBA TORAL)
Date: Mon, 13 Jun 2016 13:07:14 -0500
Subject: [R] Visualize Sparse Matrix.
In-Reply-To: <CAGaD6pw_HM2kD8WN6QWWs9RqgxF=W=5Ur2D+A8vUeVJnqWk1Og@mail.gmail.com>
References: <6BAD2DF3-D978-4C70-B547-B78CCFC8DBD3@ucuenca.ec>
	<CAGaD6pw_HM2kD8WN6QWWs9RqgxF=W=5Ur2D+A8vUeVJnqWk1Og@mail.gmail.com>
Message-ID: <AF6B297F-ADB6-4BFE-B729-0C575239918F@ucuenca.ec>

Hi, 

Thanks for your help.

I used the SparseM package http://www.econ.uiuc.edu/~roger/research/sparse/SparseM.pdf <http://www.econ.uiuc.edu/~roger/research/sparse/SparseM.pdf>
First of all, I create a class for sparse matrices stored in Compressed Sparse Row (CSR) with as.matrix.csr(matrix).
After that, I plot the non-zero entries of a matrix of class matrix.csr with image(m.csr)


This is my code:

library(SparseM)
data <- read.csv(pathCSV, header = FALSE, sep = ",")
numcol <- ncol(data)
dMatrix <- matrix(unlist(data), ncol = numcol, byrow = TRUE)
dMatrix.csr <- as.matrix.csr(dMatrix)
image(dMatrix.csr, col=c("white","blue"))

After clustering, I will have the same matrix but each row (vector) has a tag to represent a cluster id. So, how could I plot my matrix to show a different color for cluster id?

This is an example of my results:

213	0	0 	0 	0.213	0.3423  
345	0	0 	0.32 0		0  
84	0	0.4 	0 	0.54		0  
84	0.86	0 	0 	0		0  
213	0	0.98 0 	0		0.45  
345	0	0.57 0 	0		0.4  

Cheers.

> On Jun 10, 2016, at 18:51, Amos Elberg <amos.elberg at gmail.com> wrote:
> 
> Sparse matrix visualization is a feature of my largeVis package:  https://github.com/elbamos/largeVis/tree/0.1.6 <https://github.com/elbamos/largeVis/tree/0.1.6>
> 
> 
> 
> On Thu, Jun 9, 2016 at 6:27 PM, FRANCISCO XAVIER SUMBA TORAL <xavier.sumba93 at ucuenca.ec <mailto:xavier.sumba93 at ucuenca.ec>> wrote:
> Hi,
> 
> First of all, sorry for my question it could be so basic for a common user in R, but I am starting with this new environment.
> 
> I have done a clustering job and I would like to visualize my vectors. I have a matrix of TF-IDF weights of 4602 x 1817. I store the values in a CSV file. How can I visualize my vectors in a 2D-space?
> 
> After that, I execute a clustering algorithm and I got a label for each cluster. How can I visualize my vectors resulting base on a color or figure for each cluster?
> 
> This is the code that I am having trying to accomplish my graphs:
> 
> data <- read.csv(pathFile,header = FALSE, sep = ",?)
> dMatrix <- matrix(unlist(data), ncol = 4602, byrow = TRUE) # Use a matrix to use melt.
> # Graph my data
> ggplot(melt(dMatrix), aes(Var1,Var2, fill=value)) + geom_raster() + scale_fill_gradient2(low='red', high=?black', mid=?white') + theme_bw() + xlab("x1") + ylab("x2")
> 
> 
> Cheers.
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Mon Jun 13 21:35:21 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 13 Jun 2016 21:35:21 +0200 (CEST)
Subject: [R] Using weights with truncreg
In-Reply-To: <A5A30F1D451F924B902DDE8063410E670EB899@EM1A.ad.ucla.edu>
References: <A5A30F1D451F924B902DDE8063410E670EB899@EM1A.ad.ucla.edu>
Message-ID: <alpine.DEB.2.20.1606132129430.13978@paninaro>

On Mon, 13 Jun 2016, Ganz, Carl wrote:

> Hello everyone,
>
> I would like to use truncreg on survey data with weights, but so far as I can tell the weight parameter in truncreg is not working. I find that using weights does not actually change the output.
>
> Here is a small reproducible example using the example in the documentation:
>
> ## simulate a data.frame
> set.seed(1071)
> n <- 10000
> sigma <- 4
> alpha <- 2
> beta <- 1
> x <- rnorm(n, mean = 0, sd = 2)
> eps <- rnorm(n, sd = sigma)
> y <- alpha + beta * x + eps
> d <- data.frame(y = y, x = x)
>
> ## truncated response
> d$yt <- ifelse(d$y > 1, d$y, NA)
>
> ## binary threshold response
> d$yb <- factor(d$y > 0)
>
> ## censored response
> d$yc <- pmax(1, d$y)
>
> ## random weight
> wgt <- runif(10000,500,1500)
> ## unweighted
> fm_trunc <- truncreg(yt ~ x, data = d, point = 1, direction = "left")
> ## weighted
> fm_trunc_weighted <- truncreg(yt ~ x, data = d, weights = wgt, point = 1, direction = "left")
>
> coef(fm_trunc_weighted)==coef(fm_trunc) # all equal
>
> Am I misunderstanding how the weight parameter works for truncreg or is 
> the weight parameter not working?

I think you are right and the 'weights' argument in truncreg() is 
currently not used.

As an alternative you can use the "crch" package for censored (and 
truncated) regression with conditional heteroskedasticity. The models 
above can be fitted via:

library("crch")
fm_trunc2 <- trch(yt ~ x, data = d, left = 1)
fm_trunc_weighted2 <- trch(yt ~ x, data = d, weights = wgt, left = 1)

Note that by default a log-link is used for the sigma/scale parameter to 
assure positivity. But you can also set link.scale="identity" to obtain 
the same results as in truncreg().

> Kind Regards,
> Carl
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From awawaed at yahoo.com  Mon Jun 13 22:57:34 2016
From: awawaed at yahoo.com (A A)
Date: Mon, 13 Jun 2016 20:57:34 +0000 (UTC)
Subject: [R] Dashed/dotted ecdf plots using lots of points
References: <1155158271.1936883.1465851454688.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1155158271.1936883.1465851454688.JavaMail.yahoo@mail.yahoo.com>

As per the title, I'd like to generate a dashed/dotted CDF plot of my data using ecdf. Unfortunately, it seems like I can't get the plot to look dashed/dotted even after specifying it in the plot function. I suspect this may be because of the high number of data points. Here's a short sample of code that illustrates my issue:
#change to 1:100 to see the dotted line
x = 1:10000
e = ecdf(x)
plot(e,do.p=FALSE, lty = "dotted")
Is there a way to solve this problem?
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Jun 14 00:09:26 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 14 Jun 2016 00:09:26 +0200
Subject: [R] Dashed/dotted ecdf plots using lots of points
In-Reply-To: <1155158271.1936883.1465851454688.JavaMail.yahoo@mail.yahoo.com>
References: <1155158271.1936883.1465851454688.JavaMail.yahoo.ref@mail.yahoo.com>
	<1155158271.1936883.1465851454688.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <8A406000-9619-4233-8ADE-5FEA872BBF75@gmail.com>

(a) ecdf() could be an overkill for this. At 10000 points, plot(sort(x), ppoints(x), type="l") should be quite close enough. Also, plot.ecdf() draws lots of individual horisontal line segments which all start in the same way. If you have enough of them, they reduce to a single pixels which are all "on". If you draw a continuous line, at least there is a chance to get dotting and dashing to work. However...

(b) It is a generic problem to get dash/dot patterns to cycle correctly along multisegment lines. Some device drivers are better at it than others. 

The following looks OK for me, but not on the quartz() screen device. 

pdf()
x <- rnorm(10000)
plot(sort(x),ppoints(x),type="l",lty="dashed", ylim=c(0,1))
plot(sort(x),ppoints(x),type="l",lty="dotted", ylim=c(0,1))
dev.off()

-pd

> On 13 Jun 2016, at 22:57 , A A via R-help <r-help at r-project.org> wrote:
> 
> As per the title, I'd like to generate a dashed/dotted CDF plot of my data using ecdf. Unfortunately, it seems like I can't get the plot to look dashed/dotted even after specifying it in the plot function. I suspect this may be because of the high number of data points. Here's a short sample of code that illustrates my issue:
> #change to 1:100 to see the dotted line
> x = 1:10000
> e = ecdf(x)
> plot(e,do.p=FALSE, lty = "dotted")
> Is there a way to solve this problem?
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Tue Jun 14 02:56:29 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 14 Jun 2016 10:56:29 +1000
Subject: [R] Binary Value into Text
In-Reply-To: <2021175489.2234979.1465831037404.JavaMail.yahoo@mail.yahoo.com>
References: <2021175489.2234979.1465831037404.JavaMail.yahoo.ref@mail.yahoo.com>
	<2021175489.2234979.1465831037404.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fXyV=qGwn563KaQCZ135Q5g44WewZOzMVXpAg1CpysQBw@mail.gmail.com>

Hi Fahman,
That error message usually means that there is no newline at the end
of the last line of the input file. Try adding a newline,

Jim


On Tue, Jun 14, 2016 at 1:17 AM, Fahman Khan via R-help
<r-help at r-project.org> wrote:
> I have written a following piece of code.
>> binaryFile <- file("sampleBinary.dat", 'rb')>readBin(binaryFile, character(), endian="little")
>
> I'm getting a warning message that says
>
> Warning message: In readBin(binaryFile, chracter(), endian="little") : incomplete string at end of file has been discarded
>
> I did research on this topic but was still unable to solve.
>
> My file contains the following binary values: 01101000 01100101 01101100 01101100 01101111 00001010 which is hello in text. I just want to convert this into text.
>
> Any help would be appreciated.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Jun 14 05:48:04 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 13 Jun 2016 20:48:04 -0700 (PDT)
Subject: [R] summing up a column.
In-Reply-To: <1670840319.1796223.1465825507940.JavaMail.yahoo@mail.yahoo.com>
References: <31785661.876929.1465590843856.JavaMail.yahoo.ref@mail.yahoo.com>
	<31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>
	<FCDDB5B3-2D68-4BE7-AD53-4FB3AA9C2861@dcn.davis.ca.us>
	<764714753.876287.1465592795459.JavaMail.yahoo@mail.yahoo.com>
	<542840655.919423.1465592922434.JavaMail.yahoo@mail.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030449@SRVEXCHMBX.precheza.cz>
	<1670840319.1796223.1465825507940.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1606132015280.5795@pedal.dcn.davis.ca.us>

You did half of what Petr asked... but your email still looks unreadable
because you did not send it as text only. Look at [1] to see what we see, 
and why we want you to send plain text. What you see is not what we see.

This is an outer join... an inherently inefficient operation according to 
relational database theory. Most solutions to this type of problem are 
likely to be slow, but minimizing unnecessary use of memory can help and 
to do that you can overwrite existing values instead of successively 
concatenating longer vectors of results as you go.

To understand the solution below, you should execute individual 
expressions interactively as you step through the code to see what the 
intermediate values look like. In particular, expressions on the right 
side of assignments can be interactively entered at the console without 
changing the variables in the environment so do it as much as you need to 
in order to see what is happening.

# alignment not required, but HTML run-together lines not wanted
A <- structure( list( posA = c( 1L, 2L, 5L, 4L, 9L)
                     , posB = c( 9L, 7L, 12L, 7L, 13L)
                     )
               , .Names = c("posA", "posB")
               , class = "data.frame"
               , row.names = c(NA, -5L)
               )
B <- structure( list( pos = c( 4L, 2L, 7L, 1L, 13L, 12L, 9L)
                     , a = c(0.4, 0.1, 0.5, 0.4, 0.1, 0.2, 0.3)
                     , b = c(7L, 5L, 8L, 1L, 6L, 11L, 12L)
                     , c = c(0.8, 0.4, 0.32, 0.1, 0.13, 0.01, 0.23))
               , .Names = c("pos", "a", "b", "c")
               , class = "data.frame"
               , row.names = c(NA, -7L)
               )
# sort B
sB <- B[ order( B$pos ), ]
# performance: set aside memory to remember results
A$count07 <- NA
A$mina <- NA
for ( i in seq.int( nrow( A ) ) ) {
   # logical indexing vector
   idx <- A[ i, "posA" ] <= sB$pos & sB$pos <= A[ i, "posB" ]
   # only extract desired vector once
   a <- sB[ idx, "a" ]
   # sum adds logical values as if TRUE=1
   A[ i, "count07" ] <- sum( cumsum( a ) < 0.7 )
   A[ i, "mina" ] <-min( a )
}
print( A )

#=== sample interactive session for study after A and B are defined
#=== execute lines one at a time and study them!
order( B$pos )
B[ order( B$pos ), ]
sB <- B[ order( B$pos ), ]
A$count07 <- NA
A$mina <- NA
i <- 1
A[ i, "posA" ] 
A[ i, "posB" ]
sB$pos
A[ i, "posA" ] <= sB$pos
sB$pos <= A[ i, "posB" ] 
A[ i, "posA" ] <= sB$pos & sB$pos <= A[ i, "posB" ]
idx <- A[ i, "posA" ] <= sB$pos & sB$pos <= A[ i, "posB" ]
sB[ idx, "a" ]
a <- sB[ idx, "a" ]
cumsum( a )
cumsum( a ) < 0.7
sum( cumsum( a ) < 0.7 )
A[ i, "count07" ] <- sum( cumsum( a ) < 0.7 )
min( a )

------
[1] https://stat.ethz.ch/pipermail/r-help/2016-June/439404.html

On Mon, 13 Jun 2016, oslo via R-help wrote:

> Hi Petr;
> Thanks so much. Here are the questions and the dput(A) and dput(B). Basicaly I have two questions;
>> dput(A)structure(list(posA = c(1L, 2L, 5L, 4L, 9L), posB = c(9L, 7L,?12L, 7L, 13L)), .Names = c("posA", "posB"), class = "data.frame", row.names = c(NA,?-5L))> dput(B)structure(list(pos = c(4L, 2L, 7L, 1L, 13L, 12L, 9L), a = c(0.4,?0.1, 0.5, 0.4, 0.1, 0.2, 0.3), b = c(7L, 5L, 8L, 1L, 6L, 11L,?12L), c = c(0.8, 0.4, 0.32, 0.1, 0.13, 0.01, 0.23)), .Names = c("pos",?"a", "b", "c"), class = "data.frame", row.names = c(NA, -7L))
> Q1) Values in A represent the region of chromosome. I need choose these regions in B (all region in A are exist in B in a single column) and then summing up the column "a in B and count the numbers that gives >0.7. For example, consider ?the first row in A. They are 1 and 9. After sorting the first column in B then summing column "a" only between 1 to 9 in sorted B and cut off at >0.7. Then count how many rows in sorted B gives >0.7. For example there are only 5 rows between 1 to 9 in sorted B and only summing first 2 of them ?gives>0.7 . Then my answer is going to be 2
> Q2) What is the min value of B$a for given each intervals in A
> Regards,
> Oslo 
>
>    On Monday, June 13, 2016 8:05 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>
> Ok.
>
> Instead of explaining what you have, please send a result of
>
> dput(B) and dput(A)
>
> And set you mail client to send plain text mail otherwise your code is barely readable.
>
> What do you want to do with printed values?
>
> What is B? From this it seems that it is data frame but then you try to put sorted data frame into a data frame column.
>
> B$possort=B[order(B$pos),]
>
> With such code and data frame I get an error.
>
> So please try to keep above mentioned when posting a query.
>
> Regards
> Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of oslo via R-
>> help
>> Sent: Friday, June 10, 2016 11:09 PM
>> To: oslo <oslo at yahoo.com>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>;
>> oslo via R-help <r-help at r-project.org>; oslo <hokut1 at yahoo.com>
>> Subject: Re: [R] summing up a column.
>>
>> Jeff;
>> ? thanks for this. My question was job related. No from my course. I need
>> finish a job for the place I work. I am so sorry for causing misunderstanding.
>> thanks,
>> Oslo
>>
>> ? ? On Friday, June 10, 2016 5:08 PM, oslo via R-help <r-help at r-project.org>
>> wrote:
>>
>>
>> ? Jeff thanks for this. My question was job related. No from my course. I need
>> finish a job for the place I work. I am so sorry for causing misunderstanding.
>> thanks,
>> Oslo
>>
>> ? ? On Friday, June 10, 2016 5:02 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>
>>
>> ? Multiple posting happens when you are learning a new system, but reading
>> the posting guide can keep the bleeding down.
>>
>> 1) There is a no-homework policy on this list... different educational
>> organizations have different standards for what is acceptable outside help,
>> so you should be using the support offered by your instructor or educational
>> institution.
>>
>> 2) Once you have completed your course, you CAN learn to post data with
>> your code so that it is self-contained... that is, reproducible on our vanilla R
>> session. Using the dput function is one excellent strategy.
>>
>> 3) This is not a problem that needs a loop... as Bert (not Bret) said, you can do
>> this in one or two statements if you simply use basic logical indexing. If your
>> instructor wants you to do it with a loop for sine reason then you really really
>> should not be here... you should be talking to him/her.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On June 10, 2016 1:34:03 PM PDT, oslo via R-help <r-help at r-project.org>
>> wrote:
>> Dear All;
>> I had difficulty to post a mail along with appropriate of data structure. I do
>> sincerely apologize for multiple posting
>>
>>
>> I would like to sum up the B$a column and cut off at 0.7 for the each row of
>> intervals giving in file=A.For example the interval? at the first row in A$posA
>> and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from
>> the 1 to 9 in B$pos. And then I need to the same using the intervals in the
>> second, third..... rows in A. Obviously my loop is wrong and? does not work
>> properly. Please help for my this first experience.? Regards Here are my
>> codes #sorting B$possort=B[order(B$pos),] #Running loop for(i in 1:nrow(A))
>> {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } } Reply, R R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From jdnewmil at dcn.davis.ca.us  Tue Jun 14 06:05:26 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 13 Jun 2016 21:05:26 -0700 (PDT)
Subject: [R] Binary Value into Text
In-Reply-To: <2021175489.2234979.1465831037404.JavaMail.yahoo@mail.yahoo.com>
References: <2021175489.2234979.1465831037404.JavaMail.yahoo.ref@mail.yahoo.com>
	<2021175489.2234979.1465831037404.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1606132052400.5795@pedal.dcn.davis.ca.us>

Please post in plain text format. Only you have the power to format your 
email the way we will see it... using the default HTML format only leads 
to odd wraparounds and weird characters that you don't know about when you 
send but we have to wade through when we recieve it.

"Character" data is rather more complex now than it used to be in days of 
yore... what with Unicode UTF16 and UTF-8 and so on. You are getting into 
deep water trying to mix binary and text data. (I know enough to know I am 
no expert in this topic.) I highly recommend reading the article by Paul 
Murrell on reading binary data [1], but even that is unlikely to answer 
all the headaches you are diving into and it will probably stop being "on 
topic" for this list pretty quickly.

One key point is that you should read "raw" data, not "character" data 
when getting data out of files, even if they are opened in "binary mode".

[1] Viewing binary files with the hexview package. R News, 7(1):2--8, 
April 2007.

On Mon, 13 Jun 2016, Fahman Khan via R-help wrote:

> I have written a following piece of code.?
>> binaryFile <- file("sampleBinary.dat", 'rb')>readBin(binaryFile, character(), endian="little")
>
> I'm getting a warning message that says?
>
> Warning message:?In readBin(binaryFile, chracter(), endian="little") : incomplete string at end of file has been discarded
>
> I did research on this topic but was still unable to solve.
>
> My file contains the following binary values:?01101000 01100101 01101100 01101100 01101111 00001010 which is hello in text. I just want to convert this into text.?
>
> Any help would be appreciated.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From drjimlemon at gmail.com  Tue Jun 14 09:39:52 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 14 Jun 2016 17:39:52 +1000
Subject: [R] two difficult loop
In-Reply-To: <CAM9Qe4iYaLZUWG+iSKEO6NfqSQWNA9O7okxzXAGJZbG16Q0dhw@mail.gmail.com>
References: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
	<CAGxFJbQr2HFVy7K-H5FFBVZT7K4G6=+-9nQL9Q3=BpQeB9UM8g@mail.gmail.com>
	<CAM9Qe4gBctQDctAjPzoNBtXqj+fpQY3i1bqFrgEqs1WwWzQqbw@mail.gmail.com>
	<CAM9Qe4giTr6tA2-hB5yhoUV_28=1RWBFhXLktj6LXz+Vy21Qkg@mail.gmail.com>
	<CA+8X3fUtMsA91FSkoM9hUuo6DUHFSxHcDcGLM8ivqXBHObRU+w@mail.gmail.com>
	<CAM9Qe4hk2oY=NXS1jHBbHaQOu356ZFsNZmHNpmZsvWF4Zd_6AA@mail.gmail.com>
	<CAM9Qe4iYaLZUWG+iSKEO6NfqSQWNA9O7okxzXAGJZbG16Q0dhw@mail.gmail.com>
Message-ID: <CA+8X3fUaFoyzm=GXwY0PBUxrAfVJSqH51BwzbwdNzR2YXZCxSQ@mail.gmail.com>

Hi Greg,
This is obviously a problem with the data. The first error indicates
that the sequence of integers regrange[1]:regrange[2] is too long to
be allocated. Most likely this is because one or both of the endpoints
are infinite. Maybe if you can find where the NAs are you can fix it.

Jim

On Tue, Jun 14, 2016 at 12:29 AM, greg holly <mak.hholly at gmail.com> wrote:
> Hi Jim;
>
> I do apologize if bothering. I have run on the real data and here is the
> error message I got:
>
> Thanks,
>
> Greg
>
> start  end
> Error in regrange[1]:regrange[2] : result would be too long a vector
> In addition: Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
>
> On Mon, Jun 13, 2016 at 10:28 AM, greg holly <mak.hholly at gmail.com> wrote:
>>
>> Hi Jim;
>>
>> I do apologize if bothering. I have run on the real data and here is the
>> error message I got:
>>
>> Thanks,
>>
>> Greg
>>
>> start  end
>> Error in regrange[1]:regrange[2] : result would be too long a vector
>> In addition: Warning messages:
>> 1: In min(x) : no non-missing arguments to min; returning Inf
>> 2: In max(x) : no non-missing arguments to max; returning -Inf
>>
>>
>> On Mon, Jun 13, 2016 at 3:19 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Greg,
>>> Okay, I have a better idea now of what you want. The problem of
>>> multiple matches is still there, but here is a start:
>>>
>>> # this data frame actually contains all the values in ref in the "reg"
>>> field
>>> map<-read.table(text="reg p rate
>>>  10276 0.700  3.867e-18
>>>  71608 0.830  4.542e-16
>>>  29220 0.430  1.948e-15
>>>  99542 0.220  1.084e-15
>>>  26441 0.880  9.675e-14
>>>  95082 0.090  7.349e-13
>>>  36169 0.480  9.715e-13
>>>  55572 0.500  9.071e-12
>>>  65255 0.300  1.688e-11
>>>  51960 0.970  1.163e-10
>>>  55652 0.388  3.750e-10
>>>  63933 0.250  9.128e-10
>>>  35170 0.720  7.355e-09
>>>  06491 0.370  1.634e-08
>>>  85508 0.470  1.057e-07
>>>  86666 0.580  7.862e-07
>>>  04758 0.810  9.501e-07
>>>  06169 0.440  1.104e-06
>>>  63933 0.750  2.624e-06
>>>  41838 0.960  8.119e-06
>>>  74806 0.810  9.501e-07
>>>  92643 0.470  1.057e-07
>>>  73732 0.090  7.349e-13
>>>  82451 0.960  8.119e-06
>>>  86042 0.480  9.715e-13
>>>  93502 0.500  9.071e-12
>>>  85508 0.370  1.634e-08
>>>  95082 0.830  4.542e-16",
>>>  header=TRUE)
>>> # same as in your example
>>> ref<-read.table(text="reg1 reg2
>>>  29220     63933
>>>  26441     41838
>>>  06169     10276
>>>  74806     92643
>>>  73732     82451
>>>  86042     93502
>>>  85508     95082",
>>>  header=TRUE)
>>> # sort the "map" data frame
>>> map2<-map[order(map$reg),]
>>> # get a field for the counts
>>> ref$n<-NA
>>> # and a field for the minimum p values
>>> ref$min_p<-NA
>>> # get the number of rows in "ref"
>>> nref<-dim(ref)[1]
>>> for(i in 1:nref) {
>>>  start<-which(map2$reg==ref$reg1[i])
>>>  end<-which(map2$reg==ref$reg2[i])
>>>  cat("start",start,"end",end,"\n")
>>>  # get the range of matches
>>>  regrange<-range(c(start,end))
>>>  # convert this to a sequence spanning all matches
>>>  allreg<-regrange[1]:regrange[2]
>>>  ref$n[i]<-sum(map2$p[allreg] > 0.85)
>>>  ref$min_p[i]<-min(map2$p[allreg])
>>> }
>>>
>>> This example uses the span from the first match of "reg1" to the last
>>> match of "reg2". This may not be what you want, so let me know if
>>> there are further constraints.
>>>
>>> Jim
>>>
>>> On Mon, Jun 13, 2016 at 12:35 PM, greg holly <mak.hholly at gmail.com>
>>> wrote:
>>> > Hi Bert;
>>> >
>>> > I do appreciate for this. I need check your codes on task2 tomorrow at
>>> > my
>>> > office on the real data as I have difficulty (because a technical
>>> > issue) to
>>> > remote connection. I am sure it will work well.
>>> >
>>> > I am sorry that I was not able to explain my first question. Basically
>>> >
>>> > Values in ref data represent the region of chromosome. I need choose
>>> > these
>>> > regions in map (all regions values in ref data are exist in map data in
>>> > the
>>> > first column -column map$reg). And then summing up the column "map$rate
>>> > and
>>> > count the numbers that gives >0.85. For example, consider  the first
>>> > row in
>>> > data ref. They are 29220   and  63933. After sorting the first column
>>> > in
>>> > map then summing column "map$rate" only between 29220   to  63933 in
>>> > sorted
>>> > map and cut off at >0.85. Then count how many rows in sorted map gives
>>> >>0.85. For example consider there are 38 rows between 29220   in  63933
>>> >> in sorted
>>> > map$reg and only summing first 12 of them  gives>0.85. Then my answer
>>> > is
>>> > going to be 12 for 29220   -  63933 in ref.
>>> >
>>> > Thanks I lot for your patience.
>>> >
>>> > Cheers,
>>> > Greg
>>> >
>>> > On Sun, Jun 12, 2016 at 10:35 PM, greg holly <mak.hholly at gmail.com>
>>> > wrote:
>>> >
>>> >> Hi Bert;
>>> >>
>>> >> I do appreciate for this. I need check your codes on task2 tomorrow at
>>> >> my
>>> >> office on the real data as I have difficulty (because a technical
>>> >> issue) to
>>> >> remote connection. I am sure it will work well.
>>> >>
>>> >> I am sorry that I was not able to explain my first question. Basically
>>> >>
>>> >> Values in ref data represent the region of chromosome. I need choose
>>> >> these
>>> >> regions in map (all regions values in ref data are exist in map data
>>> >> in the
>>> >> first column -column map$reg). And then summing up the column
>>> >> "map$rate and
>>> >> count the numbers that gives >0.85. For example, consider  the first
>>> >> row in
>>> >> data ref. They are 29220   and  63933. After sorting the first column
>>> >> in
>>> >> map then summing column "map$rate" only between 29220   to  63933 in
>>> >> sorted map and cut off at >0.85. Then count how many rows in sorted
>>> >> map
>>> >> gives >0.85. For example consider there are 38 rows between 29220   in
>>> >>  63933 in sorted map$reg and only summing first 12 of them
>>> >> gives>0.85.
>>> >> Then my answer is going to be 12 for 29220   -  63933 in ref.
>>> >>
>>> >> Thanks I lot for your patience.
>>> >>
>>> >> Cheers,
>>> >> Greg
>>> >>
>>> >> On Sun, Jun 12, 2016 at 6:36 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>> >> wrote:
>>> >>
>>> >>> Greg:
>>> >>>
>>> >>> I was not able to understand your task 1. Perhaps others can.
>>> >>>
>>> >>> My understanding of your task 2 is that for each row of ref, you wish
>>> >>> to find all rows,of map such that the reg values in those rows fall
>>> >>> between the reg1 and reg2 values in ref (inclusive change <= to < if
>>> >>> you don't want the endpoints), and then you want the minimum map$p
>>> >>> values of all those rows. If that is correct, I believe this will do
>>> >>> it (but caution, untested, as you failed to provide data in a
>>> >>> convenient form, e.g. using dput() )
>>> >>>
>>> >>> task2 <- with(map,vapply(seq_len(nrow(ref)),function(i)
>>> >>> min(p[ref[i,1]<=reg & reg <= ref[i,2] ]),0))
>>> >>>
>>> >>>
>>> >>> If my understanding is incorrect, please ignore both the above and
>>> >>> the
>>> >>> following:
>>> >>>
>>> >>>
>>> >>> The "solution" I have given above seems inefficient, so others may be
>>> >>> able to significantly improve it if you find that it takes too long.
>>> >>> OTOH, my understanding of your specification is that you need to
>>> >>> search for all rows in map data frame that meet the criterion for
>>> >>> each
>>> >>> row of ref, and without further information, I don't know how to do
>>> >>> this without just repeating the search 560 times.
>>> >>>
>>> >>>
>>> >>> Cheers,
>>> >>> Bert
>>> >>>
>>> >>>
>>> >>> Bert Gunter
>>> >>>
>>> >>> "The trouble with having an open mind is that people keep coming
>>> >>> along
>>> >>> and sticking things into it."
>>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >>>
>>> >>>
>>> >>> On Sun, Jun 12, 2016 at 1:14 PM, greg holly <mak.hholly at gmail.com>
>>> >>> wrote:
>>> >>> > Dear all;
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> > I have two data sets, data=map and data=ref). A small part of each
>>> >>> > data
>>> >>> set
>>> >>> > are given below. Data map has more than 27 million and data ref has
>>> >>> about
>>> >>> > 560 rows. Basically I need run two different task. My R codes for
>>> >>> > these
>>> >>> > task are given below but they do not work properly.
>>> >>> >
>>> >>> > I sincerely do appreciate your helps.
>>> >>> >
>>> >>> >
>>> >>> > Regards,
>>> >>> >
>>> >>> > Greg
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> > Task 1)
>>> >>> >
>>> >>> > For example, the first and second columns for row 1 in data ref are
>>> >>> 29220
>>> >>> > 63933. So I need write an R code normally first look the first row
>>> >>> > in
>>> >>> ref
>>> >>> > (which they are 29220 and 63933) than summing the column of
>>> >>> > "map$rate"
>>> >>> and
>>> >>> > give the number of rows that >0.85. Then do the same for the
>>> >>> > second,
>>> >>> > third....in ref. At the end I would like a table gave below (the
>>> >>> results I
>>> >>> > need). Please notice the all value specified in ref data file are
>>> >>> > exist
>>> >>> in
>>> >>> > map$reg column.
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> > Task2)
>>> >>> >
>>> >>> > Again example, the first and second columns for row 1 in data ref
>>> >>> > are
>>> >>> 29220
>>> >>> > 63933. So I need write an R code give the minimum map$p for the
>>> >>> > 29220
>>> >>> > -63933 intervals in map file. Than
>>> >>> >
>>> >>> > do the same for the second, third....in ref.
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> > #my attempt for the first question
>>> >>> >
>>> >>> > temp<-map[order(map$reg, map$p),]
>>> >>> >
>>> >>> > count<-1
>>> >>> >
>>> >>> > temp<-unique(temp$reg
>>> >>> >
>>> >>> > for(i in 1:length(ref) {
>>> >>> >
>>> >>> >   for(j in 1:length(ref)
>>> >>> >
>>> >>> >   {
>>> >>> >
>>> >>> > temp1<-if (temp[pos[i]==ref[ref$reg1,] &
>>> >>> > (temp[pos[j]==ref[ref$reg2,]
>>> >>> > & temp[cumsum(temp$rate)
>>> >>> >>0.70,])
>>> >>> >
>>> >>> > count=count+1
>>> >>> >
>>> >>> >     }
>>> >>> >
>>> >>> > }
>>> >>> >
>>> >>> > #my attempt for the second question
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> > temp<-map[order(map$reg, map$p),]
>>> >>> >
>>> >>> > count<-1
>>> >>> >
>>> >>> > temp<-unique(temp$reg
>>> >>> >
>>> >>> > for(i in 1:length(ref) {
>>> >>> >
>>> >>> >   for(j in 1:length(ref)
>>> >>> >
>>> >>> >   {
>>> >>> >
>>> >>> > temp2<-if (temp[pos[i]==ref[ref$reg1,] &
>>> >>> > (temp[pos[j]==ref[ref$reg2,])
>>> >>> >
>>> >>> > output<-temp2[temp2$p==min(temp2$p),]
>>> >>> >
>>> >>> >     }
>>> >>> >
>>> >>> > }
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> > Data sets
>>> >>> >
>>> >>> >
>>> >>> >   Data= map
>>> >>> >
>>> >>> >   reg   p      rate
>>> >>> >
>>> >>> >  10276 0.700  3.867e-18
>>> >>> >
>>> >>> >  71608 0.830  4.542e-16
>>> >>> >
>>> >>> >  29220 0.430  1.948e-15
>>> >>> >
>>> >>> >  99542 0.220  1.084e-15
>>> >>> >
>>> >>> >  26441 0.880  9.675e-14
>>> >>> >
>>> >>> >  95082 0.090  7.349e-13
>>> >>> >
>>> >>> >  36169 0.480  9.715e-13
>>> >>> >
>>> >>> >  55572 0.500  9.071e-12
>>> >>> >
>>> >>> >  65255 0.300  1.688e-11
>>> >>> >
>>> >>> >  51960 0.970  1.163e-10
>>> >>> >
>>> >>> >  55652 0.388  3.750e-10
>>> >>> >
>>> >>> >  63933 0.250  9.128e-10
>>> >>> >
>>> >>> >  35170 0.720  7.355e-09
>>> >>> >
>>> >>> >  06491 0.370  1.634e-08
>>> >>> >
>>> >>> >  85508 0.470  1.057e-07
>>> >>> >
>>> >>> >  86666 0.580  7.862e-07
>>> >>> >
>>> >>> >  04758 0.810  9.501e-07
>>> >>> >
>>> >>> >  06169 0.440  1.104e-06
>>> >>> >
>>> >>> >  63933 0.750  2.624e-06
>>> >>> >
>>> >>> >  41838 0.960  8.119e-06
>>> >>> >
>>> >>> >
>>> >>> >  data=ref
>>> >>> >
>>> >>> >   reg1         reg2
>>> >>> >
>>> >>> >   29220     63933
>>> >>> >
>>> >>> >   26441     41838
>>> >>> >
>>> >>> >   06169     10276
>>> >>> >
>>> >>> >   74806     92643
>>> >>> >
>>> >>> >   73732     82451
>>> >>> >
>>> >>> >   86042     93502
>>> >>> >
>>> >>> >   85508     95082
>>> >>> >
>>> >>> >
>>> >>> >
>>> >>> >        the results I need
>>> >>> >
>>> >>> >      reg1      reg2 n
>>> >>> >
>>> >>> >    29220   63933  12
>>> >>> >
>>> >>> >    26441   41838   78
>>> >>> >
>>> >>> >    06169 10276  125
>>> >>> >
>>> >>> >    74806 92643   11
>>> >>> >
>>> >>> >    73732 82451   47
>>> >>> >
>>> >>> >    86042 93502   98
>>> >>> >
>>> >>> >    85508 95082  219
>>> >>> >
>>> >>> >         [[alternative HTML version deleted]]
>>> >>> >
>>> >>> > ______________________________________________
>>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> > PLEASE do read the posting guide
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>> > and provide commented, minimal, self-contained, reproducible code.
>>> >>>
>>> >>
>>> >>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From tr206 at kent.ac.uk  Tue Jun 14 13:46:16 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 14 Jun 2016 11:46:16 +0000
Subject: [R] AR1 model using ARIMA
In-Reply-To: <e988f50ad0f1400b9c9095e4197f2d4f@ex13-live-mbn1.ad.kent.ac.uk>
References: <e988f50ad0f1400b9c9095e4197f2d4f@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <1465904777040.51442@kent.ac.uk>


Dear R users,
I have not received any help regarding my problem. The rolling window AR1 model returns an error if I run my code as follows:

rollingarma<-rollapply(data,width=36,function(data) coef(arima(data,order=c(1,0,0))))
Error in arima(data, order = c(1, 0, 0)) :
  non-stationary AR part from CSS

However, what is wrong with my code?

Can I use the arma() function as alternative? In this case the code is


rollingarma<-rollapply(data,width=36,function(data) coef(arma(data,order=c(1,0),include.intercept = FALSE)))

There were 50 or more warnings (use warnings() to see the first 50)

> warnings()

Warning messages:

1: In optim(coef, err, gr = NULL, hessian = TRUE, ...) :

  one-dimensional optimization by Nelder-Mead is unreliable:

use "Brent" or optimize() directly

In this case, I get a warning message. How can I use Brent or optimize in this code?

Thanks for your support.

       

From murdoch.duncan at gmail.com  Tue Jun 14 14:50:25 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 14 Jun 2016 08:50:25 -0400
Subject: [R] AR1 model using ARIMA
In-Reply-To: <1465904777040.51442@kent.ac.uk>
References: <e988f50ad0f1400b9c9095e4197f2d4f@ex13-live-mbn1.ad.kent.ac.uk>
	<1465904777040.51442@kent.ac.uk>
Message-ID: <8c86beb3-a169-671c-94d4-72b32d0a0bf3@gmail.com>

On 14/06/2016 7:46 AM, T.Riedle wrote:
>
> Dear R users,
> I have not received any help regarding my problem.

Please read the posting guide (see the link at the bottom of every 
message).  If you don't post reproducible code, it's much harder to help 
you.

Duncan Murdoch


The rolling window AR1 model returns an error if I run my code as follows:
>
> rollingarma<-rollapply(data,width=36,function(data) coef(arima(data,order=c(1,0,0))))
> Error in arima(data, order = c(1, 0, 0)) :
>   non-stationary AR part from CSS
>
> However, what is wrong with my code?
>
> Can I use the arma() function as alternative? In this case the code is
>
>
> rollingarma<-rollapply(data,width=36,function(data) coef(arma(data,order=c(1,0),include.intercept = FALSE)))
>
> There were 50 or more warnings (use warnings() to see the first 50)
>
>> warnings()
>
> Warning messages:
>
> 1: In optim(coef, err, gr = NULL, hessian = TRUE, ...) :
>
>   one-dimensional optimization by Nelder-Mead is unreliable:
>
> use "Brent" or optimize() directly
>
> In this case, I get a warning message. How can I use Brent or optimize in this code?
>
> Thanks for your support.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hokut1 at yahoo.com  Tue Jun 14 15:25:57 2016
From: hokut1 at yahoo.com (oslo)
Date: Tue, 14 Jun 2016 13:25:57 +0000 (UTC)
Subject: [R] summing up a column.
In-Reply-To: <alpine.BSF.2.00.1606132015280.5795@pedal.dcn.davis.ca.us>
References: <31785661.876929.1465590843856.JavaMail.yahoo.ref@mail.yahoo.com>
	<31785661.876929.1465590843856.JavaMail.yahoo@mail.yahoo.com>
	<FCDDB5B3-2D68-4BE7-AD53-4FB3AA9C2861@dcn.davis.ca.us>
	<764714753.876287.1465592795459.JavaMail.yahoo@mail.yahoo.com>
	<542840655.919423.1465592922434.JavaMail.yahoo@mail.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030449@SRVEXCHMBX.precheza.cz>
	<1670840319.1796223.1465825507940.JavaMail.yahoo@mail.yahoo.com>
	<alpine.BSF.2.00.1606132015280.5795@pedal.dcn.davis.ca.us>
Message-ID: <1666339483.2325338.1465910757198.JavaMail.yahoo@mail.yahoo.com>

Jeff;
Thanks a lot. I do appreciate for this. I will try your codes.
Regards,
Oslo 

    On Monday, June 13, 2016 11:47 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
 

 You did half of what Petr asked... but your email still looks unreadable
because you did not send it as text only. Look at [1] to see what we see, 
and why we want you to send plain text. What you see is not what we see.

This is an outer join... an inherently inefficient operation according to 
relational database theory. Most solutions to this type of problem are 
likely to be slow, but minimizing unnecessary use of memory can help and 
to do that you can overwrite existing values instead of successively 
concatenating longer vectors of results as you go.

To understand the solution below, you should execute individual 
expressions interactively as you step through the code to see what the 
intermediate values look like. In particular, expressions on the right 
side of assignments can be interactively entered at the console without 
changing the variables in the environment so do it as much as you need to 
in order to see what is happening.

# alignment not required, but HTML run-together lines not wanted
A <- structure( list( posA = c( 1L, 2L, 5L, 4L, 9L)
? ? ? ? ? ? ? ? ? ? , posB = c( 9L, 7L, 12L, 7L, 13L)
? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? ? ? , .Names = c("posA", "posB")
? ? ? ? ? ? ? , class = "data.frame"
? ? ? ? ? ? ? , row.names = c(NA, -5L)
? ? ? ? ? ? ? )
B <- structure( list( pos = c( 4L, 2L, 7L, 1L, 13L, 12L, 9L)
? ? ? ? ? ? ? ? ? ? , a = c(0.4, 0.1, 0.5, 0.4, 0.1, 0.2, 0.3)
? ? ? ? ? ? ? ? ? ? , b = c(7L, 5L, 8L, 1L, 6L, 11L, 12L)
? ? ? ? ? ? ? ? ? ? , c = c(0.8, 0.4, 0.32, 0.1, 0.13, 0.01, 0.23))
? ? ? ? ? ? ? , .Names = c("pos", "a", "b", "c")
? ? ? ? ? ? ? , class = "data.frame"
? ? ? ? ? ? ? , row.names = c(NA, -7L)
? ? ? ? ? ? ? )
# sort B
sB <- B[ order( B$pos ), ]
# performance: set aside memory to remember results
A$count07 <- NA
A$mina <- NA
for ( i in seq.int( nrow( A ) ) ) {
? # logical indexing vector
? idx <- A[ i, "posA" ] <= sB$pos & sB$pos <= A[ i, "posB" ]
? # only extract desired vector once
? a <- sB[ idx, "a" ]
? # sum adds logical values as if TRUE=1
? A[ i, "count07" ] <- sum( cumsum( a ) < 0.7 )
? A[ i, "mina" ] <-min( a )
}
print( A )

#=== sample interactive session for study after A and B are defined
#=== execute lines one at a time and study them!
order( B$pos )
B[ order( B$pos ), ]
sB <- B[ order( B$pos ), ]
A$count07 <- NA
A$mina <- NA
i <- 1
A[ i, "posA" ] 
A[ i, "posB" ]
sB$pos
A[ i, "posA" ] <= sB$pos
sB$pos <= A[ i, "posB" ] 
A[ i, "posA" ] <= sB$pos & sB$pos <= A[ i, "posB" ]
idx <- A[ i, "posA" ] <= sB$pos & sB$pos <= A[ i, "posB" ]
sB[ idx, "a" ]
a <- sB[ idx, "a" ]
cumsum( a )
cumsum( a ) < 0.7
sum( cumsum( a ) < 0.7 )
A[ i, "count07" ] <- sum( cumsum( a ) < 0.7 )
min( a )

------
[1] https://stat.ethz.ch/pipermail/r-help/2016-June/439404.html

On Mon, 13 Jun 2016, oslo via R-help wrote:

> Hi Petr;
> Thanks so much. Here are the questions and the dput(A) and dput(B). Basicaly I have two questions;
>> dput(A)structure(list(posA = c(1L, 2L, 5L, 4L, 9L), posB = c(9L, 7L,?12L, 7L, 13L)), .Names = c("posA", "posB"), class = "data.frame", row.names = c(NA,?-5L))> dput(B)structure(list(pos = c(4L, 2L, 7L, 1L, 13L, 12L, 9L), a = c(0.4,?0.1, 0.5, 0.4, 0.1, 0.2, 0.3), b = c(7L, 5L, 8L, 1L, 6L, 11L,?12L), c = c(0.8, 0.4, 0.32, 0.1, 0.13, 0.01, 0.23)), .Names = c("pos",?"a", "b", "c"), class = "data.frame", row.names = c(NA, -7L))
> Q1) Values in A represent the region of chromosome. I need choose these regions in B (all region in A are exist in B in a single column) and then summing up the column "a in B and count the numbers that gives >0.7. For example, consider ?the first row in A. They are 1 and 9. After sorting the first column in B then summing column "a" only between 1 to 9 in sorted B and cut off at >0.7. Then count how many rows in sorted B gives >0.7. For example there are only 5 rows between 1 to 9 in sorted B and only summing first 2 of them ?gives>0.7 . Then my answer is going to be 2
> Q2) What is the min value of B$a for given each intervals in A
> Regards,
> Oslo 
>
>? ? On Monday, June 13, 2016 8:05 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>
> Ok.
>
> Instead of explaining what you have, please send a result of
>
> dput(B) and dput(A)
>
> And set you mail client to send plain text mail otherwise your code is barely readable.
>
> What do you want to do with printed values?
>
> What is B? From this it seems that it is data frame but then you try to put sorted data frame into a data frame column.
>
> B$possort=B[order(B$pos),]
>
> With such code and data frame I get an error.
>
> So please try to keep above mentioned when posting a query.
>
> Regards
> Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of oslo via R-
>> help
>> Sent: Friday, June 10, 2016 11:09 PM
>> To: oslo <oslo at yahoo.com>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>;
>> oslo via R-help <r-help at r-project.org>; oslo <hokut1 at yahoo.com>
>> Subject: Re: [R] summing up a column.
>>
>> Jeff;
>> ? thanks for this. My question was job related. No from my course. I need
>> finish a job for the place I work. I am so sorry for causing misunderstanding.
>> thanks,
>> Oslo
>>
>> ? ? On Friday, June 10, 2016 5:08 PM, oslo via R-help <r-help at r-project.org>
>> wrote:
>>
>>
>> ? Jeff thanks for this. My question was job related. No from my course. I need
>> finish a job for the place I work. I am so sorry for causing misunderstanding.
>> thanks,
>> Oslo
>>
>> ? ? On Friday, June 10, 2016 5:02 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>
>>
>> ? Multiple posting happens when you are learning a new system, but reading
>> the posting guide can keep the bleeding down.
>>
>> 1) There is a no-homework policy on this list... different educational
>> organizations have different standards for what is acceptable outside help,
>> so you should be using the support offered by your instructor or educational
>> institution.
>>
>> 2) Once you have completed your course, you CAN learn to post data with
>> your code so that it is self-contained... that is, reproducible on our vanilla R
>> session. Using the dput function is one excellent strategy.
>>
>> 3) This is not a problem that needs a loop... as Bert (not Bret) said, you can do
>> this in one or two statements if you simply use basic logical indexing. If your
>> instructor wants you to do it with a loop for sine reason then you really really
>> should not be here... you should be talking to him/her.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On June 10, 2016 1:34:03 PM PDT, oslo via R-help <r-help at r-project.org>
>> wrote:
>> Dear All;
>> I had difficulty to post a mail along with appropriate of data structure. I do
>> sincerely apologize for multiple posting
>>
>>
>> I would like to sum up the B$a column and cut off at 0.7 for the each row of
>> intervals giving in file=A.For example the interval? at the first row in A$posA
>> and A$posB is 1 and 9. So, I need adding up the B$a and cut off B$a>.7 from
>> the 1 to 9 in B$pos. And then I need to the same using the intervals in the
>> second, third..... rows in A. Obviously my loop is wrong and? does not work
>> properly. Please help for my this first experience.? Regards Here are my
>> codes #sorting B$possort=B[order(B$pos),] #Running loop for(i in 1:nrow(A))
>> {if(sum(B[a$B, i:A[1:2])>0.7) {print(A[1:i,]) } } Reply, R R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>
>
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------

  
	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Tue Jun 14 15:30:23 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 14 Jun 2016 13:30:23 +0000
Subject: [R] AR1 model using ARIMA
In-Reply-To: <8c86beb3-a169-671c-94d4-72b32d0a0bf3@gmail.com>
References: <e988f50ad0f1400b9c9095e4197f2d4f@ex13-live-mbn1.ad.kent.ac.uk>
	<1465904777040.51442@kent.ac.uk>,
	<8c86beb3-a169-671c-94d4-72b32d0a0bf3@gmail.com>
Message-ID: <1465911023117.29382@kent.ac.uk>

Sorry, I forgot to attach the file.
________________________________________

 Dear R users,
I have not received any help regarding my problem.

The rolling window AR1 model returns an error if I run my code as follows:

data<-GSDAF[,2]
rollingarma<-rollapply(data,width=36,function(data) coef(arima(data,order=c(1,0,0))))
Error in arima(data, order = c(1, 0, 0)) :
non-stationary AR part from CSS

However, what is wrong with my code?

 Can I use the arma() function as alternative? In this case the code is

 rollingarma<-rollapply(data,width=36,function(data) coef(arma(data,order=c(1,0),include.intercept = FALSE)))

Unfortunately, I get following message:

 There were 50 or more warnings (use warnings() to see the first 50)

warnings()
Warning messages:
In optim(coef, err, gr = NULL, hessian = TRUE, ...) :
one-dimensional optimization by Nelder-Mead is unreliable:
use "Brent" or optimize() directly

How can I use Brent or optimize in this code?

 Thanks for your support.
______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From G.Maubach at weinwolf.de  Tue Jun 14 16:12:04 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 14 Jun 2016 16:12:04 +0200
Subject: [R] Warning message in openxlsx
Message-ID: <OF68C4D98E.D344075E-ONC1257FD2.004D128E-C1257FD2.004E02F2@lotus.hawesko.de>

Hi All,

I get the warning message

Warning message:
In styles$font : partial match of 'font' to 'fonts'

when executing


> xls_workbook <- t_create_workbook()
> xls_sheetname <- "Kunden"
> xls_ds_to_save <- ds_merge1
> xls_filename <- paste0(data_created, 
"_Merge1_BW-SAP-Kunden_cleaned.xlsx")
> t_add_sheet(workbook = xls_workbook,
+             sheetname = xls_sheetname,
+             dataset = xls_ds_to_save)
> t_write_xlsx(workbook = xls_workbook,
+              path = path_output,
+              filename = xls_filename,
+              overwrite = TRUE)

where t_create_workbook() is

return(createWorkbook())

and t_add_sheet() is

 addWorksheet(workbook,
    sheetName = sheetname)
  writeDataTable(workbook, 
    sheet = sheetname, 
    x = dataset)
  ### writeDataTable writes data to a sheet an adds
  ### autofilter to the first line
  if (freeze_row <= 1 | freeze_col <= 1) {
    NULL # do nothing
  }
  else {
    freezePane(workbook,
      sheet = sheetname,
      firstActiveRow = freeze_row,
      firstActiveCol = freeze_col)
  }
 
  setColWidths(workbook,
    sheet = sheetname,
    cols = 1:ncol(dataset), 
    widths = "auto")

and t_write_xlsx is

saveWorkbook(workbook, 
    file = file.path(path, filename),
    overwrite = overwrite)

I am woundring what "partial match of 'font' to 'fonts'" means cause I do 
not call it in the functions calls. I use these calls a lot in my programs 
but never got this message before.

What does this message mean? How can I avoid this message?

Kind regards

Georg Maubach

PS: You can find more information about the used functions by going to 
https://sourceforge.net/projects/r-project-utilities/files/?source=navbar 
.


From jdnewmil at dcn.davis.ca.us  Tue Jun 14 16:21:00 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 14 Jun 2016 07:21:00 -0700
Subject: [R] AR1 model using ARIMA
In-Reply-To: <1465911023117.29382@kent.ac.uk>
References: <e988f50ad0f1400b9c9095e4197f2d4f@ex13-live-mbn1.ad.kent.ac.uk>
	<1465904777040.51442@kent.ac.uk>,
	<8c86beb3-a169-671c-94d4-72b32d0a0bf3@gmail.com>
	<1465911023117.29382@kent.ac.uk>
Message-ID: <61D18AAC-9899-4373-8CA7-5B30FF055B7A@dcn.davis.ca.us>

Looks like you forgot to read the Posting Guide, too. 
-- 
Sent from my phone. Please excuse my brevity.

On June 14, 2016 6:30:23 AM PDT, "T.Riedle" <tr206 at kent.ac.uk> wrote:
>Sorry, I forgot to attach the file.
>________________________________________
>
> Dear R users,
>I have not received any help regarding my problem.
>
>The rolling window AR1 model returns an error if I run my code as
>follows:
>
>data<-GSDAF[,2]
>rollingarma<-rollapply(data,width=36,function(data)
>coef(arima(data,order=c(1,0,0))))
>Error in arima(data, order = c(1, 0, 0)) :
>non-stationary AR part from CSS
>
>However, what is wrong with my code?
>
> Can I use the arma() function as alternative? In this case the code is
>
>rollingarma<-rollapply(data,width=36,function(data)
>coef(arma(data,order=c(1,0),include.intercept = FALSE)))
>
>Unfortunately, I get following message:
>
> There were 50 or more warnings (use warnings() to see the first 50)
>
>warnings()
>Warning messages:
>In optim(coef, err, gr = NULL, hessian = TRUE, ...) :
>one-dimensional optimization by Nelder-Mead is unreliable:
>use "Brent" or optimize() directly
>
>How can I use Brent or optimize in this code?
>
> Thanks for your support.
>______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ayyappach at gmail.com  Tue Jun 14 17:02:10 2016
From: ayyappach at gmail.com (Ayyappa Chaturvedula)
Date: Tue, 14 Jun 2016 10:02:10 -0500
Subject: [R] rlnorm behaviour
Message-ID: <CAL8Tui5AgLHsSG7WL0yCpkog_4Fdnfx7eoHRaEMzt5bv4cocXQ@mail.gmail.com>

Dear Group,

I am trying to simulate a dataset with 200 individuals with random
assignment of Sex (1,0) and Weight from lognormal distribution specific to
Sex.  I am intrigued by the behavior of rlnorm function to impute a value
of Weight from the specified distribution.  Here is the code:
ID<-1:200
Sex<-sample(c(0,1),200,replace=T,prob=c(0.4,0.6))
fulldata<-data.frame(ID,Sex)
fulldata$Wt<-ifelse(fulldata$Sex==1,rlnorm(100, meanlog = log(85.1), sdlog
= sqrt(0.0329)),
                    rlnorm(100, meanlog = log(73), sdlog = sqrt(0.0442)))

mean(fulldata$Wt[fulldata$Sex==0]);to check the mean is close to 73
mean(fulldata$Wt[fulldata$Sex==1]);to check the mean is close to 85

I see that the number of simulated values has an effect on the mean
calculated after imputation. That is, the code rlnorm(100, meanlog =
log(73), sdlog = sqrt(0.0442)) gives much better match compared to
rlnorm(1, meanlog = log(73), sdlog = sqrt(0.0442)) in ifelse statement in
the code above.

My understanding is that ifelse will be imputing only one value where the
condition is met as specified.  I appreciate your insights on the behavior
for better performance of increasing sample number.  I appreciate your
comments.

Regards,
Ayyappa

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Jun 14 17:15:28 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 14 Jun 2016 17:15:28 +0200
Subject: [R] rlnorm behaviour
In-Reply-To: <CAL8Tui5AgLHsSG7WL0yCpkog_4Fdnfx7eoHRaEMzt5bv4cocXQ@mail.gmail.com>
References: <CAL8Tui5AgLHsSG7WL0yCpkog_4Fdnfx7eoHRaEMzt5bv4cocXQ@mail.gmail.com>
Message-ID: <CAJuCY5y-7W3g+p1cr6cmH+J+NCwTNC9ysU-pVycBH8gFzrx7-Q@mail.gmail.com>

Dear Ayyappa,

ifelse works on a vector. See the example below.

ifelse(
  sample(c(TRUE, FALSE), size = length(letters), replace = TRUE),
  letters,
  LETTERS
)

However, note that it will recycle short vectors when they are not of equal
length.

ifelse(
  sample(c(TRUE, FALSE), size = 2 * length(letters), replace = TRUE),
  letters,
  LETTERS
)

In your code the length of the condition vector is 200, the length of the
two other vectors is 100.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-14 17:02 GMT+02:00 Ayyappa Chaturvedula <ayyappach at gmail.com>:

> Dear Group,
>
> I am trying to simulate a dataset with 200 individuals with random
> assignment of Sex (1,0) and Weight from lognormal distribution specific to
> Sex.  I am intrigued by the behavior of rlnorm function to impute a value
> of Weight from the specified distribution.  Here is the code:
> ID<-1:200
> Sex<-sample(c(0,1),200,replace=T,prob=c(0.4,0.6))
> fulldata<-data.frame(ID,Sex)
> fulldata$Wt<-ifelse(fulldata$Sex==1,rlnorm(100, meanlog = log(85.1), sdlog
> = sqrt(0.0329)),
>                     rlnorm(100, meanlog = log(73), sdlog = sqrt(0.0442)))
>
> mean(fulldata$Wt[fulldata$Sex==0]);to check the mean is close to 73
> mean(fulldata$Wt[fulldata$Sex==1]);to check the mean is close to 85
>
> I see that the number of simulated values has an effect on the mean
> calculated after imputation. That is, the code rlnorm(100, meanlog =
> log(73), sdlog = sqrt(0.0442)) gives much better match compared to
> rlnorm(1, meanlog = log(73), sdlog = sqrt(0.0442)) in ifelse statement in
> the code above.
>
> My understanding is that ifelse will be imputing only one value where the
> condition is met as specified.  I appreciate your insights on the behavior
> for better performance of increasing sample number.  I appreciate your
> comments.
>
> Regards,
> Ayyappa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Tue Jun 14 17:28:37 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Tue, 14 Jun 2016 15:28:37 +0000 (UTC)
Subject: [R] Factor levels in training set
In-Reply-To: <487756069.5046266.1465916449698.JavaMail.yahoo@mail.yahoo.com>
References: <487756069.5046266.1465916449698.JavaMail.yahoo.ref@mail.yahoo.com>
	<487756069.5046266.1465916449698.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1467905871.5110358.1465918117218.JavaMail.yahoo@mail.yahoo.com>


 Hi all, 
I want to use Supervised Self organizing Maps from Kohonen package for my data. I need to divide my df into training set and test set, but a part of my df contains column with factor levels and I don't know how to bring them into my training set. Currently I use the following command for my training set:

    dt=sort(sample(nrow(df),nrow(df)*.7))
    training=m[dt,]
till here I get no error but in the next step which I need to bring my training set in a matrix I face this error:
    
    scale(df[training,])
error: 'x' should be numeric
Does anyone know how should I include column with factor levels in my df so that I don't get this error?
Thanks for any help,
Elahe


From chalabi.elahe at yahoo.de  Tue Jun 14 17:00:49 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Tue, 14 Jun 2016 15:00:49 +0000 (UTC)
Subject: [R] Factor levels in training set
References: <487756069.5046266.1465916449698.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <487756069.5046266.1465916449698.JavaMail.yahoo@mail.yahoo.com>

Hi all, 
I want to use Supervised Self organizing Maps from Kohonen package for my data. I need to divide my df into training set and test set, but a part of my df contains column with factor levels and I don't know how to bring them into my training set. Currently I use the following command for my training set:
 
    dt=sort(sample(nrow(df),nrow(df)*.7))
    training=m[dt,]
till here I get no error but in the next step which I need to bring my training set in a matrix I face this error:
    
    scale(df[training,])
error: 'x' should be numeric
Does anyone know how should I include column with factor levels in my df so that I don't get this error?
Thanks for any help,
Elahe


From thierry.onkelinx at inbo.be  Tue Jun 14 17:42:46 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 14 Jun 2016 17:42:46 +0200
Subject: [R] rlnorm behaviour
In-Reply-To: <CAL8Tui79aAOVnmWq4O9ghe_a90YzHizB1XjL5LEj8gnJjT3zUA@mail.gmail.com>
References: <CAL8Tui5AgLHsSG7WL0yCpkog_4Fdnfx7eoHRaEMzt5bv4cocXQ@mail.gmail.com>
	<CAJuCY5y-7W3g+p1cr6cmH+J+NCwTNC9ysU-pVycBH8gFzrx7-Q@mail.gmail.com>
	<CAL8Tui79aAOVnmWq4O9ghe_a90YzHizB1XjL5LEj8gnJjT3zUA@mail.gmail.com>
Message-ID: <CAJuCY5yi541zmkeJ6nRA_H6WVaWeHEFwC6MJ9iM4T8DbX86k2Q@mail.gmail.com>

Please keep r-help in cc.

Yes. Have a look at this example

ifelse(
  sample(c(TRUE, FALSE), size = 0.5 * length(letters), replace = TRUE),
  letters,
  LETTERS
)


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-14 17:31 GMT+02:00 Ayyappa Chaturvedula <ayyappach at gmail.com>:

> Thank you very much for your kind support.  The length of my condition
> vector is ~80 because I want only Sex==1 and else will be the other.  I
> understand now how ifelse works.  If the vector of the simulated vector is
> longer than the condition vector, then it takes the first few elements to
> match the length of condition vector and discards the rest?
>
> Regards,
> Ayyappa
>
> On Tue, Jun 14, 2016 at 10:15 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Ayyappa,
>>
>> ifelse works on a vector. See the example below.
>>
>> ifelse(
>>   sample(c(TRUE, FALSE), size = length(letters), replace = TRUE),
>>   letters,
>>   LETTERS
>> )
>>
>> However, note that it will recycle short vectors when they are not of
>> equal length.
>>
>> ifelse(
>>   sample(c(TRUE, FALSE), size = 2 * length(letters), replace = TRUE),
>>   letters,
>>   LETTERS
>> )
>>
>> In your code the length of the condition vector is 200, the length of the
>> two other vectors is 100.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-06-14 17:02 GMT+02:00 Ayyappa Chaturvedula <ayyappach at gmail.com>:
>>
>>> Dear Group,
>>>
>>> I am trying to simulate a dataset with 200 individuals with random
>>> assignment of Sex (1,0) and Weight from lognormal distribution specific
>>> to
>>> Sex.  I am intrigued by the behavior of rlnorm function to impute a value
>>> of Weight from the specified distribution.  Here is the code:
>>> ID<-1:200
>>> Sex<-sample(c(0,1),200,replace=T,prob=c(0.4,0.6))
>>> fulldata<-data.frame(ID,Sex)
>>> fulldata$Wt<-ifelse(fulldata$Sex==1,rlnorm(100, meanlog = log(85.1),
>>> sdlog
>>> = sqrt(0.0329)),
>>>                     rlnorm(100, meanlog = log(73), sdlog = sqrt(0.0442)))
>>>
>>> mean(fulldata$Wt[fulldata$Sex==0]);to check the mean is close to 73
>>> mean(fulldata$Wt[fulldata$Sex==1]);to check the mean is close to 85
>>>
>>> I see that the number of simulated values has an effect on the mean
>>> calculated after imputation. That is, the code rlnorm(100, meanlog =
>>> log(73), sdlog = sqrt(0.0442)) gives much better match compared to
>>> rlnorm(1, meanlog = log(73), sdlog = sqrt(0.0442)) in ifelse statement in
>>> the code above.
>>>
>>> My understanding is that ifelse will be imputing only one value where the
>>> condition is met as specified.  I appreciate your insights on the
>>> behavior
>>> for better performance of increasing sample number.  I appreciate your
>>> comments.
>>>
>>> Regards,
>>> Ayyappa
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From ayyappach at gmail.com  Tue Jun 14 17:47:12 2016
From: ayyappach at gmail.com (Ayyappa Chaturvedula)
Date: Tue, 14 Jun 2016 10:47:12 -0500
Subject: [R] rlnorm behaviour
In-Reply-To: <CAJuCY5yi541zmkeJ6nRA_H6WVaWeHEFwC6MJ9iM4T8DbX86k2Q@mail.gmail.com>
References: <CAL8Tui5AgLHsSG7WL0yCpkog_4Fdnfx7eoHRaEMzt5bv4cocXQ@mail.gmail.com>
	<CAJuCY5y-7W3g+p1cr6cmH+J+NCwTNC9ysU-pVycBH8gFzrx7-Q@mail.gmail.com>
	<CAL8Tui79aAOVnmWq4O9ghe_a90YzHizB1XjL5LEj8gnJjT3zUA@mail.gmail.com>
	<CAJuCY5yi541zmkeJ6nRA_H6WVaWeHEFwC6MJ9iM4T8DbX86k2Q@mail.gmail.com>
Message-ID: <CAL8Tui4-_+W6r4uEdmqmoJ5hygwsOuUWSeHn8iUpooDGUXGeQA@mail.gmail.com>

I am sorry, I missed that.  I think I made it more appropriate and not
using unnecessary simulated values.  Thank you for your help.

fulldata$Wt<-ifelse(fulldata$Sex==1,rlnorm(length(fulldata$Sex[fulldata$Sex==1]),
meanlog = log(85.1), sdlog = sqrt(0.0329)),
                    rlnorm(length(fulldata$Sex[fulldata$Sex==0]), meanlog =
log(73), sdlog = sqrt(0.0442)))

On Tue, Jun 14, 2016 at 10:42 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Please keep r-help in cc.
>
> Yes. Have a look at this example
>
> ifelse(
>   sample(c(TRUE, FALSE), size = 0.5 * length(letters), replace = TRUE),
>   letters,
>   LETTERS
> )
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-06-14 17:31 GMT+02:00 Ayyappa Chaturvedula <ayyappach at gmail.com>:
>
>> Thank you very much for your kind support.  The length of my condition
>> vector is ~80 because I want only Sex==1 and else will be the other.  I
>> understand now how ifelse works.  If the vector of the simulated vector is
>> longer than the condition vector, then it takes the first few elements to
>> match the length of condition vector and discards the rest?
>>
>> Regards,
>> Ayyappa
>>
>> On Tue, Jun 14, 2016 at 10:15 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Ayyappa,
>>>
>>> ifelse works on a vector. See the example below.
>>>
>>> ifelse(
>>>   sample(c(TRUE, FALSE), size = length(letters), replace = TRUE),
>>>   letters,
>>>   LETTERS
>>> )
>>>
>>> However, note that it will recycle short vectors when they are not of
>>> equal length.
>>>
>>> ifelse(
>>>   sample(c(TRUE, FALSE), size = 2 * length(letters), replace = TRUE),
>>>   letters,
>>>   LETTERS
>>> )
>>>
>>> In your code the length of the condition vector is 200, the length of
>>> the two other vectors is 100.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2016-06-14 17:02 GMT+02:00 Ayyappa Chaturvedula <ayyappach at gmail.com>:
>>>
>>>> Dear Group,
>>>>
>>>> I am trying to simulate a dataset with 200 individuals with random
>>>> assignment of Sex (1,0) and Weight from lognormal distribution specific
>>>> to
>>>> Sex.  I am intrigued by the behavior of rlnorm function to impute a
>>>> value
>>>> of Weight from the specified distribution.  Here is the code:
>>>> ID<-1:200
>>>> Sex<-sample(c(0,1),200,replace=T,prob=c(0.4,0.6))
>>>> fulldata<-data.frame(ID,Sex)
>>>> fulldata$Wt<-ifelse(fulldata$Sex==1,rlnorm(100, meanlog = log(85.1),
>>>> sdlog
>>>> = sqrt(0.0329)),
>>>>                     rlnorm(100, meanlog = log(73), sdlog =
>>>> sqrt(0.0442)))
>>>>
>>>> mean(fulldata$Wt[fulldata$Sex==0]);to check the mean is close to 73
>>>> mean(fulldata$Wt[fulldata$Sex==1]);to check the mean is close to 85
>>>>
>>>> I see that the number of simulated values has an effect on the mean
>>>> calculated after imputation. That is, the code rlnorm(100, meanlog =
>>>> log(73), sdlog = sqrt(0.0442)) gives much better match compared to
>>>> rlnorm(1, meanlog = log(73), sdlog = sqrt(0.0442)) in ifelse statement
>>>> in
>>>> the code above.
>>>>
>>>> My understanding is that ifelse will be imputing only one value where
>>>> the
>>>> condition is met as specified.  I appreciate your insights on the
>>>> behavior
>>>> for better performance of increasing sample number.  I appreciate your
>>>> comments.
>>>>
>>>> Regards,
>>>> Ayyappa
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Tue Jun 14 17:55:06 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 14 Jun 2016 16:55:06 +0100
Subject: [R] detecting if a variable has changed
In-Reply-To: <80a72f7f-c1de-c52d-79fd-c53447ed6e97@gmail.com>
References: <87d1nvwmwy.wl-neal@walfield.org>
	<XFMail.20160605190114.Ted.Harding@wlandres.net>
	<CAGxFJbShgYUVSs2O8GPtWE9MxBEaRRXoVU=mPHvzH2-VxAruGw@mail.gmail.com>,
	<80a72f7f-c1de-c52d-79fd-c53447ed6e97@gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403E164387A@GBTEDVPEXCMB04.corp.lgc-group.com>

> > Nope, Ted. I asked for  a O(log(n)) solution, not an O(n) one.
> 
> I don't think that's possible with a numeric vector.  Inserting an entry
> at a random location is an O(n) operation, since you need to move all
> following values out of the way.

If the vector is presorted, wouldn't a binary search find the correct location in O(log(n))? (roughly log2(n)?) 

After that any insertion depends on how fast R can move memory about so the overall speed clearly depends on factors other than finding the location. 

S Ellison

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From thierry.onkelinx at inbo.be  Tue Jun 14 18:08:48 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 14 Jun 2016 18:08:48 +0200
Subject: [R] rlnorm behaviour
In-Reply-To: <CAL8Tui4-_+W6r4uEdmqmoJ5hygwsOuUWSeHn8iUpooDGUXGeQA@mail.gmail.com>
References: <CAL8Tui5AgLHsSG7WL0yCpkog_4Fdnfx7eoHRaEMzt5bv4cocXQ@mail.gmail.com>
	<CAJuCY5y-7W3g+p1cr6cmH+J+NCwTNC9ysU-pVycBH8gFzrx7-Q@mail.gmail.com>
	<CAL8Tui79aAOVnmWq4O9ghe_a90YzHizB1XjL5LEj8gnJjT3zUA@mail.gmail.com>
	<CAJuCY5yi541zmkeJ6nRA_H6WVaWeHEFwC6MJ9iM4T8DbX86k2Q@mail.gmail.com>
	<CAL8Tui4-_+W6r4uEdmqmoJ5hygwsOuUWSeHn8iUpooDGUXGeQA@mail.gmail.com>
Message-ID: <CAJuCY5wN4cxRxsxX7E07=05PnzcOLSyQ+J132zrn7mMozpp=0A@mail.gmail.com>

You need to study my examples and the helpfile of ifelse more carefully.
Then you'll understand why your code is wrong.

?
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
Op 14 jun. 2016 17:47 schreef "Ayyappa Chaturvedula" <ayyappach at gmail.com>:

> I am sorry, I missed that.  I think I made it more appropriate and not
> using unnecessary simulated values.  Thank you for your help.
>
> fulldata$Wt<-ifelse(fulldata$Sex==1,rlnorm(length(fulldata$Sex[fulldata$Sex==1]),
> meanlog = log(85.1), sdlog = sqrt(0.0329)),
>                     rlnorm(length(fulldata$Sex[fulldata$Sex==0]), meanlog
> = log(73), sdlog = sqrt(0.0442)))
>
> On Tue, Jun 14, 2016 at 10:42 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Please keep r-help in cc.
>>
>> Yes. Have a look at this example
>>
>> ifelse(
>>   sample(c(TRUE, FALSE), size = 0.5 * length(letters), replace = TRUE),
>>   letters,
>>   LETTERS
>> )
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-06-14 17:31 GMT+02:00 Ayyappa Chaturvedula <ayyappach at gmail.com>:
>>
>>> Thank you very much for your kind support.  The length of my condition
>>> vector is ~80 because I want only Sex==1 and else will be the other.  I
>>> understand now how ifelse works.  If the vector of the simulated vector is
>>> longer than the condition vector, then it takes the first few elements to
>>> match the length of condition vector and discards the rest?
>>>
>>> Regards,
>>> Ayyappa
>>>
>>> On Tue, Jun 14, 2016 at 10:15 AM, Thierry Onkelinx <
>>> thierry.onkelinx at inbo.be> wrote:
>>>
>>>> Dear Ayyappa,
>>>>
>>>> ifelse works on a vector. See the example below.
>>>>
>>>> ifelse(
>>>>   sample(c(TRUE, FALSE), size = length(letters), replace = TRUE),
>>>>   letters,
>>>>   LETTERS
>>>> )
>>>>
>>>> However, note that it will recycle short vectors when they are not of
>>>> equal length.
>>>>
>>>> ifelse(
>>>>   sample(c(TRUE, FALSE), size = 2 * length(letters), replace = TRUE),
>>>>   letters,
>>>>   LETTERS
>>>> )
>>>>
>>>> In your code the length of the condition vector is 200, the length of
>>>> the two other vectors is 100.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>>> and Forest
>>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>>> Kliniekstraat 25
>>>> 1070 Anderlecht
>>>> Belgium
>>>>
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> 2016-06-14 17:02 GMT+02:00 Ayyappa Chaturvedula <ayyappach at gmail.com>:
>>>>
>>>>> Dear Group,
>>>>>
>>>>> I am trying to simulate a dataset with 200 individuals with random
>>>>> assignment of Sex (1,0) and Weight from lognormal distribution
>>>>> specific to
>>>>> Sex.  I am intrigued by the behavior of rlnorm function to impute a
>>>>> value
>>>>> of Weight from the specified distribution.  Here is the code:
>>>>> ID<-1:200
>>>>> Sex<-sample(c(0,1),200,replace=T,prob=c(0.4,0.6))
>>>>> fulldata<-data.frame(ID,Sex)
>>>>> fulldata$Wt<-ifelse(fulldata$Sex==1,rlnorm(100, meanlog = log(85.1),
>>>>> sdlog
>>>>> = sqrt(0.0329)),
>>>>>                     rlnorm(100, meanlog = log(73), sdlog =
>>>>> sqrt(0.0442)))
>>>>>
>>>>> mean(fulldata$Wt[fulldata$Sex==0]);to check the mean is close to 73
>>>>> mean(fulldata$Wt[fulldata$Sex==1]);to check the mean is close to 85
>>>>>
>>>>> I see that the number of simulated values has an effect on the mean
>>>>> calculated after imputation. That is, the code rlnorm(100, meanlog =
>>>>> log(73), sdlog = sqrt(0.0442)) gives much better match compared to
>>>>> rlnorm(1, meanlog = log(73), sdlog = sqrt(0.0442)) in ifelse statement
>>>>> in
>>>>> the code above.
>>>>>
>>>>> My understanding is that ifelse will be imputing only one value where
>>>>> the
>>>>> condition is met as specified.  I appreciate your insights on the
>>>>> behavior
>>>>> for better performance of increasing sample number.  I appreciate your
>>>>> comments.
>>>>>
>>>>> Regards,
>>>>> Ayyappa
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Tue Jun 14 14:04:58 2016
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 14 Jun 2016 08:04:58 -0400
Subject: [R] two difficult loop
In-Reply-To: <CA+8X3fUaFoyzm=GXwY0PBUxrAfVJSqH51BwzbwdNzR2YXZCxSQ@mail.gmail.com>
References: <CAM9Qe4i7hvLU9M9KjXrFqpV0iM0-52yNV39g1s7T5i8VYR_5Ow@mail.gmail.com>
	<CAGxFJbQr2HFVy7K-H5FFBVZT7K4G6=+-9nQL9Q3=BpQeB9UM8g@mail.gmail.com>
	<CAM9Qe4gBctQDctAjPzoNBtXqj+fpQY3i1bqFrgEqs1WwWzQqbw@mail.gmail.com>
	<CAM9Qe4giTr6tA2-hB5yhoUV_28=1RWBFhXLktj6LXz+Vy21Qkg@mail.gmail.com>
	<CA+8X3fUtMsA91FSkoM9hUuo6DUHFSxHcDcGLM8ivqXBHObRU+w@mail.gmail.com>
	<CAM9Qe4hk2oY=NXS1jHBbHaQOu356ZFsNZmHNpmZsvWF4Zd_6AA@mail.gmail.com>
	<CAM9Qe4iYaLZUWG+iSKEO6NfqSQWNA9O7okxzXAGJZbG16Q0dhw@mail.gmail.com>
	<CA+8X3fUaFoyzm=GXwY0PBUxrAfVJSqH51BwzbwdNzR2YXZCxSQ@mail.gmail.com>
Message-ID: <CAM9Qe4iMRxwR79YwT+Sm3AO-VYpH768kMwZXHvcgkd_ihC1Uew@mail.gmail.com>

Thanks a lot Jim. I am struggling to solve the problem.I do appreciate for
your helps and advice.

Greg

On Tue, Jun 14, 2016 at 3:39 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Greg,
> This is obviously a problem with the data. The first error indicates
> that the sequence of integers regrange[1]:regrange[2] is too long to
> be allocated. Most likely this is because one or both of the endpoints
> are infinite. Maybe if you can find where the NAs are you can fix it.
>
> Jim
>
> On Tue, Jun 14, 2016 at 12:29 AM, greg holly <mak.hholly at gmail.com> wrote:
> > Hi Jim;
> >
> > I do apologize if bothering. I have run on the real data and here is the
> > error message I got:
> >
> > Thanks,
> >
> > Greg
> >
> > start  end
> > Error in regrange[1]:regrange[2] : result would be too long a vector
> > In addition: Warning messages:
> > 1: In min(x) : no non-missing arguments to min; returning Inf
> > 2: In max(x) : no non-missing arguments to max; returning -Inf
> >
> > On Mon, Jun 13, 2016 at 10:28 AM, greg holly <mak.hholly at gmail.com>
> wrote:
> >>
> >> Hi Jim;
> >>
> >> I do apologize if bothering. I have run on the real data and here is the
> >> error message I got:
> >>
> >> Thanks,
> >>
> >> Greg
> >>
> >> start  end
> >> Error in regrange[1]:regrange[2] : result would be too long a vector
> >> In addition: Warning messages:
> >> 1: In min(x) : no non-missing arguments to min; returning Inf
> >> 2: In max(x) : no non-missing arguments to max; returning -Inf
> >>
> >>
> >> On Mon, Jun 13, 2016 at 3:19 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>>
> >>> Hi Greg,
> >>> Okay, I have a better idea now of what you want. The problem of
> >>> multiple matches is still there, but here is a start:
> >>>
> >>> # this data frame actually contains all the values in ref in the "reg"
> >>> field
> >>> map<-read.table(text="reg p rate
> >>>  10276 0.700  3.867e-18
> >>>  71608 0.830  4.542e-16
> >>>  29220 0.430  1.948e-15
> >>>  99542 0.220  1.084e-15
> >>>  26441 0.880  9.675e-14
> >>>  95082 0.090  7.349e-13
> >>>  36169 0.480  9.715e-13
> >>>  55572 0.500  9.071e-12
> >>>  65255 0.300  1.688e-11
> >>>  51960 0.970  1.163e-10
> >>>  55652 0.388  3.750e-10
> >>>  63933 0.250  9.128e-10
> >>>  35170 0.720  7.355e-09
> >>>  06491 0.370  1.634e-08
> >>>  85508 0.470  1.057e-07
> >>>  86666 0.580  7.862e-07
> >>>  04758 0.810  9.501e-07
> >>>  06169 0.440  1.104e-06
> >>>  63933 0.750  2.624e-06
> >>>  41838 0.960  8.119e-06
> >>>  74806 0.810  9.501e-07
> >>>  92643 0.470  1.057e-07
> >>>  73732 0.090  7.349e-13
> >>>  82451 0.960  8.119e-06
> >>>  86042 0.480  9.715e-13
> >>>  93502 0.500  9.071e-12
> >>>  85508 0.370  1.634e-08
> >>>  95082 0.830  4.542e-16",
> >>>  header=TRUE)
> >>> # same as in your example
> >>> ref<-read.table(text="reg1 reg2
> >>>  29220     63933
> >>>  26441     41838
> >>>  06169     10276
> >>>  74806     92643
> >>>  73732     82451
> >>>  86042     93502
> >>>  85508     95082",
> >>>  header=TRUE)
> >>> # sort the "map" data frame
> >>> map2<-map[order(map$reg),]
> >>> # get a field for the counts
> >>> ref$n<-NA
> >>> # and a field for the minimum p values
> >>> ref$min_p<-NA
> >>> # get the number of rows in "ref"
> >>> nref<-dim(ref)[1]
> >>> for(i in 1:nref) {
> >>>  start<-which(map2$reg==ref$reg1[i])
> >>>  end<-which(map2$reg==ref$reg2[i])
> >>>  cat("start",start,"end",end,"\n")
> >>>  # get the range of matches
> >>>  regrange<-range(c(start,end))
> >>>  # convert this to a sequence spanning all matches
> >>>  allreg<-regrange[1]:regrange[2]
> >>>  ref$n[i]<-sum(map2$p[allreg] > 0.85)
> >>>  ref$min_p[i]<-min(map2$p[allreg])
> >>> }
> >>>
> >>> This example uses the span from the first match of "reg1" to the last
> >>> match of "reg2". This may not be what you want, so let me know if
> >>> there are further constraints.
> >>>
> >>> Jim
> >>>
> >>> On Mon, Jun 13, 2016 at 12:35 PM, greg holly <mak.hholly at gmail.com>
> >>> wrote:
> >>> > Hi Bert;
> >>> >
> >>> > I do appreciate for this. I need check your codes on task2 tomorrow
> at
> >>> > my
> >>> > office on the real data as I have difficulty (because a technical
> >>> > issue) to
> >>> > remote connection. I am sure it will work well.
> >>> >
> >>> > I am sorry that I was not able to explain my first question.
> Basically
> >>> >
> >>> > Values in ref data represent the region of chromosome. I need choose
> >>> > these
> >>> > regions in map (all regions values in ref data are exist in map data
> in
> >>> > the
> >>> > first column -column map$reg). And then summing up the column
> "map$rate
> >>> > and
> >>> > count the numbers that gives >0.85. For example, consider  the first
> >>> > row in
> >>> > data ref. They are 29220   and  63933. After sorting the first column
> >>> > in
> >>> > map then summing column "map$rate" only between 29220   to  63933 in
> >>> > sorted
> >>> > map and cut off at >0.85. Then count how many rows in sorted map
> gives
> >>> >>0.85. For example consider there are 38 rows between 29220   in
> 63933
> >>> >> in sorted
> >>> > map$reg and only summing first 12 of them  gives>0.85. Then my answer
> >>> > is
> >>> > going to be 12 for 29220   -  63933 in ref.
> >>> >
> >>> > Thanks I lot for your patience.
> >>> >
> >>> > Cheers,
> >>> > Greg
> >>> >
> >>> > On Sun, Jun 12, 2016 at 10:35 PM, greg holly <mak.hholly at gmail.com>
> >>> > wrote:
> >>> >
> >>> >> Hi Bert;
> >>> >>
> >>> >> I do appreciate for this. I need check your codes on task2 tomorrow
> at
> >>> >> my
> >>> >> office on the real data as I have difficulty (because a technical
> >>> >> issue) to
> >>> >> remote connection. I am sure it will work well.
> >>> >>
> >>> >> I am sorry that I was not able to explain my first question.
> Basically
> >>> >>
> >>> >> Values in ref data represent the region of chromosome. I need choose
> >>> >> these
> >>> >> regions in map (all regions values in ref data are exist in map data
> >>> >> in the
> >>> >> first column -column map$reg). And then summing up the column
> >>> >> "map$rate and
> >>> >> count the numbers that gives >0.85. For example, consider  the first
> >>> >> row in
> >>> >> data ref. They are 29220   and  63933. After sorting the first
> column
> >>> >> in
> >>> >> map then summing column "map$rate" only between 29220   to  63933 in
> >>> >> sorted map and cut off at >0.85. Then count how many rows in sorted
> >>> >> map
> >>> >> gives >0.85. For example consider there are 38 rows between 29220
>  in
> >>> >>  63933 in sorted map$reg and only summing first 12 of them
> >>> >> gives>0.85.
> >>> >> Then my answer is going to be 12 for 29220   -  63933 in ref.
> >>> >>
> >>> >> Thanks I lot for your patience.
> >>> >>
> >>> >> Cheers,
> >>> >> Greg
> >>> >>
> >>> >> On Sun, Jun 12, 2016 at 6:36 PM, Bert Gunter <
> bgunter.4567 at gmail.com>
> >>> >> wrote:
> >>> >>
> >>> >>> Greg:
> >>> >>>
> >>> >>> I was not able to understand your task 1. Perhaps others can.
> >>> >>>
> >>> >>> My understanding of your task 2 is that for each row of ref, you
> wish
> >>> >>> to find all rows,of map such that the reg values in those rows fall
> >>> >>> between the reg1 and reg2 values in ref (inclusive change <= to <
> if
> >>> >>> you don't want the endpoints), and then you want the minimum map$p
> >>> >>> values of all those rows. If that is correct, I believe this will
> do
> >>> >>> it (but caution, untested, as you failed to provide data in a
> >>> >>> convenient form, e.g. using dput() )
> >>> >>>
> >>> >>> task2 <- with(map,vapply(seq_len(nrow(ref)),function(i)
> >>> >>> min(p[ref[i,1]<=reg & reg <= ref[i,2] ]),0))
> >>> >>>
> >>> >>>
> >>> >>> If my understanding is incorrect, please ignore both the above and
> >>> >>> the
> >>> >>> following:
> >>> >>>
> >>> >>>
> >>> >>> The "solution" I have given above seems inefficient, so others may
> be
> >>> >>> able to significantly improve it if you find that it takes too
> long.
> >>> >>> OTOH, my understanding of your specification is that you need to
> >>> >>> search for all rows in map data frame that meet the criterion for
> >>> >>> each
> >>> >>> row of ref, and without further information, I don't know how to do
> >>> >>> this without just repeating the search 560 times.
> >>> >>>
> >>> >>>
> >>> >>> Cheers,
> >>> >>> Bert
> >>> >>>
> >>> >>>
> >>> >>> Bert Gunter
> >>> >>>
> >>> >>> "The trouble with having an open mind is that people keep coming
> >>> >>> along
> >>> >>> and sticking things into it."
> >>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>> >>>
> >>> >>>
> >>> >>> On Sun, Jun 12, 2016 at 1:14 PM, greg holly <mak.hholly at gmail.com>
> >>> >>> wrote:
> >>> >>> > Dear all;
> >>> >>> >
> >>> >>> >
> >>> >>> >
> >>> >>> > I have two data sets, data=map and data=ref). A small part of
> each
> >>> >>> > data
> >>> >>> set
> >>> >>> > are given below. Data map has more than 27 million and data ref
> has
> >>> >>> about
> >>> >>> > 560 rows. Basically I need run two different task. My R codes for
> >>> >>> > these
> >>> >>> > task are given below but they do not work properly.
> >>> >>> >
> >>> >>> > I sincerely do appreciate your helps.
> >>> >>> >
> >>> >>> >
> >>> >>> > Regards,
> >>> >>> >
> >>> >>> > Greg
> >>> >>> >
> >>> >>> >
> >>> >>> >
> >>> >>> > Task 1)
> >>> >>> >
> >>> >>> > For example, the first and second columns for row 1 in data ref
> are
> >>> >>> 29220
> >>> >>> > 63933. So I need write an R code normally first look the first
> row
> >>> >>> > in
> >>> >>> ref
> >>> >>> > (which they are 29220 and 63933) than summing the column of
> >>> >>> > "map$rate"
> >>> >>> and
> >>> >>> > give the number of rows that >0.85. Then do the same for the
> >>> >>> > second,
> >>> >>> > third....in ref. At the end I would like a table gave below (the
> >>> >>> results I
> >>> >>> > need). Please notice the all value specified in ref data file are
> >>> >>> > exist
> >>> >>> in
> >>> >>> > map$reg column.
> >>> >>> >
> >>> >>> >
> >>> >>> >
> >>> >>> > Task2)
> >>> >>> >
> >>> >>> > Again example, the first and second columns for row 1 in data ref
> >>> >>> > are
> >>> >>> 29220
> >>> >>> > 63933. So I need write an R code give the minimum map$p for the
> >>> >>> > 29220
> >>> >>> > -63933 intervals in map file. Than
> >>> >>> >
> >>> >>> > do the same for the second, third....in ref.
> >>> >>> >
> >>> >>> >
> >>> >>> >
> >>> >>> >
> >>> >>> > #my attempt for the first question
> >>> >>> >
> >>> >>> > temp<-map[order(map$reg, map$p),]
> >>> >>> >
> >>> >>> > count<-1
> >>> >>> >
> >>> >>> > temp<-unique(temp$reg
> >>> >>> >
> >>> >>> > for(i in 1:length(ref) {
> >>> >>> >
> >>> >>> >   for(j in 1:length(ref)
> >>> >>> >
> >>> >>> >   {
> >>> >>> >
> >>> >>> > temp1<-if (temp[pos[i]==ref[ref$reg1,] &
> >>> >>> > (temp[pos[j]==ref[ref$reg2,]
> >>> >>> > & temp[cumsum(temp$rate)
> >>> >>> >>0.70,])
> >>> >>> >
> >>> >>> > count=count+1
> >>> >>> >
> >>> >>> >     }
> >>> >>> >
> >>> >>> > }
> >>> >>> >
> >>> >>> > #my attempt for the second question
> >>> >>> >
> >>> >>> >
> >>> >>> >
> >>> >>> > temp<-map[order(map$reg, map$p),]
> >>> >>> >
> >>> >>> > count<-1
> >>> >>> >
> >>> >>> > temp<-unique(temp$reg
> >>> >>> >
> >>> >>> > for(i in 1:length(ref) {
> >>> >>> >
> >>> >>> >   for(j in 1:length(ref)
> >>> >>> >
> >>> >>> >   {
> >>> >>> >
> >>> >>> > temp2<-if (temp[pos[i]==ref[ref$reg1,] &
> >>> >>> > (temp[pos[j]==ref[ref$reg2,])
> >>> >>> >
> >>> >>> > output<-temp2[temp2$p==min(temp2$p),]
> >>> >>> >
> >>> >>> >     }
> >>> >>> >
> >>> >>> > }
> >>> >>> >
> >>> >>> >
> >>> >>> >
> >>> >>> > Data sets
> >>> >>> >
> >>> >>> >
> >>> >>> >   Data= map
> >>> >>> >
> >>> >>> >   reg   p      rate
> >>> >>> >
> >>> >>> >  10276 0.700  3.867e-18
> >>> >>> >
> >>> >>> >  71608 0.830  4.542e-16
> >>> >>> >
> >>> >>> >  29220 0.430  1.948e-15
> >>> >>> >
> >>> >>> >  99542 0.220  1.084e-15
> >>> >>> >
> >>> >>> >  26441 0.880  9.675e-14
> >>> >>> >
> >>> >>> >  95082 0.090  7.349e-13
> >>> >>> >
> >>> >>> >  36169 0.480  9.715e-13
> >>> >>> >
> >>> >>> >  55572 0.500  9.071e-12
> >>> >>> >
> >>> >>> >  65255 0.300  1.688e-11
> >>> >>> >
> >>> >>> >  51960 0.970  1.163e-10
> >>> >>> >
> >>> >>> >  55652 0.388  3.750e-10
> >>> >>> >
> >>> >>> >  63933 0.250  9.128e-10
> >>> >>> >
> >>> >>> >  35170 0.720  7.355e-09
> >>> >>> >
> >>> >>> >  06491 0.370  1.634e-08
> >>> >>> >
> >>> >>> >  85508 0.470  1.057e-07
> >>> >>> >
> >>> >>> >  86666 0.580  7.862e-07
> >>> >>> >
> >>> >>> >  04758 0.810  9.501e-07
> >>> >>> >
> >>> >>> >  06169 0.440  1.104e-06
> >>> >>> >
> >>> >>> >  63933 0.750  2.624e-06
> >>> >>> >
> >>> >>> >  41838 0.960  8.119e-06
> >>> >>> >
> >>> >>> >
> >>> >>> >  data=ref
> >>> >>> >
> >>> >>> >   reg1         reg2
> >>> >>> >
> >>> >>> >   29220     63933
> >>> >>> >
> >>> >>> >   26441     41838
> >>> >>> >
> >>> >>> >   06169     10276
> >>> >>> >
> >>> >>> >   74806     92643
> >>> >>> >
> >>> >>> >   73732     82451
> >>> >>> >
> >>> >>> >   86042     93502
> >>> >>> >
> >>> >>> >   85508     95082
> >>> >>> >
> >>> >>> >
> >>> >>> >
> >>> >>> >        the results I need
> >>> >>> >
> >>> >>> >      reg1      reg2 n
> >>> >>> >
> >>> >>> >    29220   63933  12
> >>> >>> >
> >>> >>> >    26441   41838   78
> >>> >>> >
> >>> >>> >    06169 10276  125
> >>> >>> >
> >>> >>> >    74806 92643   11
> >>> >>> >
> >>> >>> >    73732 82451   47
> >>> >>> >
> >>> >>> >    86042 93502   98
> >>> >>> >
> >>> >>> >    85508 95082  219
> >>> >>> >
> >>> >>> >         [[alternative HTML version deleted]]
> >>> >>> >
> >>> >>> > ______________________________________________
> >>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> > PLEASE do read the posting guide
> >>> >>> http://www.R-project.org/posting-guide.html
> >>> >>> > and provide commented, minimal, self-contained, reproducible
> code.
> >>> >>>
> >>> >>
> >>> >>
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide
> >>> > http://www.R-project.org/posting-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
>

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Tue Jun 14 17:56:15 2016
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 14 Jun 2016 15:56:15 +0000
Subject: [R] Haplo.glm error: Failed to converge during EM-glm loop
Message-ID: <c8109802775e45d3abc06721b67799a2@ESGEBEX10.win.ad.jhu.edu>

It is a "warning" message, but not an "error" message.  Therefore, you should still get parameter estimates.  However, lack of convergence is often an important issue. Although in the case of the EM algorithm, it may not be so serious since EM is notoriously slow to converge when you set a small tolerance for convergence. You may fiddle with the control options for EM algorithm and see if you can get convergence.  If not, you should contact the package authors.

Hope this is helpful,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


	[[alternative HTML version deleted]]


From takiyeddine at gmail.com  Tue Jun 14 16:43:31 2016
From: takiyeddine at gmail.com (takiy berrandou)
Date: Tue, 14 Jun 2016 16:43:31 +0200
Subject: [R] is there a package in R or functions to calculate odds/hasard
 ratio from spline regression
Message-ID: <CAHtav99HoJp+t3_DBesN6z3ZEqf__qQ6F6cHz=PB85+SW8Mp8w@mail.gmail.com>

Hello,

I'm looking for a package or function, which calculate OR/HR from spline
model regression. for example in SAS it exist some MACRO helping to do that
easiely.

i had make some research on the forum here and on the web but without any
succes.

thanks for the answers.

Takiy




-- 
Takiy BERRANDOU
0618916037
takiyeddine at gmail.com

	[[alternative HTML version deleted]]


From jcpayne at uw.edu  Tue Jun 14 20:41:56 2016
From: jcpayne at uw.edu (J Payne)
Date: Tue, 14 Jun 2016 11:41:56 -0700
Subject: [R] Closing FTP sessions with RCurl
Message-ID: <24975B65-64BE-46D1-9208-A5905BBE67A6@uw.edu>

Does anyone know how to close an FTP session with RCurl?? I am trying to automate the process of downloading snow data from a government website, and their server is throttling the connection after a few files are downloaded.? I contacted their system administrator, who wrote: ?My suspicion at this point is that the getURL commands are opened and perform the function asked, then linger in wait for 15 minutes until or ftp server closes the idle sessions. Is there a way to tell R to close the sessions??

 

I?ve perused the RCurl manual but I don?t see a way to close sessions.? I tried copying the following example from the RCurl manual, but it didn?t solve the problem.? I?m a novice at this and I don?t understand the relationship between handles and sessions, so I am probably missing something.

 

#EXAMPLE from getCurl(), p. 39

if(url.exists("http://www.omegahat.net/RCurl/index.html")) {

 ??curl = getCurlHandle()

?? getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)

?? #getCurlInfo(curl) # I skipped this step

?? rm(curl) # release the curl! (does this end the session???)

}

 

Thanks!

 

John


	[[alternative HTML version deleted]]


From G.Maubach at gmx.de  Tue Jun 14 21:19:14 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Tue, 14 Jun 2016 21:19:14 +0200
Subject: [R] Installation of package "rio" broken
Message-ID: <trinity-75909f36-f95a-47be-9b2c-ace3c9d559b8-1465931954503@3capp-gmx-bs30>

Hi all,

today I wanted to install package "rio". As it depends on package "feather" which is only available as source I have chosen to install "rio" from source. The installations fails with the following messages:

-- cut --
* installing *source* package 'feather' ...
** Paket 'feather' erfolgreich entpackt und MD5 Summen ?berpr?ft
** libs

*** arch - i386
g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c RcppExports.cpp -o RcppExports.o
g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-read.cpp -o feather-read.o
g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-types.cpp -o feather-types.o
g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-write.cpp -o feather-write.o
g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/buffer.cc -o feather/buffer.o
g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/feather-c.cc -o feather/feather-c.o
g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/io.cc -o feather/io.o
feather/io.cc:18:0: warning: "NOMINMAX" redefined [enabled by default]
c:\program files\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c++/4.6.3/i686-w64-mingw32/bits/os_defines.h:46:0: note: this is the location of the previous definition
g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/metadata.cc -o feather/metadata.o
feather/metadata.cc:29:7: error: expected nested-name-specifier before 'FBString'
feather/metadata.cc:29:7: error: 'FBString' has not been declared
feather/metadata.cc:29:16: error: expected ';' before '=' token
feather/metadata.cc:29:16: error: expected unqualified-id before '=' token
feather/metadata.cc:32:7: error: expected nested-name-specifier before 'ColumnVector'
feather/metadata.cc:32:7: error: 'ColumnVector' has not been declared
feather/metadata.cc:32:20: error: expected ';' before '=' token
feather/metadata.cc:32:20: error: expected unqualified-id before '=' token
feather/metadata.cc:178:3: error: 'ColumnVector' does not name a type
feather/metadata.cc: In member function 'feather::Status feather::metadata::TableBuilder::Impl::Finish()':
feather/metadata.cc:146:5: error: 'FBString' was not declared in this scope
feather/metadata.cc:146:14: error: expected ';' before 'desc'
feather/metadata.cc:148:7: error: 'desc' was not declared in this scope
feather/metadata.cc:154:9: error: 'desc' was not declared in this scope
feather/metadata.cc:156:27: error: 'columns_' was not declared in this scope
feather/metadata.cc:157:34: error: unable to deduce 'auto' from '<expression error>'
feather/metadata.cc: In member function 'void feather::metadata::TableBuilder::Impl::add_column(const flatbuffers::Offset<feather::fbs::Column>&)':
feather/metadata.cc:173:5: error: 'columns_' was not declared in this scope
feather/metadata.cc: In constructor 'feather::metadata::TableBuilder::TableBuilder()':
feather/metadata.cc:190:5: error: type 'feather::metadata::TableBuilder' is not a direct base of 'feather::metadata::TableBuilder'
make: *** [feather/metadata.o] Error 1
Warnung: Ausf?hrung von Kommando 'make -f "Makevars" -f "C:/PROGRA~1/R/R-32~1.2/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-32~1.2/share/make/winshlib.mk" CXX='$(CXX1X) $(CXX1XSTD)' CXXFLAGS='$(CXX1XFLAGS)' CXXPICFLAGS='$(CXX1XPICFLAGS)' SHLIB_LDFLAGS='$(SHLIB_CXX1XLDFLAGS)' SHLIB_LD='$(SHLIB_CXX1XLD)' SHLIB="feather.dll" OBJECTS="RcppExports.o feather-read.o feather-types.o feather-write.o"' ergab Status 2
ERROR: compilation failed for package 'feather'
* removing 'C:/Users/admin/Documents/R/win-library/3.2/feather'
Warning in install.packages :
  running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\admin\Documents\R\win-library\3.2" C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz/downloaded_packages/feather_0.0.1.tar.gz' had status 1
Warning in install.packages :
  installation of package ?feather? had non-zero exit status
ERROR: dependency 'feather' is not available for package 'rio'
* removing 'C:/Users/admin/Documents/R/win-library/3.2/rio'
Warning in install.packages :
  running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\admin\Documents\R\win-library\3.2" C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz/downloaded_packages/rio_0.4.6.tar.gz' had status 1
Warning in install.packages :
  installation of package ?rio? had non-zero exit status

The downloaded source packages are in
	?C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz\downloaded_packages?
-- cut --

How can I fix that?

Kind regards

Georg Maubach


From wdunlap at tibco.com  Tue Jun 14 21:33:21 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 14 Jun 2016 12:33:21 -0700
Subject: [R] Installation of package "rio" broken
In-Reply-To: <trinity-75909f36-f95a-47be-9b2c-ace3c9d559b8-1465931954503@3capp-gmx-bs30>
References: <trinity-75909f36-f95a-47be-9b2c-ace3c9d559b8-1465931954503@3capp-gmx-bs30>
Message-ID: <CAF8bMcazEimEZ89sQMzs_GePaXnanNk7nJgCCNF29nBP86abnQ@mail.gmail.com>

Your log showed that g++ was given the flag -std=c++0x.  It should be
-std=c++11 so the 'using typename = blahblah' syntax works.  Either
your feather/src/Makevars is missing the line CXX_STD=CXX11 or your
version of R is lacking support for CXX_STD.


> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
 -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
-I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
-mtune=core2 -c feather/metadata.cc -o feather/metadata.o
> feather/metadata.cc:29:7: error: expected nested-name-specifier before
'FBString'

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jun 14, 2016 at 12:19 PM, <G.Maubach at gmx.de> wrote:

> Hi all,
>
> today I wanted to install package "rio". As it depends on package
> "feather" which is only available as source I have chosen to install "rio"
> from source. The installations fails with the following messages:
>
> -- cut --
> * installing *source* package 'feather' ...
> ** Paket 'feather' erfolgreich entpackt und MD5 Summen ?berpr?ft
> ** libs
>
> *** arch - i386
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
>  -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
> -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
> -mtune=core2 -c RcppExports.cpp -o RcppExports.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
>  -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
> -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
> -mtune=core2 -c feather-read.cpp -o feather-read.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
>  -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
> -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
> -mtune=core2 -c feather-types.cpp -o feather-types.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
>  -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
> -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
> -mtune=core2 -c feather-write.cpp -o feather-write.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
>  -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
> -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
> -mtune=core2 -c feather/buffer.cc -o feather/buffer.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
>  -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
> -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
> -mtune=core2 -c feather/feather-c.cc -o feather/feather-c.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
>  -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
> -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
> -mtune=core2 -c feather/io.cc -o feather/io.o
> feather/io.cc:18:0: warning: "NOMINMAX" redefined [enabled by default]
> c:\program
> files\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c++/4.6.3/i686-w64-mingw32/bits/os_defines.h:46:0:
> note: this is the location of the previous definition
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.
>  -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include"
> -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall
> -mtune=core2 -c feather/metadata.cc -o feather/metadata.o
> feather/metadata.cc:29:7: error: expected nested-name-specifier before
> 'FBString'
> feather/metadata.cc:29:7: error: 'FBString' has not been declared
> feather/metadata.cc:29:16: error: expected ';' before '=' token
> feather/metadata.cc:29:16: error: expected unqualified-id before '=' token
> feather/metadata.cc:32:7: error: expected nested-name-specifier before
> 'ColumnVector'
> feather/metadata.cc:32:7: error: 'ColumnVector' has not been declared
> feather/metadata.cc:32:20: error: expected ';' before '=' token
> feather/metadata.cc:32:20: error: expected unqualified-id before '=' token
> feather/metadata.cc:178:3: error: 'ColumnVector' does not name a type
> feather/metadata.cc: In member function 'feather::Status
> feather::metadata::TableBuilder::Impl::Finish()':
> feather/metadata.cc:146:5: error: 'FBString' was not declared in this scope
> feather/metadata.cc:146:14: error: expected ';' before 'desc'
> feather/metadata.cc:148:7: error: 'desc' was not declared in this scope
> feather/metadata.cc:154:9: error: 'desc' was not declared in this scope
> feather/metadata.cc:156:27: error: 'columns_' was not declared in this
> scope
> feather/metadata.cc:157:34: error: unable to deduce 'auto' from
> '<expression error>'
> feather/metadata.cc: In member function 'void
> feather::metadata::TableBuilder::Impl::add_column(const
> flatbuffers::Offset<feather::fbs::Column>&)':
> feather/metadata.cc:173:5: error: 'columns_' was not declared in this scope
> feather/metadata.cc: In constructor
> 'feather::metadata::TableBuilder::TableBuilder()':
> feather/metadata.cc:190:5: error: type 'feather::metadata::TableBuilder'
> is not a direct base of 'feather::metadata::TableBuilder'
> make: *** [feather/metadata.o] Error 1
> Warnung: Ausf?hrung von Kommando 'make -f "Makevars" -f
> "C:/PROGRA~1/R/R-32~1.2/etc/i386/Makeconf" -f
> "C:/PROGRA~1/R/R-32~1.2/share/make/winshlib.mk" CXX='$(CXX1X)
> $(CXX1XSTD)' CXXFLAGS='$(CXX1XFLAGS)' CXXPICFLAGS='$(CXX1XPICFLAGS)'
> SHLIB_LDFLAGS='$(SHLIB_CXX1XLDFLAGS)' SHLIB_LD='$(SHLIB_CXX1XLD)'
> SHLIB="feather.dll" OBJECTS="RcppExports.o feather-read.o feather-types.o
> feather-write.o"' ergab Status 2
> ERROR: compilation failed for package 'feather'
> * removing 'C:/Users/admin/Documents/R/win-library/3.2/feather'
> Warning in install.packages :
>   running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l
> "C:\Users\admin\Documents\R\win-library\3.2"
> C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz/downloaded_packages/feather_0.0.1.tar.gz'
> had status 1
> Warning in install.packages :
>   installation of package ?feather? had non-zero exit status
> ERROR: dependency 'feather' is not available for package 'rio'
> * removing 'C:/Users/admin/Documents/R/win-library/3.2/rio'
> Warning in install.packages :
>   running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l
> "C:\Users\admin\Documents\R\win-library\3.2"
> C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz/downloaded_packages/rio_0.4.6.tar.gz'
> had status 1
> Warning in install.packages :
>   installation of package ?rio? had non-zero exit status
>
> The downloaded source packages are in
>         ?C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz\downloaded_packages?
> -- cut --
>
> How can I fix that?
>
> Kind regards
>
> Georg Maubach
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From tom at maladmin.com  Tue Jun 14 22:00:51 2016
From: tom at maladmin.com (Tom Wright)
Date: Tue, 14 Jun 2016 16:00:51 -0400
Subject: [R] Closing FTP sessions with RCurl
In-Reply-To: <24975B65-64BE-46D1-9208-A5905BBE67A6@uw.edu>
References: <24975B65-64BE-46D1-9208-A5905BBE67A6@uw.edu>
Message-ID: <CAKmUXV8a6qFJgk74ASmu6M1naMcBDN6+O4-108cHRoMhuAbYvg@mail.gmail.com>

No expert here, and this isn't tested. It seems you can set the
forbid.reuse option which will cause curl to shutdown the connection
after transfer is complete.

if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
   curl <- getCurlHandle()
   curlSetOpt(.opts=list(forbid.reuse=1),curl=curl)
   getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
}

On Tue, Jun 14, 2016 at 2:41 PM, J Payne <jcpayne at uw.edu> wrote:
> Does anyone know how to close an FTP session with RCurl?  I am trying to automate the process of downloading snow data from a government website, and their server is throttling the connection after a few files are downloaded.  I contacted their system administrator, who wrote: ?My suspicion at this point is that the getURL commands are opened and perform the function asked, then linger in wait for 15 minutes until or ftp server closes the idle sessions. Is there a way to tell R to close the sessions??
>
>
>
> I?ve perused the RCurl manual but I don?t see a way to close sessions.  I tried copying the following example from the RCurl manual, but it didn?t solve the problem.  I?m a novice at this and I don?t understand the relationship between handles and sessions, so I am probably missing something.
>
>
>
> #EXAMPLE from getCurl(), p. 39
>
> if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
>
>    curl = getCurlHandle()
>
>    getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
>
>    #getCurlInfo(curl) # I skipped this step
>
>    rm(curl) # release the curl! (does this end the session???)
>
> }
>
>
>
> Thanks!
>
>
>
> John
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Tue Jun 14 22:01:27 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 14 Jun 2016 16:01:27 -0400
Subject: [R] Installation of package "rio" broken
In-Reply-To: <trinity-75909f36-f95a-47be-9b2c-ace3c9d559b8-1465931954503@3capp-gmx-bs30>
References: <trinity-75909f36-f95a-47be-9b2c-ace3c9d559b8-1465931954503@3capp-gmx-bs30>
Message-ID: <CA+vqiLFiv3uWxvsTPHa_sXWLecGbJ0ngYA6Bqxb8su3F6wNYOQ@mail.gmail.com>

On Tue, Jun 14, 2016 at 3:19 PM,  <G.Maubach at gmx.de> wrote:
> Hi all,
>
> today I wanted to install package "rio". As it depends on package "feather" which is only available as source I have chosen to install "rio" from source. The installations fails with the following messages:

"feather" is available as in pre-compiled form for windows versions of
R >= 3.3.0. Your simplest course of action is probably to update to
the latest released version of R and install the pre-compiled
packages.

Best,
Ista

>
> -- cut --
> * installing *source* package 'feather' ...
> ** Paket 'feather' erfolgreich entpackt und MD5 Summen ?berpr?ft
> ** libs
>
> *** arch - i386
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c RcppExports.cpp -o RcppExports.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-read.cpp -o feather-read.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-types.cpp -o feather-types.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-write.cpp -o feather-write.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/buffer.cc -o feather/buffer.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/feather-c.cc -o feather/feather-c.o
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/io.cc -o feather/io.o
> feather/io.cc:18:0: warning: "NOMINMAX" redefined [enabled by default]
> c:\program files\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c++/4.6.3/i686-w64-mingw32/bits/os_defines.h:46:0: note: this is the location of the previous definition
> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/metadata.cc -o feather/metadata.o
> feather/metadata.cc:29:7: error: expected nested-name-specifier before 'FBString'
> feather/metadata.cc:29:7: error: 'FBString' has not been declared
> feather/metadata.cc:29:16: error: expected ';' before '=' token
> feather/metadata.cc:29:16: error: expected unqualified-id before '=' token
> feather/metadata.cc:32:7: error: expected nested-name-specifier before 'ColumnVector'
> feather/metadata.cc:32:7: error: 'ColumnVector' has not been declared
> feather/metadata.cc:32:20: error: expected ';' before '=' token
> feather/metadata.cc:32:20: error: expected unqualified-id before '=' token
> feather/metadata.cc:178:3: error: 'ColumnVector' does not name a type
> feather/metadata.cc: In member function 'feather::Status feather::metadata::TableBuilder::Impl::Finish()':
> feather/metadata.cc:146:5: error: 'FBString' was not declared in this scope
> feather/metadata.cc:146:14: error: expected ';' before 'desc'
> feather/metadata.cc:148:7: error: 'desc' was not declared in this scope
> feather/metadata.cc:154:9: error: 'desc' was not declared in this scope
> feather/metadata.cc:156:27: error: 'columns_' was not declared in this scope
> feather/metadata.cc:157:34: error: unable to deduce 'auto' from '<expression error>'
> feather/metadata.cc: In member function 'void feather::metadata::TableBuilder::Impl::add_column(const flatbuffers::Offset<feather::fbs::Column>&)':
> feather/metadata.cc:173:5: error: 'columns_' was not declared in this scope
> feather/metadata.cc: In constructor 'feather::metadata::TableBuilder::TableBuilder()':
> feather/metadata.cc:190:5: error: type 'feather::metadata::TableBuilder' is not a direct base of 'feather::metadata::TableBuilder'
> make: *** [feather/metadata.o] Error 1
> Warnung: Ausf?hrung von Kommando 'make -f "Makevars" -f "C:/PROGRA~1/R/R-32~1.2/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-32~1.2/share/make/winshlib.mk" CXX='$(CXX1X) $(CXX1XSTD)' CXXFLAGS='$(CXX1XFLAGS)' CXXPICFLAGS='$(CXX1XPICFLAGS)' SHLIB_LDFLAGS='$(SHLIB_CXX1XLDFLAGS)' SHLIB_LD='$(SHLIB_CXX1XLD)' SHLIB="feather.dll" OBJECTS="RcppExports.o feather-read.o feather-types.o feather-write.o"' ergab Status 2
> ERROR: compilation failed for package 'feather'
> * removing 'C:/Users/admin/Documents/R/win-library/3.2/feather'
> Warning in install.packages :
>   running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\admin\Documents\R\win-library\3.2" C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz/downloaded_packages/feather_0.0.1.tar.gz' had status 1
> Warning in install.packages :
>   installation of package ?feather? had non-zero exit status
> ERROR: dependency 'feather' is not available for package 'rio'
> * removing 'C:/Users/admin/Documents/R/win-library/3.2/rio'
> Warning in install.packages :
>   running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\admin\Documents\R\win-library\3.2" C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz/downloaded_packages/rio_0.4.6.tar.gz' had status 1
> Warning in install.packages :
>   installation of package ?rio? had non-zero exit status
>
> The downloaded source packages are in
>         ?C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz\downloaded_packages?
> -- cut --
>
> How can I fix that?
>
> Kind regards
>
> Georg Maubach
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ikycho at gmail.com  Tue Jun 14 20:06:18 2016
From: ikycho at gmail.com (JI Cho)
Date: Tue, 14 Jun 2016 14:06:18 -0400
Subject: [R] strange error message when using rnorm and rbinom
Message-ID: <CAHtUt2fV7aYo4Wt-yQCOJ0useQ1_KUvPtVf3cOz6Gf4R=VC8Ag@mail.gmail.com>

Dear R users,

I have been using rnorm, rbinom and have been getting the following warning
message when I do not have any NAs in my generated values.

Warning messages:1: In rnorm(nref, mean = mu.m2[[k]], sd = sqrt(disp.m2[[k]])) :
  NAs produced


In one of the resources I found in over the internet explains that the
mean and sd should be declared as integers. So I tried that which did
not solve the issue.


Can anyone advise me on how to eliminate the warning message?


Thank you.

	[[alternative HTML version deleted]]


From tom at maladmin.com  Tue Jun 14 22:12:22 2016
From: tom at maladmin.com (Tom Wright)
Date: Tue, 14 Jun 2016 16:12:22 -0400
Subject: [R] strange error message when using rnorm and rbinom
In-Reply-To: <CAHtUt2fV7aYo4Wt-yQCOJ0useQ1_KUvPtVf3cOz6Gf4R=VC8Ag@mail.gmail.com>
References: <CAHtUt2fV7aYo4Wt-yQCOJ0useQ1_KUvPtVf3cOz6Gf4R=VC8Ag@mail.gmail.com>
Message-ID: <CAKmUXV_+m4WAJXQNC43AP0=3hQtFGU1AuHfgq-fCNaWxzQAiBA@mail.gmail.com>

As you probably already guessed we are going to need to see the
contents of nref, mu.m2 and disp.m2 to help.
dput(nref)
dput(mu.m2)
dput(disp.m2)

k might help too.

On Tue, Jun 14, 2016 at 2:06 PM, JI Cho <ikycho at gmail.com> wrote:
> Dear R users,
>
> I have been using rnorm, rbinom and have been getting the following warning
> message when I do not have any NAs in my generated values.
>
> Warning messages:1: In rnorm(nref, mean = mu.m2[[k]], sd = sqrt(disp.m2[[k]])) :
>   NAs produced
>
>
> In one of the resources I found in over the internet explains that the
> mean and sd should be declared as integers. So I tried that which did
> not solve the issue.
>
>
> Can anyone advise me on how to eliminate the warning message?
>
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Jun 14 23:31:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Jun 2016 14:31:53 -0700
Subject: [R] strange error message when using rnorm and rbinom
In-Reply-To: <CAHtUt2fV7aYo4Wt-yQCOJ0useQ1_KUvPtVf3cOz6Gf4R=VC8Ag@mail.gmail.com>
References: <CAHtUt2fV7aYo4Wt-yQCOJ0useQ1_KUvPtVf3cOz6Gf4R=VC8Ag@mail.gmail.com>
Message-ID: <CAGxFJbQnX9u0R1YWB9fH0h=GW8oGT6BerB9tjqa4z6S6GWoU2g@mail.gmail.com>

Do not believe everything you read on the internet!

"In one of the resources I found in over the internet explains that the
mean and sd should be declared as integers."

That is compete crap.  The mean of a norma/Gaussian can be any real;
the sd can be any positive real.
Moreover, one does not need to "declare" R variables. Have you gone
through any R tutorials? -- there are many good ones on the web.
Please do so if you haven't before posting here.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 14, 2016 at 11:06 AM, JI Cho <ikycho at gmail.com> wrote:
> Dear R users,
>
> I have been using rnorm, rbinom and have been getting the following warning
> message when I do not have any NAs in my generated values.
>
> Warning messages:1: In rnorm(nref, mean = mu.m2[[k]], sd = sqrt(disp.m2[[k]])) :
>   NAs produced
>
>
> In one of the resources I found in over the internet explains that the
> mean and sd should be declared as integers. So I tried that which did
> not solve the issue.
>
>
> Can anyone advise me on how to eliminate the warning message?
>
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Wed Jun 15 00:00:00 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 14 Jun 2016 23:00:00 +0100
Subject: [R] Installation of package "rio" broken
In-Reply-To: <CA+vqiLFiv3uWxvsTPHa_sXWLecGbJ0ngYA6Bqxb8su3F6wNYOQ@mail.gmail.com>
References: <trinity-75909f36-f95a-47be-9b2c-ace3c9d559b8-1465931954503@3capp-gmx-bs30>
	<CA+vqiLFiv3uWxvsTPHa_sXWLecGbJ0ngYA6Bqxb8su3F6wNYOQ@mail.gmail.com>
Message-ID: <f3fb7ad6-9362-46b5-6ab4-1ad9205f6279@statistik.tu-dortmund.de>



On 14.06.2016 21:01, Ista Zahn wrote:
> On Tue, Jun 14, 2016 at 3:19 PM,  <G.Maubach at gmx.de> wrote:
>> Hi all,
>>
>> today I wanted to install package "rio". As it depends on package "feather" which is only available as source I have chosen to install "rio" from source. The installations fails with the following messages:
>
> "feather" is available as in pre-compiled form for windows versions of
> R >= 3.3.0. Your simplest course of action is probably to update to
> the latest released version of R and install the pre-compiled
> packages.
>


Indeed, you need at least R-3.0.0 as this is compiled with gcc-4.9.3 
that supports the new standard.

Best,
Uwe Ligges


> Best,
> Ista
>
>>
>> -- cut --
>> * installing *source* package 'feather' ...
>> ** Paket 'feather' erfolgreich entpackt und MD5 Summen ?berpr?ft
>> ** libs
>>
>> *** arch - i386
>> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c RcppExports.cpp -o RcppExports.o
>> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-read.cpp -o feather-read.o
>> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-types.cpp -o feather-types.o
>> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather-write.cpp -o feather-write.o
>> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/buffer.cc -o feather/buffer.o
>> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/feather-c.cc -o feather/feather-c.o
>> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/io.cc -o feather/io.o
>> feather/io.cc:18:0: warning: "NOMINMAX" redefined [enabled by default]
>> c:\program files\rtools\gcc-4.6.3\bin\../lib/gcc/i686-w64-mingw32/4.6.3/../../../../include/c++/4.6.3/i686-w64-mingw32/bits/os_defines.h:46:0: note: this is the location of the previous definition
>> g++ -m32 -std=c++0x -I"C:/PROGRA~1/R/R-32~1.2/include" -DNDEBUG -I.   -I"C:/Users/admin/Documents/R/win-library/3.2/Rcpp/include" -I"d:/RCompile/r-compiling/local/local320/include"     -O2 -Wall  -mtune=core2 -c feather/metadata.cc -o feather/metadata.o
>> feather/metadata.cc:29:7: error: expected nested-name-specifier before 'FBString'
>> feather/metadata.cc:29:7: error: 'FBString' has not been declared
>> feather/metadata.cc:29:16: error: expected ';' before '=' token
>> feather/metadata.cc:29:16: error: expected unqualified-id before '=' token
>> feather/metadata.cc:32:7: error: expected nested-name-specifier before 'ColumnVector'
>> feather/metadata.cc:32:7: error: 'ColumnVector' has not been declared
>> feather/metadata.cc:32:20: error: expected ';' before '=' token
>> feather/metadata.cc:32:20: error: expected unqualified-id before '=' token
>> feather/metadata.cc:178:3: error: 'ColumnVector' does not name a type
>> feather/metadata.cc: In member function 'feather::Status feather::metadata::TableBuilder::Impl::Finish()':
>> feather/metadata.cc:146:5: error: 'FBString' was not declared in this scope
>> feather/metadata.cc:146:14: error: expected ';' before 'desc'
>> feather/metadata.cc:148:7: error: 'desc' was not declared in this scope
>> feather/metadata.cc:154:9: error: 'desc' was not declared in this scope
>> feather/metadata.cc:156:27: error: 'columns_' was not declared in this scope
>> feather/metadata.cc:157:34: error: unable to deduce 'auto' from '<expression error>'
>> feather/metadata.cc: In member function 'void feather::metadata::TableBuilder::Impl::add_column(const flatbuffers::Offset<feather::fbs::Column>&)':
>> feather/metadata.cc:173:5: error: 'columns_' was not declared in this scope
>> feather/metadata.cc: In constructor 'feather::metadata::TableBuilder::TableBuilder()':
>> feather/metadata.cc:190:5: error: type 'feather::metadata::TableBuilder' is not a direct base of 'feather::metadata::TableBuilder'
>> make: *** [feather/metadata.o] Error 1
>> Warnung: Ausf?hrung von Kommando 'make -f "Makevars" -f "C:/PROGRA~1/R/R-32~1.2/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-32~1.2/share/make/winshlib.mk" CXX='$(CXX1X) $(CXX1XSTD)' CXXFLAGS='$(CXX1XFLAGS)' CXXPICFLAGS='$(CXX1XPICFLAGS)' SHLIB_LDFLAGS='$(SHLIB_CXX1XLDFLAGS)' SHLIB_LD='$(SHLIB_CXX1XLD)' SHLIB="feather.dll" OBJECTS="RcppExports.o feather-read.o feather-types.o feather-write.o"' ergab Status 2
>> ERROR: compilation failed for package 'feather'
>> * removing 'C:/Users/admin/Documents/R/win-library/3.2/feather'
>> Warning in install.packages :
>>   running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\admin\Documents\R\win-library\3.2" C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz/downloaded_packages/feather_0.0.1.tar.gz' had status 1
>> Warning in install.packages :
>>   installation of package ?feather? had non-zero exit status
>> ERROR: dependency 'feather' is not available for package 'rio'
>> * removing 'C:/Users/admin/Documents/R/win-library/3.2/rio'
>> Warning in install.packages :
>>   running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\admin\Documents\R\win-library\3.2" C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz/downloaded_packages/rio_0.4.6.tar.gz' had status 1
>> Warning in install.packages :
>>   installation of package ?rio? had non-zero exit status
>>
>> The downloaded source packages are in
>>         ?C:\Users\admin\AppData\Local\Temp\RtmpwNaGYz\downloaded_packages?
>> -- cut --
>>
>> How can I fix that?
>>
>> Kind regards
>>
>> Georg Maubach
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Wed Jun 15 01:30:25 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Jun 2016 09:30:25 +1000
Subject: [R] strange error message when using rnorm and rbinom
In-Reply-To: <CAHtUt2fV7aYo4Wt-yQCOJ0useQ1_KUvPtVf3cOz6Gf4R=VC8Ag@mail.gmail.com>
References: <CAHtUt2fV7aYo4Wt-yQCOJ0useQ1_KUvPtVf3cOz6Gf4R=VC8Ag@mail.gmail.com>
Message-ID: <CA+8X3fVwnaDH0DuDQBxQgLAL2YNvifWWGNcPrp9s0iXbDZWmUA@mail.gmail.com>

Hi JI,
The most likely problems are negative numbers for sd or "k" being
larger than the number of mu.m2 or disp.m2 values.

Jim

On Wed, Jun 15, 2016 at 4:06 AM, JI Cho <ikycho at gmail.com> wrote:
> Dear R users,
>
> I have been using rnorm, rbinom and have been getting the following warning
> message when I do not have any NAs in my generated values.
>
> Warning messages:1: In rnorm(nref, mean = mu.m2[[k]], sd = sqrt(disp.m2[[k]])) :
>   NAs produced
>
>
> In one of the resources I found in over the internet explains that the
> mean and sd should be declared as integers. So I tried that which did
> not solve the issue.
>
>
> Can anyone advise me on how to eliminate the warning message?
>
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jun 15 01:41:54 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Jun 2016 09:41:54 +1000
Subject: [R] processing time too long
In-Reply-To: <1465462637.S.9694.30605.f5-224-101.1465908090.16974@webmail.rediffmail.com>
References: <CA+8X3fU1uGz6V6Qb-tJZWBED2oFxF5e6rXdYxSNK6s350K0GGA@mail.gmail.com>
	<1465462637.S.9694.30605.f5-224-101.1465908090.16974@webmail.rediffmail.com>
Message-ID: <CA+8X3fVO1kD54PZrByaRG0tz1mD4Kk1RP5MrgbUBkf1JBU1rvw@mail.gmail.com>

Hi Sashi,
Since I do not want to create a large fake data set and then
painstakingly test and debug your code, why not try your code with a
subset of the data, maybe only 400 rows. If that runs slowly, your
code is very inefficient (it looks as though it is). You can then
begin to identify where the efficiency of the code can be improved.

Jim


On Tue, Jun 14, 2016 at 10:41 PM, SHASHI SETH <sethshashi at rediffmail.com> wrote:
> Dear Jim,
>
> Thanks for ur suggesion. Earlier problem is solved with ur advise. My code
> is taking too long to
> execute, more than 30 hours. there are 40309 rows and 26952 columns. file
> size is 110 MB.Please guide
> me what is wrong.
>
> Shashi
> On Thu, 09 Jun 2016 14:27:17 +0530 Jim Lemon wrote
>>Hi Shashi,
>
> Without trying to go through all that code, your error is something
>
> simple. When you read in "matrixdata" right in the beginning, you are
>
> getting a data frame, not a vector or a matrix (which in some cases
>
> can be treated like a vector). That will cause trouble at some point.
>
> Another thing is that when you call this:
>
>
>
> if((sum > 0 && sums1 > 0 && sums2 > 0) != NA)
>
>
>
> you seem to be asking for the union of three multi-valued vectors (?)
>
> which will probably cause at least a warning, but the error suggests
>
> that at least one of these objects has an NA value somewhere. This
>
> might be because "dtm_500_1.CSV" (whatever that is) has NA values in
>
> it. The code is fairly obscure and I can only say that your best bet
>
> is probably to check the initial data frame for NA values and then
>
> print out the results of each step, or least
>
>
>
> cat(sum(is.na(x)),"\n")
>
>
>
> where x is the object you have just created. That should allow you to
>
> find where in the tangle of code the NAs are appearing.
>
>
>
> Jim
>
>
>
>
>
>
>
> On Thu, Jun 9, 2016 at 4:49 PM, SHASHI SETH wrote:
>
>> Hi Jim,
>
>>
>
>> I am getting the following error:
>
>> Error in if ((sum > 0 && sums1 > 0 && sums2 > 0) != NA) { :
>
>> missing value where TRUE/FALSE needed
>
>>
>
>>
>
>> I have including my code below for your review:
>
>>
>
>> fitness_1_data <- c();
>
>>
>
>> src="dtm_500_1.CSV"
>
>> matrixdata <- read.csv(src)
>
>>
>
>> #get no vector/column from file/matrix
>
>> noofvec <- length(matrixdata)
>
>>
>
>> #set no of records/rows/document
>
>> noofrecords <- length(matrixdata[,1])
>
>>
>
>> #set row index
>
>> rindex<-1;
>
>>
>
>> #preapare header
>
>> colindex<-1;
>
>> colList <- colnames(matrixdata)
>
>>
>
>> combine<-"";
>
>>
>
>> vec_fitness_data<- c();
>
>>
>
>> while(colindex <= length(colList))
>
>> {
>
>> fitness_1_data <- append(fitness_1_data,colList[colindex])
>
>>
>
>> colindex<- colindex+1
>
>> }
>
>>
>
>> #add two additional vector for percentage and cluster
>
>> fitness_1_data <- append(fitness_1_data,"percentage")
>
>> fitness_1_data <- append(fitness_1_data,"Cluster")
>
>>
>
>> write.table(as.list(fitness_1_data), file ="Result_500_cycle1.csv",append
>> =
>
>> TRUE,
>
>> row.names=FALSE, col.names=FALSE, sep=",")
>
>>
>
>> #end header record
>
>>
>
>> nestedloopindex <- 2
>
>>
>
>>
>
>> while( nestedloopindex <= noofrecords )
>
>> {
>
>>
>
>> #init of temperory variables
>
>> sums1 <- 0;
>
>> sums2 <- 0;
>
>> sum <- 0;
>
>>
>
>> #set initial index of column 2 ,coloumn one hold document no not
>
>> actual data
>
>> colindex <- 2;
>
>>
>
>> # combine <-"";
>
>>
>
>> vec1 <- c();
>
>> vec2 <- c();
>
>>
>
>> #add document number in vector
>
>> vec1 <- append(vec1,matrixdata[rindex,1]);
>
>> vec2 <- append(vec2,matrixdata[nestedloopindex,1]);
>
>>
>
>> #declaration of temp -out variable for calculation
>
>> #out <- 0;
>
>>
>
>>
>
>> while(colindex <= noofvec )
>
>> {
>
>>
>
>>
>
>> vec1 <- append(vec1,matrixdata[rindex,colindex]);
>
>> vec2 <- append(vec2,matrixdata[nestedloopindex,colindex]);
>
>>
>
>> sum = sum +
>
>> matrixdata[rindex,colindex]*matrixdata[nestedloopindex,colindex]
>
>>
>
>> sums1 <- sums1 + matrixdata[rindex,colindex]^2;
>
>>
>
>> sums2 <- sums2 + matrixdata[nestedloopindex,colindex]^2;
>
>>
>
>> colindex <- colindex+1
>
>> }
>
>>
>
>> if((sum > 0 && sums1 > 0 && sums2 > 0) != NA)
>
>> {
>
>>
>
>> out <- sum / ((sqrt(sums1) * sqrt(sums2)))
>
>> }else
>
>> {
>
>> out <-0
>
>> }
>
>>
>
>> vec1 <- append(vec1,out);
>
>> vec1 <-append(vec1, "1")
>
>> vec2 <- append(vec2, out);
>
>>
>
>>
>
>>
>
>> if(nestedloopindex==2)
>
>> {
>
>> write.table(as.list(vec1), file ="Result_500_cycle1.csv",append =
>
>> TRUE, row.names=FALSE, col.names=FALSE, sep=",")
>
>> write.table(as.list(vec2), file ="Result_500_cycle1.csv",append =
>
>> TRUE, row.names=FALSE, col.names=FALSE, sep=",")
>
>> nestedloopindex<- nestedloopindex+1
>
>> } else
>
>> {
>
>> write.table(as.list(vec2), file ="Result_500_cycle1.csv",append =
>
>> TRUE, row.names=FALSE, col.names=FALSE, sep=",")
>
>> nestedloopindex<- nestedloopindex+1
>
>> }
>
>>
>
>> }
>
>>
>
>>
>
>> With Best Regards,
>
>> Shashi
>
>>
>
>> On Thu, 09 Jun 2016 04:45:09 +0530 Jim Lemon wrote
>
>>>Hi John,
>
>>
>
>> With due respect to the other respondents, here is something that might
>
>> help:
>
>>
>
>>
>
>>
>
>> # get a vector of values
>
>>
>
>> foo<-rnorm(100)
>
>>
>
>> # get a vector of increasing indices (aka your "recent" values)
>
>>
>
>> bar<-sort(sample(1:100,40))
>
>>
>
>> # write a function to "clump" the adjacent index values
>
>>
>
>> clump_adj_int<-function(x) {
>
>>
>
>> index_list<-list(x[1])
>
>>
>
>> list_index<-1
>
>>
>
>> for(i in 2:length(x)) {
>
>>
>
>> if(x[i]==x[i-1]+1)
>
>>
>
>> index_list[[list_index]]<-c(index_list[[list_index]],x[i])
>
>>
>
>> else {
>
>>
>
>> list_index<-list_index+1
>
>>
>
>> index_list[[list_index]]<-x[i]
>
>>
>
>> }
>
>>
>
>> }
>
>>
>
>> return(index_list)
>
>>
>
>> }
>
>>
>
>> index_clumps<-clump_adj_int(bar)
>
>>
>
>> # write another function to sum the values
>
>>
>
>> sum_subsets<-function(indices,vector)
>
>> return(sum(vector[indices],na.rm=TRUE))
>
>>
>
>> # now "apply" the function to the list of indices
>
>>
>
>> lapply(index_clumps,sum_subsets,foo)
>
>>
>
>>
>
>>
>
>> Jim
>
>>
>
>>
>
>>
>
>>
>
>>
>
>> On Thu, Jun 9, 2016 at 2:41 AM, John Logsdon
>
>>
>
>> wrote:
>
>>
>
>>> Folks
>
>>
>
>>>
>
>>
>
>>> Is there any way to get the row index into apply as a variable?
>
>>
>
>>>
>
>>
>
>>> I want a function to do some sums on a small subset of some very long
>
>>
>
>>> vectors, rolling through the whole vectors.
>
>>
>
>>>
>
>>
>
>>> apply(X,1,function {do something}, other arguments)
>
>>
>
>>>
>
>>
>
>>> seems to be the way to do it.
>
>>
>
>>>
>
>>
>
>>> The subset I want is the most recent set of measurements only - perhaps a
>
>>
>
>>> couple of hundred out of millions - but I can't see how to index each
>
>>
>
>>> value. The ultimate output should be a matrix of results the length of
>
>>
>
>>> the input vector. But to do the sum I need to access the current row
>
>>
>
>>> number.
>
>>
>
>>>
>
>>
>
>>> It is easy in a loop but that will take ages. Is there any vectorised
>
>>
>
>>> apply-like solution to this?
>
>>
>
>>>
>
>>
>
>>> Or does apply etc only operate on each row at a time, independently of
>
>>
>
>>> other rows?
>
>>
>
>>>
>
>>
>
>>>
>
>>
>
>>> Best wishes
>
>>
>
>>>
>
>>
>
>>> John
>
>>
>
>>>
>
>>
>
>>> John Logsdon
>
>>
>
>>> Quantex Research Ltd
>
>>
>
>>> +44 161 445 4951/+44 7717758675
>
>>
>
>>>
>
>>
>
>>> ______________________________________________
>
>>
>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
>>
>
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>
>>
>
>>> PLEASE do read the posting guide
>
>>> http://www.R-project.org/posting-guide.html
>
>>
>
>>> and provide commented, minimal, self-contained, reproducible code.
>
>>
>
>>
>
>>
>
>> ______________________________________________
>
>>
>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
>>
>
>> https://stat.ethz.ch/mailman/listinfo/r-help
>
>>
>
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>
>>
>
>> and provide commented, minimal, self-contained, reproducible code.
>
>>
>
>>
>
>


From drjimlemon at gmail.com  Wed Jun 15 06:12:47 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Jun 2016 14:12:47 +1000
Subject: [R] processing time too long
In-Reply-To: <1465947715.S.11434.20164.f5-224-131.1465961130.17667@webmail.rediffmail.com>
References: <CA+8X3fVO1kD54PZrByaRG0tz1mD4Kk1RP5MrgbUBkf1JBU1rvw@mail.gmail.com>
	<1465947715.S.11434.20164.f5-224-131.1465961130.17667@webmail.rediffmail.com>
Message-ID: <CA+8X3fVag4v6kZvKOByS4vMYQurFsZMDn0cAf8KhKezCa_8t3g@mail.gmail.com>

I'm still unsure of what you are attempting to do with this data.
First, it is very sparse, appearing to be the counts of occurrences of
2567 strings, some of which are recognizable English words. I suspect
that you are trying to get something very simple like the frequency of
these strings within whatever corpus they inhabit. The code you sent
does some manipulations I can understand, others seem to be redundant
or even discarded after they are performed. For instance, you write
the result file twice, line by line. You also try to access the
element "matrixdata$ID" when as far as I can see, it doesn't exist.
That would certainly stop the script. Without knowing what is supposed
to be the result of this, it is impossible to even analyze code that
runs (for quite a few minutes) and does not appear to produce any
output..

Jim


From adomalik at sfu.ca  Wed Jun 15 05:43:55 2016
From: adomalik at sfu.ca (Alice Domalik)
Date: Tue, 14 Jun 2016 20:43:55 -0700 (PDT)
Subject: [R] help with r package "trip"
In-Reply-To: <1162373673.16800032.1465961778324.JavaMail.zimbra@sfu.ca>
Message-ID: <363523827.16806324.1465962235355.JavaMail.zimbra@sfu.ca>

Hi List, 

I'm relatively new to R, so apologies if my question is rather elementary. 
I'm working with some bird tracking data and I would like to calculate the maximum distance traveled from the colony. 
For the maximum distance traveled, I was going to use the function homedist(). However, when I try to use this function I get the following error: 
Error: could not find function "homedist" 
Anyone know why I would get this error? I have been using other functions in "trip" without an issue. Is there an alternative way I can calculate this? 

Thanks in advance for any help! 

	[[alternative HTML version deleted]]


From shelkeseema88 at yahoo.com  Wed Jun 15 06:46:57 2016
From: shelkeseema88 at yahoo.com (Seema Shelke)
Date: Wed, 15 Jun 2016 04:46:57 +0000 (UTC)
Subject: [R] Error in twitterR package
References: <1862441125.3603297.1465966017243.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1862441125.3603297.1465966017243.JavaMail.yahoo@mail.yahoo.com>

 Hi,
I am trying to use twitter package. I got? below error?while authentication.
> setup_twitter_oauth(api_key,api_secret,access_token, access_token_secret)
[1] "Using direct authentication"
Error in check_twitter_oauth() : OAuth authentication error:
This most likely means that you have incorrectly called setup_twitter_oauth()'
I am using windows machine. Please find below code and software details;
library("twitteR")
library(httr)
library(ROAuth)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
api_key? <-"xxx"
api_secret? <- "xxx"
access_token? <- " xxx"
access_token_secret? <- "xxx"
setup_twitter_oauth(api_key,api_secret,access_token, access_token_secret)
R version : Ri386 3.3.0R studio:??0.99.902?
Thanks,Seema
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Jun 15 10:18:10 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 15 Jun 2016 18:18:10 +1000
Subject: [R] help with r package "trip"
In-Reply-To: <363523827.16806324.1465962235355.JavaMail.zimbra@sfu.ca>
References: <1162373673.16800032.1465961778324.JavaMail.zimbra@sfu.ca>
	<363523827.16806324.1465962235355.JavaMail.zimbra@sfu.ca>
Message-ID: <CA+8X3fXq3PP4Bm94ZnpWA++AFp_vqgOyXqGEneG=MHKrchS63g@mail.gmail.com>

Hi Alice,
Have you tried creating a vector of the start position (xpos[1],ypos[1]):

xstart<-rep(xpos[1],n)
ystart<-rep(ypos[1],n)
# where "n" is the number of subsequent positions in the trip
max(trackDistance(xstart,ystart,xpos[2:n],ypos[2:n],...))

may then give you the value of the longest distance from the start. I
don't have the trip package or I could see if you really need to
replicate the start positions.

JIm


On Wed, Jun 15, 2016 at 1:43 PM, Alice Domalik <adomalik at sfu.ca> wrote:
> Hi List,
>
> I'm relatively new to R, so apologies if my question is rather elementary.
> I'm working with some bird tracking data and I would like to calculate the maximum distance traveled from the colony.
> For the maximum distance traveled, I was going to use the function homedist(). However, when I try to use this function I get the following error:
> Error: could not find function "homedist"
> Anyone know why I would get this error? I have been using other functions in "trip" without an issue. Is there an alternative way I can calculate this?
>
> Thanks in advance for any help!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Jun 15 10:49:22 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 15 Jun 2016 20:49:22 +1200
Subject: [R] [FORGED] Re:  help with r package "trip"
In-Reply-To: <CA+8X3fXq3PP4Bm94ZnpWA++AFp_vqgOyXqGEneG=MHKrchS63g@mail.gmail.com>
References: <1162373673.16800032.1465961778324.JavaMail.zimbra@sfu.ca>
	<363523827.16806324.1465962235355.JavaMail.zimbra@sfu.ca>
	<CA+8X3fXq3PP4Bm94ZnpWA++AFp_vqgOyXqGEneG=MHKrchS63g@mail.gmail.com>
Message-ID: <646e22f3-0420-f048-f015-80e13c7d09f9@auckland.ac.nz>

On 15/06/16 20:18, Jim Lemon wrote:
> Hi Alice,
> Have you tried creating a vector of the start position (xpos[1],ypos[1]):
>
> xstart<-rep(xpos[1],n)
> ystart<-rep(ypos[1],n)
> # where "n" is the number of subsequent positions in the trip
> max(trackDistance(xstart,ystart,xpos[2:n],ypos[2:n],...))
>
> may then give you the value of the longest distance from the start. I
> don't have the trip package or I could see if you really need to
> replicate the start positions.

Jim:  This seems to me to be somewhat off the point.  The OP was faced 
with the problem of not being able to access the function homedist(). 
This function seems *not* to be exported from the trip package, and yet 
it is a *documented* function which I would assume to imply that users 
should be able to invoke it directly.

It is possible that in the past the OP was dealing with a version of the 
trip package that was created before namespaces came into the picture, 
whence "exporting" was not relevant.  I would suggest that the OP 
contact the package maintainer (maintainer("trip") will give you the 
email address) and enquire as to what is going on.

In the interim, a workaround *might* be to invoke homedist() as

     trip:::homedist(<whatever>)

Note the *triple* colon in the foregoing.  I am not at all familiar with 
the trip package so my advice should probably be taken with several 
grains of salt.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

> On Wed, Jun 15, 2016 at 1:43 PM, Alice Domalik <adomalik at sfu.ca> wrote:
>> Hi List,
>>
>> I'm relatively new to R, so apologies if my question is rather elementary.
>> I'm working with some bird tracking data and I would like to calculate the maximum distance traveled from the colony.
>> For the maximum distance traveled, I was going to use the function homedist(). However, when I try to use this function I get the following error:
>> Error: could not find function "homedist"
>> Anyone know why I would get this error? I have been using other functions in "trip" without an issue. Is there an alternative way I can calculate this?
>>
>> Thanks in advance for any help!


From petr.pikal at precheza.cz  Wed Jun 15 11:19:13 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 15 Jun 2016 09:19:13 +0000
Subject: [R] Factor levels in training set
In-Reply-To: <1467905871.5110358.1465918117218.JavaMail.yahoo@mail.yahoo.com>
References: <487756069.5046266.1465916449698.JavaMail.yahoo.ref@mail.yahoo.com>
	<487756069.5046266.1465916449698.JavaMail.yahoo@mail.yahoo.com>
	<1467905871.5110358.1465918117218.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030D09@SRVEXCHMBX.precheza.cz>

Hi Elahe

I get slightly different error when using scale to nonnumeric data so I am not sure if you use the scale function from base package.

> scale(raman[1:20,])
Error in colMeans(x, na.rm = TRUE) : 'x' must be numeric

Anyway, how do you expect scaling shall be done when you have nonumeric variable. What shall be the output of

scale(iris$Species)

The only workaround is either to scale only numeric variables from your data and add nonnumeric in folowing step or to change all factor variable to numeric before scaling (which I would not recommend).

If your data are supposed to be numeric you can check if they really are by

str(df)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ch.elahe
> via R-help
> Sent: Tuesday, June 14, 2016 5:29 PM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] Factor levels in training set
>
>
>  Hi all,
> I want to use Supervised Self organizing Maps from Kohonen package for my
> data. I need to divide my df into training set and test set, but a part of my df
> contains column with factor levels and I don't know how to bring them into
> my training set. Currently I use the following command for my training set:
>
>     dt=sort(sample(nrow(df),nrow(df)*.7))
>     training=m[dt,]
> till here I get no error but in the next step which I need to bring my training
> set in a matrix I face this error:
>
>     scale(df[training,])
> error: 'x' should be numeric
> Does anyone know how should I include column with factor levels in my df so
> that I don't get this error?
> Thanks for any help,
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Jun 15 11:04:47 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 15 Jun 2016 09:04:47 +0000
Subject: [R] Warning message in openxlsx
In-Reply-To: <OF68C4D98E.D344075E-ONC1257FD2.004D128E-C1257FD2.004E02F2@lotus.hawesko.de>
References: <OF68C4D98E.D344075E-ONC1257FD2.004D128E-C1257FD2.004E02F2@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030CF2@SRVEXCHMBX.precheza.cz>

Hi

not completely sure but is there a variable with name "fonts" in some of your data frames?

Regards
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Tuesday, June 14, 2016 4:12 PM
> To: r-help at r-project.org
> Subject: [R] Warning message in openxlsx
>
> Hi All,
>
> I get the warning message
>
> Warning message:
> In styles$font : partial match of 'font' to 'fonts'
>
> when executing
>
>
> > xls_workbook <- t_create_workbook()
> > xls_sheetname <- "Kunden"
> > xls_ds_to_save <- ds_merge1
> > xls_filename <- paste0(data_created,
> "_Merge1_BW-SAP-Kunden_cleaned.xlsx")
> > t_add_sheet(workbook = xls_workbook,
> +             sheetname = xls_sheetname,
> +             dataset = xls_ds_to_save)
> > t_write_xlsx(workbook = xls_workbook,
> +              path = path_output,
> +              filename = xls_filename,
> +              overwrite = TRUE)
>
> where t_create_workbook() is
>
> return(createWorkbook())
>
> and t_add_sheet() is
>
>  addWorksheet(workbook,
>     sheetName = sheetname)
>   writeDataTable(workbook,
>     sheet = sheetname,
>     x = dataset)
>   ### writeDataTable writes data to a sheet an adds
>   ### autofilter to the first line
>   if (freeze_row <= 1 | freeze_col <= 1) {
>     NULL # do nothing
>   }
>   else {
>     freezePane(workbook,
>       sheet = sheetname,
>       firstActiveRow = freeze_row,
>       firstActiveCol = freeze_col)
>   }
>
>   setColWidths(workbook,
>     sheet = sheetname,
>     cols = 1:ncol(dataset),
>     widths = "auto")
>
> and t_write_xlsx is
>
> saveWorkbook(workbook,
>     file = file.path(path, filename),
>     overwrite = overwrite)
>
> I am woundring what "partial match of 'font' to 'fonts'" means cause I do not
> call it in the functions calls. I use these calls a lot in my programs but never got
> this message before.
>
> What does this message mean? How can I avoid this message?
>
> Kind regards
>
> Georg Maubach
>
> PS: You can find more information about the used functions by going to
> https://sourceforge.net/projects/r-project-utilities/files/?source=navbar
> .
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Wed Jun 15 12:09:01 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 15 Jun 2016 12:09:01 +0200
Subject: [R] Warning message in openxlsx
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030CF2@SRVEXCHMBX.precheza.cz>
References: <OF68C4D98E.D344075E-ONC1257FD2.004D128E-C1257FD2.004E02F2@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030CF2@SRVEXCHMBX.precheza.cz>
Message-ID: <86333EED-0F46-413E-B882-74917DD47BFA@gmail.com>


On 15 Jun 2016, at 11:04 , PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
> 
> not completely sure but is there a variable with name "fonts" in some of your data frames?


That doesn't usually give a warning, unless an option is set, and even then, it's not quite the same message:

> options(warnPartialMatchDollar=TRUE)
> airquality$O
  [1]  41  36  12  18  NA  28  23  19   8  NA   7  16  11  14  18  14  34   6
....
Warning message:
In `$.data.frame`(airquality, O) :
  Partial match of 'O' to 'Ozone' in data frame

So it might another $-method that does check for partial matching(?). 

At any rate, this sort of thing can often be debugged using 

options(warn=2, error=recover)

E.g., (with the above option still on)

> options(warn=2, error=recover)
> airquality$O
Error in `$.data.frame`(airquality, O) : 
  (converted from warning) Partial match of 'O' to 'Ozone' in data frame

Enter a frame number, or 0 to exit   

1: airquality$O
2: `$.data.frame`(airquality, O)
3: warning(gettextf("Partial match of '%s' to '%s' in data frame", name, names
4: .signalSimpleWarning("Partial match of 'O' to 'Ozone' in data frame", quote
5: withRestarts({
    .Internal(.signalCondition(simpleWarning(msg, call), msg
6: withOneRestart(expr, restarts[[1]])
7: doWithOneRestart(return(expr), restart)

Selection: 2
Called from: withRestarts({
    .Internal(.signalCondition(simpleWarning(msg, call), msg, 
        call))
    .Internal(.dfltWarn(msg, call))
}, muffleWarning = function() NULL)
Browse[1]> ls()
[1] "a"     "name"  "names" "x"    
Browse[1]> x
    Ozone Solar.R Wind Temp Month Day
1      41     190  7.4   67     5   1
2      36     118  8.0   72     5   2
....
153    20     223 11.5   68     9  30
Browse[1]> name
[1] "O"
Browse[1]> names
[1] "Ozone"   "Solar.R" "Wind"    "Temp"    "Month"   "Day"    

-pd

> 
> Regards
> Petr
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> G.Maubach at weinwolf.de
>> Sent: Tuesday, June 14, 2016 4:12 PM
>> To: r-help at r-project.org
>> Subject: [R] Warning message in openxlsx
>> 
>> Hi All,
>> 
>> I get the warning message
>> 
>> Warning message:
>> In styles$font : partial match of 'font' to 'fonts'
>> 
>> when executing
>> 
>> 
>>> xls_workbook <- t_create_workbook()
>>> xls_sheetname <- "Kunden"
>>> xls_ds_to_save <- ds_merge1
>>> xls_filename <- paste0(data_created,
>> "_Merge1_BW-SAP-Kunden_cleaned.xlsx")
>>> t_add_sheet(workbook = xls_workbook,
>> +             sheetname = xls_sheetname,
>> +             dataset = xls_ds_to_save)
>>> t_write_xlsx(workbook = xls_workbook,
>> +              path = path_output,
>> +              filename = xls_filename,
>> +              overwrite = TRUE)
>> 
>> where t_create_workbook() is
>> 
>> return(createWorkbook())
>> 
>> and t_add_sheet() is
>> 
>> addWorksheet(workbook,
>>    sheetName = sheetname)
>>  writeDataTable(workbook,
>>    sheet = sheetname,
>>    x = dataset)
>>  ### writeDataTable writes data to a sheet an adds
>>  ### autofilter to the first line
>>  if (freeze_row <= 1 | freeze_col <= 1) {
>>    NULL # do nothing
>>  }
>>  else {
>>    freezePane(workbook,
>>      sheet = sheetname,
>>      firstActiveRow = freeze_row,
>>      firstActiveCol = freeze_col)
>>  }
>> 
>>  setColWidths(workbook,
>>    sheet = sheetname,
>>    cols = 1:ncol(dataset),
>>    widths = "auto")
>> 
>> and t_write_xlsx is
>> 
>> saveWorkbook(workbook,
>>    file = file.path(path, filename),
>>    overwrite = overwrite)
>> 
>> I am woundring what "partial match of 'font' to 'fonts'" means cause I do not
>> call it in the functions calls. I use these calls a lot in my programs but never got
>> this message before.
>> 
>> What does this message mean? How can I avoid this message?
>> 
>> Kind regards
>> 
>> Georg Maubach
>> 
>> PS: You can find more information about the used functions by going to
>> https://sourceforge.net/projects/r-project-utilities/files/?source=navbar
>> .
>> 
>> ______________________________________________

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lanting.li at datarx.cn  Wed Jun 15 07:22:48 2016
From: lanting.li at datarx.cn (=?UTF-8?B?5p2O5YWw5am3?=)
Date: Wed, 15 Jun 2016 13:22:48 +0800
Subject: [R] =?utf-8?q?messy_code_found_when_reading_CSV_file_on_win_10_sy?=
 =?utf-8?q?stem?=
Message-ID: <2c9cc6ee-71da-4038-837b-8782eeee108e.lanting.li@datarx.cn>

?Dear Team,
A problem occured when I run Rstudio.? Could you please give me some advice?there is a lot of messy code when I read a csv file, which includes several columns in chinese, and R code run on WIN 10? system. I tried all the methods I can find on the internet, but no one is worked. is there some way I can fix it?
Really appreciated your help.
Best regards
Lanting 
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Jun 15 12:40:03 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 15 Jun 2016 06:40:03 -0400
Subject: [R] messy code found when reading CSV file on win 10 system
In-Reply-To: <2c9cc6ee-71da-4038-837b-8782eeee108e.lanting.li@datarx.cn>
References: <2c9cc6ee-71da-4038-837b-8782eeee108e.lanting.li@datarx.cn>
Message-ID: <c7c020cd-8ae6-187d-c047-16389ec3d207@gmail.com>

On 15/06/2016 1:22 AM, ??? wrote:
>  Dear Team,
> A problem occured when I run Rstudio.  Could you please give me some advice?there is a lot of messy code when I read a csv file, which includes several columns in chinese, and R code run on WIN 10  system. I tried all the methods I can find on the internet, but no one is worked. is there some way I can fix it?
> Really appreciated your help.

You should use the RStudio help forums for RStudio problems.

Your problem might have nothing to do with RStudio, but you haven't 
given us any information about what you did, so we can't tell.

What you should do:

Start R without RStudio, e.g. using Rgui.  See if the problem persists. 
If so, post the details here.  If not, move over to the RStudio help forums.

Duncan Murdoch


From chalabi.elahe at yahoo.de  Wed Jun 15 14:18:52 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Wed, 15 Jun 2016 12:18:52 +0000 (UTC)
Subject: [R] Y in Kohonen xyf function
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I have a df and I want to use supervised Self Organizing Map to do classification. I should use Kohonen library and xyf function from it. As you know the xyf function looks like this and I have problem defining my Y:

    xyf(data,Y,grid=somgrid(),rlen=100,alpha=c(0.05,0.01))
I want to do classification based on a column which shows the speed that a protocols is run, and this column is the following:

   $speed   :num 4 4 3 3 3 1 1 1 2 1 4 4 3
numbers from 1 to 4 show the speed from very fast to very slow protocols. so the property I want to be modeled is df$speed, but I don't know how should I bring it in xyf function. Does anyone know how to do that? I also added my train set ans test set: 

   dt=sort(sample(nrow(df),nrow(df)*.7))
   train=df[dt,]
   Xtraining=scale(trian)
   Xtest=scale(-trian)
   center=attr(Xtrianing,"scaled:center")
   scale=attr(Xtraining,"scaled:scale")
   xyf(Xtraining,........,grid=somgrid(10,10,"hexagonal"))


Thanks for any Help,
Elahe


From jdnewmil at dcn.davis.ca.us  Wed Jun 15 15:35:01 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 15 Jun 2016 06:35:01 -0700
Subject: [R] Error in twitterR package
In-Reply-To: <1862441125.3603297.1465966017243.JavaMail.yahoo@mail.yahoo.com>
References: <1862441125.3603297.1465966017243.JavaMail.yahoo.ref@mail.yahoo.com>
	<1862441125.3603297.1465966017243.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <E25EADE1-333D-491D-A6D4-CC36D181B5D4@dcn.davis.ca.us>

I have never used that package, but the error message seems clear.  You need to use the correct arguments to the setup_twitter_oauth function, and that requires that you interact with twitter parsonally to obtain appropriate credentials. While someone here may be able to give you a pointer as to how to do that, Google is probably a more appropriate way to start learning about that because it involves a legal agreement between you and twitter and has nothing to do with R and we are not lawyers representing twitter or you.
-- 
Sent from my phone. Please excuse my brevity.

On June 14, 2016 9:46:57 PM PDT, Seema Shelke via R-help <r-help at r-project.org> wrote:
> Hi,
>I am trying to use twitter package. I got? below error?while
>authentication.
>> setup_twitter_oauth(api_key,api_secret,access_token,
>access_token_secret)
>[1] "Using direct authentication"
>Error in check_twitter_oauth() : OAuth authentication error:
>This most likely means that you have incorrectly called
>setup_twitter_oauth()'
>I am using windows machine. Please find below code and software
>details;
>library("twitteR")
>library(httr)
>library(ROAuth)
>download.file(url="http://curl.haxx.se/ca/cacert.pem",
>destfile="cacert.pem")
>api_key? <-"xxx"
>api_secret? <- "xxx"
>access_token? <- " xxx"
>access_token_secret? <- "xxx"
>setup_twitter_oauth(api_key,api_secret,access_token,
>access_token_secret)
>R version : Ri386 3.3.0R studio:??0.99.902?
>Thanks,Seema
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Wed Jun 15 17:20:40 2016
From: mak.hholly at gmail.com (greg holly)
Date: Wed, 15 Jun 2016 11:20:40 -0400
Subject: [R] help for fine mappting
Message-ID: <CAM9Qe4g50Jo0Wt7vvD0gfRziK0sukX_k74AAfoBpg114pcy25w@mail.gmail.com>

dear all;


I am sorry for this posting. I have got help from Jim, Bert, Jeff and PIKAL
on similar issue before. I tried to modify Jim`s code to the real data but
it did not work. Now I am posting first two rows the imitation of real data
using dput() format (please see at the bottom).  I have two data sets,
data=map and data=ref. The first to rows of each data set are given below.
Data map has more than 27 million and data ref has about 560 rows.
Basically I need run two different tasks. My R codes for these task are
given below but they do not work properly. I sincerely do appreciate your
helps.



Regards,

Greg



Task 1)

For example, the first and second columns for row 1 in data ref are chr1,
6457839 and 6638389. So I need write an R code normally first look the
first row in ref (which they are chre1 6457839  and 6638389) than summing
the column of "map$post_prob" and give the number of map$snp falls between
6457839  and 6638389 that  their cumulative sum is >0.85. Then do the same
for the second, third....in ref. At the end I would like a table gave below
(need_ouput). Please notice the all value specified info in ref data file
are exist in map$CHR and map$POS columns.



Task2)

Again example, the first and second columns for row 1 in data ref are chr1,
6457839 and 6638389. So I need that R gives me the minimum map$p for the 2
chr1, 6457839 and 6638389 (as there are many snps between these regions and
would like choose the smallest one in those regions. Than do the same for
the second, third....rows in ref.



Then put the results of Task1 and Task2 into need_ouput file




#R codes modified from Jim


map2<-map[order(map$CHR, map$POS, -map$post_prob),]



                # get a field for the counts

 ref$n<-NA



                # and a field for the minimum p values

 ref$min_p<-NA



                # get the number of rows in "ref"

 nref<-dim(ref)[1]

 for(i in 1:nref) {

  CHR<- which(map2$CHR==ref$CHR[i])

  POS_start<-which(map2$POS==ref$POS_start[i])

  POS_end<-which(map2$POS==ref$POS_end[i])

  cat("CHR", "CHR"," POS_start",POS_start,"POS_end",POS_end,"\n")



                # get the range of matches

  POSrange<-range(c(CHR,POS_start,POS_end))



                # convert this to a sequence spanning all matches

  allPOS<-POSrange[1]:POSrange[2]

  ref$n[i]<-sum(map2$post_prob[allPOS] > 0.99)

  ref$min_p[i]<-min(map2$p[allPOS])

 }





      dput(map)

      structure(list(CHR = structure(c(1L, 1L), .Label = "chr1", class =
"factor"),

          snp = structure(1:2, .Label = c("rs4747841", "rs4749917"), class
= "factor"),

          Allel1 = structure(1:2, .Label = c("A", "T"), class = "factor"),

          Allel2 = structure(c(2L, 1L), .Label = c("C", "G"), class =
"factor"),

          fr = c(0.551, 0.436), effec = c(-0.0011, 0.0011), SE = c(0.0029,

          0.0029), p = c(0.7, 0.7), POS = c(9960129L, 9960259L), post_prob
= c(1.248817e-158,

          1.248817e-158)), .Names = c("CHR", "snp", "Allel1", "Allel2",

      "fr", "effec", "SE", "p", "POS", "post_prob"), class = "data.frame",
row.names = c(NA,

      -2L))





     dput(ref)

     structure(list(CHR = structure(1:2, .Label = c("chr10", "chr14"

     ), class = "factor"), POS_start = c(6457839L, 21005246L), POS_end =
c(6638389L,

     21550658L)), .Names = c("CHR", "POS_start", "POS_end"), class =
"data.frame", row.names = c(NA,

-2L))





dput(need_output)

structure(list(CHR = structure(1:2, .Label = c("chr1", "chr22"

), class = "factor"), POS = c(312127953L, 46487552L), POS_start =
c(32036927L,

45766451L), POS_end = c(3232240262, 46801601), snp = structure(1:2, .Label
= c("rs1143427",

"rs55958907"), class = "factor"), alle1l = structure(1:2, .Label = c("G",

"T"), class = "factor"), allel2 = structure(1:2, .Label = c("A",

"G"), class = "factor"), fr = c(0.278, 0.974), effec = c(0.6,

0.106), SE = c(0.015, 0.027), P = c(0.000156, 7.63e-05), post_prob =
c(0.229,

0.125), n = c(612L, 4218L)), .Names = c("CHR", "POS", "POS_start",

"POS_end", "snp", "alle1l", "allel2", "fr", "effec", "SE", "P",

"post_prob", "n"), class = "data.frame", row.names = c(NA, -2L

))

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Jun 15 17:56:27 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 15 Jun 2016 08:56:27 -0700
Subject: [R] is there a package in R or functions to calculate
	odds/hasard ratio from spline regression
In-Reply-To: <CAHtav99HoJp+t3_DBesN6z3ZEqf__qQ6F6cHz=PB85+SW8Mp8w@mail.gmail.com>
References: <CAHtav99HoJp+t3_DBesN6z3ZEqf__qQ6F6cHz=PB85+SW8Mp8w@mail.gmail.com>
Message-ID: <B4867494-E160-4490-8C79-5C454446D18E@comcast.net>


> On Jun 14, 2016, at 7:43 AM, takiy berrandou <takiyeddine at gmail.com> wrote:
> 
> Hello,
> 
> I'm looking for a package or function, which calculate OR/HR from spline
> model regression. for example in SAS it exist some MACRO helping to do that
> easiely.
> 
> i had make some research on the forum here and on the web but without any
> succes.
> 

It's not yet clear what  you want to do. Odds ratios are easily calculated from logistic regression models (typically constructed with the glm function the stats package) and hazard ratios are easily calculated from survival models (typically constructed with survreg or coxph in the survival package). All those functions accept spline terms in their formula versions. There are many worked examples that could be found with google searching since google now properly interprets the letter "r" as referring to the computer language. You can get a more focussed search using rseek.com.



> 
> 	[[alternative HTML version deleted]]

You should read the posting guide. Rhelp is a plain text mailing list.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From leonardof at leonardof.med.br  Wed Jun 15 18:08:19 2016
From: leonardof at leonardof.med.br (Leonardo Fontenelle)
Date: Wed, 15 Jun 2016 13:08:19 -0300
Subject: [R] is there a package in R or functions to calculate
 odds/hasard ratio from spline regression
In-Reply-To: <CAHtav99HoJp+t3_DBesN6z3ZEqf__qQ6F6cHz=PB85+SW8Mp8w@mail.gmail.com>
References: <CAHtav99HoJp+t3_DBesN6z3ZEqf__qQ6F6cHz=PB85+SW8Mp8w@mail.gmail.com>
Message-ID: <1466006899.3920166.638639305.13A36587@webmail.messagingengine.com>

Em Ter 14 jun. 2016, ?s 11:43, takiy berrandou escreveu:
> Hello,
> 
> I'm looking for a package or function, which calculate OR/HR from spline
> model regression. for example in SAS it exist some MACRO helping to do
> that
> easiely.
> 
> i had make some research on the forum here and on the web but without any
> succes.
> 

One, there are functions/packages to calculate OR/HR.
Two, there are functions/packages to use splines as predictors, instead
of the usual linear effect.

As David said, "odds ration in R" and so on is a great way to find what
you want.

Att,

Leonardo Ferreira Fontenelle, MD, MPH

PhD candidate in epidemiology, Federal University of Pelotas
Professor of medicine, Vila Velha University
Legislative consultant in health, Municipal Chamber of Vit?ria.


From frederic.patrizio at gmail.com  Wed Jun 15 18:10:15 2016
From: frederic.patrizio at gmail.com (Patrizio Frederic)
Date: Wed, 15 Jun 2016 18:10:15 +0200
Subject: [R] inverse table
Message-ID: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>

Dear R-users,
I've a problem that puzzle me

suppose I have a two way contigency  table

a <- sample(al <- letters[1:10],100,T)
b <- sample(bl <- LETTERS[1:5],100,T)
ab <- cbind(a,b)

ddd <- (xtabs(data = ab))
ddd <- as.matrix(ddd)

the question is: how do I reverse the code, thus how do I get raw data
(object ab) from ddd?

I've tried

as.data.frame.table(ddd)

which is not the answer I'm looking for.
Thanks in advance,

PF



-- 
+---------------------------------------------------------------
| Patrizio Frederic,
| http://morgana.unimore.it/frederic_patrizio/
+---------------------------------------------------------------

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Wed Jun 15 18:42:45 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 15 Jun 2016 11:42:45 -0500
Subject: [R] inverse table
In-Reply-To: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
References: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
Message-ID: <01FD4139-8EC9-46D7-8A72-CA44ADF92C50@me.com>


> On Jun 15, 2016, at 11:10 AM, Patrizio Frederic <frederic.patrizio at gmail.com> wrote:
> 
> Dear R-users,
> I've a problem that puzzle me
> 
> suppose I have a two way contigency  table
> 
> a <- sample(al <- letters[1:10],100,T)
> b <- sample(bl <- LETTERS[1:5],100,T)
> ab <- cbind(a,b)
> 
> ddd <- (xtabs(data = ab))
> ddd <- as.matrix(ddd)
> 
> the question is: how do I reverse the code, thus how do I get raw data
> (object ab) from ddd?
> 
> I've tried
> 
> as.data.frame.table(ddd)
> 
> which is not the answer I'm looking for.
> Thanks in advance,
> 
> PF


Hi,

There is a function called expand.dft(), which I posted some years ago, which is a modification of a prior version, posted a few years before that.

The updated version is here:

  https://stat.ethz.ch/pipermail/r-help/2009-January/378521.html

If memory serves, that code has made its way into one or more packages on CRAN but I don't recall which at the moment.

Regards,

Marc Schwartz


From ulrik.stervbo at gmail.com  Wed Jun 15 18:46:54 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 15 Jun 2016 16:46:54 +0000
Subject: [R] inverse table
In-Reply-To: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
References: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
Message-ID: <CAKVAULNWoJipvmKCRKDeOY=ru1smMDJfD8a9eByKKPLA+cP_FA@mail.gmail.com>

Hi Patrizio,

maybe there is a more efficient way, but you can loop over rows and columns
like this

ab.recon <- data.frame()

ddd.rownames <- rownames(ddd)
ddd.colnames <- colnames(ddd)

for(cur.row in ddd.rownames){
  for(cur.col in ddd.colnames){
    times.found <- ddd[cur.row, cur.col]
    tmp.df <- data.frame(a = rep(cur.row, times.found),
                         b = rep(cur.col, times.found))
    ab.recon <- rbind(ab.recon, tmp.df)
  }
}

Hope this helps
Ulrik

On Wed, 15 Jun 2016 at 18:12 Patrizio Frederic <frederic.patrizio at gmail.com>
wrote:

> Dear R-users,
> I've a problem that puzzle me
>
> suppose I have a two way contigency  table
>
> a <- sample(al <- letters[1:10],100,T)
> b <- sample(bl <- LETTERS[1:5],100,T)
> ab <- cbind(a,b)
>
> ddd <- (xtabs(data = ab))
> ddd <- as.matrix(ddd)
>
> the question is: how do I reverse the code, thus how do I get raw data
> (object ab) from ddd?
>
> I've tried
>
> as.data.frame.table(ddd)
>
> which is not the answer I'm looking for.
> Thanks in advance,
>
> PF
>
>
>
> --
> +---------------------------------------------------------------
> | Patrizio Frederic,
> | http://morgana.unimore.it/frederic_patrizio/
> +---------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From leonardof at leonardof.med.br  Wed Jun 15 18:49:35 2016
From: leonardof at leonardof.med.br (Leonardo Fontenelle)
Date: Wed, 15 Jun 2016 13:49:35 -0300
Subject: [R] inverse table
In-Reply-To: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
References: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
Message-ID: <1466009375.3927193.638681489.6526524C@webmail.messagingengine.com>

Em Qua 15 jun. 2016, ?s 13:10, Patrizio Frederic escreveu:
> Dear R-users,
> I've a problem that puzzle me
> 
> suppose I have a two way contigency  table
> 
> a <- sample(al <- letters[1:10],100,T)
> b <- sample(bl <- LETTERS[1:5],100,T)
> ab <- cbind(a,b)
> 
> ddd <- (xtabs(data = ab))
> ddd <- as.matrix(ddd)
> 
> the question is: how do I reverse the code, thus how do I get raw data
> (object ab) from ddd?

I believe packages reshape and reshape2 could help, although I don't use
them.

a <- sample(al <- letters[1:10],100,T)
b <- sample(bl <- LETTERS[1:5],100,T)
ab <- cbind(a,b)
ddd <- (xtabs(data = ab))
ddd <- as.matrix(ddd)

df <- expand.grid(dimnames(ddd), stringsAsFactors = FALSE)
df$freq <- as.vector(ddd)
ab2 <- as.matrix(df[rep(seq.int(nrow(df)), df$freq), 1:2])
all.equal(ab2[order(ab2[, c("a", "b")])], 
          ab[order(ab[, c("a", "b")])])

Hope that helps,

Leonardo Ferreira Fontenelle


From dcarlson at tamu.edu  Wed Jun 15 20:04:44 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 15 Jun 2016 18:04:44 +0000
Subject: [R] inverse table
In-Reply-To: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
References: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
Message-ID: <46166cb411f44ca8a8a865a9964e1a4a@exch-2p-mbx-t2.ads.tamu.edu>

After converting the table to a data frame, replicate each row by the number of observations:

> ddd.df <- as.data.frame(ddd)  # as.data.frame.table does the same thing
> ddd.new <- as.matrix(ddd.df[rep(seq_along(ddd.df[, 1]), ddd.df$Freq), 1:2])
> head(ddd.new)
    a   b  
1   "a" "A"
1.1 "a" "A"
2   "b" "A"
2.1 "b" "A"
3   "c" "A"
4   "d" "A"
> rownames(ddd.new) <- NULL # Optional - get rid of row names
> head(ddd.new)
     a   b  
[1,] "a" "A"
[2,] "a" "A"
[3,] "b" "A"
[4,] "b" "A"
[5,] "c" "A"
[6,] "d" "A"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Patrizio Frederic
Sent: Wednesday, June 15, 2016 11:10 AM
To: r-help at r-project.org
Subject: [R] inverse table

Dear R-users,
I've a problem that puzzle me

suppose I have a two way contigency  table

a <- sample(al <- letters[1:10],100,T)
b <- sample(bl <- LETTERS[1:5],100,T)
ab <- cbind(a,b)

ddd <- (xtabs(data = ab))
ddd <- as.matrix(ddd)

the question is: how do I reverse the code, thus how do I get raw data
(object ab) from ddd?

I've tried

as.data.frame.table(ddd)

which is not the answer I'm looking for.
Thanks in advance,

PF



-- 
+---------------------------------------------------------------
| Patrizio Frederic,
| http://morgana.unimore.it/frederic_patrizio/
+---------------------------------------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jun 15 20:37:53 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 15 Jun 2016 11:37:53 -0700
Subject: [R] is there a package in R or functions to calculate
	odds/hasard ratio from spline regression
In-Reply-To: <CAHtav99kp3o6p5SHGY_pUcqiQ_iLotYgO5M-PkAPO_zNsCm5-g@mail.gmail.com>
References: <CAHtav99HoJp+t3_DBesN6z3ZEqf__qQ6F6cHz=PB85+SW8Mp8w@mail.gmail.com>
	<B4867494-E160-4490-8C79-5C454446D18E@comcast.net>
	<CAHtav99kp3o6p5SHGY_pUcqiQ_iLotYgO5M-PkAPO_zNsCm5-g@mail.gmail.com>
Message-ID: <F7A925D4-E74C-40C9-9657-8A87A1A96A16@comcast.net>


> On Jun 15, 2016, at 9:12 AM, takiy berrandou <takiyeddine at gmail.com> wrote:
> 
> Hello,
> thank you for the answer. it's true i was'nt clear enough. 
> the problem with glm()/gam or coxph() when the spline terms are used (specialy spline of 3rd degree) the calculated coefficients for the spline terms are difficult to interpret.

Not just difficult, but also generally unwise to attempt interpretation of individual spline coefficients. 

> for example for spline of degree=3 and 3 knots, there are 7 beta's calculated, and to represent the result clearly we need to calculate OR/HR against a reference.

Natural splines are third degree, although generally the number of knots is 1 less than the degree of the polynomial.

> just making exp(beta) does'nt have a propre meaning.
> On SAS there are some MACRO's like %regspline which help to make some calcul to figure out the OR's.
> 

The predict.* functions will generally handle that difficulty naturally. Each of hte regression functions will have a specific `predict` method for the class of model object. You simply provide the values for the covariates in a dataframe and a prediction for for total of associated terms will be returned. See:

?predict.glm

Std errors are generally available if the proper parameters are offered to the function. This procedure should be exemplified in the help documents and vignettes of the packages with whatever regression function you anticipate using. On the Rhelp mailing list you are requested to present questions with sufficient code to support a coding response.

-- 
David


> Thank's again for the answers
> 
> 
> 
> 
> 2016-06-15 17:56 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
> 
> > On Jun 14, 2016, at 7:43 AM, takiy berrandou <takiyeddine at gmail.com> wrote:
> >
> > Hello,
> >
> > I'm looking for a package or function, which calculate OR/HR from spline
> > model regression. for example in SAS it exist some MACRO helping to do that
> > easiely.
> >
> > i had make some research on the forum here and on the web but without any
> > succes.
> >
> 
> It's not yet clear what  you want to do. Odds ratios are easily calculated from logistic regression models (typically constructed with the glm function the stats package) and hazard ratios are easily calculated from survival models (typically constructed with survreg or coxph in the survival package). All those functions accept spline terms in their formula versions. There are many worked examples that could be found with google searching since google now properly interprets the letter "r" as referring to the computer language. You can get a more focussed search using rseek.com.
> 
> 
> 
> >
> >       [[alternative HTML version deleted]]
> 
> You should read the posting guide. Rhelp is a plain text mailing list.
> 
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> 
> -- 
> Takiy BERRANDOU
> 0618916037
> takiyeddine at gmail.com
> 

David Winsemius
Alameda, CA, USA


From takiyeddine at gmail.com  Wed Jun 15 18:12:23 2016
From: takiyeddine at gmail.com (takiy berrandou)
Date: Wed, 15 Jun 2016 18:12:23 +0200
Subject: [R] is there a package in R or functions to calculate
 odds/hasard ratio from spline regression
In-Reply-To: <B4867494-E160-4490-8C79-5C454446D18E@comcast.net>
References: <CAHtav99HoJp+t3_DBesN6z3ZEqf__qQ6F6cHz=PB85+SW8Mp8w@mail.gmail.com>
	<B4867494-E160-4490-8C79-5C454446D18E@comcast.net>
Message-ID: <CAHtav99kp3o6p5SHGY_pUcqiQ_iLotYgO5M-PkAPO_zNsCm5-g@mail.gmail.com>

Hello,
thank you for the answer. it's true i was'nt clear enough.
the problem with glm()/gam or coxph() when the spline terms are used
(specialy spline of 3rd degree) the calculated coefficients for the spline
terms are difficult to interpret. for example for spline of degree=3 and 3
knots, there are 7 beta's calculated, and to represent the result clearly
we need to calculate OR/HR against a reference. just making exp(beta)
does'nt have a propre meaning.
On SAS there are some MACRO's like %regspline which help to make some
calcul to figure out the OR's.

Thank's again for the answers




2016-06-15 17:56 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Jun 14, 2016, at 7:43 AM, takiy berrandou <takiyeddine at gmail.com>
> wrote:
> >
> > Hello,
> >
> > I'm looking for a package or function, which calculate OR/HR from spline
> > model regression. for example in SAS it exist some MACRO helping to do
> that
> > easiely.
> >
> > i had make some research on the forum here and on the web but without any
> > succes.
> >
>
> It's not yet clear what  you want to do. Odds ratios are easily calculated
> from logistic regression models (typically constructed with the glm
> function the stats package) and hazard ratios are easily calculated from
> survival models (typically constructed with survreg or coxph in the
> survival package). All those functions accept spline terms in their formula
> versions. There are many worked examples that could be found with google
> searching since google now properly interprets the letter "r" as referring
> to the computer language. You can get a more focussed search using
> rseek.com.
>
>
>
> >
> >       [[alternative HTML version deleted]]
>
> You should read the posting guide. Rhelp is a plain text mailing list.
>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
Takiy BERRANDOU
0618916037
takiyeddine at gmail.com

	[[alternative HTML version deleted]]


From nick.tulli.95 at gmail.com  Wed Jun 15 19:37:59 2016
From: nick.tulli.95 at gmail.com (Nick Tulli)
Date: Wed, 15 Jun 2016 13:37:59 -0400
Subject: [R] Find mean of values in three-dimensional array
Message-ID: <CAONpAsrfe_=oGyw2fu0yVBs0258CZ=2N1w5U36mp=AZQWAOgCA@mail.gmail.com>

Hey R-Help,

I've got a three dimensional array which I pulled from a netcdf file.
The data in array are the humidity values of locations in the United
States over a time period. The three dimensions are [longitude,
latitude, days], 141x81x92. My goal is to find the mean value at each
longitude/latitude over the 92 day period.

I could probably accomplish my goal by running a loop, but I'm sure
that there is a much easier and more efficient way to accomplish the
goal in R. Any suggestions?


Thanks guys.


From pdalgd at gmail.com  Wed Jun 15 21:05:12 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 15 Jun 2016 21:05:12 +0200
Subject: [R] Find mean of values in three-dimensional array
In-Reply-To: <CAONpAsrfe_=oGyw2fu0yVBs0258CZ=2N1w5U36mp=AZQWAOgCA@mail.gmail.com>
References: <CAONpAsrfe_=oGyw2fu0yVBs0258CZ=2N1w5U36mp=AZQWAOgCA@mail.gmail.com>
Message-ID: <7341260C-2024-4E17-9F9D-DD1647A84E9C@gmail.com>


> On 15 Jun 2016, at 19:37 , Nick Tulli <nick.tulli.95 at gmail.com> wrote:
> 
> Hey R-Help,
> 
> I've got a three dimensional array which I pulled from a netcdf file.
> The data in array are the humidity values of locations in the United
> States over a time period. The three dimensions are [longitude,
> latitude, days], 141x81x92. My goal is to find the mean value at each
> longitude/latitude over the 92 day period.
> 
> I could probably accomplish my goal by running a loop, but I'm sure
> that there is a much easier and more efficient way to accomplish the
> goal in R. Any suggestions?

Dunno about fast, but the canonical way is apply(A, c(1,2), mean)

E.g.

(A <- array(1:24,c(2,3,4)))
apply(A, c(1,2), mean)
apply(A, c(1,3), mean)

-pd

> 
> 
> Thanks guys.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From toth.denes at ttk.mta.hu  Wed Jun 15 21:22:00 2016
From: toth.denes at ttk.mta.hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Wed, 15 Jun 2016 21:22:00 +0200
Subject: [R] Find mean of values in three-dimensional array
In-Reply-To: <7341260C-2024-4E17-9F9D-DD1647A84E9C@gmail.com>
References: <CAONpAsrfe_=oGyw2fu0yVBs0258CZ=2N1w5U36mp=AZQWAOgCA@mail.gmail.com>
	<7341260C-2024-4E17-9F9D-DD1647A84E9C@gmail.com>
Message-ID: <5761AAD8.9090806@ttk.mta.hu>



On 06/15/2016 09:05 PM, peter dalgaard wrote:
 >
 >> On 15 Jun 2016, at 19:37 , Nick Tulli <nick.tulli.95 at gmail.com> wrote:
 >>
 >> Hey R-Help,
 >>
 >> I've got a three dimensional array which I pulled from a netcdf file.
 >> The data in array are the humidity values of locations in the United
 >> States over a time period. The three dimensions are [longitude,
 >> latitude, days], 141x81x92. My goal is to find the mean value at each
 >> longitude/latitude over the 92 day period.
 >>
 >> I could probably accomplish my goal by running a loop, but I'm sure
 >> that there is a much easier and more efficient way to accomplish the
 >> goal in R. Any suggestions?
 >
 > Dunno about fast, but the canonical way is apply(A, c(1,2), mean)

For "mean" and "sum", row/colMeans() is pretty fast and efficient. Note 
the 'dims' argument; you might also consider the aperm() function before 
the aggregation.

E.g.:

# create an array
x <- provideDimnames(array(rnorm(141*81*92), c(141, 81, 92)))
names(dimnames(x)) <- c("long", "lat", "days")

# collapse over days
str(rowMeans(x, dims = 2))

# collapse over lat
x_new <- aperm(x, c("lat", "long", "days"))
str(colMeans(x_new))

Cheers,
Denes


 >
 > E.g.
 >
 > (A <- array(1:24,c(2,3,4)))
 > apply(A, c(1,2), mean)
 > apply(A, c(1,3), mean)
 >
 > -pd
 >
 >>
 >>
 >> Thanks guys.
 >>
 >> ______________________________________________
 >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.
 >


From jcpayne at uw.edu  Wed Jun 15 21:34:31 2016
From: jcpayne at uw.edu (J Payne)
Date: Wed, 15 Jun 2016 12:34:31 -0700
Subject: [R] Closing FTP sessions with RCurl
In-Reply-To: <CAKmUXV8a6qFJgk74ASmu6M1naMcBDN6+O4-108cHRoMhuAbYvg@mail.gmail.com>
References: <24975B65-64BE-46D1-9208-A5905BBE67A6@uw.edu>
	<CAKmUXV8a6qFJgk74ASmu6M1naMcBDN6+O4-108cHRoMhuAbYvg@mail.gmail.com>
Message-ID: <4342CC8E-711B-4F51-8B50-6773122B78C6@uw.edu>

Thanks Tom!  I tried that and it didn?t work, but perhaps there are other problems.  The system administrator wrote ?I think closing sessions immediately upon completion of the transfer,
or continuing to use the same session for additional requests would both have a similar and positive effect.?  However, I?ve now tried your solution to close the session, and also tried using one curl handle throughout, but the throttling persists.  

John

On 6/14/16, 1:00 PM, "Tom Wright" <tom at maladmin.com> wrote:

>No expert here, and this isn't tested. It seems you can set the
>forbid.reuse option which will cause curl to shutdown the connection
>after transfer is complete.
>
>if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
>   curl <- getCurlHandle()
>   curlSetOpt(.opts=list(forbid.reuse=1),curl=curl)
>   getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
>}
>
>On Tue, Jun 14, 2016 at 2:41 PM, J Payne <jcpayne at uw.edu> wrote:
>> Does anyone know how to close an FTP session with RCurl?  I am trying to automate the process of downloading snow data from a government website, and their server is throttling the connection after a few files are downloaded.  I contacted their system administrator, who wrote: ?My suspicion at this point is that the getURL commands are opened and perform the function asked, then linger in wait for 15 minutes until or ftp server closes the idle sessions. Is there a way to tell R to close the sessions??
>>
>>
>>
>> I?ve perused the RCurl manual but I don?t see a way to close sessions.  I tried copying the following example from the RCurl manual, but it didn?t solve the problem.  I?m a novice at this and I don?t understand the relationship between handles and sessions, so I am probably missing something.
>>
>>
>>
>> #EXAMPLE from getCurl(), p. 39
>>
>> if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
>>
>>    curl = getCurlHandle()
>>
>>    getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
>>
>>    #getCurlInfo(curl) # I skipped this step
>>
>>    rm(curl) # release the curl! (does this end the session???)
>>
>> }
>>
>>
>>
>> Thanks!
>>
>>
>>
>> John
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From farzana.akbari2013 at gmail.com  Wed Jun 15 21:47:28 2016
From: farzana.akbari2013 at gmail.com (farzana akbari)
Date: Wed, 15 Jun 2016 09:47:28 -1000
Subject: [R] benchmark-dea
Message-ID: <CAL3rq9i3X1_dZmJDxqxevRZpe3UTRAcgK-7yjvQ9N4-jqALKVQ@mail.gmail.com>

in the name of God


hi dear

I  use benchmark package to use of dea  and when I wanna save my result
as csv by this as below
 write.csv(farzana,'D:sajjaad.csv')

I can not and the error is as below


Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors =
stringsAsFactors) :
  cannot coerce class ""Farrell"" to a data.frame


what should I do ?


best regards
farzana

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Jun 15 21:57:21 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 15 Jun 2016 12:57:21 -0700
Subject: [R] Closing FTP sessions with RCurl
In-Reply-To: <4342CC8E-711B-4F51-8B50-6773122B78C6@uw.edu>
References: <24975B65-64BE-46D1-9208-A5905BBE67A6@uw.edu>
	<CAKmUXV8a6qFJgk74ASmu6M1naMcBDN6+O4-108cHRoMhuAbYvg@mail.gmail.com>
	<4342CC8E-711B-4F51-8B50-6773122B78C6@uw.edu>
Message-ID: <CAF8bMca2L9NqpeP6bv+cP5Nwdh1gO8JvySFMGJUQP3LgPP_QXw@mail.gmail.com>

>>    rm(curl) # release the curl! (does this end the session???)

Try adding a call to gc() immediately after this removal.  That will force
an
immediate run of any finalizer associated with the object just removed.
With the call to gc(), the garbage collector will be called some time in the
future and the finalizers will be run then.

(I don't know if curl has a finalizer that closes the session.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jun 15, 2016 at 12:34 PM, J Payne <jcpayne at uw.edu> wrote:

> Thanks Tom!  I tried that and it didn?t work, but perhaps there are other
> problems.  The system administrator wrote ?I think closing sessions
> immediately upon completion of the transfer,
> or continuing to use the same session for additional requests would both
> have a similar and positive effect.?  However, I?ve now tried your solution
> to close the session, and also tried using one curl handle throughout, but
> the throttling persists.
>
> John
>
> On 6/14/16, 1:00 PM, "Tom Wright" <tom at maladmin.com> wrote:
>
> >No expert here, and this isn't tested. It seems you can set the
> >forbid.reuse option which will cause curl to shutdown the connection
> >after transfer is complete.
> >
> >if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
> >   curl <- getCurlHandle()
> >   curlSetOpt(.opts=list(forbid.reuse=1),curl=curl)
> >   getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
> >}
> >
> >On Tue, Jun 14, 2016 at 2:41 PM, J Payne <jcpayne at uw.edu> wrote:
> >> Does anyone know how to close an FTP session with RCurl?  I am trying
> to automate the process of downloading snow data from a government website,
> and their server is throttling the connection after a few files are
> downloaded.  I contacted their system administrator, who wrote: ?My
> suspicion at this point is that the getURL commands are opened and perform
> the function asked, then linger in wait for 15 minutes until or ftp server
> closes the idle sessions. Is there a way to tell R to close the sessions??
> >>
> >>
> >>
> >> I?ve perused the RCurl manual but I don?t see a way to close sessions.
> I tried copying the following example from the RCurl manual, but it didn?t
> solve the problem.  I?m a novice at this and I don?t understand the
> relationship between handles and sessions, so I am probably missing
> something.
> >>
> >>
> >>
> >> #EXAMPLE from getCurl(), p. 39
> >>
> >> if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
> >>
> >>    curl = getCurlHandle()
> >>
> >>    getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
> >>
> >>    #getCurlInfo(curl) # I skipped this step
> >>
> >>    rm(curl) # release the curl! (does this end the session???)
> >>
> >> }
> >>
> >>
> >>
> >> Thanks!
> >>
> >>
> >>
> >> John
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From vwkv13 at mun.ca  Wed Jun 15 22:20:01 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Wed, 15 Jun 2016 14:20:01 -0600
Subject: [R] Writing R package that call Fortran codes
Message-ID: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>

Hi,

I'm trying to write an R package that calls a Fortran subroutine on my  Mac
os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build and
load the library but when I try to use it in R I get this error:
>library(NEpidemic)
>random_epi(variable_names)

Error in .Fortran("random_epi", : "random_pi" not resolved from current
namespace (NEpidemic).

Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
additional to useDynLib(NEpidemic). After doing that I couldn't build the
package and it gave me another error:

Error in library.dynam(lib, package, package.lib) :
  shared object ?random_epi.so? not found
Error: loading failed
Execution halted
ERROR: loading failed

When I checked my src folder, there is only random_epi.o file.  How can I
fix this issue? Any help would be much appreciated. I'm vey new to both R
and Fortran coding, especially in package building.

Thanks in advance!
Vineetha

	[[alternative HTML version deleted]]


From jcpayne at uw.edu  Wed Jun 15 22:52:39 2016
From: jcpayne at uw.edu (J Payne)
Date: Wed, 15 Jun 2016 13:52:39 -0700
Subject: [R] Closing FTP sessions with RCurl
In-Reply-To: <CAF8bMca2L9NqpeP6bv+cP5Nwdh1gO8JvySFMGJUQP3LgPP_QXw@mail.gmail.com>
References: <24975B65-64BE-46D1-9208-A5905BBE67A6@uw.edu>
	<CAKmUXV8a6qFJgk74ASmu6M1naMcBDN6+O4-108cHRoMhuAbYvg@mail.gmail.com>
	<4342CC8E-711B-4F51-8B50-6773122B78C6@uw.edu>
	<CAF8bMca2L9NqpeP6bv+cP5Nwdh1gO8JvySFMGJUQP3LgPP_QXw@mail.gmail.com>
Message-ID: <06EFB7B4-7795-4102-9751-ED398BB0DBFD@uw.edu>

Fantastic!? That did the trick.? I still suspect that there may be a command within RCurl that accomplishes the same thing, but in any case I?m very grateful to have a solution that works.? 

 

Best,

 

John

 

From: William Dunlap <wdunlap at tibco.com>
Date: Wednesday, June 15, 2016 at 12:57 PM
To: J Payne <jcpayne at uw.edu>
Cc: Tom Wright <tom at maladmin.com>, R help list <r-help at r-project.org>
Subject: Re: [R] Closing FTP sessions with RCurl

 

>>    rm(curl) # release the curl! (does this end the session???)

 

Try adding a call to gc() immediately after this removal.  That will force an

immediate run of any finalizer associated with the object just removed.

With the call to gc(), the garbage collector will be called some time in the

future and the finalizers will be run then.

 

(I don't know if curl has a finalizer that closes the session.)

 


Bill Dunlap
TIBCO Software
wdunlap tibco.com

 

On Wed, Jun 15, 2016 at 12:34 PM, J Payne <jcpayne at uw.edu> wrote:

Thanks Tom!  I tried that and it didn?t work, but perhaps there are other problems.  The system administrator wrote ?I think closing sessions immediately upon completion of the transfer,
or continuing to use the same session for additional requests would both have a similar and positive effect.?  However, I?ve now tried your solution to close the session, and also tried using one curl handle throughout, but the throttling persists.

John

On 6/14/16, 1:00 PM, "Tom Wright" <tom at maladmin.com> wrote:

>No expert here, and this isn't tested. It seems you can set the
>forbid.reuse option which will cause curl to shutdown the connection
>after transfer is complete.
>
>if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
>   curl <- getCurlHandle()
>   curlSetOpt(.opts=list(forbid.reuse=1),curl=curl)
>   getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
>}
>
>On Tue, Jun 14, 2016 at 2:41 PM, J Payne <jcpayne at uw.edu> wrote:
>> Does anyone know how to close an FTP session with RCurl?  I am trying to automate the process of downloading snow data from a government website, and their server is throttling the connection after a few files are downloaded.  I contacted their system administrator, who wrote: ?My suspicion at this point is that the getURL commands are opened and perform the function asked, then linger in wait for 15 minutes until or ftp server closes the idle sessions. Is there a way to tell R to close the sessions??
>>
>>
>>
>> I?ve perused the RCurl manual but I don?t see a way to close sessions.  I tried copying the following example from the RCurl manual, but it didn?t solve the problem.  I?m a novice at this and I don?t understand the relationship between handles and sessions, so I am probably missing something.
>>
>>
>>
>> #EXAMPLE from getCurl(), p. 39
>>
>> if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
>>
>>    curl = getCurlHandle()
>>
>>    getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
>>
>>    #getCurlInfo(curl) # I skipped this step
>>
>>    rm(curl) # release the curl! (does this end the session???)
>>
>> }
>>
>>
>>
>> Thanks!
>>
>>
>>
>> John
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Jun 15 22:58:19 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 15 Jun 2016 13:58:19 -0700
Subject: [R] Closing FTP sessions with RCurl
In-Reply-To: <CAF8bMca2L9NqpeP6bv+cP5Nwdh1gO8JvySFMGJUQP3LgPP_QXw@mail.gmail.com>
References: <24975B65-64BE-46D1-9208-A5905BBE67A6@uw.edu>
	<CAKmUXV8a6qFJgk74ASmu6M1naMcBDN6+O4-108cHRoMhuAbYvg@mail.gmail.com>
	<4342CC8E-711B-4F51-8B50-6773122B78C6@uw.edu>
	<CAF8bMca2L9NqpeP6bv+cP5Nwdh1gO8JvySFMGJUQP3LgPP_QXw@mail.gmail.com>
Message-ID: <CAF8bMcb8jXGwicWGCja_UFea75fS6HsmwiENkO6GfufdF2NruQ@mail.gmail.com>

>With the call to gc(), the garbage collector will be called some time in
the
>future and the finalizers will be run then.

Typo: that initial 'With' should be 'Without'.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jun 15, 2016 at 12:57 PM, William Dunlap <wdunlap at tibco.com> wrote:

> >>    rm(curl) # release the curl! (does this end the session???)
>
> Try adding a call to gc() immediately after this removal.  That will force
> an
> immediate run of any finalizer associated with the object just removed.
> With the call to gc(), the garbage collector will be called some time in
> the
> future and the finalizers will be run then.
>
> (I don't know if curl has a finalizer that closes the session.)
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Jun 15, 2016 at 12:34 PM, J Payne <jcpayne at uw.edu> wrote:
>
>> Thanks Tom!  I tried that and it didn?t work, but perhaps there are other
>> problems.  The system administrator wrote ?I think closing sessions
>> immediately upon completion of the transfer,
>> or continuing to use the same session for additional requests would both
>> have a similar and positive effect.?  However, I?ve now tried your solution
>> to close the session, and also tried using one curl handle throughout, but
>> the throttling persists.
>>
>> John
>>
>> On 6/14/16, 1:00 PM, "Tom Wright" <tom at maladmin.com> wrote:
>>
>> >No expert here, and this isn't tested. It seems you can set the
>> >forbid.reuse option which will cause curl to shutdown the connection
>> >after transfer is complete.
>> >
>> >if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
>> >   curl <- getCurlHandle()
>> >   curlSetOpt(.opts=list(forbid.reuse=1),curl=curl)
>> >   getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
>> >}
>> >
>> >On Tue, Jun 14, 2016 at 2:41 PM, J Payne <jcpayne at uw.edu> wrote:
>> >> Does anyone know how to close an FTP session with RCurl?  I am trying
>> to automate the process of downloading snow data from a government website,
>> and their server is throttling the connection after a few files are
>> downloaded.  I contacted their system administrator, who wrote: ?My
>> suspicion at this point is that the getURL commands are opened and perform
>> the function asked, then linger in wait for 15 minutes until or ftp server
>> closes the idle sessions. Is there a way to tell R to close the sessions??
>> >>
>> >>
>> >>
>> >> I?ve perused the RCurl manual but I don?t see a way to close
>> sessions.  I tried copying the following example from the RCurl manual, but
>> it didn?t solve the problem.  I?m a novice at this and I don?t understand
>> the relationship between handles and sessions, so I am probably missing
>> something.
>> >>
>> >>
>> >>
>> >> #EXAMPLE from getCurl(), p. 39
>> >>
>> >> if(url.exists("http://www.omegahat.net/RCurl/index.html")) {
>> >>
>> >>    curl = getCurlHandle()
>> >>
>> >>    getURL("http://www.omegahat.net/RCurl/index.html", curl = curl)
>> >>
>> >>    #getCurlInfo(curl) # I skipped this step
>> >>
>> >>    rm(curl) # release the curl! (does this end the session???)
>> >>
>> >> }
>> >>
>> >>
>> >>
>> >> Thanks!
>> >>
>> >>
>> >>
>> >> John
>> >>
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From emammendes at gmail.com  Wed Jun 15 23:55:56 2016
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Wed, 15 Jun 2016 18:55:56 -0300
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
Message-ID: <ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>

Hi

Have you tried to load and run the fortran code using just a wrapper function in R?   I do that as the first step in order to build a package.  

Example:   fortran sources -> rk4_mod_r.f90 ,derive_henonheilles.f90, poincare_section.f90

a) I use R CMD SHLIB rk4_mod_r.f90 ,derive_henonheilles.f90, poincare_section.f90 - o poincare_section_henonheilles_rk4.so 
b) Then I write a wrapper function in R, poinc_section_henonheilles.R
...
 dyn.load("poincare_section_henonheilles_rk4.so")
  
  out<-.Fortran("section_crossing",
                h=as.numeric(h),
                nphas=as.integer(nphas),..
...
c) and call the function as usual.

Please note that the function called by .Fortran is the name of the subroutine within poincare_section.f90 and not the filename.

I take the opportunity to thank R-developers for making the calling of C and Fortran in R very easy.   

I hope this helps.

regards

Ed

PS.  If you need an example of a package using Fortran90, please check https://github.com/emammendes/mittagleffler <https://github.com/emammendes/mittagleffler>



> On Jun 15, 2016, at 5:20 PM, Kodalore Vijayan, Vineetha W <vwkv13 at mun.ca> wrote:
> 
> Hi,
> 
> I'm trying to write an R package that calls a Fortran subroutine on my  Mac
> os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build and
> load the library but when I try to use it in R I get this error:
>> library(NEpidemic)
>> random_epi(variable_names)
> 
> Error in .Fortran("random_epi", : "random_pi" not resolved from current
> namespace (NEpidemic).
> 
> Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
> additional to useDynLib(NEpidemic). After doing that I couldn't build the
> package and it gave me another error:
> 
> Error in library.dynam(lib, package, package.lib) :
>  shared object ?random_epi.so? not found
> Error: loading failed
> Execution halted
> ERROR: loading failed
> 
> When I checked my src folder, there is only random_epi.o file.  How can I
> fix this issue? Any help would be much appreciated. I'm vey new to both R
> and Fortran coding, especially in package building.
> 
> Thanks in advance!
> Vineetha
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From Pradip.Muhuri at ahrq.hhs.gov  Wed Jun 15 23:08:44 2016
From: Pradip.Muhuri at ahrq.hhs.gov (Muhuri, Pradip (AHRQ/CFACT))
Date: Wed, 15 Jun 2016 21:08:44 +0000
Subject: [R] dplyr's  arrange function
Message-ID: <BN1PR09MB0305CEB2672364FBC1968A02D3550@BN1PR09MB0305.namprd09.prod.outlook.com>

Hello,

I am using the dplyr's arrange() function to sort  one of the  many data frames  on a character variable (named "prevalence").

Issue: I am not getting the desired output  (line 7 is the problem, which should be the very last line in the sorted data frame) because the sorted field is character, not numeric. 

The reproducible example and the output are appended below. 

Is there any work-around  to convert/treat  this character variable (named "prevalence" in the data frame below)  as numeric before using the arrange() function within the dplyr package?

Any hints will be appreciated.

Thanks,

Pradip Muhuri

# Reproducible Example 

library("readr")
testdata <- read_csv(
"indicator,  prevalence
1. Health check-up, 77.2 (1.19)
2. Blood cholesterol checked,  84.5 (1.14)
3. Recieved flu vaccine, 50.0 (1.33)
4. Blood pressure checked, 88.7 (0.88)
5. Aspirin use-problems, 11.7 (1.02)
6.Colonoscopy, 60.2 (1.41)
7. Sigmoidoscopy,  6.1 (0.61)
8. Blood stool test, 14.6 (1.00)
9.Mammogram,  72.6 (1.82)
10. Pap Smear test, 73.3 (2.37)")

# Sort on the character variable in descending order
arrange(testdata, desc(prevalence))

# Results from Console

                      indicator  prevalence
                          (chr)       (chr)
1     4. Blood pressure checked 88.7 (0.88)
2  2. Blood cholesterol checked 84.5 (1.14)
3            1. Health check-up 77.2 (1.19)
4            10. Pap Smear test 73.3 (2.37)
5                   9.Mammogram 72.6 (1.82)
6                 6.Colonoscopy 60.2 (1.41)
7              7. Sigmoidoscopy  6.1 (0.61)
8       3. Recieved flu vaccine 50.0 (1.33)
9           8. Blood stool test 14.6 (1.00)
10      5. Aspirin use-problems 11.7 (1.02)


Pradip K. Muhuri,  AHRQ/CFACT
 5600 Fishers Lane # 7N142A, Rockville, MD 20857
Tel: 301-427-1564


 


From asengupta94404 at yahoo.com  Wed Jun 15 23:46:35 2016
From: asengupta94404 at yahoo.com (Amit Sengupta)
Date: Wed, 15 Jun 2016 21:46:35 +0000 (UTC)
Subject: [R] cv.glm problem
References: <391373546.3894700.1466027195039.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <391373546.3894700.1466027195039.JavaMail.yahoo@mail.yahoo.com>

HI,I am analyzing a risk model for type 2 diabetes using a logistic regression. In the final model I have only 6 predictors. The regression gives correct output (fullmod is the fitted model). Now I have a subset of dataset (mydata1) with 7 variables (1 response(0/1) + 6 predictors) and try to do cross validation using cv.glm. The dataset mydata1 has 1410 rows and no NA entry. This is the problem I run into (It does not matter what K I choose). Any help in this matter will be appreciated.
> cv.glm(mydata1,fullmod,K=6)
Error in if ((K > n) || (K <= 1)) stop("'K' outside allowable range") : 
? missing value where TRUE/FALSE needed
Regards,Amit

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Thu Jun 16 00:37:27 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Wed, 15 Jun 2016 15:37:27 -0700
Subject: [R] dplyr's arrange function
In-Reply-To: <BN1PR09MB0305CEB2672364FBC1968A02D3550@BN1PR09MB0305.namprd09.prod.outlook.com>
References: <BN1PR09MB0305CEB2672364FBC1968A02D3550@BN1PR09MB0305.namprd09.prod.outlook.com>
Message-ID: <12ba52b4-1911-f29d-9aff-298f8e99689a@gmail.com>

On 6/15/2016 2:08 PM, Muhuri, Pradip (AHRQ/CFACT) wrote:
> Hello,
>
> I am using the dplyr's arrange() function to sort  one of the  many data frames  on a character variable (named "prevalence").
>
> Issue: I am not getting the desired output  (line 7 is the problem, which should be the very last line in the sorted data frame) because the sorted field is character, not numeric.
>
> The reproducible example and the output are appended below.
>
> Is there any work-around  to convert/treat  this character variable (named "prevalence" in the data frame below)  as numeric before using the arrange() function within the dplyr package?
>
> Any hints will be appreciated.
>
> Thanks,
>
> Pradip Muhuri
>
> # Reproducible Example
>
> library("readr")
> testdata <- read_csv(
> "indicator,  prevalence
> 1. Health check-up, 77.2 (1.19)
> 2. Blood cholesterol checked,  84.5 (1.14)
> 3. Recieved flu vaccine, 50.0 (1.33)
> 4. Blood pressure checked, 88.7 (0.88)
> 5. Aspirin use-problems, 11.7 (1.02)
> 6.Colonoscopy, 60.2 (1.41)
> 7. Sigmoidoscopy,  6.1 (0.61)
> 8. Blood stool test, 14.6 (1.00)
> 9.Mammogram,  72.6 (1.82)
> 10. Pap Smear test, 73.3 (2.37)")
>
> # Sort on the character variable in descending order
> arrange(testdata, desc(prevalence))
>
> # Results from Console
>
>                       indicator  prevalence
>                           (chr)       (chr)
> 1     4. Blood pressure checked 88.7 (0.88)
> 2  2. Blood cholesterol checked 84.5 (1.14)
> 3            1. Health check-up 77.2 (1.19)
> 4            10. Pap Smear test 73.3 (2.37)
> 5                   9.Mammogram 72.6 (1.82)
> 6                 6.Colonoscopy 60.2 (1.41)
> 7              7. Sigmoidoscopy  6.1 (0.61)
> 8       3. Recieved flu vaccine 50.0 (1.33)
> 9           8. Blood stool test 14.6 (1.00)
> 10      5. Aspirin use-problems 11.7 (1.02)
>
>
> Pradip K. Muhuri,  AHRQ/CFACT
>  5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
>
>
>

The problem is that you are sorting a character variable.

> testdata$prevalence
  [1] "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" "11.7 (1.02)"
  [6] "60.2 (1.41)" "6.1 (0.61)"  "14.6 (1.00)" "72.6 (1.82)" "73.3 (2.37)"
>

Notice that the 7th element is "6.1 (0.61)".  The first CHARACTER is a 
"6", so it is going to sort BEFORE the "50.0 (1.33)" (in descending 
order).  If you want the character value of line 7 to sort last, it 
would need to be "06.1 (0.61)" or " 6.1 (0.61)" (notice the leading space).

Hope this is helpful,

Dan

Daniel Nordlund
Port Townsend, WA USA


From drjimlemon at gmail.com  Thu Jun 16 00:50:28 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 16 Jun 2016 08:50:28 +1000
Subject: [R] benchmark-dea
In-Reply-To: <CAL3rq9i3X1_dZmJDxqxevRZpe3UTRAcgK-7yjvQ9N4-jqALKVQ@mail.gmail.com>
References: <CAL3rq9i3X1_dZmJDxqxevRZpe3UTRAcgK-7yjvQ9N4-jqALKVQ@mail.gmail.com>
Message-ID: <CA+8X3fVHjZS+DkNKVaFt+AkYcM4Ekup0Yv-Pcy6c9WfaCsAMZw@mail.gmail.com>

Hi farzana,
Probably the first thing is to ascertain what the class of "farzana" might be:

class(farzana)

Because "write.csv" expects "the object to be written, preferably a
matrix or data frame. If not, it is attempted to coerce x to a data
frame." to be the first argument. It seems that "farzana" is neither a
matrix nor a data frame and something for which there is no method to
convert it to one.

The second thing to do is to try to work out what is inside "farzana":

str(farzana)

This will produce a summary of what is in there. _Maybe_ with that
summary you can figure out how to convert it into a data frame. If
not, you can always save the object:

save(farzana,file="farzana.Rdata")

and reload it later.

Jiim


On Thu, Jun 16, 2016 at 5:47 AM, farzana akbari
<farzana.akbari2013 at gmail.com> wrote:
> in the name of God
>
>
> hi dear
>
> I  use benchmark package to use of dea  and when I wanna save my result
> as csv by this as below
>  write.csv(farzana,'D:sajjaad.csv')
>
> I can not and the error is as below
>
>
> Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors =
> stringsAsFactors) :
>   cannot coerce class ""Farrell"" to a data.frame
>
>
> what should I do ?
>
>
> best regards
> farzana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Jun 16 01:14:13 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 16 Jun 2016 09:14:13 +1000
Subject: [R] dplyr's arrange function
In-Reply-To: <BN1PR09MB0305CEB2672364FBC1968A02D3550@BN1PR09MB0305.namprd09.prod.outlook.com>
References: <BN1PR09MB0305CEB2672364FBC1968A02D3550@BN1PR09MB0305.namprd09.prod.outlook.com>
Message-ID: <CA+8X3fX4OsobodnwmtF1fs1DgmELKRA=0xpVo=Ws31oewF43Tg@mail.gmail.com>

Hi Pradip,
I'll assume that you are reading the data from a file:

pm.df<-read.csv("pmdat.txt",stringsAsFactors=FALSE)
# create a vector of numeric values of prevalence
numprev<-as.numeric(sapply(strsplit(trimws(pm.df$prevalence)," "),"[",1))
# order the data frame by that vector
pm.df[order(numprev),]

Jim


On Thu, Jun 16, 2016 at 7:08 AM, Muhuri, Pradip (AHRQ/CFACT)
<Pradip.Muhuri at ahrq.hhs.gov> wrote:
> Hello,
>
> I am using the dplyr's arrange() function to sort  one of the  many data frames  on a character variable (named "prevalence").
>
> Issue: I am not getting the desired output  (line 7 is the problem, which should be the very last line in the sorted data frame) because the sorted field is character, not numeric.
>
> The reproducible example and the output are appended below.
>
> Is there any work-around  to convert/treat  this character variable (named "prevalence" in the data frame below)  as numeric before using the arrange() function within the dplyr package?
>
> Any hints will be appreciated.
>
> Thanks,
>
> Pradip Muhuri
>
> # Reproducible Example
>
> library("readr")
> testdata <- read_csv(
> "indicator,  prevalence
> 1. Health check-up, 77.2 (1.19)
> 2. Blood cholesterol checked,  84.5 (1.14)
> 3. Recieved flu vaccine, 50.0 (1.33)
> 4. Blood pressure checked, 88.7 (0.88)
> 5. Aspirin use-problems, 11.7 (1.02)
> 6.Colonoscopy, 60.2 (1.41)
> 7. Sigmoidoscopy,  6.1 (0.61)
> 8. Blood stool test, 14.6 (1.00)
> 9.Mammogram,  72.6 (1.82)
> 10. Pap Smear test, 73.3 (2.37)")
>
> # Sort on the character variable in descending order
> arrange(testdata, desc(prevalence))
>
> # Results from Console
>
>                       indicator  prevalence
>                           (chr)       (chr)
> 1     4. Blood pressure checked 88.7 (0.88)
> 2  2. Blood cholesterol checked 84.5 (1.14)
> 3            1. Health check-up 77.2 (1.19)
> 4            10. Pap Smear test 73.3 (2.37)
> 5                   9.Mammogram 72.6 (1.82)
> 6                 6.Colonoscopy 60.2 (1.41)
> 7              7. Sigmoidoscopy  6.1 (0.61)
> 8       3. Recieved flu vaccine 50.0 (1.33)
> 9           8. Blood stool test 14.6 (1.00)
> 10      5. Aspirin use-problems 11.7 (1.02)
>
>
> Pradip K. Muhuri,  AHRQ/CFACT
>  5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jun 16 01:16:11 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 15 Jun 2016 16:16:11 -0700
Subject: [R] dplyr's  arrange function
In-Reply-To: <BN1PR09MB0305CEB2672364FBC1968A02D3550@BN1PR09MB0305.namprd09.prod.outlook.com>
References: <BN1PR09MB0305CEB2672364FBC1968A02D3550@BN1PR09MB0305.namprd09.prod.outlook.com>
Message-ID: <E8734D61-628E-4C24-824B-31FFFF52A9AF@comcast.net>


> On Jun 15, 2016, at 2:08 PM, Muhuri, Pradip (AHRQ/CFACT) <Pradip.Muhuri at ahrq.hhs.gov> wrote:
> 
> Hello,
> 
> I am using the dplyr's arrange() function to sort  one of the  many data frames  on a character variable (named "prevalence").
> 
> Issue: I am not getting the desired output  (line 7 is the problem, which should be the very last line in the sorted data frame) because the sorted field is character, not numeric. 
> 
> The reproducible example and the output are appended below. 
> 
> Is there any work-around  to convert/treat  this character variable (named "prevalence" in the data frame below)  as numeric before using the arrange() function within the dplyr package?
> 
> Any hints will be appreciated.
> 
> Thanks,
> 
> Pradip Muhuri
> 
> # Reproducible Example 
> 
> library("readr")
> testdata <- read_csv(
> "indicator,  prevalence
> 1. Health check-up, 77.2 (1.19)
> 2. Blood cholesterol checked,  84.5 (1.14)
> 3. Recieved flu vaccine, 50.0 (1.33)
> 4. Blood pressure checked, 88.7 (0.88)
> 5. Aspirin use-problems, 11.7 (1.02)
> 6.Colonoscopy, 60.2 (1.41)
> 7. Sigmoidoscopy,  6.1 (0.61)
> 8. Blood stool test, 14.6 (1.00)
> 9.Mammogram,  72.6 (1.82)
> 10. Pap Smear test, 73.3 (2.37)")
> 
> # Sort on the character variable in descending order
> arrange(testdata, desc(prevalence))
> 
> # Results from Console
> 
>                      indicator  prevalence
>                          (chr)       (chr)
> 1     4. Blood pressure checked 88.7 (0.88)
> 2  2. Blood cholesterol checked 84.5 (1.14)
> 3            1. Health check-up 77.2 (1.19)
> 4            10. Pap Smear test 73.3 (2.37)
> 5                   9.Mammogram 72.6 (1.82)
> 6                 6.Colonoscopy 60.2 (1.41)
> 7              7. Sigmoidoscopy  6.1 (0.61)
> 8       3. Recieved flu vaccine 50.0 (1.33)
> 9           8. Blood stool test 14.6 (1.00)
> 10      5. Aspirin use-problems 11.7 (1.02)

Despite the fact that the prevalence columns is not really the  mixed numeric/alpha , it still can be sorted quite easily with the very handy gtools::mixedorder function:

> > require(gtools)
> Loading required package: gtools
> > testdata[ mixedorder(testdata$prevalence), ]
>                       indicator  prevalence
> 7              7. Sigmoidoscopy  6.1 (0.61)
> 5       5. Aspirin use-problems 11.7 (1.02)
> 8           8. Blood stool test 14.6 (1.00)
> 3       3. Recieved flu vaccine 50.0 (1.33)
> 6                 6.Colonoscopy 60.2 (1.41)
> 9                   9.Mammogram 72.6 (1.82)
> 10           10. Pap Smear test 73.3 (2.37)
> 1            1. Health check-up 77.2 (1.19)
> 2  2. Blood cholesterol checked 84.5 (1.14)
> 4     4. Blood pressure checked 88.7 (0.88)

The mixedorder function splits the strings at the space boundaries and tests for numeric or alpha.

> 
> 
> Pradip K. Muhuri,  AHRQ/CFACT
> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
> 

-- 

David Winsemius
Alameda, CA, USA


From mak.hholly at gmail.com  Thu Jun 16 02:45:19 2016
From: mak.hholly at gmail.com (greg holly)
Date: Wed, 15 Jun 2016 20:45:19 -0400
Subject: [R] Fwd: help for fine mappting
In-Reply-To: <CAM9Qe4g50Jo0Wt7vvD0gfRziK0sukX_k74AAfoBpg114pcy25w@mail.gmail.com>
References: <CAM9Qe4g50Jo0Wt7vvD0gfRziK0sukX_k74AAfoBpg114pcy25w@mail.gmail.com>
Message-ID: <CAM9Qe4hc2Xzw7X0mOfCkmr98MwwMnBywuRazR8MCXH4kAWd+nQ@mail.gmail.com>

Dear all;


Unfortunately I did not get any response for my  following questions. It is
time sensitive job. I would be greatly appreciate if you give help soon.


Regards,

Greg



I am sorry for this posting. I have got help from Jim, Bert, Jeff and PIKAL
on similar issue before. I tried to modify Jim`s code to the real data but
it did not work. Now I am posting first two rows the imitation of real data
using dput() format (please see at the bottom).  I have two data sets,
data=map and data=ref. The first to rows of each data set are given below.
Data map has more than 27 million and data ref has about 560 rows.
Basically I need run two different tasks. My R codes for these task are
given below but they do not work properly. I sincerely do appreciate your
helps.



Regards,

Greg



Task 1)

For example, the first and second columns for row 1 in data ref are chr1,
6457839 and 6638389. So I need write an R code normally first look the
first row in ref (which they are chre1 6457839  and 6638389) than summing
the column of "map$post_prob" and give the number of map$snp falls between
6457839  and 6638389 that  their cumulative sum is >0.85. Then do the same
for the second, third....in ref. At the end I would like a table gave below
(need_ouput). Please notice the all value specified info in ref data file
are exist in map$CHR and map$POS columns.



Task2)

Again example, the first and second columns for row 1 in data ref are chr1,
6457839 and 6638389. So I need that R gives me the minimum map$p for the 2
chr1, 6457839 and 6638389 (as there are many snps between these regions and
would like choose the smallest one in those regions. Than do the same for
the second, third....rows in ref.



Then put the results of Task1 and Task2 into need_ouput file




#R codes modified from Jim


map2<-map[order(map$CHR, map$POS, -map$post_prob),]



                # get a field for the counts

 ref$n<-NA



                # and a field for the minimum p values

 ref$min_p<-NA



                # get the number of rows in "ref"

 nref<-dim(ref)[1]

 for(i in 1:nref) {

  CHR<- which(map2$CHR==ref$CHR[i])

  POS_start<-which(map2$POS==ref$POS_start[i])

  POS_end<-which(map2$POS==ref$POS_end[i])

  cat("CHR", "CHR"," POS_start",POS_start,"POS_end",POS_end,"\n")



                # get the range of matches

  POSrange<-range(c(CHR,POS_start,POS_end))



                # convert this to a sequence spanning all matches

  allPOS<-POSrange[1]:POSrange[2]

  ref$n[i]<-sum(map2$post_prob[allPOS] > 0.99)

  ref$min_p[i]<-min(map2$p[allPOS])

 }





      dput(map)

      structure(list(CHR = structure(c(1L, 1L), .Label = "chr1", class =
"factor"),

          snp = structure(1:2, .Label = c("rs4747841", "rs4749917"), class
= "factor"),

          Allel1 = structure(1:2, .Label = c("A", "T"), class = "factor"),

          Allel2 = structure(c(2L, 1L), .Label = c("C", "G"), class =
"factor"),

          fr = c(0.551, 0.436), effec = c(-0.0011, 0.0011), SE = c(0.0029,

          0.0029), p = c(0.7, 0.7), POS = c(9960129L, 9960259L), post_prob
= c(1.248817e-158,

          1.248817e-158)), .Names = c("CHR", "snp", "Allel1", "Allel2",

      "fr", "effec", "SE", "p", "POS", "post_prob"), class = "data.frame",
row.names = c(NA,

      -2L))





     dput(ref)

     structure(list(CHR = structure(1:2, .Label = c("chr10", "chr14"

     ), class = "factor"), POS_start = c(6457839L, 21005246L), POS_end =
c(6638389L,

     21550658L)), .Names = c("CHR", "POS_start", "POS_end"), class =
"data.frame", row.names = c(NA,

-2L))





dput(need_output)

structure(list(CHR = structure(1:2, .Label = c("chr1", "chr22"

), class = "factor"), POS = c(312127953L, 46487552L), POS_start =
c(32036927L,

45766451L), POS_end = c(3232240262, 46801601), snp = structure(1:2, .Label
= c("rs1143427",

"rs55958907"), class = "factor"), alle1l = structure(1:2, .Label = c("G",

"T"), class = "factor"), allel2 = structure(1:2, .Label = c("A",

"G"), class = "factor"), fr = c(0.278, 0.974), effec = c(0.6,

0.106), SE = c(0.015, 0.027), P = c(0.000156, 7.63e-05), post_prob =
c(0.229,

0.125), n = c(612L, 4218L)), .Names = c("CHR", "POS", "POS_start",

"POS_end", "snp", "alle1l", "allel2", "fr", "effec", "SE", "P",

"post_prob", "n"), class = "data.frame", row.names = c(NA, -2L

))

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Thu Jun 16 04:17:03 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 16 Jun 2016 02:17:03 +0000
Subject: [R] [FORGED] Re: help with r package "trip"
In-Reply-To: <646e22f3-0420-f048-f015-80e13c7d09f9@auckland.ac.nz>
References: <1162373673.16800032.1465961778324.JavaMail.zimbra@sfu.ca>
	<363523827.16806324.1465962235355.JavaMail.zimbra@sfu.ca>
	<CA+8X3fXq3PP4Bm94ZnpWA++AFp_vqgOyXqGEneG=MHKrchS63g@mail.gmail.com>
	<646e22f3-0420-f048-f015-80e13c7d09f9@auckland.ac.nz>
Message-ID: <CAAcGz9-10TDrSz3U-zEMCmehvJaqY6OqoR2e5OKnyWoBPc-vag@mail.gmail.com>

On Wed, 15 Jun 2016 at 18:51 Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 15/06/16 20:18, Jim Lemon wrote:
> > Hi Alice,
> > Have you tried creating a vector of the start position (xpos[1],ypos[1]):
> >
> > xstart<-rep(xpos[1],n)
> > ystart<-rep(ypos[1],n)
> > # where "n" is the number of subsequent positions in the trip
> > max(trackDistance(xstart,ystart,xpos[2:n],ypos[2:n],...))
> >
> > may then give you the value of the longest distance from the start. I
> > don't have the trip package or I could see if you really need to
> > replicate the start positions.
>
> Jim:  This seems to me to be somewhat off the point.  The OP was faced
> with the problem of not being able to access the function homedist().
> This function seems *not* to be exported from the trip package, and yet
> it is a *documented* function which I would assume to imply that users
> should be able to invoke it directly.
>
> It is possible that in the past the OP was dealing with a version of the
> trip package that was created before namespaces came into the picture,
> whence "exporting" was not relevant.  I would suggest that the OP
> contact the package maintainer (maintainer("trip") will give you the
> email address) and enquire as to what is going on.
>
>
This is correct, the maintainer of trip never finished the task and so it's
documented but not exported - but also the CRAN version is incorrect so
please don't use it. Apologies for this.


> In the interim, a workaround *might* be to invoke homedist() as
>
>      trip:::homedist(<whatever>)
>

Please don't do this, the current definition is incorrect. I've updated it
here but can't spend much time checking, any direct input to me is welcome
- perhaps via the Issues feature on the GitHub repository.

https://github.com/mdsumner/trip

Again, my apologies for this.

Cheers, Mike.


> Note the *triple* colon in the foregoing.  I am not at all familiar with
> the trip package so my advice should probably be taken with several
> grains of salt.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> > On Wed, Jun 15, 2016 at 1:43 PM, Alice Domalik <adomalik at sfu.ca> wrote:
> >> Hi List,
> >>
> >> I'm relatively new to R, so apologies if my question is rather
> elementary.
> >> I'm working with some bird tracking data and I would like to calculate
> the maximum distance traveled from the colony.
> >> For the maximum distance traveled, I was going to use the function
> homedist(). However, when I try to use this function I get the following
> error:
> >> Error: could not find function "homedist"
> >> Anyone know why I would get this error? I have been using other
> functions in "trip" without an issue. Is there an alternative way I can
> calculate this?
> >>
> >> Thanks in advance for any help!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From asengupta94404 at yahoo.com  Thu Jun 16 01:52:42 2016
From: asengupta94404 at yahoo.com (Amit Sengupta)
Date: Wed, 15 Jun 2016 23:52:42 +0000 (UTC)
Subject: [R] cv.binary problem
References: <257648654.3983753.1466034762036.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <257648654.3983753.1466034762036.JavaMail.yahoo@mail.yahoo.com>

HI,I am analyzing a risk model for type 2 diabetes using a logistic regression. In the final model I have only 6 predictors. The regression gives correct output (fullmod is the fitted model). Now I? try to do cross validation using cv.binary. Any help in resolving this problem will be appreciated.
> cv.binary(fullmod)
Error in sample.int(x, size, replace, prob) : invalid 'size' argument
Regards,Amit

	[[alternative HTML version deleted]]


From mp.sylvestre at gmail.com  Thu Jun 16 03:44:35 2016
From: mp.sylvestre at gmail.com (Marie-Pierre Sylvestre)
Date: Wed, 15 Jun 2016 21:44:35 -0400
Subject: [R] Package rms: c-statistic from lrm function with weights
Message-ID: <CAHrHE-TRhBMe2ZHqSt3tBuyywjD=x90D4QhAj0OJwuGZjd-uBw@mail.gmail.com>

Dear list,

I am using the lrm function from the rms package to estimate a logistic
model with weights. The c-statistic (or area under the curve) is part of
the lrm output.

To understand how the weights enter the computation of the c-statistics, I
looked at the script of lrm and lrm.fit but I am out of luck because it is
making a call to a Fortran routine and I don't know Fortran.

    z <- .Fortran("lrmfit", coef = initial, nx, 1:nx, x,
            y, offset, u = double(nvi), double(nvi * (nvi + 1)),
            double(1), n, nx, sumw, nvi, v = double(nvi * nvi),
            double(nvi), double(2 * nvi), double(nvi), integer(nvi),
            opts = opts, ftable, penmat, weights, PACKAGE = "rms")


Can somebody help me figure out how the weights from the regression are
used in the computation of the c-statistic? Here is a small example that
shows that the c-statistic computed from the rms package and using the pROC
packages are not the same (not even close) when calculated from a weighted
logistic regression.

set.seed(1233)
x <- rnorm(100)
w <- runif(100)
y <- rbinom(100, 1, .5)
require(rms)
# unweighted model
umod <- lrm(y~x)
umod$stat # c-statistic is   0.5776796
# weighted model
wmod <- lrm(y~x, weight = w)
wmod$stat # c-statistic is  0.65625
# using pROC
require(pROC)
umod2 <- glm(y~x, family = binomial)
auc(y, predict(umod2)) # 0.5769
wmod2 <- glm(y~x, weights = w, family = binomial)
auc(y, predict(wmod2)) # 0.5769

BTW results from umod and umod2 and from wmod and wmod2 are identical so
the discrepancy in c-statistics in not due to using lrm vs. glm.

Best regards,
MP

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Jun 16 09:16:17 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Jun 2016 07:16:17 +0000
Subject: [R] help for fine mappting
In-Reply-To: <CAM9Qe4g50Jo0Wt7vvD0gfRziK0sukX_k74AAfoBpg114pcy25w@mail.gmail.com>
References: <CAM9Qe4g50Jo0Wt7vvD0gfRziK0sukX_k74AAfoBpg114pcy25w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030E95@SRVEXCHMBX.precheza.cz>

Hi

From posted ref and map you cannot obtain final file need, they have nothing in common.

answers see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg holly
> Sent: Wednesday, June 15, 2016 5:21 PM
> To: r-help at r-project.org
> Subject: [R] help for fine mappting
>
> dear all;
>
>
> I am sorry for this posting. I have got help from Jim, Bert, Jeff and PIKAL
> on similar issue before. I tried to modify Jim`s code to the real data but
> it did not work. Now I am posting first two rows the imitation of real data
> using dput() format (please see at the bottom).  I have two data sets,
> data=map and data=ref. The first to rows of each data set are given below.
> Data map has more than 27 million and data ref has about 560 rows.
> Basically I need run two different tasks. My R codes for these task are
> given below but they do not work properly. I sincerely do appreciate your
> helps.
>
>
>
> Regards,
>
> Greg
>
>
>
> Task 1)
>
> For example, the first and second columns for row 1 in data ref are chr1,
> 6457839 and 6638389. So I need write an R code normally first look the
> first row in ref (which they are chre1 6457839  and 6638389) than summing
> the column of "map$post_prob" and give the number of map$snp falls
> between
> 6457839  and 6638389 that  their cumulative sum is >0.85. Then do the same
> for the second, third....in ref. At the end I would like a table gave below
> (need_ouput). Please notice the all value specified info in ref data file
> are exist in map$CHR and map$POS columns.

If I understand correctly you need to get

sel <- map$POS >= ref$POS_start & map$POS < ref$POS_end
result1 <- sum( map$post_prob[sel] )
and then check if the result is >0.85
(but in your final table post_prob is below this threshold)
compute
result2 <- length( map$post_prob[sel] )

and add the results into final table.

>
>
>
> Task2)
>
> Again example, the first and second columns for row 1 in data ref are chr1,
> 6457839 and 6638389. So I need that R gives me the minimum map$p for the
> 2
> chr1, 6457839 and 6638389 (as there are many snps between these regions
> and
> would like choose the smallest one in those regions. Than do the same for
> the second, third....rows in ref.

Your task 2 can be done alongside task1
result3 <- min( map$p[sel] )

>
>
>
> Then put the results of Task1 and Task2 into need_ouput file

Again if I understand correctly your result data frame shall have same number of rows as ref data frame. I wonder how do you want to put there POS, snp, allele... and other multiple values from map data frame? How do you want to summarise them?

Two final comments:

Do not post in HTML, you can see that the code below is rather scrammbled due to behaviour of HTML mail.
If posting some examples, it would be preferable that they can be used directly with code we are trying to find to help you solve your task. Especially if you want quick answer.

Cheers
Petr

>
>
>
>
> #R codes modified from Jim
>
>
> map2<-map[order(map$CHR, map$POS, -map$post_prob),]
>
>
>
>                 # get a field for the counts
>
>  ref$n<-NA
>
>
>
>                 # and a field for the minimum p values
>
>  ref$min_p<-NA
>
>
>
>                 # get the number of rows in "ref"
>
>  nref<-dim(ref)[1]
>
>  for(i in 1:nref) {
>
>   CHR<- which(map2$CHR==ref$CHR[i])
>
>   POS_start<-which(map2$POS==ref$POS_start[i])
>
>   POS_end<-which(map2$POS==ref$POS_end[i])
>
>   cat("CHR", "CHR"," POS_start",POS_start,"POS_end",POS_end,"\n")
>
>
>
>                 # get the range of matches
>
>   POSrange<-range(c(CHR,POS_start,POS_end))
>
>
>
>                 # convert this to a sequence spanning all matches
>
>   allPOS<-POSrange[1]:POSrange[2]
>
>   ref$n[i]<-sum(map2$post_prob[allPOS] > 0.99)
>
>   ref$min_p[i]<-min(map2$p[allPOS])
>
>  }
>
>
>
>
>
>       dput(map)
>
>       structure(list(CHR = structure(c(1L, 1L), .Label = "chr1", class =
> "factor"),
>
>           snp = structure(1:2, .Label = c("rs4747841", "rs4749917"), class
> = "factor"),
>
>           Allel1 = structure(1:2, .Label = c("A", "T"), class = "factor"),
>
>           Allel2 = structure(c(2L, 1L), .Label = c("C", "G"), class =
> "factor"),
>
>           fr = c(0.551, 0.436), effec = c(-0.0011, 0.0011), SE = c(0.0029,
>
>           0.0029), p = c(0.7, 0.7), POS = c(9960129L, 9960259L), post_prob
> = c(1.248817e-158,
>
>           1.248817e-158)), .Names = c("CHR", "snp", "Allel1", "Allel2",
>
>       "fr", "effec", "SE", "p", "POS", "post_prob"), class = "data.frame",
> row.names = c(NA,
>
>       -2L))
>
>
>
>
>
>      dput(ref)
>
>      structure(list(CHR = structure(1:2, .Label = c("chr10", "chr14"
>
>      ), class = "factor"), POS_start = c(6457839L, 21005246L), POS_end =
> c(6638389L,
>
>      21550658L)), .Names = c("CHR", "POS_start", "POS_end"), class =
> "data.frame", row.names = c(NA,
>
> -2L))
>
>
>
>
>
> dput(need_output)
>
> structure(list(CHR = structure(1:2, .Label = c("chr1", "chr22"
>
> ), class = "factor"), POS = c(312127953L, 46487552L), POS_start =
> c(32036927L,
>
> 45766451L), POS_end = c(3232240262, 46801601), snp = structure(1:2, .Label
> = c("rs1143427",
>
> "rs55958907"), class = "factor"), alle1l = structure(1:2, .Label = c("G",
>
> "T"), class = "factor"), allel2 = structure(1:2, .Label = c("A",
>
> "G"), class = "factor"), fr = c(0.278, 0.974), effec = c(0.6,
>
> 0.106), SE = c(0.015, 0.027), P = c(0.000156, 7.63e-05), post_prob =
> c(0.229,
>
> 0.125), n = c(612L, 4218L)), .Names = c("CHR", "POS", "POS_start",
>
> "POS_end", "snp", "alle1l", "allel2", "fr", "effec", "SE", "P",
>
> "post_prob", "n"), class = "data.frame", row.names = c(NA, -2L
>
> ))
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From teotjunk at hotmail.com  Thu Jun 16 10:49:23 2016
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Thu, 16 Jun 2016 16:49:23 +0800
Subject: [R] Installing Caret
Message-ID: <SNT152-W572BEA24272EBEB56017FDDF560@phx.gbl>

I am trying to install the package but am I keep getting this error messages



  installation of
package ??minqa?? had non-zero exit status

2: In install.packages("caret", repos =
"http://cran.stat.ucla.edu/") :

  installation of
package ??RcppEigen?? had non-zero exit status

3: In install.packages("caret", repos = "http://cran.stat.ucla.edu/")
:

  installation of
package ??SparseM?? had non-zero exit status

4: In install.packages("caret", repos =
"http://cran.stat.ucla.edu/") :

  installation of
package ??lme4?? had non-zero exit status

5: In install.packages("caret", repos =
"http://cran.stat.ucla.edu/") :

  installation of
package ??quantreg?? had non-zero exit status

6: In install.packages("caret", repos =
"http://cran.stat.ucla.edu/") :

  installation of
package ??pbkrtest?? had non-zero exit status

7: In install.packages("caret", repos =
"http://cran.stat.ucla.edu/") :

  installation of
package ??car?? had non-zero exit status

8: In install.packages("caret", repos =
"http://cran.stat.ucla.edu/") :

  installation of
package ??caret?? had non-zero exit status


Anyone has any idea what wrong?

Tjun Kiat


 		 	   		  
	[[alternative HTML version deleted]]


From frederic.patrizio at gmail.com  Thu Jun 16 11:10:46 2016
From: frederic.patrizio at gmail.com (Patrizio Frederic)
Date: Thu, 16 Jun 2016 11:10:46 +0200
Subject: [R] inverse table
In-Reply-To: <46166cb411f44ca8a8a865a9964e1a4a@exch-2p-mbx-t2.ads.tamu.edu>
References: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
	<46166cb411f44ca8a8a865a9964e1a4a@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CAPHoPG8SewYcKCD0C9Oh+Q=oV9V-8_DgeqB22eRS_9piRLSGpw@mail.gmail.com>

Thank you all,
David's solution is the one that matches my taste the most.

Patrizio

On Wed, Jun 15, 2016 at 8:04 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> After converting the table to a data frame, replicate each row by the
> number of observations:
>
> > ddd.df <- as.data.frame(ddd)  # as.data.frame.table does the same thing
> > ddd.new <- as.matrix(ddd.df[rep(seq_along(ddd.df[, 1]), ddd.df$Freq),
> 1:2])
> > head(ddd.new)
>     a   b
> 1   "a" "A"
> 1.1 "a" "A"
> 2   "b" "A"
> 2.1 "b" "A"
> 3   "c" "A"
> 4   "d" "A"
> > rownames(ddd.new) <- NULL # Optional - get rid of row names
> > head(ddd.new)
>      a   b
> [1,] "a" "A"
> [2,] "a" "A"
> [3,] "b" "A"
> [4,] "b" "A"
> [5,] "c" "A"
> [6,] "d" "A"
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Patrizio
> Frederic
> Sent: Wednesday, June 15, 2016 11:10 AM
> To: r-help at r-project.org
> Subject: [R] inverse table
>
> Dear R-users,
> I've a problem that puzzle me
>
> suppose I have a two way contigency  table
>
> a <- sample(al <- letters[1:10],100,T)
> b <- sample(bl <- LETTERS[1:5],100,T)
> ab <- cbind(a,b)
>
> ddd <- (xtabs(data = ab))
> ddd <- as.matrix(ddd)
>
> the question is: how do I reverse the code, thus how do I get raw data
> (object ab) from ddd?
>
> I've tried
>
> as.data.frame.table(ddd)
>
> which is not the answer I'm looking for.
> Thanks in advance,
>
> PF
>
>
>
> --
> +---------------------------------------------------------------
> | Patrizio Frederic,
> | http://morgana.unimore.it/frederic_patrizio/
> +---------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
+---------------------------------------------------------------
| Patrizio Frederic,
| http://morgana.unimore.it/frederic_patrizio/
+---------------------------------------------------------------

	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Jun 16 13:01:44 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 16 Jun 2016 19:01:44 +0800
Subject: [R] Mixed modelling course in Sydney
Message-ID: <a875d562-1e72-5ef5-270b-c4a6983266ea@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Linear Mixed Effects Models and GLMM with R. 
Frequentist and Bayesian approaches.
Where:  UNSW, Sydney, Australia
When:   18-22 July 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2016_07Sydney_GLMM_V2.pdf


Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email:highstat at highstat.com
URL:www.highstat.com


	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Thu Jun 16 13:34:04 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Thu, 16 Jun 2016 11:34:04 +0000
Subject: [R] extracting coefficients from ar() output
Message-ID: <1466076844890.54542@kent.ac.uk>

Hi everybody,

I am trying to run an AR1 model using the ar() function as shown below.

> rollingarma<-rollapply(data,width=36,function(data) ar(data,aic=TRUE))
> head(rollingarma,50)
      order ar        var.pred x.mean   aic        n.used order.max partialacf resid      method        series
 [1,] 1     0.7433347 1.382908 49.99861 Numeric,16 36     15        Numeric,15 Numeric,36 "Yule-Walker" "data"
 [2,] 1     0.7410181 1.565755 49.94778 Numeric,16 36     15        Numeric,15 Numeric,36 "Yule-Walker" "data"
 [3,] 1     0.7636966 1.660581 49.86861 Numeric,16 36     15        Numeric,15 Numeric,36 "Yule-Walker" "data"


I get the table as shown above if I use head().

How can I extract the ar coefficients from this table? I have already tried coef() and rollingarma$ar but both do not work.
What can I do?

Thanks for your help.


	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Thu Jun 16 14:13:38 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Thu, 16 Jun 2016 12:13:38 +0000 (UTC)
Subject: [R]  Y in Kohonen xyf function
In-Reply-To: <1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
	<1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>

Is there any answer?
 

 Hi all,
I have a df and I want to use supervised Self Organizing Map to do classification. I should use Kohonen library and xyf function from it. As you know the xyf function looks like this and I have problem defining my Y:

    xyf(data,Y,grid=somgrid(),rlen=100,alpha=c(0.05,0.01))
I want to do classification based on a column which shows the speed that a protocols is run, and this column is the following:

   $speed   :num 4 4 3 3 3 1 1 1 2 1 4 4 3
numbers from 1 to 4 show the speed from very fast to very slow protocols. so the property I want to be modeled is df$speed, but I don't know how should I bring it in xyf function. Does anyone know how to do that? I also added my train set ans test set: 

   dt=sort(sample(nrow(df),nrow(df)*.7))
   train=df[dt,]
   Xtraining=scale(trian)
   Xtest=scale(-trian)
   center=attr(Xtrianing,"scaled:center")
   scale=attr(Xtraining,"scaled:scale")
   xyf(Xtraining,........,grid=somgrid(10,10,"hexagonal"))


Thanks for any Help,
Elahe

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From maillists at pp.inet.fi  Thu Jun 16 14:26:59 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Thu, 16 Jun 2016 15:26:59 +0300
Subject: [R] Y in Kohonen xyf function
In-Reply-To: <840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
	<1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
	<840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <95758e53-dde9-4a86-95d8-e1538f337845@pp.inet.fi>

Hi!

Some sample data could help us to help you...

But have you read '?xyf' in order to ensure that your 'Y' is what 'xyf' 
expects it to be?

What kind of error messages do you get?

Regards,
Kimmo

16.06.2016, 15:13, ch.elahe via R-help wrote:
> Is there any answer?
>
>
> Hi all, I have a df and I want to use supervised Self Organizing Map
> to do classification. I should use Kohonen library and xyf function
> from it. As you know the xyf function looks like this and I have
> problem defining my Y:
>
> xyf(data,Y,grid=somgrid(),rlen=100,alpha=c(0.05,0.01)) I want to do
> classification based on a column which shows the speed that a
> protocols is run, and this column is the following:
>
> $speed   :num 4 4 3 3 3 1 1 1 2 1 4 4 3 numbers from 1 to 4 show the
> speed from very fast to very slow protocols. so the property I want
> to be modeled is df$speed, but I don't know how should I bring it in
> xyf function. Does anyone know how to do that? I also added my train
> set ans test set:
>
> dt=sort(sample(nrow(df),nrow(df)*.7)) train=df[dt,]
> Xtraining=scale(trian) Xtest=scale(-trian)
> center=attr(Xtrianing,"scaled:center")
> scale=attr(Xtraining,"scaled:scale")
> xyf(Xtraining,........,grid=somgrid(10,10,"hexagonal"))
>
>
> Thanks for any Help, Elahe
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>


From G.Maubach at weinwolf.de  Thu Jun 16 14:57:33 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 16 Jun 2016 14:57:33 +0200
Subject: [R] Building a binary vector out of dichotomous variables
Message-ID: <OF6A6794EB.955DBFA5-ONC1257FD4.0046CFF5-C1257FD4.00473077@lotus.hawesko.de>

Hi All,

I need to build a binary vector made of a set of dichotomous variables.

What I have so far is:

-- cut --

ds_example <-
  structure(
    list(
      year2013 = c(0, 0, 0, 1, 1, 1, 1, 0),
      year2014 = c(0,
                   0, 1, 1, 0, 0, 1, 1),
      year2015 = c(0, 1, 1, 1, 0, 1, 0, 0)
    ),
    .Names = c("year2013",
               "year2014", "year2015"),
    row.names = c(NA, 8L),
    class = "data.frame"
  )

attach(ds_example)
base <- 1000
binary_vector <- base + year2013 * 100 + year2014 * 10 + year2015
detach(ds_example)

binary_vector

ds_example <- cbind(ds_example, binary_vector)

varlist <- c("year2013", "year2014", "year2015")

base <- 10^length(varlist)

binary_vector <- NULL

for (i in 1:3) {
  binary_vector <- 
   base + 
   ds_example [[varlist[i]]] * base / (10 ^ i)
}

ds_example <- cbind(ds_example, binary_vector)

message("Wrong result!")
ds_example

-- cut --

How do I get vectors like  1000 1001 1011 1111 1100 1101 1110 1010 for 
each case?

Is there a better approach than mine?

Kind regards

Georg


From petr.pikal at precheza.cz  Thu Jun 16 15:28:49 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Jun 2016 13:28:49 +0000
Subject: [R] help for fine mappting
In-Reply-To: <CAM9Qe4gsa94-z7TN3k1Csi2OZOJ1KxyrhGw9+s8cq8MNXA+rdQ@mail.gmail.com>
References: <CAM9Qe4g50Jo0Wt7vvD0gfRziK0sukX_k74AAfoBpg114pcy25w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030E95@SRVEXCHMBX.precheza.cz>
	<CAM9Qe4gsa94-z7TN3k1Csi2OZOJ1KxyrhGw9+s8cq8MNXA+rdQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5031036@SRVEXCHMBX.precheza.cz>

Hi

Did you test my suggestions? If not, why not? If yes, in what respect they did not work?

sel <- map$POS >= ref$POS_start[1] & map$POS < ref$POS_end[1]
result1 <- sum( map$post_prob[sel] )
result2 <- length( map$post_prob[sel] )
result3 <- min( map$p[sel] )

should give you desired values. It is up to you how do you want to organise them, as from your examples I do not have faintest idea what you want to do.

And keep your responds to r help list, I cc?d it.

Cheers
Petr

From: greg holly [mailto:mak.hholly at gmail.com]
Sent: Thursday, June 16, 2016 3:06 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] help for fine mappting

Hi PIKAL;

Thanks so much your writing. I am sorry if I could not explain precisely. All information in ref file are exist in map file. So they are in common. Ref file has about 560 and map file has 27 million rows.That is CHR column common in both and all value given ref$POS_start & ref$POS_end columns  are exist in map$POS.

Thanks in advance,

Greg

On Thu, Jun 16, 2016 at 3:16 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

From posted ref and map you cannot obtain final file need, they have nothing in common.

answers see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of greg holly
> Sent: Wednesday, June 15, 2016 5:21 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] help for fine mappting
>
> dear all;
>
>
> I am sorry for this posting. I have got help from Jim, Bert, Jeff and PIKAL
> on similar issue before. I tried to modify Jim`s code to the real data but
> it did not work. Now I am posting first two rows the imitation of real data
> using dput() format (please see at the bottom).  I have two data sets,
> data=map and data=ref. The first to rows of each data set are given below.
> Data map has more than 27 million and data ref has about 560 rows.
> Basically I need run two different tasks. My R codes for these task are
> given below but they do not work properly. I sincerely do appreciate your
> helps.
>
>
>
> Regards,
>
> Greg
>
>
>
> Task 1)
>
> For example, the first and second columns for row 1 in data ref are chr1,
> 6457839 and 6638389. So I need write an R code normally first look the
> first row in ref (which they are chre1 6457839  and 6638389) than summing
> the column of "map$post_prob" and give the number of map$snp falls
> between
> 6457839  and 6638389 that  their cumulative sum is >0.85. Then do the same
> for the second, third....in ref. At the end I would like a table gave below
> (need_ouput). Please notice the all value specified info in ref data file
> are exist in map$CHR and map$POS columns.
If I understand correctly you need to get

sel <- map$POS >= ref$POS_start & map$POS < ref$POS_end
result1 <- sum( map$post_prob[sel] )
and then check if the result is >0.85
(but in your final table post_prob is below this threshold)
compute
result2 <- length( map$post_prob[sel] )

and add the results into final table.

>
>
>
> Task2)
>
> Again example, the first and second columns for row 1 in data ref are chr1,
> 6457839 and 6638389. So I need that R gives me the minimum map$p for the
> 2
> chr1, 6457839 and 6638389 (as there are many snps between these regions
> and
> would like choose the smallest one in those regions. Than do the same for
> the second, third....rows in ref.

Your task 2 can be done alongside task1
result3 <- min( map$p[sel] )

>
>
>
> Then put the results of Task1 and Task2 into need_ouput file

Again if I understand correctly your result data frame shall have same number of rows as ref data frame. I wonder how do you want to put there POS, snp, allele... and other multiple values from map data frame? How do you want to summarise them?

Two final comments:

Do not post in HTML, you can see that the code below is rather scrammbled due to behaviour of HTML mail.
If posting some examples, it would be preferable that they can be used directly with code we are trying to find to help you solve your task. Especially if you want quick answer.

Cheers
Petr

>
>
>
>
> #R codes modified from Jim
>
>
> map2<-map[order(map$CHR, map$POS, -map$post_prob),]
>
>
>
>                 # get a field for the counts
>
>  ref$n<-NA
>
>
>
>                 # and a field for the minimum p values
>
>  ref$min_p<-NA
>
>
>
>                 # get the number of rows in "ref"
>
>  nref<-dim(ref)[1]
>
>  for(i in 1:nref) {
>
>   CHR<- which(map2$CHR==ref$CHR[i])
>
>   POS_start<-which(map2$POS==ref$POS_start[i])
>
>   POS_end<-which(map2$POS==ref$POS_end[i])
>
>   cat("CHR", "CHR"," POS_start",POS_start,"POS_end",POS_end,"\n")
>
>
>
>                 # get the range of matches
>
>   POSrange<-range(c(CHR,POS_start,POS_end))
>
>
>
>                 # convert this to a sequence spanning all matches
>
>   allPOS<-POSrange[1]:POSrange[2]
>
>   ref$n[i]<-sum(map2$post_prob[allPOS] > 0.99)
>
>   ref$min_p[i]<-min(map2$p[allPOS])
>
>  }
>
>
>
>
>
>       dput(map)
>
>       structure(list(CHR = structure(c(1L, 1L), .Label = "chr1", class =
> "factor"),
>
>           snp = structure(1:2, .Label = c("rs4747841", "rs4749917"), class
> = "factor"),
>
>           Allel1 = structure(1:2, .Label = c("A", "T"), class = "factor"),
>
>           Allel2 = structure(c(2L, 1L), .Label = c("C", "G"), class =
> "factor"),
>
>           fr = c(0.551, 0.436), effec = c(-0.0011, 0.0011), SE = c(0.0029,
>
>           0.0029), p = c(0.7, 0.7), POS = c(9960129L, 9960259L), post_prob
> = c(1.248817e-158,
>
>           1.248817e-158)), .Names = c("CHR", "snp", "Allel1", "Allel2",
>
>       "fr", "effec", "SE", "p", "POS", "post_prob"), class = "data.frame",
> row.names = c(NA,
>
>       -2L))
>
>
>
>
>
>      dput(ref)
>
>      structure(list(CHR = structure(1:2, .Label = c("chr10", "chr14"
>
>      ), class = "factor"), POS_start = c(6457839L, 21005246L), POS_end =
> c(6638389L,
>
>      21550658L)), .Names = c("CHR", "POS_start", "POS_end"), class =
> "data.frame", row.names = c(NA,
>
> -2L))
>
>
>
>
>
> dput(need_output)
>
> structure(list(CHR = structure(1:2, .Label = c("chr1", "chr22"
>
> ), class = "factor"), POS = c(312127953L, 46487552L), POS_start =
> c(32036927L,
>
> 45766451L), POS_end = c(3232240262, 46801601), snp = structure(1:2, .Label
> = c("rs1143427",
>
> "rs55958907"), class = "factor"), alle1l = structure(1:2, .Label = c("G",
>
> "T"), class = "factor"), allel2 = structure(1:2, .Label = c("A",
>
> "G"), class = "factor"), fr = c(0.278, 0.974), effec = c(0.6,
>
> 0.106), SE = c(0.015, 0.027), P = c(0.000156, 7.63e-05), post_prob =
> c(0.229,
>
> 0.125), n = c(612L, 4218L)), .Names = c("CHR", "POS", "POS_start",
>
> "POS_end", "snp", "alle1l", "allel2", "fr", "effec", "SE", "P",
>
> "post_prob", "n"), class = "data.frame", row.names = c(NA, -2L
>
> ))
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.




________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From mxkuhn at gmail.com  Thu Jun 16 15:32:54 2016
From: mxkuhn at gmail.com (Max Kuhn)
Date: Thu, 16 Jun 2016 09:32:54 -0400
Subject: [R] Installing Caret
In-Reply-To: <SNT152-W572BEA24272EBEB56017FDDF560@phx.gbl>
References: <SNT152-W572BEA24272EBEB56017FDDF560@phx.gbl>
Message-ID: <CAJ9CoWkLi7f4dV+DaY25PBD0RYEveLsS-Xxy8r8Wc=nrsHEsNg@mail.gmail.com>

The problem is not with `caret. Your output says:

 > installation of package ?minqa? had non-zero exit status

`caret` has a dependency that has a dependency on `minqa`. The same is true
for `RcppEigen` and the others.

What code did you use to do the install? What OS and version or R etc?


On Thu, Jun 16, 2016 at 4:49 AM, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:

> I am trying to install the package but am I keep getting this error
> messages
>
>
>
>   installation of
> package ?minqa? had non-zero exit status
>
> 2: In install.packages("caret", repos =
> "http://cran.stat.ucla.edu/") :
>
>   installation of
> package ?RcppEigen? had non-zero exit status
>
> 3: In install.packages("caret", repos = "http://cran.stat.ucla.edu/")
> :
>
>   installation of
> package ?SparseM? had non-zero exit status
>
> 4: In install.packages("caret", repos =
> "http://cran.stat.ucla.edu/") :
>
>   installation of
> package ?lme4? had non-zero exit status
>
> 5: In install.packages("caret", repos =
> "http://cran.stat.ucla.edu/") :
>
>   installation of
> package ?quantreg? had non-zero exit status
>
> 6: In install.packages("caret", repos =
> "http://cran.stat.ucla.edu/") :
>
>   installation of
> package ?pbkrtest? had non-zero exit status
>
> 7: In install.packages("caret", repos =
> "http://cran.stat.ucla.edu/") :
>
>   installation of
> package ?car? had non-zero exit status
>
> 8: In install.packages("caret", repos =
> "http://cran.stat.ucla.edu/") :
>
>   installation of
> package ?caret? had non-zero exit status
>
>
> Anyone has any idea what wrong?
>
> Tjun Kiat
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Thu Jun 16 16:13:25 2016
From: tom at maladmin.com (Tom Wright)
Date: Thu, 16 Jun 2016 10:13:25 -0400
Subject: [R] Building a binary vector out of dichotomous variables
In-Reply-To: <OF6A6794EB.955DBFA5-ONC1257FD4.0046CFF5-C1257FD4.00473077@lotus.hawesko.de>
References: <OF6A6794EB.955DBFA5-ONC1257FD4.0046CFF5-C1257FD4.00473077@lotus.hawesko.de>
Message-ID: <CAKmUXV9FFUYygXEL7xHXS5gmUPztH1hdo0viXaTMmwMb1VJSRQ@mail.gmail.com>

Does this do what you want?

as.numeric(with(ds_example,paste(1,year2013,year2014,year2015,sep='')))

On Thu, Jun 16, 2016 at 8:57 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I need to build a binary vector made of a set of dichotomous variables.
>
> What I have so far is:
>
> -- cut --
>
> ds_example <-
>   structure(
>     list(
>       year2013 = c(0, 0, 0, 1, 1, 1, 1, 0),
>       year2014 = c(0,
>                    0, 1, 1, 0, 0, 1, 1),
>       year2015 = c(0, 1, 1, 1, 0, 1, 0, 0)
>     ),
>     .Names = c("year2013",
>                "year2014", "year2015"),
>     row.names = c(NA, 8L),
>     class = "data.frame"
>   )
>
> attach(ds_example)
> base <- 1000
> binary_vector <- base + year2013 * 100 + year2014 * 10 + year2015
> detach(ds_example)
>
> binary_vector
>
> ds_example <- cbind(ds_example, binary_vector)
>
> varlist <- c("year2013", "year2014", "year2015")
>
> base <- 10^length(varlist)
>
> binary_vector <- NULL
>
> for (i in 1:3) {
>   binary_vector <-
>    base +
>    ds_example [[varlist[i]]] * base / (10 ^ i)
> }
>
> ds_example <- cbind(ds_example, binary_vector)
>
> message("Wrong result!")
> ds_example
>
> -- cut --
>
> How do I get vectors like  1000 1001 1011 1111 1100 1101 1110 1010 for
> each case?
>
> Is there a better approach than mine?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Thu Jun 16 16:30:16 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Thu, 16 Jun 2016 14:30:16 +0000 (UTC)
Subject: [R] Y in Kohonen xyf function
In-Reply-To: <95758e53-dde9-4a86-95d8-e1538f337845@pp.inet.fi>
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
	<1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
	<840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>
	<95758e53-dde9-4a86-95d8-e1538f337845@pp.inet.fi>
Message-ID: <171290742.7409726.1466087416379.JavaMail.yahoo@mail.yahoo.com>

Hi Kimmo,

Thanks for your reply, Here is a part of my df:

 
     'data.frame':  562 obs. of 128 variables
     $ TE         :int 37 37 35 34 37 37 35 33 32 ...
     $ TR         :int 11 11 8 13 11 8 15 12 8 .....
     $ BW         :int 150 191 128 145 200 191 ........
     $speed       :int 4 4 3 3 2 1 4 1 2 3 ..........
and I want to cluster my data based on speed, to see the coming costumer's protocols fall into which speed group and I think I need to bring this speed column in Y element of xyf    


On Thursday, June 16, 2016 2:29 PM, K. Elo <maillists at pp.inet.fi> wrote:
Hi!

Some sample data could help us to help you...

But have you read '?xyf' in order to ensure that your 'Y' is what 'xyf' 
expects it to be?

What kind of error messages do you get?

Regards,
Kimmo

16.06.2016, 15:13, ch.elahe via R-help wrote:
> Is there any answer?
>
>
> Hi all, I have a df and I want to use supervised Self Organizing Map
> to do classification. I should use Kohonen library and xyf function
> from it. As you know the xyf function looks like this and I have
> problem defining my Y:
>
> xyf(data,Y,grid=somgrid(),rlen=100,alpha=c(0.05,0.01)) I want to do
> classification based on a column which shows the speed that a
> protocols is run, and this column is the following:
>
> $speed   :num 4 4 3 3 3 1 1 1 2 1 4 4 3 numbers from 1 to 4 show the
> speed from very fast to very slow protocols. so the property I want
> to be modeled is df$speed, but I don't know how should I bring it in
> xyf function. Does anyone know how to do that? I also added my train
> set ans test set:
>
> dt=sort(sample(nrow(df),nrow(df)*.7)) train=df[dt,]
> Xtraining=scale(trian) Xtest=scale(-trian)
> center=attr(Xtrianing,"scaled:center")
> scale=attr(Xtraining,"scaled:scale")
> xyf(Xtraining,........,grid=somgrid(10,10,"hexagonal"))
>
>
> Thanks for any Help, Elahe
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.

>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jun 16 16:49:17 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 16 Jun 2016 07:49:17 -0700
Subject: [R] Package rms: c-statistic from lrm function with weights
In-Reply-To: <CAHrHE-TRhBMe2ZHqSt3tBuyywjD=x90D4QhAj0OJwuGZjd-uBw@mail.gmail.com>
References: <CAHrHE-TRhBMe2ZHqSt3tBuyywjD=x90D4QhAj0OJwuGZjd-uBw@mail.gmail.com>
Message-ID: <1D915879-478E-43AA-899F-81DE65C1369B@comcast.net>


> On Jun 15, 2016, at 6:44 PM, Marie-Pierre Sylvestre <mp.sylvestre at gmail.com> wrote:
> 
> Dear list,
> 
> I am using the lrm function from the rms package to estimate a logistic
> model with weights. The c-statistic (or area under the curve) is part of
> the lrm output.
> 
> To understand how the weights enter the computation of the c-statistics, I
> looked at the script of lrm and lrm.fit but I am out of luck because it is
> making a call to a Fortran routine and I don't know Fortran.
> 
>    z <- .Fortran("lrmfit", coef = initial, nx, 1:nx, x,
>            y, offset, u = double(nvi), double(nvi * (nvi + 1)),
>            double(1), n, nx, sumw, nvi, v = double(nvi * nvi),
>            double(nvi), double(2 * nvi), double(nvi), integer(nvi),
>            opts = opts, ftable, penmat, weights, PACKAGE = "rms")
> 
> 
> Can somebody help me figure out how the weights from the regression are
> used in the computation of the c-statistic? Here is a small example that
> shows that the c-statistic computed from the rms package and using the pROC
> packages are not the same (not even close) when calculated from a weighted
> logistic regression.
> 
> set.seed(1233)
> x <- rnorm(100)
> w <- runif(100)
> y <- rbinom(100, 1, .5)
> require(rms)
> # unweighted model
> umod <- lrm(y~x)
> umod$stat # c-statistic is   0.5776796
> # weighted model
> wmod <- lrm(y~x, weight = w)
> wmod$stat # c-statistic is  0.65625
> # using pROC
> require(pROC)
> umod2 <- glm(y~x, family = binomial)
> auc(y, predict(umod2)) # 0.5769
> wmod2 <- glm(y~x, weights = w, family = binomial)
> auc(y, predict(wmod2)) # 0.5769
> 
> BTW results from umod and umod2 and from wmod and wmod2 are identical so
> the discrepancy in c-statistics in not due to using lrm vs. glm.

Your output appears to imply that the `auc` function is ignoring the weights, whereas the lrm function is honoring them. The `lrm` documentation implies these are handled as possibly fractional case weights.

-- 
David.
> 
> Best regards,
> MP
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Thu Jun 16 17:07:09 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Jun 2016 08:07:09 -0700
Subject: [R] extracting coefficients from ar() output
In-Reply-To: <1466076844890.54542@kent.ac.uk>
References: <1466076844890.54542@kent.ac.uk>
Message-ID: <CAF8bMcYtv8YfwKUQF2GnDkxDq_U=5xx+6ygDGPmADhPz1kw57Q@mail.gmail.com>

help(ar) should tell you how to get the coefficients.  If, like me, you
don't
read help files, you can use str() to look at the structure of ar's output.

> str(a <- ar(sin(1:30), aic=TRUE))
List of 14
 $ order       : int 2
 $ ar          : num [1:2] 1.011 -0.918
 $ var.pred    : num 0.0654
 $ x.mean      : num 0.00934
 $ aic         : Named num [1:15] 61.215 53.442 0 0.985 2.917 ...
  ..- attr(*, "names")= chr [1:15] "0" "1" "2" "3" ...
 $ n.used      : int 30
 $ order.max   : num 14
 $ partialacf  : num [1:14, 1, 1] 0.5273 -0.9179 -0.1824 -0.0477 -0.0393 ...
 $ resid       : num [1:30] NA NA -0.0145 -0.0734 -0.0725 ...
 $ method      : chr "Yule-Walker"
 $ series      : chr "sin(1:30)"
 $ frequency   : num 1
 $ call        : language ar(x = sin(1:30), aic = TRUE)
 $ asy.var.coef: num [1:2, 1:2] 0.00583 -0.00308 -0.00308 0.00583
 - attr(*, "class")= chr "ar"
> a$ar
[1]  1.0112512 -0.9178554




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 16, 2016 at 4:34 AM, T.Riedle <tr206 at kent.ac.uk> wrote:

> Hi everybody,
>
> I am trying to run an AR1 model using the ar() function as shown below.
>
> > rollingarma<-rollapply(data,width=36,function(data) ar(data,aic=TRUE))
> > head(rollingarma,50)
>       order ar        var.pred x.mean   aic        n.used order.max
> partialacf resid      method        series
>  [1,] 1     0.7433347 1.382908 49.99861 Numeric,16 36     15
> Numeric,15 Numeric,36 "Yule-Walker" "data"
>  [2,] 1     0.7410181 1.565755 49.94778 Numeric,16 36     15
> Numeric,15 Numeric,36 "Yule-Walker" "data"
>  [3,] 1     0.7636966 1.660581 49.86861 Numeric,16 36     15
> Numeric,15 Numeric,36 "Yule-Walker" "data"
>
>
> I get the table as shown above if I use head().
>
> How can I extract the ar coefficients from this table? I have already
> tried coef() and rollingarma$ar but both do not work.
> What can I do?
>
> Thanks for your help.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From biree2016 at gmail.com  Thu Jun 16 14:04:25 2016
From: biree2016 at gmail.com (Birhanu Worku)
Date: Thu, 16 Jun 2016 15:04:25 +0300
Subject: [R] Mplus in R
Message-ID: <CANZx+rYJmxuSyyLVt_e-fCHBQnkg_nmLod7_3Usb=AdeBnyMZQ@mail.gmail.com>

Hi everyone
why this code is not running ?
here is it;

library(MplusAutomation)
res <- mplusModeler(
  mplusObject(
    MODEL = "mpg ON wt hp; wt WITH hp;", rdata = mtcars),
  "mtcars.dat", run = 1L)
summary(res)

note that mtcars is the data in r

The out put;

"No R variables to use specified.
Selected automatically as any variable name that occurs in the MODEL or
DEFINE section.
Wrote model to: mtcars.inp
Wrote data to: mtcars.dat

Running model: mtcars.inp
System command: C:\Windows\system32\cmd.exe /c cd "C:\Users\Bira\Documents"
&& "Mplus" "mtcars.inp"
Error in getOutFileList(target, recursive, filefilter) :
  Specified target does not exist.
  Target: mtcars.out
In addition: Warning messages:
1: In prepareMplusData(df = object$rdata[i, object$usevariables], filename
= dataout,  :
  The file ?mtcars.dat? currently exists and will be overwritten
2: running command 'C:\Windows\system32\cmd.exe /c cd
"C:\Users\Bira\Documents" && "Mplus" "mtcars.inp"' had status 1
> summary(res)
Error in summary(res) : object 'res' not found"


Thank you

	[[alternative HTML version deleted]]


From Pradip.Muhuri at ahrq.hhs.gov  Thu Jun 16 15:12:00 2016
From: Pradip.Muhuri at ahrq.hhs.gov (Muhuri, Pradip (AHRQ/CFACT))
Date: Thu, 16 Jun 2016 13:12:00 +0000
Subject: [R] dplyr's arrange function - 3 solutions received - 1 New
 Question
Message-ID: <BN1PR09MB0305CC61450E93634F95E8F6D3560@BN1PR09MB0305.namprd09.prod.outlook.com>

Hello,

I got 3 solutions to my earlier code.  Thanks to the contributors.  May I bring your attention to  a new question below (with respect to David's solution)?

1) Thanks to Daniel Nordlund  for the tips - replacing leading space with a 0  in the data.

2)  Thanks to David Winsemius for  his  solution with the gtools::mixedorder function.   I  have added an argument to his.

mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE),  ]

3)  Thanks to Jim Lemon's for his  solution. I  have prepended a minus sign to reverse the order.

numprev<-as.numeric(sapply(strsplit(trimws(mydata$prevalence_c)," "),"[",1))
mydata[order(-numprev), ]


(New)Question for solution 2:

I want to keep only 2 variables  (say, indicator and prevalence_c) in the output.  Where to insert the additional code? Why does the following code fail?

> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), c(mydata$indicator, mydata$prevalence_c) ]

Error in `[.data.frame`(mydata, mixedorder(mydata$prevalence_c, decreasing = TRUE),  : 
  undefined columns selected

********************
> str(mydata)
Classes 'tbl_df', 'tbl' and 'data.frame':	10 obs. of  10 variables:
 $ indicator   : chr  "1. Health check-up" "2. Blood cholesterol checked " "3. Recieved flu vaccine" "4. Blood pressure checked" ...
 $ subgroup    : chr  "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ ...
 $ n           : num  2117 2127 2124 2135 1027 ...
 $ prevalence_c: chr  "74.7 (1.20)" "90.3 (0.89)" "51.7 (1.35)" "93.2 (0.70)" ...
 $ prevalence_p: chr  "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" ...
 $ sensitivity : chr  "87.4 (1.10)" "99.2 (0.27)" "97.0 (0.62)" "99.0 (0.27)" ...
 $ specificity : chr  "68.3 (2.80)" "58.2 (3.72)" "93.5 (0.90)" "52.7 (3.90)" ...
 $ ppv         : chr  "90.4 (0.94)" "92.8 (0.85)" "93.7 (0.87)" "94.3 (0.63)" ...
 $ npv         : chr  "61.5 (3.00)" "92.8 (2.27)" "96.9 (0.63)" "87.5 (3.27)" ...
 $ kappa       : chr  "0.536 (0.029)" "0.676 (0.032)" "0.905 (0.011)" "0.626 (0.035)" ...

Pradip K. Muhuri,  AHRQ/CFACT
 5600 Fishers Lane # 7N142A, Rockville, MD 20857
Tel: 301-427-1564


 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel Nordlund
Sent: Wednesday, June 15, 2016 6:37 PM
To: r-help at r-project.org
Subject: Re: [R] dplyr's arrange function

On 6/15/2016 2:08 PM, Muhuri, Pradip (AHRQ/CFACT) wrote:
> Hello,
>
> I am using the dplyr's arrange() function to sort  one of the  many data frames  on a character variable (named "prevalence").
>
> Issue: I am not getting the desired output  (line 7 is the problem, which should be the very last line in the sorted data frame) because the sorted field is character, not numeric.
>
> The reproducible example and the output are appended below.
>
> Is there any work-around  to convert/treat  this character variable (named "prevalence" in the data frame below)  as numeric before using the arrange() function within the dplyr package?
>
> Any hints will be appreciated.
>
> Thanks,
>
> Pradip Muhuri
>
> # Reproducible Example
>
> library("readr")
> testdata <- read_csv(
> "indicator,  prevalence
> 1. Health check-up, 77.2 (1.19)
> 2. Blood cholesterol checked,  84.5 (1.14) 3. Recieved flu vaccine, 
> 50.0 (1.33) 4. Blood pressure checked, 88.7 (0.88) 5. Aspirin 
> use-problems, 11.7 (1.02) 6.Colonoscopy, 60.2 (1.41) 7. Sigmoidoscopy,  
> 6.1 (0.61) 8. Blood stool test, 14.6 (1.00) 9.Mammogram,  72.6 (1.82) 
> 10. Pap Smear test, 73.3 (2.37)")
>
> # Sort on the character variable in descending order arrange(testdata, 
> desc(prevalence))
>
> # Results from Console
>
>                       indicator  prevalence
>                           (chr)       (chr)
> 1     4. Blood pressure checked 88.7 (0.88)
> 2  2. Blood cholesterol checked 84.5 (1.14)
> 3            1. Health check-up 77.2 (1.19)
> 4            10. Pap Smear test 73.3 (2.37)
> 5                   9.Mammogram 72.6 (1.82)
> 6                 6.Colonoscopy 60.2 (1.41)
> 7              7. Sigmoidoscopy  6.1 (0.61)
> 8       3. Recieved flu vaccine 50.0 (1.33)
> 9           8. Blood stool test 14.6 (1.00)
> 10      5. Aspirin use-problems 11.7 (1.02)
>
>
> Pradip K. Muhuri,  AHRQ/CFACT
>  5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
>
>
>

The problem is that you are sorting a character variable.

> testdata$prevalence
  [1] "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" "11.7 (1.02)"
  [6] "60.2 (1.41)" "6.1 (0.61)"  "14.6 (1.00)" "72.6 (1.82)" "73.3 (2.37)"
>

Notice that the 7th element is "6.1 (0.61)".  The first CHARACTER is a "6", so it is going to sort BEFORE the "50.0 (1.33)" (in descending order).  If you want the character value of line 7 to sort last, it would need to be "06.1 (0.61)" or " 6.1 (0.61)" (notice the leading space).

Hope this is helpful,

Dan

Daniel Nordlund
Port Townsend, WA USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Thu Jun 16 18:36:36 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 16 Jun 2016 16:36:36 +0000
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
Message-ID: <D3882005.17BCEF%macqueen1@llnl.gov>

You might want to take this question to R-sig-mac.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/15/16, 1:20 PM, "R-help on behalf of Kodalore Vijayan, Vineetha W"
<r-help-bounces at r-project.org on behalf of vwkv13 at mun.ca> wrote:

>Hi,
>
>I'm trying to write an R package that calls a Fortran subroutine on my
>Mac
>os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build and
>load the library but when I try to use it in R I get this error:
>>library(NEpidemic)
>>random_epi(variable_names)
>
>Error in .Fortran("random_epi", : "random_pi" not resolved from current
>namespace (NEpidemic).
>
>Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
>additional to useDynLib(NEpidemic). After doing that I couldn't build the
>package and it gave me another error:
>
>Error in library.dynam(lib, package, package.lib) :
>  shared object ?random_epi.so? not found
>Error: loading failed
>Execution halted
>ERROR: loading failed
>
>When I checked my src folder, there is only random_epi.o file.  How can I
>fix this issue? Any help would be much appreciated. I'm vey new to both R
>and Fortran coding, especially in package building.
>
>Thanks in advance!
>Vineetha
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jun 16 18:54:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 16 Jun 2016 09:54:16 -0700
Subject: [R] dplyr's arrange function - 3 solutions received - 1 New
	Question
In-Reply-To: <BN1PR09MB0305CC61450E93634F95E8F6D3560@BN1PR09MB0305.namprd09.prod.outlook.com>
References: <BN1PR09MB0305CC61450E93634F95E8F6D3560@BN1PR09MB0305.namprd09.prod.outlook.com>
Message-ID: <1E8741CC-8DAB-4BD1-BD81-61CBC18A27A3@comcast.net>


> On Jun 16, 2016, at 6:12 AM, Muhuri, Pradip (AHRQ/CFACT) <Pradip.Muhuri at ahrq.hhs.gov> wrote:
> 
> Hello,
> 
> I got 3 solutions to my earlier code.  Thanks to the contributors.  May I bring your attention to  a new question below (with respect to David's solution)?
> 
> 1) Thanks to Daniel Nordlund  for the tips - replacing leading space with a 0  in the data.
> 
> 2)  Thanks to David Winsemius for  his  solution with the gtools::mixedorder function.   I  have added an argument to his.
> 
> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE),  ]
> 
> 3)  Thanks to Jim Lemon's for his  solution. I  have prepended a minus sign to reverse the order.
> 
> numprev<-as.numeric(sapply(strsplit(trimws(mydata$prevalence_c)," "),"[",1))
> mydata[order(-numprev), ]
> 
> 
> (New)Question for solution 2:
> 
> I want to keep only 2 variables  (say, indicator and prevalence_c) in the output.  Where to insert the additional code? Why does the following code fail?
> 
>> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), c(mydata$indicator, mydata$prevalence_c) ]
> 


Try instead just a vector of names for the second argument to "["

 mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), 
         c("indicator", "prevalence_c") ]

> Error in `[.data.frame`(mydata, mixedorder(mydata$prevalence_c, decreasing = TRUE),  : 
>  undefined columns selected
> 
> ********************
>> str(mydata)
> Classes 'tbl_df', 'tbl' and 'data.frame':	10 obs. of  10 variables:
> $ indicator   : chr  "1. Health check-up" "2. Blood cholesterol checked " "3. Recieved flu vaccine" "4. Blood pressure checked" ...
> $ subgroup    : chr  "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ ...
> $ n           : num  2117 2127 2124 2135 1027 ...
> $ prevalence_c: chr  "74.7 (1.20)" "90.3 (0.89)" "51.7 (1.35)" "93.2 (0.70)" ...
> $ prevalence_p: chr  "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" ...
> $ sensitivity : chr  "87.4 (1.10)" "99.2 (0.27)" "97.0 (0.62)" "99.0 (0.27)" ...
> $ specificity : chr  "68.3 (2.80)" "58.2 (3.72)" "93.5 (0.90)" "52.7 (3.90)" ...
> $ ppv         : chr  "90.4 (0.94)" "92.8 (0.85)" "93.7 (0.87)" "94.3 (0.63)" ...
> $ npv         : chr  "61.5 (3.00)" "92.8 (2.27)" "96.9 (0.63)" "87.5 (3.27)" ...
> $ kappa       : chr  "0.536 (0.029)" "0.676 (0.032)" "0.905 (0.011)" "0.626 (0.035)" ...
> 
> Pradip K. Muhuri,  AHRQ/CFACT
> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
> 
> 
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel Nordlund
> Sent: Wednesday, June 15, 2016 6:37 PM
> To: r-help at r-project.org
> Subject: Re: [R] dplyr's arrange function
> 
> On 6/15/2016 2:08 PM, Muhuri, Pradip (AHRQ/CFACT) wrote:
>> Hello,
>> 
>> I am using the dplyr's arrange() function to sort  one of the  many data frames  on a character variable (named "prevalence").
>> 
>> Issue: I am not getting the desired output  (line 7 is the problem, which should be the very last line in the sorted data frame) because the sorted field is character, not numeric.
>> 
>> The reproducible example and the output are appended below.
>> 
>> Is there any work-around  to convert/treat  this character variable (named "prevalence" in the data frame below)  as numeric before using the arrange() function within the dplyr package?
>> 
>> Any hints will be appreciated.
>> 
>> Thanks,
>> 
>> Pradip Muhuri
>> 
>> # Reproducible Example
>> 
>> library("readr")
>> testdata <- read_csv(
>> "indicator,  prevalence
>> 1. Health check-up, 77.2 (1.19)
>> 2. Blood cholesterol checked,  84.5 (1.14) 3. Recieved flu vaccine, 
>> 50.0 (1.33) 4. Blood pressure checked, 88.7 (0.88) 5. Aspirin 
>> use-problems, 11.7 (1.02) 6.Colonoscopy, 60.2 (1.41) 7. Sigmoidoscopy,  
>> 6.1 (0.61) 8. Blood stool test, 14.6 (1.00) 9.Mammogram,  72.6 (1.82) 
>> 10. Pap Smear test, 73.3 (2.37)")
>> 
>> # Sort on the character variable in descending order arrange(testdata, 
>> desc(prevalence))
>> 
>> # Results from Console
>> 
>>                      indicator  prevalence
>>                          (chr)       (chr)
>> 1     4. Blood pressure checked 88.7 (0.88)
>> 2  2. Blood cholesterol checked 84.5 (1.14)
>> 3            1. Health check-up 77.2 (1.19)
>> 4            10. Pap Smear test 73.3 (2.37)
>> 5                   9.Mammogram 72.6 (1.82)
>> 6                 6.Colonoscopy 60.2 (1.41)
>> 7              7. Sigmoidoscopy  6.1 (0.61)
>> 8       3. Recieved flu vaccine 50.0 (1.33)
>> 9           8. Blood stool test 14.6 (1.00)
>> 10      5. Aspirin use-problems 11.7 (1.02)
>> 
>> 
>> Pradip K. Muhuri,  AHRQ/CFACT
>> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
>> Tel: 301-427-1564
>> 
>> 
>> 
> 
> The problem is that you are sorting a character variable.
> 
>> testdata$prevalence
>  [1] "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" "11.7 (1.02)"
>  [6] "60.2 (1.41)" "6.1 (0.61)"  "14.6 (1.00)" "72.6 (1.82)" "73.3 (2.37)"
>> 
> 
> Notice that the 7th element is "6.1 (0.61)".  The first CHARACTER is a "6", so it is going to sort BEFORE the "50.0 (1.33)" (in descending order).  If you want the character value of line 7 to sort last, it would need to be "06.1 (0.61)" or " 6.1 (0.61)" (notice the leading space).
> 
> Hope this is helpful,
> 
> Dan
> 
> Daniel Nordlund
> Port Townsend, WA USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From vwkv13 at mun.ca  Thu Jun 16 19:03:18 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Thu, 16 Jun 2016 11:03:18 -0600
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
Message-ID: <CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>

Hi Eduardo,

 Thanks for your comments. I haven't tried the way you told me. Now when I
tried, got the following error:

*** caught segfault ***
address 0x0, cause 'memory not mapped'

Traceback:
 1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
length = n), y = as.double(0, length = n), tau = as.integer(0,
length = n))
 2: out(NULL, NULL, NULL, NULL)

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:

Any suggestions?

Thanks,
Vineetha

On Wed, Jun 15, 2016 at 3:55 PM, Eduardo M. A. M.Mendes <
emammendes at gmail.com> wrote:

> Hi
>
> Have you tried to load and run the fortran code using just a wrapper
> function in R?   I do that as the first step in order to build a package.
>
> Example:   fortran sources -> rk4_mod_r.f90 ,derive_henonheilles.f90,
> poincare_section.f90
>
> a) I use R CMD SHLIB rk4_mod_r.f90 ,derive_henonheilles.f90,
> poincare_section.f90 - o poincare_section_henonheilles_rk4.so
> b) Then I write a wrapper function in R, poinc_section_henonheilles.R
> ...
>  dyn.load("poincare_section_henonheilles_rk4.so")
>
>   out<-.Fortran("section_crossing",
>                 h=as.numeric(h),
>                 nphas=as.integer(nphas),..
> ...
> c) and call the function as usual.
>
> Please note that the function called by .Fortran is the name of the
> subroutine within poincare_section.f90 and not the filename.
>
> I take the opportunity to thank R-developers for making the calling of C
> and Fortran in R very easy.
>
> I hope this helps.
>
> regards
>
> Ed
>
> PS.  If you need an example of a package using Fortran90, please check
> https://github.com/emammendes/mittagleffler
>
>
>
> On Jun 15, 2016, at 5:20 PM, Kodalore Vijayan, Vineetha W <vwkv13 at mun.ca>
> wrote:
>
> Hi,
>
> I'm trying to write an R package that calls a Fortran subroutine on my  Mac
> os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build and
> load the library but when I try to use it in R I get this error:
>
> library(NEpidemic)
> random_epi(variable_names)
>
>
> Error in .Fortran("random_epi", : "random_pi" not resolved from current
> namespace (NEpidemic).
>
> Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
> additional to useDynLib(NEpidemic). After doing that I couldn't build the
> package and it gave me another error:
>
> Error in library.dynam(lib, package, package.lib) :
>  shared object ?random_epi.so? not found
> Error: loading failed
> Execution halted
> ERROR: loading failed
>
> When I checked my src folder, there is only random_epi.o file.  How can I
> fix this issue? Any help would be much appreciated. I'm vey new to both R
> and Fortran coding, especially in package building.
>
> Thanks in advance!
> Vineetha
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From emammendes at gmail.com  Thu Jun 16 19:14:19 2016
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Thu, 16 Jun 2016 14:14:19 -0300
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
Message-ID: <CC0EAE16-33A6-4996-AA90-AA1FA9852C91@gmail.com>

Hi Vineetha

It seems that there are some problems in the Fortran code as far as allocating memory is concerned.  If you have statements such as double preciosion :: y(n)   you will need to allocate memory for the vector within the Fortran code or in the R wrapper-function.  It is hard to pinpoint the error without seeing the source files.

Cheers

Ed



> On Jun 16, 2016, at 2:03 PM, Kodalore Vijayan, Vineetha W <vwkv13 at mun.ca> wrote:
> 
> Hi Eduardo,
> 
>  Thanks for your comments. I haven't tried the way you told me. Now when I tried, got the following error:
> 
> *** caught segfault ***
> address 0x0, cause 'memory not mapped'
> 
> Traceback:
>  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),     alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,         length = n), y = as.double(0, length = n), tau = as.integer(0,         length = n))
>  2: out(NULL, NULL, NULL, NULL)
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 
> 
> Any suggestions?
> 
> Thanks,
> Vineetha
> 
> On Wed, Jun 15, 2016 at 3:55 PM, Eduardo M. A. M.Mendes <emammendes at gmail.com <mailto:emammendes at gmail.com>> wrote:
> Hi
> 
> Have you tried to load and run the fortran code using just a wrapper function in R?   I do that as the first step in order to build a package.  
> 
> Example:   fortran sources -> rk4_mod_r.f90 ,derive_henonheilles.f90, poincare_section.f90
> 
> a) I use R CMD SHLIB rk4_mod_r.f90 ,derive_henonheilles.f90, poincare_section.f90 - o poincare_section_henonheilles_rk4.so 
> b) Then I write a wrapper function in R, poinc_section_henonheilles.R
> ...
>  dyn.load("poincare_section_henonheilles_rk4.so")
>   
>   out<-.Fortran("section_crossing",
>                 h=as.numeric(h),
>                 nphas=as.integer(nphas),..
> ...
> c) and call the function as usual.
> 
> Please note that the function called by .Fortran is the name of the subroutine within poincare_section.f90 and not the filename.
> 
> I take the opportunity to thank R-developers for making the calling of C and Fortran in R very easy.   
> 
> I hope this helps.
> 
> regards
> 
> Ed
> 
> PS.  If you need an example of a package using Fortran90, please check https://github.com/emammendes/mittagleffler <https://github.com/emammendes/mittagleffler>
> 
> 
> 
>> On Jun 15, 2016, at 5:20 PM, Kodalore Vijayan, Vineetha W <vwkv13 at mun.ca <mailto:vwkv13 at mun.ca>> wrote:
>> 
>> Hi,
>> 
>> I'm trying to write an R package that calls a Fortran subroutine on my  Mac
>> os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build and
>> load the library but when I try to use it in R I get this error:
>>> library(NEpidemic)
>>> random_epi(variable_names)
>> 
>> Error in .Fortran("random_epi", : "random_pi" not resolved from current
>> namespace (NEpidemic).
>> 
>> Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
>> additional to useDynLib(NEpidemic). After doing that I couldn't build the
>> package and it gave me another error:
>> 
>> Error in library.dynam(lib, package, package.lib) :
>>  shared object ?random_epi.so? not found
>> Error: loading failed
>> Execution halted
>> ERROR: loading failed
>> 
>> When I checked my src folder, there is only random_epi.o file.  How can I
>> fix this issue? Any help would be much appreciated. I'm vey new to both R
>> and Fortran coding, especially in package building.
>> 
>> Thanks in advance!
>> Vineetha
>> 
>> 	
>> [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 


	[[alternative HTML version deleted]]


From friendly at yorku.ca  Thu Jun 16 19:36:33 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 16 Jun 2016 13:36:33 -0400
Subject: [R] inverse table
In-Reply-To: <01FD4139-8EC9-46D7-8A72-CA44ADF92C50@me.com>
References: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
	<01FD4139-8EC9-46D7-8A72-CA44ADF92C50@me.com>
Message-ID: <e5d6746f-21dd-e109-b62c-f1bd34651f8f@yorku.ca>

That function, expand.dft is in the vcdExtra package

On 6/15/2016 12:42 PM, Marc Schwartz wrote:
>
>
> There is a function called expand.dft(), which I posted some years ago, which is a modification of a prior version, posted a few years before that.
>
> The updated version is here:
>
>   https://stat.ethz.ch/pipermail/r-help/2009-January/378521.html
>
> If memory serves, that code has made its way into one or more packages on CRAN but I don't recall which at the moment.
>
> Regards,
>
> Marc Schwartz
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From friendly at yorku.ca  Thu Jun 16 19:36:33 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 16 Jun 2016 13:36:33 -0400
Subject: [R] inverse table
In-Reply-To: <01FD4139-8EC9-46D7-8A72-CA44ADF92C50@me.com>
References: <CAPHoPG9FD4eyc41RBWZUs5q1RhPjiBA0O+XrRrVf94mi0Ap3EA@mail.gmail.com>
	<01FD4139-8EC9-46D7-8A72-CA44ADF92C50@me.com>
Message-ID: <e5d6746f-21dd-e109-b62c-f1bd34651f8f@yorku.ca>

That function, expand.dft is in the vcdExtra package

On 6/15/2016 12:42 PM, Marc Schwartz wrote:
>
>
> There is a function called expand.dft(), which I posted some years ago, which is a modification of a prior version, posted a few years before that.
>
> The updated version is here:
>
>   https://stat.ethz.ch/pipermail/r-help/2009-January/378521.html
>
> If memory serves, that code has made its way into one or more packages on CRAN but I don't recall which at the moment.
>
> Regards,
>
> Marc Schwartz
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From pdalgd at gmail.com  Thu Jun 16 19:49:21 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 16 Jun 2016 19:49:21 +0200
Subject: [R] extracting coefficients from ar() output
In-Reply-To: <CAF8bMcYtv8YfwKUQF2GnDkxDq_U=5xx+6ygDGPmADhPz1kw57Q@mail.gmail.com>
References: <1466076844890.54542@kent.ac.uk>
	<CAF8bMcYtv8YfwKUQF2GnDkxDq_U=5xx+6ygDGPmADhPz1kw57Q@mail.gmail.com>
Message-ID: <BE03BC36-0DF7-4570-9A8F-DBE3A6F959FE@gmail.com>


> On 16 Jun 2016, at 17:07 , William Dunlap via R-help <r-help at r-project.org> wrote:
> 
> help(ar) should tell you how to get the coefficients.  If, like me, you
> don't
> read help files, you can use str() to look at the structure of ar's output.

Also notice that the output of rollapply is not an ar object. More likely a list of them, so  try rollingarma[[i]]$ar or maybe lapply(rollingarma, function(x)x$ar) or sapply(rollingarma, "[[", "ar") or...

> 
>> str(a <- ar(sin(1:30), aic=TRUE))
> List of 14
> $ order       : int 2
> $ ar          : num [1:2] 1.011 -0.918
> $ var.pred    : num 0.0654
> $ x.mean      : num 0.00934
> $ aic         : Named num [1:15] 61.215 53.442 0 0.985 2.917 ...
>  ..- attr(*, "names")= chr [1:15] "0" "1" "2" "3" ...
> $ n.used      : int 30
> $ order.max   : num 14
> $ partialacf  : num [1:14, 1, 1] 0.5273 -0.9179 -0.1824 -0.0477 -0.0393 ...
> $ resid       : num [1:30] NA NA -0.0145 -0.0734 -0.0725 ...
> $ method      : chr "Yule-Walker"
> $ series      : chr "sin(1:30)"
> $ frequency   : num 1
> $ call        : language ar(x = sin(1:30), aic = TRUE)
> $ asy.var.coef: num [1:2, 1:2] 0.00583 -0.00308 -0.00308 0.00583
> - attr(*, "class")= chr "ar"
>> a$ar
> [1]  1.0112512 -0.9178554
> 
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Thu, Jun 16, 2016 at 4:34 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
>> Hi everybody,
>> 
>> I am trying to run an AR1 model using the ar() function as shown below.
>> 
>>> rollingarma<-rollapply(data,width=36,function(data) ar(data,aic=TRUE))
>>> head(rollingarma,50)
>>      order ar        var.pred x.mean   aic        n.used order.max
>> partialacf resid      method        series
>> [1,] 1     0.7433347 1.382908 49.99861 Numeric,16 36     15
>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>> [2,] 1     0.7410181 1.565755 49.94778 Numeric,16 36     15
>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>> [3,] 1     0.7636966 1.660581 49.86861 Numeric,16 36     15
>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>> 
>> 
>> I get the table as shown above if I use head().
>> 
>> How can I extract the ar coefficients from this table? I have already
>> tried coef() and rollingarma$ar but both do not work.
>> What can I do?
>> 
>> Thanks for your help.
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Thu Jun 16 19:54:56 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Jun 2016 10:54:56 -0700
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
Message-ID: <CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>

>  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
 alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
 length = n), y = as.double(0, length = n), tau = as.integer(0,
 length = n))

Are you expecting that
    as.integer(0, length=n)
and
    as.double(0, length = n)
will produce vectors of length 'n'?  They do not and short inputs will
usually
cause memory misuse and crashes in the Fortran code.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 16, 2016 at 10:03 AM, Kodalore Vijayan, Vineetha W <
vwkv13 at mun.ca> wrote:

> Hi Eduardo,
>
>  Thanks for your comments. I haven't tried the way you told me. Now when I
> tried, got the following error:
>
> *** caught segfault ***
> address 0x0, cause 'memory not mapped'
>
> Traceback:
>  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
> alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
> length = n), y = as.double(0, length = n), tau = as.integer(0,
> length = n))
>  2: out(NULL, NULL, NULL, NULL)
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
>
> Any suggestions?
>
> Thanks,
> Vineetha
>
> On Wed, Jun 15, 2016 at 3:55 PM, Eduardo M. A. M.Mendes <
> emammendes at gmail.com> wrote:
>
> > Hi
> >
> > Have you tried to load and run the fortran code using just a wrapper
> > function in R?   I do that as the first step in order to build a package.
> >
> > Example:   fortran sources -> rk4_mod_r.f90 ,derive_henonheilles.f90,
> > poincare_section.f90
> >
> > a) I use R CMD SHLIB rk4_mod_r.f90 ,derive_henonheilles.f90,
> > poincare_section.f90 - o poincare_section_henonheilles_rk4.so
> > b) Then I write a wrapper function in R, poinc_section_henonheilles.R
> > ...
> >  dyn.load("poincare_section_henonheilles_rk4.so")
> >
> >   out<-.Fortran("section_crossing",
> >                 h=as.numeric(h),
> >                 nphas=as.integer(nphas),..
> > ...
> > c) and call the function as usual.
> >
> > Please note that the function called by .Fortran is the name of the
> > subroutine within poincare_section.f90 and not the filename.
> >
> > I take the opportunity to thank R-developers for making the calling of C
> > and Fortran in R very easy.
> >
> > I hope this helps.
> >
> > regards
> >
> > Ed
> >
> > PS.  If you need an example of a package using Fortran90, please check
> > https://github.com/emammendes/mittagleffler
> >
> >
> >
> > On Jun 15, 2016, at 5:20 PM, Kodalore Vijayan, Vineetha W <vwkv13 at mun.ca
> >
> > wrote:
> >
> > Hi,
> >
> > I'm trying to write an R package that calls a Fortran subroutine on my
> Mac
> > os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build and
> > load the library but when I try to use it in R I get this error:
> >
> > library(NEpidemic)
> > random_epi(variable_names)
> >
> >
> > Error in .Fortran("random_epi", : "random_pi" not resolved from current
> > namespace (NEpidemic).
> >
> > Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
> > additional to useDynLib(NEpidemic). After doing that I couldn't build the
> > package and it gave me another error:
> >
> > Error in library.dynam(lib, package, package.lib) :
> >  shared object ?random_epi.so? not found
> > Error: loading failed
> > Execution halted
> > ERROR: loading failed
> >
> > When I checked my src folder, there is only random_epi.o file.  How can I
> > fix this issue? Any help would be much appreciated. I'm vey new to both R
> > and Fortran coding, especially in package building.
> >
> > Thanks in advance!
> > Vineetha
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From emammendes at gmail.com  Thu Jun 16 20:02:59 2016
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Thu, 16 Jun 2016 15:02:59 -0300
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
	<CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
Message-ID: <F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>

Thanks  Bill for pointing this out.  I haven?t noticed it.

Vineetha, try as.double(rep(0,n)) or as.matrix(rep(0,n)),

Ed

> On Jun 16, 2016, at 2:54 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> >  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),     alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,         length = n), y = as.double(0, length = n), tau = as.integer(0,         length = n))
> 
> Are you expecting that
>     as.integer(0, length=n)
> and
>     as.double(0, length = n)
> will produce vectors of length 'n'?  They do not and short inputs will usually
> cause memory misuse and crashes in the Fortran code.
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com/>
> On Thu, Jun 16, 2016 at 10:03 AM, Kodalore Vijayan, Vineetha W <vwkv13 at mun.ca <mailto:vwkv13 at mun.ca>> wrote:
> Hi Eduardo,
> 
>  Thanks for your comments. I haven't tried the way you told me. Now when I
> tried, got the following error:
> 
> *** caught segfault ***
> address 0x0, cause 'memory not mapped'
> 
> Traceback:
>  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
> alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
> length = n), y = as.double(0, length = n), tau = as.integer(0,
> length = n))
>  2: out(NULL, NULL, NULL, NULL)
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
> 
> Any suggestions?
> 
> Thanks,
> Vineetha
> 
> On Wed, Jun 15, 2016 at 3:55 PM, Eduardo M. A. M.Mendes <
> emammendes at gmail.com <mailto:emammendes at gmail.com>> wrote:
> 
> > Hi
> >
> > Have you tried to load and run the fortran code using just a wrapper
> > function in R?   I do that as the first step in order to build a package.
> >
> > Example:   fortran sources -> rk4_mod_r.f90 ,derive_henonheilles.f90,
> > poincare_section.f90
> >
> > a) I use R CMD SHLIB rk4_mod_r.f90 ,derive_henonheilles.f90,
> > poincare_section.f90 - o poincare_section_henonheilles_rk4.so
> > b) Then I write a wrapper function in R, poinc_section_henonheilles.R
> > ...
> >  dyn.load("poincare_section_henonheilles_rk4.so")
> >
> >   out<-.Fortran("section_crossing",
> >                 h=as.numeric(h),
> >                 nphas=as.integer(nphas),..
> > ...
> > c) and call the function as usual.
> >
> > Please note that the function called by .Fortran is the name of the
> > subroutine within poincare_section.f90 and not the filename.
> >
> > I take the opportunity to thank R-developers for making the calling of C
> > and Fortran in R very easy.
> >
> > I hope this helps.
> >
> > regards
> >
> > Ed
> >
> > PS.  If you need an example of a package using Fortran90, please check
> > https://github.com/emammendes/mittagleffler <https://github.com/emammendes/mittagleffler>
> >
> >
> >
> > On Jun 15, 2016, at 5:20 PM, Kodalore Vijayan, Vineetha W <vwkv13 at mun.ca <mailto:vwkv13 at mun.ca>>
> > wrote:
> >
> > Hi,
> >
> > I'm trying to write an R package that calls a Fortran subroutine on my  Mac
> > os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build and
> > load the library but when I try to use it in R I get this error:
> >
> > library(NEpidemic)
> > random_epi(variable_names)
> >
> >
> > Error in .Fortran("random_epi", : "random_pi" not resolved from current
> > namespace (NEpidemic).
> >
> > Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
> > additional to useDynLib(NEpidemic). After doing that I couldn't build the
> > package and it gave me another error:
> >
> > Error in library.dynam(lib, package, package.lib) :
> >  shared object ?random_epi.so? not found
> > Error: loading failed
> > Execution halted
> > ERROR: loading failed
> >
> > When I checked my src folder, there is only random_epi.o file.  How can I
> > fix this issue? Any help would be much appreciated. I'm vey new to both R
> > and Fortran coding, especially in package building.
> >
> > Thanks in advance!
> > Vineetha
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From vwkv13 at mun.ca  Thu Jun 16 20:01:24 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Thu, 16 Jun 2016 12:01:24 -0600
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
	<CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
Message-ID: <CALStW+oy5ezHj7K7eF=3yWBeQGg63=SdZqv6-DFwFUbLCo-Z5w@mail.gmail.com>

Hi,

@Eduardo:  I do have statements like, double preciosion :: y(n) in my
fortran code. Will change the code and run again.

@ William :  Yes I was initializing X ,Y,and tau, each  have a vector of
length "n".

Thanks,
Vineetha

On Thu, Jun 16, 2016 at 11:54 AM, William Dunlap <wdunlap at tibco.com> wrote:

> >  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
>  alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
>  length = n), y = as.double(0, length = n), tau = as.integer(0,
>  length = n))
>
> Are you expecting that
>     as.integer(0, length=n)
> and
>     as.double(0, length = n)
> will produce vectors of length 'n'?  They do not and short inputs will
> usually
> cause memory misuse and crashes in the Fortran code.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Jun 16, 2016 at 10:03 AM, Kodalore Vijayan, Vineetha W <
> vwkv13 at mun.ca> wrote:
>
>> Hi Eduardo,
>>
>>  Thanks for your comments. I haven't tried the way you told me. Now when I
>> tried, got the following error:
>>
>> *** caught segfault ***
>> address 0x0, cause 'memory not mapped'
>>
>> Traceback:
>>  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
>> alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
>> length = n), y = as.double(0, length = n), tau = as.integer(0,
>> length = n))
>>  2: out(NULL, NULL, NULL, NULL)
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> Selection:
>>
>> Any suggestions?
>>
>> Thanks,
>> Vineetha
>>
>> On Wed, Jun 15, 2016 at 3:55 PM, Eduardo M. A. M.Mendes <
>> emammendes at gmail.com> wrote:
>>
>> > Hi
>> >
>> > Have you tried to load and run the fortran code using just a wrapper
>> > function in R?   I do that as the first step in order to build a
>> package.
>> >
>> > Example:   fortran sources -> rk4_mod_r.f90 ,derive_henonheilles.f90,
>> > poincare_section.f90
>> >
>> > a) I use R CMD SHLIB rk4_mod_r.f90 ,derive_henonheilles.f90,
>> > poincare_section.f90 - o poincare_section_henonheilles_rk4.so
>> > b) Then I write a wrapper function in R, poinc_section_henonheilles.R
>> > ...
>> >  dyn.load("poincare_section_henonheilles_rk4.so")
>> >
>> >   out<-.Fortran("section_crossing",
>> >                 h=as.numeric(h),
>> >                 nphas=as.integer(nphas),..
>> > ...
>> > c) and call the function as usual.
>> >
>> > Please note that the function called by .Fortran is the name of the
>> > subroutine within poincare_section.f90 and not the filename.
>> >
>> > I take the opportunity to thank R-developers for making the calling of C
>> > and Fortran in R very easy.
>> >
>> > I hope this helps.
>> >
>> > regards
>> >
>> > Ed
>> >
>> > PS.  If you need an example of a package using Fortran90, please check
>> > https://github.com/emammendes/mittagleffler
>> >
>> >
>> >
>> > On Jun 15, 2016, at 5:20 PM, Kodalore Vijayan, Vineetha W <
>> vwkv13 at mun.ca>
>> > wrote:
>> >
>> > Hi,
>> >
>> > I'm trying to write an R package that calls a Fortran subroutine on my
>> Mac
>> > os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build
>> and
>> > load the library but when I try to use it in R I get this error:
>> >
>> > library(NEpidemic)
>> > random_epi(variable_names)
>> >
>> >
>> > Error in .Fortran("random_epi", : "random_pi" not resolved from current
>> > namespace (NEpidemic).
>> >
>> > Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
>> > additional to useDynLib(NEpidemic). After doing that I couldn't build
>> the
>> > package and it gave me another error:
>> >
>> > Error in library.dynam(lib, package, package.lib) :
>> >  shared object ?random_epi.so? not found
>> > Error: loading failed
>> > Execution halted
>> > ERROR: loading failed
>> >
>> > When I checked my src folder, there is only random_epi.o file.  How can
>> I
>> > fix this issue? Any help would be much appreciated. I'm vey new to both
>> R
>> > and Fortran coding, especially in package building.
>> >
>> > Thanks in advance!
>> > Vineetha
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From vwkv13 at mun.ca  Thu Jun 16 20:17:56 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Thu, 16 Jun 2016 12:17:56 -0600
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
	<CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
	<F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>
Message-ID: <CALStW+pbM6CGss379hyMpM_FKwr1VMffgTkAA0eqS_OvCft-yw@mail.gmail.com>

Hi,

 Its running in R separately using dyn.load(). Thanks!

 But my original issue is still there. I still can not build my package. My
source code file name in SRC folder is "randomepi.f95" , the package name
is "NEpidemic". and the wrapper function in the R folder is "randomepi.r".
Not sure if I have to give the same file names.

$R CMD BUILD NEpidemic

> Error in library.dynam(lib, package, package.lib) :
   shared object ?randomepi.so? not found
   Error: loading failed

My namespace file has the following:

exportPattern("^[[:alpha:]]+")
export(randomepi)
useDynLib(randomepi)
import(graphics,grDevices,stats, utils)


Thanks,
Vineetha


On Thu, Jun 16, 2016 at 12:02 PM, Eduardo M. A. M.Mendes <
emammendes at gmail.com> wrote:

> Thanks  Bill for pointing this out.  I haven?t noticed it.
>
> Vineetha, try as.double(rep(0,n)) or as.matrix(rep(0,n)),
>
> Ed
>
> On Jun 16, 2016, at 2:54 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
> >  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
>  alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
>  length = n), y = as.double(0, length = n), tau = as.integer(0,
>  length = n))
>
> Are you expecting that
>     as.integer(0, length=n)
> and
>     as.double(0, length = n)
> will produce vectors of length 'n'?  They do not and short inputs will
> usually
> cause memory misuse and crashes in the Fortran code.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Jun 16, 2016 at 10:03 AM, Kodalore Vijayan, Vineetha W <
> vwkv13 at mun.ca> wrote:
>
>> Hi Eduardo,
>>
>>  Thanks for your comments. I haven't tried the way you told me. Now when I
>> tried, got the following error:
>>
>> *** caught segfault ***
>> address 0x0, cause 'memory not mapped'
>>
>> Traceback:
>>  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
>> alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
>> length = n), y = as.double(0, length = n), tau = as.integer(0,
>> length = n))
>>  2: out(NULL, NULL, NULL, NULL)
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> Selection:
>>
>> Any suggestions?
>>
>> Thanks,
>> Vineetha
>>
>> On Wed, Jun 15, 2016 at 3:55 PM, Eduardo M. A. M.Mendes <
>> emammendes at gmail.com> wrote:
>>
>> > Hi
>> >
>> > Have you tried to load and run the fortran code using just a wrapper
>> > function in R?   I do that as the first step in order to build a
>> package.
>> >
>> > Example:   fortran sources -> rk4_mod_r.f90 ,derive_henonheilles.f90,
>> > poincare_section.f90
>> >
>> > a) I use R CMD SHLIB rk4_mod_r.f90 ,derive_henonheilles.f90,
>> > poincare_section.f90 - o poincare_section_henonheilles_rk4.so
>> > b) Then I write a wrapper function in R, poinc_section_henonheilles.R
>> > ...
>> >  dyn.load("poincare_section_henonheilles_rk4.so")
>> >
>> >   out<-.Fortran("section_crossing",
>> >                 h=as.numeric(h),
>> >                 nphas=as.integer(nphas),..
>> > ...
>> > c) and call the function as usual.
>> >
>> > Please note that the function called by .Fortran is the name of the
>> > subroutine within poincare_section.f90 and not the filename.
>> >
>> > I take the opportunity to thank R-developers for making the calling of C
>> > and Fortran in R very easy.
>> >
>> > I hope this helps.
>> >
>> > regards
>> >
>> > Ed
>> >
>> > PS.  If you need an example of a package using Fortran90, please check
>> > https://github.com/emammendes/mittagleffler
>> >
>> >
>> >
>> > On Jun 15, 2016, at 5:20 PM, Kodalore Vijayan, Vineetha W <
>> vwkv13 at mun.ca>
>> > wrote:
>> >
>> > Hi,
>> >
>> > I'm trying to write an R package that calls a Fortran subroutine on my
>> Mac
>> > os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build
>> and
>> > load the library but when I try to use it in R I get this error:
>> >
>> > library(NEpidemic)
>> > random_epi(variable_names)
>> >
>> >
>> > Error in .Fortran("random_epi", : "random_pi" not resolved from current
>> > namespace (NEpidemic).
>> >
>> > Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
>> > additional to useDynLib(NEpidemic). After doing that I couldn't build
>> the
>> > package and it gave me another error:
>> >
>> > Error in library.dynam(lib, package, package.lib) :
>> >  shared object ?random_epi.so? not found
>> > Error: loading failed
>> > Execution halted
>> > ERROR: loading failed
>> >
>> > When I checked my src folder, there is only random_epi.o file.  How can
>> I
>> > fix this issue? Any help would be much appreciated. I'm vey new to both
>> R
>> > and Fortran coding, especially in package building.
>> >
>> > Thanks in advance!
>> > Vineetha
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Thu Jun 16 20:50:24 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 16 Jun 2016 20:50:24 +0200
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
	<CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
	<F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>
Message-ID: <354D2AA1-368E-4CDD-8801-66DC1CB3EBBA@xs4all.nl>


> On 16 Jun 2016, at 20:02, Eduardo M. A. M.Mendes <emammendes at gmail.com> wrote:
> 
> Thanks  Bill for pointing this out.  I haven?t noticed it.
> 
> Vineetha, try as.double(rep(0,n)) or as.matrix(rep(0,n)),
> 

Why not simply numeric(n)?

Berend Hasselman


From emammendes at gmail.com  Thu Jun 16 21:04:03 2016
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Thu, 16 Jun 2016 16:04:03 -0300
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <354D2AA1-368E-4CDD-8801-66DC1CB3EBBA@xs4all.nl>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
	<CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
	<F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>
	<354D2AA1-368E-4CDD-8801-66DC1CB3EBBA@xs4all.nl>
Message-ID: <A0CB18EC-3369-454F-92CE-D92919204FCC@gmail.com>


> On Jun 16, 2016, at 3:50 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> 
>> On 16 Jun 2016, at 20:02, Eduardo M. A. M.Mendes <emammendes at gmail.com> wrote:
>> 
>> Thanks  Bill for pointing this out.  I haven?t noticed it.
>> 
>> Vineetha, try as.double(rep(0,n)) or as.matrix(rep(0,n)),
>> 
> 
> Why not simply numeric(n)?
> 
> Berend Hasselman
> 

as.numeric(rep(0,n)) works too. Please remember that he wants a vector nor a scalar.


From bhh at xs4all.nl  Thu Jun 16 21:19:01 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 16 Jun 2016 21:19:01 +0200
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <A0CB18EC-3369-454F-92CE-D92919204FCC@gmail.com>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
	<CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
	<F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>
	<354D2AA1-368E-4CDD-8801-66DC1CB3EBBA@xs4all.nl>
	<A0CB18EC-3369-454F-92CE-D92919204FCC@gmail.com>
Message-ID: <1E277F00-4D0E-4F18-AB3C-0A2E08150033@xs4all.nl>


> On 16 Jun 2016, at 21:04, Eduardo M. A. M.Mendes <emammendes at gmail.com> wrote:
> 
> 
>> On Jun 16, 2016, at 3:50 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>> 
>> 
>>> On 16 Jun 2016, at 20:02, Eduardo M. A. M.Mendes <emammendes at gmail.com> wrote:
>>> 
>>> Thanks  Bill for pointing this out.  I haven?t noticed it.
>>> 
>>> Vineetha, try as.double(rep(0,n)) or as.matrix(rep(0,n)),
>>> 
>> 
>> Why not simply numeric(n)?
>> 
>> Berend Hasselman
>> 
> 
> as.numeric(rep(0,n)) works too. Please remember that he wants a vector nor a scalar.
> 

Indeed it does. And I certainly remembered that the OP wants a vector of length n.
But so does numeric(n), which creates a length n vector. Just try numeric(2).

Berend


From vwkv13 at mun.ca  Thu Jun 16 21:31:18 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Thu, 16 Jun 2016 13:31:18 -0600
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <1E277F00-4D0E-4F18-AB3C-0A2E08150033@xs4all.nl>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
	<CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
	<F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>
	<354D2AA1-368E-4CDD-8801-66DC1CB3EBBA@xs4all.nl>
	<A0CB18EC-3369-454F-92CE-D92919204FCC@gmail.com>
	<1E277F00-4D0E-4F18-AB3C-0A2E08150033@xs4all.nl>
Message-ID: <CALStW+rAic=HpNKAeK6zHZNnuwiiJQ10borEnSoUrxEVx+zHBg@mail.gmail.com>

Thanks for the suggestion Berend. I just tried with numeric(n) and its
working for  x and y.

But my issue is different and its not resolved yet.

-Vineetha

On Thu, Jun 16, 2016 at 1:19 PM, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> > On 16 Jun 2016, at 21:04, Eduardo M. A. M.Mendes <emammendes at gmail.com>
> wrote:
> >
> >
> >> On Jun 16, 2016, at 3:50 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
> >>
> >>
> >>> On 16 Jun 2016, at 20:02, Eduardo M. A. M.Mendes <emammendes at gmail.com>
> wrote:
> >>>
> >>> Thanks  Bill for pointing this out.  I haven?t noticed it.
> >>>
> >>> Vineetha, try as.double(rep(0,n)) or as.matrix(rep(0,n)),
> >>>
> >>
> >> Why not simply numeric(n)?
> >>
> >> Berend Hasselman
> >>
> >
> > as.numeric(rep(0,n)) works too. Please remember that he wants a vector
> nor a scalar.
> >
>
> Indeed it does. And I certainly remembered that the OP wants a vector of
> length n.
> But so does numeric(n), which creates a length n vector. Just try
> numeric(2).
>
> Berend
>
>

	[[alternative HTML version deleted]]


From vwkv13 at mun.ca  Thu Jun 16 21:33:30 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Thu, 16 Jun 2016 13:33:30 -0600
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <D3882005.17BCEF%macqueen1@llnl.gov>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<D3882005.17BCEF%macqueen1@llnl.gov>
Message-ID: <CALStW+rpE16uVq8CnnBN2xNaW6hb-42i_RA6Jn2FVdr3cY+_ow@mail.gmail.com>

Thank you Don. I did send an email to R-sig-mac.

-Vineetha

On Thu, Jun 16, 2016 at 10:36 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> You might want to take this question to R-sig-mac.
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 6/15/16, 1:20 PM, "R-help on behalf of Kodalore Vijayan, Vineetha W"
> <r-help-bounces at r-project.org on behalf of vwkv13 at mun.ca> wrote:
>
> >Hi,
> >
> >I'm trying to write an R package that calls a Fortran subroutine on my
> >Mac
> >os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build and
> >load the library but when I try to use it in R I get this error:
> >>library(NEpidemic)
> >>random_epi(variable_names)
> >
> >Error in .Fortran("random_epi", : "random_pi" not resolved from current
> >namespace (NEpidemic).
> >
> >Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
> >additional to useDynLib(NEpidemic). After doing that I couldn't build the
> >package and it gave me another error:
> >
> >Error in library.dynam(lib, package, package.lib) :
> >  shared object ?random_epi.so? not found
> >Error: loading failed
> >Execution halted
> >ERROR: loading failed
> >
> >When I checked my src folder, there is only random_epi.o file.  How can I
> >fix this issue? Any help would be much appreciated. I'm vey new to both R
> >and Fortran coding, especially in package building.
> >
> >Thanks in advance!
> >Vineetha
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From Pradip.Muhuri at ahrq.hhs.gov  Thu Jun 16 20:06:14 2016
From: Pradip.Muhuri at ahrq.hhs.gov (Muhuri, Pradip (AHRQ/CFACT))
Date: Thu, 16 Jun 2016 18:06:14 +0000
Subject: [R] dplyr's arrange function - 3 solutions received - 1 New
 Question
In-Reply-To: <1E8741CC-8DAB-4BD1-BD81-61CBC18A27A3@comcast.net>
References: <BN1PR09MB0305CC61450E93634F95E8F6D3560@BN1PR09MB0305.namprd09.prod.outlook.com>
	<1E8741CC-8DAB-4BD1-BD81-61CBC18A27A3@comcast.net>
Message-ID: <BN1PR09MB03054C4A34834307C409FEBAD3560@BN1PR09MB0305.namprd09.prod.outlook.com>

Hello David,

Your revisions to the earlier code have given me desired results.

library("gtools")
mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), c("indicator", "prevalence_c")  ]

Thanks,

Pradip


Pradip K. Muhuri,  AHRQ/CFACT
 5600 Fishers Lane # 7N142A, Rockville, MD 20857
Tel: 301-427-1564


 


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Thursday, June 16, 2016 12:54 PM
To: Muhuri, Pradip (AHRQ/CFACT)
Cc: r-help at r-project.org
Subject: Re: [R] dplyr's arrange function - 3 solutions received - 1 New Question


> On Jun 16, 2016, at 6:12 AM, Muhuri, Pradip (AHRQ/CFACT) <Pradip.Muhuri at ahrq.hhs.gov> wrote:
> 
> Hello,
> 
> I got 3 solutions to my earlier code.  Thanks to the contributors.  May I bring your attention to  a new question below (with respect to David's solution)?
> 
> 1) Thanks to Daniel Nordlund  for the tips - replacing leading space with a 0  in the data.
> 
> 2)  Thanks to David Winsemius for  his  solution with the gtools::mixedorder function.   I  have added an argument to his.
> 
> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE),  ]
> 
> 3)  Thanks to Jim Lemon's for his  solution. I  have prepended a minus sign to reverse the order.
> 
> numprev<-as.numeric(sapply(strsplit(trimws(mydata$prevalence_c)," 
> "),"[",1)) mydata[order(-numprev), ]
> 
> 
> (New)Question for solution 2:
> 
> I want to keep only 2 variables  (say, indicator and prevalence_c) in the output.  Where to insert the additional code? Why does the following code fail?
> 
>> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), 
>> c(mydata$indicator, mydata$prevalence_c) ]
> 


Try instead just a vector of names for the second argument to "["

 mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), 
         c("indicator", "prevalence_c") ]

> Error in `[.data.frame`(mydata, mixedorder(mydata$prevalence_c, decreasing = TRUE),  : 
>  undefined columns selected
> 
> ********************
>> str(mydata)
> Classes 'tbl_df', 'tbl' and 'data.frame':	10 obs. of  10 variables:
> $ indicator   : chr  "1. Health check-up" "2. Blood cholesterol checked " "3. Recieved flu vaccine" "4. Blood pressure checked" ...
> $ subgroup    : chr  "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ ...
> $ n           : num  2117 2127 2124 2135 1027 ...
> $ prevalence_c: chr  "74.7 (1.20)" "90.3 (0.89)" "51.7 (1.35)" "93.2 (0.70)" ...
> $ prevalence_p: chr  "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" ...
> $ sensitivity : chr  "87.4 (1.10)" "99.2 (0.27)" "97.0 (0.62)" "99.0 (0.27)" ...
> $ specificity : chr  "68.3 (2.80)" "58.2 (3.72)" "93.5 (0.90)" "52.7 (3.90)" ...
> $ ppv         : chr  "90.4 (0.94)" "92.8 (0.85)" "93.7 (0.87)" "94.3 (0.63)" ...
> $ npv         : chr  "61.5 (3.00)" "92.8 (2.27)" "96.9 (0.63)" "87.5 (3.27)" ...
> $ kappa       : chr  "0.536 (0.029)" "0.676 (0.032)" "0.905 (0.011)" "0.626 (0.035)" ...
> 
> Pradip K. Muhuri,  AHRQ/CFACT
> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
> 
> 
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel 
> Nordlund
> Sent: Wednesday, June 15, 2016 6:37 PM
> To: r-help at r-project.org
> Subject: Re: [R] dplyr's arrange function
> 
> On 6/15/2016 2:08 PM, Muhuri, Pradip (AHRQ/CFACT) wrote:
>> Hello,
>> 
>> I am using the dplyr's arrange() function to sort  one of the  many data frames  on a character variable (named "prevalence").
>> 
>> Issue: I am not getting the desired output  (line 7 is the problem, which should be the very last line in the sorted data frame) because the sorted field is character, not numeric.
>> 
>> The reproducible example and the output are appended below.
>> 
>> Is there any work-around  to convert/treat  this character variable (named "prevalence" in the data frame below)  as numeric before using the arrange() function within the dplyr package?
>> 
>> Any hints will be appreciated.
>> 
>> Thanks,
>> 
>> Pradip Muhuri
>> 
>> # Reproducible Example
>> 
>> library("readr")
>> testdata <- read_csv(
>> "indicator,  prevalence
>> 1. Health check-up, 77.2 (1.19)
>> 2. Blood cholesterol checked,  84.5 (1.14) 3. Recieved flu vaccine,
>> 50.0 (1.33) 4. Blood pressure checked, 88.7 (0.88) 5. Aspirin 
>> use-problems, 11.7 (1.02) 6.Colonoscopy, 60.2 (1.41) 7. 
>> Sigmoidoscopy,
>> 6.1 (0.61) 8. Blood stool test, 14.6 (1.00) 9.Mammogram,  72.6 (1.82) 
>> 10. Pap Smear test, 73.3 (2.37)")
>> 
>> # Sort on the character variable in descending order 
>> arrange(testdata,
>> desc(prevalence))
>> 
>> # Results from Console
>> 
>>                      indicator  prevalence
>>                          (chr)       (chr)
>> 1     4. Blood pressure checked 88.7 (0.88)
>> 2  2. Blood cholesterol checked 84.5 (1.14)
>> 3            1. Health check-up 77.2 (1.19)
>> 4            10. Pap Smear test 73.3 (2.37)
>> 5                   9.Mammogram 72.6 (1.82)
>> 6                 6.Colonoscopy 60.2 (1.41)
>> 7              7. Sigmoidoscopy  6.1 (0.61)
>> 8       3. Recieved flu vaccine 50.0 (1.33)
>> 9           8. Blood stool test 14.6 (1.00)
>> 10      5. Aspirin use-problems 11.7 (1.02)
>> 
>> 
>> Pradip K. Muhuri,  AHRQ/CFACT
>> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
>> Tel: 301-427-1564
>> 
>> 
>> 
> 
> The problem is that you are sorting a character variable.
> 
>> testdata$prevalence
>  [1] "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" "11.7 (1.02)"
>  [6] "60.2 (1.41)" "6.1 (0.61)"  "14.6 (1.00)" "72.6 (1.82)" "73.3 (2.37)"
>> 
> 
> Notice that the 7th element is "6.1 (0.61)".  The first CHARACTER is a "6", so it is going to sort BEFORE the "50.0 (1.33)" (in descending order).  If you want the character value of line 7 to sort last, it would need to be "06.1 (0.61)" or " 6.1 (0.61)" (notice the leading space).
> 
> Hope this is helpful,
> 
> Dan
> 
> Daniel Nordlund
> Port Townsend, WA USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mbravo at med.umich.edu  Thu Jun 16 21:34:45 2016
From: mbravo at med.umich.edu (Bravo, Mercedes)
Date: Thu, 16 Jun 2016 19:34:45 +0000
Subject: [R] maptools readShapeSpatial not working in R 3.3.0
Message-ID: <642C1CECB5C56040A52AAFDAF5EDBB60010E31DF@UHEXMBSPR03.umhs.med.umich.edu>

Hello,
I have some R code that uses readShapeSpatial in the maptools package to read a shapefile from ArcGIS.   This code worked as recently as May 2016, when I was using R version 3.2.3.  Then, R was updated to version 3.3.0. Now, when I run the same code that worked three weeks ago, I get an error:

> path      <- "W:/..../CAP_2011_blocks_repair.shp"
> shape     <- readShapeSpatial(path, IDvar="GEOID10")
Error in if (nchar(projargs) == 0) projargs <- as.character(NA) :
  missing value where TRUE/FALSE needed

Note that if I run the code above using the older version of R (3.2.3), it does not give me an error, and instead provides me with an "SpatialPolygonsDataFrame" object.

However, it is not easy for me to switch back and forth between versions of R because I work on a protected computer that does not have an internet connection or an easy mechanism for file transfer.

I am using the SpatialPolygons object as an input for subsequent analysis, so I need something of this type.

Your help would be greatly appreciated.


Regards,
Mercedes
**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Jun 16 22:06:38 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 16 Jun 2016 20:06:38 +0000
Subject: [R] maptools readShapeSpatial not working in R 3.3.0
Message-ID: <D388548B.17BD5E%macqueen1@llnl.gov>

You might want to ask about this on R-sig-geo.

I use readOGR() from the rgdal package to read shapefiles, and it is
currently working for me in R 3.3.0.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/16/16, 12:34 PM, "R-help on behalf of Bravo, Mercedes"
<r-help-bounces at r-project.org on behalf of mbravo at med.umich.edu> wrote:

>Hello,
>I have some R code that uses readShapeSpatial in the maptools package to
>read a shapefile from ArcGIS.   This code worked as recently as May 2016,
>when I was using R version 3.2.3.  Then, R was updated to version 3.3.0.
>Now, when I run the same code that worked three weeks ago, I get an error:
>
>> path      <- "W:/..../CAP_2011_blocks_repair.shp"
>> shape     <- readShapeSpatial(path, IDvar="GEOID10")
>Error in if (nchar(projargs) == 0) projargs <- as.character(NA) :
>  missing value where TRUE/FALSE needed
>
>Note that if I run the code above using the older version of R (3.2.3),
>it does not give me an error, and instead provides me with an
>"SpatialPolygonsDataFrame" object.
>
>However, it is not easy for me to switch back and forth between versions
>of R because I work on a protected computer that does not have an
>internet connection or an easy mechanism for file transfer.
>
>I am using the SpatialPolygons object as an input for subsequent
>analysis, so I need something of this type.
>
>Your help would be greatly appreciated.
>
>
>Regards,
>Mercedes
>**********************************************************
>Electronic Mail is not secure, may not be read every day, and should not
>be used for urgent or sensitive issues
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From vwkv13 at mun.ca  Thu Jun 16 23:27:08 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Thu, 16 Jun 2016 15:27:08 -0600
Subject: [R] Writing R package that call Fortran codes
In-Reply-To: <e4291898-2258-15c2-41ea-3787fef2f055@statistik.tu-dortmund.de>
References: <CALStW+qmepHZg+58q_Zd1QFNDkFKMSgroEDF-zz__coe7zs-Eg@mail.gmail.com>
	<ADAF1276-DEE0-4998-BF4A-4C1C708778EA@gmail.com>
	<CALStW+on_zQihNbc27pSsCXcb+NeNzh7kMZGQxMinnmwLMd=3A@mail.gmail.com>
	<CAF8bMcZC3+BmE1vyCWK8yNNT+7eb_mPHxUC0FwxJPZxw+FeWJA@mail.gmail.com>
	<F1F56050-0E51-4764-897D-C415BBFC954B@gmail.com>
	<CALStW+pbM6CGss379hyMpM_FKwr1VMffgTkAA0eqS_OvCft-yw@mail.gmail.com>
	<e4291898-2258-15c2-41ea-3787fef2f055@statistik.tu-dortmund.de>
Message-ID: <CALStW+r1oLgCKGRhu4bGrD4Qj6S5yPCtyZPJvBfK0peUfpt18A@mail.gmail.com>

Thanks for the comment. It resolved now. I have edited my namespace file.
-V

On Thu, Jun 16, 2016 at 3:20 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 16.06.2016 20:17, Kodalore Vijayan, Vineetha W wrote:
>
>> Hi,
>>
>>  Its running in R separately using dyn.load(). Thanks!
>>
>>  But my original issue is still there. I still can not build my package.
>> My
>> source code file name in SRC folder is "randomepi.f95" , the package name
>> is "NEpidemic". and the wrapper function in the R folder is "randomepi.r".
>> Not sure if I have to give the same file names.
>>
>> $R CMD BUILD NEpidemic
>>
>> Error in library.dynam(lib, package, package.lib) :
>>>
>>    shared object ?randomepi.so? not found
>>    Error: loading failed
>>
>> My namespace file has the following:
>>
>> exportPattern("^[[:alpha:]]+")
>> export(randomepi)
>> useDynLib(randomepi)
>>
>
> You probably need
>  useDynLib(NEpidemic)
> since the package mechanism will build a NEpidemic.so
>
> Best,
> Uwe Ligges
>
>
>
> import(graphics,grDevices,stats, utils)
>>
>>
>> Thanks,
>> Vineetha
>>
>>
>> On Thu, Jun 16, 2016 at 12:02 PM, Eduardo M. A. M.Mendes <
>> emammendes at gmail.com> wrote:
>>
>> Thanks  Bill for pointing this out.  I haven?t noticed it.
>>>
>>> Vineetha, try as.double(rep(0,n)) or as.matrix(rep(0,n)),
>>>
>>> Ed
>>>
>>> On Jun 16, 2016, at 2:54 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>
>>>  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
>>>>
>>>  alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
>>>  length = n), y = as.double(0, length = n), tau = as.integer(0,
>>>  length = n))
>>>
>>> Are you expecting that
>>>     as.integer(0, length=n)
>>> and
>>>     as.double(0, length = n)
>>> will produce vectors of length 'n'?  They do not and short inputs will
>>> usually
>>> cause memory misuse and crashes in the Fortran code.
>>>
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Thu, Jun 16, 2016 at 10:03 AM, Kodalore Vijayan, Vineetha W <
>>> vwkv13 at mun.ca> wrote:
>>>
>>> Hi Eduardo,
>>>>
>>>>  Thanks for your comments. I haven't tried the way you told me. Now
>>>> when I
>>>> tried, got the following error:
>>>>
>>>> *** caught segfault ***
>>>> address 0x0, cause 'memory not mapped'
>>>>
>>>> Traceback:
>>>>  1: .Fortran("dataxy", n = as.integer(n), tmax = as.integer(tmax),
>>>> alpha = as.double(alpha), beta = as.double(beta), x = as.double(0,
>>>> length = n), y = as.double(0, length = n), tau = as.integer(0,
>>>> length = n))
>>>>  2: out(NULL, NULL, NULL, NULL)
>>>>
>>>> Possible actions:
>>>> 1: abort (with core dump, if enabled)
>>>> 2: normal R exit
>>>> 3: exit R without saving workspace
>>>> 4: exit R saving workspace
>>>> Selection:
>>>>
>>>> Any suggestions?
>>>>
>>>> Thanks,
>>>> Vineetha
>>>>
>>>> On Wed, Jun 15, 2016 at 3:55 PM, Eduardo M. A. M.Mendes <
>>>> emammendes at gmail.com> wrote:
>>>>
>>>> Hi
>>>>>
>>>>> Have you tried to load and run the fortran code using just a wrapper
>>>>> function in R?   I do that as the first step in order to build a
>>>>>
>>>> package.
>>>>
>>>>>
>>>>> Example:   fortran sources -> rk4_mod_r.f90 ,derive_henonheilles.f90,
>>>>> poincare_section.f90
>>>>>
>>>>> a) I use R CMD SHLIB rk4_mod_r.f90 ,derive_henonheilles.f90,
>>>>> poincare_section.f90 - o poincare_section_henonheilles_rk4.so
>>>>> b) Then I write a wrapper function in R, poinc_section_henonheilles.R
>>>>> ...
>>>>>  dyn.load("poincare_section_henonheilles_rk4.so")
>>>>>
>>>>>   out<-.Fortran("section_crossing",
>>>>>                 h=as.numeric(h),
>>>>>                 nphas=as.integer(nphas),..
>>>>> ...
>>>>> c) and call the function as usual.
>>>>>
>>>>> Please note that the function called by .Fortran is the name of the
>>>>> subroutine within poincare_section.f90 and not the filename.
>>>>>
>>>>> I take the opportunity to thank R-developers for making the calling of
>>>>> C
>>>>> and Fortran in R very easy.
>>>>>
>>>>> I hope this helps.
>>>>>
>>>>> regards
>>>>>
>>>>> Ed
>>>>>
>>>>> PS.  If you need an example of a package using Fortran90, please check
>>>>> https://github.com/emammendes/mittagleffler
>>>>>
>>>>>
>>>>>
>>>>> On Jun 15, 2016, at 5:20 PM, Kodalore Vijayan, Vineetha W <
>>>>>
>>>> vwkv13 at mun.ca>
>>>>
>>>>> wrote:
>>>>>
>>>>> Hi,
>>>>>
>>>>> I'm trying to write an R package that calls a Fortran subroutine on my
>>>>>
>>>> Mac
>>>>
>>>>> os x El Capitan with Xcode 7 and gfortran 6.1, R 3.3.0.   I can build
>>>>>
>>>> and
>>>>
>>>>> load the library but when I try to use it in R I get this error:
>>>>>
>>>>> library(NEpidemic)
>>>>> random_epi(variable_names)
>>>>>
>>>>>
>>>>> Error in .Fortran("random_epi", : "random_pi" not resolved from current
>>>>> namespace (NEpidemic).
>>>>>
>>>>> Then I  tried adding useDynLib(random_epi.f95) in the NAMESPACE file,
>>>>> additional to useDynLib(NEpidemic). After doing that I couldn't build
>>>>>
>>>> the
>>>>
>>>>> package and it gave me another error:
>>>>>
>>>>> Error in library.dynam(lib, package, package.lib) :
>>>>>  shared object ?random_epi.so? not found
>>>>> Error: loading failed
>>>>> Execution halted
>>>>> ERROR: loading failed
>>>>>
>>>>> When I checked my src folder, there is only random_epi.o file.  How can
>>>>>
>>>> I
>>>>
>>>>> fix this issue? Any help would be much appreciated. I'm vey new to both
>>>>>
>>>> R
>>>>
>>>>> and Fortran coding, especially in package building.
>>>>>
>>>>> Thanks in advance!
>>>>> Vineetha
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>>
>>>> <http://www.r-project.org/posting-guide.html>
>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> <http://www.r-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From satish.vadlamani at gmail.com  Fri Jun 17 05:42:50 2016
From: satish.vadlamani at gmail.com (Satish Vadlamani)
Date: Thu, 16 Jun 2016 20:42:50 -0700
Subject: [R] what is the best way to process the following data?
Message-ID: <CAK3+11Tm5KD4qYmvoUoLBWr+OKLTQvTmffL7fHrMyvcgTBNewg@mail.gmail.com>

Hello,
I have multiple text files with the format shown below (see the two files
that I pasted below). Each file is a log of multiple steps that the system
has processed and for each step, it has shown the start time of the process
step. For example, in the data below, the filter started at
|06/16/2016|03:44:16

How to read this data so that Step 001 is one data frame, Step 002 is
another, and so on. After I do this, I will then compare the Step 001 times
with and without parallel process.

For example, the files pasted below "no_parallel_process_SLS_4.txt" and
"parallel_process_SLS_4.txt" will make it clear what I am trying to do. I
want to compare the parallel process times taken for each step with the non
parallel process times.

If there are better ways of performing this task that what I am thinking,
could you let me know? Thanks in advance.

Satish Vadlamani

>> parallel_process_file.txt

|06/16/2016|03:44:16|Step 001
|06/16/2016|03:44:16|Initialization
|06/16/2016|03:44:16|Filters
|06/16/2016|03:45:03|Split Items
|06/16/2016|03:46:20|Sort
|06/16/2016|03:46:43|Check
|06/16/2016|04:01:13|Save
|06/16/2016|04:04:35|Update preparation
|06/16/2016|04:04:36|Update comparison
|06/16/2016|04:04:38|Update
|06/16/2016|04:04:38|Update
|06/16/2016|04:06:01|Close
|06/16/2016|04:06:33|BOP processing for 7,960 items has finished
|06/16/2016|04:06:34|Step 002
|06/16/2016|04:06:35|Initialization
|06/16/2016|04:06:35|Filters
|06/16/2016|04:07:14|Split Items
|06/16/2016|04:08:57|Sort
|06/16/2016|04:09:06|Check
|06/16/2016|04:26:36|Save
|06/16/2016|04:39:29|Update preparation
|06/16/2016|04:39:31|Update comparison
|06/16/2016|04:39:43|Update
|06/16/2016|04:39:45|Update
|06/16/2016|04:44:28|Close
|06/16/2016|04:45:26|BOP processing for 8,420 items has finished
|06/16/2016|04:45:27|Step 003
|06/16/2016|04:45:27|Initialization
|06/16/2016|04:45:27|Filters
|06/16/2016|04:48:50|Split Items
|06/16/2016|04:55:15|Sort
|06/16/2016|04:55:40|Check
|06/16/2016|05:13:35|Save
|06/16/2016|05:17:34|Update preparation
|06/16/2016|05:17:34|Update comparison
|06/16/2016|05:17:36|Update
|06/16/2016|05:17:36|Update
|06/16/2016|05:19:29|Close
|06/16/2016|05:19:49|BOP processing for 8,876 items has finished
|06/16/2016|05:19:50|Step 004
|06/16/2016|05:19:50|Initialization
|06/16/2016|05:19:50|Filters
|06/16/2016|05:20:43|Split Items
|06/16/2016|05:22:14|Sort
|06/16/2016|05:22:29|Check
|06/16/2016|05:37:27|Save
|06/16/2016|05:38:43|Update preparation
|06/16/2016|05:38:44|Update comparison
|06/16/2016|05:38:45|Update
|06/16/2016|05:38:45|Update
|06/16/2016|05:39:09|Close
|06/16/2016|05:39:19|BOP processing for 5,391 items has finished
|06/16/2016|05:39:20|Step 005
|06/16/2016|05:39:20|Initialization
|06/16/2016|05:39:20|Filters
|06/16/2016|05:39:57|Split Items
|06/16/2016|05:40:21|Sort
|06/16/2016|05:40:24|Check
|06/16/2016|05:46:01|Save
|06/16/2016|05:46:54|Update preparation
|06/16/2016|05:46:54|Update comparison
|06/16/2016|05:46:54|Update
|06/16/2016|05:46:55|Update
|06/16/2016|05:47:24|Close
|06/16/2016|05:47:31|BOP processing for 3,016 items has finished
|06/16/2016|05:47:32|Step 006
|06/16/2016|05:47:32|Initialization
|06/16/2016|05:47:32|Filters
|06/16/2016|05:47:32|Update preparation
|06/16/2016|05:47:32|Update comparison
|06/16/2016|05:47:32|Update
|06/16/2016|05:47:32|Close
|06/16/2016|05:47:33|BOP processing for 0 items has finished
|06/16/2016|05:47:33|Step 007
|06/16/2016|05:47:33|Initialization
|06/16/2016|05:47:33|Filters
|06/16/2016|05:47:34|Split Items
|06/16/2016|05:47:34|Sort
|06/16/2016|05:47:34|Check
|06/16/2016|05:47:37|Save
|06/16/2016|05:47:37|Update preparation
|06/16/2016|05:47:37|Update comparison
|06/16/2016|05:47:37|Update
|06/16/2016|05:47:37|Update
|06/16/2016|05:47:37|Close
|06/16/2016|05:47:37|BOP processing for 9 items has finished
|06/16/2016|05:47:37|Step 008
|06/16/2016|05:47:37|Initialization
|06/16/2016|05:47:37|Filters
|06/16/2016|05:47:38|Update preparation
|06/16/2016|05:47:38|Update comparison
|06/16/2016|05:47:38|Update
|06/16/2016|05:47:38|Close
|06/16/2016|05:47:38|BOP processing for 0 items has finished




>> no_parallel_process_file.txt

|06/15/2016|22:52:46|Step 001
|06/15/2016|22:52:46|Initialization

|06/15/2016|22:52:46|Filters

|06/15/2016|22:54:21|Split Items

|06/15/2016|22:55:10|Sort

|06/15/2016|22:55:15|Check

|06/15/2016|23:04:43|Save

|06/15/2016|23:06:38|Update preparation

|06/15/2016|23:06:38|Update comparison

|06/15/2016|23:06:39|Update

|06/15/2016|23:06:39|Update

|06/15/2016|23:12:04|Close

|06/15/2016|23:13:16|BOP processing for 7,942 items has finished

|06/15/2016|23:13:17|Step 002
|06/15/2016|23:13:17|Initialization

|06/15/2016|23:13:17|Filters

|06/15/2016|23:16:27|Split Items

|06/15/2016|23:20:18|Sort

|06/15/2016|23:20:34|Check

|06/16/2016|00:08:08|Save

|06/16/2016|00:26:19|Update preparation

|06/16/2016|00:26:20|Update comparison

|06/16/2016|00:26:30|Update

|06/16/2016|00:26:31|Update

|06/16/2016|00:42:31|Close

|06/16/2016|00:45:09|BOP processing for 8,400 items has finished

|06/16/2016|00:45:11|Step 003
|06/16/2016|00:45:12|Initialization

|06/16/2016|00:45:12|Filters

|06/16/2016|00:53:01|Split Items

|06/16/2016|01:01:44|Sort

|06/16/2016|01:02:55|Check

|06/16/2016|01:41:40|Save

|06/16/2016|01:44:37|Update preparation

|06/16/2016|01:44:37|Update comparison

|06/16/2016|01:44:39|Update

|06/16/2016|01:44:39|Update

|06/16/2016|01:47:37|Close

|06/16/2016|01:48:07|BOP processing for 8,867 items has finished

|06/16/2016|01:48:08|Step 004
|06/16/2016|01:48:08|Initialization

|06/16/2016|01:48:08|Filters

|06/16/2016|01:49:51|Split Items

|06/16/2016|01:50:35|Sort

|06/16/2016|01:50:39|Check

|06/16/2016|01:59:12|Save

|06/16/2016|02:00:47|Update preparation

|06/16/2016|02:00:47|Update comparison

|06/16/2016|02:00:48|Update

|06/16/2016|02:00:48|Update

|06/16/2016|02:02:40|Close

|06/16/2016|02:02:55|BOP processing for 5,383 items has finished

|06/16/2016|02:02:56|Step 005
|06/16/2016|02:02:56|Initialization

|06/16/2016|02:02:56|Filters

|06/16/2016|02:03:47|Split Items

|06/16/2016|02:04:19|Sort

|06/16/2016|02:04:21|Check

|06/16/2016|02:08:08|Save

|06/16/2016|02:09:22|Update preparation

|06/16/2016|02:09:22|Update comparison

|06/16/2016|02:09:22|Update

|06/16/2016|02:09:22|Update

|06/16/2016|02:11:03|Close

|06/16/2016|02:11:14|BOP processing for 3,016 items has finished

|06/16/2016|02:11:14|Step 006
|06/16/2016|02:11:14|Initialization

|06/16/2016|02:11:14|Filters

|06/16/2016|02:11:15|Update preparation

|06/16/2016|02:11:15|Update comparison

|06/16/2016|02:11:15|Update

|06/16/2016|02:11:15|Close

|06/16/2016|02:11:15|BOP processing for 0 items has finished

|06/16/2016|02:11:15|Step 007
|06/16/2016|02:11:15|Initialization

|06/16/2016|02:11:15|Filters

|06/16/2016|02:11:17|Split Items

|06/16/2016|02:11:17|Sort

|06/16/2016|02:11:17|Check

|06/16/2016|02:11:20|Save

|06/16/2016|02:11:20|Update preparation

|06/16/2016|02:11:20|Update comparison

|06/16/2016|02:11:20|Update

|06/16/2016|02:11:20|Update

|06/16/2016|02:11:20|Close

|06/16/2016|02:11:20|BOP processing for 9 items has finished

|06/16/2016|02:11:20|Step 008
|06/16/2016|02:11:20|Initialization

|06/16/2016|02:11:21|Filters

|06/16/2016|02:11:21|Update preparation

|06/16/2016|02:11:21|Update comparison

|06/16/2016|02:11:21|Update

|06/16/2016|02:11:21|Close

|06/16/2016|02:11:21|BOP processing for 0 items has finished



-- 

Satish Vadlamani

	[[alternative HTML version deleted]]


From satish.vadlamani at gmail.com  Fri Jun 17 05:48:41 2016
From: satish.vadlamani at gmail.com (Satish Vadlamani)
Date: Thu, 16 Jun 2016 20:48:41 -0700
Subject: [R] question - how to subcribe to this list
Message-ID: <CAK3+11QEjRTX8jqeuBDL2mJ9gxqJEhztffGRzLQ+EHfGGcD4vA@mail.gmail.com>

Hello All:
I posted one question in the past and another today and hope to get the
same excellent help that I got last time.

My question is this: is there any way to subcribe to the forum so that I
can see the questions and answers posted to r-help?

Thanks,

-- 

Satish Vadlamani

	[[alternative HTML version deleted]]


From hyu0401 at hotmail.com  Fri Jun 17 08:58:03 2016
From: hyu0401 at hotmail.com (Hong Yu)
Date: Fri, 17 Jun 2016 14:58:03 +0800
Subject: [R] question - how to subcribe to this list
Message-ID: <SNT405-EAS1573B2E74A353A4F59704E9AE570@phx.gbl>


First, I am using ?Windows Live Mail?, and not able to reply with usual format.  Sorry for that.

I am a bit confused, since you can email to the list.  It seems that you have subscribed here.

In general, you can go to the official website https://www.r-project.org/.  There you follow the menu link ?mailing lists?, and then you can find the mailing groups of interest and subscribe to them.

Also, I believe on the official site, you should be able to view message histories.

HTH



From: Satish Vadlamani 
Sent: Friday, June 17, 2016 2:38 PM
To: R help 
Subject: [R] question - how to subcribe to this list

Hello All:
I posted one question in the past and another today and hope to get the
same excellent help that I got last time.

My question is this: is there any way to subcribe to the forum so that I
can see the questions and answers posted to r-help?

Thanks,

-- 

Satish Vadlamani

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From maillists at pp.inet.fi  Fri Jun 17 09:19:19 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Fri, 17 Jun 2016 10:19:19 +0300
Subject: [R] Y in Kohonen xyf function
In-Reply-To: <171290742.7409726.1466087416379.JavaMail.yahoo@mail.yahoo.com>
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
	<1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
	<840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>
	<95758e53-dde9-4a86-95d8-e1538f337845@pp.inet.fi>
	<171290742.7409726.1466087416379.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <928929ff-a9e9-3c7e-a4c1-c424e8318ef9@pp.inet.fi>

Hi again!

According to '?xyf', the function is expecting following parameters:

(1) data = a matrix, with each row representing an object.

So, please ensure that your data is a matrix

(2) Y = property that is to be modelled. In case of classification, Y is 
a matrix of zeros, with exactly one '1' in each row indicating the 
class. For prediction of continuous properties, Y is a vector. A 
combination is possible, too, but one then should take care of 
appropriate scaling.

Once again, no data frame here, but a scaled vector or a matrix.

Your could try following steps (I assume 'df' to be you data frame):

--- snip ---
set.seed(7)
training <- sample(nrow(df), 120)
Xtraining <- scale(df[training,])
Xtest <- scale(df[-training,],
                center = attr(Xtraining, "scaled:center"),
                scale = attr(Xtraining, "scaled:scale"))

xyf.df <- xyf(Xtraining,
               factor(df.classes[training]),
               grid = somgrid(5, 5, "hexagonal"))

--- snip ---

Let us know - with output, please - what happens. The point is, if this 
works, then you could try in experimenting the parameter 
'factor(df.classes[training]'. It seems to, that also here you need a 
matrix or a list as a base, not a data frame.

This might also be of interest for your: 
https://www.jstatsoft.org/article/view/v021i05/v21i05.pdf

HTH,
Kimmo

16.06.2016, 17:30, chalabi.elahe at yahoo.de wrote:
> Hi Kimmo,
>
> Thanks for your reply, Here is a part of my df:
>
>
>      'data.frame':  562 obs. of 128 variables
>      $ TE         :int 37 37 35 34 37 37 35 33 32 ...
>      $ TR         :int 11 11 8 13 11 8 15 12 8 .....
>      $ BW         :int 150 191 128 145 200 191 ........
>      $speed       :int 4 4 3 3 2 1 4 1 2 3 ..........
> and I want to cluster my data based on speed, to see the coming costumer's protocols fall into which speed group and I think I need to bring this speed column in Y element of xyf
>
>
> On Thursday, June 16, 2016 2:29 PM, K. Elo <maillists at pp.inet.fi> wrote:
> Hi!
>
> Some sample data could help us to help you...
>
> But have you read '?xyf' in order to ensure that your 'Y' is what 'xyf'
> expects it to be?
>
> What kind of error messages do you get?
>
> Regards,
> Kimmo
>
> 16.06.2016, 15:13, ch.elahe via R-help wrote:
>> Is there any answer?
>>
>>
>> Hi all, I have a df and I want to use supervised Self Organizing Map
>> to do classification. I should use Kohonen library and xyf function
>> from it. As you know the xyf function looks like this and I have
>> problem defining my Y:
>>
>> xyf(data,Y,grid=somgrid(),rlen=100,alpha=c(0.05,0.01)) I want to do
>> classification based on a column which shows the speed that a
>> protocols is run, and this column is the following:
>>
>> $speed   :num 4 4 3 3 3 1 1 1 2 1 4 4 3 numbers from 1 to 4 show the
>> speed from very fast to very slow protocols. so the property I want
>> to be modeled is df$speed, but I don't know how should I bring it in
>> xyf function. Does anyone know how to do that? I also added my train
>> set ans test set:
>>
>> dt=sort(sample(nrow(df),nrow(df)*.7)) train=df[dt,]
>> Xtraining=scale(trian) Xtest=scale(-trian)
>> center=attr(Xtrianing,"scaled:center")
>> scale=attr(Xtraining,"scaled:scale")
>> xyf(Xtraining,........,grid=somgrid(10,10,"hexagonal"))
>>
>>
>> Thanks for any Help, Elahe
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From G.Maubach at gmx.de  Fri Jun 17 09:19:10 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Fri, 17 Jun 2016 09:19:10 +0200
Subject: [R] Fw: Aw: Re: Building a binary vector out of dichotomous
 variables
References: <OF6A6794EB.955DBFA5-ONC1257FD4.0046CFF5-C1257FD4.00473077@lotus.hawesko.de>,
	<CAKmUXV9FFUYygXEL7xHXS5gmUPztH1hdo0viXaTMmwMb1VJSRQ@mail.gmail.com>,
	<trinity-cfaf84f4-dd91-4f90-840f-e3f3efb445a3-1466147759326@3capp-gmx-bs62>
Message-ID: <trinity-b7ae38c2-2816-4354-82e4-3add3bfd5351-1466147950330@3capp-gmx-bs62>

> Hi Tom,
> 
> thanks for your reply.
> 
> Yes, that's exactly what I am looking for. I did not know about the automatic type conversion in R.
> 
> #-- cut --
> ds_example <-
>   structure(
>     list(
>       year2013 = c(0, 0, 0, 1, 1, 1, 1, 0),
>       year2014 = c(0,
>                    0, 1, 1, 0, 0, 1, 1),
>       year2015 = c(0, 1, 1, 1, 0, 1, 0, 0)
>     ),
>     .Names = c("year2013",
>                "year2014", "year2015"),
>     row.names = c(NA, 8L),
>     class = "data.frame"
>   )
> 
> #-- Proposal: works!
> as.numeric(with(ds_example,paste(1,year2013,year2014,year2015,sep='')))
> 
> # I store my know-how about R in functions for later use.
> 
> #--? Putting it in a function - does not work!
> t_make_binary_vector <- function(dataset,
>                                  input_variables,
>                                  output_variable = "binary_vector") {
>   dataset[output_variable] <- "1"
>   print(dataset[output_variable])
>   
>   for (variable in input_variables) {
>     print(variable)
>     dataset[output_variable] <- paste(dataset[output_variable],
>                                       dataset[variable], 
>                                       sep='')
>   }
>   
>   # print(dataset[output_variable])
> 
>   dataset[output_variable] <- as.integer(dataset[output_variable])
>   
>   return(dataset)
> }
> 
> t_make_binary_vector(dataset = ds_example,
>                      input_variables = c("year2013", "year2014", "year2015"),
>                      output_variable = "binary_vector")
> 
> 
> #-- Doesn't work either.
> t_make_binary_vector <- function(dataset,
>                                  input_variables,
>                                  output_variable = "binary_vector") {
>   dataset[output_variable] <- as.integer(paste(1, dataset[ , input_variables], sep = ''))
> 
>   return(dataset)
> }
> 
> t_make_binary_vector(dataset = ds_example,
>                      input_variables = c("year2013", "year2014", "year2015"),
>                      output_variable = "binary_vector")
> 
> #-- cut --
> 
> Why is R taking the parameter value itself to paste it together instead of referencing the variable within the dataset?
> 
> What did I get wrong about R? How can I fix it?
> 
> Kind regards
> 
> Georg
> 
> 
> > Gesendet: Donnerstag, 16. Juni 2016 um 16:13 Uhr
> > Von: "Tom Wright" <tom at maladmin.com>
> > An: G.Maubach at weinwolf.de
> > Cc: "R. Help" <r-help at r-project.org>
> > Betreff: Re: [R] Building a binary vector out of dichotomous variables
> >
> > Does this do what you want?
> > 
> > as.numeric(with(ds_example,paste(1,year2013,year2014,year2015,sep='')))
> > 
> > On Thu, Jun 16, 2016 at 8:57 AM,  <G.Maubach at weinwolf.de> wrote:
> > > Hi All,
> > >
> > > I need to build a binary vector made of a set of dichotomous variables.
> > >
> > > What I have so far is:
> > >
> > > -- cut --
> > >
> > > ds_example <-
> > >   structure(
> > >     list(
> > >       year2013 = c(0, 0, 0, 1, 1, 1, 1, 0),
> > >       year2014 = c(0,
> > >                    0, 1, 1, 0, 0, 1, 1),
> > >       year2015 = c(0, 1, 1, 1, 0, 1, 0, 0)
> > >     ),
> > >     .Names = c("year2013",
> > >                "year2014", "year2015"),
> > >     row.names = c(NA, 8L),
> > >     class = "data.frame"
> > >   )
> > >
> > > attach(ds_example)
> > > base <- 1000
> > > binary_vector <- base + year2013 * 100 + year2014 * 10 + year2015
> > > detach(ds_example)
> > >
> > > binary_vector
> > >
> > > ds_example <- cbind(ds_example, binary_vector)
> > >
> > > varlist <- c("year2013", "year2014", "year2015")
> > >
> > > base <- 10^length(varlist)
> > >
> > > binary_vector <- NULL
> > >
> > > for (i in 1:3) {
> > >   binary_vector <-
> > >    base +
> > >    ds_example [[varlist[i]]] * base / (10 ^ i)
> > > }
> > >
> > > ds_example <- cbind(ds_example, binary_vector)
> > >
> > > message("Wrong result!")
> > > ds_example
> > >
> > > -- cut --
> > >
> > > How do I get vectors like  1000 1001 1011 1111 1100 1101 1110 1010 for
> > > each case?
> > >
> > > Is there a better approach than mine?
> > >
> > > Kind regards
> > >
> > > Georg
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From petr.pikal at precheza.cz  Fri Jun 17 10:05:22 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Jun 2016 08:05:22 +0000
Subject: [R] help for fine mappting
In-Reply-To: <CAM9Qe4gxhnviJRUL_8DOuWDFiE6gxYf_P1G1fnjY2ivMonBcSA@mail.gmail.com>
References: <CAM9Qe4g50Jo0Wt7vvD0gfRziK0sukX_k74AAfoBpg114pcy25w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5030E95@SRVEXCHMBX.precheza.cz>
	<CAM9Qe4gsa94-z7TN3k1Csi2OZOJ1KxyrhGw9+s8cq8MNXA+rdQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5031036@SRVEXCHMBX.precheza.cz>
	<CAM9Qe4gxhnviJRUL_8DOuWDFiE6gxYf_P1G1fnjY2ivMonBcSA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50311A3@SRVEXCHMBX.precheza.cz>

Hi Greg

Seems to me that spending some time with R tutorial would be way forward for you.

Something like that could work, but without some fake (but resembling real) data it is untested.

result <- data.frame(ss=rep(NA, nrow(ref)), ll= rep(NA, nrow(ref)), mm= rep(NA, nrow(ref)))

for (i in 1:nrow(ref)) {
sel <- map$ SNP_chr==ref$CHR & map$POS >= ref$POS_start[i] & map$POS < ref$POS_end[i]
result1 <- sum( map$post_prob[sel] )
result2 <- length( map$post_prob[sel] )
result3 <- min( map$p[sel] )
result[i, ] <-c(result1, result2, result3)
}

Cheers
Petr


From: greg holly [mailto:mak.hholly at gmail.com]
Sent: Thursday, June 16, 2016 10:04 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] help for fine mappting

Hi Petr;

I got chance to try your codes. Once again thanks a lot. It seems the results3 is correct after I modified the "sel" as
sel <- map$ SNP_chr==ref$CHR & map$POS >= ref$POS_start[1] & map$POS < ref$POS_end[1] in the your codes:

sel <- map$POS >= ref$POS_start[1] & map$POS < ref$POS_end[1]
result1 <- sum( map$post_prob[sel] )
result2 <- length( map$post_prob[sel] )
result3 <- min( map$p[sel] )

and results3 is output of only the dirst row in "ref"file. I need results of other rows which I have 560 rows in "ref" file. I think I need a loop which more difficult part for me as I am beginner in R. In addition I need a output at the end as follow which has 560 rows.

All the best
Greg

structure(list(CHR = structure(1:2, .Label = c("chr1", "chr22"
), class = "factor"), POS = c(312127953L, 46487552L), POS_start = c(32036927L,
45766451L), POS_end = c(3232240262<tel:%283232240262>, 46801601), snp = structure(1:2, .Label = c("rs1143427",
"rs55958907"), class = "factor"), alle1l = structure(1:2, .Label = c("G",
"T"), class = "factor"), allel2 = structure(1:2, .Label = c("A",
"G"), class = "factor"), fr = c(0.278, 0.974), effec = c(0.6,
0.106), SE = c(0.015, 0.027), P = c(0.000156, 7.63e-05), post_prob = c(0.229,
0.125), n = c(612L, 4218L)), .Names = c("CHR", "POS", "POS_start",
"POS_end", "snp", "alle1l", "allel2", "fr", "effec", "SE", "P",
"post_prob", "n"), class = "data.frame", row.names = c(NA, -2L
))

On Thu, Jun 16, 2016 at 9:28 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Did you test my suggestions? If not, why not? If yes, in what respect they did not work?

sel <- map$POS >= ref$POS_start[1] & map$POS < ref$POS_end[1]
result1 <- sum( map$post_prob[sel] )
result2 <- length( map$post_prob[sel] )
result3 <- min( map$p[sel] )

should give you desired values. It is up to you how do you want to organise them, as from your examples I do not have faintest idea what you want to do.

And keep your responds to r help list, I cc?d it.

Cheers
Petr

From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
Sent: Thursday, June 16, 2016 3:06 PM
To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Subject: Re: [R] help for fine mappting

Hi PIKAL;

Thanks so much your writing. I am sorry if I could not explain precisely. All information in ref file are exist in map file. So they are in common. Ref file has about 560 and map file has 27 million rows.That is CHR column common in both and all value given ref$POS_start & ref$POS_end columns  are exist in map$POS.

Thanks in advance,

Greg

On Thu, Jun 16, 2016 at 3:16 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

From posted ref and map you cannot obtain final file need, they have nothing in common.

answers see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of greg holly
> Sent: Wednesday, June 15, 2016 5:21 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] help for fine mappting
>
> dear all;
>
>
> I am sorry for this posting. I have got help from Jim, Bert, Jeff and PIKAL
> on similar issue before. I tried to modify Jim`s code to the real data but
> it did not work. Now I am posting first two rows the imitation of real data
> using dput() format (please see at the bottom).  I have two data sets,
> data=map and data=ref. The first to rows of each data set are given below.
> Data map has more than 27 million and data ref has about 560 rows.
> Basically I need run two different tasks. My R codes for these task are
> given below but they do not work properly. I sincerely do appreciate your
> helps.
>
>
>
> Regards,
>
> Greg
>
>
>
> Task 1)
>
> For example, the first and second columns for row 1 in data ref are chr1,
> 6457839 and 6638389. So I need write an R code normally first look the
> first row in ref (which they are chre1 6457839  and 6638389) than summing
> the column of "map$post_prob" and give the number of map$snp falls
> between
> 6457839  and 6638389 that  their cumulative sum is >0.85. Then do the same
> for the second, third....in ref. At the end I would like a table gave below
> (need_ouput). Please notice the all value specified info in ref data file
> are exist in map$CHR and map$POS columns.
If I understand correctly you need to get

sel <- map$POS >= ref$POS_start & map$POS < ref$POS_end
result1 <- sum( map$post_prob[sel] )
and then check if the result is >0.85
(but in your final table post_prob is below this threshold)
compute
result2 <- length( map$post_prob[sel] )

and add the results into final table.

>
>
>
> Task2)
>
> Again example, the first and second columns for row 1 in data ref are chr1,
> 6457839 and 6638389. So I need that R gives me the minimum map$p for the
> 2
> chr1, 6457839 and 6638389 (as there are many snps between these regions
> and
> would like choose the smallest one in those regions. Than do the same for
> the second, third....rows in ref.

Your task 2 can be done alongside task1
result3 <- min( map$p[sel] )

>
>
>
> Then put the results of Task1 and Task2 into need_ouput file

Again if I understand correctly your result data frame shall have same number of rows as ref data frame. I wonder how do you want to put there POS, snp, allele... and other multiple values from map data frame? How do you want to summarise them?

Two final comments:

Do not post in HTML, you can see that the code below is rather scrammbled due to behaviour of HTML mail.
If posting some examples, it would be preferable that they can be used directly with code we are trying to find to help you solve your task. Especially if you want quick answer.

Cheers
Petr

>
>
>
>
> #R codes modified from Jim
>
>
> map2<-map[order(map$CHR, map$POS, -map$post_prob),]
>
>
>
>                 # get a field for the counts
>
>  ref$n<-NA
>
>
>
>                 # and a field for the minimum p values
>
>  ref$min_p<-NA
>
>
>
>                 # get the number of rows in "ref"
>
>  nref<-dim(ref)[1]
>
>  for(i in 1:nref) {
>
>   CHR<- which(map2$CHR==ref$CHR[i])
>
>   POS_start<-which(map2$POS==ref$POS_start[i])
>
>   POS_end<-which(map2$POS==ref$POS_end[i])
>
>   cat("CHR", "CHR"," POS_start",POS_start,"POS_end",POS_end,"\n")
>
>
>
>                 # get the range of matches
>
>   POSrange<-range(c(CHR,POS_start,POS_end))
>
>
>
>                 # convert this to a sequence spanning all matches
>
>   allPOS<-POSrange[1]:POSrange[2]
>
>   ref$n[i]<-sum(map2$post_prob[allPOS] > 0.99)
>
>   ref$min_p[i]<-min(map2$p[allPOS])
>
>  }
>
>
>
>
>
>       dput(map)
>
>       structure(list(CHR = structure(c(1L, 1L), .Label = "chr1", class =
> "factor"),
>
>           snp = structure(1:2, .Label = c("rs4747841", "rs4749917"), class
> = "factor"),
>
>           Allel1 = structure(1:2, .Label = c("A", "T"), class = "factor"),
>
>           Allel2 = structure(c(2L, 1L), .Label = c("C", "G"), class =
> "factor"),
>
>           fr = c(0.551, 0.436), effec = c(-0.0011, 0.0011), SE = c(0.0029,
>
>           0.0029), p = c(0.7, 0.7), POS = c(9960129L, 9960259L), post_prob
> = c(1.248817e-158,
>
>           1.248817e-158)), .Names = c("CHR", "snp", "Allel1", "Allel2",
>
>       "fr", "effec", "SE", "p", "POS", "post_prob"), class = "data.frame",
> row.names = c(NA,
>
>       -2L))
>
>
>
>
>
>      dput(ref)
>
>      structure(list(CHR = structure(1:2, .Label = c("chr10", "chr14"
>
>      ), class = "factor"), POS_start = c(6457839L, 21005246L), POS_end =
> c(6638389L,
>
>      21550658L)), .Names = c("CHR", "POS_start", "POS_end"), class =
> "data.frame", row.names = c(NA,
>
> -2L))
>
>
>
>
>
> dput(need_output)
>
> structure(list(CHR = structure(1:2, .Label = c("chr1", "chr22"
>
> ), class = "factor"), POS = c(312127953L, 46487552L), POS_start =
> c(32036927L,
>
> 45766451L), POS_end = c(3232240262<tel:%283232240262>, 46801601), snp = structure(1:2, .Label
> = c("rs1143427",
>
> "rs55958907"), class = "factor"), alle1l = structure(1:2, .Label = c("G",
>
> "T"), class = "factor"), allel2 = structure(1:2, .Label = c("A",
>
> "G"), class = "factor"), fr = c(0.278, 0.974), effec = c(0.6,
>
> 0.106), SE = c(0.015, 0.027), P = c(0.000156, 7.63e-05), post_prob =
> c(0.229,
>
> 0.125), n = c(612L, 4218L)), .Names = c("CHR", "POS", "POS_start",
>
> "POS_end", "snp", "alle1l", "allel2", "fr", "effec", "SE", "P",
>
> "post_prob", "n"), class = "data.frame", row.names = c(NA, -2L
>
> ))
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.





________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Jun 17 10:34:30 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Jun 2016 08:34:30 +0000
Subject: [R] Fw: Aw: Re: Building a binary vector out of dichotomous
 variables
In-Reply-To: <trinity-b7ae38c2-2816-4354-82e4-3add3bfd5351-1466147950330@3capp-gmx-bs62>
References: <OF6A6794EB.955DBFA5-ONC1257FD4.0046CFF5-C1257FD4.00473077@lotus.hawesko.de>,
	<CAKmUXV9FFUYygXEL7xHXS5gmUPztH1hdo0viXaTMmwMb1VJSRQ@mail.gmail.com>,
	<trinity-cfaf84f4-dd91-4f90-840f-e3f3efb445a3-1466147759326@3capp-gmx-bs62>
	<trinity-b7ae38c2-2816-4354-82e4-3add3bfd5351-1466147950330@3capp-gmx-bs62>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50311EE@SRVEXCHMBX.precheza.cz>

Hi

Your approach seems to me rather tricky

This should work

make_bv <- function(dataset,  input_variables) {

dd <- which(names(dataset) %in% input_variables)
dat<-dataset[,dd]
x <- 10^(ncol(dat):0)
result <- cbind(dataset, binary_vec=x[1]+rowSums(sweep(dat, 2, x[-1], "*")))
result}

make_bv(dataset = ds_example,  input_variables = c("year2013", "year2015"))

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at gmx.de
> Sent: Friday, June 17, 2016 9:19 AM
> To: r-help at r-project.org
> Subject: [R] Fw: Aw: Re: Building a binary vector out of dichotomous variables
>
> > Hi Tom,
> >
> > thanks for your reply.
> >
> > Yes, that's exactly what I am looking for. I did not know about the
> automatic type conversion in R.
> >
> > #-- cut --
> > ds_example <-
> >   structure(
> >     list(
> >       year2013 = c(0, 0, 0, 1, 1, 1, 1, 0),
> >       year2014 = c(0,
> >                    0, 1, 1, 0, 0, 1, 1),
> >       year2015 = c(0, 1, 1, 1, 0, 1, 0, 0)
> >     ),
> >     .Names = c("year2013",
> >                "year2014", "year2015"),
> >     row.names = c(NA, 8L),
> >     class = "data.frame"
> >   )
> >
> > #-- Proposal: works!
> > as.numeric(with(ds_example,paste(1,year2013,year2014,year2015,sep=''))
> > )
> >
> > # I store my know-how about R in functions for later use.
> >
> > #--? Putting it in a function - does not work!
> > t_make_binary_vector <- function(dataset,
> >                                  input_variables,
> >                                  output_variable = "binary_vector") {
> >   dataset[output_variable] <- "1"
> >   print(dataset[output_variable])
> >
> >   for (variable in input_variables) {
> >     print(variable)
> >     dataset[output_variable] <- paste(dataset[output_variable],
> >                                       dataset[variable],
> >                                       sep='')
> >   }
> >
> >   # print(dataset[output_variable])
> >
> >   dataset[output_variable] <- as.integer(dataset[output_variable])
> >
> >   return(dataset)
> > }
> >
> > t_make_binary_vector(dataset = ds_example,
> >                      input_variables = c("year2013", "year2014", "year2015"),
> >                      output_variable = "binary_vector")
> >
> >
> > #-- Doesn't work either.
> > t_make_binary_vector <- function(dataset,
> >                                  input_variables,
> >                                  output_variable = "binary_vector") {
> >   dataset[output_variable] <- as.integer(paste(1, dataset[ ,
> > input_variables], sep = ''))
> >
> >   return(dataset)
> > }
> >
> > t_make_binary_vector(dataset = ds_example,
> >                      input_variables = c("year2013", "year2014", "year2015"),
> >                      output_variable = "binary_vector")
> >
> > #-- cut --
> >
> > Why is R taking the parameter value itself to paste it together instead of
> referencing the variable within the dataset?
> >
> > What did I get wrong about R? How can I fix it?
> >
> > Kind regards
> >
> > Georg
> >
> >
> > > Gesendet: Donnerstag, 16. Juni 2016 um 16:13 Uhr
> > > Von: "Tom Wright" <tom at maladmin.com>
> > > An: G.Maubach at weinwolf.de
> > > Cc: "R. Help" <r-help at r-project.org>
> > > Betreff: Re: [R] Building a binary vector out of dichotomous
> > > variables
> > >
> > > Does this do what you want?
> > >
> > > as.numeric(with(ds_example,paste(1,year2013,year2014,year2015,sep=''
> > > )))
> > >
> > > On Thu, Jun 16, 2016 at 8:57 AM,  <G.Maubach at weinwolf.de> wrote:
> > > > Hi All,
> > > >
> > > > I need to build a binary vector made of a set of dichotomous variables.
> > > >
> > > > What I have so far is:
> > > >
> > > > -- cut --
> > > >
> > > > ds_example <-
> > > >   structure(
> > > >     list(
> > > >       year2013 = c(0, 0, 0, 1, 1, 1, 1, 0),
> > > >       year2014 = c(0,
> > > >                    0, 1, 1, 0, 0, 1, 1),
> > > >       year2015 = c(0, 1, 1, 1, 0, 1, 0, 0)
> > > >     ),
> > > >     .Names = c("year2013",
> > > >                "year2014", "year2015"),
> > > >     row.names = c(NA, 8L),
> > > >     class = "data.frame"
> > > >   )
> > > >
> > > > attach(ds_example)
> > > > base <- 1000
> > > > binary_vector <- base + year2013 * 100 + year2014 * 10 + year2015
> > > > detach(ds_example)
> > > >
> > > > binary_vector
> > > >
> > > > ds_example <- cbind(ds_example, binary_vector)
> > > >
> > > > varlist <- c("year2013", "year2014", "year2015")
> > > >
> > > > base <- 10^length(varlist)
> > > >
> > > > binary_vector <- NULL
> > > >
> > > > for (i in 1:3) {
> > > >   binary_vector <-
> > > >    base +
> > > >    ds_example [[varlist[i]]] * base / (10 ^ i) }
> > > >
> > > > ds_example <- cbind(ds_example, binary_vector)
> > > >
> > > > message("Wrong result!")
> > > > ds_example
> > > >
> > > > -- cut --
> > > >
> > > > How do I get vectors like  1000 1001 1011 1111 1100 1101 1110 1010
> > > > for each case?
> > > >
> > > > Is there a better approach than mine?
> > > >
> > > > Kind regards
> > > >
> > > > Georg
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Matthias.Weber at fntsoftware.com  Fri Jun 17 09:49:42 2016
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Fri, 17 Jun 2016 07:49:42 +0000
Subject: [R] filter a data.frame in dependence of a column value
Message-ID: <HE1PR07MB1212A945302ECCD0C285349090570@HE1PR07MB1212.eurprd07.prod.outlook.com>

Hello togehter,

i have short question, maybe anyone can help me.

I have a data.frame like this one:

       NO       ORDER
1     1530     for Mr. Muller (10.0 -> 11.2)
2     1799     for Mr Giulani
3     1888     for Mr. Marius (11.2 -> 12)

I need a solution, which only contains the values in brackets. The result should look like the following:

       NO       ORDER
1     1530     for Mr. Muller (10.0 -> 11.2)
2     1888     for Mr. Marius (11.2 -> 12)

I tried it with the following code, but that doesn't work.

data4.1<-data3[data3$ORDER%in% "[(]*->*[)]",]

maybe anyone can help me.

Thank you.

Best regards

Mat

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Jun 17 11:19:56 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 17 Jun 2016 11:19:56 +0200
Subject: [R] filter a data.frame in dependence of a column value
In-Reply-To: <HE1PR07MB1212A945302ECCD0C285349090570@HE1PR07MB1212.eurprd07.prod.outlook.com>
References: <HE1PR07MB1212A945302ECCD0C285349090570@HE1PR07MB1212.eurprd07.prod.outlook.com>
Message-ID: <CAJuCY5ztFVV6ji1ODNDZ4Tt_FEQsYYUJDyUKGvbz8fwsq8_grw@mail.gmail.com>

Dear Mat,

You can use grepl() to select based on are regular expression.

subset(data3, grepl("\\(.*\\)", ORDER))

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-17 9:49 GMT+02:00 Matthias Weber <Matthias.Weber at fntsoftware.com>:

> Hello togehter,
>
> i have short question, maybe anyone can help me.
>
> I have a data.frame like this one:
>
>        NO       ORDER
> 1     1530     for Mr. Muller (10.0 -> 11.2)
> 2     1799     for Mr Giulani
> 3     1888     for Mr. Marius (11.2 -> 12)
>
> I need a solution, which only contains the values in brackets. The result
> should look like the following:
>
>        NO       ORDER
> 1     1530     for Mr. Muller (10.0 -> 11.2)
> 2     1888     for Mr. Marius (11.2 -> 12)
>
> I tried it with the following code, but that doesn't work.
>
> data4.1<-data3[data3$ORDER%in% "[(]*->*[)]",]
>
> maybe anyone can help me.
>
> Thank you.
>
> Best regards
>
> Mat
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From es at enricoschumann.net  Fri Jun 17 11:22:54 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Fri, 17 Jun 2016 11:22:54 +0200
Subject: [R] filter a data.frame in dependence of a column value
In-Reply-To: <HE1PR07MB1212A945302ECCD0C285349090570@HE1PR07MB1212.eurprd07.prod.outlook.com>
	(Matthias Weber's message of "Fri, 17 Jun 2016 07:49:42 +0000")
References: <HE1PR07MB1212A945302ECCD0C285349090570@HE1PR07MB1212.eurprd07.prod.outlook.com>
Message-ID: <8760t8jhjl.fsf@enricoschumann.net>

On Fri, 17 Jun 2016, Matthias Weber <Matthias.Weber at fntsoftware.com> writes:

> Hello togehter,
>
> i have short question, maybe anyone can help me.
>
> I have a data.frame like this one:
>
>        NO       ORDER
> 1     1530     for Mr. Muller (10.0 -> 11.2)
> 2     1799     for Mr Giulani
> 3     1888     for Mr. Marius (11.2 -> 12)
>
> I need a solution, which only contains the values in brackets. The result should look like the following:
>
>        NO       ORDER
> 1     1530     for Mr. Muller (10.0 -> 11.2)
> 2     1888     for Mr. Marius (11.2 -> 12)
>
> I tried it with the following code, but that doesn't work.
>
> data4.1<-data3[data3$ORDER%in% "[(]*->*[)]",]
>
> maybe anyone can help me.
>
> Thank you.
>
> Best regards
>
> Mat
>

Try ?grepl instead of %in%.

x <- c("for Mr. Muller (10.0 -> 11.2)",
       "for Mr Giulani",
       "for Mr. Marius (11.2 -> 12)")

grepl("[(].*->.*[)]", x)




-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From careyshan at gmail.com  Fri Jun 17 11:47:25 2016
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 17 Jun 2016 10:47:25 +0100
Subject: [R] Kendall heat map
Message-ID: <CA+jRDxDa1y3oz7C_oxfqPxHmAxzEH++zVCegAoyd-mkfsLtXDw@mail.gmail.com>

Hi,

I was hoping someone could help me. I was wondering are there any libraries
available to undertake a kendall correlation on a matrix of data, in the
same way as what can be undertaken with the rcorr function:

cormatrix = rcorr(as.matrix(A), type='spearman')
cordata = melt(cormatrix$r)
ggplot(cordata, aes(x=Var1, y=Var2, fill=value)) +
  geom_tile() + xlab("") + ylab("")

Thanks

-- 
Le gach dea ghui,
Shane

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Jun 17 12:00:52 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 17 Jun 2016 20:00:52 +1000
Subject: [R] Kendall heat map
In-Reply-To: <CA+jRDxDa1y3oz7C_oxfqPxHmAxzEH++zVCegAoyd-mkfsLtXDw@mail.gmail.com>
References: <CA+jRDxDa1y3oz7C_oxfqPxHmAxzEH++zVCegAoyd-mkfsLtXDw@mail.gmail.com>
Message-ID: <CA+8X3fXqvLCfGUeeUTaxs-9nGYjp_LvFJ3GHUB+KKc6pOk4oCQ@mail.gmail.com>

Hi Shane,
Try the "Kendall" package.

Jim


On Fri, Jun 17, 2016 at 7:47 PM, Shane Carey <careyshan at gmail.com> wrote:
> Hi,
>
> I was hoping someone could help me. I was wondering are there any libraries
> available to undertake a kendall correlation on a matrix of data, in the
> same way as what can be undertaken with the rcorr function:
>
> cormatrix = rcorr(as.matrix(A), type='spearman')
> cordata = melt(cormatrix$r)
> ggplot(cordata, aes(x=Var1, y=Var2, fill=value)) +
>   geom_tile() + xlab("") + ylab("")
>
> Thanks
>
> --
> Le gach dea ghui,
> Shane
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bob at rudis.net  Fri Jun 17 12:11:28 2016
From: bob at rudis.net (boB Rudis)
Date: Fri, 17 Jun 2016 06:11:28 -0400
Subject: [R] Kendall heat map
In-Reply-To: <CA+jRDxDa1y3oz7C_oxfqPxHmAxzEH++zVCegAoyd-mkfsLtXDw@mail.gmail.com>
References: <CA+jRDxDa1y3oz7C_oxfqPxHmAxzEH++zVCegAoyd-mkfsLtXDw@mail.gmail.com>
Message-ID: <CAJ4QxaPAgHg2_7UD37fDuGYw8NHxrRr1MUFangfX91F+=ehuaA@mail.gmail.com>

Did you try:

    cor(mat, method="kendall", use="pairwise")

That only provides the matrix (so the equiv of the $r list component),
but that seems to be all you need.

On Fri, Jun 17, 2016 at 5:47 AM, Shane Carey <careyshan at gmail.com> wrote:
> Hi,
>
> I was hoping someone could help me. I was wondering are there any libraries
> available to undertake a kendall correlation on a matrix of data, in the
> same way as what can be undertaken with the rcorr function:
>
> cormatrix = rcorr(as.matrix(A), type='spearman')
> cordata = melt(cormatrix$r)
> ggplot(cordata, aes(x=Var1, y=Var2, fill=value)) +
>   geom_tile() + xlab("") + ylab("")
>
> Thanks
>
> --
> Le gach dea ghui,
> Shane
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From careyshan at gmail.com  Fri Jun 17 12:13:52 2016
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 17 Jun 2016 11:13:52 +0100
Subject: [R] Kendall heat map
In-Reply-To: <CAJ4QxaPAgHg2_7UD37fDuGYw8NHxrRr1MUFangfX91F+=ehuaA@mail.gmail.com>
References: <CA+jRDxDa1y3oz7C_oxfqPxHmAxzEH++zVCegAoyd-mkfsLtXDw@mail.gmail.com>
	<CAJ4QxaPAgHg2_7UD37fDuGYw8NHxrRr1MUFangfX91F+=ehuaA@mail.gmail.com>
Message-ID: <CA+jRDxBR-OuHO2mFQQvYH=nHVx2fo4yxweBcX2xFYzXm_7snHQ@mail.gmail.com>

I also need the significance value

Thanks

On Fri, Jun 17, 2016 at 11:11 AM, boB Rudis <bob at rudis.net> wrote:

> Did you try:
>
>     cor(mat, method="kendall", use="pairwise")
>
> That only provides the matrix (so the equiv of the $r list component),
> but that seems to be all you need.
>
> On Fri, Jun 17, 2016 at 5:47 AM, Shane Carey <careyshan at gmail.com> wrote:
> > Hi,
> >
> > I was hoping someone could help me. I was wondering are there any
> libraries
> > available to undertake a kendall correlation on a matrix of data, in the
> > same way as what can be undertaken with the rcorr function:
> >
> > cormatrix = rcorr(as.matrix(A), type='spearman')
> > cordata = melt(cormatrix$r)
> > ggplot(cordata, aes(x=Var1, y=Var2, fill=value)) +
> >   geom_tile() + xlab("") + ylab("")
> >
> > Thanks
> >
> > --
> > Le gach dea ghui,
> > Shane
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Le gach dea ghui,
Shane

	[[alternative HTML version deleted]]


From gmoyeyemi at gmail.com  Fri Jun 17 14:25:20 2016
From: gmoyeyemi at gmail.com (Gafar Matanmi Oyeyemi)
Date: Fri, 17 Jun 2016 13:25:20 +0100
Subject: [R] Obtaining and extracting cells sample in cross-tabulation
In-Reply-To: <CAFcbP-C9BD-i5eYB7qOH0UQV7t4b+KoUdfo8gZg_uaHm4w_jdg@mail.gmail.com>
References: <CAFcbP-A9wqzvXLeAek71cf6C_9dG1ZFm0CKexJF7RWxa=ADEVQ@mail.gmail.com>
	<CAFcbP-Bd0y_qFfFQKPQzUxqDN-S4rNZCgaaX0G3pwTnZD4wzFw@mail.gmail.com>
	<CAFcbP-CJWpkzD+YF7h-_eLmBgHsf8nWfRAfZDfALovwG7-c1yQ@mail.gmail.com>
	<CAFcbP-B2L4eWZupGiYbdrBFD=mgH4pr+gw9v-cVK3FRsSjNPkw@mail.gmail.com>
	<CAFcbP-BR=AzfvqPDc-A9doDcZRww=cMabhxAh06x0mmgJx6ygw@mail.gmail.com>
	<CAFcbP-AJUSPvaw2LPL4jr_GGXbBzR-N8RAryVCaq-pHCfkdsXQ@mail.gmail.com>
	<CAFcbP-Bz5fz-tY_j=pScEVeigEOSgtpih+Sk9fVHUsmvNvNGvw@mail.gmail.com>
	<CAFcbP-DaNL3qrKOJYN5tMkK5=Zd+Vox5EGgbqh8MEUProD0jgg@mail.gmail.com>
	<CAFcbP-AFP_b1=31xnH7Grj23nnJ-nAa8VZzVMOuB0Jth_a4sfQ@mail.gmail.com>
	<CAFcbP-BFGiP9_w=dReE+tKyVAi035fvLZ4RYYb+qqrH-tTrYAg@mail.gmail.com>
	<CAFcbP-CESK1PP9MUK40QMbrTajumYMTnkPi6LJQyn23Wpb40Bg@mail.gmail.com>
	<CAFcbP-Ba1JnAVyEdStNOMhpLP1_iPke88vZvUDK9B1eX=mo5iw@mail.gmail.com>
	<CAFcbP-C9BD-i5eYB7qOH0UQV7t4b+KoUdfo8gZg_uaHm4w_jdg@mail.gmail.com>
Message-ID: <CAFcbP-BrNDhnDmhwP3-tGj6KeNCBd0Nds99EnMSgriRPBb9=ig@mail.gmail.com>

Hello everyone,
I'm writing a function in R but was stalked.
I have a data set that contains mixture of categorical and continuous
variables. I want to use the categorical variables to cross-tabulate the
data and extract the observations in the resulting cells that contain only
continuous variables.

Data.
X1   X2   X3   X4   X5
2.4  5.3  4.8    0      1
4.2  3.2  4.8    1      1
3.3  4.4  5.1    0      0
5.2  1.1  2.5    1      0
.
.
.
3.7  2.8  3.8    0      1

Thanks.

	[[alternative HTML version deleted]]


From bjpmodi2016 at gmail.com  Fri Jun 17 15:51:59 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Fri, 17 Jun 2016 08:51:59 -0500
Subject: [R] Non Linear Solver - Optim in R
Message-ID: <CAPq=xQCMuqih7gQy4j4wYPxq_1eHyTH7rudg8e-PHm_9dT4e5g@mail.gmail.com>

Hello,
Resending this message in "Plain-text".

Thank you for the add to the list.

I have written a R snippet to solve a non-linear problem using Optim solver.

The parameters to be solved are supposed to be in a matrix form as attached

such that summation of columns is <=1 except for the first column. ie,
P1.F1j + P2.F1j <=1 ,  P1.F2j + P2.F2j <=1 ,  P1.F3j + P2.F3j <=1 and so
on..

Since OPTIM solver considers "pars" only as vector, I defined the vector as

my.data.var <- vector("numeric",length = 12)

and in the OPTIM solver, I passed it as

optim(my.data.var, Error.func, method="L-BFGS-B",
upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1))

Then in the error function, I stacked the vector into a matrix as :

my.data.var.mat <- matrix(my.data.var,nrow = 2, ncol = 6,byrow = TRUE)

So, my first question is how do I define the constraints for each column
except the first one in the OPTIM solver? As you can see, with the UPPER
limit in the OPTIM solver, I can fix the upper bound, but there is no way
for me set the summation constraint to <=1.

Do I need a different solver for this scenario which allows me to use
Matrix elements as parameters?

Thanks!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Matrix.PNG
Type: image/png
Size: 3957 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160617/ac99d55b/attachment.png>

From maitra.mbox.ignored at inbox.com  Fri Jun 17 16:22:22 2016
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Fri, 17 Jun 2016 09:22:22 -0500
Subject: [R] Non Linear Solver - Optim in R
In-Reply-To: <CAPq=xQCMuqih7gQy4j4wYPxq_1eHyTH7rudg8e-PHm_9dT4e5g@mail.gmail.com>
References: <CAPq=xQCMuqih7gQy4j4wYPxq_1eHyTH7rudg8e-PHm_9dT4e5g@mail.gmail.com>
Message-ID: <20160617092222.f0cbe2539a6a9e4f06e0f791@inbox.com>

You need to send e-mail from a properly identifiable address (which has a correct name/e-mail address) and not a made-up scam address. You can easily be reported for impersonation!

Ranjan


On Fri, 17 Jun 2016 08:51:59 -0500 Narendra Modi <bjpmodi2016 at gmail.com> wrote:

> Hello,
> Resending this message in "Plain-text".
> 
> Thank you for the add to the list.
> 
> I have written a R snippet to solve a non-linear problem using Optim solver.
> 
> The parameters to be solved are supposed to be in a matrix form as attached
> 
> such that summation of columns is <=1 except for the first column. ie,
> P1.F1j + P2.F1j <=1 ,  P1.F2j + P2.F2j <=1 ,  P1.F3j + P2.F3j <=1 and so
> on..
> 
> Since OPTIM solver considers "pars" only as vector, I defined the vector as
> 
> my.data.var <- vector("numeric",length = 12)
> 
> and in the OPTIM solver, I passed it as
> 
> optim(my.data.var, Error.func, method="L-BFGS-B",
> upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1))
> 
> Then in the error function, I stacked the vector into a matrix as :
> 
> my.data.var.mat <- matrix(my.data.var,nrow = 2, ncol = 6,byrow = TRUE)
> 
> So, my first question is how do I define the constraints for each column
> except the first one in the OPTIM solver? As you can see, with the UPPER
> limit in the OPTIM solver, I can fix the upper bound, but there is no way
> for me set the summation constraint to <=1.
> 
> Do I need a different solver for this scenario which allows me to use
> Matrix elements as parameters?
> 
> Thanks!


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From petr.pikal at precheza.cz  Fri Jun 17 16:23:46 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Jun 2016 14:23:46 +0000
Subject: [R] Obtaining and extracting cells sample in cross-tabulation
In-Reply-To: <CAFcbP-BrNDhnDmhwP3-tGj6KeNCBd0Nds99EnMSgriRPBb9=ig@mail.gmail.com>
References: <CAFcbP-A9wqzvXLeAek71cf6C_9dG1ZFm0CKexJF7RWxa=ADEVQ@mail.gmail.com>
	<CAFcbP-Bd0y_qFfFQKPQzUxqDN-S4rNZCgaaX0G3pwTnZD4wzFw@mail.gmail.com>
	<CAFcbP-CJWpkzD+YF7h-_eLmBgHsf8nWfRAfZDfALovwG7-c1yQ@mail.gmail.com>
	<CAFcbP-B2L4eWZupGiYbdrBFD=mgH4pr+gw9v-cVK3FRsSjNPkw@mail.gmail.com>
	<CAFcbP-BR=AzfvqPDc-A9doDcZRww=cMabhxAh06x0mmgJx6ygw@mail.gmail.com>
	<CAFcbP-AJUSPvaw2LPL4jr_GGXbBzR-N8RAryVCaq-pHCfkdsXQ@mail.gmail.com>
	<CAFcbP-Bz5fz-tY_j=pScEVeigEOSgtpih+Sk9fVHUsmvNvNGvw@mail.gmail.com>
	<CAFcbP-DaNL3qrKOJYN5tMkK5=Zd+Vox5EGgbqh8MEUProD0jgg@mail.gmail.com>
	<CAFcbP-AFP_b1=31xnH7Grj23nnJ-nAa8VZzVMOuB0Jth_a4sfQ@mail.gmail.com>
	<CAFcbP-BFGiP9_w=dReE+tKyVAi035fvLZ4RYYb+qqrH-tTrYAg@mail.gmail.com>
	<CAFcbP-CESK1PP9MUK40QMbrTajumYMTnkPi6LJQyn23Wpb40Bg@mail.gmail.com>
	<CAFcbP-Ba1JnAVyEdStNOMhpLP1_iPke88vZvUDK9B1eX=mo5iw@mail.gmail.com>
	<CAFcbP-C9BD-i5eYB7qOH0UQV7t4b+KoUdfo8gZg_uaHm4w_jdg@mail.gmail.com>
	<CAFcbP-BrNDhnDmhwP3-tGj6KeNCBd0Nds99EnMSgriRPBb9=ig@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503131B@SRVEXCHMBX.precheza.cz>

Hi

did you try table or xtabs?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Gafar
> Matanmi Oyeyemi
> Sent: Friday, June 17, 2016 2:25 PM
> To: r-help at r-project.org
> Subject: [R] Obtaining and extracting cells sample in cross-tabulation
>
> Hello everyone,
> I'm writing a function in R but was stalked.
> I have a data set that contains mixture of categorical and continuous
> variables. I want to use the categorical variables to cross-tabulate the data
> and extract the observations in the resulting cells that contain only
> continuous variables.
>
> Data.
> X1   X2   X3   X4   X5
> 2.4  5.3  4.8    0      1
> 4.2  3.2  4.8    1      1
> 3.3  4.4  5.1    0      0
> 5.2  1.1  2.5    1      0
> .
> .
> .
> 3.7  2.8  3.8    0      1
>
> Thanks.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bjpmodi2016 at gmail.com  Fri Jun 17 16:40:35 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Fri, 17 Jun 2016 09:40:35 -0500
Subject: [R] Non Linear Solver - Optim in R
In-Reply-To: <20160617092222.f0cbe2539a6a9e4f06e0f791@inbox.com>
References: <CAPq=xQCMuqih7gQy4j4wYPxq_1eHyTH7rudg8e-PHm_9dT4e5g@mail.gmail.com>
	<20160617092222.f0cbe2539a6a9e4f06e0f791@inbox.com>
Message-ID: <CAPq=xQCD+tR_ZKzj5OeFNZj4+BDABzyV8xzjQcGzWA8p8a54-g@mail.gmail.com>

Ooops. I can change that real quick.

Any help on the problem itself Ranjan?

Thanks!

On Fri, Jun 17, 2016 at 9:22 AM, Ranjan Maitra <
maitra.mbox.ignored at inbox.com> wrote:

> You need to send e-mail from a properly identifiable address (which has a
> correct name/e-mail address) and not a made-up scam address. You can easily
> be reported for impersonation!
>
> Ranjan
>
>
> On Fri, 17 Jun 2016 08:51:59 -0500 Narendra Modi <bjpmodi2016 at gmail.com>
> wrote:
>
> > Hello,
> > Resending this message in "Plain-text".
> >
> > Thank you for the add to the list.
> >
> > I have written a R snippet to solve a non-linear problem using Optim
> solver.
> >
> > The parameters to be solved are supposed to be in a matrix form as
> attached
> >
> > such that summation of columns is <=1 except for the first column. ie,
> > P1.F1j + P2.F1j <=1 ,  P1.F2j + P2.F2j <=1 ,  P1.F3j + P2.F3j <=1 and so
> > on..
> >
> > Since OPTIM solver considers "pars" only as vector, I defined the vector
> as
> >
> > my.data.var <- vector("numeric",length = 12)
> >
> > and in the OPTIM solver, I passed it as
> >
> > optim(my.data.var, Error.func, method="L-BFGS-B",
> > upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1))
> >
> > Then in the error function, I stacked the vector into a matrix as :
> >
> > my.data.var.mat <- matrix(my.data.var,nrow = 2, ncol = 6,byrow = TRUE)
> >
> > So, my first question is how do I define the constraints for each column
> > except the first one in the OPTIM solver? As you can see, with the UPPER
> > limit in the OPTIM solver, I can fix the upper bound, but there is no way
> > for me set the summation constraint to <=1.
> >
> > Do I need a different solver for this scenario which allows me to use
> > Matrix elements as parameters?
> >
> > Thanks!
>
>
> --
> Important Notice: This mailbox is ignored: e-mails are set to be deleted
> on receipt. Please respond to the mailing list if appropriate. For those
> needing to send personal or professional e-mail, please use appropriate
> addresses.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
> family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Jun 17 17:26:10 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 17 Jun 2016 15:26:10 +0000
Subject: [R] Obtaining and extracting cells sample in cross-tabulation
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503131B@SRVEXCHMBX.precheza.cz>
References: <CAFcbP-A9wqzvXLeAek71cf6C_9dG1ZFm0CKexJF7RWxa=ADEVQ@mail.gmail.com>
	<CAFcbP-Bd0y_qFfFQKPQzUxqDN-S4rNZCgaaX0G3pwTnZD4wzFw@mail.gmail.com>
	<CAFcbP-CJWpkzD+YF7h-_eLmBgHsf8nWfRAfZDfALovwG7-c1yQ@mail.gmail.com>
	<CAFcbP-B2L4eWZupGiYbdrBFD=mgH4pr+gw9v-cVK3FRsSjNPkw@mail.gmail.com>
	<CAFcbP-BR=AzfvqPDc-A9doDcZRww=cMabhxAh06x0mmgJx6ygw@mail.gmail.com>
	<CAFcbP-AJUSPvaw2LPL4jr_GGXbBzR-N8RAryVCaq-pHCfkdsXQ@mail.gmail.com>
	<CAFcbP-Bz5fz-tY_j=pScEVeigEOSgtpih+Sk9fVHUsmvNvNGvw@mail.gmail.com>
	<CAFcbP-DaNL3qrKOJYN5tMkK5=Zd+Vox5EGgbqh8MEUProD0jgg@mail.gmail.com>
	<CAFcbP-AFP_b1=31xnH7Grj23nnJ-nAa8VZzVMOuB0Jth_a4sfQ@mail.gmail.com>
	<CAFcbP-BFGiP9_w=dReE+tKyVAi035fvLZ4RYYb+qqrH-tTrYAg@mail.gmail.com>
	<CAFcbP-CESK1PP9MUK40QMbrTajumYMTnkPi6LJQyn23Wpb40Bg@mail.gmail.com>
	<CAFcbP-Ba1JnAVyEdStNOMhpLP1_iPke88vZvUDK9B1eX=mo5iw@mail.gmail.com>
	<CAFcbP-C9BD-i5eYB7qOH0UQV7t4b+KoUdfo8gZg_uaHm4w_jdg@mail.gmail.com>
	<CAFcbP-BrNDhnDmhwP3-tGj6KeNCBd0Nds99EnMSgriRPBb9=ig@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C503131B@SRVEXCHMBX.precheza.cz>
Message-ID: <cafd72aa9e974f849e605da2fd19d023@exch-2p-mbx-t2.ads.tamu.edu>

Your request is not clear. If you want to analyze the numeric variables by the groups formed by the categorical variables, try something like this.

> # Create reproducible data
> set.seed(42)
> x <- data.frame(matrix(rnorm(75, 5), 25), X4=sample(0:1, 25, 
+ replace=TRUE), X5=sample(0:1, 25, replace=TRUE))
> head(x)
        X1       X2       X3 X4 X5
1 6.370958 4.569531 5.321925  1  0
2 4.435302 4.742731 4.216161  0  1
3 5.363128 3.236837 6.575728  1  1
4 5.632863 5.460097 5.642899  0  1
5 5.404268 4.360005 5.089761  1  1
6 4.893875 5.455450 5.276551  1  1
> # Use split() to create a list of data frames
> grps <- apply(x[, 4:5], 1, paste0, collapse="")
> x.grps <- split(x[, 1:3], grps)
> names(x.grps)
[1] "00" "01" "10" "11"
> x.grps[["00"]] # or x.grps[[1]]
         X1       X2       X3
8  4.905341 6.035104 5.089833
9  7.018424 4.391074 2.006910
14 4.721211 2.585792 6.399737
16 5.635950 5.205999 6.302543
18 2.343545 5.758163 6.038506
19 2.559533 4.273295 5.920729
20 6.320113 3.631719 5.720878
23 4.828083 6.444101 5.623518

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Friday, June 17, 2016 9:24 AM
To: Gafar Matanmi Oyeyemi; r-help at r-project.org
Subject: Re: [R] Obtaining and extracting cells sample in cross-tabulation

Hi

did you try table or xtabs?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Gafar
> Matanmi Oyeyemi
> Sent: Friday, June 17, 2016 2:25 PM
> To: r-help at r-project.org
> Subject: [R] Obtaining and extracting cells sample in cross-tabulation
>
> Hello everyone,
> I'm writing a function in R but was stalked.
> I have a data set that contains mixture of categorical and continuous
> variables. I want to use the categorical variables to cross-tabulate the data
> and extract the observations in the resulting cells that contain only
> continuous variables.
>
> Data.
> X1   X2   X3   X4   X5
> 2.4  5.3  4.8    0      1
> 4.2  3.2  4.8    1      1
> 3.3  4.4  5.1    0      0
> 5.2  1.1  2.5    1      0
> .
> .
> .
> 3.7  2.8  3.8    0      1
>
> Thanks.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From wdunlap at tibco.com  Fri Jun 17 17:57:50 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Jun 2016 08:57:50 -0700
Subject: [R] what is the best way to process the following data?
In-Reply-To: <CAK3+11Tm5KD4qYmvoUoLBWr+OKLTQvTmffL7fHrMyvcgTBNewg@mail.gmail.com>
References: <CAK3+11Tm5KD4qYmvoUoLBWr+OKLTQvTmffL7fHrMyvcgTBNewg@mail.gmail.com>
Message-ID: <CAF8bMcYJP8OgK5YyyAjMSJP-gFG9y7xEvfr21ZzbbbPCii3hKg@mail.gmail.com>

You can make a step-number variable with cumsum(grepl("^Step ", ...)) and
use it as the splitting variable in split.  E.g.,

> dat <- read.table(yourFile, stringsAsFactors=FALSE, sep="|",
colClasses=c("NULL", "character", "character", "character"),
col.names=c("Junk","Date","Time","Type"))
> dat <- with(dat, data.frame(DateTime=as.POSIXct(paste(Date, Time),
format="%m/%d/%Y %H:%M:%S"), Type=Type, stringsAsFactors=FALSE))
> head(dat)
             DateTime           Type
1 2016-06-16 03:44:16       Step 001
2 2016-06-16 03:44:16 Initialization
3 2016-06-16 03:44:16        Filters
4 2016-06-16 03:45:03    Split Items
5 2016-06-16 03:46:20           Sort
6 2016-06-16 03:46:43          Check
> split(dat, cumsum(grepl("^Step ", dat$Type)))
$`1`
              DateTime                                        Type
1  2016-06-16 03:44:16                                    Step 001
2  2016-06-16 03:44:16                              Initialization
...
13 2016-06-16 04:06:33 BOP processing for 7,960 items has finished

$`2`
              DateTime                                        Type
14 2016-06-16 04:06:34                                    Step 002
15 2016-06-16 04:06:35                              Initialization
...



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Jun 16, 2016 at 8:42 PM, Satish Vadlamani <
satish.vadlamani at gmail.com> wrote:

> Hello,
> I have multiple text files with the format shown below (see the two files
> that I pasted below). Each file is a log of multiple steps that the system
> has processed and for each step, it has shown the start time of the process
> step. For example, in the data below, the filter started at
> |06/16/2016|03:44:16
>
> How to read this data so that Step 001 is one data frame, Step 002 is
> another, and so on. After I do this, I will then compare the Step 001 times
> with and without parallel process.
>
> For example, the files pasted below "no_parallel_process_SLS_4.txt" and
> "parallel_process_SLS_4.txt" will make it clear what I am trying to do. I
> want to compare the parallel process times taken for each step with the non
> parallel process times.
>
> If there are better ways of performing this task that what I am thinking,
> could you let me know? Thanks in advance.
>
> Satish Vadlamani
>
> >> parallel_process_file.txt
>
> |06/16/2016|03:44:16|Step 001
> |06/16/2016|03:44:16|Initialization
> |06/16/2016|03:44:16|Filters
> |06/16/2016|03:45:03|Split Items
> |06/16/2016|03:46:20|Sort
> |06/16/2016|03:46:43|Check
> |06/16/2016|04:01:13|Save
> |06/16/2016|04:04:35|Update preparation
> |06/16/2016|04:04:36|Update comparison
> |06/16/2016|04:04:38|Update
> |06/16/2016|04:04:38|Update
> |06/16/2016|04:06:01|Close
> |06/16/2016|04:06:33|BOP processing for 7,960 items has finished
> |06/16/2016|04:06:34|Step 002
> |06/16/2016|04:06:35|Initialization
> |06/16/2016|04:06:35|Filters
> |06/16/2016|04:07:14|Split Items
> |06/16/2016|04:08:57|Sort
> |06/16/2016|04:09:06|Check
> |06/16/2016|04:26:36|Save
> |06/16/2016|04:39:29|Update preparation
> |06/16/2016|04:39:31|Update comparison
> |06/16/2016|04:39:43|Update
> |06/16/2016|04:39:45|Update
> |06/16/2016|04:44:28|Close
> |06/16/2016|04:45:26|BOP processing for 8,420 items has finished
> |06/16/2016|04:45:27|Step 003
> |06/16/2016|04:45:27|Initialization
> |06/16/2016|04:45:27|Filters
> |06/16/2016|04:48:50|Split Items
> |06/16/2016|04:55:15|Sort
> |06/16/2016|04:55:40|Check
> |06/16/2016|05:13:35|Save
> |06/16/2016|05:17:34|Update preparation
> |06/16/2016|05:17:34|Update comparison
> |06/16/2016|05:17:36|Update
> |06/16/2016|05:17:36|Update
> |06/16/2016|05:19:29|Close
> |06/16/2016|05:19:49|BOP processing for 8,876 items has finished
> |06/16/2016|05:19:50|Step 004
> |06/16/2016|05:19:50|Initialization
> |06/16/2016|05:19:50|Filters
> |06/16/2016|05:20:43|Split Items
> |06/16/2016|05:22:14|Sort
> |06/16/2016|05:22:29|Check
> |06/16/2016|05:37:27|Save
> |06/16/2016|05:38:43|Update preparation
> |06/16/2016|05:38:44|Update comparison
> |06/16/2016|05:38:45|Update
> |06/16/2016|05:38:45|Update
> |06/16/2016|05:39:09|Close
> |06/16/2016|05:39:19|BOP processing for 5,391 items has finished
> |06/16/2016|05:39:20|Step 005
> |06/16/2016|05:39:20|Initialization
> |06/16/2016|05:39:20|Filters
> |06/16/2016|05:39:57|Split Items
> |06/16/2016|05:40:21|Sort
> |06/16/2016|05:40:24|Check
> |06/16/2016|05:46:01|Save
> |06/16/2016|05:46:54|Update preparation
> |06/16/2016|05:46:54|Update comparison
> |06/16/2016|05:46:54|Update
> |06/16/2016|05:46:55|Update
> |06/16/2016|05:47:24|Close
> |06/16/2016|05:47:31|BOP processing for 3,016 items has finished
> |06/16/2016|05:47:32|Step 006
> |06/16/2016|05:47:32|Initialization
> |06/16/2016|05:47:32|Filters
> |06/16/2016|05:47:32|Update preparation
> |06/16/2016|05:47:32|Update comparison
> |06/16/2016|05:47:32|Update
> |06/16/2016|05:47:32|Close
> |06/16/2016|05:47:33|BOP processing for 0 items has finished
> |06/16/2016|05:47:33|Step 007
> |06/16/2016|05:47:33|Initialization
> |06/16/2016|05:47:33|Filters
> |06/16/2016|05:47:34|Split Items
> |06/16/2016|05:47:34|Sort
> |06/16/2016|05:47:34|Check
> |06/16/2016|05:47:37|Save
> |06/16/2016|05:47:37|Update preparation
> |06/16/2016|05:47:37|Update comparison
> |06/16/2016|05:47:37|Update
> |06/16/2016|05:47:37|Update
> |06/16/2016|05:47:37|Close
> |06/16/2016|05:47:37|BOP processing for 9 items has finished
> |06/16/2016|05:47:37|Step 008
> |06/16/2016|05:47:37|Initialization
> |06/16/2016|05:47:37|Filters
> |06/16/2016|05:47:38|Update preparation
> |06/16/2016|05:47:38|Update comparison
> |06/16/2016|05:47:38|Update
> |06/16/2016|05:47:38|Close
> |06/16/2016|05:47:38|BOP processing for 0 items has finished
>
>
>
>
> >> no_parallel_process_file.txt
>
> |06/15/2016|22:52:46|Step 001
> |06/15/2016|22:52:46|Initialization
>
> |06/15/2016|22:52:46|Filters
>
> |06/15/2016|22:54:21|Split Items
>
> |06/15/2016|22:55:10|Sort
>
> |06/15/2016|22:55:15|Check
>
> |06/15/2016|23:04:43|Save
>
> |06/15/2016|23:06:38|Update preparation
>
> |06/15/2016|23:06:38|Update comparison
>
> |06/15/2016|23:06:39|Update
>
> |06/15/2016|23:06:39|Update
>
> |06/15/2016|23:12:04|Close
>
> |06/15/2016|23:13:16|BOP processing for 7,942 items has finished
>
> |06/15/2016|23:13:17|Step 002
> |06/15/2016|23:13:17|Initialization
>
> |06/15/2016|23:13:17|Filters
>
> |06/15/2016|23:16:27|Split Items
>
> |06/15/2016|23:20:18|Sort
>
> |06/15/2016|23:20:34|Check
>
> |06/16/2016|00:08:08|Save
>
> |06/16/2016|00:26:19|Update preparation
>
> |06/16/2016|00:26:20|Update comparison
>
> |06/16/2016|00:26:30|Update
>
> |06/16/2016|00:26:31|Update
>
> |06/16/2016|00:42:31|Close
>
> |06/16/2016|00:45:09|BOP processing for 8,400 items has finished
>
> |06/16/2016|00:45:11|Step 003
> |06/16/2016|00:45:12|Initialization
>
> |06/16/2016|00:45:12|Filters
>
> |06/16/2016|00:53:01|Split Items
>
> |06/16/2016|01:01:44|Sort
>
> |06/16/2016|01:02:55|Check
>
> |06/16/2016|01:41:40|Save
>
> |06/16/2016|01:44:37|Update preparation
>
> |06/16/2016|01:44:37|Update comparison
>
> |06/16/2016|01:44:39|Update
>
> |06/16/2016|01:44:39|Update
>
> |06/16/2016|01:47:37|Close
>
> |06/16/2016|01:48:07|BOP processing for 8,867 items has finished
>
> |06/16/2016|01:48:08|Step 004
> |06/16/2016|01:48:08|Initialization
>
> |06/16/2016|01:48:08|Filters
>
> |06/16/2016|01:49:51|Split Items
>
> |06/16/2016|01:50:35|Sort
>
> |06/16/2016|01:50:39|Check
>
> |06/16/2016|01:59:12|Save
>
> |06/16/2016|02:00:47|Update preparation
>
> |06/16/2016|02:00:47|Update comparison
>
> |06/16/2016|02:00:48|Update
>
> |06/16/2016|02:00:48|Update
>
> |06/16/2016|02:02:40|Close
>
> |06/16/2016|02:02:55|BOP processing for 5,383 items has finished
>
> |06/16/2016|02:02:56|Step 005
> |06/16/2016|02:02:56|Initialization
>
> |06/16/2016|02:02:56|Filters
>
> |06/16/2016|02:03:47|Split Items
>
> |06/16/2016|02:04:19|Sort
>
> |06/16/2016|02:04:21|Check
>
> |06/16/2016|02:08:08|Save
>
> |06/16/2016|02:09:22|Update preparation
>
> |06/16/2016|02:09:22|Update comparison
>
> |06/16/2016|02:09:22|Update
>
> |06/16/2016|02:09:22|Update
>
> |06/16/2016|02:11:03|Close
>
> |06/16/2016|02:11:14|BOP processing for 3,016 items has finished
>
> |06/16/2016|02:11:14|Step 006
> |06/16/2016|02:11:14|Initialization
>
> |06/16/2016|02:11:14|Filters
>
> |06/16/2016|02:11:15|Update preparation
>
> |06/16/2016|02:11:15|Update comparison
>
> |06/16/2016|02:11:15|Update
>
> |06/16/2016|02:11:15|Close
>
> |06/16/2016|02:11:15|BOP processing for 0 items has finished
>
> |06/16/2016|02:11:15|Step 007
> |06/16/2016|02:11:15|Initialization
>
> |06/16/2016|02:11:15|Filters
>
> |06/16/2016|02:11:17|Split Items
>
> |06/16/2016|02:11:17|Sort
>
> |06/16/2016|02:11:17|Check
>
> |06/16/2016|02:11:20|Save
>
> |06/16/2016|02:11:20|Update preparation
>
> |06/16/2016|02:11:20|Update comparison
>
> |06/16/2016|02:11:20|Update
>
> |06/16/2016|02:11:20|Update
>
> |06/16/2016|02:11:20|Close
>
> |06/16/2016|02:11:20|BOP processing for 9 items has finished
>
> |06/16/2016|02:11:20|Step 008
> |06/16/2016|02:11:20|Initialization
>
> |06/16/2016|02:11:21|Filters
>
> |06/16/2016|02:11:21|Update preparation
>
> |06/16/2016|02:11:21|Update comparison
>
> |06/16/2016|02:11:21|Update
>
> |06/16/2016|02:11:21|Close
>
> |06/16/2016|02:11:21|BOP processing for 0 items has finished
>
>
>
> --
>
> Satish Vadlamani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pascal.niklaus at ieu.uzh.ch  Fri Jun 17 17:45:16 2016
From: pascal.niklaus at ieu.uzh.ch (Pascal A. Niklaus)
Date: Fri, 17 Jun 2016 17:45:16 +0200
Subject: [R] import of data set and warning from R CMD check
Message-ID: <57641B0C.6030705@ieu.uzh.ch>

Hi all,

When checking an R package, I get:

|Consider adding importFrom("datasets","CO2")

(this data set is used in some example code)

However, when I add the suggested 'importFrom' statement to NAMESPACE 
(using roxygen2), I get
|
|Error :object ?CO2? is not exported by 'namespace:datasets'|
||
|I understand that datasets are not exported, and the comment printed by 
'R CMD check' seems not to have any consequences, but it nevertheless 
seems inconsistent to me. But maybe I miss something here...

Pascal

|

-- 

Dr. Pascal A. Niklaus
Department of Evolutionary Biology and Environmental Studies
University of Zurich
Winterthurerstrasse 190
CH-8057 Zurich / Switzerland


||||

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Jun 17 18:15:32 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 17 Jun 2016 16:15:32 +0000
Subject: [R] Obtaining and extracting cells sample in cross-tabulation
In-Reply-To: <CAFcbP-BrNDhnDmhwP3-tGj6KeNCBd0Nds99EnMSgriRPBb9=ig@mail.gmail.com>
References: <CAFcbP-A9wqzvXLeAek71cf6C_9dG1ZFm0CKexJF7RWxa=ADEVQ@mail.gmail.com>
	<CAFcbP-Bd0y_qFfFQKPQzUxqDN-S4rNZCgaaX0G3pwTnZD4wzFw@mail.gmail.com>
	<CAFcbP-CJWpkzD+YF7h-_eLmBgHsf8nWfRAfZDfALovwG7-c1yQ@mail.gmail.com>
	<CAFcbP-B2L4eWZupGiYbdrBFD=mgH4pr+gw9v-cVK3FRsSjNPkw@mail.gmail.com>
	<CAFcbP-BR=AzfvqPDc-A9doDcZRww=cMabhxAh06x0mmgJx6ygw@mail.gmail.com>
	<CAFcbP-AJUSPvaw2LPL4jr_GGXbBzR-N8RAryVCaq-pHCfkdsXQ@mail.gmail.com>
	<CAFcbP-Bz5fz-tY_j=pScEVeigEOSgtpih+Sk9fVHUsmvNvNGvw@mail.gmail.com>
	<CAFcbP-DaNL3qrKOJYN5tMkK5=Zd+Vox5EGgbqh8MEUProD0jgg@mail.gmail.com>
	<CAFcbP-AFP_b1=31xnH7Grj23nnJ-nAa8VZzVMOuB0Jth_a4sfQ@mail.gmail.com>
	<CAFcbP-BFGiP9_w=dReE+tKyVAi035fvLZ4RYYb+qqrH-tTrYAg@mail.gmail.com>
	<CAFcbP-CESK1PP9MUK40QMbrTajumYMTnkPi6LJQyn23Wpb40Bg@mail.gmail.com>
	<CAFcbP-Ba1JnAVyEdStNOMhpLP1_iPke88vZvUDK9B1eX=mo5iw@mail.gmail.com>
	<CAFcbP-C9BD-i5eYB7qOH0UQV7t4b+KoUdfo8gZg_uaHm4w_jdg@mail.gmail.com>
	<CAFcbP-BrNDhnDmhwP3-tGj6KeNCBd0Nds99EnMSgriRPBb9=ig@mail.gmail.com>
Message-ID: <D3896F05.17BE5C%macqueen1@llnl.gov>

I don't know exactly what you mean, but perhaps this will get you started:

This:
subset(Data, X4==1 & X5==1, select=c(X1, X2, X3))
will extract the continuous variables in the cross-tabulation cell for
which X4 and X5 are both equal to one. Similar commands will extract the
other cells.

Of course, this gets tedious if your categorical variables have more than
two levels.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/17/16, 5:25 AM, "R-help on behalf of Gafar Matanmi Oyeyemi"
<r-help-bounces at r-project.org on behalf of gmoyeyemi at gmail.com> wrote:

>Hello everyone,
>I'm writing a function in R but was stalked.
>I have a data set that contains mixture of categorical and continuous
>variables. I want to use the categorical variables to cross-tabulate the
>data and extract the observations in the resulting cells that contain only
>continuous variables.
>
>Data.
>X1   X2   X3   X4   X5
>2.4  5.3  4.8    0      1
>4.2  3.2  4.8    1      1
>3.3  4.4  5.1    0      0
>5.2  1.1  2.5    1      0
>.
>.
>.
>3.7  2.8  3.8    0      1
>
>Thanks.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From adomalik at sfu.ca  Fri Jun 17 19:26:32 2016
From: adomalik at sfu.ca (Alice Domalik)
Date: Fri, 17 Jun 2016 10:26:32 -0700 (PDT)
Subject: [R] Excluding coordinates that fall within a circle
In-Reply-To: <130565413.23175770.1466183644080.JavaMail.zimbra@sfu.ca>
Message-ID: <1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>

Hi List, 

I'm working with some bird tracking data, and to filter the data set, I need to exclude points taken at the colony. 
I would like to exclude coordinates from within a 500 meter radius of a point centered on the colony. 
However, as an R novice, I'm not sure how to accomplish this. 

My df looks like this: 

AnimalID Latitude Longitude Datetime 

Any suggestions would be greatly appreciated. 


	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Jun 17 20:09:12 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 17 Jun 2016 18:09:12 +0000
Subject: [R] Excluding coordinates that fall within a circle
Message-ID: <D38988D0.17BE9F%macqueen1@llnl.gov>

This would be a good question for R-sig-geo.

To do it properly, there would be a few steps:

1. transform from lat/long (units=degrees) to projected coordinate system
(units = meters)

2. find one of the R functions for calculating distances (there are
several)

3. subset the data according to your distance threshold

The sp package provides a lot of the fundamental tools for these kinds of
things.

The spDists() function in the sp package may take care of both steps 1 and
2.

The overhead required to learn R's spatial capabilities can be
significant, but I think will be worth it if you will be needing to do a
lot of spatial manipulations.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/17/16, 10:26 AM, "R-help on behalf of Alice Domalik"
<r-help-bounces at r-project.org on behalf of adomalik at sfu.ca> wrote:

>Hi List, 
>
>I'm working with some bird tracking data, and to filter the data set, I
>need to exclude points taken at the colony.
>I would like to exclude coordinates from within a 500 meter radius of a
>point centered on the colony.
>However, as an R novice, I'm not sure how to accomplish this.
>
>My df looks like this:
>
>AnimalID Latitude Longitude Datetime
>
>Any suggestions would be greatly appreciated.
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Jun 17 20:09:38 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Jun 2016 11:09:38 -0700
Subject: [R] Excluding coordinates that fall within a circle
In-Reply-To: <1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>
References: <1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>
Message-ID: <5D46931F-978F-47CA-B39D-8864FCFE7055@comcast.net>


> On Jun 17, 2016, at 10:26 AM, Alice Domalik <adomalik at sfu.ca> wrote:
> 
> Hi List, 
> 
> I'm working with some bird tracking data, and to filter the data set, I need to exclude points taken at the colony. 
> I would like to exclude coordinates from within a 500 meter radius of a point centered on the colony. 
> However, as an R novice, I'm not sure how to accomplish this. 
> 
> My df looks like this: 
> 
> AnimalID Latitude Longitude Datetime 


Use the first argument of the "[" function to select rows that meet your requirement. I constructed values in hte unit square and select only items in hte corners by excluding values within 0.5 units of the center, (0.5,0.5)


dfrm <- data.frame(ID=1:100, lat=runif(100), long=runif(100), 
                   Datetime=as.POSIXct(runif(100)*10000,origin="1970-01-01") )
reduced <- dfrm[ (dfrm$lat - .5)^2+(dfrm$long-.5)^2 > .25 , ]
with( reduced, plot(lat,long) )

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.pdf
Type: application/pdf
Size: 90150 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160617/a96d318d/attachment.pdf>
-------------- next part --------------


Probably should have plotted (long, lat), and it might have been more eser freindly to use subset instead of `[ logical-vector, ]`  but I think this demonstrates the essential steps.

-- 

David Winsemius
Alameda, CA, USA


From tom at maladmin.com  Fri Jun 17 20:15:42 2016
From: tom at maladmin.com (Tom Wright)
Date: Fri, 17 Jun 2016 14:15:42 -0400
Subject: [R] Excluding coordinates that fall within a circle
In-Reply-To: <1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>
References: <130565413.23175770.1466183644080.JavaMail.zimbra@sfu.ca>
	<1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>
Message-ID: <CAKmUXV_KwG72oZYZsztHtYUjFFKtKGtLziUoN+neQddq5jRzww@mail.gmail.com>

I'm no expert here but I have recently been playing with the package
'geosphere' it contains plenty of options to calculate distance
between two coordinates specified as lat and long.

install.packages('geosphere') # only needed once

library(geosphere)
coord1 <- c(43.60923,-79.322799)
coord2 <- c(43.683266,-79.323703)

distHaversine(coord1,coord2)

Once you have a vector of distances you can then filter your df

df <- df[df$distance < radius,]

On Fri, Jun 17, 2016 at 1:26 PM, Alice Domalik <adomalik at sfu.ca> wrote:
> Hi List,
>
> I'm working with some bird tracking data, and to filter the data set, I need to exclude points taken at the colony.
> I would like to exclude coordinates from within a 500 meter radius of a point centered on the colony.
> However, as an R novice, I'm not sure how to accomplish this.
>
> My df looks like this:
>
> AnimalID Latitude Longitude Datetime
>
> Any suggestions would be greatly appreciated.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr206 at kent.ac.uk  Fri Jun 17 20:23:26 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 17 Jun 2016 18:23:26 +0000
Subject: [R] extracting coefficients from ar() output
In-Reply-To: <BE03BC36-0DF7-4570-9A8F-DBE3A6F959FE@gmail.com>
References: <1466076844890.54542@kent.ac.uk>
	<CAF8bMcYtv8YfwKUQF2GnDkxDq_U=5xx+6ygDGPmADhPz1kw57Q@mail.gmail.com>
	<BE03BC36-0DF7-4570-9A8F-DBE3A6F959FE@gmail.com>
Message-ID: <5474a6a854754d99807ab2c1f6b48758@ex13-live-mbn1.ad.kent.ac.uk>

Thank you very much, Peter. I played a bit and found a solution. 
> rollingarmaols<-rollapply(data,width=36,function(data) ar(data,order.max=1,method="ols"))
> coefar<-apply(rollingarmaols, 1, getElement, "ar")
> head(coefar,50)
 [1] 0.9430692 0.9140253 0.9236898 0.9426744 0.9465110 0.9318470 0.9033054 0.9206048 0.9243736 0.9129082
[11] 0.9181811 0.9350779 0.9464205 0.9410245 0.9335568 0.9201928 0.8869414 0.8320984 0.8185671 0.7989182
[21] 0.7454876 0.6388364 0.6797046 0.6704642 0.7077033 0.8895698 0.8755445 0.8965050 0.8969068 0.8891385
[31] 0.9284835 0.9628297 0.9674624 0.9524462 0.9423693 0.9629843 0.9996613 1.0000295 0.9845222 0.9877242
[41] 0.9582863 0.9596756 0.9415847 0.9471677 0.9447052 0.9324048 0.9171082 0.8928825 0.9133751 0.9203662

I am trying to export the data to Excel using WriteXLS:
> WriteXLS(coefar, ExcelFileName = "R.xls", SheetNames = test)

Unfortunately, it doesn't work. How can I export the data to Excel?

-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: 16 June 2016 18:49
To: William Dunlap
Cc: T.Riedle; R-help at r-project.org
Subject: Re: [R] extracting coefficients from ar() output


> On 16 Jun 2016, at 17:07 , William Dunlap via R-help <r-help at r-project.org> wrote:
> 
> help(ar) should tell you how to get the coefficients.  If, like me, 
> you don't read help files, you can use str() to look at the structure 
> of ar's output.

Also notice that the output of rollapply is not an ar object. More likely a list of them, so  try rollingarma[[i]]$ar or maybe lapply(rollingarma, function(x)x$ar) or sapply(rollingarma, "[[", "ar") or...

> 
>> str(a <- ar(sin(1:30), aic=TRUE))
> List of 14
> $ order       : int 2
> $ ar          : num [1:2] 1.011 -0.918
> $ var.pred    : num 0.0654
> $ x.mean      : num 0.00934
> $ aic         : Named num [1:15] 61.215 53.442 0 0.985 2.917 ...
>  ..- attr(*, "names")= chr [1:15] "0" "1" "2" "3" ...
> $ n.used      : int 30
> $ order.max   : num 14
> $ partialacf  : num [1:14, 1, 1] 0.5273 -0.9179 -0.1824 -0.0477 -0.0393 ...
> $ resid       : num [1:30] NA NA -0.0145 -0.0734 -0.0725 ...
> $ method      : chr "Yule-Walker"
> $ series      : chr "sin(1:30)"
> $ frequency   : num 1
> $ call        : language ar(x = sin(1:30), aic = TRUE)
> $ asy.var.coef: num [1:2, 1:2] 0.00583 -0.00308 -0.00308 0.00583
> - attr(*, "class")= chr "ar"
>> a$ar
> [1]  1.0112512 -0.9178554
> 
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Thu, Jun 16, 2016 at 4:34 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
>> Hi everybody,
>> 
>> I am trying to run an AR1 model using the ar() function as shown below.
>> 
>>> rollingarma<-rollapply(data,width=36,function(data) 
>>> ar(data,aic=TRUE))
>>> head(rollingarma,50)
>>      order ar        var.pred x.mean   aic        n.used order.max
>> partialacf resid      method        series
>> [1,] 1     0.7433347 1.382908 49.99861 Numeric,16 36     15
>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>> [2,] 1     0.7410181 1.565755 49.94778 Numeric,16 36     15
>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>> [3,] 1     0.7636966 1.660581 49.86861 Numeric,16 36     15
>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>> 
>> 
>> I get the table as shown above if I use head().
>> 
>> How can I extract the ar coefficients from this table? I have already 
>> tried coef() and rollingarma$ar but both do not work.
>> What can I do?
>> 
>> Thanks for your help.
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Fri Jun 17 20:27:17 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Jun 2016 11:27:17 -0700
Subject: [R] extracting coefficients from ar() output
In-Reply-To: <5474a6a854754d99807ab2c1f6b48758@ex13-live-mbn1.ad.kent.ac.uk>
References: <1466076844890.54542@kent.ac.uk>
	<CAF8bMcYtv8YfwKUQF2GnDkxDq_U=5xx+6ygDGPmADhPz1kw57Q@mail.gmail.com>
	<BE03BC36-0DF7-4570-9A8F-DBE3A6F959FE@gmail.com>
	<5474a6a854754d99807ab2c1f6b48758@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <B3BAB004-9E3E-492A-9C7C-551C7EB120D7@comcast.net>


> On Jun 17, 2016, at 11:23 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Thank you very much, Peter. I played a bit and found a solution. 
>> rollingarmaols<-rollapply(data,width=36,function(data) ar(data,order.max=1,method="ols"))
>> coefar<-apply(rollingarmaols, 1, getElement, "ar")
>> head(coefar,50)
> [1] 0.9430692 0.9140253 0.9236898 0.9426744 0.9465110 0.9318470 0.9033054 0.9206048 0.9243736 0.9129082
> [11] 0.9181811 0.9350779 0.9464205 0.9410245 0.9335568 0.9201928 0.8869414 0.8320984 0.8185671 0.7989182
> [21] 0.7454876 0.6388364 0.6797046 0.6704642 0.7077033 0.8895698 0.8755445 0.8965050 0.8969068 0.8891385
> [31] 0.9284835 0.9628297 0.9674624 0.9524462 0.9423693 0.9629843 0.9996613 1.0000295 0.9845222 0.9877242
> [41] 0.9582863 0.9596756 0.9415847 0.9471677 0.9447052 0.9324048 0.9171082 0.8928825 0.9133751 0.9203662
> 
> I am trying to export the data to Excel using WriteXLS:
>> WriteXLS(coefar, ExcelFileName = "R.xls", SheetNames = test)

Just a guess (since you didn't include the error message) but do you have a length-1 character vector named `test`. I thought not. So try using SheetNames = 'test'

-- 
David.
> 
> Unfortunately, it doesn't work. How can I export the data to Excel?
> 
> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com] 
> Sent: 16 June 2016 18:49
> To: William Dunlap
> Cc: T.Riedle; R-help at r-project.org
> Subject: Re: [R] extracting coefficients from ar() output
> 
> 
>> On 16 Jun 2016, at 17:07 , William Dunlap via R-help <r-help at r-project.org> wrote:
>> 
>> help(ar) should tell you how to get the coefficients.  If, like me, 
>> you don't read help files, you can use str() to look at the structure 
>> of ar's output.
> 
> Also notice that the output of rollapply is not an ar object. More likely a list of them, so  try rollingarma[[i]]$ar or maybe lapply(rollingarma, function(x)x$ar) or sapply(rollingarma, "[[", "ar") or...
> 
>> 
>>> str(a <- ar(sin(1:30), aic=TRUE))
>> List of 14
>> $ order       : int 2
>> $ ar          : num [1:2] 1.011 -0.918
>> $ var.pred    : num 0.0654
>> $ x.mean      : num 0.00934
>> $ aic         : Named num [1:15] 61.215 53.442 0 0.985 2.917 ...
>> ..- attr(*, "names")= chr [1:15] "0" "1" "2" "3" ...
>> $ n.used      : int 30
>> $ order.max   : num 14
>> $ partialacf  : num [1:14, 1, 1] 0.5273 -0.9179 -0.1824 -0.0477 -0.0393 ...
>> $ resid       : num [1:30] NA NA -0.0145 -0.0734 -0.0725 ...
>> $ method      : chr "Yule-Walker"
>> $ series      : chr "sin(1:30)"
>> $ frequency   : num 1
>> $ call        : language ar(x = sin(1:30), aic = TRUE)
>> $ asy.var.coef: num [1:2, 1:2] 0.00583 -0.00308 -0.00308 0.00583
>> - attr(*, "class")= chr "ar"
>>> a$ar
>> [1]  1.0112512 -0.9178554
>> 
>> 
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> On Thu, Jun 16, 2016 at 4:34 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
>> 
>>> Hi everybody,
>>> 
>>> I am trying to run an AR1 model using the ar() function as shown below.
>>> 
>>>> rollingarma<-rollapply(data,width=36,function(data) 
>>>> ar(data,aic=TRUE))
>>>> head(rollingarma,50)
>>>     order ar        var.pred x.mean   aic        n.used order.max
>>> partialacf resid      method        series
>>> [1,] 1     0.7433347 1.382908 49.99861 Numeric,16 36     15
>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>> [2,] 1     0.7410181 1.565755 49.94778 Numeric,16 36     15
>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>> [3,] 1     0.7636966 1.660581 49.86861 Numeric,16 36     15
>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>> 
>>> 
>>> I get the table as shown above if I use head().
>>> 
>>> How can I extract the ar coefficients from this table? I have already 
>>> tried coef() and rollingarma$ar but both do not work.
>>> What can I do?
>>> 
>>> Thanks for your help.
>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Fri Jun 17 20:29:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 17 Jun 2016 11:29:19 -0700
Subject: [R] Excluding coordinates that fall within a circle
In-Reply-To: <1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>
References: <1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>
Message-ID: <CCC25B14-7069-4E5B-AFE3-86D8183845E3@dcn.davis.ca.us>

This is mostly a domain-specific question about coordinate conversion and algebra, not really about R. However, there are packages that could be useful for this problem that are discussed in the CRAN "Analysis of Spatial Data" Task View [1] and on the R-sig-geo mailing list [2].

Some points to get you started:

1) You need to know about georeferencing coordinate systems. In particular, what LatLon system are the coordinates you have measured in. The range of values in your data will be something to mention when you ask your question on R-sig-geo if they are to help you figure that out. 

2) A small sample of your data extracted from R with the dput function will be helpful. 

3) Read the Posting Guide. Note in particular that you need to tell your email client to use plain text format if you want to insure that the recipients see what you sent instead of some garbled version of it. 

[1] https://cran.r-project.org/view=Spatial
[2] https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-- 
Sent from my phone. Please excuse my brevity.

On June 17, 2016 10:26:32 AM PDT, Alice Domalik <adomalik at sfu.ca> wrote:
>Hi List, 
>
>I'm working with some bird tracking data, and to filter the data set, I
>need to exclude points taken at the colony. 
>I would like to exclude coordinates from within a 500 meter radius of a
>point centered on the colony. 
>However, as an R novice, I'm not sure how to accomplish this. 
>
>My df looks like this: 
>
>AnimalID Latitude Longitude Datetime 
>
>Any suggestions would be greatly appreciated. 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Fri Jun 17 20:34:36 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 17 Jun 2016 18:34:36 +0000
Subject: [R] extracting coefficients from ar() output
In-Reply-To: <B3BAB004-9E3E-492A-9C7C-551C7EB120D7@comcast.net>
References: <1466076844890.54542@kent.ac.uk>
	<CAF8bMcYtv8YfwKUQF2GnDkxDq_U=5xx+6ygDGPmADhPz1kw57Q@mail.gmail.com>
	<BE03BC36-0DF7-4570-9A8F-DBE3A6F959FE@gmail.com>
	<5474a6a854754d99807ab2c1f6b48758@ex13-live-mbn1.ad.kent.ac.uk>
	<B3BAB004-9E3E-492A-9C7C-551C7EB120D7@comcast.net>
Message-ID: <67df521b69614a0fb32a5be5d33184cb@ex13-live-mbn1.ad.kent.ac.uk>

Thank you very much.
Here is the error message.

> WriteXLS(coefar,ExcelFileName = "R.xls",SheetNames="test")
Error in WriteXLS(coefar, ExcelFileName = "R.xls", SheetNames = "test") : 
  'x' must be the name of a data frame, the name of a list of data frames, a data frame object, a list object of data frames.

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: 17 June 2016 19:27
To: T.Riedle
Cc: peter dalgaard; R-help at r-project.org
Subject: Re: [R] extracting coefficients from ar() output


> On Jun 17, 2016, at 11:23 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Thank you very much, Peter. I played a bit and found a solution. 
>> rollingarmaols<-rollapply(data,width=36,function(data) 
>> ar(data,order.max=1,method="ols"))
>> coefar<-apply(rollingarmaols, 1, getElement, "ar")
>> head(coefar,50)
> [1] 0.9430692 0.9140253 0.9236898 0.9426744 0.9465110 0.9318470 
> 0.9033054 0.9206048 0.9243736 0.9129082 [11] 0.9181811 0.9350779 
> 0.9464205 0.9410245 0.9335568 0.9201928 0.8869414 0.8320984 0.8185671 
> 0.7989182 [21] 0.7454876 0.6388364 0.6797046 0.6704642 0.7077033 
> 0.8895698 0.8755445 0.8965050 0.8969068 0.8891385 [31] 0.9284835 
> 0.9628297 0.9674624 0.9524462 0.9423693 0.9629843 0.9996613 1.0000295 
> 0.9845222 0.9877242 [41] 0.9582863 0.9596756 0.9415847 0.9471677 
> 0.9447052 0.9324048 0.9171082 0.8928825 0.9133751 0.9203662
> 
> I am trying to export the data to Excel using WriteXLS:
>> WriteXLS(coefar, ExcelFileName = "R.xls", SheetNames = test)

Just a guess (since you didn't include the error message) but do you have a length-1 character vector named `test`. I thought not. So try using SheetNames = 'test'

--
David.
> 
> Unfortunately, it doesn't work. How can I export the data to Excel?
> 
> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com]
> Sent: 16 June 2016 18:49
> To: William Dunlap
> Cc: T.Riedle; R-help at r-project.org
> Subject: Re: [R] extracting coefficients from ar() output
> 
> 
>> On 16 Jun 2016, at 17:07 , William Dunlap via R-help <r-help at r-project.org> wrote:
>> 
>> help(ar) should tell you how to get the coefficients.  If, like me, 
>> you don't read help files, you can use str() to look at the structure 
>> of ar's output.
> 
> Also notice that the output of rollapply is not an ar object. More likely a list of them, so  try rollingarma[[i]]$ar or maybe lapply(rollingarma, function(x)x$ar) or sapply(rollingarma, "[[", "ar") or...
> 
>> 
>>> str(a <- ar(sin(1:30), aic=TRUE))
>> List of 14
>> $ order       : int 2
>> $ ar          : num [1:2] 1.011 -0.918
>> $ var.pred    : num 0.0654
>> $ x.mean      : num 0.00934
>> $ aic         : Named num [1:15] 61.215 53.442 0 0.985 2.917 ...
>> ..- attr(*, "names")= chr [1:15] "0" "1" "2" "3" ...
>> $ n.used      : int 30
>> $ order.max   : num 14
>> $ partialacf  : num [1:14, 1, 1] 0.5273 -0.9179 -0.1824 -0.0477 -0.0393 ...
>> $ resid       : num [1:30] NA NA -0.0145 -0.0734 -0.0725 ...
>> $ method      : chr "Yule-Walker"
>> $ series      : chr "sin(1:30)"
>> $ frequency   : num 1
>> $ call        : language ar(x = sin(1:30), aic = TRUE)
>> $ asy.var.coef: num [1:2, 1:2] 0.00583 -0.00308 -0.00308 0.00583
>> - attr(*, "class")= chr "ar"
>>> a$ar
>> [1]  1.0112512 -0.9178554
>> 
>> 
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> On Thu, Jun 16, 2016 at 4:34 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
>> 
>>> Hi everybody,
>>> 
>>> I am trying to run an AR1 model using the ar() function as shown below.
>>> 
>>>> rollingarma<-rollapply(data,width=36,function(data)
>>>> ar(data,aic=TRUE))
>>>> head(rollingarma,50)
>>>     order ar        var.pred x.mean   aic        n.used order.max
>>> partialacf resid      method        series
>>> [1,] 1     0.7433347 1.382908 49.99861 Numeric,16 36     15
>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>> [2,] 1     0.7410181 1.565755 49.94778 Numeric,16 36     15
>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>> [3,] 1     0.7636966 1.660581 49.86861 Numeric,16 36     15
>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>> 
>>> 
>>> I get the table as shown above if I use head().
>>> 
>>> How can I extract the ar coefficients from this table? I have 
>>> already tried coef() and rollingarma$ar but both do not work.
>>> What can I do?
>>> 
>>> Thanks for your help.
>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 
> 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Fri Jun 17 20:40:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 17 Jun 2016 11:40:45 -0700
Subject: [R] Excluding coordinates that fall within a circle
In-Reply-To: <1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>
References: <130565413.23175770.1466183644080.JavaMail.zimbra@sfu.ca>
	<1628514766.23197020.1466184392035.JavaMail.zimbra@sfu.ca>
Message-ID: <CAGxFJbR9JpV+CR7u9T+xN8p8ikRjUgycMa4oinFFNBhHxnMzzg@mail.gmail.com>

...
and adding, perhaps, to what David and Jeff told you:

Let ctr = c(ctr.lat, ctr.long) be the center of a bird colony (this
can be vectorized for many centers).

Then you need to figure out how much change in latitude and longitude
a distance of 500 meters is at that ctr (I think latitudes are easy;
it's longitudes that vary in distance depending on where you. But I
hasten to add that I ain't an expert). You can approximate this by
pretending the latitudes and longitude are perpendicular on a plane
unless you are close to the poles.I strongly suspect there are
functions in geostatistics and/or ecology packages that do this:
search (e.g. web or rseek.org) on "convert distance to latitude and
longitude" or similar (this seemed to yield useful results when I
tried it). Then apply David's (and Jeff's) suggestions.

Cheers,

Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 17, 2016 at 10:26 AM, Alice Domalik <adomalik at sfu.ca> wrote:
> Hi List,
>
> I'm working with some bird tracking data, and to filter the data set, I need to exclude points taken at the colony.
> I would like to exclude coordinates from within a 500 meter radius of a point centered on the colony.
> However, as an R novice, I'm not sure how to accomplish this.
>
> My df looks like this:
>
> AnimalID Latitude Longitude Datetime
>
> Any suggestions would be greatly appreciated.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Fri Jun 17 22:06:29 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Fri, 17 Jun 2016 20:06:29 +0000 (UTC)
Subject: [R] merging df with world map
References: <871107819.8642588.1466193989968.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <871107819.8642588.1466193989968.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I want to use world map in ggplot2 and show my data on world map. my df is:


    $ COUNTRY           : chr  "DE" "DE" "FR" "FR" ..

    $ ContrastColor     : int  9 9 9 9 13 9 9 9 9 ..

    $ quant             : Factor w/ 4 levels "FAST","SLOW",..I need to merge my df with world_map data which is like this:

    
    world_map=map_data("world")
    data.frame':   99338 obs. of  6 variables:
    $ long     : num  -69.9 -69.9 -69.9 -70 -70.1 ...
    $ lat      : num  12.5 12.4 12.4 12.5 12.5 ...
    $ group    : num  1 1 1 1 1 1 1 1 1 1 ...
    $ order    : int  1 2 3 4 5 6 7 8 9 10 ...
    $ region   : chr  "Aruba" "Aruba" "Aruba" "Aruba" ...
    $ subregion: chr  NA NA NA NA ...
but by merging my df with world map data I get a data frame with zero observation in it,I use this command for merging:


    world_map=merge(world_map,df,by.x="region",by.y="COUNTRY")
    str(world_map) 

    'data.frame':   0 obs. of  133 variables:
    $ region            : chr 
    $ long              : num 
    $ lat               : num 
    $ group             : num 
    $ order             : int 
    $ subregion         : chr
does anyone know what is the problem of this merging that I am currently using?
thanks for any help!
Elahe


From dwinsemius at comcast.net  Fri Jun 17 22:19:59 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Jun 2016 13:19:59 -0700
Subject: [R] extracting coefficients from ar() output
In-Reply-To: <67df521b69614a0fb32a5be5d33184cb@ex13-live-mbn1.ad.kent.ac.uk>
References: <1466076844890.54542@kent.ac.uk>
	<CAF8bMcYtv8YfwKUQF2GnDkxDq_U=5xx+6ygDGPmADhPz1kw57Q@mail.gmail.com>
	<BE03BC36-0DF7-4570-9A8F-DBE3A6F959FE@gmail.com>
	<5474a6a854754d99807ab2c1f6b48758@ex13-live-mbn1.ad.kent.ac.uk>
	<B3BAB004-9E3E-492A-9C7C-551C7EB120D7@comcast.net>
	<67df521b69614a0fb32a5be5d33184cb@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <0966A0EC-7B9B-4EA2-9B4D-4CE6C2824974@comcast.net>


> On Jun 17, 2016, at 11:34 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Thank you very much.
> Here is the error message.
> 
>> WriteXLS(coefar,ExcelFileName = "R.xls",SheetNames="test")
> Error in WriteXLS(coefar, ExcelFileName = "R.xls", SheetNames = "test") : 
>  'x' must be the name of a data frame, the name of a list of data frames, a data frame object, a list object of data frames.

sos::findFn("writeXLS")

So after tracking down the package that has writeXLS (also named writeXLS), I see that the example in the help page quotes the names of dataframe objects and the help page says the x values should be _character_ (rather than R symbol/names). You didn't provide a character vector as the first argument which, since it was unnamed, was therefore matched to the 'x' parameter.

-- 
David.
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: 17 June 2016 19:27
> To: T.Riedle
> Cc: peter dalgaard; R-help at r-project.org
> Subject: Re: [R] extracting coefficients from ar() output
> 
> 
>> On Jun 17, 2016, at 11:23 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
>> 
>> Thank you very much, Peter. I played a bit and found a solution. 
>>> rollingarmaols<-rollapply(data,width=36,function(data) 
>>> ar(data,order.max=1,method="ols"))
>>> coefar<-apply(rollingarmaols, 1, getElement, "ar")
>>> head(coefar,50)
>> [1] 0.9430692 0.9140253 0.9236898 0.9426744 0.9465110 0.9318470 
>> 0.9033054 0.9206048 0.9243736 0.9129082 [11] 0.9181811 0.9350779 
>> 0.9464205 0.9410245 0.9335568 0.9201928 0.8869414 0.8320984 0.8185671 
>> 0.7989182 [21] 0.7454876 0.6388364 0.6797046 0.6704642 0.7077033 
>> 0.8895698 0.8755445 0.8965050 0.8969068 0.8891385 [31] 0.9284835 
>> 0.9628297 0.9674624 0.9524462 0.9423693 0.9629843 0.9996613 1.0000295 
>> 0.9845222 0.9877242 [41] 0.9582863 0.9596756 0.9415847 0.9471677 
>> 0.9447052 0.9324048 0.9171082 0.8928825 0.9133751 0.9203662
>> 
>> I am trying to export the data to Excel using WriteXLS:
>>> WriteXLS(coefar, ExcelFileName = "R.xls", SheetNames = test)
> 
> Just a guess (since you didn't include the error message) but do you have a length-1 character vector named `test`. I thought not. So try using SheetNames = 'test'
> 
> --
> David.
>> 
>> Unfortunately, it doesn't work. How can I export the data to Excel?
>> 
>> -----Original Message-----
>> From: peter dalgaard [mailto:pdalgd at gmail.com]
>> Sent: 16 June 2016 18:49
>> To: William Dunlap
>> Cc: T.Riedle; R-help at r-project.org
>> Subject: Re: [R] extracting coefficients from ar() output
>> 
>> 
>>> On 16 Jun 2016, at 17:07 , William Dunlap via R-help <r-help at r-project.org> wrote:
>>> 
>>> help(ar) should tell you how to get the coefficients.  If, like me, 
>>> you don't read help files, you can use str() to look at the structure 
>>> of ar's output.
>> 
>> Also notice that the output of rollapply is not an ar object. More likely a list of them, so  try rollingarma[[i]]$ar or maybe lapply(rollingarma, function(x)x$ar) or sapply(rollingarma, "[[", "ar") or...
>> 
>>> 
>>>> str(a <- ar(sin(1:30), aic=TRUE))
>>> List of 14
>>> $ order       : int 2
>>> $ ar          : num [1:2] 1.011 -0.918
>>> $ var.pred    : num 0.0654
>>> $ x.mean      : num 0.00934
>>> $ aic         : Named num [1:15] 61.215 53.442 0 0.985 2.917 ...
>>> ..- attr(*, "names")= chr [1:15] "0" "1" "2" "3" ...
>>> $ n.used      : int 30
>>> $ order.max   : num 14
>>> $ partialacf  : num [1:14, 1, 1] 0.5273 -0.9179 -0.1824 -0.0477 -0.0393 ...
>>> $ resid       : num [1:30] NA NA -0.0145 -0.0734 -0.0725 ...
>>> $ method      : chr "Yule-Walker"
>>> $ series      : chr "sin(1:30)"
>>> $ frequency   : num 1
>>> $ call        : language ar(x = sin(1:30), aic = TRUE)
>>> $ asy.var.coef: num [1:2, 1:2] 0.00583 -0.00308 -0.00308 0.00583
>>> - attr(*, "class")= chr "ar"
>>>> a$ar
>>> [1]  1.0112512 -0.9178554
>>> 
>>> 
>>> 
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> On Thu, Jun 16, 2016 at 4:34 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
>>> 
>>>> Hi everybody,
>>>> 
>>>> I am trying to run an AR1 model using the ar() function as shown below.
>>>> 
>>>>> rollingarma<-rollapply(data,width=36,function(data)
>>>>> ar(data,aic=TRUE))
>>>>> head(rollingarma,50)
>>>>    order ar        var.pred x.mean   aic        n.used order.max
>>>> partialacf resid      method        series
>>>> [1,] 1     0.7433347 1.382908 49.99861 Numeric,16 36     15
>>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>>> [2,] 1     0.7410181 1.565755 49.94778 Numeric,16 36     15
>>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>>> [3,] 1     0.7636966 1.660581 49.86861 Numeric,16 36     15
>>>> Numeric,15 Numeric,36 "Yule-Walker" "data"
>>>> 
>>>> 
>>>> I get the table as shown above if I use head().
>>>> 
>>>> How can I extract the ar coefficients from this table? I have 
>>>> already tried coef() and rollingarma$ar but both do not work.
>>>> What can I do?
>>>> 
>>>> Thanks for your help.
>>>> 
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 
>> 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Fri Jun 17 22:21:30 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 17 Jun 2016 13:21:30 -0700
Subject: [R] merging df with world map
In-Reply-To: <871107819.8642588.1466193989968.JavaMail.yahoo@mail.yahoo.com>
References: <871107819.8642588.1466193989968.JavaMail.yahoo.ref@mail.yahoo.com>
	<871107819.8642588.1466193989968.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <0EF9EF76-2F4C-4681-85FB-92619A35E4DB@dcn.davis.ca.us>

You should look at your own data before you post. The information in COUNTRY is not the same as the information in region.

Also, dput is better than str for posting questions. 
-- 
Sent from my phone. Please excuse my brevity.

On June 17, 2016 1:06:29 PM PDT, "ch.elahe via R-help" <r-help at r-project.org> wrote:
>Hi all,
>I want to use world map in ggplot2 and show my data on world map. my df
>is:
>
>
>    $ COUNTRY           : chr  "DE" "DE" "FR" "FR" ..
>
>    $ ContrastColor     : int  9 9 9 9 13 9 9 9 9 ..
>
>$ quant             : Factor w/ 4 levels "FAST","SLOW",..I need to
>merge my df with world_map data which is like this:
>
>    
>    world_map=map_data("world")
>    data.frame':   99338 obs. of  6 variables:
>    $ long     : num  -69.9 -69.9 -69.9 -70 -70.1 ...
>    $ lat      : num  12.5 12.4 12.4 12.5 12.5 ...
>    $ group    : num  1 1 1 1 1 1 1 1 1 1 ...
>    $ order    : int  1 2 3 4 5 6 7 8 9 10 ...
>    $ region   : chr  "Aruba" "Aruba" "Aruba" "Aruba" ...
>    $ subregion: chr  NA NA NA NA ...
>but by merging my df with world map data I get a data frame with zero
>observation in it,I use this command for merging:
>
>
>    world_map=merge(world_map,df,by.x="region",by.y="COUNTRY")
>    str(world_map) 
>
>    'data.frame':   0 obs. of  133 variables:
>    $ region            : chr 
>    $ long              : num 
>    $ lat               : num 
>    $ group             : num 
>    $ order             : int 
>    $ subregion         : chr
>does anyone know what is the problem of this merging that I am
>currently using?
>thanks for any help!
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Jun 17 22:22:58 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Jun 2016 13:22:58 -0700
Subject: [R] merging df with world map
In-Reply-To: <871107819.8642588.1466193989968.JavaMail.yahoo@mail.yahoo.com>
References: <871107819.8642588.1466193989968.JavaMail.yahoo.ref@mail.yahoo.com>
	<871107819.8642588.1466193989968.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <3CB033C3-3427-44EC-9CD5-F9C07A16F73C@comcast.net>


> On Jun 17, 2016, at 1:06 PM, ch.elahe via R-help <r-help at r-project.org> wrote:
> 
> Hi all,
> I want to use world map in ggplot2 and show my data on world map. my df is:
> 
> 
>    $ COUNTRY           : chr  "DE" "DE" "FR" "FR" ..
> 
>    $ ContrastColor     : int  9 9 9 9 13 9 9 9 9 ..
> 
>    $ quant             : Factor w/ 4 levels "FAST","SLOW",..I need to merge my df with world_map data which is like this:
> 
> 
>    world_map=map_data("world")
>    data.frame':   99338 obs. of  6 variables:
>    $ long     : num  -69.9 -69.9 -69.9 -70 -70.1 ...
>    $ lat      : num  12.5 12.4 12.4 12.5 12.5 ...
>    $ group    : num  1 1 1 1 1 1 1 1 1 1 ...
>    $ order    : int  1 2 3 4 5 6 7 8 9 10 ...
>    $ region   : chr  "Aruba" "Aruba" "Aruba" "Aruba" ...
>    $ subregion: chr  NA NA NA NA ...
> but by merging my df with world map data I get a data frame with zero observation in it,I use this command for merging:
> 
> 
>    world_map=merge(world_map,df,by.x="region",by.y="COUNTRY")
>    str(world_map) 
> 
>    'data.frame':   0 obs. of  133 variables:
>    $ region            : chr 
>    $ long              : num 
>    $ lat               : num 
>    $ group             : num 
>    $ order             : int 
>    $ subregion         : chr
> does anyone know what is the problem of this merging that I am currently using?
> thanks for any help!

I would not expect a merger based on the one hand on two letter initials to match on the other hand fully spelled-out country names.


-- 

David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Fri Jun 17 23:08:27 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 17 Jun 2016 21:08:27 +0000
Subject: [R] merging df with world map
In-Reply-To: <871107819.8642588.1466193989968.JavaMail.yahoo@mail.yahoo.com>
References: <871107819.8642588.1466193989968.JavaMail.yahoo.ref@mail.yahoo.com>
	<871107819.8642588.1466193989968.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D389B2DE.17BEE0%macqueen1@llnl.gov>

And you can check what David and Jeff suggested like this:

intersect( df$COUNTRY, world_map$region )

If they have any values in common, that command will show them. (Note that
I said values in common, not countries in common.)

WARNING:
It appears that you have each country appearing more than once in both of
the data frames. Even if the country names were spelled the same (which
they are not in the first few rows), I would not care to predict the
outcome of a many-to-many merge. It probably won't make sense for showing
the data on a map.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/17/16, 1:06 PM, "R-help on behalf of ch.elahe via R-help"
<r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

>Hi all,
>I want to use world map in ggplot2 and show my data on world map. my df
>is:
>
>
>    $ COUNTRY           : chr  "DE" "DE" "FR" "FR" ..
>
>    $ ContrastColor     : int  9 9 9 9 13 9 9 9 9 ..
>
>    $ quant             : Factor w/ 4 levels "FAST","SLOW",..I need to
>merge my df with world_map data which is like this:
>
>    
>    world_map=map_data("world")
>    data.frame':   99338 obs. of  6 variables:
>    $ long     : num  -69.9 -69.9 -69.9 -70 -70.1 ...
>    $ lat      : num  12.5 12.4 12.4 12.5 12.5 ...
>    $ group    : num  1 1 1 1 1 1 1 1 1 1 ...
>    $ order    : int  1 2 3 4 5 6 7 8 9 10 ...
>    $ region   : chr  "Aruba" "Aruba" "Aruba" "Aruba" ...
>    $ subregion: chr  NA NA NA NA ...
>but by merging my df with world map data I get a data frame with zero
>observation in it,I use this command for merging:
>
>
>    world_map=merge(world_map,df,by.x="region",by.y="COUNTRY")
>    str(world_map)
>
>    'data.frame':   0 obs. of  133 variables:
>    $ region            : chr
>    $ long              : num
>    $ lat               : num
>    $ group             : num
>    $ order             : int
>    $ subregion         : chr
>does anyone know what is the problem of this merging that I am currently
>using?
>thanks for any help!
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dpriyank23 at gmail.com  Fri Jun 17 22:07:21 2016
From: dpriyank23 at gmail.com (Priyank Dwivedi)
Date: Fri, 17 Jun 2016 15:07:21 -0500
Subject: [R] Fwd: Matrix Constraints in R Optim
In-Reply-To: <CADya=_wMawuy4A8+58=vgAXn7F4eSZ1z2m00pCkfe-HVGt34ow@mail.gmail.com>
References: <CADya=_wMawuy4A8+58=vgAXn7F4eSZ1z2m00pCkfe-HVGt34ow@mail.gmail.com>
Message-ID: <CADya=_ymi22=6Xj5BtVKf7jisUrjK_pogM6qx04NvL287cK3fA@mail.gmail.com>

By mistake, I sent it earlier to the wrong address.

---------- Forwarded message ----------
From: Priyank Dwivedi <dpriyank23 at gmail.com>
Date: 17 June 2016 at 14:50
Subject: Matrix Constraints in R Optim
To: r-help-owner at r-project.org


Hi,

Below is the code snippet I wrote in R:

The basic idea is to minimize error by optimizing set of values (in this
scenario 12) in the form of a matrix. I defined the matrix elements as
vector "*my.data.var" * and then stacked it into a matrix called
"*my.data.var.mat"
in the error function. *

The only part that I can't figure out is "what if the column sum in
the *my.data.var.mat
needs to be <=1"; that's the constraint/s.. Where do I introduce it in the
OPTIM solver or elsewhere?*






*my.data.matrix.inj* <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
my.data.matrix.inj


*my.data.matrix.time* <- as.matrix(my.data.2)  #convert DATA FRAME to MATRIX
my.data.matrix.time


*my.data.matrix.prod* <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
my.data.matrix.prod


*my.data.var* <-
c(2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01)
my.data.var

*my.data.qo* <- c(5990,150,199,996)   #Pre-Waterflood Production

*my.data.timet0* <- 0 # starting condition for time


*#FUNCTIONQjk.Cal.func* <-
function(my.data.timet0,my.data.qo,my.data.matrix.time,
                         my.data.matrix.inj,
my.data.matrix.prod,my.data.var,my.data.var.mat)
{

  qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
ncol=ncol(my.data.matrix.prod))

  count <- 1
  number <- 1
  for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
wells columns
  {
    sum <-0
    for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
    {
      sum <-0
      deltaT <-0
      expo <-0


        for(column in 1:ncol(my.data.matrix.inj)) #loop through all the
injector columns to get the PRODUCT SUM
         {
            sum = sum +
my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
         }

      if(count<2)
      {
        deltaT<- my.data.matrix.time[row]
      }
      else
      {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}


      expo <- exp(-deltaT/my.data.var.mat[colnum,1])                  #
change here too

      if(count<2)
      {
        qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo + (1-expo)*sum
      }
      else
      {
        qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
(1-expo)*sum
      }
      count <- count+1
    }

    count <-1
  }

  qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION

}


*# ERROR FUNCTION* - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
MATRIX. Miminize the Error by changing my.data.var

*Error.func* <- function(my.data.var)
{
  #First convert vector(my.data.var) to MATRIX aand send it to calculate
new MATRIX
  *my.data.var.mat* <- matrix(my.data.var,nrow =
ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow = TRUE)

*  Calc.Qjk.Value* <-
Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
                                 my.data.matrix.inj,
my.data.matrix.prod,my.data.var,my.data.var.mat)


  diff.values <- my.data.matrix.prod-Calc.Qjk.Value    #FIND DIFFERENCE
BETWEEN CAL. MATRIX AND ORIGINAL MATRIX


  Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
  print(paste(Error))

  Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   # total
avg error


 * Error_total*
}

# OPTIMIZE

*optim*(*my.data.var*
,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1))



-- 
Best Regards,
PD



-- 
Best Regards,
Priyank Dwivedi

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Fri Jun 17 21:47:07 2016
From: chocold12 at gmail.com (lily li)
Date: Fri, 17 Jun 2016 13:47:07 -0600
Subject: [R] Problems with Mann-Kendall trend test
Message-ID: <CAN5afy8CH8pJaNgCXthtSrepvAe79VYLjcR_LF0hSDMurqY16Q@mail.gmail.com>

Dear R users,

Can anyone help me with mann-kendall trend test? I tried to use the newest
packages 'trend', and the function mk.test, but had problems in applying
the input data.

For example, res <- mk.test(Nile), Nile is a time-series data. But when I
use my dataset, with one column which is a time-series data, it says
"error: input must be ts object". How to do this? Thanks for your help.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Jun 17 23:55:18 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 17 Jun 2016 14:55:18 -0700
Subject: [R] Fwd: Matrix Constraints in R Optim
In-Reply-To: <CADya=_ymi22=6Xj5BtVKf7jisUrjK_pogM6qx04NvL287cK3fA@mail.gmail.com>
References: <CADya=_wMawuy4A8+58=vgAXn7F4eSZ1z2m00pCkfe-HVGt34ow@mail.gmail.com>
	<CADya=_ymi22=6Xj5BtVKf7jisUrjK_pogM6qx04NvL287cK3fA@mail.gmail.com>
Message-ID: <A8E545C2-7085-4AEF-817C-CD0102FB30F6@dcn.davis.ca.us>

Your code is corrupt because you failed to send your email in plain text format. 

You also don't appear to have all data needed to reproduce the problem. Use the dput function to generate R code form of a sample of your data. 
-- 
Sent from my phone. Please excuse my brevity.

On June 17, 2016 1:07:21 PM PDT, Priyank Dwivedi <dpriyank23 at gmail.com> wrote:
>By mistake, I sent it earlier to the wrong address.
>
>---------- Forwarded message ----------
>From: Priyank Dwivedi <dpriyank23 at gmail.com>
>Date: 17 June 2016 at 14:50
>Subject: Matrix Constraints in R Optim
>To: r-help-owner at r-project.org
>
>
>Hi,
>
>Below is the code snippet I wrote in R:
>
>The basic idea is to minimize error by optimizing set of values (in
>this
>scenario 12) in the form of a matrix. I defined the matrix elements as
>vector "*my.data.var" * and then stacked it into a matrix called
>"*my.data.var.mat"
>in the error function. *
>
>The only part that I can't figure out is "what if the column sum in
>the *my.data.var.mat
>needs to be <=1"; that's the constraint/s.. Where do I introduce it in
>the
>OPTIM solver or elsewhere?*
>
>
>
>
>
>
>*my.data.matrix.inj* <- as.matrix(my.data)  #convert DATA FRAME to
>MATRIX
>my.data.matrix.inj
>
>
>*my.data.matrix.time* <- as.matrix(my.data.2)  #convert DATA FRAME to
>MATRIX
>my.data.matrix.time
>
>
>*my.data.matrix.prod* <- as.matrix(my.data)  #convert DATA FRAME to
>MATRIX
>my.data.matrix.prod
>
>
>*my.data.var* <-
>c(2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01)
>my.data.var
>
>*my.data.qo* <- c(5990,150,199,996)   #Pre-Waterflood Production
>
>*my.data.timet0* <- 0 # starting condition for time
>
>
>*#FUNCTIONQjk.Cal.func* <-
>function(my.data.timet0,my.data.qo,my.data.matrix.time,
>                         my.data.matrix.inj,
>my.data.matrix.prod,my.data.var,my.data.var.mat)
>{
>
>  qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>ncol=ncol(my.data.matrix.prod))
>
>  count <- 1
>  number <- 1
>  for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
>wells columns
>  {
>    sum <-0
>    for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
>    {
>      sum <-0
>      deltaT <-0
>      expo <-0
>
>
>        for(column in 1:ncol(my.data.matrix.inj)) #loop through all the
>injector columns to get the PRODUCT SUM
>         {
>            sum = sum +
>my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>         }
>
>      if(count<2)
>      {
>        deltaT<- my.data.matrix.time[row]
>      }
>      else
>      {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>
>
>      expo <- exp(-deltaT/my.data.var.mat[colnum,1])                  #
>change here too
>
>      if(count<2)
>      {
>    qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo + (1-expo)*sum
>      }
>      else
>      {
>        qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
>(1-expo)*sum
>      }
>      count <- count+1
>    }
>
>    count <-1
>  }
>
>  qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>
>}
>
>
>*# ERROR FUNCTION* - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
>MATRIX. Miminize the Error by changing my.data.var
>
>*Error.func* <- function(my.data.var)
>{
> #First convert vector(my.data.var) to MATRIX aand send it to calculate
>new MATRIX
>  *my.data.var.mat* <- matrix(my.data.var,nrow =
>ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow =
>TRUE)
>
>*  Calc.Qjk.Value* <-
>Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>                                 my.data.matrix.inj,
>my.data.matrix.prod,my.data.var,my.data.var.mat)
>
>
>  diff.values <- my.data.matrix.prod-Calc.Qjk.Value    #FIND DIFFERENCE
>BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>
>
>  Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>  print(paste(Error))
>
>Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
>total
>avg error
>
>
> * Error_total*
>}
>
># OPTIMIZE
>
>*optim*(*my.data.var*
>,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1))
>
>
>
>-- 
>Best Regards,
>PD
>
>
>
>-- 
>Best Regards,
>Priyank Dwivedi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Jun 17 23:58:40 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 17 Jun 2016 14:58:40 -0700
Subject: [R] Problems with Mann-Kendall trend test
In-Reply-To: <CAN5afy8CH8pJaNgCXthtSrepvAe79VYLjcR_LF0hSDMurqY16Q@mail.gmail.com>
References: <CAN5afy8CH8pJaNgCXthtSrepvAe79VYLjcR_LF0hSDMurqY16Q@mail.gmail.com>
Message-ID: <82B7F284-8342-4CB5-8896-133A9E31365F@dcn.davis.ca.us>

Not reproducible. Use dput to generate R code form of your data along with the code that gave you the error, and set the email to plain text only when you send it so it doesn't get corrupted when the html is stripped on the mailing list. 
-- 
Sent from my phone. Please excuse my brevity.

On June 17, 2016 12:47:07 PM PDT, lily li <chocold12 at gmail.com> wrote:
>Dear R users,
>
>Can anyone help me with mann-kendall trend test? I tried to use the
>newest
>packages 'trend', and the function mk.test, but had problems in
>applying
>the input data.
>
>For example, res <- mk.test(Nile), Nile is a time-series data. But when
>I
>use my dataset, with one column which is a time-series data, it says
>"error: input must be ts object". How to do this? Thanks for your help.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mortezafirouzi at yahoo.com  Sat Jun 18 00:16:17 2016
From: mortezafirouzi at yahoo.com (Morteza Firouzi)
Date: Fri, 17 Jun 2016 22:16:17 +0000 (UTC)
Subject: [R] Problems with Mann-Kendall trend test
In-Reply-To: <CAN5afy8CH8pJaNgCXthtSrepvAe79VYLjcR_LF0hSDMurqY16Q@mail.gmail.com>
References: <CAN5afy8CH8pJaNgCXthtSrepvAe79VYLjcR_LF0hSDMurqY16Q@mail.gmail.com>
Message-ID: <43106300.5227235.1466201777661.JavaMail.yahoo@mail.yahoo.com>

Dear,
You have to store your data as a Time-Series (ts), first.?To define a column of data as ts, you may use this:
library(timeSeries)Nile <- read.csv(file.choose(), header=F)#If your data is monthly, you may define the frequency as 12, for annual ts set freq. as 1.
#If your data starts from for e.g., 1990, then:NileTS <- ts(Nile, frequency=1, start=c(1990,1))#To plot the time seriesplot.ts(NileTS)
Morteza
?
 

    On Saturday, June 18, 2016 3:47 AM, lily li <chocold12 at gmail.com> wrote:
 

 Dear R users,

Can anyone help me with mann-kendall trend test? I tried to use the newest
packages 'trend', and the function mk.test, but had problems in applying
the input data.

For example, res <- mk.test(Nile), Nile is a time-series data. But when I
use my dataset, with one column which is a time-series data, it says
"error: input must be ts object". How to do this? Thanks for your help.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Jun 18 00:57:36 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 17 Jun 2016 15:57:36 -0700
Subject: [R] Fwd: Matrix Constraints in R Optim
In-Reply-To: <CAPq=xQAhSXVjuk_uSwnz8-4AE388YSmBeuBmfG7hiwO_i=xRVg@mail.gmail.com>
References: <CADya=_wMawuy4A8+58=vgAXn7F4eSZ1z2m00pCkfe-HVGt34ow@mail.gmail.com>
	<CADya=_ymi22=6Xj5BtVKf7jisUrjK_pogM6qx04NvL287cK3fA@mail.gmail.com>
	<A8E545C2-7085-4AEF-817C-CD0102FB30F6@dcn.davis.ca.us>
	<CAPq=xQAhSXVjuk_uSwnz8-4AE388YSmBeuBmfG7hiwO_i=xRVg@mail.gmail.com>
Message-ID: <9C392FEC-2FE8-477F-AFB3-15089E3286B9@dcn.davis.ca.us>

Always reply-to-all to keep the mailing list informed... I don't do private consulting online. 

You look like you have plain text worked out, but we still cannot run your code. 

Read the Posting Guide and [1]. You cannot attach Excel files here (and many R users can't or won't do that anyway) so you need to figure out dput. You will know you have a reproducible example when you don't read from any files and the code produces the error you are asking about when run in a newly opened R session.  I think you should (!) only need the dput of my.data.var, definition of Error.func, and the call to optim if you do it right. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
-- 
Sent from my phone. Please excuse my brevity.

On June 17, 2016 3:10:41 PM PDT, Narendra Modi <bjpmodi2016 at gmail.com> wrote:
>how to do that Jeff? I am newbie to R.
>
>I am posting the whole message again here and I made sure it is in
>plain-text format.
>
>
>
>
>
>
>my.data.matrix.inj <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
>my.data.matrix.inj
>
>
>my.data.2 <- readWorksheetFromFile(file,sheet=2,startRow=1)
>str(my.data.2)  # DATA FRAME
>my.data.matrix.time <- as.matrix(my.data.2)  #convert DATA FRAME to
>MATRIX
>my.data.matrix.time
>
>my.data <- readWorksheetFromFile(file,sheet=3,startRow=1)
>str(my.data)  # DATA FRAME
>my.data.matrix.prod <- as.matrix(my.data)  #convert DATA FRAME to
>MATRIX
>my.data.matrix.prod
>
>
> # my.data.var <- vector("numeric",length = 24)
> # my.data.var
>
>my.data.var <- c(10,0.25,0.25,0.25,0.25,0.25,
>                 10,0.25,0.25,0.25,0.25,0.25,
>                 10,0.25,0.25,0.25,0.25,0.25,
>                 10,0.25,0.25,0.25,0.25,0.25)
>my.data.var
>
>my.data.qo <- c(5990,150,199,996)   #Pre-Waterflood Production
>my.data.timet0 <- 0 # starting condition for time
>
>#FUNCTION
>Qjk.Cal.func <- function(my.data.timet0,my.data.qo,my.data.matrix.time,
>                         my.data.matrix.inj,
>my.data.matrix.prod,my.data.var,my.data.var.mat)
>{
>
>  qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>ncol=ncol(my.data.matrix.prod))
>
>  count <- 1
>  number <- 1
>  for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
>wells columns
>  {
>    sum <-0
>    for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
>    {
>      sum <-0
>      deltaT <-0
>      expo <-0
>
>
>        for(column in 1:ncol(my.data.matrix.inj)) #loop through all
>the injector columns to get the PRODUCT SUM
>         {
>            sum = sum +
>my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>         }
>
>      if(count<2)
>      {
>        deltaT<- my.data.matrix.time[row]
>      }
>      else
>      {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>
>
>      expo <- exp(-deltaT/my.data.var.mat[colnum,1])
># change here too
>
>      if(count<2)
>      {
>    qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo + (1-expo)*sum
>      }
>      else
>      {
>        qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
>(1-expo)*sum
>      }
>      count <- count+1
>    }
>
>    count <-1
>  }
>
>  qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>
>}
>
>
># ERROR FUNCTION - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
>MATRIX. Miminize the Error by changing my.data.var
>
>Error.func <- function(my.data.var)
>{
>  #First convert vector(my.data.var) to MATRIX aand send it to
>calculate new MATRIX
>  my.data.var.mat <- matrix(my.data.var,nrow =
>ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow =
>TRUE)
>
>Calc.Qjk.Value <-
>Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>                                 my.data.matrix.inj,
>my.data.matrix.prod,my.data.var,my.data.var.mat)
>
>
>  diff.values <- my.data.matrix.prod-Calc.Qjk.Value    #FIND
>DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>
>
>  Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>  print(paste(Error))
>
>  Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
>total avg error
>
>
>  Error_total
>}
>
># OPTIMIZE
>
>sols<-optim(my.data.var,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1),
>lower=c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),control=list(maxit
>=1000))
>sols
>
>
>
>
>
>
>On Fri, Jun 17, 2016 at 4:55 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Your code is corrupt because you failed to send your email in plain
>text format.
>>
>> You also don't appear to have all data needed to reproduce the
>problem. Use the dput function to generate R code form of a sample of
>your data.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On June 17, 2016 1:07:21 PM PDT, Priyank Dwivedi
><dpriyank23 at gmail.com> wrote:
>> >By mistake, I sent it earlier to the wrong address.
>> >
>> >---------- Forwarded message ----------
>> >From: Priyank Dwivedi <dpriyank23 at gmail.com>
>> >Date: 17 June 2016 at 14:50
>> >Subject: Matrix Constraints in R Optim
>> >To: r-help-owner at r-project.org
>> >
>> >
>> >Hi,
>> >
>> >Below is the code snippet I wrote in R:
>> >
>> >The basic idea is to minimize error by optimizing set of values (in
>> >this
>> >scenario 12) in the form of a matrix. I defined the matrix elements
>as
>> >vector "*my.data.var" * and then stacked it into a matrix called
>> >"*my.data.var.mat"
>> >in the error function. *
>> >
>> >The only part that I can't figure out is "what if the column sum in
>> >the *my.data.var.mat
>> >needs to be <=1"; that's the constraint/s.. Where do I introduce it
>in
>> >the
>> >OPTIM solver or elsewhere?*
>> >
>> >
>> >
>> >
>> >
>> >
>> >*my.data.matrix.inj* <- as.matrix(my.data)  #convert DATA FRAME to
>> >MATRIX
>> >my.data.matrix.inj
>> >
>> >
>> >*my.data.matrix.time* <- as.matrix(my.data.2)  #convert DATA FRAME
>to
>> >MATRIX
>> >my.data.matrix.time
>> >
>> >
>> >*my.data.matrix.prod* <- as.matrix(my.data)  #convert DATA FRAME to
>> >MATRIX
>> >my.data.matrix.prod
>> >
>> >
>> >*my.data.var* <-
>>
>>c(2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01)
>> >my.data.var
>> >
>> >*my.data.qo* <- c(5990,150,199,996)   #Pre-Waterflood Production
>> >
>> >*my.data.timet0* <- 0 # starting condition for time
>> >
>> >
>> >*#FUNCTIONQjk.Cal.func* <-
>> >function(my.data.timet0,my.data.qo,my.data.matrix.time,
>> >                         my.data.matrix.inj,
>> >my.data.matrix.prod,my.data.var,my.data.var.mat)
>> >{
>> >
>> >  qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>> >ncol=ncol(my.data.matrix.prod))
>> >
>> >  count <- 1
>> >  number <- 1
>> >  for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all
>PROD
>> >wells columns
>> >  {
>> >    sum <-0
>> >    for(row in 1:nrow(my.data.matrix.prod)) #loop through all the
>rows
>> >    {
>> >      sum <-0
>> >      deltaT <-0
>> >      expo <-0
>> >
>> >
>> >        for(column in 1:ncol(my.data.matrix.inj)) #loop through all
>the
>> >injector columns to get the PRODUCT SUM
>> >         {
>> >            sum = sum +
>> >my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>> >         }
>> >
>> >      if(count<2)
>> >      {
>> >        deltaT<- my.data.matrix.time[row]
>> >      }
>> >      else
>> >      {deltaT <-
>my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>> >
>> >
>> >      expo <- exp(-deltaT/my.data.var.mat[colnum,1])                
> #
>> >change here too
>> >
>> >      if(count<2)
>> >      {
>> >    qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo +
>(1-expo)*sum
>> >      }
>> >      else
>> >      {
>> >        qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo
>+
>> >(1-expo)*sum
>> >      }
>> >      count <- count+1
>> >    }
>> >
>> >    count <-1
>> >  }
>> >
>> >  qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR
>FUNCTION
>> >
>> >}
>> >
>> >
>> >*# ERROR FUNCTION* - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND
>ORIGINAL
>> >MATRIX. Miminize the Error by changing my.data.var
>> >
>> >*Error.func* <- function(my.data.var)
>> >{
>> > #First convert vector(my.data.var) to MATRIX aand send it to
>calculate
>> >new MATRIX
>> >  *my.data.var.mat* <- matrix(my.data.var,nrow =
>> >ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow =
>> >TRUE)
>> >
>> >*  Calc.Qjk.Value* <-
>> >Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>> >                                 my.data.matrix.inj,
>> >my.data.matrix.prod,my.data.var,my.data.var.mat)
>> >
>> >
>> >  diff.values <- my.data.matrix.prod-Calc.Qjk.Value    #FIND
>DIFFERENCE
>> >BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>> >
>> >
>> >  Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>> >1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>> >  print(paste(Error))
>> >
>> >Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
>> >total
>> >avg error
>> >
>> >
>> > * Error_total*
>> >}
>> >
>> ># OPTIMIZE
>> >
>> >*optim*(*my.data.var*
>>
>>,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1))
>> >
>> >
>> >
>> >--
>> >Best Regards,
>> >PD
>> >
>> >
>> >
>> >--
>> >Best Regards,
>> >Priyank Dwivedi
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Jun 18 01:39:20 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Jun 2016 16:39:20 -0700
Subject: [R] row.names c(NA, -length) vs. c(NA, +length)
Message-ID: <CAF8bMcaBf9a7=+fgmkhvQZZK4T32WP5btwhxvAbWnpZM_GuE3Q@mail.gmail.com>

The default row.names on a data.frame made by the core-R data.frame
function are of the the form c(NA, -NROW(dataFrame)).  The dplyr package
has a 'data_frame' function that uses c(NA, +NROW(dataFrame)) instead.  The
tibble package also has a data_frame function, but it uses the negative
length.

As far as I can see, the positive and negative forms mean the same thing.
Is there any reason for the difference?  It makes testing a bit difficult
since all.equal() says they are the the same but identical() says they
differ.

> base::.row_names_info(dplyr::data_frame(X=101:110), 0)
[1] NA 10
> base::.row_names_info(tibble::data_frame(X=101:110), 0)
[1]  NA -10
> base::.row_names_info(base::data.frame(X=101:110), 0)
[1]  NA -10
>
> packageDescription("dplyr")$Author
[1] "Hadley Wickham [aut, cre],\n  Romain Francois [aut],\n  RStudio [cph]"
> packageDescription("tibble")$Author
[1] "Hadley Wickham [aut],\n  Romain Francois [aut],\n  Kirill M?ller [aut,
cre],\n  RStudio [cph]"
> packageDescription("base")$Author
[1] "R Core Team and contributors worldwide"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

	[[alternative HTML version deleted]]


From hmunoz40 at hotmail.com  Sat Jun 18 01:53:01 2016
From: hmunoz40 at hotmail.com (Humberto Munoz Barona)
Date: Fri, 17 Jun 2016 16:53:01 -0700
Subject: [R] replacement has 0 rows, data has 2809
Message-ID: <BLU437-SMTP40BAE9BD447582620D740EC0570@phx.gbl>

I am running the following R-code 

countToTpm <- function(counts, effLen)
{
  rate <- log(counts) - log(effLen)
  denom <- log(sum(exp(rate)))
  exp(rate - denom + log(1e6))
}

countToFpkm <- function(counts, effLen)
{
  N <- sum(counts)
  exp( log(counts) + log(1e9) - log(effLen) - log(N) )
}

fpkmToTpm <- function(fpkm)
{
  exp(log(fpkm) - log(sum(fpkm)) + log(1e6))
}

countToEffCounts <- function(counts, len, effLen)
{
  counts * (len / effLen)
}
################################################################################
# An example
################################################################################
data1 <- read.delim("Dark Aerobic1.csv", check.names=FALSE, stringsAsFactors=FALSE)
cnts <- data1['ReadCount']
lens <- data1['Length']
countDf <- data.frame(count = cnts, length = lens)

 # assume a mean(FLD) = 170.71

countDf$effLength <- countDf$length - 170.71 + 1
countDf$tpm <- with(countDf, countToTpm(count, effLength))
countDf$fpkm <- with(countDf, countToFpkm(count, effLength))
with(countDf, all.equal(tpm, fpkmToTpm(fpkm)))
countDf$effCounts <- with(countDf, countToEffCounts(count, length, effLength))

 I am receiving the errors

> countDf$effLength <- countDf$length - 170.71 + 1
Error in `$<-.data.frame`(`*tmp*`, "effLength", value = numeric(0)) : 
  replacement has 0 rows, data has 2809
> countDf$tpm <- with(countDf, countToTpm(count, effLength))
Error in countToTpm(count, effLength) : object 'count' not found
> countDf$fpkm <- with(countDf, countToFpkm(count, effLength))
Error in countToFpkm(count, effLength) : object 'count' not found
> with(countDf, all.equal(tpm, fpkmToTpm(fpkm)))
Error in all.equal(tpm, fpkmToTpm(fpkm)) : object 'tpm' not found
> countDf$effCounts <- with(countDf, countToEffCounts(count, length, effLength))
Error in countToEffCounts(count, length, effLength) : 
  object 'count' not found
> 

Thanks for any help to fix this error

Humberto Munoz

From farnoosh_81 at yahoo.com  Sat Jun 18 02:33:11 2016
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Sat, 18 Jun 2016 00:33:11 +0000 (UTC)
Subject: [R] Merging Issue
References: <773448765.5225771.1466209991563.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <773448765.5225771.1466209991563.JavaMail.yahoo@mail.yahoo.com>

Hi all,?
I have two data sets similar like below and wanted to merge them with variable "deps".?As this is a sample data with small sample size, I don't have any problem using command merge.?However, the actual data set has ~60,000 observations with a lot of repeated measures. For example, for a given ID I have 100 different dates and groups. Thee problem is using "merge" command gives me a lot of duplicates that I can't even track.?I was wondering if there is any other way to merge such a data.Any help is appreciated. Thanks.
## Data ASubject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5", "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by = 1)?deps<-c("A", "B", "C", "C", "D", "A", "F", "G", "A", "F", "A", "D")df <- data.frame(Subject, dates, deps)
## Data Bloc<-c("CA","NY", "CA", "NY", "WA", "WA")grp<-c("DE", "OC", "DE", "OT", "DE", "OC")deps<-c("A","B","C", "D", "F","G")df2<-data.frame(loc, grp, deps )
dat<-merge(df, df2, by="deps")
?


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Jun 18 09:19:31 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 18 Jun 2016 17:19:31 +1000
Subject: [R] replacement has 0 rows, data has 2809
In-Reply-To: <BLU437-SMTP40BAE9BD447582620D740EC0570@phx.gbl>
References: <BLU437-SMTP40BAE9BD447582620D740EC0570@phx.gbl>
Message-ID: <CA+8X3fW3YYnnr+aqAZZRcxrxUgMzh-Dq5wGg7tMFdMFbF4fLAQ@mail.gmail.com>

Hi Humberto,
The "0 row" error usually arises from a calculation in which a
non-existent object is used. I see that you have created a vector with
the name "lens" and that may be where this is happening. Have a look
at:

length(lens)

or if it is not too long, just:

lens

If it is zero length, that is your problem. This might be due to
"data1" not having a column named "Length" or it may not contain
numeric values (i.e. a factor)..

Jim


On Sat, Jun 18, 2016 at 9:53 AM, Humberto Munoz Barona
<hmunoz40 at hotmail.com> wrote:
> I am running the following R-code
>
> countToTpm <- function(counts, effLen)
> {
>   rate <- log(counts) - log(effLen)
>   denom <- log(sum(exp(rate)))
>   exp(rate - denom + log(1e6))
> }
>
> countToFpkm <- function(counts, effLen)
> {
>   N <- sum(counts)
>   exp( log(counts) + log(1e9) - log(effLen) - log(N) )
> }
>
> fpkmToTpm <- function(fpkm)
> {
>   exp(log(fpkm) - log(sum(fpkm)) + log(1e6))
> }
>
> countToEffCounts <- function(counts, len, effLen)
> {
>   counts * (len / effLen)
> }
> ################################################################################
> # An example
> ################################################################################
> data1 <- read.delim("Dark Aerobic1.csv", check.names=FALSE, stringsAsFactors=FALSE)
> cnts <- data1['ReadCount']
> lens <- data1['Length']
> countDf <- data.frame(count = cnts, length = lens)
>
>  # assume a mean(FLD) = 170.71
>
> countDf$effLength <- countDf$length - 170.71 + 1
> countDf$tpm <- with(countDf, countToTpm(count, effLength))
> countDf$fpkm <- with(countDf, countToFpkm(count, effLength))
> with(countDf, all.equal(tpm, fpkmToTpm(fpkm)))
> countDf$effCounts <- with(countDf, countToEffCounts(count, length, effLength))
>
>  I am receiving the errors
>
>> countDf$effLength <- countDf$length - 170.71 + 1
> Error in `$<-.data.frame`(`*tmp*`, "effLength", value = numeric(0)) :
>   replacement has 0 rows, data has 2809
>> countDf$tpm <- with(countDf, countToTpm(count, effLength))
> Error in countToTpm(count, effLength) : object 'count' not found
>> countDf$fpkm <- with(countDf, countToFpkm(count, effLength))
> Error in countToFpkm(count, effLength) : object 'count' not found
>> with(countDf, all.equal(tpm, fpkmToTpm(fpkm)))
> Error in all.equal(tpm, fpkmToTpm(fpkm)) : object 'tpm' not found
>> countDf$effCounts <- with(countDf, countToEffCounts(count, length, effLength))
> Error in countToEffCounts(count, length, effLength) :
>   object 'count' not found
>>
>
> Thanks for any help to fix this error
>
> Humberto Munoz
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From naresh_gurbuxani at hotmail.com  Sun Jun 19 00:12:16 2016
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Sat, 18 Jun 2016 22:12:16 +0000
Subject: [R] better loop for simulation
Message-ID: <CY1PR07MB25888BEDCE91D0116E2987E9FA280@CY1PR07MB2588.namprd07.prod.outlook.com>

I want to calculate a function many times over.  My solution below works, but does not seem very elegant.  

# my function to run many times over
stud.score <- function(n.questions, mult.choice = 2) {
	prob.success <- 1 / mult.choice
	answers <- (runif(n.questions) < prob.success)
	return(sum(answers))
} 

# my method to run above function 1000 times and store results
count.df <- data.frame(n.count = rep(10, 1000))
scores.df <- apply(count.df, 1, function(x) return(stud.score(x)))	

Creating a data frame just to repeat the the count seems wasteful.  How can I generate scores.df without count.df?

Thanks,
Naresh

From jholtman at gmail.com  Sun Jun 19 00:33:01 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 18 Jun 2016 18:33:01 -0400
Subject: [R] better loop for simulation
In-Reply-To: <CY1PR07MB25888BEDCE91D0116E2987E9FA280@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB25888BEDCE91D0116E2987E9FA280@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <CAAxdm-4D0N4d640hV2TdX0evPjt5hzP+aEC46XMEHRzaeuTqkw@mail.gmail.com>

use replicate:

> stud.score <- function(n.questions, mult.choice = 2) {
+          prob.success <- 1 / mult.choice
+          answers <- (runif(n.questions) < prob.success)
+          return(sum(answers))
+  }
>
> # create 1000 results
> result <- replicate(1000, stud.score(10))
>
> # look at histogram
> stem(result)
  The decimal point is at the |
   0 | 0
   1 | 0000000000000
   2 | 000000000000000000000000000000000000000000000000000000000
   3 |
00000000000000000000000000000000000000000000000000000000000000000000+26
   4 |
00000000000000000000000000000000000000000000000000000000000000000000+116
   5 |
00000000000000000000000000000000000000000000000000000000000000000000+153
   6 |
00000000000000000000000000000000000000000000000000000000000000000000+142
   7 |
00000000000000000000000000000000000000000000000000000000000000000000+35
   8 | 00000000000000000000000000000000000000000000
   9 | 000000000000
  10 | 0


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Jun 18, 2016 at 6:12 PM, Naresh Gurbuxani <
naresh_gurbuxani at hotmail.com> wrote:

> I want to calculate a function many times over.  My solution below works,
> but does not seem very elegant.
>
> # my function to run many times over
> stud.score <- function(n.questions, mult.choice = 2) {
>         prob.success <- 1 / mult.choice
>         answers <- (runif(n.questions) < prob.success)
>         return(sum(answers))
> }
>
> # my method to run above function 1000 times and store results
> count.df <- data.frame(n.count = rep(10, 1000))
> scores.df <- apply(count.df, 1, function(x) return(stud.score(x)))
>
> Creating a data frame just to repeat the the count seems wasteful.  How
> can I generate scores.df without count.df?
>
> Thanks,
> Naresh
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun Jun 19 00:41:34 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 18 Jun 2016 18:41:34 -0400
Subject: [R] Merging Issue
In-Reply-To: <773448765.5225771.1466209991563.JavaMail.yahoo@mail.yahoo.com>
References: <773448765.5225771.1466209991563.JavaMail.yahoo.ref@mail.yahoo.com>
	<773448765.5225771.1466209991563.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-44_HO921pm0XcjwJHOO3VwcVooR40gGD8K2sUkTU_8Fg@mail.gmail.com>

Don't use HTML on sending email- messes up the data.

What do you mean that you get lots of duplicates?  If you have duplicated
entries in df2 this will lead to dups because of the way merge works (here
is the help file):

 If there is more than one match, all possible matches contribute
     one row each.  For the precise meaning of ?match?, see ?match?.

So you need to define the problem that you want to solve in going the
merge.  Here is what happens in your data if I duplicate some entries in
df2; is this what you are seeing:

>  #Data A
>  Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5", "5")
>  dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by = 1)
>  deps<-c("A", "B", "C", "C", "D", "A", "F", "G", "A", "F", "A", "D")
>  df <- data.frame(Subject, dates, deps)
>  ##
>  #Data B
>  loc<-c("CA","NY", "CA", "NY", "WA", "WA", 'yy')
>  grp<-c("DE", "OC", "DE", "OT", "DE", "OC", "xx")
>  deps<-c("A","B","C", "D", "F","G", "A")
>  df2<-data.frame(loc, grp, deps )
>  dat<-merge(df, df2, by="deps")
>
> dat
   deps Subject      dates loc grp
1     A       2 2011-01-01  CA  DE
2     A       2 2011-01-01  yy  xx
3     A       3 2011-01-06  CA  DE
4     A       3 2011-01-06  yy  xx
5     A       5 2011-01-11  CA  DE
6     A       5 2011-01-11  yy  xx
7     A       5 2011-01-09  CA  DE
8     A       5 2011-01-09  yy  xx
9     B       2 2011-01-02  NY  OC
10    C       3 2011-01-04  CA  DE
11    C       2 2011-01-03  CA  DE
12    D       5 2011-01-12  NY  OT
13    D       3 2011-01-05  NY  OT
14    F       5 2011-01-10  WA  DE
15    F       4 2011-01-07  WA  DE
16    G       4 2011-01-08  WA  OC



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Jun 17, 2016 at 8:33 PM, Farnoosh Sheikhi via R-help <
r-help at r-project.org> wrote:

> Hi all,
> I have two data sets similar like below and wanted to merge them with
> variable "deps". As this is a sample data with small sample size, I don't
> have any problem using command merge. However, the actual data set has
> ~60,000 observations with a lot of repeated measures. For example, for a
> given ID I have 100 different dates and groups. Thee problem is using
> "merge" command gives me a lot of duplicates that I can't even track. I was
> wondering if there is any other way to merge such a data.Any help is
> appreciated. Thanks.
> ## Data ASubject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5",
> "5", "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by =
> 1) deps<-c("A", "B", "C", "C", "D", "A", "F", "G", "A", "F", "A", "D")df <-
> data.frame(Subject, dates, deps)
> ## Data Bloc<-c("CA","NY", "CA", "NY", "WA", "WA")grp<-c("DE", "OC", "DE",
> "OT", "DE", "OC")deps<-c("A","B","C", "D", "F","G")df2<-data.frame(loc,
> grp, deps )
> dat<-merge(df, df2, by="deps")
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Jun 19 01:24:49 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 18 Jun 2016 19:24:49 -0400
Subject: [R] better loop for simulation
In-Reply-To: <CY1PR07MB25888BEDCE91D0116E2987E9FA280@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB25888BEDCE91D0116E2987E9FA280@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <8b727e71-d41f-01e1-55b3-67836578782a@gmail.com>

On 18/06/2016 6:12 PM, Naresh Gurbuxani wrote:
> I want to calculate a function many times over.  My solution below works, but does not seem very elegant.
>
> # my function to run many times over
> stud.score <- function(n.questions, mult.choice = 2) {
> 	prob.success <- 1 / mult.choice
> 	answers <- (runif(n.questions) < prob.success)
> 	return(sum(answers))
> }
>
> # my method to run above function 1000 times and store results
> count.df <- data.frame(n.count = rep(10, 1000))
> scores.df <- apply(count.df, 1, function(x) return(stud.score(x)))	
>
> Creating a data frame just to repeat the the count seems wasteful.  How can I generate scores.df without count.df?
>
> Thanks,

You don't need a data frame or a loop at all.  You're simulating 
binomial values, and R has rbinom() to do that in a vectorized way.

Duncan


From ddalthorp at usgs.gov  Sun Jun 19 01:31:44 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Sat, 18 Jun 2016 16:31:44 -0700
Subject: [R] better loop for simulation
In-Reply-To: <CY1PR07MB25888BEDCE91D0116E2987E9FA280@CY1PR07MB2588.namprd07.prod.outlook.com>
References: <CY1PR07MB25888BEDCE91D0116E2987E9FA280@CY1PR07MB2588.namprd07.prod.outlook.com>
Message-ID: <CAJeYpE9jeJQCr6+Qc7XLZ9Bvw14nx1odVPe9w0T=z0Grz+eLnQ@mail.gmail.com>

try:

n.questions <- 10  # or however many you want
mult.choice <- 2
scores <- rbinom(1000, size = n.questions, prob = 1/mult.choice)


On Sat, Jun 18, 2016 at 3:12 PM, Naresh Gurbuxani <
naresh_gurbuxani at hotmail.com> wrote:

> I want to calculate a function many times over.  My solution below works,
> but does not seem very elegant.
>
> # my function to run many times over
> stud.score <- function(n.questions, mult.choice = 2) {
>         prob.success <- 1 / mult.choice
>         answers <- (runif(n.questions) < prob.success)
>         return(sum(answers))
> }
>
> # my method to run above function 1000 times and store results
> count.df <- data.frame(n.count = rep(10, 1000))
> scores.df <- apply(count.df, 1, function(x) return(stud.score(x)))
>
> Creating a data frame just to repeat the the count seems wasteful.  How
> can I generate scores.df without count.df?
>
> Thanks,
> Naresh
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sun Jun 19 04:48:14 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 19 Jun 2016 08:18:14 +0530
Subject: [R] relevel for sigma constraint
Message-ID: <CAC8=1ep3vCsYwgud+OtqDM1C1x1r0khgbfmMrr6+TiZQTfz-eQ@mail.gmail.com>

Dear all,

For treatment contrasts I would :

library(car)
data(Prestige)
attach(Prestige)
levels(type)
contrasts(type) <-contr.treatment(levels(type),base =2 )
Alternatively to change my level I would do :-
type = relevel(type,ref="prof")

Now I want the sigma constraint.
For this the LAST level ( the one whose mean is not computed and is equal
to -alpha1 - alpha2 (where alpha's are the mean of group i ) is to be set.
How do I set that ?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From naresh_gurbuxani at hotmail.com  Sun Jun 19 05:15:43 2016
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Sun, 19 Jun 2016 03:15:43 +0000
Subject: [R] better loop for simulation
In-Reply-To: <CAJeYpE9jeJQCr6+Qc7XLZ9Bvw14nx1odVPe9w0T=z0Grz+eLnQ@mail.gmail.com>
References: <CY1PR07MB25888BEDCE91D0116E2987E9FA280@CY1PR07MB2588.namprd07.prod.outlook.com>,
	<CAJeYpE9jeJQCr6+Qc7XLZ9Bvw14nx1odVPe9w0T=z0Grz+eLnQ@mail.gmail.com>
Message-ID: <CY1PR07MB25883512AD896DCEEE3AF50AFA290@CY1PR07MB2588.namprd07.prod.outlook.com>

Daniel, Duncan, and Jim,


Many thanks for your prompt responses.  My example function is indeed binomial, for which a built function already exists.  But my goal is to find a general solution which would work for other functions as well.

replicate() works well for me.

Naresh
________________________________
From: Dalthorp, Daniel <ddalthorp at usgs.gov>
Sent: Saturday, June 18, 2016 7:31 PM
To: Naresh Gurbuxani
Cc: R-help at r-project.org
Subject: Re: [R] better loop for simulation

try:

n.questions <- 10  # or however many you want
mult.choice <- 2
scores <- rbinom(1000, size = n.questions, prob = 1/mult.choice)


On Sat, Jun 18, 2016 at 3:12 PM, Naresh Gurbuxani <naresh_gurbuxani at hotmail.com<mailto:naresh_gurbuxani at hotmail.com>> wrote:
I want to calculate a function many times over.  My solution below works, but does not seem very elegant.

# my function to run many times over
stud.score <- function(n.questions, mult.choice = 2) {
        prob.success <- 1 / mult.choice
        answers <- (runif(n.questions) < prob.success)
        return(sum(answers))
}

# my method to run above function 1000 times and store results
count.df <- data.frame(n.count = rep(10, 1000))
scores.df <- apply(count.df, 1, function(x) return(stud.score(x)))

Creating a data frame just to repeat the the count seems wasteful.  How can I generate scores.df without count.df?

Thanks,
Naresh
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov<mailto:ddalthorp at usgs.gov>


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun 20 00:45:20 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 20 Jun 2016 08:45:20 +1000
Subject: [R] benchmark-dea
In-Reply-To: <CAL3rq9heFjYNMUb+f+KTtJ95yjuWKvup7owaKQR-v7aYgEjMpQ@mail.gmail.com>
References: <CAL3rq9i3X1_dZmJDxqxevRZpe3UTRAcgK-7yjvQ9N4-jqALKVQ@mail.gmail.com>
	<CA+8X3fVHjZS+DkNKVaFt+AkYcM4Ekup0Yv-Pcy6c9WfaCsAMZw@mail.gmail.com>
	<CAL3rq9heFjYNMUb+f+KTtJ95yjuWKvup7owaKQR-v7aYgEjMpQ@mail.gmail.com>
Message-ID: <CA+8X3fVG4YHvsfdVDYH4iLbLJ5h=CyfeCBD0ndUdXcGm99EZ6Q@mail.gmail.com>

Hi farzana,
You can't, because it doesn't fit into the definition of a CSV file.
The "dea" function converts the nine element data frame "data1" into a
list, the elements of which are of different lengths. Therefore, it
can't be a data frame. Additionally, it can't be a matrix because its
elements are of different data types. A CSV file is a rectangular text
block in which the lines are interpreted as rows and the elements of
each row are separated by commas (or other specified separators). The
"Farrell" object is nothing like that. You can save it with the "save"
function and retrieve it with the "load" function, but you can't cram
it into a CSV file that can be retrieved later, and I think that is
what you are asking.

Jim


On Mon, Jun 20, 2016 at 4:43 AM, farzana akbari
<farzana.akbari2013 at gmail.com> wrote:
> hi Dear
> the first data that I used is data1   one as below
>
>
>> head(data1)
>
>   firm indus bazar year     y1     x1    x2  x3    x4
> 1    1     6     1 1382 117232  89110  3975 106 30198
> 2    1     6     1 1383 159865 121072  5399 109 35208
> 3    1     6     1 1384 181653 126703  7597 109 36442
> 4    1     6     1 1385 242900 163429 12768 109 41974
> 5    1     6     1 1386 341478 229209 11081 109 50036
> 6    1     6     1 1387 403594 268295 14581 109 57970
>> summary(data1)
>       firm            indus           bazar             year            y1
> x1                  x2                  x3                  x4
>  Min.   :  1.00   Min.   :1.000   Min.   :0.0000   Min.   :1382   Min.   :
> 0   Min.   :       45   Min.   :      254   Min.   :       13   Min.   :
> 134
>  1st Qu.: 43.00   1st Qu.:1.000   1st Qu.:1.0000   1st Qu.:1385   1st Qu.:
> 139218   1st Qu.:   139788   1st Qu.:    11790   1st Qu.:     2452   1st
> Qu.:    43231
>  Median : 85.00   Median :4.000   Median :1.0000   Median :1388   Median :
> 405936   Median :   394484   Median :    27708   Median :   405576   Median
> :   129125
>  Mean   : 85.74   Mean   :3.371   Mean   :0.9165   Mean   :1388   Mean   :
> 3588140   Mean   : 74125965   Mean   : 32702944   Mean   :489595378   Mean
> : 36749864
>  3rd Qu.:129.00   3rd Qu.:4.000   3rd Qu.:1.0000   3rd Qu.:1391   3rd Qu.:
> 1244035   3rd Qu.:  1406170   3rd Qu.:    77408   3rd Qu.:999999999   3rd
> Qu.:   472913
>  Max.   :170.00   Max.   :6.000   Max.   :1.0000   Max.   :1393   Max.
> :400779395   Max.   :999999999   Max.   :999999999   Max.   :999999999
> Max.   :999999999
>> sapply(data1,sd)
>         firm        indus        bazar         year           y1
> x1           x2           x3           x4
> 4.913015e+01 1.814535e+00 2.766475e-01 3.470185e+00 1.928340e+07
> 2.571194e+08 1.775295e+08 4.999911e+08 1.852238e+08
>
>
>> is.data.frame(data1)
> [1] TRUE
>
>
>
>
>
> for dea I used
>
> x=with(data1, cbind(x1,x2,x3,x4))
> y=with(data1, cbind(y1))
> farzana=dea(x,y)
> farzana
>
>
> and also
>
>
>
>> str(farzana)
>
> List of 12
>  $ eff        : num [1:1965] 0.732 0.717 0.713 0.705 0.768 ...
>  $ lambda     : num [1:1965, 1:1965] 0 0 0 0 0 0 0 0 0 0 ...
>   ..- attr(*, "dimnames")=List of 2
>   .. ..$ : NULL
>   .. ..$ : chr [1:1965] "L1" "L2" "L3" "L4" ...
>  $ objval     : num [1:1965] 0.732 0.717 0.713 0.705 0.768 ...
>  $ RTS        : chr "vrs"
>  $ primal     : NULL
>  $ dual       : NULL
>  $ ux         : NULL
>  $ vy         : NULL
>  $ gamma      :function (x)
>  $ ORIENTATION: chr "in"
>  $ TRANSPOSE  : logi FALSE
>  $ param      : NULL
>  - attr(*, "class")= chr "Farrell"
>
>
>
>
>
> but now
>
>
>> write.csv(farzana,'D:sajjaad.csv')
> Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors =
> stringsAsFactors) :
>   cannot coerce class ""Farrell"" to a data.frame
>
>
> so haw can I save it as csv?
>
>
> best regards
>>
>>
>
> On Wed, Jun 15, 2016 at 12:50 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi farzana,
>> Probably the first thing is to ascertain what the class of "farzana" might
>> be:
>>
>> class(farzana)
>>
>> Because "write.csv" expects "the object to be written, preferably a
>> matrix or data frame. If not, it is attempted to coerce x to a data
>> frame." to be the first argument. It seems that "farzana" is neither a
>> matrix nor a data frame and something for which there is no method to
>> convert it to one.
>>
>> The second thing to do is to try to work out what is inside "farzana":
>>
>> str(farzana)
>>
>> This will produce a summary of what is in there. _Maybe_ with that
>> summary you can figure out how to convert it into a data frame. If
>> not, you can always save the object:
>>
>> save(farzana,file="farzana.Rdata")
>>
>> and reload it later.
>>
>> Jiim
>>
>>
>> On Thu, Jun 16, 2016 at 5:47 AM, farzana akbari
>> <farzana.akbari2013 at gmail.com> wrote:
>> > in the name of God
>> >
>> >
>> > hi dear
>> >
>> > I  use benchmark package to use of dea  and when I wanna save my result
>> > as csv by this as below
>> >  write.csv(farzana,'D:sajjaad.csv')
>> >
>> > I can not and the error is as below
>> >
>> >
>> > Error in as.data.frame.default(x[[i]], optional = TRUE, stringsAsFactors
>> > =
>> > stringsAsFactors) :
>> >   cannot coerce class ""Farrell"" to a data.frame
>> >
>> >
>> > what should I do ?
>> >
>> >
>> > best regards
>> > farzana
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From G.Maubach at weinwolf.de  Mon Jun 20 09:37:32 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 20 Jun 2016 09:37:32 +0200
Subject: [R] (Off-Topic] Introducing a new R Blog
Message-ID: <OF20584C8A.2FD4CCF7-ONC1257FD8.00296C0B-C1257FD8.0029E665@lotus.hawesko.de>

Hi All,

today I would like to announce a now R blog. I contains a few entries 
about the findings during my course of studies and my daily work:

https://github.com/gmaubach/R-Know-How/wiki/R-Blog

I hope you'll find my hints usefull.

In addition you could have a look at a small R collection of functions I 
found usefull when working with my data:

https://github.com/gmaubach/R-Project-Utilities

Kind regards

Georg Maubach


From dargosch at gmail.com  Mon Jun 20 09:48:43 2016
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Mon, 20 Jun 2016 09:48:43 +0200
Subject: [R] L1 penalized regression fails to predict from model
Message-ID: <CANO=ohL9MoBckD-6MqfdwD7NwnjYON+Tz2DJok7ObOj62xLtqQ@mail.gmail.com>

Dear list,

Sorry for this cross-post from StackOverflow, but I see that SO was maybe
the wrong forum for this question. Too package specific and

Ok, what I am trying to do is to predict from an L1 penalized regression.
This falls due to a data set dimension problem that I cannot figure out.

The procedure I'm using is the following:

require(penalized)# neg contains negative data# pos contains positive data

Now, the procedure below aims to construct comparable (balanced in terms os
positive and negative cases) training and validation data sets.

# 50% negative training set
negSamp <- neg %>% sample_frac(0.5) %>% as.data.frame()# Negative validation set
negCompl <- neg[setdiff(row.names(neg),row.names(negSamp)),]# 50%
positive training set
posSamp <- pos %>% sample_frac(0.5) %>% as.data.frame()# Positive validation set
posCompl <- pos[setdiff(row.names(pos),row.names(posSamp)),]# Combine sets
validat <- rbind(negSamp,posSamp)
training <- rbind(negCompl,posCompl)

Ok, so here we now have two comparable sets.

[1] FALSE  TRUE> dim(training)[1] 1061  381> dim(validat)[1] 1060
381> identical(names(training),names(validat))[1] TRUE

I fit the model to the training set without a problem (and I've tried using
a range of Lambda1 values here). But, fitting the model to the validation
data set fails, with a just odd error description.

> fit <- penalized(VoiceTremor,training[-1],data=training,lambda1=40,standardize=TRUE)# nonzero coefficients: 13> fit2 <- predict(fit, penalized=validat[-1], data=validat)
Error in .local(object, ...) :
  row counts of "penalized", "unpenalized" and/or "data" do not match

Just to make sure that this is not due to some NA's in the data set:

> identical(validat,na.omit(validat))[1] TRUE

Oddly enough, I may generate some new data that is comparable to the proper
data set:

> data.frame(VoiceTremor="NVT",matrix(rnorm(380000),nrow=1000,ncol=380) ) -> neg
> data.frame(VoiceTremor="VT",matrix(rnorm(380000),nrow=1000,ncol=380) ) -> pos> dim(pos)[1] 1000  381> dim(neg)[1] 1000  381

and run the procedure above, and then the prediction step works!

How come?

What could be wrong with my second (not training) data set?

Fredrik

-- 
"Life is like a trumpet - if you don't put anything into it, you don't get
anything out of it."

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Mon Jun 20 13:18:13 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Mon, 20 Jun 2016 11:18:13 +0000 (UTC)
Subject: [R] How to visualize this df
References: <2145568060.10386739.1466421493243.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2145568060.10386739.1466421493243.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I have a question about how to visualize my df! here is my df I need to visualize:

    'data.frame':   455 obs. of 128 variables:
    $Protocol      :Factor w/132 levels "_unknown","PD FS SAG","T1 SAG FS","T2 FS OR",...
    $NRuns         : int   45 45 156 75 89 69 ......
    $Speed         :Factor w/4 levels "Slow","Fast","VeryFast","VerySlow" 
NRuns is actually number of times that the customer used the protocol and speed is how did the costumer run the Protocol. Each Protocol can have different NRuns. Do you know what's the best way to visualize this df? 
Thanks for any help!
Elahe


From Rainer at krugs.de  Mon Jun 20 13:28:51 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 20 Jun 2016 13:28:51 +0200
Subject: [R] How to visualize this df
In-Reply-To: <2145568060.10386739.1466421493243.JavaMail.yahoo@mail.yahoo.com>
	(ch elahe via R-help's message of "Mon, 20 Jun 2016 11:18:13 +0000
	(UTC)")
References: <2145568060.10386739.1466421493243.JavaMail.yahoo.ref@mail.yahoo.com>
	<2145568060.10386739.1466421493243.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <m2twgorte4.fsf@krugs.de>

"ch.elahe via R-help" <r-help at r-project.org> writes:

> Hi all,
> I have a question about how to visualize my df! here is my df I need to visualize:
>
>     'data.frame':   455 obs. of 128 variables:
>     $Protocol      :Factor w/132 levels "_unknown","PD FS SAG","T1 SAG FS","T2 FS OR",...
>     $NRuns         : int   45 45 156 75 89 69 ......
>     $Speed         :Factor w/4 levels "Slow","Fast","VeryFast","VerySlow" 
> NRuns is actually number of times that the customer used the protocol
> and speed is how did the costumer run the Protocol. Each Protocol can
> have different NRuns. Do you know what's the best way to visualize
> this df?

That depends what you want to show. And that determines the best
visualization.

Also: what do you want to use it for: an interactive
presentation may call for different visualizations than a printed
report.

Cheers,

Rainer

> Thanks for any help!
> Elahe
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160620/e6885ef0/attachment.bin>

From fromnorden at gmail.com  Sun Jun 19 18:40:35 2016
From: fromnorden at gmail.com (Andreu Ferrero)
Date: Sun, 19 Jun 2016 18:40:35 +0200
Subject: [R] frailtypack - Model did not converge
Message-ID: <CAH2QH=cCEnqCtJ+_4uevYOb2v+4MT-d5B3cRjggt=5g2hxvqBQ@mail.gmail.com>

Hey,


I am using "frailtyPenal" to fit a general joint model:

I got a "Model did not converge" message, and I guess it is because I miss
specify something in the command:

"Call:
frailtyPenal(formula = Surv(Time_final_mes_cor, BD_RE2.Re_IC1_cor) ~
    cluster(BD_RE2.e_b_id) + (BD_RE2.X.a_probnp_bnpR) +
(BD_RE2.ae_presencia_Cizquierda) +
        (BD_RE2.CKD_EPI60) + terminal(BD_RE2.death1_cor),
formula.terminalEvent = ~(BD_RE2.X.a_probnp_bnpR) +
    (BD_RE2.ae_presencia_Cizquierda) + (BD_RE2.CKD_EPI60), data = BD_AV,
    recurrentAG = FALSE, jointGeneral = TRUE, n.knots = 20, kappa =
c(10000,
        10000), maxit = 700, LIMlogl = 0.0142)


  General Joint gamma frailty model for recurrent and a terminal event
processes
  using a Penalized Likelihood on the hazard function

   Convergence criteria:
   parameters = 6.81e-09 likelihood = 0.0115 gradient = 1

   n= 2473
   n recurrent events= 406
   n terminal events= 195"


Any idea??? Cause PC computing takes hours to "fit/non-fit" this model.


Thanks,




Andreu Ferrero Gregori

	[[alternative HTML version deleted]]


From hadar.nomi at gmail.com  Mon Jun 20 13:11:47 2016
From: hadar.nomi at gmail.com (Nomi Hadar)
Date: Mon, 20 Jun 2016 14:11:47 +0300
Subject: [R] gbresolve function from the geiger package
Message-ID: <CAFnqqUZm3DgT8TyDSBY8JxenyNm1vukN5nr-Rn0tBTHfAWOzDA@mail.gmail.com>

Hello,

I have troubles with the gbresolve function from the *geiger *package,
which works with the NCBI taxonomy.
When I use it, there are genera that are not found although they *do appear
*in the NCBI taxonomy browser.
<http://www.ncbi.nlm.nih.gov/Taxonomy/taxonomyhome.html/>

for example, when I run:

library("ape")
library("geiger")

genus = "Christia"
gbresolve(genus, rank= "genus", within = "Fabaceae")

("Christia" is a genus within a plants group called Fabaceae)

I get:

Error in tmp[[idx]] : subscript out of bounds
In addition: Warning messages:
1: In FUN(X[[i]], ...) : Attempt one of the following:
Bacterium purifaciens Christiansen 1917
...
...
2: In gbresolve.default(genus, rank = "genus", within = "Fabaceae") :
  The following taxa were not encountered in the NCBI taxonomy:
Christia


And so for other genera such as "Pycnospora" / "Solori" / "Thailentadopsis"
and more.
You can see that "Christia" appears in browser
<http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi>, and so I expect
to get "Christia vespertilionis" as result.

Why is that?

Thank you very much!
Nomi


-- 
*Nomi Hadar*

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Sun Jun 19 22:22:37 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Mon, 20 Jun 2016 01:52:37 +0530
Subject: [R] Error in setwd() : argument "dir" is missing, with no default
Message-ID: <CAB=p7SrVCiXKw0B+vNMTY=_fcpbd_Dne9D2YkGN-Mw3C_qu7oA@mail.gmail.com>

Dear Team,

I have searched for this error at various forums but enable to find a
relevant solution.

When i had installed R studio the WD was saved at a particular location now
when i try to change it gives me this error:

Error in setwd() : argument "dir" is missing, with no default. I have tried
setting the WD using Shift+ Ctrl+ H or using setwd() command. While it
changes the WD for that particular session but when i restart the session
it is again reset to the old previous location hence every instance i have
to reset this as all my data and other files are saved at another location.
While searching at some of the forums like stat exchange it was advised to
use setwd("../") as it selects your WD one step back however with this also
i cant fix the issue.

Kindly advice at the earliest.

Thanks, Shivi

	[[alternative HTML version deleted]]


From loupiote93 at hotmail.fr  Mon Jun 20 04:09:44 2016
From: loupiote93 at hotmail.fr (Lucie Dupond)
Date: Mon, 20 Jun 2016 02:09:44 +0000
Subject: [R] R help contingency table
Message-ID: <DB5PR03MB147949B7C7EF9A538867A0A7A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>

Hello,
I'm sorry if my question is really basic, but I'm having some troubles with the statistics for my thesis, and especially the khi square test and contingency tables.

For what I understood, there are two "kinds" of khisquare test, that are quite similar :
- Homogeneity, when we have one variable and we want to compare it with a theorical distribution
- Independence test, when we have 2 variable and we want to see if they are linked

-- -

I'm working on color transitions, with 3 possible factors : ? High ? , ? Medium ? and ? Low ?
I want to know if an individual will go preferably from a color ? High ? to another color ? High ?, more than from a color ? High ? to a color ? Medium ? (for example)

I have this table :

trans1<-c(51,17,27,12,21,13,37,15,60)
transitions1<-matrix(trans1, nrow=3, ncol=3, byrow=T)
rownames(transitions1) <- c("High"," Medium", "Low")
colnames(transitions1) <- c("High"," Medium", "Low")

The first colomn is showing the first color, and the second is showing the second color of the transition

It looks like I'm in the case of an Independence test, in order to see if the variable "second color" is linked to the "first color".

So I'm making the test :

chisq.test(transitions1)


(If I understood well, the test on the matrix is the independence  test, and the test on the vector trans1 is the homogeneity test ?)

The result is significatif, it means that some transitions are prefered.

My problem is that I have other transition tables like this one (with other individuals or other conditions)
For example, I also have this one :


trans2<-c(13,7,8,5,16,18,11,8,17)
transitions2<-matrix(trans2, nrow=3, ncol=3, byrow=T)
rownames(transitions2) <- c("High","Low", "Stick")
colnames(transitions2) <- c("High","Low", "Stick")

I want to know if the "prefered" transitions in the table 1 are the same in the table 2.
But if I try a khisquare test on those two matrix, R only takes the first one.

How can I compare those tables
Maybe with another test ?

Thanks in advance !

Kind regards

Lucie S.

	[[alternative HTML version deleted]]


From dpriyank23 at gmail.com  Mon Jun 20 01:17:27 2016
From: dpriyank23 at gmail.com (Priyank Dwivedi)
Date: Sun, 19 Jun 2016 18:17:27 -0500
Subject: [R] Fwd: Matrix Constraints in R Optim
In-Reply-To: <A8E545C2-7085-4AEF-817C-CD0102FB30F6@dcn.davis.ca.us>
References: <CADya=_wMawuy4A8+58=vgAXn7F4eSZ1z2m00pCkfe-HVGt34ow@mail.gmail.com>
	<CADya=_ymi22=6Xj5BtVKf7jisUrjK_pogM6qx04NvL287cK3fA@mail.gmail.com>
	<A8E545C2-7085-4AEF-817C-CD0102FB30F6@dcn.davis.ca.us>
Message-ID: <CADya=_xfAD3wt2BXaD899FuJY2Vyo0u+7GdsF3O3+1JxUVbSHA@mail.gmail.com>

All,
Here are the dput files of the input data to the code.

Thanks for any advice.

I am adding the entire code below too just in case.


file <- file.path("Learning R","CRM_R_Ver4.xlsx")
file
my.data <- readWorksheetFromFile(file,sheet=1,startRow=1)
str(my.data)  # DATA FRAME
my.data.matrix.inj <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
my.data.matrix.inj

dput(my.data.matrix.inj,"my.data.matrix.inj.txt")


my.data.2 <- readWorksheetFromFile(file,sheet=2,startRow=1)
str(my.data.2)  # DATA FRAME
my.data.matrix.time <- as.matrix(my.data.2)  #convert DATA FRAME to MATRIX
my.data.matrix.time

dput(my.data.matrix.time,"my.data.matrix.time.txt")

my.data <- readWorksheetFromFile(file,sheet=3,startRow=1)
str(my.data)  # DATA FRAME
my.data.matrix.prod <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
my.data.matrix.prod

dput(my.data.matrix.prod,"my.data.matrix.prod.txt")

 # my.data.var <- vector("numeric",length = 24)
 # my.data.var

my.data.var <- c(10,0.25,0.25,0.25,0.25,0.25,
                 10,0.25,0.25,0.25,0.25,0.25,
                 10,0.25,0.25,0.25,0.25,0.25,
                 10,0.25,0.25,0.25,0.25,0.25)
my.data.var

dput(my.data.var,"my.data.var.txt")


my.data.qo <- c(5990,150,199,996)   #Pre-Waterflood Production
my.data.timet0 <- 0 # starting condition for time

#FUNCTION
Qjk.Cal.func <- function(my.data.timet0,my.data.qo,my.data.matrix.time,
                         my.data.matrix.inj,
my.data.matrix.prod,my.data.var,my.data.var.mat)
{

  qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
ncol=ncol(my.data.matrix.prod))

  count <- 1
  number <- 1
  for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
wells columns
  {
    sum <-0
    for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
    {
      sum <-0
      deltaT <-0
      expo <-0


        for(column in 1:ncol(my.data.matrix.inj)) #loop through all
the injector columns to get the PRODUCT SUM
         {
            sum = sum +
my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
         }

      if(count<2)
      {
        deltaT<- my.data.matrix.time[row]
      }
      else
      {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}


      expo <- exp(-deltaT/my.data.var.mat[colnum,1])
# change here too

      if(count<2)
      {
        qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo + (1-expo)*sum
      }
      else
      {
        qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
(1-expo)*sum
      }
      count <- count+1
    }

    count <-1
  }

  qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION

}


# ERROR FUNCTION - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
MATRIX. Miminize the Error by changing my.data.var

Error.func <- function(my.data.var)
{
  #First convert vector(my.data.var) to MATRIX aand send it to
calculate new MATRIX
  my.data.var.mat <- matrix(my.data.var,nrow =
ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow =
TRUE)

  Calc.Qjk.Value <- Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
                                 my.data.matrix.inj,
my.data.matrix.prod,my.data.var,my.data.var.mat)


  diff.values <- my.data.matrix.prod-Calc.Qjk.Value    #FIND
DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL MATRIX


  Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
  print(paste(Error))

  Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
total avg error


  Error_total
}

# OPTIMIZE

sols<-optim(my.data.var,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1),
      lower=c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))

sols

On 17 June 2016 at 16:55, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Your code is corrupt because you failed to send your email in plain text
> format.
>
> You also don't appear to have all data needed to reproduce the problem. Use
> the dput function to generate R code form of a sample of your data.
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 17, 2016 1:07:21 PM PDT, Priyank Dwivedi <dpriyank23 at gmail.com>
> wrote:
>>
>> By mistake, I sent it earlier to the wrong address.
>>
>> ---------- Forwarded message ----------
>> From: Priyank Dwivedi <dpriyank23 at gmail.com>
>> Date: 17 June 2016 at 14:50
>> Subject: Matrix Constraints in R Optim
>> To: r-help-owner at r-project.org
>>
>>
>> Hi,
>>
>> Below is the code snippet I wrote in R:
>>
>> The basic idea is to minimize error by optimizing set of values (in this
>> scenario 12) in the form of a matrix. I defined the matrix elements as
>> vector "*my.data.var" * and then stacked it into a matrix called
>> "*my.data.var.mat"
>> in the error function. *
>>
>> The only part that I can't figure out is "what if the column sum in
>> the *my.data.var.mat
>> needs to be <=1"; that's the constraint/s.. Where do I introduce it in the
>> OPTIM solver or elsewhere?*
>>
>>
>>
>>
>>
>>
>> *my.data.matrix.inj* <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
>> my.data.matrix.inj
>>
>>
>> *my.data.matrix.time* <- as.matrix(my.data.2)  #convert DATA FRAME to
>> MATRIX
>> my.data.matrix.time
>>
>>
>> *my.data.matrix.prod* <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
>> my.data.matrix.prod
>>
>>
>> *my.data.var* <-
>>
>> c(2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01)
>> my.data.var
>>
>> *my.data.qo* <- c(5990,150,199,996)   #Pre-Waterflood Production
>>
>> *my.data.timet0* <- 0 # starting condition for time
>>
>>
>> *#FUNCTIONQjk.Cal.func* <-
>>
>> function(my.data.timet0,my.data.qo,my.data.matrix.time,
>>                          my.data.matrix.inj,
>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>> {
>>
>>   qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>> ncol=ncol(my.data.matrix.prod))
>>
>>   count <- 1
>>   number <- 1
>>   for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
>> wells columns
>>   {
>>     sum <-0
>>     for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
>>     {
>>       sum <-0
>>       deltaT <-0
>>       expo <-0
>>
>>
>>         for(column in 1:ncol(my.data.matrix.inj)) #loop through all the
>> injector columns to get the PRODUCT SUM
>>          {
>>             sum = sum +
>> my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>>          }
>>
>>       if(count<2)
>>       {
>>         deltaT<- my.data.matrix.time[row]
>>       }
>>       else
>>       {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>>
>>
>>       expo <- exp(-deltaT/my.data.var.mat[colnum,1])                  #
>> change here too
>>
>>       if(count<2)
>>       {
>>         qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo +
>> (1-expo)*sum
>>
>>  }
>>       else
>>       {
>>         qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
>> (1-expo)*sum
>>       }
>>       count <- count+1
>>     }
>>
>>     count <-1
>>   }
>>
>>   qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>>
>> }
>>
>>
>> *# ERROR FUNCTION* - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
>> MATRIX. Miminize the Error by changing my.data.var
>>
>> *Error.func* <- function(my.data.var)
>> {
>>   #First convert vector(my.data.var) to MATRIX aand send it to calculate
>> new MATRIX
>>   *my.data.var.mat* <- matrix(my.data.var,nrow =
>> ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow = TRUE)
>>
>> *  Calc.Qjk.Value* <-
>> Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>>                                  my.data.matrix.inj,
>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>
>>
>>   diff.values <-
>> my.data.matrix.prod-Calc.Qjk.Value    #FIND DIFFERENCE
>> BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>>
>>
>>   Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>> 1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>>   print(paste(Error))
>>
>>   Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
>> total
>> avg error
>>
>>
>>  * Error_total*
>> }
>>
>> # OPTIMIZE
>>
>> *optim*(*my.data.var*
>>
>> ,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1))
>>
>>
>



-- 
Best Regards,
Priyank Dwivedi
-------------- next part --------------
structure(c(284.6624, 284.6743, 284.6771, 284.6746, 284.6664, 
284.6516, 284.6283, 284.5931, 555.1354, 555.0648, 555.0361, 2717.121, 
2716.909, 2716.857, 3537.007, 3537.209, 454.2328, 454.2205, 454.2086, 
1297.769, 1297.827, 1386.995, 2040.08, 2040.237, 1074.394, 1409.096, 
1187.767, 1453.882, 1149.305, 1329.487, 1376.219, 1881.046, 1538.514, 
1002.312, 612.8742, 1373.664, 1424.084, 1352.598, 1479.259, 767.9471, 
1277.077, 1477.096, 1383.378, 1398.408, 1353.671, 882.6216, 1399.007, 
1159.061, 1507.469, 1089.506, 1642.942, 1799.764, 1873.927, 2145.548, 
2017.962, 1993.64, 2221.32, 2123.962, 2463.256, 2405.041, 2404.414, 
2438.734, 2638.787, 2616.91, 2346.845, 2852.143, 2942.838, 3140.032, 
762.2396, 1720.488, 1789.752, 371.4107, 1225.91, 1686.064, 1652.747, 
1724.248, 1655.486, 1552.557, 1870.383, 1807.614, 1498.599, 1376.45, 
1453.844, 1441.684, 1363.064, 1066.156, 1365.101, 1358.903, 1288.348, 
610.3185, 532.7502, 1573.272, 1768.713, 1781.086, 1747.261, 1977.336, 
1904.75, 1538.454, 1678.361, 1774.035, 1495.381, 1285.172, 1511.251, 
1627.114, 1626.432, 1579.333, 1574.744, 1435.232, 2135.695, 2031.769, 
2350.99, 2562.418, 2515.922, 2709.281, 1824.588, 1824.665, 1824.682, 
1824.666, 1824.613, 1824.519, 1824.37, 1824.144, 1367.973, 1367.799, 
1367.728, 626.0895, 626.0406, 626.0286, 299.3024, 299.3194, 1420.26, 
1420.222, 1420.185, 1626.06, 1626.133, 1181.016, 1067.529, 1067.611, 
1346.783, 1286.029, 1669.494, 1469.061, 1571.632, 1369.969, 1342.855, 
1635.875, 1769.014, 1876.71, 1794.846, 1658.31, 1526.607, 1676.101, 
1705.561, 1641.514, 1605.627, 1298.534, 1591.755, 1611.691, 1571.183, 
1584.321, 1572.948, 1532.965, 1524.934, 1534.853, 1538.834, 1463.963, 
1462.23, 1420.739, 1447.045, 1406.715, 1419.408, 1478.69, 1273.244, 
1262.34, 1165.642, 787.8699, 657.2443, 617.5942, 672.4419, 562.5458, 
600.0635, 553.3339, 581.2515, 686.7953, 448.5355, 1967.524, 968.7045, 
1253.422, 1417.029, 1348.352, 607.6661, 795.2877, 1122.037, 951.7014, 
1218.465, 1452.847, 1708.894, 1789.318, 1774.066, 1730.023, 1792.384, 
1647.639, 1532.214, 1398.604, 1456.599, 1405.635, 1341.6, 1384.088, 
1547.139, 1480.687, 1527.453, 1541.885, 1348.729, 1359.007, 1093.668, 
1078.121, 1202.416, 895.9857, 1175.532, 1010.464, 967.2054, 851.1081, 
740.4431, 930.6541, 1057.503, 1036.018, 1250.418, 1382.047, 278.5883, 
278.6001, 278.6027, 278.6003, 278.5922, 278.5778, 278.555, 278.5205, 
922.1713, 922.054, 922.0063, 967.21, 967.1343, 967.1157, 774.6002, 
774.6443, 772.0591, 772.0382, 772.018, 870.8308, 870.8698, 904.8117, 
825.425, 792.9547, 876.54, 882.7752, 681.8339, 775.945, 1081.869, 
928.0758, 921.4498, 1079.74, 795.1276, 810.2282, 835.9764, 825.9167, 
825.2587, 943.9789, 745.8108, 709.2183, 718.3409, 656.4478, 553.8104, 
682.1406, 863.1352, 837.0597, 850.8278, 789.4566, 827.334, 813.5239, 
723.0217, 808.3031, 871.0251, 1023.663, 1008.41, 1118.704, 1113.178, 
907.1134, 726.4997, 1064.354, 1208.275, 1269.964, 1226.312, 834.8596, 
952.5037, 1019.817, 922.9584, 886.3052, 898.9753, 868.3756, 869.4521, 
105.3649, 407.1053, 136.8827, 722.5133, 841.0006, 706.9567, 542.9826, 
198.147, 233.6965, 114.3593, 252.4854, 284.9101, 418.044, 215.6109, 
543.6895, 654.181, 927.2443, 896.0264, 822.9401, 878.3534, 692.4314, 
738.8477, 984.3605, 1069.655, 1022.925, 1002.807, 850.6902, 991.8134, 
1034.01, 1148.745, 1142.539, 1163.838, 1275.52, 1145.691, 1460.11, 
1377.891, 1306.395, 1304.617, 1278.456, 1378.95, 1374.073, 1449.972, 
1184.909, 270.0509, 270.0623, 270.0648, 270.0624, 270.0547, 270.0407, 
270.0186, 269.9851, 631.4337, 631.3534, 631.3207, 607.871, 607.8235, 
607.8118, 570.1067, 570.1392, 471.9973, 471.9845, 471.9722, 374.8601, 
374.8769, 482.6559, 509.4759, 259.6612, 601.047, 612.4909, 599.3603, 
368.4525, 541.0823, 637.376, 572.6561, 520.8604, 602.978, 508.6731, 
518.9494, 559.4774, 583.3226, 665.8262, 675.3377, 604.7722, 619.4575, 
567.0582, 700.1987, 680.9487, 720.6385, 697.012, 662.4166, 683.2136, 
659.8345, 667.4672, 707.6854, 743.7268, 858.9992, 832.3246, 779.6216, 
698.0973, 703.4314, 791.7886, 726.9083, 854.6981, 834.7772, 832.3445, 
812.7689, 727.6645, 652.1965, 826.9865, 849.4389, 811.6799, 850.7483, 
832.3735, 819.6655, 1042.436, 720.7501, 952.0648, 1195, 848.0734, 
976.9899, 1112.395, 1113.345, 1153.728, 805.5801, 646.0727, 617.1312, 
791.8318, 847.233, 683.816, 724.7269, 911.1725, 827.3728, 995.0048, 
800.6775, 879.0817, 972.6709, 799.3595, 1029.595, 1007.769, 852.9899, 
837.8101, 941.9149, 982.4396, 979.9702, 967.2394, 937.1133, 960.9035, 
908.2497, 996.8404, 1190.648, 1202.747, 1350.496, 1267.897, 1132.526, 
1055.183, 799.7894, 639.9702, 769.6429, 769.6754, 769.6827, 769.676, 
769.6537, 769.6139, 769.551, 769.4556, 499.9228, 499.8593, 499.8334, 
1051.619, 1051.537, 1051.517, 1017.837, 1017.895, 787.5231, 787.5018, 
787.4812, 127.3492, 127.3549, 240.9772, 248.1084, 400.2578, 663.3332, 
986.2067, 936.059, 1061.159, 849.0998, 884.3383, 1183.185, 1208.31, 
981.9471, 1076.72, 1124.325, 1008.958, 780.2723, 692.6738, 1044.181, 
804.3527, 664.2988, 713.3538, 768.6463, 791.4983, 1408.636, 1460.505, 
1331.472, 1436.979, 1223.143, 1192.528, 1165.123, 1187.325, 889.4554, 
1755.404, 1539.565, 1367.623, 1197.647, 1204.832, 1253.376, 1064.125, 
1221.669, 1063.684, 1029.96, 941.9225, 953.305, 1135.038, 995.6816, 
1202.049, 1179.09, 1238.77, 1252.872, 195.4976, 796.9503, 1409.675, 
2215.336, 1971.793, 1372.014, 1194.094, 990.832, 1240.13, 1272.831, 
1110.265, 1083.954, 1277.695, 1224.066, 1216.931, 1036.133, 1275.89, 
650.2736, 493.1569, 443.461, 457.3099, 492.6304, 514.841, 490.7231, 
505.4785, 567.1318, 544.3971, 547.5244, 528.4097, 662.0999, 964.6831, 
1006.148, 1102.357, 1207.62, 1272.277, 1173.155, 1125.227, 1039.502, 
1074.456, 1146.245, 1429.14, 1246.974, 1215.329), .Dim = c(114L, 
5L), .Dimnames = list(NULL, c("I1", "I2", "I3", "I4", "I5")))
-------------- next part --------------
structure(c(2916.28, 1893.82, 1446.496, 1223.643, 1093.515, 1027.691, 
1025.575, 1069.484, 1350.653, 1383.106, 1404.12, 3229.087, 3287.819, 
3292.214, 3949.526, 3934.924, 1344.882, 1276.475, 1281.724, 2080.675, 
2170.162, 2204.06, 2733.114, 2709.72, 1906.547, 2226.197, 2147.538, 
2396.16, 2170.339, 2295.214, 2325.382, 2863.881, 2633.29, 2191.615, 
1823.576, 2462.448, 2472.716, 2426.248, 2558.359, 1898.222, 2311.003, 
2405.334, 2359.773, 2406.227, 2404.66, 2005.993, 2470.426, 2262.771, 
2564.288, 2187.93, 2672.702, 2817.843, 2886.186, 3159.216, 3071.983, 
3038.874, 3232.614, 3153.618, 3396.065, 3337.943, 3314.298, 3228.766, 
3312.479, 3214.223, 2943.438, 3374.134, 3471.613, 3649.256, 1494.396, 
2318.848, 2353.137, 1392.929, 2017.725, 2497.875, 2650.34, 2772.884, 
2503.756, 2341.685, 2665.939, 2603.909, 2361.046, 2307.904, 2466.254, 
2545.271, 2505.55, 2239.917, 2518.568, 2521.566, 2398.009, 1700.699, 
1570.964, 2475.785, 2666.551, 2696.887, 2733.822, 2956.056, 2906.461, 
2566.767, 2639.433, 2717.689, 2399.816, 2175.098, 2405.237, 2461.575, 
2513.077, 2476.729, 2467.291, 2303.615, 2898.341, 2858.363, 3200.795, 
3426.61, 3443.722, 3647.533, 195.3348, 176.5879, 161.8616, 147.6775, 
132.3667, 116.3203, 100.9762, 90.91395, 102.5056, 111.2312, 119.294, 
139.5639, 148.0501, 154.4379, 162.0608, 166.5477, 150.7256, 143.1064, 
137.4059, 131.9734, 127.8249, 129.6863, 136.1022, 121.6995, 131.2575, 
144.92, 150.0162, 140.1022, 146.21, 156.451, 158.8145, 162.6809, 
164.6031, 156.6059, 150.636, 155.6411, 158.7302, 166.222, 171.0211, 
162.1327, 161.2135, 156.3216, 162.0996, 166.6428, 175.9184, 176.8375, 
178.7133, 178.7524, 179.3178, 176.1973, 180.4867, 187.3193, 199.2127, 
209.983, 210.1795, 203.8254, 201.1218, 203.3554, 199.8475, 209.8946, 
215.1455, 215.6018, 213.2702, 199.2345, 185.3278, 197.2057, 205.0727, 
207.3002, 193.6611, 194.2139, 193.8643, 193.2228, 177.8776, 191.4582, 
231.8191, 227.0726, 224.6594, 229.7895, 230.8227, 234.7284, 206.1662, 
179.8467, 167.3609, 179.5722, 188.3897, 180.9705, 182.7036, 202.3105, 
200.8232, 203.9204, 189.2181, 192.9931, 204.6493, 199.082, 215.5948, 
223.7031, 213.8644, 202.6964, 208.5682, 216.1876, 217.9815, 217.007, 
217.463, 221.4278, 218.8876, 228.6546, 247.8913, 255.3423, 274.8202, 
276.3341, 269.6512, 262.6747, 239.2566, 213.2598, 196.0692, 179.3542, 
174.4489, 179.1992, 193.516, 219.7416, 261.9235, 307.7595, 339.0413, 
349.1725, 355.6877, 355.0119, 353.4153, 351.7466, 334.9937, 315.7924, 
338.9163, 353.4399, 367.3095, 370.7577, 368.3222, 338.1546, 309.5753, 
302.9909, 343.3383, 390.3582, 442.8708, 467.6517, 475.7294, 463.2386, 
475.4719, 512.9818, 525.4725, 546.562, 555.4177, 539.306, 499.4974, 
483.7216, 504.7977, 493.012, 470.5119, 433.9357, 442.8588, 456.0057, 
512.4643, 550.1924, 558.0298, 564.4106, 550.0839, 538.8026, 530.6313, 
523.3772, 495.919, 552.271, 570.1813, 559.772, 539.137, 531.285, 
511.5488, 489.0468, 483.7139, 434.6737, 391.9633, 353.6852, 341.9161, 
345.1014, 337.9316, 347.3225, 351.3463, 368.2297, 356.9464, 385.1567, 
367.8657, 433.608, 567.5147, 609.7797, 502.3615, 441.0474, 421.461, 
421.8376, 446.8344, 468.2683, 499.6648, 542.9484, 556.0471, 560.2142, 
552.7231, 561.0404, 498.0082, 435.9498, 406.5746, 388.8749, 379.8109, 
384.6039, 402.4961, 406.7456, 417.0511, 418.7817, 404.1004, 396.1866, 
381.1434, 398.5426, 424.4879, 419.1766, 448.4539, 459.9056, 450.9682, 
429.8293, 402.7214, 409.8873, 434.7366, 470.5877, 491.6042, 505.3956, 
2379.811, 1683.061, 1348.136, 1183.511, 1096.342, 1063.209, 1083.307, 
1137.872, 1698.039, 1777.531, 1824.798, 1990.391, 2049.531, 2094.436, 
1982.723, 1974.184, 1931.659, 1916.844, 1909.946, 1859.683, 1768.624, 
1733.896, 1644.874, 1566.683, 1802.985, 2026.399, 2002.01, 2095.246, 
2341.096, 2261.631, 2337.393, 2534.549, 2322.27, 2333.124, 2367.872, 
2336.886, 2235.952, 2284.032, 2240.623, 2144.319, 2069.301, 1946.398, 
1910.047, 2043.538, 2433.989, 2556.197, 2578.596, 2568.367, 2534.411, 
2478.992, 2395.445, 2468.419, 2459.169, 2850.418, 2889.555, 2898.655, 
2802.34, 2630.252, 2451.473, 2667.949, 2813.618, 2777.629, 2657.484, 
2226.911, 2225.193, 2366.028, 2296.084, 2321.493, 2335.952, 2351.763, 
2347.124, 1576.808, 1743.489, 1847.67, 2869.197, 3040.427, 2686.383, 
2409.108, 2028.894, 2091.013, 1932.818, 1923.021, 1920.55, 2171.707, 
2086.544, 2304.832, 2344.914, 2685.513, 2448.996, 2252.836, 2147.083, 
1971.758, 2033.175, 2196.932, 2353.921, 2357.346, 2326.293, 2178.859, 
2293.083, 2341.083, 2452.64, 2557.318, 2645.425, 2778.83, 2744.436, 
3066.146, 3070.198, 3004.751, 3008.488, 2991.268, 3074.413, 3159.114, 
3126.801, 2823.369), .Dim = c(114L, 4L), .Dimnames = list(NULL, 
    c("Q1", "Q2", "Q3", "Q4")))
-------------- next part --------------
structure(c(1, 1.944202, 3.803123, 6.203458, 9.420446, 14.03878, 
21.35927, 30.4375, 44.67685, 52.77593, 60.875, 76.09375, 83.70312, 
91.3125, 104.9416, 121.75, 136.9688, 144.5781, 152.1875, 167.4062, 
182.625, 213.0625, 243.5, 273.9375, 304.375, 334.8125, 365.25, 
395.6875, 426.125, 456.5625, 487, 517.4375, 547.875, 578.3125, 
608.75, 639.1875, 669.625, 700.0625, 730.5, 760.9375, 791.375, 
821.8125, 852.25, 882.6875, 913.125, 943.5625, 974, 1004.438, 
1034.875, 1065.312, 1095.75, 1126.188, 1156.625, 1187.062, 1217.5, 
1247.938, 1278.375, 1308.812, 1339.25, 1369.688, 1400.125, 1430.562, 
1461, 1491.438, 1521.875, 1552.312, 1582.75, 1613.188, 1643.625, 
1674.062, 1704.5, 1734.938, 1765.375, 1795.812, 1826.25, 1856.688, 
1887.125, 1917.562, 1948, 1978.438, 2008.875, 2039.312, 2069.75, 
2100.188, 2130.625, 2161.062, 2191.5, 2221.938, 2252.375, 2282.812, 
2313.25, 2343.688, 2374.125, 2404.562, 2435, 2465.438, 2495.875, 
2526.312, 2556.75, 2587.188, 2617.625, 2648.062, 2678.5, 2708.938, 
2739.375, 2769.812, 2800.25, 2830.688, 2861.125, 2891.562, 2922, 
2952.438, 2982.875, 3013.312), .Dim = c(114L, 1L), .Dimnames = list(
    NULL, "time"))
-------------- next part --------------
c(10, 0.25, 0.25, 0.25, 0.25, 0.25, 10, 0.25, 0.25, 0.25, 0.25, 
0.25, 10, 0.25, 0.25, 0.25, 0.25, 0.25, 10, 0.25, 0.25, 0.25, 
0.25, 0.25)

From Rainer at krugs.de  Mon Jun 20 14:48:13 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 20 Jun 2016 14:48:13 +0200
Subject: [R] How to visualize this df
In-Reply-To: <709819472.10367189.1466422787123.JavaMail.yahoo@mail.yahoo.com>
	(chalabi elahe's message of "Mon, 20 Jun 2016 11:39:47 +0000 (UTC)")
References: <2145568060.10386739.1466421493243.JavaMail.yahoo.ref@mail.yahoo.com>
	<2145568060.10386739.1466421493243.JavaMail.yahoo@mail.yahoo.com>
	<m2twgorte4.fsf@krugs.de>
	<709819472.10367189.1466422787123.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <m2lh20rppu.fsf@krugs.de>

<chalabi.elahe at yahoo.de> writes:

>  Hi Rainer,

Please keep this on the mailing list for info.

> Thanks for your reply. I want to show NRuns for each Protocol in my df
> and color it by Speed. I think it's possible by a bar chart but I am
> confused how to subset my df for using Bar chart in ggplot

Sorry - haven't used ggplot in ages.

Can't help you with that.

Rainer

>  
>
> On Monday, June 20, 2016 1:29 PM, Rainer M Krug <Rainer at krugs.de> wrote:
> "ch.elahe via R-help" <r-help at r-project.org> writes:
>
>> Hi all,
>> I have a question about how to visualize my df! here is my df I need to visualize:
>>
>>     'data.frame':   455 obs. of 128 variables:
>>     $Protocol      :Factor w/132 levels "_unknown","PD FS SAG","T1 SAG FS","T2 FS OR",...
>>     $NRuns         : int   45 45 156 75 89 69 ......
>>     $Speed         :Factor w/4 levels "Slow","Fast","VeryFast","VerySlow" 
>> NRuns is actually number of times that the customer used the protocol
>> and speed is how did the costumer run the Protocol. Each Protocol can
>> have different NRuns. Do you know what's the best way to visualize
>> this df?
>
> That depends what you want to show. And that determines the best
> visualization.
>
> Also: what do you want to use it for: an interactive
> presentation may call for different visualizations than a printed
> report.
>
> Cheers,
>
> Rainer
>
>
>> Thanks for any help!
>> Elahe
>>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160620/dddf7f70/attachment.bin>

From petr.pikal at precheza.cz  Mon Jun 20 14:59:04 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 20 Jun 2016 12:59:04 +0000
Subject: [R] Error in setwd() : argument "dir" is missing,
 with no default
In-Reply-To: <CAB=p7SrVCiXKw0B+vNMTY=_fcpbd_Dne9D2YkGN-Mw3C_qu7oA@mail.gmail.com>
References: <CAB=p7SrVCiXKw0B+vNMTY=_fcpbd_Dne9D2YkGN-Mw3C_qu7oA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50317C1@SRVEXCHMBX.precheza.cz>

Hi

maybe it is feature of RStudio so you shall probably ask there. I use to start each project in a separate folder and I always start R by doubleclick on .RData icon.

So for each project I have different .RData.

Beware that Windows keeps you safe and usually hides files with dot at the beginning so you need to allow such files to be displayed.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi
> Bhatia
> Sent: Sunday, June 19, 2016 10:23 PM
> To: r-help at r-project.org
> Subject: [R] Error in setwd() : argument "dir" is missing, with no default
>
> Dear Team,
>
> I have searched for this error at various forums but enable to find a relevant
> solution.
>
> When i had installed R studio the WD was saved at a particular location now
> when i try to change it gives me this error:
>
> Error in setwd() : argument "dir" is missing, with no default. I have tried
> setting the WD using Shift+ Ctrl+ H or using setwd() command. While it
> changes the WD for that particular session but when i restart the session it is
> again reset to the old previous location hence every instance i have to reset
> this as all my data and other files are saved at another location.
> While searching at some of the forums like stat exchange it was advised to
> use setwd("../") as it selects your WD one step back however with this also i
> cant fix the issue.
>
> Kindly advice at the earliest.
>
> Thanks, Shivi
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Mon Jun 20 15:21:22 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 20 Jun 2016 14:21:22 +0100
Subject: [R] R help contingency table
In-Reply-To: <DB5PR03MB147949B7C7EF9A538867A0A7A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>
References: <DB5PR03MB147949B7C7EF9A538867A0A7A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403E1955A03@GBTEDVPEXCMB04.corp.lgc-group.com>

> The first colomn is showing the first color, and the second is showing the
> second color of the transition
Are you sure?
transitions1 is a 3x3 matrix; it has three columns, not two. 

Could it be that the columns are colour 2 following initial condition given by row, or vice versa?

[not that that will help _me_ answer your question, but it may help someone else].

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From petr.pikal at precheza.cz  Mon Jun 20 15:25:21 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 20 Jun 2016 13:25:21 +0000
Subject: [R] How to visualize this df
In-Reply-To: <m2lh20rppu.fsf@krugs.de>
References: <2145568060.10386739.1466421493243.JavaMail.yahoo.ref@mail.yahoo.com>
	<2145568060.10386739.1466421493243.JavaMail.yahoo@mail.yahoo.com>
	<m2twgorte4.fsf@krugs.de>
	<709819472.10367189.1466422787123.JavaMail.yahoo@mail.yahoo.com>
	<m2lh20rppu.fsf@krugs.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50317E2@SRVEXCHMBX.precheza.cz>

Hi

you still should post a snippet of your data to help others better understand.

It should be something like
p<- ggplot(dat, aes(x=Protocol, y=NRuns, fill=Speed))
p+geom_bar(stat="identity")

But as you have 132 levels of protocol unless you have big big monitor you will have problems to display all protocols properly.

You could try to use points but it probably does not help much.

You could try similar approach as here
http://www.phaget4.org/R/image_matrix.html

or you could try to tweek your table to fit image function.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rainer M
> Krug
> Sent: Monday, June 20, 2016 2:48 PM
> To: ch.elahe via R-help <r-help at r-project.org>
> Subject: Re: [R] How to visualize this df
>
> <chalabi.elahe at yahoo.de> writes:
>
> >  Hi Rainer,
>
> Please keep this on the mailing list for info.
>
> > Thanks for your reply. I want to show NRuns for each Protocol in my df
> > and color it by Speed. I think it's possible by a bar chart but I am
> > confused how to subset my df for using Bar chart in ggplot
>
> Sorry - haven't used ggplot in ages.
>
> Can't help you with that.
>
> Rainer
>
> >
> >
> > On Monday, June 20, 2016 1:29 PM, Rainer M Krug <Rainer at krugs.de>
> wrote:
> > "ch.elahe via R-help" <r-help at r-project.org> writes:
> >
> >> Hi all,
> >> I have a question about how to visualize my df! here is my df I need to
> visualize:
> >>
> >>     'data.frame':   455 obs. of 128 variables:
> >>     $Protocol      :Factor w/132 levels "_unknown","PD FS SAG","T1 SAG
> FS","T2 FS OR",...
> >>     $NRuns         : int   45 45 156 75 89 69 ......
> >>     $Speed         :Factor w/4 levels "Slow","Fast","VeryFast","VerySlow"
> >> NRuns is actually number of times that the customer used the protocol
> >> and speed is how did the costumer run the Protocol. Each Protocol can
> >> have different NRuns. Do you know what's the best way to visualize
> >> this df?
> >
> > That depends what you want to show. And that determines the best
> > visualization.
> >
> > Also: what do you want to use it for: an interactive presentation may
> > call for different visualizations than a printed report.
> >
> > Cheers,
> >
> > Rainer
> >
> >
> >> Thanks for any help!
> >> Elahe
> >>
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology Stellenbosch University South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From demmitba at gmail.com  Mon Jun 20 19:14:56 2016
From: demmitba at gmail.com (Brittany Demmitt)
Date: Mon, 20 Jun 2016 11:14:56 -0600
Subject: [R] loop testing unidentified columns
Message-ID: <5B4BEC93-DBC8-4092-B15A-07B0131A2C0A@gmail.com>

Hello,

I want to compare all of the columns of one data frame to another to see if any of the columns are equivalent to one another. The first column in both of my data frames are the sample IDs and do not need to be compared. Below is an example of the loop I am using to compare the two data frames that counts the number of equivalent values there between two columns. So in this example the value of 3 means that all three observations for the two columns being compared were equivalent. The loop works fine but I do not understand why it tests the first column of the sample IDs providing ?NA? for the sum of matching when my loop is specifying to only test columns 2-3.  

Thank you!


#create dataframe A 
A = matrix(c("a",3,4,"b",5,7,"c",3,7),nrow=3, ncol=3,byrow = TRUE)    
A <- as.data.frame(A)
A$V2 <- as.numeric(A$V2)
A$V3 <- as.numeric(A$V3)
str(A)

#create dataframe B
B = matrix(c("a",1,1,"b",6,2,"c",2,2),nrow=3, ncol=3,byrow = TRUE)    
B <- as.data.frame(B)
B$V2 <- as.numeric(B$V2)
B$V3 <- as.numeric(B$V3)
str(B)

results.2 <- numeric()
results.3  <- numeric()


#compare columns to identify those that are identical in the two dataframes 
for(i in 2:3){
  results.2[i] <- sum(A[,2]==B[,i])
  results.3[i] <- sum(A[,3]==B[,i])
  results.pc.all <- rbind(results.2,results.3)
}
results.pc.all


From dcarlson at tamu.edu  Mon Jun 20 20:38:08 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 20 Jun 2016 18:38:08 +0000
Subject: [R] Error in setwd() : argument "dir" is missing,
	with no default
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50317C1@SRVEXCHMBX.precheza.cz>
References: <CAB=p7SrVCiXKw0B+vNMTY=_fcpbd_Dne9D2YkGN-Mw3C_qu7oA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50317C1@SRVEXCHMBX.precheza.cz>
Message-ID: <e5ff8b59288d4b418ee4cf9b06f3e643@exch-2p-mbx-t2.ads.tamu.edu>

You cannot use setwd() without an argument:
> setwd()
Error in setwd() : argument "dir" is missing, with no default

If you want to choose a directory use choose.dir(). But if you are using RStudio, you can use the Files tab in the window on the lower right. Navigate to the folder/directory you want and then click the More tab and select "Set As Working Directory."

------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Monday, June 20, 2016 7:59 AM
To: Shivi Bhatia; r-help at r-project.org
Subject: Re: [R] Error in setwd() : argument "dir" is missing, with no default

Hi

maybe it is feature of RStudio so you shall probably ask there. I use to start each project in a separate folder and I always start R by doubleclick on .RData icon.

So for each project I have different .RData.

Beware that Windows keeps you safe and usually hides files with dot at the beginning so you need to allow such files to be displayed.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shivi
> Bhatia
> Sent: Sunday, June 19, 2016 10:23 PM
> To: r-help at r-project.org
> Subject: [R] Error in setwd() : argument "dir" is missing, with no default
>
> Dear Team,
>
> I have searched for this error at various forums but enable to find a relevant
> solution.
>
> When i had installed R studio the WD was saved at a particular location now
> when i try to change it gives me this error:
>
> Error in setwd() : argument "dir" is missing, with no default. I have tried
> setting the WD using Shift+ Ctrl+ H or using setwd() command. While it
> changes the WD for that particular session but when i restart the session it is
> again reset to the old previous location hence every instance i have to reset
> this as all my data and other files are saved at another location.
> While searching at some of the forums like stat exchange it was advised to
> use setwd("../") as it selects your WD one step back however with this also i
> cant fix the issue.
>
> Kindly advice at the earliest.
>
> Thanks, Shivi
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dcarlson at tamu.edu  Mon Jun 20 20:41:37 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 20 Jun 2016 18:41:37 +0000
Subject: [R] loop testing unidentified columns
In-Reply-To: <5B4BEC93-DBC8-4092-B15A-07B0131A2C0A@gmail.com>
References: <5B4BEC93-DBC8-4092-B15A-07B0131A2C0A@gmail.com>
Message-ID: <673ddaf871204cafa7e2b27e3bc4ed2b@exch-2p-mbx-t2.ads.tamu.edu>

It does not test the first column, but a vector must have consecutive indices. Since you did not assign a value, R inserts a missing value. If you don't want to see it use

> results.pc.all[, -1]
          [,1] [,2]
results.2    1    2
results.3    2    3

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brittany Demmitt
Sent: Monday, June 20, 2016 12:15 PM
To: r-help at r-project.org
Subject: [R] loop testing unidentified columns

Hello,

I want to compare all of the columns of one data frame to another to see if any of the columns are equivalent to one another. The first column in both of my data frames are the sample IDs and do not need to be compared. Below is an example of the loop I am using to compare the two data frames that counts the number of equivalent values there between two columns. So in this example the value of 3 means that all three observations for the two columns being compared were equivalent. The loop works fine but I do not understand why it tests the first column of the sample IDs providing ?NA? for the sum of matching when my loop is specifying to only test columns 2-3.  

Thank you!


#create dataframe A 
A = matrix(c("a",3,4,"b",5,7,"c",3,7),nrow=3, ncol=3,byrow = TRUE)    
A <- as.data.frame(A)
A$V2 <- as.numeric(A$V2)
A$V3 <- as.numeric(A$V3)
str(A)

#create dataframe B
B = matrix(c("a",1,1,"b",6,2,"c",2,2),nrow=3, ncol=3,byrow = TRUE)    
B <- as.data.frame(B)
B$V2 <- as.numeric(B$V2)
B$V3 <- as.numeric(B$V3)
str(B)

results.2 <- numeric()
results.3  <- numeric()


#compare columns to identify those that are identical in the two dataframes 
for(i in 2:3){
  results.2[i] <- sum(A[,2]==B[,i])
  results.3[i] <- sum(A[,3]==B[,i])
  results.pc.all <- rbind(results.2,results.3)
}
results.pc.all

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bob at rudis.net  Mon Jun 20 20:43:43 2016
From: bob at rudis.net (boB Rudis)
Date: Mon, 20 Jun 2016 14:43:43 -0400
Subject: [R] merging df with world map
In-Reply-To: <D389B2DE.17BEE0%macqueen1@llnl.gov>
References: <871107819.8642588.1466193989968.JavaMail.yahoo.ref@mail.yahoo.com>
	<871107819.8642588.1466193989968.JavaMail.yahoo@mail.yahoo.com>
	<D389B2DE.17BEE0%macqueen1@llnl.gov>
Message-ID: <CAJ4QxaMgRB39EViBavHjb5cfqpNr4Xgu9ynuqrd69FaOTPYBjg@mail.gmail.com>

you also don't need to do a merger if you use a base `geom_map()`
layer with the polygons and another using the fill (or points, lines,
etc).

On Fri, Jun 17, 2016 at 5:08 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> And you can check what David and Jeff suggested like this:
>
> intersect( df$COUNTRY, world_map$region )
>
> If they have any values in common, that command will show them. (Note that
> I said values in common, not countries in common.)
>
> WARNING:
> It appears that you have each country appearing more than once in both of
> the data frames. Even if the country names were spelled the same (which
> they are not in the first few rows), I would not care to predict the
> outcome of a many-to-many merge. It probably won't make sense for showing
> the data on a map.
>
> -Don
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 6/17/16, 1:06 PM, "R-help on behalf of ch.elahe via R-help"
> <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:
>
>>Hi all,
>>I want to use world map in ggplot2 and show my data on world map. my df
>>is:
>>
>>
>>    $ COUNTRY           : chr  "DE" "DE" "FR" "FR" ..
>>
>>    $ ContrastColor     : int  9 9 9 9 13 9 9 9 9 ..
>>
>>    $ quant             : Factor w/ 4 levels "FAST","SLOW",..I need to
>>merge my df with world_map data which is like this:
>>
>>
>>    world_map=map_data("world")
>>    data.frame':   99338 obs. of  6 variables:
>>    $ long     : num  -69.9 -69.9 -69.9 -70 -70.1 ...
>>    $ lat      : num  12.5 12.4 12.4 12.5 12.5 ...
>>    $ group    : num  1 1 1 1 1 1 1 1 1 1 ...
>>    $ order    : int  1 2 3 4 5 6 7 8 9 10 ...
>>    $ region   : chr  "Aruba" "Aruba" "Aruba" "Aruba" ...
>>    $ subregion: chr  NA NA NA NA ...
>>but by merging my df with world map data I get a data frame with zero
>>observation in it,I use this command for merging:
>>
>>
>>    world_map=merge(world_map,df,by.x="region",by.y="COUNTRY")
>>    str(world_map)
>>
>>    'data.frame':   0 obs. of  133 variables:
>>    $ region            : chr
>>    $ long              : num
>>    $ lat               : num
>>    $ group             : num
>>    $ order             : int
>>    $ subregion         : chr
>>does anyone know what is the problem of this merging that I am currently
>>using?
>>thanks for any help!
>>Elahe
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From demmitba at gmail.com  Mon Jun 20 20:47:48 2016
From: demmitba at gmail.com (Brittany Demmitt)
Date: Mon, 20 Jun 2016 12:47:48 -0600
Subject: [R] loop testing unidentified columns
In-Reply-To: <673ddaf871204cafa7e2b27e3bc4ed2b@exch-2p-mbx-t2.ads.tamu.edu>
References: <5B4BEC93-DBC8-4092-B15A-07B0131A2C0A@gmail.com>
	<673ddaf871204cafa7e2b27e3bc4ed2b@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <A5857260-7248-4F5C-97ED-22FA0A447EF4@gmail.com>

Thank you!

> On Jun 20, 2016, at 12:41 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> It does not test the first column, but a vector must have consecutive indices. Since you did not assign a value, R inserts a missing value. If you don't want to see it use
> 
>> results.pc.all[, -1]
>          [,1] [,2]
> results.2    1    2
> results.3    2    3
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brittany Demmitt
> Sent: Monday, June 20, 2016 12:15 PM
> To: r-help at r-project.org
> Subject: [R] loop testing unidentified columns
> 
> Hello,
> 
> I want to compare all of the columns of one data frame to another to see if any of the columns are equivalent to one another. The first column in both of my data frames are the sample IDs and do not need to be compared. Below is an example of the loop I am using to compare the two data frames that counts the number of equivalent values there between two columns. So in this example the value of 3 means that all three observations for the two columns being compared were equivalent. The loop works fine but I do not understand why it tests the first column of the sample IDs providing ?NA? for the sum of matching when my loop is specifying to only test columns 2-3.  
> 
> Thank you!
> 
> 
> #create dataframe A 
> A = matrix(c("a",3,4,"b",5,7,"c",3,7),nrow=3, ncol=3,byrow = TRUE)    
> A <- as.data.frame(A)
> A$V2 <- as.numeric(A$V2)
> A$V3 <- as.numeric(A$V3)
> str(A)
> 
> #create dataframe B
> B = matrix(c("a",1,1,"b",6,2,"c",2,2),nrow=3, ncol=3,byrow = TRUE)    
> B <- as.data.frame(B)
> B$V2 <- as.numeric(B$V2)
> B$V3 <- as.numeric(B$V3)
> str(B)
> 
> results.2 <- numeric()
> results.3  <- numeric()
> 
> 
> #compare columns to identify those that are identical in the two dataframes 
> for(i in 2:3){
>  results.2[i] <- sum(A[,2]==B[,i])
>  results.3[i] <- sum(A[,3]==B[,i])
>  results.pc.all <- rbind(results.2,results.3)
> }
> results.pc.all
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Jun 20 21:06:54 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 20 Jun 2016 19:06:54 +0000
Subject: [R] R help contingency table
In-Reply-To: <DB5PR03MB147949B7C7EF9A538867A0A7A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>
References: <DB5PR03MB147949B7C7EF9A538867A0A7A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>
Message-ID: <1b85bc155e9f436dbf982a7339e141ef@exch-2p-mbx-t2.ads.tamu.edu>

You should consult with your adviser or someone at your institution who has more experience in statistical analysis than you do. You want to compare the matrices, but the row/column labels are different so you may be comparing completely different categories.

Technically, you need to convert the two matrices into a single matrix. You can do that by converting each into a vector with the c() function. BUT this will compare High with High, Medium with Low, and Low with Stick which seems inadvisable. 

> rbind(c(transitions1), c(transitions2))
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
[1,]   51   12   37   17   21   15   27   13   60
[2,]   13    5   11    7   16    8    8   18   17
> chisq.test(rbind(c(transitions1), c(transitions2)))

        Pearson's Chi-squared test

data:  rbind(c(transitions1), c(transitions2))
X-squared = 22.411, df = 8, p-value = 0.004208

Warning message:
In chisq.test(rbind(c(transitions1), c(transitions2))) :
  Chi-squared approximation may be incorrect

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lucie Dupond
Sent: Sunday, June 19, 2016 9:10 PM
To: r-help at r-project.org
Subject: [R] R help contingency table

Hello,
I'm sorry if my question is really basic, but I'm having some troubles with the statistics for my thesis, and especially the khi square test and contingency tables.

For what I understood, there are two "kinds" of khisquare test, that are quite similar :
- Homogeneity, when we have one variable and we want to compare it with a theorical distribution
- Independence test, when we have 2 variable and we want to see if they are linked

-- -

I'm working on color transitions, with 3 possible factors : ? High ? , ? Medium ? and ? Low ?
I want to know if an individual will go preferably from a color ? High ? to another color ? High ?, more than from a color ? High ? to a color ? Medium ? (for example)

I have this table :

trans1<-c(51,17,27,12,21,13,37,15,60)
transitions1<-matrix(trans1, nrow=3, ncol=3, byrow=T)
rownames(transitions1) <- c("High"," Medium", "Low")
colnames(transitions1) <- c("High"," Medium", "Low")

The first colomn is showing the first color, and the second is showing the second color of the transition

It looks like I'm in the case of an Independence test, in order to see if the variable "second color" is linked to the "first color".

So I'm making the test :

chisq.test(transitions1)


(If I understood well, the test on the matrix is the independence  test, and the test on the vector trans1 is the homogeneity test ?)

The result is significatif, it means that some transitions are prefered.

My problem is that I have other transition tables like this one (with other individuals or other conditions)
For example, I also have this one :


trans2<-c(13,7,8,5,16,18,11,8,17)
transitions2<-matrix(trans2, nrow=3, ncol=3, byrow=T)
rownames(transitions2) <- c("High","Low", "Stick")
colnames(transitions2) <- c("High","Low", "Stick")

I want to know if the "prefered" transitions in the table 1 are the same in the table 2.
But if I try a khisquare test on those two matrix, R only takes the first one.

How can I compare those tables
Maybe with another test ?

Thanks in advance !

Kind regards

Lucie S.

	[[alternative HTML version deleted]]


From stadisin at Brocade.COM  Mon Jun 20 17:03:34 2016
From: stadisin at Brocade.COM (Shashank Tadisina)
Date: Mon, 20 Jun 2016 15:03:34 +0000
Subject: [R] R crashed on Mips64 on executing library for certain package
Message-ID: <7efd5778d50748d6a665d0b9d0deaaef@BRMWP-EXMB12.corp.brocade.com>

Hi All,

I was trying to get R cross-compiled for Mips64. The build system architecture I used is x86-64 while the system architecture to which R is cross-compiled to is Mips64
The below are the details of the mips64 system where I am running R

~ # uname -a
Linux (none) 2.6.32.27-Cavium-Octeon #3 SMP Tue Jun 14 11:06:49 PDT 2016 mips64 GNU/Linux

My requirement was to run few ARIMA models on the mips64 system. So, I decided to use the forecast package which had dependencies on several other packages. So, I cross-compiled all the required packages along with the R-base. But when I try to load "timeDate" package, R crashes. Below is the output. If you see below output, several other packages are getting successfully loaded. What I also found was timeDate package took long time to load and eventually crashed. So, I thought timeout could be an issue and tried to change timeout value using options(timeout = 300). Still R crashed and I am pretty sure timeout is not the issue as R crashed within a minute.
I am clueless as to how to debug this issue. Any insights would really help. Thanks in advance.
> library("Rcpp")
> library("RcppArmadillo")
> library("fracdiff")
> library("timeDate")
Creating a generic function for 'sample' from package 'base' in package 'timeDate'
Killed

Thanks
Shashank


	[[alternative HTML version deleted]]


From rxprtgama at gmail.com  Mon Jun 20 20:46:22 2016
From: rxprtgama at gmail.com (Joseph Gama)
Date: Mon, 20 Jun 2016 21:46:22 +0300
Subject: [R] No reply from CRAN Task View: Graphic Displays & Dynamic
 Graphics & Graphic Devices & Visualization
Message-ID: <CAEHfrcGHtBWw91F4Mqn2f8B38fG-Wj=3ddtdgBKPe00PnRiOvA@mail.gmail.com>

Hi all,

I emailed a suggestion to Nicholas Lewin-Koh, the maintainer of the CRAN
Task View: Graphic Displays & Dynamic Graphics & Graphic Devices &
Visualization. I got no reply, so I wonder, is he still maintaining that
view?
If not, then who else does or will maintain it?

BR,

Jos? Gama

	[[alternative HTML version deleted]]


From baccts at hotmail.com  Mon Jun 20 20:58:08 2016
From: baccts at hotmail.com (C Lin)
Date: Mon, 20 Jun 2016 18:58:08 +0000
Subject: [R] patterns in numeric vector
Message-ID: <CY1PR19MB01565074D971D77D7CCBEA96CB2A0@CY1PR19MB0156.namprd19.prod.outlook.com>

Hello,

Can?someone?help me with this?

I am trying to find the start and end positions in a vector where?numbers less than x is surrounded by number(s) greater than x.
 For example:
 try = c(7,223,42,55,30,25,61,5,70)
 x=40

 The desired output would be:

> loc
??? start end
1???? 5????? 6
2 ??? 8?????? 8

So the?numbers I am interested in finding is: 30, 25 and the start=?5 and end =?6
Also, 5?with the start=8 and end =?8
??
Thank you in advance for your help.


From dbmass18 at gmail.com  Mon Jun 20 21:35:57 2016
From: dbmass18 at gmail.com (Dielia Ba)
Date: Mon, 20 Jun 2016 12:35:57 -0700 (PDT)
Subject: [R] Generating input population for microsimulation
In-Reply-To: <1323817701.73589.YahooMailNeo@web125003.mail.ne1.yahoo.com>
References: <1323817701.73589.YahooMailNeo@web125003.mail.ne1.yahoo.com>
Message-ID: <7d222cea-cd71-435f-9594-a09f0646bb2e@googlegroups.com>

Hi everyone, 
I really need your help !! 
I am currently working on a micro-simulation project and I cannot find a 
package in R that does what I want. 
Here is the picture: I have macroeconomic variables such as 
income,consumption, household weight and I calculated the elasticities 
already. 
I also have two other data sets with income growth rates and population 
projection. What I want is to create a data set with an income variable for 
each year (from 2014 to 2030) and the same thing for consumption, based on 
the existing patterns in the input data sets. 
Do I really have to code my own R package to perform the micro- simulation 
? 
FYI: I tried almost all R packages related  to micro-simulation or 
simulation ( mostly spatial - demographic and health- survival designed 
tools) 
I would really appreciate any constructive comments and remarks.
Thanks a lot, 
Dielia 

Le mardi 13 d?cembre 2011 18:08:21 UTC-5, Emma Thomas a ?crit :
>
> Hi all,
>
> I've been struggling with some code and was wondering if you all could 
> help.
>
> I am trying to generate a theoretical population of P people who are 
> housed within X different units. Each unit follows the same structure- 10 
> people per unit, 8 of whom are junior and two of whom are senior. I'd like 
> to create a unit ID and a unique identifier for each person (person ID, 
> PID) in the population so that I have a matrix that looks like:
>
>      unit_id pid senior
>   [1,]      1   1      0
>   [2,]      1   2      0
>   [3,]      1   3      0
>   [4,]      1   4      0
>   [5,]      1   5      0
>   [6,]      1   6      0
>   [7,]      1   7      0
>   [8,]      1   8      0
>   [9,]      1   9      1
>   [10,]    1   10   1
> ...
>
> I came up with the following code, but am having some trouble getting it 
> to populate my matrix the way I'd like.
>
> world <- function(units, pop_size, unit_size){
>     pid <- rep(0,pop_size) #person ID
>     senior <- rep(0,pop_size) #senior in charge
>     unit_id <- rep(0,pop_size) #unit ID
>     
>         for (i in 1:pop_size){
>         for (f in 1:units)    {  
>         senior[i] = sample(c(1,1,0,0,0,0,0,0,0,0), 1, replace = FALSE)
>         pid[i] = sample(c(1:10), 1, replace = FALSE)
>         unit_id[i] <- f
>                 }}    
>     data <- cbind(unit_id, pid, senior)
>     
>     return(data)
>     }
>
>     world(units = 10,pop_size = 100, unit_size = 10) #call the function
>
> The output looks like:
>      unit_id pid senior
>   [1,]      10   7      0
>   [2,]      10   4      0
>   [3,]      10  10      0
>   [4,]      10   9      1
>   [5,]      10  10      0
>   [6,]      10   1      1
> ...
>
> but what I really want is to generate is 10 different units with two 
> seniors per unit, and with each person in the population having a unique 
> identifier.
>
> I thought a nested for loop was one way to go about creating my data set 
> of people and families, but obviously I'm doing something (or many things) 
> wrong. Any suggestions on how to fix this? I had been focusing on creating 
> a person and assigning them to a unit, but perhaps I should create the 
> units and then populate the units with people?
>
> Thanks so much in advance.
>
> Emma
>
> ______________________________________________
> R-h... at r-project.org <javascript:> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From Achim.Zeileis at uibk.ac.at  Mon Jun 20 21:53:33 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 20 Jun 2016 21:53:33 +0200 (CEST)
Subject: [R] No reply from CRAN Task View: Graphic Displays & Dynamic
 Graphics & Graphic Devices & Visualization
In-Reply-To: <CAEHfrcGHtBWw91F4Mqn2f8B38fG-Wj=3ddtdgBKPe00PnRiOvA@mail.gmail.com>
References: <CAEHfrcGHtBWw91F4Mqn2f8B38fG-Wj=3ddtdgBKPe00PnRiOvA@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1606202152310.32217@paninaro>

On Mon, 20 Jun 2016, Joseph Gama wrote:

> Hi all,
>
> I emailed a suggestion to Nicholas Lewin-Koh, the maintainer of the CRAN 
> Task View: Graphic Displays & Dynamic Graphics & Graphic Devices & 
> Visualization. I got no reply, so I wonder, is he still maintaining that 
> view? If not, then who else does or will maintain it?

To the best of my knowledge he is still maintaining it. I cc'ed Nicholas 
in this reply.

> BR,
>
> Jos? Gama
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jvadams at usgs.gov  Mon Jun 20 22:59:20 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 20 Jun 2016 15:59:20 -0500
Subject: [R] ASA Conference on Statistical Practice - deadline Thursday
Message-ID: <CAN5YmCFJi1JzWJ84S3GCFx9N84nrsqebgSXOnC0VMkDx0AVBOQ@mail.gmail.com>

R users,

Abstracts are now being accepted for the
     ASA Conference on Statistical Practice
     February 23-25, 2017
     Jacksonville FL, USA

Past conference attendees have shown particular interest in R,
reproducibility, and data visualization.

The deadline for submission is June 23.  Presentations will be 35 minutes
long and fall into four broad themes:
     Communication, Collaboration, and Career Development
     Data Modeling and Analysis
     Big Data and Data Science
     Software, Programming, and Graphics

Abstracts may be submitted at
     http://www.amstat.org/meetings/csp/2017/submitabstract.cfm

Thank you.

Jean V. Adams
on behalf of the ASA-CSP 2017 Steering Committee



`?.,,  ><(((?>   `?.,,  ><(((?>   `?.,,  ><(((?>

Jean V. Adams
Statistician
U.S. Geological Survey
Great Lakes Science Center
223 East Steinfest Road
Antigo, WI 54409  USA
http://www.glsc.usgs.gov
http://profile.usgs.gov/jvadams

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jun 20 23:40:46 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 20 Jun 2016 14:40:46 -0700
Subject: [R] patterns in numeric vector
In-Reply-To: <CAGxFJbSw73nG+C0avK=OKXkA4_eL3ma=LHgKQ-yoFAmkFwrd9w@mail.gmail.com>
References: <CY1PR19MB01565074D971D77D7CCBEA96CB2A0@CY1PR19MB0156.namprd19.prod.outlook.com>
	<CAGxFJbSw73nG+C0avK=OKXkA4_eL3ma=LHgKQ-yoFAmkFwrd9w@mail.gmail.com>
Message-ID: <CAGxFJbQ6mgRB2fEf47GCiYf9_5bcQrzHBw24+JzoihmSCmLpUg@mail.gmail.com>

Oops  -- neglected to cc the list. Also note the correction at the
end, changing "starts" to "begins".

-- Bert




On Mon, Jun 20, 2016 at 2:33 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
 Thanks for the reproducible example -- it made your meaning clear.

This is the sort of thing for which rle() is useful. If you go through
the following step by step it should be clear what's going on.

 z<-c(7,223,42,55,30,25,61,5,70)
x <- 40
rl <- rle( z < x)  ## runs of TRUE and FALSE (logicals)
## Note that you may wish to change this to <=

lens <- rl$lengths    ## lengths of runs
ends <- cumsum(lens)   ##  indices where the runs end
begins <- c(1,ends[-length(ends)]+1)  ## indices where the runs begin

## now use logical indexing to pick out only the runs meeting the
condition that  z < x
vals <- rl$values
begins[vals]
ends[vals]


Note: This is the sort of query for which someone cleverer than I may
have a simpler or more efficient solution. If so, please post it so I
and others can learn from it.

 Cheers,
 Bert



 Bert Gunter

 "The trouble with having an open mind is that people keep coming along
 and sticking things into it."
 -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

>
> On Mon, Jun 20, 2016 at 11:58 AM, C Lin <baccts at hotmail.com> wrote:
>> Hello,
>>
>> Can someone help me with this?
>>
>> I am trying to find the start and end positions in a vector where numbers less than x is surrounded by number(s) greater than x.
>>  For example:
>>  try = c(7,223,42,55,30,25,61,5,70)
>>  x=40
>>
>>  The desired output would be:
>>
>>> loc
>>     start end
>> 1     5      6
>> 2     8       8
>>
>> So the numbers I am interested in finding is: 30, 25 and the start= 5 and end = 6
>> Also, 5 with the start=8 and end = 8
>>
>> Thank you in advance for your help.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From loupiote93 at hotmail.fr  Tue Jun 21 01:18:33 2016
From: loupiote93 at hotmail.fr (Lucie Dupond)
Date: Mon, 20 Jun 2016 23:18:33 +0000
Subject: [R] R help contingency table
In-Reply-To: <1b85bc155e9f436dbf982a7339e141ef@exch-2p-mbx-t2.ads.tamu.edu>
References: <DB5PR03MB147949B7C7EF9A538867A0A7A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>,
	<1b85bc155e9f436dbf982a7339e141ef@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <DB5PR03MB1479E6C56809DFB12D091E90A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>

Thank you for your answer !

I'm sorry, i've made a mistake in the second matrix, they should have the same row/column labels, I just used another label vector by mistake.

My supervisor doesn't have a solution for this, and neither have every one I asked around me.

Thanks for your solution, but I'm afraid that I will loose the interaction between the variable "first color" and "second color" if I convert the matrix into a vector.


Thank you for your help



________________________________
De : David L Carlson <dcarlson at tamu.edu>
Envoy? : lundi 20 juin 2016 21:06
? : Lucie Dupond; r-help at r-project.org
Objet : RE: R help contingency table

You should consult with your adviser or someone at your institution who has more experience in statistical analysis than you do. You want to compare the matrices, but the row/column labels are different so you may be comparing completely different categories.

Technically, you need to convert the two matrices into a single matrix. You can do that by converting each into a vector with the c() function. BUT this will compare High with High, Medium with Low, and Low with Stick which seems inadvisable.

> rbind(c(transitions1), c(transitions2))
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
[1,]   51   12   37   17   21   15   27   13   60
[2,]   13    5   11    7   16    8    8   18   17
> chisq.test(rbind(c(transitions1), c(transitions2)))

        Pearson's Chi-squared test

data:  rbind(c(transitions1), c(transitions2))
X-squared = 22.411, df = 8, p-value = 0.004208

Warning message:
In chisq.test(rbind(c(transitions1), c(transitions2))) :
  Chi-squared approximation may be incorrect

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Lucie Dupond
Sent: Sunday, June 19, 2016 9:10 PM
To: r-help at r-project.org
Subject: [R] R help contingency table

Hello,
I'm sorry if my question is really basic, but I'm having some troubles with the statistics for my thesis, and especially the khi square test and contingency tables.

For what I understood, there are two "kinds" of khisquare test, that are quite similar :
- Homogeneity, when we have one variable and we want to compare it with a theorical distribution
- Independence test, when we have 2 variable and we want to see if they are linked

-- -

I'm working on color transitions, with 3 possible factors : ? High ? , ? Medium ? and ? Low ?
I want to know if an individual will go preferably from a color ? High ? to another color ? High ?, more than from a color ? High ? to a color ? Medium ? (for example)

I have this table :

trans1<-c(51,17,27,12,21,13,37,15,60)
transitions1<-matrix(trans1, nrow=3, ncol=3, byrow=T)
rownames(transitions1) <- c("High"," Medium", "Low")
colnames(transitions1) <- c("High"," Medium", "Low")

The first colomn is showing the first color, and the second is showing the second color of the transition

It looks like I'm in the case of an Independence test, in order to see if the variable "second color" is linked to the "first color".

So I'm making the test :

chisq.test(transitions1)


(If I understood well, the test on the matrix is the independence  test, and the test on the vector trans1 is the homogeneity test ?)

The result is significatif, it means that some transitions are prefered.

My problem is that I have other transition tables like this one (with other individuals or other conditions)
For example, I also have this one :


trans2<-c(13,7,8,5,16,18,11,8,17)
transitions2<-matrix(trans2, nrow=3, ncol=3, byrow=T)
rownames(transitions2) <- c("High","Low", "Stick")
colnames(transitions2) <- c("High","Low", "Stick")

I want to know if the "prefered" transitions in the table 1 are the same in the table 2.
But if I try a khisquare test on those two matrix, R only takes the first one.

How can I compare those tables
Maybe with another test ?

Thanks in advance !

Kind regards

Lucie S.

        [[alternative HTML version deleted]]


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Jun 21 02:02:41 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 21 Jun 2016 10:02:41 +1000
Subject: [R] R help contingency table
In-Reply-To: <DB5PR03MB147949B7C7EF9A538867A0A7A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>
References: <DB5PR03MB147949B7C7EF9A538867A0A7A12A0@DB5PR03MB1479.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fUpo2hbCLPNCCxmRrPivKF5GnS1MXrukOYvMZYLNjL0Fw@mail.gmail.com>

Hi Lucie,
You can visualize this using the sizetree function (plotrix). You
supply a data frame of the individual choice sequences.

# form a data frame of "random" choices
coltrans<-data.frame(choice1=sample(c("High","Medium","Low"),100,TRUE),
 choice2=sample(c("High","Medium","Low"),100,TRUE))
sizetree(coltrans,main="Random color choice transitions")
# test the two way table of transitions for independence
chisq.test(table(coltrans))
# now try a data frame of "habitual" choices
coltrans2<-data.frame(choice1=rep(c("High","Medium","Low"),c(33,33,34)),
 choice2=c(sample(c("High","Medium","Low"),33,TRUE,prob=c(0.6,0.2,0.2)),
 sample(c("High","Medium","Low"),33,TRUE,prob=c(0.2,0.6,0.2)),
 sample(c("High","Medium","Low"),34,TRUE,prob=c(0.2,0.2,0.6))))
sizetree(coltrans2,main="Habitual color choice transitions")
# test the table again
chisq.test(table(coltrans2))

This may be what you want.

Jim


On Mon, Jun 20, 2016 at 12:09 PM, Lucie Dupond <loupiote93 at hotmail.fr> wrote:
> Hello,
> I'm sorry if my question is really basic, but I'm having some troubles with the statistics for my thesis, and especially the khi square test and contingency tables.
>
> For what I understood, there are two "kinds" of khisquare test, that are quite similar :
> - Homogeneity, when we have one variable and we want to compare it with a theorical distribution
> - Independence test, when we have 2 variable and we want to see if they are linked
>
> -- -
>
> I'm working on color transitions, with 3 possible factors : ? High ? , ? Medium ? and ? Low ?
> I want to know if an individual will go preferably from a color ? High ? to another color ? High ?, more than from a color ? High ? to a color ? Medium ? (for example)
>
> I have this table :
>
> trans1<-c(51,17,27,12,21,13,37,15,60)
> transitions1<-matrix(trans1, nrow=3, ncol=3, byrow=T)
> rownames(transitions1) <- c("High"," Medium", "Low")
> colnames(transitions1) <- c("High"," Medium", "Low")
>
> The first colomn is showing the first color, and the second is showing the second color of the transition
>
> It looks like I'm in the case of an Independence test, in order to see if the variable "second color" is linked to the "first color".
>
> So I'm making the test :
>
> chisq.test(transitions1)
>
>
> (If I understood well, the test on the matrix is the independence  test, and the test on the vector trans1 is the homogeneity test ?)
>
> The result is significatif, it means that some transitions are prefered.
>
> My problem is that I have other transition tables like this one (with other individuals or other conditions)
> For example, I also have this one :
>
>
> trans2<-c(13,7,8,5,16,18,11,8,17)
> transitions2<-matrix(trans2, nrow=3, ncol=3, byrow=T)
> rownames(transitions2) <- c("High","Low", "Stick")
> colnames(transitions2) <- c("High","Low", "Stick")
>
> I want to know if the "prefered" transitions in the table 1 are the same in the table 2.
> But if I try a khisquare test on those two matrix, R only takes the first one.
>
> How can I compare those tables
> Maybe with another test ?
>
> Thanks in advance !
>
> Kind regards
>
> Lucie S.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Jun 21 02:10:10 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 21 Jun 2016 10:10:10 +1000
Subject: [R] replacement has 0 rows, data has 2809
In-Reply-To: <BLU436-SMTP262A16A315604AB8A7A212C02A0@phx.gbl>
References: <BLU437-SMTP40BAE9BD447582620D740EC0570@phx.gbl>
	<CA+8X3fW3YYnnr+aqAZZRcxrxUgMzh-Dq5wGg7tMFdMFbF4fLAQ@mail.gmail.com>
	<BLU436-SMTP262A16A315604AB8A7A212C02A0@phx.gbl>
Message-ID: <CA+8X3fUug1XQuAxeW2pZ=RY8OgY1-=MgHZR0DrAgEkqB7MhDtg@mail.gmail.com>

Hi Humberto,
It may simply be that the file is C(omma)SV format and the default
separator for read.delim is a TAB character. Try read.csv.

Jim


On Tue, Jun 21, 2016 at 2:14 AM, Humberto Munoz Barona
<hmunoz40 at hotmail.com> wrote:
> Hi Jim,
> Thanks for your reply. length(lens) gives me 6, which is the size of lens in the previous run with a shorter file. length(data1)=1, that means data1 is not reading the data from the file DarkAerobic1.CSV, which contains the four columns in this order Gene ID, Length, ReadCount, and Normalized Coverage. I want the vector lens = Length and cnts = ReadCounts. How I can make this import of data correctly?
>
>  > data1 <- read.delim("DarkAerobic1.CSV", check.names=FALSE, stringsAsFactors=FALSE)
>> lenght(data1)
> Error: could not find function "lenght"
>> length(data1)
> [1] 1
>
> I need to calculate two normalizations with the vectors lens and cnts, and have the two options for sorting the normalizations up or down.
>
> Thanks for any help you can give me to fix this issue.
>
> Humberto
>
>> On Jun 18, 2016, at 12:19 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Humberto,
>> The "0 row" error usually arises from a calculation in which a
>> non-existent object is used. I see that you have created a vector with
>> the name "lens" and that may be where this is happening. Have a look
>> at:
>>
>> length(lens)
>>
>> or if it is not too long, just:
>>
>> lens
>>
>> If it is zero length, that is your problem. This might be due to
>> "data1" not having a column named "Length" or it may not contain
>> numeric values (i.e. a factor)..
>>
>> Jim
>>
>>
>> On Sat, Jun 18, 2016 at 9:53 AM, Humberto Munoz Barona
>> <hmunoz40 at hotmail.com> wrote:
>>> I am running the following R-code
>>>
>>> countToTpm <- function(counts, effLen)
>>> {
>>>  rate <- log(counts) - log(effLen)
>>>  denom <- log(sum(exp(rate)))
>>>  exp(rate - denom + log(1e6))
>>> }
>>>
>>> countToFpkm <- function(counts, effLen)
>>> {
>>>  N <- sum(counts)
>>>  exp( log(counts) + log(1e9) - log(effLen) - log(N) )
>>> }
>>>
>>> fpkmToTpm <- function(fpkm)
>>> {
>>>  exp(log(fpkm) - log(sum(fpkm)) + log(1e6))
>>> }
>>>
>>> countToEffCounts <- function(counts, len, effLen)
>>> {
>>>  counts * (len / effLen)
>>> }
>>> ################################################################################
>>> # An example
>>> ################################################################################
>>> data1 <- read.delim("Dark Aerobic1.csv", check.names=FALSE, stringsAsFactors=FALSE)
>>> cnts <- data1['ReadCount']
>>> lens <- data1['Length']
>>> countDf <- data.frame(count = cnts, length = lens)
>>>
>>> # assume a mean(FLD) = 170.71
>>>
>>> countDf$effLength <- countDf$length - 170.71 + 1
>>> countDf$tpm <- with(countDf, countToTpm(count, effLength))
>>> countDf$fpkm <- with(countDf, countToFpkm(count, effLength))
>>> with(countDf, all.equal(tpm, fpkmToTpm(fpkm)))
>>> countDf$effCounts <- with(countDf, countToEffCounts(count, length, effLength))
>>>
>>> I am receiving the errors
>>>
>>>> countDf$effLength <- countDf$length - 170.71 + 1
>>> Error in `$<-.data.frame`(`*tmp*`, "effLength", value = numeric(0)) :
>>>  replacement has 0 rows, data has 2809
>>>> countDf$tpm <- with(countDf, countToTpm(count, effLength))
>>> Error in countToTpm(count, effLength) : object 'count' not found
>>>> countDf$fpkm <- with(countDf, countToFpkm(count, effLength))
>>> Error in countToFpkm(count, effLength) : object 'count' not found
>>>> with(countDf, all.equal(tpm, fpkmToTpm(fpkm)))
>>> Error in all.equal(tpm, fpkmToTpm(fpkm)) : object 'tpm' not found
>>>> countDf$effCounts <- with(countDf, countToEffCounts(count, length, effLength))
>>> Error in countToEffCounts(count, length, effLength) :
>>>  object 'count' not found
>>>>
>>>
>>> Thanks for any help to fix this error
>>>
>>> Humberto Munoz
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From paolo.letizia at gmail.com  Mon Jun 20 23:34:19 2016
From: paolo.letizia at gmail.com (Paolo Letizia)
Date: Mon, 20 Jun 2016 17:34:19 -0400
Subject: [R] Data aggregation
Message-ID: <CAOgs+Oy3RGqi9yFbaO=Be-ZU2=1jMCa=3sYQPWk37PwYnBFvHw@mail.gmail.com>

Dear All:
I have a data frame with 3 columns: "Regime", "Industry", and "Cost".
I want to sum the value of "Cost" for each industry and "Regime".
Example:

The data frame is:
Regime, Industry, Cost
10, 01, 370
11, 01, 400
10, 02, 200
10, 01, 500
11, 02, 60
10, 02, 30

I want the following output:
01, 10, 870
01, 11, 400
02, 10, 230
02, 11, 600

Can you please help me on this? Paolo

	[[alternative HTML version deleted]]


From Pradip.Muhuri at ahrq.hhs.gov  Tue Jun 21 01:49:55 2016
From: Pradip.Muhuri at ahrq.hhs.gov (Muhuri, Pradip (AHRQ/CFACT))
Date: Mon, 20 Jun 2016 23:49:55 +0000
Subject: [R] svykappa using the survey package
Message-ID: <BN1PR09MB03050FCD28F9620F5A3449BAD32A0@BN1PR09MB0305.namprd09.prod.outlook.com>

Hello,

My goal is to calculate the weighted kappa measure of agreement between two factors  using the R  survey package.  I am getting the following error message (the console is appended below; sorry no data provided).

> # calculate survey Kappa
> svykappa(~xbpchek53+xcholck53, design)
Error in names(probs) <- nms : 
  'names' attribute [15] must be the same length as the vector [8]

I have followed the following major steps:

1) Used the "haven" package to read the sas data set into R.
2) Used the dplyr mutate() to create 2 new variables and converted to factors [required for the svykappa()?].
3) Created an object (named design) using the survey design variables and the data file.
4) Used the svykappa() to compute the kappa measure of agreement. 

I will appreciate if someone could give me hints on how to resolve the issue.

Thanks,

Pradip Muhuri

###############  The detailed console is appended below  ####################

> setwd ("U:/A_PSAQ")
> library(haven)
> library(dplyr)
> library(survey)
> library(srvyr)
> library(Hmisc)
> my_hc2013_data <- read_sas("pc2013.sas7bdat")
> 
> # Function to convert var names in upper cases to var names in lower cases
> lower <- function (df) {
+   names(df) <- tolower(names(df))
+   df
+ }
> my_hc2013_data <- lower(my_hc2013_data)
> 
> # Check the contents - Hmisc package (as above) required
> # contents(my_hc2013_data)
> 
> # create two new variables
> my_hc2013_data <- mutate(my_hc2013_data, 
+                          xbpchek53 = ifelse(bpchek53 ==1, 1,
+                             ifelse(bpchek53 %in% 2:6, 2,NA)), 
+                          xcholck53 = ifelse(cholck53 ==1, 1,
+                            ifelse(cholck53 %in% 2:6, 2,NA)))
> 
> # convert the numeric variables to factors for the kappa measure
> my_hc2013_data$xbpchek53 <- as.factor(my_hc2013_data$xbpchek53)
> my_hc2013_data$xcholck53 <- as.factor(my_hc2013_data$xcholck53)
> 
> # check whether the variables are factors
> is.factor(my_hc2013_data$xbpchek53)
[1] TRUE
> is.factor(my_hc2013_data$xcholck53)
[1] TRUE
> 
> 
> # check the data from the cross table
> addmargins(with(my_hc2013_data, table(bpchek53,xbpchek53 )))
        xbpchek53
bpchek53     1     2   Sum
     -9      0     0     0
     -8      0     0     0
     -7      0     0     0
     -1      0     0     0
     1   19778     0 19778
     2       0  2652  2652
     3       0  1014  1014
     4       0   538   538
     5       0   737   737
     6       0   623   623
     Sum 19778  5564 25342
> addmargins(with(my_hc2013_data, table(cholck53,xcholck53 )))
        xcholck53
cholck53     1     2   Sum
     -9      0     0     0
     -8      0     0     0
     -7      0     0     0
     -1      0     0     0
     1   14850     0 14850
     2       0  3153  3153
     3       0  1170  1170
     4       0   696   696
     5       0   909   909
     6       0  3764  3764
     Sum 14850  9692 24542
> addmargins(with(my_hc2013_data, table(xbpchek53,xcholck53 )))
         xcholck53
xbpchek53     1     2   Sum
      1   14667  4379 19046
      2     163  5225  5388
      Sum 14830  9604 24434
> 
> # create an object with design variables and data
> design<-svydesign(id=~varpsu,strat=~varstr, weights=~perwt13f, data=my_hc2013_data, nest=TRUE)
> 
> # calculate survey Kappa
> svykappa(~xbpchek53+xcholck53, design)
Error in names(probs) <- nms : 
  'names' attribute [15] must be the same length as the vector [8]

#################################################################

Pradip K. Muhuri,  AHRQ/CFACT
 5600 Fishers Lane # 7N142A, Rockville, MD 20857
Tel: 301-427-1564




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip (AHRQ/CFACT)
Sent: Thursday, June 16, 2016 2:06 PM
To: David Winsemius
Cc: r-help at r-project.org
Subject: Re: [R] dplyr's arrange function - 3 solutions received - 1 New Question

Hello David,

Your revisions to the earlier code have given me desired results.

library("gtools")
mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), c("indicator", "prevalence_c")  ]

Thanks,

Pradip


Pradip K. Muhuri,  AHRQ/CFACT
 5600 Fishers Lane # 7N142A, Rockville, MD 20857
Tel: 301-427-1564





-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Thursday, June 16, 2016 12:54 PM
To: Muhuri, Pradip (AHRQ/CFACT)
Cc: r-help at r-project.org
Subject: Re: [R] dplyr's arrange function - 3 solutions received - 1 New Question


> On Jun 16, 2016, at 6:12 AM, Muhuri, Pradip (AHRQ/CFACT) <Pradip.Muhuri at ahrq.hhs.gov> wrote:
> 
> Hello,
> 
> I got 3 solutions to my earlier code.  Thanks to the contributors.  May I bring your attention to  a new question below (with respect to David's solution)?
> 
> 1) Thanks to Daniel Nordlund  for the tips - replacing leading space with a 0  in the data.
> 
> 2)  Thanks to David Winsemius for  his  solution with the gtools::mixedorder function.   I  have added an argument to his.
> 
> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE),  ]
> 
> 3)  Thanks to Jim Lemon's for his  solution. I  have prepended a minus sign to reverse the order.
> 
> numprev<-as.numeric(sapply(strsplit(trimws(mydata$prevalence_c)," 
> "),"[",1)) mydata[order(-numprev), ]
> 
> 
> (New)Question for solution 2:
> 
> I want to keep only 2 variables  (say, indicator and prevalence_c) in the output.  Where to insert the additional code? Why does the following code fail?
> 
>> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), 
>> c(mydata$indicator, mydata$prevalence_c) ]
> 


Try instead just a vector of names for the second argument to "["

 mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), 
         c("indicator", "prevalence_c") ]

> Error in `[.data.frame`(mydata, mixedorder(mydata$prevalence_c, decreasing = TRUE),  : 
>  undefined columns selected
> 
> ********************
>> str(mydata)
> Classes 'tbl_df', 'tbl' and 'data.frame':	10 obs. of  10 variables:
> $ indicator   : chr  "1. Health check-up" "2. Blood cholesterol checked " "3. Recieved flu vaccine" "4. Blood pressure checked" ...
> $ subgroup    : chr  "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""| __truncated__ ...
> $ n           : num  2117 2127 2124 2135 1027 ...
> $ prevalence_c: chr  "74.7 (1.20)" "90.3 (0.89)" "51.7 (1.35)" "93.2 (0.70)" ...
> $ prevalence_p: chr  "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" ...
> $ sensitivity : chr  "87.4 (1.10)" "99.2 (0.27)" "97.0 (0.62)" "99.0 (0.27)" ...
> $ specificity : chr  "68.3 (2.80)" "58.2 (3.72)" "93.5 (0.90)" "52.7 (3.90)" ...
> $ ppv         : chr  "90.4 (0.94)" "92.8 (0.85)" "93.7 (0.87)" "94.3 (0.63)" ...
> $ npv         : chr  "61.5 (3.00)" "92.8 (2.27)" "96.9 (0.63)" "87.5 (3.27)" ...
> $ kappa       : chr  "0.536 (0.029)" "0.676 (0.032)" "0.905 (0.011)" "0.626 (0.035)" ...
> 
> Pradip K. Muhuri,  AHRQ/CFACT
> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
> 
> 
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel 
> Nordlund
> Sent: Wednesday, June 15, 2016 6:37 PM
> To: r-help at r-project.org
> Subject: Re: [R] dplyr's arrange function
> 
> On 6/15/2016 2:08 PM, Muhuri, Pradip (AHRQ/CFACT) wrote:
>> Hello,
>> 
>> I am using the dplyr's arrange() function to sort  one of the  many data frames  on a character variable (named "prevalence").
>> 
>> Issue: I am not getting the desired output  (line 7 is the problem, which should be the very last line in the sorted data frame) because the sorted field is character, not numeric.
>> 
>> The reproducible example and the output are appended below.
>> 
>> Is there any work-around  to convert/treat  this character variable (named "prevalence" in the data frame below)  as numeric before using the arrange() function within the dplyr package?
>> 
>> Any hints will be appreciated.
>> 
>> Thanks,
>> 
>> Pradip Muhuri
>> 
>> # Reproducible Example
>> 
>> library("readr")
>> testdata <- read_csv(
>> "indicator,  prevalence
>> 1. Health check-up, 77.2 (1.19)
>> 2. Blood cholesterol checked,  84.5 (1.14) 3. Recieved flu vaccine,
>> 50.0 (1.33) 4. Blood pressure checked, 88.7 (0.88) 5. Aspirin 
>> use-problems, 11.7 (1.02) 6.Colonoscopy, 60.2 (1.41) 7. 
>> Sigmoidoscopy,
>> 6.1 (0.61) 8. Blood stool test, 14.6 (1.00) 9.Mammogram,  72.6 (1.82) 
>> 10. Pap Smear test, 73.3 (2.37)")
>> 
>> # Sort on the character variable in descending order 
>> arrange(testdata,
>> desc(prevalence))
>> 
>> # Results from Console
>> 
>>                      indicator  prevalence
>>                          (chr)       (chr)
>> 1     4. Blood pressure checked 88.7 (0.88)
>> 2  2. Blood cholesterol checked 84.5 (1.14)
>> 3            1. Health check-up 77.2 (1.19)
>> 4            10. Pap Smear test 73.3 (2.37)
>> 5                   9.Mammogram 72.6 (1.82)
>> 6                 6.Colonoscopy 60.2 (1.41)
>> 7              7. Sigmoidoscopy  6.1 (0.61)
>> 8       3. Recieved flu vaccine 50.0 (1.33)
>> 9           8. Blood stool test 14.6 (1.00)
>> 10      5. Aspirin use-problems 11.7 (1.02)
>> 
>> 
>> Pradip K. Muhuri,  AHRQ/CFACT
>> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
>> Tel: 301-427-1564
>> 
>> 
>> 
> 
> The problem is that you are sorting a character variable.
> 
>> testdata$prevalence
>  [1] "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" "11.7 (1.02)"
>  [6] "60.2 (1.41)" "6.1 (0.61)"  "14.6 (1.00)" "72.6 (1.82)" "73.3 (2.37)"
>> 
> 
> Notice that the 7th element is "6.1 (0.61)".  The first CHARACTER is a "6", so it is going to sort BEFORE the "50.0 (1.33)" (in descending order).  If you want the character value of line 7 to sort last, it would need to be "06.1 (0.61)" or " 6.1 (0.61)" (notice the leading space).
> 
> Hope this is helpful,
> 
> Dan
> 
> Daniel Nordlund
> Port Townsend, WA USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Jun 21 07:17:40 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 20 Jun 2016 22:17:40 -0700
Subject: [R] Data aggregation
In-Reply-To: <CAOgs+Oy3RGqi9yFbaO=Be-ZU2=1jMCa=3sYQPWk37PwYnBFvHw@mail.gmail.com>
References: <CAOgs+Oy3RGqi9yFbaO=Be-ZU2=1jMCa=3sYQPWk37PwYnBFvHw@mail.gmail.com>
Message-ID: <CAGxFJbTyv4YZHZLnoNCikoApWzn8GfcPx+10gh2f9oKL83DDHw@mail.gmail.com>

?tapply

You should have encountered this already in most basic R tutorials.
Have you gone through any? If not, you should. In particular,you need
to learn about R's basic data structures (e.g. data frames).

Alternatively, the dplyr package has many elegant tools for this sort
of thing. You might do well to learn it instead or in addition to the
*apply type operations of base R.

Finally, I should ask: is this homework? This list tries to implement
a no homework policy.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 20, 2016 at 2:34 PM, Paolo Letizia <paolo.letizia at gmail.com> wrote:
> Dear All:
> I have a data frame with 3 columns: "Regime", "Industry", and "Cost".
> I want to sum the value of "Cost" for each industry and "Regime".
> Example:
>
> The data frame is:
> Regime, Industry, Cost
> 10, 01, 370
> 11, 01, 400
> 10, 02, 200
> 10, 01, 500
> 11, 02, 60
> 10, 02, 30
>
> I want the following output:
> 01, 10, 870
> 01, 11, 400
> 02, 10, 230
> 02, 11, 600
>
> Can you please help me on this? Paolo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Tue Jun 21 07:32:54 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 21 Jun 2016 01:32:54 -0400
Subject: [R] svykappa using the survey package
In-Reply-To: <BN1PR09MB03050FCD28F9620F5A3449BAD32A0@BN1PR09MB0305.namprd09.prod.outlook.com>
References: <BN1PR09MB03050FCD28F9620F5A3449BAD32A0@BN1PR09MB0305.namprd09.prod.outlook.com>
Message-ID: <CAOwvMDxq8-E2+UZc2sQpv=PRa9ZuA6djqPOn=CrjnC2GGbWMew@mail.gmail.com>

hi pradip, this should give you what you want


    library(foreign)
    library(survey)

    tf <- tempfile()

    download.file( "
https://meps.ahrq.gov/mepsweb/data_files/pufs/h163ssp.zip" , tf , mode =
'wb' )

    z <- unzip( tf , exdir = tempdir() )

    x <- read.xport( z )

    names( x ) <- tolower( names( x ) )

    design <- svydesign(id=~varpsu,strat=~varstr, weights=~perwt13f,
data=x, nest=TRUE)

    # include missings as "No" values here
    design <-
        update(design,
            xbpchek53 = ifelse(bpchek53 ==1,'yes','no or missing'),
            xcholck53 = ifelse(cholck53 ==1, 'yes','no or missing')
        )

    # subset out records that were missing for either variable
    svykappa( ~ xbpchek53 + xcholck53 , subset(design, bpchek53 > 0 &
cholck53 > 0 ) )


















On Mon, Jun 20, 2016 at 7:49 PM, Muhuri, Pradip (AHRQ/CFACT) <
Pradip.Muhuri at ahrq.hhs.gov> wrote:

> Hello,
>
> My goal is to calculate the weighted kappa measure of agreement between
> two factors  using the R  survey package.  I am getting the following error
> message (the console is appended below; sorry no data provided).
>
> > # calculate survey Kappa
> > svykappa(~xbpchek53+xcholck53, design)
> Error in names(probs) <- nms :
>   'names' attribute [15] must be the same length as the vector [8]
>
> I have followed the following major steps:
>
> 1) Used the "haven" package to read the sas data set into R.
> 2) Used the dplyr mutate() to create 2 new variables and converted to
> factors [required for the svykappa()?].
> 3) Created an object (named design) using the survey design variables and
> the data file.
> 4) Used the svykappa() to compute the kappa measure of agreement.
>
> I will appreciate if someone could give me hints on how to resolve the
> issue.
>
> Thanks,
>
> Pradip Muhuri
>
> ###############  The detailed console is appended below
> ####################
>
> > setwd ("U:/A_PSAQ")
> > library(haven)
> > library(dplyr)
> > library(survey)
> > library(srvyr)
> > library(Hmisc)
> > my_hc2013_data <- read_sas("pc2013.sas7bdat")
> >
> > # Function to convert var names in upper cases to var names in lower
> cases
> > lower <- function (df) {
> +   names(df) <- tolower(names(df))
> +   df
> + }
> > my_hc2013_data <- lower(my_hc2013_data)
> >
> > # Check the contents - Hmisc package (as above) required
> > # contents(my_hc2013_data)
> >
> > # create two new variables
> > my_hc2013_data <- mutate(my_hc2013_data,
> +                          xbpchek53 = ifelse(bpchek53 ==1, 1,
> +                             ifelse(bpchek53 %in% 2:6, 2,NA)),
> +                          xcholck53 = ifelse(cholck53 ==1, 1,
> +                            ifelse(cholck53 %in% 2:6, 2,NA)))
> >
> > # convert the numeric variables to factors for the kappa measure
> > my_hc2013_data$xbpchek53 <- as.factor(my_hc2013_data$xbpchek53)
> > my_hc2013_data$xcholck53 <- as.factor(my_hc2013_data$xcholck53)
> >
> > # check whether the variables are factors
> > is.factor(my_hc2013_data$xbpchek53)
> [1] TRUE
> > is.factor(my_hc2013_data$xcholck53)
> [1] TRUE
> >
> >
> > # check the data from the cross table
> > addmargins(with(my_hc2013_data, table(bpchek53,xbpchek53 )))
>         xbpchek53
> bpchek53     1     2   Sum
>      -9      0     0     0
>      -8      0     0     0
>      -7      0     0     0
>      -1      0     0     0
>      1   19778     0 19778
>      2       0  2652  2652
>      3       0  1014  1014
>      4       0   538   538
>      5       0   737   737
>      6       0   623   623
>      Sum 19778  5564 25342
> > addmargins(with(my_hc2013_data, table(cholck53,xcholck53 )))
>         xcholck53
> cholck53     1     2   Sum
>      -9      0     0     0
>      -8      0     0     0
>      -7      0     0     0
>      -1      0     0     0
>      1   14850     0 14850
>      2       0  3153  3153
>      3       0  1170  1170
>      4       0   696   696
>      5       0   909   909
>      6       0  3764  3764
>      Sum 14850  9692 24542
> > addmargins(with(my_hc2013_data, table(xbpchek53,xcholck53 )))
>          xcholck53
> xbpchek53     1     2   Sum
>       1   14667  4379 19046
>       2     163  5225  5388
>       Sum 14830  9604 24434
> >
> > # create an object with design variables and data
> > design<-svydesign(id=~varpsu,strat=~varstr, weights=~perwt13f,
> data=my_hc2013_data, nest=TRUE)
> >
> > # calculate survey Kappa
> > svykappa(~xbpchek53+xcholck53, design)
> Error in names(probs) <- nms :
>   'names' attribute [15] must be the same length as the vector [8]
>
> #################################################################
>
> Pradip K. Muhuri,  AHRQ/CFACT
>  5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri,
> Pradip (AHRQ/CFACT)
> Sent: Thursday, June 16, 2016 2:06 PM
> To: David Winsemius
> Cc: r-help at r-project.org
> Subject: Re: [R] dplyr's arrange function - 3 solutions received - 1 New
> Question
>
> Hello David,
>
> Your revisions to the earlier code have given me desired results.
>
> library("gtools")
> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE), c("indicator",
> "prevalence_c")  ]
>
> Thanks,
>
> Pradip
>
>
> Pradip K. Muhuri,  AHRQ/CFACT
>  5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
>
>
>
>
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Thursday, June 16, 2016 12:54 PM
> To: Muhuri, Pradip (AHRQ/CFACT)
> Cc: r-help at r-project.org
> Subject: Re: [R] dplyr's arrange function - 3 solutions received - 1 New
> Question
>
>
> > On Jun 16, 2016, at 6:12 AM, Muhuri, Pradip (AHRQ/CFACT) <
> Pradip.Muhuri at ahrq.hhs.gov> wrote:
> >
> > Hello,
> >
> > I got 3 solutions to my earlier code.  Thanks to the contributors.  May
> I bring your attention to  a new question below (with respect to David's
> solution)?
> >
> > 1) Thanks to Daniel Nordlund  for the tips - replacing leading space
> with a 0  in the data.
> >
> > 2)  Thanks to David Winsemius for  his  solution with the
> gtools::mixedorder function.   I  have added an argument to his.
> >
> > mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE),  ]
> >
> > 3)  Thanks to Jim Lemon's for his  solution. I  have prepended a minus
> sign to reverse the order.
> >
> > numprev<-as.numeric(sapply(strsplit(trimws(mydata$prevalence_c),"
> > "),"[",1)) mydata[order(-numprev), ]
> >
> >
> > (New)Question for solution 2:
> >
> > I want to keep only 2 variables  (say, indicator and prevalence_c) in
> the output.  Where to insert the additional code? Why does the following
> code fail?
> >
> >> mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE),
> >> c(mydata$indicator, mydata$prevalence_c) ]
> >
>
>
> Try instead just a vector of names for the second argument to "["
>
>  mydata[ mixedorder(mydata$prevalence_c, decreasing=TRUE),
>          c("indicator", "prevalence_c") ]
>
> > Error in `[.data.frame`(mydata, mixedorder(mydata$prevalence_c,
> decreasing = TRUE),  :
> >  undefined columns selected
> >
> > ********************
> >> str(mydata)
> > Classes 'tbl_df', 'tbl' and 'data.frame':     10 obs. of  10 variables:
> > $ indicator   : chr  "1. Health check-up" "2. Blood cholesterol checked
> " "3. Recieved flu vaccine" "4. Blood pressure checked" ...
> > $ subgroup    : chr  "Both sexes, ages =35 yrs""| __truncated__ "Both
> sexes, ages =35 yrs""| __truncated__ "Both sexes, ages =35 yrs""|
> __truncated__ "Both sexes, ages =35 yrs""| __truncated__ ...
> > $ n           : num  2117 2127 2124 2135 1027 ...
> > $ prevalence_c: chr  "74.7 (1.20)" "90.3 (0.89)" "51.7 (1.35)" "93.2
> (0.70)" ...
> > $ prevalence_p: chr  "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7
> (0.88)" ...
> > $ sensitivity : chr  "87.4 (1.10)" "99.2 (0.27)" "97.0 (0.62)" "99.0
> (0.27)" ...
> > $ specificity : chr  "68.3 (2.80)" "58.2 (3.72)" "93.5 (0.90)" "52.7
> (3.90)" ...
> > $ ppv         : chr  "90.4 (0.94)" "92.8 (0.85)" "93.7 (0.87)" "94.3
> (0.63)" ...
> > $ npv         : chr  "61.5 (3.00)" "92.8 (2.27)" "96.9 (0.63)" "87.5
> (3.27)" ...
> > $ kappa       : chr  "0.536 (0.029)" "0.676 (0.032)" "0.905 (0.011)"
> "0.626 (0.035)" ...
> >
> > Pradip K. Muhuri,  AHRQ/CFACT
> > 5600 Fishers Lane # 7N142A, Rockville, MD 20857
> > Tel: 301-427-1564
> >
> >
> >
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel
> > Nordlund
> > Sent: Wednesday, June 15, 2016 6:37 PM
> > To: r-help at r-project.org
> > Subject: Re: [R] dplyr's arrange function
> >
> > On 6/15/2016 2:08 PM, Muhuri, Pradip (AHRQ/CFACT) wrote:
> >> Hello,
> >>
> >> I am using the dplyr's arrange() function to sort  one of the  many
> data frames  on a character variable (named "prevalence").
> >>
> >> Issue: I am not getting the desired output  (line 7 is the problem,
> which should be the very last line in the sorted data frame) because the
> sorted field is character, not numeric.
> >>
> >> The reproducible example and the output are appended below.
> >>
> >> Is there any work-around  to convert/treat  this character variable
> (named "prevalence" in the data frame below)  as numeric before using the
> arrange() function within the dplyr package?
> >>
> >> Any hints will be appreciated.
> >>
> >> Thanks,
> >>
> >> Pradip Muhuri
> >>
> >> # Reproducible Example
> >>
> >> library("readr")
> >> testdata <- read_csv(
> >> "indicator,  prevalence
> >> 1. Health check-up, 77.2 (1.19)
> >> 2. Blood cholesterol checked,  84.5 (1.14) 3. Recieved flu vaccine,
> >> 50.0 (1.33) 4. Blood pressure checked, 88.7 (0.88) 5. Aspirin
> >> use-problems, 11.7 (1.02) 6.Colonoscopy, 60.2 (1.41) 7.
> >> Sigmoidoscopy,
> >> 6.1 (0.61) 8. Blood stool test, 14.6 (1.00) 9.Mammogram,  72.6 (1.82)
> >> 10. Pap Smear test, 73.3 (2.37)")
> >>
> >> # Sort on the character variable in descending order
> >> arrange(testdata,
> >> desc(prevalence))
> >>
> >> # Results from Console
> >>
> >>                      indicator  prevalence
> >>                          (chr)       (chr)
> >> 1     4. Blood pressure checked 88.7 (0.88)
> >> 2  2. Blood cholesterol checked 84.5 (1.14)
> >> 3            1. Health check-up 77.2 (1.19)
> >> 4            10. Pap Smear test 73.3 (2.37)
> >> 5                   9.Mammogram 72.6 (1.82)
> >> 6                 6.Colonoscopy 60.2 (1.41)
> >> 7              7. Sigmoidoscopy  6.1 (0.61)
> >> 8       3. Recieved flu vaccine 50.0 (1.33)
> >> 9           8. Blood stool test 14.6 (1.00)
> >> 10      5. Aspirin use-problems 11.7 (1.02)
> >>
> >>
> >> Pradip K. Muhuri,  AHRQ/CFACT
> >> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
> >> Tel: 301-427-1564
> >>
> >>
> >>
> >
> > The problem is that you are sorting a character variable.
> >
> >> testdata$prevalence
> >  [1] "77.2 (1.19)" "84.5 (1.14)" "50.0 (1.33)" "88.7 (0.88)" "11.7
> (1.02)"
> >  [6] "60.2 (1.41)" "6.1 (0.61)"  "14.6 (1.00)" "72.6 (1.82)" "73.3
> (2.37)"
> >>
> >
> > Notice that the 7th element is "6.1 (0.61)".  The first CHARACTER is a
> "6", so it is going to sort BEFORE the "50.0 (1.33)" (in descending
> order).  If you want the character value of line 7 to sort last, it would
> need to be "06.1 (0.61)" or " 6.1 (0.61)" (notice the leading space).
> >
> > Hope this is helpful,
> >
> > Dan
> >
> > Daniel Nordlund
> > Port Townsend, WA USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Jun 21 09:39:50 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 21 Jun 2016 07:39:50 +0000
Subject: [R] Data aggregation
In-Reply-To: <CAGxFJbTyv4YZHZLnoNCikoApWzn8GfcPx+10gh2f9oKL83DDHw@mail.gmail.com>
References: <CAOgs+Oy3RGqi9yFbaO=Be-ZU2=1jMCa=3sYQPWk37PwYnBFvHw@mail.gmail.com>
	<CAGxFJbTyv4YZHZLnoNCikoApWzn8GfcPx+10gh2f9oKL83DDHw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5031939@SRVEXCHMBX.precheza.cz>

Hi

And if you are reading tapply help page, you can also notice

?aggregate

which maybe could suit better.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
> Gunter
> Sent: Tuesday, June 21, 2016 7:18 AM
> To: Paolo Letizia <paolo.letizia at gmail.com>
> Cc: R Help <r-help at r-project.org>
> Subject: Re: [R] Data aggregation
>
> ?tapply
>
> You should have encountered this already in most basic R tutorials.
> Have you gone through any? If not, you should. In particular,you need to
> learn about R's basic data structures (e.g. data frames).
>
> Alternatively, the dplyr package has many elegant tools for this sort of thing.
> You might do well to learn it instead or in addition to the *apply type
> operations of base R.
>
> Finally, I should ask: is this homework? This list tries to implement a no
> homework policy.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 20, 2016 at 2:34 PM, Paolo Letizia <paolo.letizia at gmail.com>
> wrote:
> > Dear All:
> > I have a data frame with 3 columns: "Regime", "Industry", and "Cost".
> > I want to sum the value of "Cost" for each industry and "Regime".
> > Example:
> >
> > The data frame is:
> > Regime, Industry, Cost
> > 10, 01, 370
> > 11, 01, 400
> > 10, 02, 200
> > 10, 01, 500
> > 11, 02, 60
> > 10, 02, 30
> >
> > I want the following output:
> > 01, 10, 870
> > 01, 11, 400
> > 02, 10, 230
> > 02, 11, 600
> >
> > Can you please help me on this? Paolo
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pd.mes at cbs.dk  Tue Jun 21 10:06:45 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Tue, 21 Jun 2016 08:06:45 +0000
Subject: [R]   R 3.3.1 is released
Message-ID: <D968F122-374F-42C9-ADAD-38EEE90FED56@cbs.dk>

The build system rolled up R-3.3.1.tar.gz (codename "Bug in Your Hair") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.3.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 1f3efdc0790126ceef40a14f8f70af83
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 2fa93210e18cc0e20b0636480ee283ff
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = f50a659738b73036e2f5635adbd229c5
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f80d02e7ba9729a927e1c9cf7b435b32
MD5 (VERSION-INFO.dcf) = 5b73f37889f8a3f1d2dd5cbc8d309b93
MD5 (R-3/R-3.3.1.tar.gz) = f50a659738b73036e2f5635adbd229c5


This is the relevant part of the NEWS file

CHANGES IN R 3.3.1:

  BUG FIXES:

    * R CMD INSTALL and hence install.packages() gave an internal error
      installing a package called description from a tarball on a
      case-insensitive file system.

    * match(x, t) (and hence x %in% t) failed when x was of length one,
      and either character and x and t only differed in their Encoding
      or when x and t where complex with NAs or NaNs.  (PR#16885.)

    * unloadNamespace(ns) also works again when ns is a 'namespace', as
      from getNamespace().

    * rgamma(1,Inf) or rgamma(1, 0,0) no longer give NaN but the
      correct limit.

    * length(baseenv()) is correct now.

    * pretty(d, ..) for date-time d rarely failed when "halfmonth" time
      steps were tried (PR#16923) and on 'inaccurate' platforms such as
      32-bit windows or a configuration with --disable-long-double; see
      comment #15 of PR#16761.

    * In text.default(x, y, labels), the rarely(?) used default for
      labels is now correct also for the case of a 2-column matrix x
      and missing y.

    * as.factor(c(a = 1L)) preserves names() again as in R < 3.1.0.

    * strtrim(""[0], 0[0]) now works.

    * Use of Ctrl-C to terminate a reverse incremental search started
      by Ctrl-R in the readline-based Unix terminal interface is now
      supported for readline >= 6.3 (Ctrl-G always worked).  (PR#16603)

    * diff(<difftime>) now keeps the "units" attribute, as subtraction
      already did, PR#16940.
_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ruipbarradas at sapo.pt  Tue Jun 21 10:49:37 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 21 Jun 2016 09:49:37 +0100
Subject: [R] Data aggregation
In-Reply-To: <CAOgs+Oy3RGqi9yFbaO=Be-ZU2=1jMCa=3sYQPWk37PwYnBFvHw@mail.gmail.com>
References: <CAOgs+Oy3RGqi9yFbaO=Be-ZU2=1jMCa=3sYQPWk37PwYnBFvHw@mail.gmail.com>
Message-ID: <20160621094937.Horde.Sz1McbL3wnVXaP_hZLgin2A@mail.sapo.pt>

Hello,

Try the following.

dat <- read.csv(text = "
Regime, Industry, Cost
10, 01, 370
11, 01, 400
10, 02, 200
10, 01, 500
11, 02, 60
10, 02, 30
")

dat

res <- aggregate(Cost ~ Industry + Regime, data = dat, sum)

res <- res[order(res$Industry), ]
res

And see the help page ?aggregate

Hope this helps,

Rui Barradas


Quoting Paolo Letizia <paolo.letizia at gmail.com>:

> Dear All:
> I have a data frame with 3 columns: "Regime", "Industry", and "Cost".
> I want to sum the value of "Cost" for each industry and "Regime".
> Example:
>
> The data frame is:
> Regime, Industry, Cost
> 10, 01, 370
> 11, 01, 400
> 10, 02, 200
> 10, 01, 500
> 11, 02, 60
> 10, 02, 30
>
> I want the following output:
> 01, 10, 870
> 01, 11, 400
> 02, 10, 230
> 02, 11, 600
>
> Can you please help me on this? Paolo
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Tue Jun 21 11:31:39 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 21 Jun 2016 11:31:39 +0200
Subject: [R] import of data set and warning from R CMD check
In-Reply-To: <57641B0C.6030705@ieu.uzh.ch>
References: <57641B0C.6030705@ieu.uzh.ch>
Message-ID: <CAJuCY5zi6-LwVZyr=Jt+aTGDXOWj1=Qzf9V0kP3d+fX+uwH4JQ@mail.gmail.com>

Dear Pascal,

You could try to use data(CO2, package = "datasets") instead of data(CO2)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-06-17 17:45 GMT+02:00 Pascal A. Niklaus <pascal.niklaus at ieu.uzh.ch>:

> Hi all,
>
> When checking an R package, I get:
>
> |Consider adding importFrom("datasets","CO2")
>
> (this data set is used in some example code)
>
> However, when I add the suggested 'importFrom' statement to NAMESPACE
> (using roxygen2), I get
> |
> |Error :object ?CO2? is not exported by 'namespace:datasets'|
> ||
> |I understand that datasets are not exported, and the comment printed by
> 'R CMD check' seems not to have any consequences, but it nevertheless
> seems inconsistent to me. But maybe I miss something here...
>
> Pascal
>
> |
>
> --
>
> Dr. Pascal A. Niklaus
> Department of Evolutionary Biology and Environmental Studies
> University of Zurich
> Winterthurerstrasse 190
> CH-8057 Zurich / Switzerland
>
>
> ||||
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Tue Jun 21 11:48:55 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Tue, 21 Jun 2016 09:48:55 +0000 (UTC)
Subject: [R] duplicate labels in Bar chart geom_text()
References: <283897313.11356528.1466502535072.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <283897313.11356528.1466502535072.JavaMail.yahoo@mail.yahoo.com>

Hi all,
how should I avoid duplicate labels in geom_text for bar chart? in the bar chart below I have name of one country repeated several times on my bars, I only want COUNTRY to be shown above each bar:

    ggplot(df,aes(factor(Variable1),y=Variable2,fill=Variable3))+geom_bar(stat='identity')+geom_text(paste0(df$COUNTRY),position=position_dodge(width=0.2))

Thanks for any help!
Elahe


From gianfranco.lovison at unipa.it  Tue Jun 21 12:23:55 2016
From: gianfranco.lovison at unipa.it (Gianfranco Lovison)
Date: Tue, 21 Jun 2016 12:23:55 +0200
Subject: [R] Effect size measures for GLM
Message-ID: <20160621122355.Horde.Jnth7jq6y-9QM9jvB5TE-w2@webmail.unipa.it>

Is there a library for (friendly) calculation of effect size measures for
Generalized Linear Models? I have found "compute.es", but it seems to be
suitable only for Linear Models. A library taking a glm object and computing
partial R^2-type statistics, appropriate for GLMs, would be enough, but I have
bee unable to find it!

Rhanks for your help.

Fianfranco Lovison
Professor of Statistics
Deoartment of Economic, Business and Statistical Sciences
University of Palermo
Italy


From attenka at utu.fi  Tue Jun 21 12:50:32 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Tue, 21 Jun 2016 13:50:32 +0300
Subject: [R] About the parameters of rotationMatrix
Message-ID: <57691BF8.3070309@utu.fi>

Hi,

Why does this not work? The values inside the rotationMatrix() doesn't 
seem to change:

library(rgl)

for(i in 1: 10)
{
     a2=i*0.1; b2=i*0.2; c2=i*0.3
     print(c(a2,b2,c2))
     UserMatrix = rotationMatrix(pi/4,a2,b2,c2)
     print(UserMatrix)
}

Yours,

Atte Tenkanen


From murdoch.duncan at gmail.com  Tue Jun 21 16:30:36 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 Jun 2016 10:30:36 -0400
Subject: [R] About the parameters of rotationMatrix
In-Reply-To: <57691BF8.3070309@utu.fi>
References: <57691BF8.3070309@utu.fi>
Message-ID: <acc24916-6d46-0720-8805-971244fb517e@gmail.com>

On 21/06/2016 6:50 AM, Atte Tenkanen wrote:
> Hi,
>
> Why does this not work? The values inside the rotationMatrix() doesn't
> seem to change:
>
> library(rgl)
>
> for(i in 1: 10)
> {
>       a2=i*0.1; b2=i*0.2; c2=i*0.3
>       print(c(a2,b2,c2))
>       UserMatrix = rotationMatrix(pi/4,a2,b2,c2)
>       print(UserMatrix)
> }
>

You are rotating by a constant amount about a sequence of parallel 
vectors.  Only the length of the vectors is changing.

If you want to see a change, you need to use a different rotation axis, 
or a different amount of rotation.

Duncan Murdoch


From jenny.vanderpluym at noaa.gov  Tue Jun 21 16:42:51 2016
From: jenny.vanderpluym at noaa.gov (Jenny Vander Pluym - NOAA Federal)
Date: Tue, 21 Jun 2016 10:42:51 -0400
Subject: [R]  check broken links in a column
Message-ID: <CAJbh8eut-zJscuzrc+fOwaR-0a=bDAV-tnfCs7fAX4M2GH+Cig@mail.gmail.com>

Hello all,

I am having trouble finding code that will check links in a table, not all
of the links on a specific web page.

I have csv files that include links to images which are stored on the web.
I have over 1,000 of them to check.

I see things for curl, but that appears to be specific to pulling
information from a website vs. just using a column of url in a table. I
would like the results in a readable table format that tells me which links
do not work. I do not want all of the images opened on my machine, just the
links checked.

Thank you so much for your time.

Jenny VP

-- 
Jenny Vander Pluym
NOAA's National Centers for Coastal Ocean Science
Research and Communications Specialist
101 Pivers Island Rd.
Beaufort, NC 28516-9722 cell: 252.728.8777
What is NCCOS up to? <http://coastalscience.noaa.gov/news/>

"The contents of this message are mine personally and do not necessarily
reflect any position of the Government or the National Oceanic and
Atmospheric Administration."

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Jun 21 16:58:42 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 21 Jun 2016 14:58:42 +0000
Subject: [R] check broken links in a column
In-Reply-To: <CAJbh8eut-zJscuzrc+fOwaR-0a=bDAV-tnfCs7fAX4M2GH+Cig@mail.gmail.com>
References: <CAJbh8eut-zJscuzrc+fOwaR-0a=bDAV-tnfCs7fAX4M2GH+Cig@mail.gmail.com>
Message-ID: <CAKVAULO4PKoAEEr6ZuhvdtuGHHNa0kJsB56Ff6fmkZUC=mn3ow@mail.gmail.com>

I don't know about R for this but how about wget:
http://www.createdbypete.com/articles/simple-way-to-find-broken-links-with-wget/

You could store the list of links in a file and additionally use the -i
flag.

HTH
Ulrik

On Tue, 21 Jun 2016 at 16:47 Jenny Vander Pluym - NOAA Federal <
jenny.vanderpluym at noaa.gov> wrote:

> Hello all,
>
> I am having trouble finding code that will check links in a table, not all
> of the links on a specific web page.
>
> I have csv files that include links to images which are stored on the web.
> I have over 1,000 of them to check.
>
> I see things for curl, but that appears to be specific to pulling
> information from a website vs. just using a column of url in a table. I
> would like the results in a readable table format that tells me which links
> do not work. I do not want all of the images opened on my machine, just the
> links checked.
>
> Thank you so much for your time.
>
> Jenny VP
>
> --
> Jenny Vander Pluym
> NOAA's National Centers for Coastal Ocean Science
> Research and Communications Specialist
> 101 Pivers Island Rd.
> Beaufort, NC 28516-9722 cell: 252.728.8777
> What is NCCOS up to? <http://coastalscience.noaa.gov/news/>
>
> "The contents of this message are mine personally and do not necessarily
> reflect any position of the Government or the National Oceanic and
> Atmospheric Administration."
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Jun 21 17:06:10 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 21 Jun 2016 11:06:10 -0400
Subject: [R] check broken links in a column
In-Reply-To: <CAJbh8eut-zJscuzrc+fOwaR-0a=bDAV-tnfCs7fAX4M2GH+Cig@mail.gmail.com>
References: <CAJbh8eut-zJscuzrc+fOwaR-0a=bDAV-tnfCs7fAX4M2GH+Cig@mail.gmail.com>
Message-ID: <c0e4c56d-a711-a97c-7b19-2e114fc99ccc@gmail.com>

On 21/06/2016 10:42 AM, Jenny Vander Pluym - NOAA Federal wrote:
> Hello all,
>
> I am having trouble finding code that will check links in a table, not all
> of the links on a specific web page.
>
> I have csv files that include links to images which are stored on the web.
> I have over 1,000 of them to check.
>
> I see things for curl, but that appears to be specific to pulling
> information from a website vs. just using a column of url in a table. I
> would like the results in a readable table format that tells me which links
> do not work. I do not want all of the images opened on my machine, just the
> links checked.
>
> Thank you so much for your time.
>
> Jenny VP
>
You could loop through the entries, and try to read from each. If the 
link doesn't exist, you'll get an error.  For example:


urls <- c("http://www.r-project.org", "http://foo.bar")

result <- rep(NA, length(urls))

for (i in seq_along(urls)) {

   if (inherits(try(readLines(urls[i], 1), silent = TRUE), "try-error"))

     result[i] <- FALSE

   else

     result[i] <- TRUE

}

You can put together something more sophisticated with tryCatch(), which 
would make it easier to catch the warning messages when the reads fail.


Duncan Murdoch


From ssefick at gmail.com  Tue Jun 21 17:15:40 2016
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 21 Jun 2016 10:15:40 -0500
Subject: [R] Rcpp on R 3.2.4 compile problem Linux
Message-ID: <CADKEMqgr7fRThuBeB+0ybv5UFOFsS0ZDHGBCeDY+Ui3pZ2ubJA@mail.gmail.com>

I am trying to install Rcpp to a local library on an HPC. I am having
problems. I can provide any relevant information. Thank you in advance for
the help.

install.packages("Rcpp", repos=*)
*=a couple of different repos; all give the same errors

Relevant Cutout of errors (note I have replaced my home directory with
"HOME"):
Warning in file.copy(file.path(R.home("doc"), "html", "R.css"), outman) :
  problem copying /tools/R-3.2.4/lib64/R/doc/html/R.css to
/HOME/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/html/R.css: No such file or
directory
** building package indices
** installing vignettes
** testing if installed package can be loaded
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object
'/HOME/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/Rcpp.so':
  /HOME/R/x86_64-pc-linux-gnu-library/3.2/Rcpp/libs/Rcpp.so: undefined
symbol: _ZSt24__throw_out_of_range_fmtPKcz
Error: loading failed
Execution halted
ERROR: loading failed


Session Info:
R version 3.2.4 (2016-03-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS release 6.6 (Final)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.2.4

kindest regards,

-- 
Stephen Sefick, PhD
**************************************************
Auburn University
Biological Sciences
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Jun 21 19:18:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Jun 2016 10:18:50 -0700 (PDT)
Subject: [R] Fwd: Matrix Constraints in R Optim
In-Reply-To: <CADya=_xfAD3wt2BXaD899FuJY2Vyo0u+7GdsF3O3+1JxUVbSHA@mail.gmail.com>
References: <CADya=_wMawuy4A8+58=vgAXn7F4eSZ1z2m00pCkfe-HVGt34ow@mail.gmail.com>
	<CADya=_ymi22=6Xj5BtVKf7jisUrjK_pogM6qx04NvL287cK3fA@mail.gmail.com>
	<A8E545C2-7085-4AEF-817C-CD0102FB30F6@dcn.davis.ca.us>
	<CADya=_xfAD3wt2BXaD899FuJY2Vyo0u+7GdsF3O3+1JxUVbSHA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1606210942310.21156@pedal.dcn.davis.ca.us>

The size of this request is a bit big for this list.

I think you need the constrOptim function to achieve this constraint. See 
reproducible example below (no contributed packages needed):

#-----

my.data.matrix.inj <- structure(c(284.6624, 284.6743, 284.6771, 284.6746, 
284.6664, 284.6516, 284.6283, 284.5931, 555.1354, 555.0648, 555.0361, 
2717.121, 2716.909, 2716.857, 3537.007, 3537.209, 454.2328, 454.2205, 
454.2086, 1297.769, 1297.827, 1386.995, 2040.08, 2040.237, 1074.394, 
1409.096, 1187.767, 1453.882, 1149.305, 1329.487, 1376.219, 1881.046, 
1538.514, 1002.312, 612.8742, 1373.664, 1424.084, 1352.598, 1479.259, 
767.9471, 1277.077, 1477.096, 1383.378, 1398.408, 1353.671, 882.6216, 
1399.007, 1159.061, 1507.469, 1089.506, 1642.942, 1799.764, 1873.927, 
2145.548, 2017.962, 1993.64, 2221.32, 2123.962, 2463.256, 2405.041, 
2404.414, 2438.734, 2638.787, 2616.91, 2346.845, 2852.143, 2942.838, 
3140.032, 762.2396, 1720.488, 1789.752, 371.4107, 1225.91, 1686.064, 
1652.747, 1724.248, 1655.486, 1552.557, 1870.383, 1807.614, 1498.599, 
1376.45, 1453.844, 1441.684, 1363.064, 1066.156, 1365.101, 1358.903, 
1288.348, 610.3185, 532.7502, 1573.272, 1768.713, 1781.086, 1747.261, 
1977.336, 1904.75, 1538.454, 1678.361, 1774.035, 1495.381, 1285.172, 
1511.251, 1627.114, 1626.432, 1579.333, 1574.744, 1435.232, 2135.695, 
2031.769, 2350.99, 2562.418, 2515.922, 2709.281, 1824.588, 1824.665, 
1824.682, 1824.666, 1824.613, 1824.519, 1824.37, 1824.144, 1367.973, 
1367.799, 1367.728, 626.0895, 626.0406, 626.0286, 299.3024, 299.3194, 
1420.26, 1420.222, 1420.185, 1626.06, 1626.133, 1181.016, 1067.529, 
1067.611, 1346.783, 1286.029, 1669.494, 1469.061, 1571.632, 1369.969, 
1342.855, 1635.875, 1769.014, 1876.71, 1794.846, 1658.31, 1526.607, 
1676.101, 1705.561, 1641.514, 1605.627, 1298.534, 1591.755, 1611.691, 
1571.183, 1584.321, 1572.948, 1532.965, 1524.934, 1534.853, 1538.834, 
1463.963, 1462.23, 1420.739, 1447.045, 1406.715, 1419.408, 1478.69, 
1273.244, 1262.34, 1165.642, 787.8699, 657.2443, 617.5942, 672.4419, 
562.5458, 600.0635, 553.3339, 581.2515, 686.7953, 448.5355, 1967.524, 
968.7045, 1253.422, 1417.029, 1348.352, 607.6661, 795.2877, 1122.037, 
951.7014, 1218.465, 1452.847, 1708.894, 1789.318, 1774.066, 1730.023, 
1792.384, 1647.639, 1532.214, 1398.604, 1456.599, 1405.635, 1341.6, 
1384.088, 1547.139, 1480.687, 1527.453, 1541.885, 1348.729, 1359.007, 
1093.668, 1078.121, 1202.416, 895.9857, 1175.532, 1010.464, 967.2054, 
851.1081, 740.4431, 930.6541, 1057.503, 1036.018, 1250.418, 1382.047, 
278.5883, 278.6001, 278.6027, 278.6003, 278.5922, 278.5778, 278.555, 
278.5205, 922.1713, 922.054, 922.0063, 967.21, 967.1343, 967.1157, 
774.6002, 774.6443, 772.0591, 772.0382, 772.018, 870.8308, 870.8698, 
904.8117, 825.425, 792.9547, 876.54, 882.7752, 681.8339, 775.945, 
1081.869, 928.0758, 921.4498, 1079.74, 795.1276, 810.2282, 835.9764, 
825.9167, 825.2587, 943.9789, 745.8108, 709.2183, 718.3409, 656.4478, 
553.8104, 682.1406, 863.1352, 837.0597, 850.8278, 789.4566, 827.334, 
813.5239, 723.0217, 808.3031, 871.0251, 1023.663, 1008.41, 1118.704, 
1113.178, 907.1134, 726.4997, 1064.354, 1208.275, 1269.964, 1226.312, 
834.8596, 952.5037, 1019.817, 922.9584, 886.3052, 898.9753, 868.3756, 
869.4521, 105.3649, 407.1053, 136.8827, 722.5133, 841.0006, 706.9567, 
542.9826, 198.147, 233.6965, 114.3593, 252.4854, 284.9101, 418.044, 
215.6109, 543.6895, 654.181, 927.2443, 896.0264, 822.9401, 878.3534, 
692.4314, 738.8477, 984.3605, 1069.655, 1022.925, 1002.807, 850.6902, 
991.8134, 1034.01, 1148.745, 1142.539, 1163.838, 1275.52, 1145.691, 
1460.11, 1377.891, 1306.395, 1304.617, 1278.456, 1378.95, 1374.073, 
1449.972, 1184.909, 270.0509, 270.0623, 270.0648, 270.0624, 270.0547, 
270.0407, 270.0186, 269.9851, 631.4337, 631.3534, 631.3207, 607.871, 
607.8235, 607.8118, 570.1067, 570.1392, 471.9973, 471.9845, 471.9722, 
374.8601, 374.8769, 482.6559, 509.4759, 259.6612, 601.047, 612.4909, 
599.3603, 368.4525, 541.0823, 637.376, 572.6561, 520.8604, 602.978, 
508.6731, 518.9494, 559.4774, 583.3226, 665.8262, 675.3377, 604.7722, 
619.4575, 567.0582, 700.1987, 680.9487, 720.6385, 697.012, 662.4166, 
683.2136, 659.8345, 667.4672, 707.6854, 743.7268, 858.9992, 832.3246, 
779.6216, 698.0973, 703.4314, 791.7886, 726.9083, 854.6981, 834.7772, 
832.3445, 812.7689, 727.6645, 652.1965, 826.9865, 849.4389, 811.6799, 
850.7483, 832.3735, 819.6655, 1042.436, 720.7501, 952.0648, 1195, 
848.0734, 976.9899, 1112.395, 1113.345, 1153.728, 805.5801, 646.0727, 
617.1312, 791.8318, 847.233, 683.816, 724.7269, 911.1725, 827.3728, 
995.0048, 800.6775, 879.0817, 972.6709, 799.3595, 1029.595, 1007.769, 
852.9899, 837.8101, 941.9149, 982.4396, 979.9702, 967.2394, 937.1133, 
960.9035, 908.2497, 996.8404, 1190.648, 1202.747, 1350.496, 1267.897, 
1132.526, 1055.183, 799.7894, 639.9702, 769.6429, 769.6754, 769.6827, 
769.676, 769.6537, 769.6139, 769.551, 769.4556, 499.9228, 499.8593, 
499.8334, 1051.619, 1051.537, 1051.517, 1017.837, 1017.895, 787.5231, 
787.5018, 787.4812, 127.3492, 127.3549, 240.9772, 248.1084, 400.2578, 
663.3332, 986.2067, 936.059, 1061.159, 849.0998, 884.3383, 1183.185, 
1208.31, 981.9471, 1076.72, 1124.325, 1008.958, 780.2723, 692.6738, 
1044.181, 804.3527, 664.2988, 713.3538, 768.6463, 791.4983, 1408.636, 
1460.505, 1331.472, 1436.979, 1223.143, 1192.528, 1165.123, 1187.325, 
889.4554, 1755.404, 1539.565, 1367.623, 1197.647, 1204.832, 1253.376, 
1064.125, 1221.669, 1063.684, 1029.96, 941.9225, 953.305, 1135.038, 
995.6816, 1202.049, 1179.09, 1238.77, 1252.872, 195.4976, 796.9503, 
1409.675, 2215.336, 1971.793, 1372.014, 1194.094, 990.832, 1240.13, 
1272.831, 1110.265, 1083.954, 1277.695, 1224.066, 1216.931, 1036.133, 
1275.89, 650.2736, 493.1569, 443.461, 457.3099, 492.6304, 514.841, 
490.7231, 505.4785, 567.1318, 544.3971, 547.5244, 528.4097, 662.0999, 
964.6831, 1006.148, 1102.357, 1207.62, 1272.277, 1173.155, 1125.227, 
1039.502, 1074.456, 1146.245, 1429.14, 1246.974, 1215.329)
, .Dim = c(114L, 5L)
, .Dimnames = list(NULL, c("I1", "I2", "I3", "I4", "I5")))

my.data.matrix.prod <- structure(c(2916.28, 1893.82, 1446.496, 1223.643, 
1093.515, 1027.691, 1025.575, 1069.484, 1350.653, 1383.106, 1404.12, 
3229.087, 3287.819, 3292.214, 3949.526, 3934.924, 1344.882, 1276.475, 
1281.724, 2080.675, 2170.162, 2204.06, 2733.114, 2709.72, 1906.547, 
2226.197, 2147.538, 2396.16, 2170.339, 2295.214, 2325.382, 2863.881, 
2633.29, 2191.615, 1823.576, 2462.448, 2472.716, 2426.248, 2558.359, 
1898.222, 2311.003, 2405.334, 2359.773, 2406.227, 2404.66, 2005.993, 
2470.426, 2262.771, 2564.288, 2187.93, 2672.702, 2817.843, 2886.186, 
3159.216, 3071.983, 3038.874, 3232.614, 3153.618, 3396.065, 3337.943, 
3314.298, 3228.766, 3312.479, 3214.223, 2943.438, 3374.134, 3471.613, 
3649.256, 1494.396, 2318.848, 2353.137, 1392.929, 2017.725, 2497.875, 
2650.34, 2772.884, 2503.756, 2341.685, 2665.939, 2603.909, 2361.046, 
2307.904, 2466.254, 2545.271, 2505.55, 2239.917, 2518.568, 2521.566, 
2398.009, 1700.699, 1570.964, 2475.785, 2666.551, 2696.887, 2733.822, 
2956.056, 2906.461, 2566.767, 2639.433, 2717.689, 2399.816, 2175.098, 
2405.237, 2461.575, 2513.077, 2476.729, 2467.291, 2303.615, 2898.341, 
2858.363, 3200.795, 3426.61, 3443.722, 3647.533, 195.3348, 176.5879, 
161.8616, 147.6775, 132.3667, 116.3203, 100.9762, 90.91395, 102.5056, 
111.2312, 119.294, 139.5639, 148.0501, 154.4379, 162.0608, 166.5477, 
150.7256, 143.1064, 137.4059, 131.9734, 127.8249, 129.6863, 136.1022, 
121.6995, 131.2575, 144.92, 150.0162, 140.1022, 146.21, 156.451, 158.8145, 
162.6809, 164.6031, 156.6059, 150.636, 155.6411, 158.7302, 166.222, 
171.0211, 162.1327, 161.2135, 156.3216, 162.0996, 166.6428, 175.9184, 
176.8375, 178.7133, 178.7524, 179.3178, 176.1973, 180.4867, 187.3193, 
199.2127, 209.983, 210.1795, 203.8254, 201.1218, 203.3554, 199.8475, 
209.8946, 215.1455, 215.6018, 213.2702, 199.2345, 185.3278, 197.2057, 
205.0727, 207.3002, 193.6611, 194.2139, 193.8643, 193.2228, 177.8776, 
191.4582, 231.8191, 227.0726, 224.6594, 229.7895, 230.8227, 234.7284, 
206.1662, 179.8467, 167.3609, 179.5722, 188.3897, 180.9705, 182.7036, 
202.3105, 200.8232, 203.9204, 189.2181, 192.9931, 204.6493, 199.082, 
215.5948, 223.7031, 213.8644, 202.6964, 208.5682, 216.1876, 217.9815, 
217.007, 217.463, 221.4278, 218.8876, 228.6546, 247.8913, 255.3423, 
274.8202, 276.3341, 269.6512, 262.6747, 239.2566, 213.2598, 196.0692, 
179.3542, 174.4489, 179.1992, 193.516, 219.7416, 261.9235, 307.7595, 
339.0413, 349.1725, 355.6877, 355.0119, 353.4153, 351.7466, 334.9937, 
315.7924, 338.9163, 353.4399, 367.3095, 370.7577, 368.3222, 338.1546, 
309.5753, 302.9909, 343.3383, 390.3582, 442.8708, 467.6517, 475.7294, 
463.2386, 475.4719, 512.9818, 525.4725, 546.562, 555.4177, 539.306, 
499.4974, 483.7216, 504.7977, 493.012, 470.5119, 433.9357, 442.8588, 
456.0057, 512.4643, 550.1924, 558.0298, 564.4106, 550.0839, 538.8026, 
530.6313, 523.3772, 495.919, 552.271, 570.1813, 559.772, 539.137, 531.285, 
511.5488, 489.0468, 483.7139, 434.6737, 391.9633, 353.6852, 341.9161, 
345.1014, 337.9316, 347.3225, 351.3463, 368.2297, 356.9464, 385.1567, 
367.8657, 433.608, 567.5147, 609.7797, 502.3615, 441.0474, 421.461, 
421.8376, 446.8344, 468.2683, 499.6648, 542.9484, 556.0471, 560.2142, 
552.7231, 561.0404, 498.0082, 435.9498, 406.5746, 388.8749, 379.8109, 
384.6039, 402.4961, 406.7456, 417.0511, 418.7817, 404.1004, 396.1866, 
381.1434, 398.5426, 424.4879, 419.1766, 448.4539, 459.9056, 450.9682, 
429.8293, 402.7214, 409.8873, 434.7366, 470.5877, 491.6042, 505.3956, 
2379.811, 1683.061, 1348.136, 1183.511, 1096.342, 1063.209, 1083.307, 
1137.872, 1698.039, 1777.531, 1824.798, 1990.391, 2049.531, 2094.436, 
1982.723, 1974.184, 1931.659, 1916.844, 1909.946, 1859.683, 1768.624, 
1733.896, 1644.874, 1566.683, 1802.985, 2026.399, 2002.01, 2095.246, 
2341.096, 2261.631, 2337.393, 2534.549, 2322.27, 2333.124, 2367.872, 
2336.886, 2235.952, 2284.032, 2240.623, 2144.319, 2069.301, 1946.398, 
1910.047, 2043.538, 2433.989, 2556.197, 2578.596, 2568.367, 2534.411, 
2478.992, 2395.445, 2468.419, 2459.169, 2850.418, 2889.555, 2898.655, 
2802.34, 2630.252, 2451.473, 2667.949, 2813.618, 2777.629, 2657.484, 
2226.911, 2225.193, 2366.028, 2296.084, 2321.493, 2335.952, 2351.763, 
2347.124, 1576.808, 1743.489, 1847.67, 2869.197, 3040.427, 2686.383, 
2409.108, 2028.894, 2091.013, 1932.818, 1923.021, 1920.55, 2171.707, 
2086.544, 2304.832, 2344.914, 2685.513, 2448.996, 2252.836, 2147.083, 
1971.758, 2033.175, 2196.932, 2353.921, 2357.346, 2326.293, 2178.859, 
2293.083, 2341.083, 2452.64, 2557.318, 2645.425, 2778.83, 2744.436, 
3066.146, 3070.198, 3004.751, 3008.488, 2991.268, 3074.413, 3159.114, 
3126.801, 2823.369)
, .Dim = c(114L, 4L)
, .Dimnames = list(NULL, c("Q1", "Q2", "Q3", "Q4")))

my.data.matrix.time <- structure(c(1, 1.944202, 3.803123, 6.203458, 
9.420446, 14.03878, 21.35927, 30.4375, 44.67685, 52.77593, 60.875, 
76.09375, 83.70312, 91.3125, 104.9416, 121.75, 136.9688, 144.5781, 
152.1875, 167.4062, 182.625, 213.0625, 243.5, 273.9375, 304.375, 334.8125, 
365.25, 395.6875, 426.125, 456.5625, 487, 517.4375, 547.875, 578.3125, 
608.75, 639.1875, 669.625, 700.0625, 730.5, 760.9375, 791.375, 821.8125, 
852.25, 882.6875, 913.125, 943.5625, 974, 1004.438, 1034.875, 1065.312, 
1095.75, 1126.188, 1156.625, 1187.062, 1217.5, 1247.938, 1278.375, 
1308.812, 1339.25, 1369.688, 1400.125, 1430.562, 1461, 1491.438, 1521.875, 
1552.312, 1582.75, 1613.188, 1643.625, 1674.062, 1704.5, 1734.938, 
1765.375, 1795.812, 1826.25, 1856.688, 1887.125, 1917.562, 1948, 1978.438, 
2008.875, 2039.312, 2069.75, 2100.188, 2130.625, 2161.062, 2191.5, 
2221.938, 2252.375, 2282.812, 2313.25, 2343.688, 2374.125, 2404.562, 2435, 
2465.438, 2495.875, 2526.312, 2556.75, 2587.188, 2617.625, 2648.062, 
2678.5, 2708.938, 2739.375, 2769.812, 2800.25, 2830.688, 2861.125, 
2891.562, 2922, 2952.438, 2982.875, 3013.312)
, .Dim = c(114L, 1L)
, .Dimnames = list( NULL, "time"))

my.data.var <- c( 10, 0.25, 0.25, 0.25, 0.25, 0.25
                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
                 )

my.data.qo <- c( 5990, 150, 199, 996 )   #Pre-Waterflood Production
my.data.timet0 <- 0 # starting condition for time

#FUNCTION
Qjk.Cal.func <- function( my.data.timet0
                         , my.data.qo
                         , my.data.matrix.time
                         , my.data.matrix.inj
                         , my.data.matrix.prod
                         , my.data.var
                         , my.data.var.mat
                         )
{

     qjk.cal.matrix <- matrix(
                             , nrow = nrow( my.data.matrix.prod )
                             , ncol = ncol( my.data.matrix.prod )
                             )

     count <- 1
     number <- 1
     # loop through all PROD wells columns
     for ( colnum in 1:ncol( my.data.matrix.prod ) ) {
          # "sum" is a very bad choice of variable name
          # as it is a commonly-used base function
         sum <- 0 # this initialization is redundant see below
         #loop through all the rows
         for( row in 1:nrow( my.data.matrix.prod ) ) {
             sum <- 0 # most frequent re-initialization
             deltaT <- 0
             expo <- 0

             #loop through all the injector columns to get the PRODUCT SUM
             for( column in 1:ncol( my.data.matrix.inj ) ) {
                 sum <- ( sum
                        +   my.data.matrix.inj[ row, column ]
                          * my.data.var.mat[ colnum, number+column ]
                        )
             }

             if ( count < 2 ) {
                 deltaT <- my.data.matrix.time[ row ]
             } else {
                 deltaT <- ( my.data.matrix.time[ row ]
                           - my.data.matrix.time[ row - 1 ]
                           )
             }

             expo <- exp( -deltaT / my.data.var.mat[ colnum, 1 ] )
             # change here too

             if ( count < 2 ) {
                  qjk.cal.matrix[ row, colnum ] <-
 			my.data.qo[ colnum ] * expo + ( 1 - expo ) * sum
             } else {
                 qjk.cal.matrix[ row, colnum ] <-
 			(   qjk.cal.matrix[ row - 1, colnum ] * expo
                         + ( 1 - expo ) * sum
                         )
             }
             count <- count + 1
         }

         count <- 1
     }

     # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
     qjk.cal.matrix
}

Error.func <- function( my.data.var ) {
     #First convert vector(my.data.var) to MATRIX
     # and send it to calculate new MATRIX
     my.data.var.mat <- matrix( my.data.var
                              , nrow = ncol( my.data.matrix.prod )
                              , ncol = ncol( my.data.matrix.inj ) + 1
                              , byrow = TRUE
                              )

     Calc.Qjk.Value <- Qjk.Cal.func( my.data.timet0
                                   , my.data.qo
                                   , my.data.matrix.time
                                   , my.data.matrix.inj
                                   , my.data.matrix.prod
                                   , my.data.var
                                   , my.data.var.mat
                                   )

     #FIND DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
     diff.values <- my.data.matrix.prod - Calc.Qjk.Value

     #sum of square root of the diff
     Error <- ( ( colSums( ( diff.values^2 )
                         , na.rm = FALSE
                         , dims = 1
                         )
                ) / nrow( my.data.matrix.inj )
              )^0.5
     #print(paste(Error))

     # total avg error
     Error_total <- sum( Error
                       , na.rm=FALSE
                       ) / ncol( my.data.matrix.prod )

     Error_total
}

n <- ncol( my.data.matrix.prod )
m <- ncol( my.data.matrix.inj )
k <- ( 1 + n ) * m
ciA <- numeric( k )
uiA <- array( 0, dim = c( m+1, n, k ) )
ia <- 0
#Aoff2 <- (m+1) * n
for ( i in seq.int( m ) ) {
     ia <- ia + 1L
     # sum of columns <= 1
     uiA[ i+1, , i ] <- -1
     ciA[ ia ] <- -1
}
for ( i in ( 1 + seq.int( m ) ) ) {
     for ( j in seq.int( n ) ) {
         ia <- ia + 1L
         # elements > 0
         uiA[ i, j, ia ] <- 1
         ciA[ ia ] <- 0
     }
}
uiA <- matrix( uiA, nrow = k, byrow = TRUE )

my.data.varA <- c( 10, 0.25, 0.25, 0.25, 0.25, 0.25
                  , 10, 0.25, 0.25, 0.25, 0.25, 0.25
                  , 10, 0.25, 0.25, 0.25, 0.25, 0.25
                  , 10, 0.24, 0.24, 0.24, 0.24, 0.24
                  )
# interior?
all( uiA %*% my.data.var1 - (ciA) > 0 )

sols <- constrOptim( my.data.varA
                    , Error.func
                    , NULL
                    , ui = uiA
                    , ci = ciA
                    , method = "SANN"
                    )
# meets constraint?
all( uiA %*% sols$par - (ciA) >= 0 )

sols
##########################

On Sun, 19 Jun 2016, Priyank Dwivedi wrote:

> All,
> Here are the dput files of the input data to the code.
>
> Thanks for any advice.
>
> I am adding the entire code below too just in case.
>
>
> file <- file.path("Learning R","CRM_R_Ver4.xlsx")
> file
> my.data <- readWorksheetFromFile(file,sheet=1,startRow=1)
> str(my.data)  # DATA FRAME
> my.data.matrix.inj <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
> my.data.matrix.inj
>
> dput(my.data.matrix.inj,"my.data.matrix.inj.txt")
>
>
> my.data.2 <- readWorksheetFromFile(file,sheet=2,startRow=1)
> str(my.data.2)  # DATA FRAME
> my.data.matrix.time <- as.matrix(my.data.2)  #convert DATA FRAME to MATRIX
> my.data.matrix.time
>
> dput(my.data.matrix.time,"my.data.matrix.time.txt")
>
> my.data <- readWorksheetFromFile(file,sheet=3,startRow=1)
> str(my.data)  # DATA FRAME
> my.data.matrix.prod <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
> my.data.matrix.prod
>
> dput(my.data.matrix.prod,"my.data.matrix.prod.txt")
>
> # my.data.var <- vector("numeric",length = 24)
> # my.data.var
>
> my.data.var <- c(10,0.25,0.25,0.25,0.25,0.25,
>                 10,0.25,0.25,0.25,0.25,0.25,
>                 10,0.25,0.25,0.25,0.25,0.25,
>                 10,0.25,0.25,0.25,0.25,0.25)
> my.data.var
>
> dput(my.data.var,"my.data.var.txt")
>
>
> my.data.qo <- c(5990,150,199,996)   #Pre-Waterflood Production
> my.data.timet0 <- 0 # starting condition for time
>
> #FUNCTION
> Qjk.Cal.func <- function(my.data.timet0,my.data.qo,my.data.matrix.time,
>                         my.data.matrix.inj,
> my.data.matrix.prod,my.data.var,my.data.var.mat)
> {
>
>  qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
> ncol=ncol(my.data.matrix.prod))
>
>  count <- 1
>  number <- 1
>  for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
> wells columns
>  {
>    sum <-0
>    for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
>    {
>      sum <-0
>      deltaT <-0
>      expo <-0
>
>
>        for(column in 1:ncol(my.data.matrix.inj)) #loop through all
> the injector columns to get the PRODUCT SUM
>         {
>            sum = sum +
> my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>         }
>
>      if(count<2)
>      {
>        deltaT<- my.data.matrix.time[row]
>      }
>      else
>      {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>
>
>      expo <- exp(-deltaT/my.data.var.mat[colnum,1])
> # change here too
>
>      if(count<2)
>      {
>        qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo + (1-expo)*sum
>      }
>      else
>      {
>        qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
> (1-expo)*sum
>      }
>      count <- count+1
>    }
>
>    count <-1
>  }
>
>  qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>
> }
>
>
> # ERROR FUNCTION - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
> MATRIX. Miminize the Error by changing my.data.var
>
> Error.func <- function(my.data.var)
> {
>  #First convert vector(my.data.var) to MATRIX aand send it to
> calculate new MATRIX
>  my.data.var.mat <- matrix(my.data.var,nrow =
> ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow =
> TRUE)
>
>  Calc.Qjk.Value <- Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>                                 my.data.matrix.inj,
> my.data.matrix.prod,my.data.var,my.data.var.mat)
>
>
>  diff.values <- my.data.matrix.prod-Calc.Qjk.Value    #FIND
> DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>
>
>  Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
> 1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>  print(paste(Error))
>
>  Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
> total avg error
>
>
>  Error_total
> }
>
> # OPTIMIZE
>
> sols<-optim(my.data.var,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1),
>      lower=c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))
>
> sols
>
> On 17 June 2016 at 16:55, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> Your code is corrupt because you failed to send your email in plain text
>> format.
>>
>> You also don't appear to have all data needed to reproduce the problem. Use
>> the dput function to generate R code form of a sample of your data.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On June 17, 2016 1:07:21 PM PDT, Priyank Dwivedi <dpriyank23 at gmail.com>
>> wrote:
>>>
>>> By mistake, I sent it earlier to the wrong address.
>>>
>>> ---------- Forwarded message ----------
>>> From: Priyank Dwivedi <dpriyank23 at gmail.com>
>>> Date: 17 June 2016 at 14:50
>>> Subject: Matrix Constraints in R Optim
>>> To: r-help-owner at r-project.org
>>>
>>>
>>> Hi,
>>>
>>> Below is the code snippet I wrote in R:
>>>
>>> The basic idea is to minimize error by optimizing set of values (in this
>>> scenario 12) in the form of a matrix. I defined the matrix elements as
>>> vector "*my.data.var" * and then stacked it into a matrix called
>>> "*my.data.var.mat"
>>> in the error function. *
>>>
>>> The only part that I can't figure out is "what if the column sum in
>>> the *my.data.var.mat
>>> needs to be <=1"; that's the constraint/s.. Where do I introduce it in the
>>> OPTIM solver or elsewhere?*
>>>
>>>
>>>
>>>
>>>
>>>
>>> *my.data.matrix.inj* <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
>>> my.data.matrix.inj
>>>
>>>
>>> *my.data.matrix.time* <- as.matrix(my.data.2)  #convert DATA FRAME to
>>> MATRIX
>>> my.data.matrix.time
>>>
>>>
>>> *my.data.matrix.prod* <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
>>> my.data.matrix.prod
>>>
>>>
>>> *my.data.var* <-
>>>
>>> c(2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01)
>>> my.data.var
>>>
>>> *my.data.qo* <- c(5990,150,199,996)   #Pre-Waterflood Production
>>>
>>> *my.data.timet0* <- 0 # starting condition for time
>>>
>>>
>>> *#FUNCTIONQjk.Cal.func* <-
>>>
>>> function(my.data.timet0,my.data.qo,my.data.matrix.time,
>>>                          my.data.matrix.inj,
>>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>> {
>>>
>>>   qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>>> ncol=ncol(my.data.matrix.prod))
>>>
>>>   count <- 1
>>>   number <- 1
>>>   for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
>>> wells columns
>>>   {
>>>     sum <-0
>>>     for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
>>>     {
>>>       sum <-0
>>>       deltaT <-0
>>>       expo <-0
>>>
>>>
>>>         for(column in 1:ncol(my.data.matrix.inj)) #loop through all the
>>> injector columns to get the PRODUCT SUM
>>>          {
>>>             sum = sum +
>>> my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>>>          }
>>>
>>>       if(count<2)
>>>       {
>>>         deltaT<- my.data.matrix.time[row]
>>>       }
>>>       else
>>>       {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>>>
>>>
>>>       expo <- exp(-deltaT/my.data.var.mat[colnum,1])                  #
>>> change here too
>>>
>>>       if(count<2)
>>>       {
>>>         qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo +
>>> (1-expo)*sum
>>>
>>>  }
>>>       else
>>>       {
>>>         qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
>>> (1-expo)*sum
>>>       }
>>>       count <- count+1
>>>     }
>>>
>>>     count <-1
>>>   }
>>>
>>>   qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>>>
>>> }
>>>
>>>
>>> *# ERROR FUNCTION* - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
>>> MATRIX. Miminize the Error by changing my.data.var
>>>
>>> *Error.func* <- function(my.data.var)
>>> {
>>>   #First convert vector(my.data.var) to MATRIX aand send it to calculate
>>> new MATRIX
>>>   *my.data.var.mat* <- matrix(my.data.var,nrow =
>>> ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow = TRUE)
>>>
>>> *  Calc.Qjk.Value* <-
>>> Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>>>                                  my.data.matrix.inj,
>>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>>
>>>
>>>   diff.values <-
>>> my.data.matrix.prod-Calc.Qjk.Value    #FIND DIFFERENCE
>>> BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>>>
>>>
>>>   Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>>> 1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>>>   print(paste(Error))
>>>
>>>   Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
>>> total
>>> avg error
>>>
>>>
>>>  * Error_total*
>>> }
>>>
>>> # OPTIMIZE
>>>
>>> *optim*(*my.data.var*
>>>
>>> ,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1))
>>>
>>>
>>
>
>
>
> -- 
> Best Regards,
> Priyank Dwivedi
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From chalabi.elahe at yahoo.de  Tue Jun 21 20:34:16 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Tue, 21 Jun 2016 18:34:16 +0000 (UTC)
Subject: [R] Y in Kohonen xyf function
In-Reply-To: <928929ff-a9e9-3c7e-a4c1-c424e8318ef9@pp.inet.fi>
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
	<1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
	<840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>
	<95758e53-dde9-4a86-95d8-e1538f337845@pp.inet.fi>
	<171290742.7409726.1466087416379.JavaMail.yahoo@mail.yahoo.com>
	<928929ff-a9e9-3c7e-a4c1-c424e8318ef9@pp.inet.fi>
Message-ID: <1853322541.12249612.1466534056769.JavaMail.yahoo@mail.yahoo.com>






On Friday, June 17, 2016 12:21 AM, K. Elo <maillists at pp.inet.fi> wrote:
Hi again!

According to '?xyf', the function is expecting following parameters:

(1) data = a matrix, with each row representing an object.

So, please ensure that your data is a matrix

(2) Y = property that is to be modelled. In case of classification, Y is 
a matrix of zeros, with exactly one '1' in each row indicating the 
class. For prediction of continuous properties, Y is a vector. A 
combination is possible, too, but one then should take care of 
appropriate scaling.

Once again, no data frame here, but a scaled vector or a matrix.

Your could try following steps (I assume 'df' to be you data frame):

--- snip ---
set.seed(7)
training <- sample(nrow(df), 120)
Xtraining <- scale(df[training,])
Xtest <- scale(df[-training,],
                center = attr(Xtraining, "scaled:center"),
                scale = attr(Xtraining, "scaled:scale"))

xyf.df <- xyf(Xtraining,
               factor(df.classes[training]),
               grid = somgrid(5, 5, "hexagonal"))

--- snip ---

Let us know - with output, please - what happens. The point is, if this 
works, then you could try in experimenting the parameter 
'factor(df.classes[training]'. It seems to, that also here you need a 
matrix or a list as a base, not a data frame.

This might also be of interest for your: 
https://www.jstatsoft.org/article/view/v021i05/v21i05.pdf

HTH,
Kimmo


16.06.2016, 17:30, chalabi.elahe at yahoo.de wrote:
> Hi Kimmo,
>
> Thanks for your reply, Here is a part of my df:
>
>
>      'data.frame':  562 obs. of 128 variables
>      $ TE         :int 37 37 35 34 37 37 35 33 32 ...
>      $ TR         :int 11 11 8 13 11 8 15 12 8 .....
>      $ BW         :int 150 191 128 145 200 191 ........
>      $speed       :int 4 4 3 3 2 1 4 1 2 3 ..........
> and I want to cluster my data based on speed, to see the coming costumer's protocols fall into which speed group and I think I need to bring this speed column in Y element of xyf
>
>
> On Thursday, June 16, 2016 2:29 PM, K. Elo <maillists at pp.inet.fi> wrote:
> Hi!
>
> Some sample data could help us to help you...
>
> But have you read '?xyf' in order to ensure that your 'Y' is what 'xyf'
> expects it to be?
>
> What kind of error messages do you get?
>
> Regards,
> Kimmo
>
> 16.06.2016, 15:13, ch.elahe via R-help wrote:
>> Is there any answer?
>>
>>
>> Hi all, I have a df and I want to use supervised Self Organizing Map
>> to do classification. I should use Kohonen library and xyf function
>> from it. As you know the xyf function looks like this and I have
>> problem defining my Y:
>>
>> xyf(data,Y,grid=somgrid(),rlen=100,alpha=c(0.05,0.01)) I want to do
>> classification based on a column which shows the speed that a
>> protocols is run, and this column is the following:
>>
>> $speed   :num 4 4 3 3 3 1 1 1 2 1 4 4 3 numbers from 1 to 4 show the
>> speed from very fast to very slow protocols. so the property I want
>> to be modeled is df$speed, but I don't know how should I bring it in
>> xyf function. Does anyone know how to do that? I also added my train
>> set ans test set:
>>
>> dt=sort(sample(nrow(df),nrow(df)*.7)) train=df[dt,]
>> Xtraining=scale(trian) Xtest=scale(-trian)
>> center=attr(Xtrianing,"scaled:center")
>> scale=attr(Xtraining,"scaled:scale")
>> xyf(Xtraining,........,grid=somgrid(10,10,"hexagonal"))
>>
>>
>> Thanks for any Help, Elahe
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Jun 21 23:02:55 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Jun 2016 14:02:55 -0700
Subject: [R] Fwd: Matrix Constraints in R Optim
In-Reply-To: <CADya=_yqzpQ0PVkLKXgz1L-sL5RzRbh=YvCaAPeSoH_r-W4GBg@mail.gmail.com>
References: <CADya=_wMawuy4A8+58=vgAXn7F4eSZ1z2m00pCkfe-HVGt34ow@mail.gmail.com>
	<CADya=_ymi22=6Xj5BtVKf7jisUrjK_pogM6qx04NvL287cK3fA@mail.gmail.com>
	<A8E545C2-7085-4AEF-817C-CD0102FB30F6@dcn.davis.ca.us>
	<CADya=_xfAD3wt2BXaD899FuJY2Vyo0u+7GdsF3O3+1JxUVbSHA@mail.gmail.com>
	<alpine.BSF.2.00.1606210942310.21156@pedal.dcn.davis.ca.us>
	<CADya=_yqzpQ0PVkLKXgz1L-sL5RzRbh=YvCaAPeSoH_r-W4GBg@mail.gmail.com>
Message-ID: <072A5DB6-4CA1-48E4-A076-C54F20A5E875@dcn.davis.ca.us>

Not my problem. You are the one applying constraints. 
-- 
Sent from my phone. Please excuse my brevity.

On June 21, 2016 1:13:35 PM PDT, Priyank Dwivedi <dpriyank23 at gmail.com> wrote:
>Thank you Jeff.
>It seems to definitely solve it but the "total_error" is very high.
>Around 399.
>I also tried with the method = "L-BFGS-B". Still the error is around
>399.
>How can we reduce it?
>
>Priyank
>
>On 21 June 2016 at 12:18, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> The size of this request is a bit big for this list.
>>
>> I think you need the constrOptim function to achieve this constraint.
>See
>> reproducible example below (no contributed packages needed):
>>
>> #-----
>>
>> my.data.matrix.inj <- structure(c(284.6624, 284.6743, 284.6771,
>284.6746,
>> 284.6664, 284.6516, 284.6283, 284.5931, 555.1354, 555.0648, 555.0361,
>> 2717.121, 2716.909, 2716.857, 3537.007, 3537.209, 454.2328, 454.2205,
>> 454.2086, 1297.769, 1297.827, 1386.995, 2040.08, 2040.237, 1074.394,
>> 1409.096, 1187.767, 1453.882, 1149.305, 1329.487, 1376.219, 1881.046,
>> 1538.514, 1002.312, 612.8742, 1373.664, 1424.084, 1352.598, 1479.259,
>> 767.9471, 1277.077, 1477.096, 1383.378, 1398.408, 1353.671, 882.6216,
>> 1399.007, 1159.061, 1507.469, 1089.506, 1642.942, 1799.764, 1873.927,
>> 2145.548, 2017.962, 1993.64, 2221.32, 2123.962, 2463.256, 2405.041,
>> 2404.414, 2438.734, 2638.787, 2616.91, 2346.845, 2852.143, 2942.838,
>> 3140.032, 762.2396, 1720.488, 1789.752, 371.4107, 1225.91, 1686.064,
>> 1652.747, 1724.248, 1655.486, 1552.557, 1870.383, 1807.614, 1498.599,
>> 1376.45, 1453.844, 1441.684, 1363.064, 1066.156, 1365.101, 1358.903,
>> 1288.348, 610.3185, 532.7502, 1573.272, 1768.713, 1781.086, 1747.261,
>> 1977.336, 1904.75, 1538.454, 1678.361, 1774.035, 1495.381, 1285.172,
>> 1511.251, 1627.114, 1626.432, 1579.333, 1574.744, 1435.232, 2135.695,
>> 2031.769, 2350.99, 2562.418, 2515.922, 2709.281, 1824.588, 1824.665,
>> 1824.682, 1824.666, 1824.613, 1824.519, 1824.37, 1824.144, 1367.973,
>> 1367.799, 1367.728, 626.0895, 626.0406, 626.0286, 299.3024, 299.3194,
>> 1420.26, 1420.222, 1420.185, 1626.06, 1626.133, 1181.016, 1067.529,
>> 1067.611, 1346.783, 1286.029, 1669.494, 1469.061, 1571.632, 1369.969,
>> 1342.855, 1635.875, 1769.014, 1876.71, 1794.846, 1658.31, 1526.607,
>> 1676.101, 1705.561, 1641.514, 1605.627, 1298.534, 1591.755, 1611.691,
>> 1571.183, 1584.321, 1572.948, 1532.965, 1524.934, 1534.853, 1538.834,
>> 1463.963, 1462.23, 1420.739, 1447.045, 1406.715, 1419.408, 1478.69,
>> 1273.244, 1262.34, 1165.642, 787.8699, 657.2443, 617.5942, 672.4419,
>> 562.5458, 600.0635, 553.3339, 581.2515, 686.7953, 448.5355, 1967.524,
>> 968.7045, 1253.422, 1417.029, 1348.352, 607.6661, 795.2877, 1122.037,
>> 951.7014, 1218.465, 1452.847, 1708.894, 1789.318, 1774.066, 1730.023,
>> 1792.384, 1647.639, 1532.214, 1398.604, 1456.599, 1405.635, 1341.6,
>> 1384.088, 1547.139, 1480.687, 1527.453, 1541.885, 1348.729, 1359.007,
>> 1093.668, 1078.121, 1202.416, 895.9857, 1175.532, 1010.464, 967.2054,
>> 851.1081, 740.4431, 930.6541, 1057.503, 1036.018, 1250.418, 1382.047,
>> 278.5883, 278.6001, 278.6027, 278.6003, 278.5922, 278.5778, 278.555,
>> 278.5205, 922.1713, 922.054, 922.0063, 967.21, 967.1343, 967.1157,
>774.6002,
>> 774.6443, 772.0591, 772.0382, 772.018, 870.8308, 870.8698, 904.8117,
>> 825.425, 792.9547, 876.54, 882.7752, 681.8339, 775.945, 1081.869,
>928.0758,
>> 921.4498, 1079.74, 795.1276, 810.2282, 835.9764, 825.9167, 825.2587,
>> 943.9789, 745.8108, 709.2183, 718.3409, 656.4478, 553.8104, 682.1406,
>> 863.1352, 837.0597, 850.8278, 789.4566, 827.334, 813.5239, 723.0217,
>> 808.3031, 871.0251, 1023.663, 1008.41, 1118.704, 1113.178, 907.1134,
>> 726.4997, 1064.354, 1208.275, 1269.964, 1226.312, 834.8596, 952.5037,
>> 1019.817, 922.9584, 886.3052, 898.9753, 868.3756, 869.4521, 105.3649,
>> 407.1053, 136.8827, 722.5133, 841.0006, 706.9567, 542.9826, 198.147,
>> 233.6965, 114.3593, 252.4854, 284.9101, 418.044, 215.6109, 543.6895,
>> 654.181, 927.2443, 896.0264, 822.9401, 878.3534, 692.4314, 738.8477,
>> 984.3605, 1069.655, 1022.925, 1002.807, 850.6902, 991.8134, 1034.01,
>> 1148.745, 1142.539, 1163.838, 1275.52, 1145.691, 1460.11, 1377.891,
>> 1306.395, 1304.617, 1278.456, 1378.95, 1374.073, 1449.972, 1184.909,
>> 270.0509, 270.0623, 270.0648, 270.0624, 270.0547, 270.0407, 270.0186,
>> 269.9851, 631.4337, 631.3534, 631.3207, 607.871, 607.8235, 607.8118,
>> 570.1067, 570.1392, 471.9973, 471.9845, 471.9722, 374.8601, 374.8769,
>> 482.6559, 509.4759, 259.6612, 601.047, 612.4909, 599.3603, 368.4525,
>> 541.0823, 637.376, 572.6561, 520.8604, 602.978, 508.6731, 518.9494,
>> 559.4774, 583.3226, 665.8262, 675.3377, 604.7722, 619.4575, 567.0582,
>> 700.1987, 680.9487, 720.6385, 697.012, 662.4166, 683.2136, 659.8345,
>> 667.4672, 707.6854, 743.7268, 858.9992, 832.3246, 779.6216, 698.0973,
>> 703.4314, 791.7886, 726.9083, 854.6981, 834.7772, 832.3445, 812.7689,
>> 727.6645, 652.1965, 826.9865, 849.4389, 811.6799, 850.7483, 832.3735,
>> 819.6655, 1042.436, 720.7501, 952.0648, 1195, 848.0734, 976.9899,
>1112.395,
>> 1113.345, 1153.728, 805.5801, 646.0727, 617.1312, 791.8318, 847.233,
>> 683.816, 724.7269, 911.1725, 827.3728, 995.0048, 800.6775, 879.0817,
>> 972.6709, 799.3595, 1029.595, 1007.769, 852.9899, 837.8101, 941.9149,
>> 982.4396, 979.9702, 967.2394, 937.1133, 960.9035, 908.2497, 996.8404,
>> 1190.648, 1202.747, 1350.496, 1267.897, 1132.526, 1055.183, 799.7894,
>> 639.9702, 769.6429, 769.6754, 769.6827, 769.676, 769.6537, 769.6139,
>> 769.551, 769.4556, 499.9228, 499.8593, 499.8334, 1051.619, 1051.537,
>> 1051.517, 1017.837, 1017.895, 787.5231, 787.5018, 787.4812, 127.3492,
>> 127.3549, 240.9772, 248.1084, 400.2578, 663.3332, 986.2067, 936.059,
>> 1061.159, 849.0998, 884.3383, 1183.185, 1208.31, 981.9471, 1076.72,
>> 1124.325, 1008.958, 780.2723, 692.6738, 1044.181, 804.3527, 664.2988,
>> 713.3538, 768.6463, 791.4983, 1408.636, 1460.505, 1331.472, 1436.979,
>> 1223.143, 1192.528, 1165.123, 1187.325, 889.4554, 1755.404, 1539.565,
>> 1367.623, 1197.647, 1204.832, 1253.376, 1064.125, 1221.669, 1063.684,
>> 1029.96, 941.9225, 953.305, 1135.038, 995.6816, 1202.049, 1179.09,
>1238.77,
>> 1252.872, 195.4976, 796.9503, 1409.675, 2215.336, 1971.793, 1372.014,
>> 1194.094, 990.832, 1240.13, 1272.831, 1110.265, 1083.954, 1277.695,
>> 1224.066, 1216.931, 1036.133, 1275.89, 650.2736, 493.1569, 443.461,
>> 457.3099, 492.6304, 514.841, 490.7231, 505.4785, 567.1318, 544.3971,
>> 547.5244, 528.4097, 662.0999, 964.6831, 1006.148, 1102.357, 1207.62,
>> 1272.277, 1173.155, 1125.227, 1039.502, 1074.456, 1146.245, 1429.14,
>> 1246.974, 1215.329)
>> , .Dim = c(114L, 5L)
>> , .Dimnames = list(NULL, c("I1", "I2", "I3", "I4", "I5")))
>>
>> my.data.matrix.prod <- structure(c(2916.28, 1893.82, 1446.496,
>1223.643,
>> 1093.515, 1027.691, 1025.575, 1069.484, 1350.653, 1383.106, 1404.12,
>> 3229.087, 3287.819, 3292.214, 3949.526, 3934.924, 1344.882, 1276.475,
>> 1281.724, 2080.675, 2170.162, 2204.06, 2733.114, 2709.72, 1906.547,
>> 2226.197, 2147.538, 2396.16, 2170.339, 2295.214, 2325.382, 2863.881,
>> 2633.29, 2191.615, 1823.576, 2462.448, 2472.716, 2426.248, 2558.359,
>> 1898.222, 2311.003, 2405.334, 2359.773, 2406.227, 2404.66, 2005.993,
>> 2470.426, 2262.771, 2564.288, 2187.93, 2672.702, 2817.843, 2886.186,
>> 3159.216, 3071.983, 3038.874, 3232.614, 3153.618, 3396.065, 3337.943,
>> 3314.298, 3228.766, 3312.479, 3214.223, 2943.438, 3374.134, 3471.613,
>> 3649.256, 1494.396, 2318.848, 2353.137, 1392.929, 2017.725, 2497.875,
>> 2650.34, 2772.884, 2503.756, 2341.685, 2665.939, 2603.909, 2361.046,
>> 2307.904, 2466.254, 2545.271, 2505.55, 2239.917, 2518.568, 2521.566,
>> 2398.009, 1700.699, 1570.964, 2475.785, 2666.551, 2696.887, 2733.822,
>> 2956.056, 2906.461, 2566.767, 2639.433, 2717.689, 2399.816, 2175.098,
>> 2405.237, 2461.575, 2513.077, 2476.729, 2467.291, 2303.615, 2898.341,
>> 2858.363, 3200.795, 3426.61, 3443.722, 3647.533, 195.3348, 176.5879,
>> 161.8616, 147.6775, 132.3667, 116.3203, 100.9762, 90.91395, 102.5056,
>> 111.2312, 119.294, 139.5639, 148.0501, 154.4379, 162.0608, 166.5477,
>> 150.7256, 143.1064, 137.4059, 131.9734, 127.8249, 129.6863, 136.1022,
>> 121.6995, 131.2575, 144.92, 150.0162, 140.1022, 146.21, 156.451,
>158.8145,
>> 162.6809, 164.6031, 156.6059, 150.636, 155.6411, 158.7302, 166.222,
>> 171.0211, 162.1327, 161.2135, 156.3216, 162.0996, 166.6428, 175.9184,
>> 176.8375, 178.7133, 178.7524, 179.3178, 176.1973, 180.4867, 187.3193,
>> 199.2127, 209.983, 210.1795, 203.8254, 201.1218, 203.3554, 199.8475,
>> 209.8946, 215.1455, 215.6018, 213.2702, 199.2345, 185.3278, 197.2057,
>> 205.0727, 207.3002, 193.6611, 194.2139, 193.8643, 193.2228, 177.8776,
>> 191.4582, 231.8191, 227.0726, 224.6594, 229.7895, 230.8227, 234.7284,
>> 206.1662, 179.8467, 167.3609, 179.5722, 188.3897, 180.9705, 182.7036,
>> 202.3105, 200.8232, 203.9204, 189.2181, 192.9931, 204.6493, 199.082,
>> 215.5948, 223.7031, 213.8644, 202.6964, 208.5682, 216.1876, 217.9815,
>> 217.007, 217.463, 221.4278, 218.8876, 228.6546, 247.8913, 255.3423,
>> 274.8202, 276.3341, 269.6512, 262.6747, 239.2566, 213.2598, 196.0692,
>> 179.3542, 174.4489, 179.1992, 193.516, 219.7416, 261.9235, 307.7595,
>> 339.0413, 349.1725, 355.6877, 355.0119, 353.4153, 351.7466, 334.9937,
>> 315.7924, 338.9163, 353.4399, 367.3095, 370.7577, 368.3222, 338.1546,
>> 309.5753, 302.9909, 343.3383, 390.3582, 442.8708, 467.6517, 475.7294,
>> 463.2386, 475.4719, 512.9818, 525.4725, 546.562, 555.4177, 539.306,
>> 499.4974, 483.7216, 504.7977, 493.012, 470.5119, 433.9357, 442.8588,
>> 456.0057, 512.4643, 550.1924, 558.0298, 564.4106, 550.0839, 538.8026,
>> 530.6313, 523.3772, 495.919, 552.271, 570.1813, 559.772, 539.137,
>531.285,
>> 511.5488, 489.0468, 483.7139, 434.6737, 391.9633, 353.6852, 341.9161,
>> 345.1014, 337.9316, 347.3225, 351.3463, 368.2297, 356.9464, 385.1567,
>> 367.8657, 433.608, 567.5147, 609.7797, 502.3615, 441.0474, 421.461,
>> 421.8376, 446.8344, 468.2683, 499.6648, 542.9484, 556.0471, 560.2142,
>> 552.7231, 561.0404, 498.0082, 435.9498, 406.5746, 388.8749, 379.8109,
>> 384.6039, 402.4961, 406.7456, 417.0511, 418.7817, 404.1004, 396.1866,
>> 381.1434, 398.5426, 424.4879, 419.1766, 448.4539, 459.9056, 450.9682,
>> 429.8293, 402.7214, 409.8873, 434.7366, 470.5877, 491.6042, 505.3956,
>> 2379.811, 1683.061, 1348.136, 1183.511, 1096.342, 1063.209, 1083.307,
>> 1137.872, 1698.039, 1777.531, 1824.798, 1990.391, 2049.531, 2094.436,
>> 1982.723, 1974.184, 1931.659, 1916.844, 1909.946, 1859.683, 1768.624,
>> 1733.896, 1644.874, 1566.683, 1802.985, 2026.399, 2002.01, 2095.246,
>> 2341.096, 2261.631, 2337.393, 2534.549, 2322.27, 2333.124, 2367.872,
>> 2336.886, 2235.952, 2284.032, 2240.623, 2144.319, 2069.301, 1946.398,
>> 1910.047, 2043.538, 2433.989, 2556.197, 2578.596, 2568.367, 2534.411,
>> 2478.992, 2395.445, 2468.419, 2459.169, 2850.418, 2889.555, 2898.655,
>> 2802.34, 2630.252, 2451.473, 2667.949, 2813.618, 2777.629, 2657.484,
>> 2226.911, 2225.193, 2366.028, 2296.084, 2321.493, 2335.952, 2351.763,
>> 2347.124, 1576.808, 1743.489, 1847.67, 2869.197, 3040.427, 2686.383,
>> 2409.108, 2028.894, 2091.013, 1932.818, 1923.021, 1920.55, 2171.707,
>> 2086.544, 2304.832, 2344.914, 2685.513, 2448.996, 2252.836, 2147.083,
>> 1971.758, 2033.175, 2196.932, 2353.921, 2357.346, 2326.293, 2178.859,
>> 2293.083, 2341.083, 2452.64, 2557.318, 2645.425, 2778.83, 2744.436,
>> 3066.146, 3070.198, 3004.751, 3008.488, 2991.268, 3074.413, 3159.114,
>> 3126.801, 2823.369)
>> , .Dim = c(114L, 4L)
>> , .Dimnames = list(NULL, c("Q1", "Q2", "Q3", "Q4")))
>>
>> my.data.matrix.time <- structure(c(1, 1.944202, 3.803123, 6.203458,
>> 9.420446, 14.03878, 21.35927, 30.4375, 44.67685, 52.77593, 60.875,
>76.09375,
>> 83.70312, 91.3125, 104.9416, 121.75, 136.9688, 144.5781, 152.1875,
>167.4062,
>> 182.625, 213.0625, 243.5, 273.9375, 304.375, 334.8125, 365.25,
>395.6875,
>> 426.125, 456.5625, 487, 517.4375, 547.875, 578.3125, 608.75,
>639.1875,
>> 669.625, 700.0625, 730.5, 760.9375, 791.375, 821.8125, 852.25,
>882.6875,
>> 913.125, 943.5625, 974, 1004.438, 1034.875, 1065.312, 1095.75,
>1126.188,
>> 1156.625, 1187.062, 1217.5, 1247.938, 1278.375, 1308.812, 1339.25,
>1369.688,
>> 1400.125, 1430.562, 1461, 1491.438, 1521.875, 1552.312, 1582.75,
>1613.188,
>> 1643.625, 1674.062, 1704.5, 1734.938, 1765.375, 1795.812, 1826.25,
>1856.688,
>> 1887.125, 1917.562, 1948, 1978.438, 2008.875, 2039.312, 2069.75,
>2100.188,
>> 2130.625, 2161.062, 2191.5, 2221.938, 2252.375, 2282.812, 2313.25,
>2343.688,
>> 2374.125, 2404.562, 2435, 2465.438, 2495.875, 2526.312, 2556.75,
>2587.188,
>> 2617.625, 2648.062, 2678.5, 2708.938, 2739.375, 2769.812, 2800.25,
>2830.688,
>> 2861.125, 2891.562, 2922, 2952.438, 2982.875, 3013.312)
>> , .Dim = c(114L, 1L)
>> , .Dimnames = list( NULL, "time"))
>>
>> my.data.var <- c( 10, 0.25, 0.25, 0.25, 0.25, 0.25
>>                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>>                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>>                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>>                 )
>>
>> my.data.qo <- c( 5990, 150, 199, 996 )   #Pre-Waterflood Production
>> my.data.timet0 <- 0 # starting condition for time
>>
>> #FUNCTION
>> Qjk.Cal.func <- function( my.data.timet0
>>                         , my.data.qo
>>                         , my.data.matrix.time
>>                         , my.data.matrix.inj
>>                         , my.data.matrix.prod
>>                         , my.data.var
>>                         , my.data.var.mat
>>                         )
>> {
>>
>>     qjk.cal.matrix <- matrix(
>>                             , nrow = nrow( my.data.matrix.prod )
>>                             , ncol = ncol( my.data.matrix.prod )
>>                             )
>>
>>     count <- 1
>>     number <- 1
>>     # loop through all PROD wells columns
>>     for ( colnum in 1:ncol( my.data.matrix.prod ) ) {
>>          # "sum" is a very bad choice of variable name
>>          # as it is a commonly-used base function
>>         sum <- 0 # this initialization is redundant see below
>>         #loop through all the rows
>>         for( row in 1:nrow( my.data.matrix.prod ) ) {
>>             sum <- 0 # most frequent re-initialization
>>             deltaT <- 0
>>             expo <- 0
>>
>>             #loop through all the injector columns to get the PRODUCT
>SUM
>>             for( column in 1:ncol( my.data.matrix.inj ) ) {
>>                 sum <- ( sum
>>                        +   my.data.matrix.inj[ row, column ]
>>                          * my.data.var.mat[ colnum, number+column ]
>>                        )
>>             }
>>
>>             if ( count < 2 ) {
>>                 deltaT <- my.data.matrix.time[ row ]
>>             } else {
>>                 deltaT <- ( my.data.matrix.time[ row ]
>>                           - my.data.matrix.time[ row - 1 ]
>>                           )
>>             }
>>
>>             expo <- exp( -deltaT / my.data.var.mat[ colnum, 1 ] )
>>             # change here too
>>
>>             if ( count < 2 ) {
>>                  qjk.cal.matrix[ row, colnum ] <-
>>                         my.data.qo[ colnum ] * expo + ( 1 - expo ) *
>sum
>>             } else {
>>                 qjk.cal.matrix[ row, colnum ] <-
>>                         (   qjk.cal.matrix[ row - 1, colnum ] * expo
>>                         + ( 1 - expo ) * sum
>>                         )
>>             }
>>             count <- count + 1
>>         }
>>
>>         count <- 1
>>     }
>>
>>     # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>>     qjk.cal.matrix
>> }
>>
>> Error.func <- function( my.data.var ) {
>>     #First convert vector(my.data.var) to MATRIX
>>     # and send it to calculate new MATRIX
>>     my.data.var.mat <- matrix( my.data.var
>>                              , nrow = ncol( my.data.matrix.prod )
>>                              , ncol = ncol( my.data.matrix.inj ) + 1
>>                              , byrow = TRUE
>>                              )
>>
>>     Calc.Qjk.Value <- Qjk.Cal.func( my.data.timet0
>>                                   , my.data.qo
>>                                   , my.data.matrix.time
>>                                   , my.data.matrix.inj
>>                                   , my.data.matrix.prod
>>                                   , my.data.var
>>                                   , my.data.var.mat
>>                                   )
>>
>>     #FIND DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>>     diff.values <- my.data.matrix.prod - Calc.Qjk.Value
>>
>>     #sum of square root of the diff
>>     Error <- ( ( colSums( ( diff.values^2 )
>>                         , na.rm = FALSE
>>                         , dims = 1
>>                         )
>>                ) / nrow( my.data.matrix.inj )
>>              )^0.5
>>     #print(paste(Error))
>>
>>     # total avg error
>>     Error_total <- sum( Error
>>                       , na.rm=FALSE
>>                       ) / ncol( my.data.matrix.prod )
>>
>>     Error_total
>> }
>>
>> n <- ncol( my.data.matrix.prod )
>> m <- ncol( my.data.matrix.inj )
>> k <- ( 1 + n ) * m
>> ciA <- numeric( k )
>> uiA <- array( 0, dim = c( m+1, n, k ) )
>> ia <- 0
>> #Aoff2 <- (m+1) * n
>> for ( i in seq.int( m ) ) {
>>     ia <- ia + 1L
>>     # sum of columns <= 1
>>     uiA[ i+1, , i ] <- -1
>>     ciA[ ia ] <- -1
>> }
>> for ( i in ( 1 + seq.int( m ) ) ) {
>>     for ( j in seq.int( n ) ) {
>>         ia <- ia + 1L
>>         # elements > 0
>>         uiA[ i, j, ia ] <- 1
>>         ciA[ ia ] <- 0
>>     }
>> }
>> uiA <- matrix( uiA, nrow = k, byrow = TRUE )
>>
>> my.data.varA <- c( 10, 0.25, 0.25, 0.25, 0.25, 0.25
>>                  , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>>                  , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>>                  , 10, 0.24, 0.24, 0.24, 0.24, 0.24
>>                  )
>> # interior?
>> all( uiA %*% my.data.var1 - (ciA) > 0 )
>>
>> sols <- constrOptim( my.data.varA
>>                    , Error.func
>>                    , NULL
>>                    , ui = uiA
>>                    , ci = ciA
>>                    , method = "SANN"
>>                    )
>> # meets constraint?
>> all( uiA %*% sols$par - (ciA) >= 0 )
>>
>> sols
>> ##########################
>>
>>
>> On Sun, 19 Jun 2016, Priyank Dwivedi wrote:
>>
>>> All,
>>> Here are the dput files of the input data to the code.
>>>
>>> Thanks for any advice.
>>>
>>> I am adding the entire code below too just in case.
>>>
>>>
>>> file <- file.path("Learning R","CRM_R_Ver4.xlsx")
>>> file
>>> my.data <- readWorksheetFromFile(file,sheet=1,startRow=1)
>>> str(my.data)  # DATA FRAME
>>> my.data.matrix.inj <- as.matrix(my.data)  #convert DATA FRAME to
>MATRIX
>>> my.data.matrix.inj
>>>
>>> dput(my.data.matrix.inj,"my.data.matrix.inj.txt")
>>>
>>>
>>> my.data.2 <- readWorksheetFromFile(file,sheet=2,startRow=1)
>>> str(my.data.2)  # DATA FRAME
>>> my.data.matrix.time <- as.matrix(my.data.2)  #convert DATA FRAME to
>MATRIX
>>> my.data.matrix.time
>>>
>>> dput(my.data.matrix.time,"my.data.matrix.time.txt")
>>>
>>> my.data <- readWorksheetFromFile(file,sheet=3,startRow=1)
>>> str(my.data)  # DATA FRAME
>>> my.data.matrix.prod <- as.matrix(my.data)  #convert DATA FRAME to
>MATRIX
>>> my.data.matrix.prod
>>>
>>> dput(my.data.matrix.prod,"my.data.matrix.prod.txt")
>>>
>>> # my.data.var <- vector("numeric",length = 24)
>>> # my.data.var
>>>
>>> my.data.var <- c(10,0.25,0.25,0.25,0.25,0.25,
>>>                 10,0.25,0.25,0.25,0.25,0.25,
>>>                 10,0.25,0.25,0.25,0.25,0.25,
>>>                 10,0.25,0.25,0.25,0.25,0.25)
>>> my.data.var
>>>
>>> dput(my.data.var,"my.data.var.txt")
>>>
>>>
>>> my.data.qo <- c(5990,150,199,996)   #Pre-Waterflood Production
>>> my.data.timet0 <- 0 # starting condition for time
>>>
>>> #FUNCTION
>>> Qjk.Cal.func <-
>function(my.data.timet0,my.data.qo,my.data.matrix.time,
>>>                         my.data.matrix.inj,
>>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>> {
>>>
>>>  qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>>> ncol=ncol(my.data.matrix.prod))
>>>
>>>  count <- 1
>>>  number <- 1
>>>  for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all
>PROD
>>> wells columns
>>>  {
>>>    sum <-0
>>>    for(row in 1:nrow(my.data.matrix.prod)) #loop through all the
>rows
>>>    {
>>>      sum <-0
>>>      deltaT <-0
>>>      expo <-0
>>>
>>>
>>>        for(column in 1:ncol(my.data.matrix.inj)) #loop through all
>>> the injector columns to get the PRODUCT SUM
>>>         {
>>>            sum = sum +
>>> my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>>>         }
>>>
>>>      if(count<2)
>>>      {
>>>        deltaT<- my.data.matrix.time[row]
>>>      }
>>>      else
>>>      {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>>>
>>>
>>>      expo <- exp(-deltaT/my.data.var.mat[colnum,1])
>>> # change here too
>>>
>>>      if(count<2)
>>>      {
>>>        qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo +
>(1-expo)*sum
>>>      }
>>>      else
>>>      {
>>>        qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo
>+
>>> (1-expo)*sum
>>>      }
>>>      count <- count+1
>>>    }
>>>
>>>    count <-1
>>>  }
>>>
>>>  qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR
>FUNCTION
>>>
>>> }
>>>
>>>
>>> # ERROR FUNCTION - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
>>> MATRIX. Miminize the Error by changing my.data.var
>>>
>>> Error.func <- function(my.data.var)
>>> {
>>>  #First convert vector(my.data.var) to MATRIX aand send it to
>>> calculate new MATRIX
>>>  my.data.var.mat <- matrix(my.data.var,nrow =
>>> ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow =
>>> TRUE)
>>>
>>>  Calc.Qjk.Value <-
>>> Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>>>                                 my.data.matrix.inj,
>>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>>
>>>
>>>  diff.values <- my.data.matrix.prod-Calc.Qjk.Value    #FIND
>>> DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>>>
>>>
>>>  Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>>> 1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>>>  print(paste(Error))
>>>
>>>  Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
>>> total avg error
>>>
>>>
>>>  Error_total
>>> }
>>>
>>> # OPTIMIZE
>>>
>>>
>>>
>sols<-optim(my.data.var,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1),
>>>      lower=c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))
>>>
>>> sols
>>>
>>> On 17 June 2016 at 16:55, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>>>>
>>>> Your code is corrupt because you failed to send your email in plain
>text
>>>> format.
>>>>
>>>> You also don't appear to have all data needed to reproduce the
>problem.
>>>> Use
>>>> the dput function to generate R code form of a sample of your data.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On June 17, 2016 1:07:21 PM PDT, Priyank Dwivedi
><dpriyank23 at gmail.com>
>>>> wrote:
>>>>>
>>>>>
>>>>> By mistake, I sent it earlier to the wrong address.
>>>>>
>>>>> ---------- Forwarded message ----------
>>>>> From: Priyank Dwivedi <dpriyank23 at gmail.com>
>>>>> Date: 17 June 2016 at 14:50
>>>>> Subject: Matrix Constraints in R Optim
>>>>> To: r-help-owner at r-project.org
>>>>>
>>>>>
>>>>> Hi,
>>>>>
>>>>> Below is the code snippet I wrote in R:
>>>>>
>>>>> The basic idea is to minimize error by optimizing set of values
>(in this
>>>>> scenario 12) in the form of a matrix. I defined the matrix
>elements as
>>>>> vector "*my.data.var" * and then stacked it into a matrix called
>>>>> "*my.data.var.mat"
>>>>> in the error function. *
>>>>>
>>>>> The only part that I can't figure out is "what if the column sum
>in
>>>>> the *my.data.var.mat
>>>>> needs to be <=1"; that's the constraint/s.. Where do I introduce
>it in
>>>>> the
>>>>> OPTIM solver or elsewhere?*
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> *my.data.matrix.inj* <- as.matrix(my.data)  #convert DATA FRAME to
>>>>> MATRIX
>>>>> my.data.matrix.inj
>>>>>
>>>>>
>>>>> *my.data.matrix.time* <- as.matrix(my.data.2)  #convert DATA FRAME
>to
>>>>> MATRIX
>>>>> my.data.matrix.time
>>>>>
>>>>>
>>>>> *my.data.matrix.prod* <- as.matrix(my.data)  #convert DATA FRAME
>to
>>>>> MATRIX
>>>>> my.data.matrix.prod
>>>>>
>>>>>
>>>>> *my.data.var* <-
>>>>>
>>>>>
>>>>>
>c(2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01)
>>>>> my.data.var
>>>>>
>>>>> *my.data.qo* <- c(5990,150,199,996)   #Pre-Waterflood Production
>>>>>
>>>>> *my.data.timet0* <- 0 # starting condition for time
>>>>>
>>>>>
>>>>> *#FUNCTIONQjk.Cal.func* <-
>>>>>
>>>>> function(my.data.timet0,my.data.qo,my.data.matrix.time,
>>>>>                          my.data.matrix.inj,
>>>>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>>>> {
>>>>>
>>>>>   qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>>>>> ncol=ncol(my.data.matrix.prod))
>>>>>
>>>>>   count <- 1
>>>>>   number <- 1
>>>>>   for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all
>PROD
>>>>> wells columns
>>>>>   {
>>>>>     sum <-0
>>>>>     for(row in 1:nrow(my.data.matrix.prod)) #loop through all the
>rows
>>>>>     {
>>>>>       sum <-0
>>>>>       deltaT <-0
>>>>>       expo <-0
>>>>>
>>>>>
>>>>>         for(column in 1:ncol(my.data.matrix.inj)) #loop through
>all the
>>>>> injector columns to get the PRODUCT SUM
>>>>>          {
>>>>>             sum = sum +
>>>>>
>my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>>>>>          }
>>>>>
>>>>>       if(count<2)
>>>>>       {
>>>>>         deltaT<- my.data.matrix.time[row]
>>>>>       }
>>>>>       else
>>>>>       {deltaT <-
>my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>>>>>
>>>>>
>>>>>       expo <- exp(-deltaT/my.data.var.mat[colnum,1])              
>   #
>>>>> change here too
>>>>>
>>>>>       if(count<2)
>>>>>       {
>>>>>         qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo +
>>>>> (1-expo)*sum
>>>>>
>>>>>  }
>>>>>       else
>>>>>       {
>>>>>        
>qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
>>>>> (1-expo)*sum
>>>>>       }
>>>>>       count <- count+1
>>>>>     }
>>>>>
>>>>>     count <-1
>>>>>   }
>>>>>
>>>>>   qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR
>FUNCTION
>>>>>
>>>>> }
>>>>>
>>>>>
>>>>> *# ERROR FUNCTION* - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND
>ORIGINAL
>>>>> MATRIX. Miminize the Error by changing my.data.var
>>>>>
>>>>> *Error.func* <- function(my.data.var)
>>>>> {
>>>>>   #First convert vector(my.data.var) to MATRIX aand send it to
>calculate
>>>>> new MATRIX
>>>>>   *my.data.var.mat* <- matrix(my.data.var,nrow =
>>>>> ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow
>=
>>>>> TRUE)
>>>>>
>>>>> *  Calc.Qjk.Value* <-
>>>>> Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>>>>>                                  my.data.matrix.inj,
>>>>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>>>>
>>>>>
>>>>>   diff.values <-
>>>>> my.data.matrix.prod-Calc.Qjk.Value    #FIND DIFFERENCE
>>>>> BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>>>>>
>>>>>
>>>>>   Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>>>>> 1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the
>diff
>>>>>   print(paste(Error))
>>>>>
>>>>>   Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod) 
> #
>>>>> total
>>>>> avg error
>>>>>
>>>>>
>>>>>  * Error_total*
>>>>> }
>>>>>
>>>>> # OPTIMIZE
>>>>>
>>>>> *optim*(*my.data.var*
>>>>>
>>>>>
>>>>>
>,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1))
>>>>>
>>>>>
>>>>
>>>
>>>
>>>
>>> --
>>> Best Regards,
>>> Priyank Dwivedi
>>>
>>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------


From marine.regis at hotmail.fr  Tue Jun 21 23:55:33 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Tue, 21 Jun 2016 21:55:33 +0000
Subject: [R] Extract character strings from a vector
Message-ID: <AMSPR07MB470CA7DE5C094933EA5CF52E22B0@AMSPR07MB470.eurprd07.prod.outlook.com>


Hello,



I have a vector x of character strings:



x <- c("LM0122","RTGFFFF", "GF TYHH", "HJN 89963", "KFTR1","RT 8")



>From this vector, how can I extract the following character strings (i.e., which contain 0 or 1 numeric value)



[1] "RTGFFFF"   "GF TYHH"   "KFTR1"  "RT 8"



Thank you very much for your help.

Have a nice day

Marine


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Jun 22 00:09:17 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 21 Jun 2016 15:09:17 -0700
Subject: [R] Extract character strings from a vector
In-Reply-To: <AMSPR07MB470CA7DE5C094933EA5CF52E22B0@AMSPR07MB470.eurprd07.prod.outlook.com>
References: <AMSPR07MB470CA7DE5C094933EA5CF52E22B0@AMSPR07MB470.eurprd07.prod.outlook.com>
Message-ID: <CAF8bMcb27tpkUbvVCPVoWxdyFypWfeaFkd+Eja0sM0HL+jLCbg@mail.gmail.com>

You could remove all non-digits from the strings with
   > gsub("[^[:digit:]]+", "", x)
   [1] "0122"  ""      ""      "89963" "1"     "8"
and then count the number of characters remaining with nchar
  > x[nchar(gsub("[^[:digit:]]+", "", x)) <= 1]
  [1] "RTGFFFF" "GF TYHH" "KFTR1"   "RT 8"

Or you could do it with grep and a fancier regular expression
  > grep(value=TRUE, "^[^[:digit:]]*([[:digit:]][^[:digit:]]*){0,1}$", x)
  [1] "RTGFFFF" "GF TYHH" "KFTR1"   "RT 8"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jun 21, 2016 at 2:55 PM, Marine Regis <marine.regis at hotmail.fr>
wrote:

>
> Hello,
>
>
>
> I have a vector x of character strings:
>
>
>
> x <- c("LM0122","RTGFFFF", "GF TYHH", "HJN 89963", "KFTR1","RT 8")
>
>
>
> >From this vector, how can I extract the following character strings
> (i.e., which contain 0 or 1 numeric value)
>
>
>
> [1] "RTGFFFF"   "GF TYHH"   "KFTR1"  "RT 8"
>
>
>
> Thank you very much for your help.
>
> Have a nice day
>
> Marine
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Jun 22 01:38:33 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Jun 2016 16:38:33 -0700
Subject: [R] Extract character strings from a vector
In-Reply-To: <CAF8bMcb27tpkUbvVCPVoWxdyFypWfeaFkd+Eja0sM0HL+jLCbg@mail.gmail.com>
References: <AMSPR07MB470CA7DE5C094933EA5CF52E22B0@AMSPR07MB470.eurprd07.prod.outlook.com>
	<CAF8bMcb27tpkUbvVCPVoWxdyFypWfeaFkd+Eja0sM0HL+jLCbg@mail.gmail.com>
Message-ID: <E07881CE-7D2E-4367-AE79-B6E1A7F6CDD3@comcast.net>


> On Jun 21, 2016, at 3:09 PM, William Dunlap via R-help <r-help at r-project.org> wrote:
> 
> You could remove all non-digits from the strings with
>> gsub("[^[:digit:]]+", "", x)
>   [1] "0122"  ""      ""      "89963" "1"     "8"
> and then count the number of characters remaining with nchar
>> x[nchar(gsub("[^[:digit:]]+", "", x)) <= 1]
>  [1] "RTGFFFF" "GF TYHH" "KFTR1"   "RT 8"
> 
> Or you could do it with grep and a fancier regular expression
>> grep(value=TRUE, "^[^[:digit:]]*([[:digit:]][^[:digit:]]*){0,1}$", x)
>  [1] "RTGFFFF" "GF TYHH" "KFTR1"   "RT 8"
> 

If the question is how to slect those items with no adjacent digits, which is not exactly what was described but was one possible interpretation of the example, it could be:

> x[ !grepl("\\d{2,}", x) ]
[1] "RTGFFFF" "GF TYHH" "KFTR1"   "RT 8"   

and an addition regex OR "clause" could handle the possibility of separated digits:

> x[ !grepl("\\d{2,}|\\d.+\\d", x) ]
[1] "RTGFFFF" "GF TYHH" "KFTR1"   "RT 8" 

-- 
David.

> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Tue, Jun 21, 2016 at 2:55 PM, Marine Regis <marine.regis at hotmail.fr>
> wrote:
> 
>> 
>> Hello,
>> 
>> 
>> 
>> I have a vector x of character strings:
>> 
>> 
>> 
>> x <- c("LM0122","RTGFFFF", "GF TYHH", "HJN 89963", "KFTR1","RT 8")
>> 
>> 
>> 
>>> From this vector, how can I extract the following character strings
>> (i.e., which contain 0 or 1 numeric value)
>> 
>> 
>> 
>> [1] "RTGFFFF"   "GF TYHH"   "KFTR1"  "RT 8"
>> 
>> 
>> 
>> Thank you very much for your help.
>> 
>> Have a nice day
>> 
>> Marine
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ashimkapoor at gmail.com  Wed Jun 22 03:06:07 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 22 Jun 2016 06:36:07 +0530
Subject: [R] Ask function missing in package car
Message-ID: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>

Dear All,

my details:-
> sessionInfo()
R version 3.3.0 (2016-05-03)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 15.10

locale:
 [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
 [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
 [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] car_2.1-2

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
grid_3.3.0
 [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
minqa_1.2.4
 [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
lme4_1.1-12
[13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
nnet_7.3-10
[17] quantreg_5.24
>

>     ## Not run:
> attach(UN)
>
> # enter the power-transformation parameter
> # start with 1
> Ask(p, function(p) qq.plot(box.cox(gdp, p),
+         ylab=paste("transformed gdp, power =",p)))
Error: could not find function "Ask"
>

What can I do to correct this?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Jun 22 03:27:09 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 22 Jun 2016 13:27:09 +1200
Subject: [R] [FORGED]  Ask function missing in package car
In-Reply-To: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
Message-ID: <833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>

On 22/06/16 13:06, Ashim Kapoor wrote:
> Dear All,
>
> my details:-
>> sessionInfo()
> R version 3.3.0 (2016-05-03)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 15.10
>
> locale:
>  [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
>  [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
>  [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] car_2.1-2
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
> grid_3.3.0
>  [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
> minqa_1.2.4
>  [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
> lme4_1.1-12
> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
> nnet_7.3-10
> [17] quantreg_5.24
>>
>
>>     ## Not run:
>> attach(UN)
>>
>> # enter the power-transformation parameter
>> # start with 1
>> Ask(p, function(p) qq.plot(box.cox(gdp, p),
> +         ylab=paste("transformed gdp, power =",p)))
> Error: could not find function "Ask"
>>
>
> What can I do to correct this?

What led you to believe that such a function exists (in the "car" 
package or anywhere else for that matter)?  And what exactly do you want 
it to do for you?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ashimkapoor at gmail.com  Wed Jun 22 03:29:10 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 22 Jun 2016 06:59:10 +0530
Subject: [R] [FORGED]  Ask function missing in package car
In-Reply-To: <833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
Message-ID: <CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>

I am reading the book An R and S plus companion to Applied Regression and I
found this function there.

Googling gave me the link [1].

1. http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html

On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 22/06/16 13:06, Ashim Kapoor wrote:
>
>> Dear All,
>>
>> my details:-
>>
>>> sessionInfo()
>>>
>> R version 3.3.0 (2016-05-03)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 15.10
>>
>> locale:
>>  [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
>>  [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
>>  [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] car_2.1-2
>>
>> loaded via a namespace (and not attached):
>>  [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
>> grid_3.3.0
>>  [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
>> minqa_1.2.4
>>  [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
>> lme4_1.1-12
>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
>> nnet_7.3-10
>> [17] quantreg_5.24
>>
>>>
>>>
>>     ## Not run:
>>> attach(UN)
>>>
>>> # enter the power-transformation parameter
>>> # start with 1
>>> Ask(p, function(p) qq.plot(box.cox(gdp, p),
>>>
>> +         ylab=paste("transformed gdp, power =",p)))
>> Error: could not find function "Ask"
>>
>>>
>>>
>> What can I do to correct this?
>>
>
> What led you to believe that such a function exists (in the "car" package
> or anywhere else for that matter)?  And what exactly do you want it to do
> for you?
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Wed Jun 22 04:15:04 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 21 Jun 2016 21:15:04 -0500
Subject: [R] [FORGED]  Ask function missing in package car
In-Reply-To: <CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
	<CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
Message-ID: <356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>

According to the NEWS file for the package:

  https://cran.r-project.org/web/packages/car/NEWS

the Ask() function was removed in car version 2.0-0, which was released on 2010-07-26. So it has been gone for about 6 years.

The version of car that is used in the documentation that you are using is 1.2-16, which is from 2009-10-11.

So the online documentation source is outdated.

I see that the Ask() function is listed in the first edition of John's book, which I have on my shelf, but I don't have the second edition to know if that had been updated. A review of the index for the second edition on Amazon.com would suggest that it was removed for the second edition.

Regards,

Marc Schwartz


> On Jun 21, 2016, at 8:29 PM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> 
> I am reading the book An R and S plus companion to Applied Regression and I
> found this function there.
> 
> Googling gave me the link [1].
> 
> 1. http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html
> 
> On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> 
>> On 22/06/16 13:06, Ashim Kapoor wrote:
>> 
>>> Dear All,
>>> 
>>> my details:-
>>> 
>>>> sessionInfo()
>>>> 
>>> R version 3.3.0 (2016-05-03)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 15.10
>>> 
>>> locale:
>>> [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
>>> [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
>>> [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
>>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN LC_IDENTIFICATION=C
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> other attached packages:
>>> [1] car_2.1-2
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
>>> grid_3.3.0
>>> [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
>>> minqa_1.2.4
>>> [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
>>> lme4_1.1-12
>>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
>>> nnet_7.3-10
>>> [17] quantreg_5.24
>>> 
>>>> 
>>>> 
>>>    ## Not run:
>>>> attach(UN)
>>>> 
>>>> # enter the power-transformation parameter
>>>> # start with 1
>>>> Ask(p, function(p) qq.plot(box.cox(gdp, p),
>>>> 
>>> +         ylab=paste("transformed gdp, power =",p)))
>>> Error: could not find function "Ask"
>>> 
>>>> 
>>>> 
>>> What can I do to correct this?
>>> 
>> 
>> What led you to believe that such a function exists (in the "car" package
>> or anywhere else for that matter)?  And what exactly do you want it to do
>> for you?
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276


From ashimkapoor at gmail.com  Wed Jun 22 04:35:19 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 22 Jun 2016 08:05:19 +0530
Subject: [R] [FORGED] Ask function missing in package car
In-Reply-To: <356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
	<CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
	<356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>
Message-ID: <CAC8=1eq2M1X4Tk1uwLJ14JU7bSsPvPZDB31jb9Vi0t_AfT66GA@mail.gmail.com>

Dear Mark,

Many thanks.

Best Regards,
Ashim

On Wed, Jun 22, 2016 at 7:45 AM, Marc Schwartz <marc_schwartz at me.com> wrote:

> According to the NEWS file for the package:
>
>   https://cran.r-project.org/web/packages/car/NEWS
>
> the Ask() function was removed in car version 2.0-0, which was released on
> 2010-07-26. So it has been gone for about 6 years.
>
> The version of car that is used in the documentation that you are using is
> 1.2-16, which is from 2009-10-11.
>
> So the online documentation source is outdated.
>
> I see that the Ask() function is listed in the first edition of John's
> book, which I have on my shelf, but I don't have the second edition to know
> if that had been updated. A review of the index for the second edition on
> Amazon.com would suggest that it was removed for the second edition.
>
> Regards,
>
> Marc Schwartz
>
>
> > On Jun 21, 2016, at 8:29 PM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > I am reading the book An R and S plus companion to Applied Regression
> and I
> > found this function there.
> >
> > Googling gave me the link [1].
> >
> > 1. http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html
> >
> > On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner <r.turner at auckland.ac.nz>
> > wrote:
> >
> >> On 22/06/16 13:06, Ashim Kapoor wrote:
> >>
> >>> Dear All,
> >>>
> >>> my details:-
> >>>
> >>>> sessionInfo()
> >>>>
> >>> R version 3.3.0 (2016-05-03)
> >>> Platform: x86_64-pc-linux-gnu (64-bit)
> >>> Running under: Ubuntu 15.10
> >>>
> >>> locale:
> >>> [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
> >>> [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
> >>> [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
> >>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN LC_IDENTIFICATION=C
> >>>
> >>> attached base packages:
> >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>
> >>> other attached packages:
> >>> [1] car_2.1-2
> >>>
> >>> loaded via a namespace (and not attached):
> >>> [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
> >>> grid_3.3.0
> >>> [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
> >>> minqa_1.2.4
> >>> [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
> >>> lme4_1.1-12
> >>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
> >>> nnet_7.3-10
> >>> [17] quantreg_5.24
> >>>
> >>>>
> >>>>
> >>>    ## Not run:
> >>>> attach(UN)
> >>>>
> >>>> # enter the power-transformation parameter
> >>>> # start with 1
> >>>> Ask(p, function(p) qq.plot(box.cox(gdp, p),
> >>>>
> >>> +         ylab=paste("transformed gdp, power =",p)))
> >>> Error: could not find function "Ask"
> >>>
> >>>>
> >>>>
> >>> What can I do to correct this?
> >>>
> >>
> >> What led you to believe that such a function exists (in the "car"
> package
> >> or anywhere else for that matter)?  And what exactly do you want it to
> do
> >> for you?
> >>
> >> cheers,
> >>
> >> Rolf Turner
> >>
> >> --
> >> Technical Editor ANZJS
> >> Department of Statistics
> >> University of Auckland
> >> Phone: +64-9-373-7599 ext. 88276
>
>

	[[alternative HTML version deleted]]


From attenka at utu.fi  Tue Jun 21 17:52:57 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Tue, 21 Jun 2016 18:52:57 +0300
Subject: [R] About the parameters of rotationMatrix
In-Reply-To: <acc24916-6d46-0720-8805-971244fb517e@gmail.com>
References: <57691BF8.3070309@utu.fi>
	<acc24916-6d46-0720-8805-971244fb517e@gmail.com>
Message-ID: <576962D9.2030307@utu.fi>

Oh, thanks... ;-)

Atte

21.6.2016, 17.30, Duncan Murdoch kirjoitti:
> for(i in 1: 10)
> {
>       a2=i*0.1; b2=i*0.2; c2=i*0.3
>       print(c(a2,b2,c2))
>       UserMatrix = rotationMatrix(pi/4,a2,b2,c2)
>       print(UserMatrix)
> }


From Chi.Pham at colostate.edu  Tue Jun 21 20:30:24 2016
From: Chi.Pham at colostate.edu (Pham,Chi)
Date: Tue, 21 Jun 2016 18:30:24 +0000
Subject: [R] Spatial Durbin (mixed) Model Inquery
Message-ID: <BY1PR0701MB17068794632A9654436C28D2802B0@BY1PR0701MB1706.namprd07.prod.outlook.com>

Hi,
I am trying to run a Spatial Durbin Model but I need to incorporate a robust standard error in it since the data have heteroskedasticity, I don?t know how to return the results with robust standard error. One other thing I would like to do is to also return the Direct and Indirect effects with the robust standard error. I managed to get R to show the Direct and Indirect coeffients but could not see their standard error. If you have some insight about this, I would be really thankful. Below are the commands I used:

#LOADING DATA FILE
> nonadj <- read.csv("C:/Users/Chi/OneDrive/Thesis/R/nonadj-percent.csv", 1)
> attach(nonadj)

#CREATING DEPENDENT AND INDEPENDENT MATRICES
> Y1 <- cbind(growth)
> X1 <- cbind(pop, Net.Migra, FDI.capita, Retail.sale.thou, Vol.Freight.N, Labor.in.business, Turnover.of.biz, Coll.Stu.pcnt, highschool, secondprim, Hospital, cereal, fishaqua, cattlepoul)

#CREATING THE WEIGHT MATRIX (376x376)
> weight1 <- read.csv("C:/Users/Chi/OneDrive/Thesis/R/nonadjW.csv", 1)
> attach(weight1)
> W1 <- cbind(A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20, A21, A22, A23, A24, A25, A26, A27, A28, A29, A30, A31, A32, A33, A34, A35, A36, A37, A38, A39, A40, A41, A42, A43, A44, A45, A46, A47, A48, A49, A50, A51, A52, A53, A54, A55, A56, A57, A58, A59, A60, A61, A62, A63, A64, A65, A66, A67, A68, A69, A70, A71, A72, A73, A74, A75, A76, A77, A78, A79, A80, A81, A82, A83, A84, A85, A86, A87, A88, A89, A90, A91, A92, A93, A94, A95, A96, A97, A98, A99, A100, A101, A102, A103, A104, A105, A106, A107, A108, A109, A110, A111, A112, A113, A114, A115, A116, A117, A118, A119, A120, A121, A122, A123, A124, A125, A126, A127, A128, A129, A130, A131, A132, A133, A134, A135, A136, A137, A138, A139, A140, A141, A142, A143, A144, A145, A146, A147, A148, A149, A150, A151, A152, A153, A154, A155, A156, A157, A158, A159, A160, A161, A162, A163, A164, A165, A166, A167, A168, A169, A170, A171, A172, A173, A174, A175, A176, A177, A178, A179, A180, A181, A182, A183, A184, A185, A186, A187, A188, A189, A190, A191, A192, A193, A194, A195, A196, A197, A198, A199, A200, A201, A202, A203, A204, A205, A206, A207, A208, A209, A210, A211, A212, A213, A214, A215, A216, A217, A218, A219, A220, A221, A222, A223, A224, A225, A226, A227, A228, A229, A230, A231, A232, A233, A234, A235, A236, A237, A238, A239, A240, A241, A242, A243, A244, A245, A246, A247, A248, A249, A250, A251, A252, A253, A254, A255, A256, A257, A258, A259, A260, A261, A262, A263, A264, A265, A266, A267, A268, A269, A270, A271, A272, A273, A274, A275, A276, A277, A278, A279, A280, A281, A282, A283, A284, A285, A286, A287, A288, A289, A290, A291, A292, A293, A294, A295, A296, A297, A298, A299, A300, A301, A302, A303, A304, A305, A306, A307, A308, A309, A310, A311, A312, A313, A314, A315, A316, A317, A318, A319, A320, A321, A322, A323, A324, A325, A326, A327, A328, A329, A330, A331, A332, A333, A334, A335, A336, A337, A338, A339, A340, A341, A342, A343, A344, A345, A346, A347, A348, A349, A350, A351, A352, A353, A354, A355, A356, A357, A358, A359, A360, A361, A362, A363, A364, A365, A366, A367, A368, A369, A370, A371, A372, A373, A374, A375, A376)
> W1 <- mat2listw(W1)

#RUNNING SPATIAL DURBIN REGRESSION
> library(spdep)
> SDM1 <- lagsarlm(Y1~X1,data=nonadj,W1, type="mixed")
> summary (SDM1)

Call:lagsarlm(formula = Y1 ~ X1, data = nonadj, listw = W1, type = "mixed")

Residuals:
      Min        1Q    Median        3Q       Max
-0.245203 -0.054391 -0.010243  0.037691  0.650065

Type: mixed
Coefficients: (asymptotic standard errors)
    (1 not defined because of singularities)
                           Estimate  Std. Error  z value  Pr(>|z|)
(Intercept)              8.4752e-02  1.0352e-01   0.8187 0.4129595
X1pop                    8.1888e-01  8.0222e-01   1.0208 0.3073616
X1Net.Migra              1.4557e-04  5.4679e-04   0.2662 0.7900713
X1FDI.capita             1.0825e-04  7.9579e-05   1.3603 0.1737211
X1Retail.sale.thou       3.5921e-01  4.7799e-02   7.5150 5.684e-14
X1Vol.Freight.N         -1.5598e-01  2.1753e-02  -7.1705 7.472e-13
X1Labor.in.business     -6.2889e-01  5.2969e-02 -11.8728 < 2.2e-16
X1Turnover.of.biz       -1.0088e-01  2.8196e-02  -3.5778 0.0003465
X1Coll.Stu.pcnt         -2.3874e-03  1.6242e-03  -1.4699 0.1415996
X1highschool             9.7207e-02  6.0762e-02   1.5998 0.1096474
X1secondprim            -2.0255e-02  1.2884e-01  -0.1572 0.8750760
X1Hospital               2.5882e-03  6.3570e-02   0.0407 0.9675240
X1cereal                -3.2210e-03  6.1418e-02  -0.0524 0.9581746
X1fishaqua               2.4810e-02  3.2659e-02   0.7596 0.4474674
X1cattlepoul             4.9122e-02  3.9470e-02   1.2445 0.2133005
lag.(Intercept)                  NA          NA       NA        NA
lag.X1pop                3.1168e-02  2.1213e-01   0.1469 0.8831907
lag.X1Net.Migra         -1.0739e-04  3.3696e-04  -0.3187 0.7499517
lag.X1FDI.capita         2.8408e-05  9.2314e-05   0.3077 0.7582897
lag.X1Retail.sale.thou  -6.2861e-02  5.8775e-02  -1.0695 0.2848380
lag.X1Vol.Freight.N      2.6938e-02  2.5154e-02   1.0709 0.2842134
lag.X1Labor.in.business -4.2901e-03  4.2330e-02  -0.1013 0.9192736
lag.X1Turnover.of.biz   -5.3610e-02  2.7632e-02  -1.9401 0.0523647
lag.X1Coll.Stu.pcnt     -2.6502e-03  1.5856e-03  -1.6714 0.0946416
lag.X1highschool        -4.9215e-03  7.5851e-02  -0.0649 0.9482666
lag.X1secondprim        -2.2008e-01  1.5629e-01  -1.4082 0.1590763
lag.X1Hospital           1.0957e-02  6.4151e-02   0.1708 0.8643748
lag.X1cereal            -1.9200e-02  4.8177e-02  -0.3985 0.6902360
lag.X1fishaqua           5.3577e-02  2.4049e-02   2.2279 0.0258902
lag.X1cattlepoul        -9.2296e-03  5.1168e-02  -0.1804 0.8568547

Rho: 0.021541, LR test value: 0.64222, p-value: 0.42291
Asymptotic standard error: 0.020742
    z-value: 1.0385, p-value: 0.29903
Wald statistic: 1.0785, p-value: 0.29903

Log likelihood: 362.6504 for mixed model
ML residual variance (sigma squared): 0.0084969, (sigma: 0.092178)
Number of observations: 376
Number of parameters estimated: 31
AIC: -663.3, (AIC for lm: -664.66)
LM test for residual autocorrelation
test value: 1.0739, p-value: 0.30008

#DIRECT AND INDIRECT EFFECT
> DirectIndirect <- impacts(SDM1, listw=W1)
> print(DirectIndirect, zstats=T)
Impact measures (mixed, exact):
                           Direct      Indirect         Total
X1pop                0.8216413667  0.4689926598  1.2906340265
X1Net.Migra          0.0001396760 -0.0010017906 -0.0008621146
X1FDI.capita         0.0001099911  0.0002953802  0.0004053713
X1Retail.sale.thou   0.3560995192 -0.5296852825 -0.1735857633
X1Vol.Freight.N     -0.1546482688  0.2265607787  0.0719125099
X1Labor.in.business -0.6298927708 -0.1713948301 -0.8012876009
X1Turnover.of.biz   -0.1040310437 -0.5360237512 -0.6400547949
X1Coll.Stu.pcnt     -0.0025399984 -0.0259598778 -0.0284998762
X1highschool         0.0970468278 -0.0271707229  0.0698761049
X1secondprim        -0.0327121352 -2.1189667965 -2.1516789317
X1Hospital           0.0032102908  0.1058274395  0.1090377303
X1cereal            -0.0043095229 -0.1851649223 -0.1894744453
X1fishaqua           0.0278662464  0.5199654674  0.5478317137
X1cattlepoul         0.0486605830 -0.0785212636 -0.0298606805



Thank you for any information that you have on this!
Chi Pham

	[[alternative HTML version deleted]]


From dpriyank23 at gmail.com  Tue Jun 21 22:13:35 2016
From: dpriyank23 at gmail.com (Priyank Dwivedi)
Date: Tue, 21 Jun 2016 15:13:35 -0500
Subject: [R] Fwd: Matrix Constraints in R Optim
In-Reply-To: <alpine.BSF.2.00.1606210942310.21156@pedal.dcn.davis.ca.us>
References: <CADya=_wMawuy4A8+58=vgAXn7F4eSZ1z2m00pCkfe-HVGt34ow@mail.gmail.com>
	<CADya=_ymi22=6Xj5BtVKf7jisUrjK_pogM6qx04NvL287cK3fA@mail.gmail.com>
	<A8E545C2-7085-4AEF-817C-CD0102FB30F6@dcn.davis.ca.us>
	<CADya=_xfAD3wt2BXaD899FuJY2Vyo0u+7GdsF3O3+1JxUVbSHA@mail.gmail.com>
	<alpine.BSF.2.00.1606210942310.21156@pedal.dcn.davis.ca.us>
Message-ID: <CADya=_yqzpQ0PVkLKXgz1L-sL5RzRbh=YvCaAPeSoH_r-W4GBg@mail.gmail.com>

Thank you Jeff.
It seems to definitely solve it but the "total_error" is very high. Around 399.
I also tried with the method = "L-BFGS-B". Still the error is around 399.
How can we reduce it?

Priyank

On 21 June 2016 at 12:18, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> The size of this request is a bit big for this list.
>
> I think you need the constrOptim function to achieve this constraint. See
> reproducible example below (no contributed packages needed):
>
> #-----
>
> my.data.matrix.inj <- structure(c(284.6624, 284.6743, 284.6771, 284.6746,
> 284.6664, 284.6516, 284.6283, 284.5931, 555.1354, 555.0648, 555.0361,
> 2717.121, 2716.909, 2716.857, 3537.007, 3537.209, 454.2328, 454.2205,
> 454.2086, 1297.769, 1297.827, 1386.995, 2040.08, 2040.237, 1074.394,
> 1409.096, 1187.767, 1453.882, 1149.305, 1329.487, 1376.219, 1881.046,
> 1538.514, 1002.312, 612.8742, 1373.664, 1424.084, 1352.598, 1479.259,
> 767.9471, 1277.077, 1477.096, 1383.378, 1398.408, 1353.671, 882.6216,
> 1399.007, 1159.061, 1507.469, 1089.506, 1642.942, 1799.764, 1873.927,
> 2145.548, 2017.962, 1993.64, 2221.32, 2123.962, 2463.256, 2405.041,
> 2404.414, 2438.734, 2638.787, 2616.91, 2346.845, 2852.143, 2942.838,
> 3140.032, 762.2396, 1720.488, 1789.752, 371.4107, 1225.91, 1686.064,
> 1652.747, 1724.248, 1655.486, 1552.557, 1870.383, 1807.614, 1498.599,
> 1376.45, 1453.844, 1441.684, 1363.064, 1066.156, 1365.101, 1358.903,
> 1288.348, 610.3185, 532.7502, 1573.272, 1768.713, 1781.086, 1747.261,
> 1977.336, 1904.75, 1538.454, 1678.361, 1774.035, 1495.381, 1285.172,
> 1511.251, 1627.114, 1626.432, 1579.333, 1574.744, 1435.232, 2135.695,
> 2031.769, 2350.99, 2562.418, 2515.922, 2709.281, 1824.588, 1824.665,
> 1824.682, 1824.666, 1824.613, 1824.519, 1824.37, 1824.144, 1367.973,
> 1367.799, 1367.728, 626.0895, 626.0406, 626.0286, 299.3024, 299.3194,
> 1420.26, 1420.222, 1420.185, 1626.06, 1626.133, 1181.016, 1067.529,
> 1067.611, 1346.783, 1286.029, 1669.494, 1469.061, 1571.632, 1369.969,
> 1342.855, 1635.875, 1769.014, 1876.71, 1794.846, 1658.31, 1526.607,
> 1676.101, 1705.561, 1641.514, 1605.627, 1298.534, 1591.755, 1611.691,
> 1571.183, 1584.321, 1572.948, 1532.965, 1524.934, 1534.853, 1538.834,
> 1463.963, 1462.23, 1420.739, 1447.045, 1406.715, 1419.408, 1478.69,
> 1273.244, 1262.34, 1165.642, 787.8699, 657.2443, 617.5942, 672.4419,
> 562.5458, 600.0635, 553.3339, 581.2515, 686.7953, 448.5355, 1967.524,
> 968.7045, 1253.422, 1417.029, 1348.352, 607.6661, 795.2877, 1122.037,
> 951.7014, 1218.465, 1452.847, 1708.894, 1789.318, 1774.066, 1730.023,
> 1792.384, 1647.639, 1532.214, 1398.604, 1456.599, 1405.635, 1341.6,
> 1384.088, 1547.139, 1480.687, 1527.453, 1541.885, 1348.729, 1359.007,
> 1093.668, 1078.121, 1202.416, 895.9857, 1175.532, 1010.464, 967.2054,
> 851.1081, 740.4431, 930.6541, 1057.503, 1036.018, 1250.418, 1382.047,
> 278.5883, 278.6001, 278.6027, 278.6003, 278.5922, 278.5778, 278.555,
> 278.5205, 922.1713, 922.054, 922.0063, 967.21, 967.1343, 967.1157, 774.6002,
> 774.6443, 772.0591, 772.0382, 772.018, 870.8308, 870.8698, 904.8117,
> 825.425, 792.9547, 876.54, 882.7752, 681.8339, 775.945, 1081.869, 928.0758,
> 921.4498, 1079.74, 795.1276, 810.2282, 835.9764, 825.9167, 825.2587,
> 943.9789, 745.8108, 709.2183, 718.3409, 656.4478, 553.8104, 682.1406,
> 863.1352, 837.0597, 850.8278, 789.4566, 827.334, 813.5239, 723.0217,
> 808.3031, 871.0251, 1023.663, 1008.41, 1118.704, 1113.178, 907.1134,
> 726.4997, 1064.354, 1208.275, 1269.964, 1226.312, 834.8596, 952.5037,
> 1019.817, 922.9584, 886.3052, 898.9753, 868.3756, 869.4521, 105.3649,
> 407.1053, 136.8827, 722.5133, 841.0006, 706.9567, 542.9826, 198.147,
> 233.6965, 114.3593, 252.4854, 284.9101, 418.044, 215.6109, 543.6895,
> 654.181, 927.2443, 896.0264, 822.9401, 878.3534, 692.4314, 738.8477,
> 984.3605, 1069.655, 1022.925, 1002.807, 850.6902, 991.8134, 1034.01,
> 1148.745, 1142.539, 1163.838, 1275.52, 1145.691, 1460.11, 1377.891,
> 1306.395, 1304.617, 1278.456, 1378.95, 1374.073, 1449.972, 1184.909,
> 270.0509, 270.0623, 270.0648, 270.0624, 270.0547, 270.0407, 270.0186,
> 269.9851, 631.4337, 631.3534, 631.3207, 607.871, 607.8235, 607.8118,
> 570.1067, 570.1392, 471.9973, 471.9845, 471.9722, 374.8601, 374.8769,
> 482.6559, 509.4759, 259.6612, 601.047, 612.4909, 599.3603, 368.4525,
> 541.0823, 637.376, 572.6561, 520.8604, 602.978, 508.6731, 518.9494,
> 559.4774, 583.3226, 665.8262, 675.3377, 604.7722, 619.4575, 567.0582,
> 700.1987, 680.9487, 720.6385, 697.012, 662.4166, 683.2136, 659.8345,
> 667.4672, 707.6854, 743.7268, 858.9992, 832.3246, 779.6216, 698.0973,
> 703.4314, 791.7886, 726.9083, 854.6981, 834.7772, 832.3445, 812.7689,
> 727.6645, 652.1965, 826.9865, 849.4389, 811.6799, 850.7483, 832.3735,
> 819.6655, 1042.436, 720.7501, 952.0648, 1195, 848.0734, 976.9899, 1112.395,
> 1113.345, 1153.728, 805.5801, 646.0727, 617.1312, 791.8318, 847.233,
> 683.816, 724.7269, 911.1725, 827.3728, 995.0048, 800.6775, 879.0817,
> 972.6709, 799.3595, 1029.595, 1007.769, 852.9899, 837.8101, 941.9149,
> 982.4396, 979.9702, 967.2394, 937.1133, 960.9035, 908.2497, 996.8404,
> 1190.648, 1202.747, 1350.496, 1267.897, 1132.526, 1055.183, 799.7894,
> 639.9702, 769.6429, 769.6754, 769.6827, 769.676, 769.6537, 769.6139,
> 769.551, 769.4556, 499.9228, 499.8593, 499.8334, 1051.619, 1051.537,
> 1051.517, 1017.837, 1017.895, 787.5231, 787.5018, 787.4812, 127.3492,
> 127.3549, 240.9772, 248.1084, 400.2578, 663.3332, 986.2067, 936.059,
> 1061.159, 849.0998, 884.3383, 1183.185, 1208.31, 981.9471, 1076.72,
> 1124.325, 1008.958, 780.2723, 692.6738, 1044.181, 804.3527, 664.2988,
> 713.3538, 768.6463, 791.4983, 1408.636, 1460.505, 1331.472, 1436.979,
> 1223.143, 1192.528, 1165.123, 1187.325, 889.4554, 1755.404, 1539.565,
> 1367.623, 1197.647, 1204.832, 1253.376, 1064.125, 1221.669, 1063.684,
> 1029.96, 941.9225, 953.305, 1135.038, 995.6816, 1202.049, 1179.09, 1238.77,
> 1252.872, 195.4976, 796.9503, 1409.675, 2215.336, 1971.793, 1372.014,
> 1194.094, 990.832, 1240.13, 1272.831, 1110.265, 1083.954, 1277.695,
> 1224.066, 1216.931, 1036.133, 1275.89, 650.2736, 493.1569, 443.461,
> 457.3099, 492.6304, 514.841, 490.7231, 505.4785, 567.1318, 544.3971,
> 547.5244, 528.4097, 662.0999, 964.6831, 1006.148, 1102.357, 1207.62,
> 1272.277, 1173.155, 1125.227, 1039.502, 1074.456, 1146.245, 1429.14,
> 1246.974, 1215.329)
> , .Dim = c(114L, 5L)
> , .Dimnames = list(NULL, c("I1", "I2", "I3", "I4", "I5")))
>
> my.data.matrix.prod <- structure(c(2916.28, 1893.82, 1446.496, 1223.643,
> 1093.515, 1027.691, 1025.575, 1069.484, 1350.653, 1383.106, 1404.12,
> 3229.087, 3287.819, 3292.214, 3949.526, 3934.924, 1344.882, 1276.475,
> 1281.724, 2080.675, 2170.162, 2204.06, 2733.114, 2709.72, 1906.547,
> 2226.197, 2147.538, 2396.16, 2170.339, 2295.214, 2325.382, 2863.881,
> 2633.29, 2191.615, 1823.576, 2462.448, 2472.716, 2426.248, 2558.359,
> 1898.222, 2311.003, 2405.334, 2359.773, 2406.227, 2404.66, 2005.993,
> 2470.426, 2262.771, 2564.288, 2187.93, 2672.702, 2817.843, 2886.186,
> 3159.216, 3071.983, 3038.874, 3232.614, 3153.618, 3396.065, 3337.943,
> 3314.298, 3228.766, 3312.479, 3214.223, 2943.438, 3374.134, 3471.613,
> 3649.256, 1494.396, 2318.848, 2353.137, 1392.929, 2017.725, 2497.875,
> 2650.34, 2772.884, 2503.756, 2341.685, 2665.939, 2603.909, 2361.046,
> 2307.904, 2466.254, 2545.271, 2505.55, 2239.917, 2518.568, 2521.566,
> 2398.009, 1700.699, 1570.964, 2475.785, 2666.551, 2696.887, 2733.822,
> 2956.056, 2906.461, 2566.767, 2639.433, 2717.689, 2399.816, 2175.098,
> 2405.237, 2461.575, 2513.077, 2476.729, 2467.291, 2303.615, 2898.341,
> 2858.363, 3200.795, 3426.61, 3443.722, 3647.533, 195.3348, 176.5879,
> 161.8616, 147.6775, 132.3667, 116.3203, 100.9762, 90.91395, 102.5056,
> 111.2312, 119.294, 139.5639, 148.0501, 154.4379, 162.0608, 166.5477,
> 150.7256, 143.1064, 137.4059, 131.9734, 127.8249, 129.6863, 136.1022,
> 121.6995, 131.2575, 144.92, 150.0162, 140.1022, 146.21, 156.451, 158.8145,
> 162.6809, 164.6031, 156.6059, 150.636, 155.6411, 158.7302, 166.222,
> 171.0211, 162.1327, 161.2135, 156.3216, 162.0996, 166.6428, 175.9184,
> 176.8375, 178.7133, 178.7524, 179.3178, 176.1973, 180.4867, 187.3193,
> 199.2127, 209.983, 210.1795, 203.8254, 201.1218, 203.3554, 199.8475,
> 209.8946, 215.1455, 215.6018, 213.2702, 199.2345, 185.3278, 197.2057,
> 205.0727, 207.3002, 193.6611, 194.2139, 193.8643, 193.2228, 177.8776,
> 191.4582, 231.8191, 227.0726, 224.6594, 229.7895, 230.8227, 234.7284,
> 206.1662, 179.8467, 167.3609, 179.5722, 188.3897, 180.9705, 182.7036,
> 202.3105, 200.8232, 203.9204, 189.2181, 192.9931, 204.6493, 199.082,
> 215.5948, 223.7031, 213.8644, 202.6964, 208.5682, 216.1876, 217.9815,
> 217.007, 217.463, 221.4278, 218.8876, 228.6546, 247.8913, 255.3423,
> 274.8202, 276.3341, 269.6512, 262.6747, 239.2566, 213.2598, 196.0692,
> 179.3542, 174.4489, 179.1992, 193.516, 219.7416, 261.9235, 307.7595,
> 339.0413, 349.1725, 355.6877, 355.0119, 353.4153, 351.7466, 334.9937,
> 315.7924, 338.9163, 353.4399, 367.3095, 370.7577, 368.3222, 338.1546,
> 309.5753, 302.9909, 343.3383, 390.3582, 442.8708, 467.6517, 475.7294,
> 463.2386, 475.4719, 512.9818, 525.4725, 546.562, 555.4177, 539.306,
> 499.4974, 483.7216, 504.7977, 493.012, 470.5119, 433.9357, 442.8588,
> 456.0057, 512.4643, 550.1924, 558.0298, 564.4106, 550.0839, 538.8026,
> 530.6313, 523.3772, 495.919, 552.271, 570.1813, 559.772, 539.137, 531.285,
> 511.5488, 489.0468, 483.7139, 434.6737, 391.9633, 353.6852, 341.9161,
> 345.1014, 337.9316, 347.3225, 351.3463, 368.2297, 356.9464, 385.1567,
> 367.8657, 433.608, 567.5147, 609.7797, 502.3615, 441.0474, 421.461,
> 421.8376, 446.8344, 468.2683, 499.6648, 542.9484, 556.0471, 560.2142,
> 552.7231, 561.0404, 498.0082, 435.9498, 406.5746, 388.8749, 379.8109,
> 384.6039, 402.4961, 406.7456, 417.0511, 418.7817, 404.1004, 396.1866,
> 381.1434, 398.5426, 424.4879, 419.1766, 448.4539, 459.9056, 450.9682,
> 429.8293, 402.7214, 409.8873, 434.7366, 470.5877, 491.6042, 505.3956,
> 2379.811, 1683.061, 1348.136, 1183.511, 1096.342, 1063.209, 1083.307,
> 1137.872, 1698.039, 1777.531, 1824.798, 1990.391, 2049.531, 2094.436,
> 1982.723, 1974.184, 1931.659, 1916.844, 1909.946, 1859.683, 1768.624,
> 1733.896, 1644.874, 1566.683, 1802.985, 2026.399, 2002.01, 2095.246,
> 2341.096, 2261.631, 2337.393, 2534.549, 2322.27, 2333.124, 2367.872,
> 2336.886, 2235.952, 2284.032, 2240.623, 2144.319, 2069.301, 1946.398,
> 1910.047, 2043.538, 2433.989, 2556.197, 2578.596, 2568.367, 2534.411,
> 2478.992, 2395.445, 2468.419, 2459.169, 2850.418, 2889.555, 2898.655,
> 2802.34, 2630.252, 2451.473, 2667.949, 2813.618, 2777.629, 2657.484,
> 2226.911, 2225.193, 2366.028, 2296.084, 2321.493, 2335.952, 2351.763,
> 2347.124, 1576.808, 1743.489, 1847.67, 2869.197, 3040.427, 2686.383,
> 2409.108, 2028.894, 2091.013, 1932.818, 1923.021, 1920.55, 2171.707,
> 2086.544, 2304.832, 2344.914, 2685.513, 2448.996, 2252.836, 2147.083,
> 1971.758, 2033.175, 2196.932, 2353.921, 2357.346, 2326.293, 2178.859,
> 2293.083, 2341.083, 2452.64, 2557.318, 2645.425, 2778.83, 2744.436,
> 3066.146, 3070.198, 3004.751, 3008.488, 2991.268, 3074.413, 3159.114,
> 3126.801, 2823.369)
> , .Dim = c(114L, 4L)
> , .Dimnames = list(NULL, c("Q1", "Q2", "Q3", "Q4")))
>
> my.data.matrix.time <- structure(c(1, 1.944202, 3.803123, 6.203458,
> 9.420446, 14.03878, 21.35927, 30.4375, 44.67685, 52.77593, 60.875, 76.09375,
> 83.70312, 91.3125, 104.9416, 121.75, 136.9688, 144.5781, 152.1875, 167.4062,
> 182.625, 213.0625, 243.5, 273.9375, 304.375, 334.8125, 365.25, 395.6875,
> 426.125, 456.5625, 487, 517.4375, 547.875, 578.3125, 608.75, 639.1875,
> 669.625, 700.0625, 730.5, 760.9375, 791.375, 821.8125, 852.25, 882.6875,
> 913.125, 943.5625, 974, 1004.438, 1034.875, 1065.312, 1095.75, 1126.188,
> 1156.625, 1187.062, 1217.5, 1247.938, 1278.375, 1308.812, 1339.25, 1369.688,
> 1400.125, 1430.562, 1461, 1491.438, 1521.875, 1552.312, 1582.75, 1613.188,
> 1643.625, 1674.062, 1704.5, 1734.938, 1765.375, 1795.812, 1826.25, 1856.688,
> 1887.125, 1917.562, 1948, 1978.438, 2008.875, 2039.312, 2069.75, 2100.188,
> 2130.625, 2161.062, 2191.5, 2221.938, 2252.375, 2282.812, 2313.25, 2343.688,
> 2374.125, 2404.562, 2435, 2465.438, 2495.875, 2526.312, 2556.75, 2587.188,
> 2617.625, 2648.062, 2678.5, 2708.938, 2739.375, 2769.812, 2800.25, 2830.688,
> 2861.125, 2891.562, 2922, 2952.438, 2982.875, 3013.312)
> , .Dim = c(114L, 1L)
> , .Dimnames = list( NULL, "time"))
>
> my.data.var <- c( 10, 0.25, 0.25, 0.25, 0.25, 0.25
>                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>                 , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>                 )
>
> my.data.qo <- c( 5990, 150, 199, 996 )   #Pre-Waterflood Production
> my.data.timet0 <- 0 # starting condition for time
>
> #FUNCTION
> Qjk.Cal.func <- function( my.data.timet0
>                         , my.data.qo
>                         , my.data.matrix.time
>                         , my.data.matrix.inj
>                         , my.data.matrix.prod
>                         , my.data.var
>                         , my.data.var.mat
>                         )
> {
>
>     qjk.cal.matrix <- matrix(
>                             , nrow = nrow( my.data.matrix.prod )
>                             , ncol = ncol( my.data.matrix.prod )
>                             )
>
>     count <- 1
>     number <- 1
>     # loop through all PROD wells columns
>     for ( colnum in 1:ncol( my.data.matrix.prod ) ) {
>          # "sum" is a very bad choice of variable name
>          # as it is a commonly-used base function
>         sum <- 0 # this initialization is redundant see below
>         #loop through all the rows
>         for( row in 1:nrow( my.data.matrix.prod ) ) {
>             sum <- 0 # most frequent re-initialization
>             deltaT <- 0
>             expo <- 0
>
>             #loop through all the injector columns to get the PRODUCT SUM
>             for( column in 1:ncol( my.data.matrix.inj ) ) {
>                 sum <- ( sum
>                        +   my.data.matrix.inj[ row, column ]
>                          * my.data.var.mat[ colnum, number+column ]
>                        )
>             }
>
>             if ( count < 2 ) {
>                 deltaT <- my.data.matrix.time[ row ]
>             } else {
>                 deltaT <- ( my.data.matrix.time[ row ]
>                           - my.data.matrix.time[ row - 1 ]
>                           )
>             }
>
>             expo <- exp( -deltaT / my.data.var.mat[ colnum, 1 ] )
>             # change here too
>
>             if ( count < 2 ) {
>                  qjk.cal.matrix[ row, colnum ] <-
>                         my.data.qo[ colnum ] * expo + ( 1 - expo ) * sum
>             } else {
>                 qjk.cal.matrix[ row, colnum ] <-
>                         (   qjk.cal.matrix[ row - 1, colnum ] * expo
>                         + ( 1 - expo ) * sum
>                         )
>             }
>             count <- count + 1
>         }
>
>         count <- 1
>     }
>
>     # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>     qjk.cal.matrix
> }
>
> Error.func <- function( my.data.var ) {
>     #First convert vector(my.data.var) to MATRIX
>     # and send it to calculate new MATRIX
>     my.data.var.mat <- matrix( my.data.var
>                              , nrow = ncol( my.data.matrix.prod )
>                              , ncol = ncol( my.data.matrix.inj ) + 1
>                              , byrow = TRUE
>                              )
>
>     Calc.Qjk.Value <- Qjk.Cal.func( my.data.timet0
>                                   , my.data.qo
>                                   , my.data.matrix.time
>                                   , my.data.matrix.inj
>                                   , my.data.matrix.prod
>                                   , my.data.var
>                                   , my.data.var.mat
>                                   )
>
>     #FIND DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>     diff.values <- my.data.matrix.prod - Calc.Qjk.Value
>
>     #sum of square root of the diff
>     Error <- ( ( colSums( ( diff.values^2 )
>                         , na.rm = FALSE
>                         , dims = 1
>                         )
>                ) / nrow( my.data.matrix.inj )
>              )^0.5
>     #print(paste(Error))
>
>     # total avg error
>     Error_total <- sum( Error
>                       , na.rm=FALSE
>                       ) / ncol( my.data.matrix.prod )
>
>     Error_total
> }
>
> n <- ncol( my.data.matrix.prod )
> m <- ncol( my.data.matrix.inj )
> k <- ( 1 + n ) * m
> ciA <- numeric( k )
> uiA <- array( 0, dim = c( m+1, n, k ) )
> ia <- 0
> #Aoff2 <- (m+1) * n
> for ( i in seq.int( m ) ) {
>     ia <- ia + 1L
>     # sum of columns <= 1
>     uiA[ i+1, , i ] <- -1
>     ciA[ ia ] <- -1
> }
> for ( i in ( 1 + seq.int( m ) ) ) {
>     for ( j in seq.int( n ) ) {
>         ia <- ia + 1L
>         # elements > 0
>         uiA[ i, j, ia ] <- 1
>         ciA[ ia ] <- 0
>     }
> }
> uiA <- matrix( uiA, nrow = k, byrow = TRUE )
>
> my.data.varA <- c( 10, 0.25, 0.25, 0.25, 0.25, 0.25
>                  , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>                  , 10, 0.25, 0.25, 0.25, 0.25, 0.25
>                  , 10, 0.24, 0.24, 0.24, 0.24, 0.24
>                  )
> # interior?
> all( uiA %*% my.data.var1 - (ciA) > 0 )
>
> sols <- constrOptim( my.data.varA
>                    , Error.func
>                    , NULL
>                    , ui = uiA
>                    , ci = ciA
>                    , method = "SANN"
>                    )
> # meets constraint?
> all( uiA %*% sols$par - (ciA) >= 0 )
>
> sols
> ##########################
>
>
> On Sun, 19 Jun 2016, Priyank Dwivedi wrote:
>
>> All,
>> Here are the dput files of the input data to the code.
>>
>> Thanks for any advice.
>>
>> I am adding the entire code below too just in case.
>>
>>
>> file <- file.path("Learning R","CRM_R_Ver4.xlsx")
>> file
>> my.data <- readWorksheetFromFile(file,sheet=1,startRow=1)
>> str(my.data)  # DATA FRAME
>> my.data.matrix.inj <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
>> my.data.matrix.inj
>>
>> dput(my.data.matrix.inj,"my.data.matrix.inj.txt")
>>
>>
>> my.data.2 <- readWorksheetFromFile(file,sheet=2,startRow=1)
>> str(my.data.2)  # DATA FRAME
>> my.data.matrix.time <- as.matrix(my.data.2)  #convert DATA FRAME to MATRIX
>> my.data.matrix.time
>>
>> dput(my.data.matrix.time,"my.data.matrix.time.txt")
>>
>> my.data <- readWorksheetFromFile(file,sheet=3,startRow=1)
>> str(my.data)  # DATA FRAME
>> my.data.matrix.prod <- as.matrix(my.data)  #convert DATA FRAME to MATRIX
>> my.data.matrix.prod
>>
>> dput(my.data.matrix.prod,"my.data.matrix.prod.txt")
>>
>> # my.data.var <- vector("numeric",length = 24)
>> # my.data.var
>>
>> my.data.var <- c(10,0.25,0.25,0.25,0.25,0.25,
>>                 10,0.25,0.25,0.25,0.25,0.25,
>>                 10,0.25,0.25,0.25,0.25,0.25,
>>                 10,0.25,0.25,0.25,0.25,0.25)
>> my.data.var
>>
>> dput(my.data.var,"my.data.var.txt")
>>
>>
>> my.data.qo <- c(5990,150,199,996)   #Pre-Waterflood Production
>> my.data.timet0 <- 0 # starting condition for time
>>
>> #FUNCTION
>> Qjk.Cal.func <- function(my.data.timet0,my.data.qo,my.data.matrix.time,
>>                         my.data.matrix.inj,
>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>> {
>>
>>  qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>> ncol=ncol(my.data.matrix.prod))
>>
>>  count <- 1
>>  number <- 1
>>  for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
>> wells columns
>>  {
>>    sum <-0
>>    for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
>>    {
>>      sum <-0
>>      deltaT <-0
>>      expo <-0
>>
>>
>>        for(column in 1:ncol(my.data.matrix.inj)) #loop through all
>> the injector columns to get the PRODUCT SUM
>>         {
>>            sum = sum +
>> my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>>         }
>>
>>      if(count<2)
>>      {
>>        deltaT<- my.data.matrix.time[row]
>>      }
>>      else
>>      {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>>
>>
>>      expo <- exp(-deltaT/my.data.var.mat[colnum,1])
>> # change here too
>>
>>      if(count<2)
>>      {
>>        qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo + (1-expo)*sum
>>      }
>>      else
>>      {
>>        qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
>> (1-expo)*sum
>>      }
>>      count <- count+1
>>    }
>>
>>    count <-1
>>  }
>>
>>  qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>>
>> }
>>
>>
>> # ERROR FUNCTION - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
>> MATRIX. Miminize the Error by changing my.data.var
>>
>> Error.func <- function(my.data.var)
>> {
>>  #First convert vector(my.data.var) to MATRIX aand send it to
>> calculate new MATRIX
>>  my.data.var.mat <- matrix(my.data.var,nrow =
>> ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow =
>> TRUE)
>>
>>  Calc.Qjk.Value <-
>> Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>>                                 my.data.matrix.inj,
>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>
>>
>>  diff.values <- my.data.matrix.prod-Calc.Qjk.Value    #FIND
>> DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>>
>>
>>  Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>> 1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>>  print(paste(Error))
>>
>>  Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
>> total avg error
>>
>>
>>  Error_total
>> }
>>
>> # OPTIMIZE
>>
>>
>> sols<-optim(my.data.var,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1),
>>      lower=c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))
>>
>> sols
>>
>> On 17 June 2016 at 16:55, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>
>>> Your code is corrupt because you failed to send your email in plain text
>>> format.
>>>
>>> You also don't appear to have all data needed to reproduce the problem.
>>> Use
>>> the dput function to generate R code form of a sample of your data.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On June 17, 2016 1:07:21 PM PDT, Priyank Dwivedi <dpriyank23 at gmail.com>
>>> wrote:
>>>>
>>>>
>>>> By mistake, I sent it earlier to the wrong address.
>>>>
>>>> ---------- Forwarded message ----------
>>>> From: Priyank Dwivedi <dpriyank23 at gmail.com>
>>>> Date: 17 June 2016 at 14:50
>>>> Subject: Matrix Constraints in R Optim
>>>> To: r-help-owner at r-project.org
>>>>
>>>>
>>>> Hi,
>>>>
>>>> Below is the code snippet I wrote in R:
>>>>
>>>> The basic idea is to minimize error by optimizing set of values (in this
>>>> scenario 12) in the form of a matrix. I defined the matrix elements as
>>>> vector "*my.data.var" * and then stacked it into a matrix called
>>>> "*my.data.var.mat"
>>>> in the error function. *
>>>>
>>>> The only part that I can't figure out is "what if the column sum in
>>>> the *my.data.var.mat
>>>> needs to be <=1"; that's the constraint/s.. Where do I introduce it in
>>>> the
>>>> OPTIM solver or elsewhere?*
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> *my.data.matrix.inj* <- as.matrix(my.data)  #convert DATA FRAME to
>>>> MATRIX
>>>> my.data.matrix.inj
>>>>
>>>>
>>>> *my.data.matrix.time* <- as.matrix(my.data.2)  #convert DATA FRAME to
>>>> MATRIX
>>>> my.data.matrix.time
>>>>
>>>>
>>>> *my.data.matrix.prod* <- as.matrix(my.data)  #convert DATA FRAME to
>>>> MATRIX
>>>> my.data.matrix.prod
>>>>
>>>>
>>>> *my.data.var* <-
>>>>
>>>>
>>>> c(2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01,2,0.8,0.5,0.2,0.2,0.1,10,0.01,0.02,0.2,0.1,0.01)
>>>> my.data.var
>>>>
>>>> *my.data.qo* <- c(5990,150,199,996)   #Pre-Waterflood Production
>>>>
>>>> *my.data.timet0* <- 0 # starting condition for time
>>>>
>>>>
>>>> *#FUNCTIONQjk.Cal.func* <-
>>>>
>>>> function(my.data.timet0,my.data.qo,my.data.matrix.time,
>>>>                          my.data.matrix.inj,
>>>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>>> {
>>>>
>>>>   qjk.cal.matrix <- matrix(,nrow = nrow(my.data.matrix.prod),
>>>> ncol=ncol(my.data.matrix.prod))
>>>>
>>>>   count <- 1
>>>>   number <- 1
>>>>   for(colnum in 1:ncol(my.data.matrix.prod))   # loop through all PROD
>>>> wells columns
>>>>   {
>>>>     sum <-0
>>>>     for(row in 1:nrow(my.data.matrix.prod)) #loop through all the rows
>>>>     {
>>>>       sum <-0
>>>>       deltaT <-0
>>>>       expo <-0
>>>>
>>>>
>>>>         for(column in 1:ncol(my.data.matrix.inj)) #loop through all the
>>>> injector columns to get the PRODUCT SUM
>>>>          {
>>>>             sum = sum +
>>>> my.data.matrix.inj[row,column]*my.data.var.mat[colnum,number+column]
>>>>          }
>>>>
>>>>       if(count<2)
>>>>       {
>>>>         deltaT<- my.data.matrix.time[row]
>>>>       }
>>>>       else
>>>>       {deltaT <- my.data.matrix.time[row]-my.data.matrix.time[row-1]}
>>>>
>>>>
>>>>       expo <- exp(-deltaT/my.data.var.mat[colnum,1])                  #
>>>> change here too
>>>>
>>>>       if(count<2)
>>>>       {
>>>>         qjk.cal.matrix[row,colnum] = my.data.qo[colnum]*expo +
>>>> (1-expo)*sum
>>>>
>>>>  }
>>>>       else
>>>>       {
>>>>         qjk.cal.matrix[row,colnum]=qjk.cal.matrix[row-1,colnum]*expo +
>>>> (1-expo)*sum
>>>>       }
>>>>       count <- count+1
>>>>     }
>>>>
>>>>     count <-1
>>>>   }
>>>>
>>>>   qjk.cal.matrix      # RETURN CALCULATED MATRIX TO THE ERROR FUNCTION
>>>>
>>>> }
>>>>
>>>>
>>>> *# ERROR FUNCTION* - FINDS DIFFERENCE BETWEEN CAL. MATRIX AND ORIGINAL
>>>> MATRIX. Miminize the Error by changing my.data.var
>>>>
>>>> *Error.func* <- function(my.data.var)
>>>> {
>>>>   #First convert vector(my.data.var) to MATRIX aand send it to calculate
>>>> new MATRIX
>>>>   *my.data.var.mat* <- matrix(my.data.var,nrow =
>>>> ncol(my.data.matrix.prod),ncol = ncol(my.data.matrix.inj)+1,byrow =
>>>> TRUE)
>>>>
>>>> *  Calc.Qjk.Value* <-
>>>> Qjk.Cal.func(my.data.timet0,my.data.qo,my.data.matrix.time,
>>>>                                  my.data.matrix.inj,
>>>> my.data.matrix.prod,my.data.var,my.data.var.mat)
>>>>
>>>>
>>>>   diff.values <-
>>>> my.data.matrix.prod-Calc.Qjk.Value    #FIND DIFFERENCE
>>>> BETWEEN CAL. MATRIX AND ORIGINAL MATRIX
>>>>
>>>>
>>>>   Error <- ((colSums ((diff.values^2), na.rm = FALSE, dims =
>>>> 1))/nrow(my.data.matrix.inj))^0.5    #sum of square root of the diff
>>>>   print(paste(Error))
>>>>
>>>>   Error_total <- sum(Error,na.rm=FALSE)/ncol(my.data.matrix.prod)   #
>>>> total
>>>> avg error
>>>>
>>>>
>>>>  * Error_total*
>>>> }
>>>>
>>>> # OPTIMIZE
>>>>
>>>> *optim*(*my.data.var*
>>>>
>>>>
>>>> ,Error.func,method="L-BFGS-B",upper=c(Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1,Inf,1,1,1,1,1))
>>>>
>>>>
>>>
>>
>>
>>
>> --
>> Best Regards,
>> Priyank Dwivedi
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------



-- 
Best Regards,
Priyank Dwivedi


From 9add2 at queensu.ca  Wed Jun 22 00:57:54 2016
From: 9add2 at queensu.ca (Alice Domalik)
Date: Tue, 21 Jun 2016 22:57:54 +0000
Subject: [R] filtering data by the time stamp
Message-ID: <SN2PR07MB26381BD777E83FE2B16055BBD02B0@SN2PR07MB2638.namprd07.prod.outlook.com>

Hi List,


I'm working with some bird GPS tracking data, and I would like to exclude points based on the time stamp.

Some background information- the GPS loggers track each bird for just over 24 hours, starting in the evening, and continuing through the night and the following day. What I would like to do is exclude points taken after 21:30 on the day AFTER deployment (but retain points between 21:30 and 23:59 on the day of deployment).

My data is set up like this:

birdID           x                     y                  datetime
15K11          492719.9        5634805      2015-06-23 18:25:00

I've tried running the code posted below.
The idea is to use the function "mutate" to create a new variable called newdate that takes the earliest observation for each bird and sets the date for cutoff as the next day at 21:30:00.

library(dplyr); library(lubridate)

df %>%
  group_by(birdID) %>%
  mutate(newdate=as.POSIXct(date(min(datetime)) + days(1) + hours(21) + minutes(30))) %>%
  filter(datetime<newdate)

R runs the code, but it doesn't actually change the data frame. I've double checked that "datetime" is POSIXct. I've also tried running the code without the the last line to check if R will at least create the new column "newdate", but it doesn't.
Any insight into why my code isn't working?

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun 22 06:07:17 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Jun 2016 21:07:17 -0700
Subject: [R] filtering data by the time stamp
In-Reply-To: <SN2PR07MB26381BD777E83FE2B16055BBD02B0@SN2PR07MB2638.namprd07.prod.outlook.com>
References: <SN2PR07MB26381BD777E83FE2B16055BBD02B0@SN2PR07MB2638.namprd07.prod.outlook.com>
Message-ID: <10ABFD32-5C3A-435B-8EA9-E0B160F5859E@dcn.davis.ca.us>

This is normal. R is a (mostly) functional language, which means functions normally don't have side effects like changing input data. 

Try saving the result of your function calls in a new object. 
-- 
Sent from my phone. Please excuse my brevity.

On June 21, 2016 3:57:54 PM PDT, Alice Domalik <9add2 at queensu.ca> wrote:
>Hi List,
>
>
>I'm working with some bird GPS tracking data, and I would like to
>exclude points based on the time stamp.
>
>Some background information- the GPS loggers track each bird for just
>over 24 hours, starting in the evening, and continuing through the
>night and the following day. What I would like to do is exclude points
>taken after 21:30 on the day AFTER deployment (but retain points
>between 21:30 and 23:59 on the day of deployment).
>
>My data is set up like this:
>
>birdID           x                     y                  datetime
>15K11          492719.9        5634805      2015-06-23 18:25:00
>
>I've tried running the code posted below.
>The idea is to use the function "mutate" to create a new variable
>called newdate that takes the earliest observation for each bird and
>sets the date for cutoff as the next day at 21:30:00.
>
>library(dplyr); library(lubridate)
>
>df %>%
>  group_by(birdID) %>%
>mutate(newdate=as.POSIXct(date(min(datetime)) + days(1) + hours(21) +
>minutes(30))) %>%
>  filter(datetime<newdate)
>
>R runs the code, but it doesn't actually change the data frame. I've
>double checked that "datetime" is POSIXct. I've also tried running the
>code without the the last line to check if R will at least create the
>new column "newdate", but it doesn't.
>Any insight into why my code isn't working?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Wed Jun 22 07:05:02 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 22 Jun 2016 05:05:02 +0000
Subject: [R] [FORGED] Ask function missing in package car
In-Reply-To: <CAC8=1eq2M1X4Tk1uwLJ14JU7bSsPvPZDB31jb9Vi0t_AfT66GA@mail.gmail.com>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
	<CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
	<356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>
	<CAC8=1eq2M1X4Tk1uwLJ14JU7bSsPvPZDB31jb9Vi0t_AfT66GA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83653189D@FHSDB4H16-2.csu.mcmaster.ca>

Dear Ashim and Marc,

Sorry to chime in late. As Marc suggests, the Ask() function went the way of the dodo before the second edition of the book (coauthored with Sandy Weisberg, and retitled "An R Companion to Applied Regression") was published. 

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> Kapoor
> Sent: June 21, 2016 7:35 PM
> To: Marc Schwartz <marc_schwartz at me.com>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] [FORGED] Ask function missing in package car
> 
> Dear Mark,
> 
> Many thanks.
> 
> Best Regards,
> Ashim
> 
> On Wed, Jun 22, 2016 at 7:45 AM, Marc Schwartz <marc_schwartz at me.com>
> wrote:
> 
> > According to the NEWS file for the package:
> >
> >   https://cran.r-project.org/web/packages/car/NEWS
> >
> > the Ask() function was removed in car version 2.0-0, which was
> > released on 2010-07-26. So it has been gone for about 6 years.
> >
> > The version of car that is used in the documentation that you are
> > using is 1.2-16, which is from 2009-10-11.
> >
> > So the online documentation source is outdated.
> >
> > I see that the Ask() function is listed in the first edition of John's
> > book, which I have on my shelf, but I don't have the second edition to
> > know if that had been updated. A review of the index for the second
> > edition on Amazon.com would suggest that it was removed for the second
> edition.
> >
> > Regards,
> >
> > Marc Schwartz
> >
> >
> > > On Jun 21, 2016, at 8:29 PM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> > >
> > > I am reading the book An R and S plus companion to Applied
> > > Regression
> > and I
> > > found this function there.
> > >
> > > Googling gave me the link [1].
> > >
> > > 1. http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html
> > >
> > > On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner
> > > <r.turner at auckland.ac.nz>
> > > wrote:
> > >
> > >> On 22/06/16 13:06, Ashim Kapoor wrote:
> > >>
> > >>> Dear All,
> > >>>
> > >>> my details:-
> > >>>
> > >>>> sessionInfo()
> > >>>>
> > >>> R version 3.3.0 (2016-05-03)
> > >>> Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 15.10
> > >>>
> > >>> locale:
> > >>> [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
> > >>> [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
> > >>> [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
> > >>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN
> LC_IDENTIFICATION=C
> > >>>
> > >>> attached base packages:
> > >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> > >>>
> > >>> other attached packages:
> > >>> [1] car_2.1-2
> > >>>
> > >>> loaded via a namespace (and not attached):
> > >>> [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
> > >>> grid_3.3.0
> > >>> [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
> > >>> minqa_1.2.4
> > >>> [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
> > >>> lme4_1.1-12
> > >>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
> > >>> nnet_7.3-10
> > >>> [17] quantreg_5.24
> > >>>
> > >>>>
> > >>>>
> > >>>    ## Not run:
> > >>>> attach(UN)
> > >>>>
> > >>>> # enter the power-transformation parameter # start with 1 Ask(p,
> > >>>> function(p) qq.plot(box.cox(gdp, p),
> > >>>>
> > >>> +         ylab=paste("transformed gdp, power =",p)))
> > >>> Error: could not find function "Ask"
> > >>>
> > >>>>
> > >>>>
> > >>> What can I do to correct this?
> > >>>
> > >>
> > >> What led you to believe that such a function exists (in the "car"
> > package
> > >> or anywhere else for that matter)?  And what exactly do you want it
> > >> to
> > do
> > >> for you?
> > >>
> > >> cheers,
> > >>
> > >> Rolf Turner
> > >>
> > >> --
> > >> Technical Editor ANZJS
> > >> Department of Statistics
> > >> University of Auckland
> > >> Phone: +64-9-373-7599 ext. 88276
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Wed Jun 22 07:10:09 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 22 Jun 2016 10:40:09 +0530
Subject: [R] [FORGED] Ask function missing in package car
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83653189D@FHSDB4H16-2.csu.mcmaster.ca>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
	<CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
	<356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>
	<CAC8=1eq2M1X4Tk1uwLJ14JU7bSsPvPZDB31jb9Vi0t_AfT66GA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653189D@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <CAC8=1eqFCKkHWeBAo9wxXUmE01TEtqY=TSz9A9jM_fobswz1iw@mail.gmail.com>

Dear Sir,

Many thanks for your reply. May I ask,was it replaced by another similar
function? It seems interesting enough to have a function like that.

Best Regards,
Ashim

On Wed, Jun 22, 2016 at 10:35 AM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Ashim and Marc,
>
> Sorry to chime in late. As Marc suggests, the Ask() function went the way
> of the dodo before the second edition of the book (coauthored with Sandy
> Weisberg, and retitled "An R Companion to Applied Regression") was
> published.
>
> Best,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> > Kapoor
> > Sent: June 21, 2016 7:35 PM
> > To: Marc Schwartz <marc_schwartz at me.com>
> > Cc: R-help <r-help at r-project.org>
> > Subject: Re: [R] [FORGED] Ask function missing in package car
> >
> > Dear Mark,
> >
> > Many thanks.
> >
> > Best Regards,
> > Ashim
> >
> > On Wed, Jun 22, 2016 at 7:45 AM, Marc Schwartz <marc_schwartz at me.com>
> > wrote:
> >
> > > According to the NEWS file for the package:
> > >
> > >   https://cran.r-project.org/web/packages/car/NEWS
> > >
> > > the Ask() function was removed in car version 2.0-0, which was
> > > released on 2010-07-26. So it has been gone for about 6 years.
> > >
> > > The version of car that is used in the documentation that you are
> > > using is 1.2-16, which is from 2009-10-11.
> > >
> > > So the online documentation source is outdated.
> > >
> > > I see that the Ask() function is listed in the first edition of John's
> > > book, which I have on my shelf, but I don't have the second edition to
> > > know if that had been updated. A review of the index for the second
> > > edition on Amazon.com would suggest that it was removed for the second
> > edition.
> > >
> > > Regards,
> > >
> > > Marc Schwartz
> > >
> > >
> > > > On Jun 21, 2016, at 8:29 PM, Ashim Kapoor <ashimkapoor at gmail.com>
> > wrote:
> > > >
> > > > I am reading the book An R and S plus companion to Applied
> > > > Regression
> > > and I
> > > > found this function there.
> > > >
> > > > Googling gave me the link [1].
> > > >
> > > > 1. http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html
> > > >
> > > > On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner
> > > > <r.turner at auckland.ac.nz>
> > > > wrote:
> > > >
> > > >> On 22/06/16 13:06, Ashim Kapoor wrote:
> > > >>
> > > >>> Dear All,
> > > >>>
> > > >>> my details:-
> > > >>>
> > > >>>> sessionInfo()
> > > >>>>
> > > >>> R version 3.3.0 (2016-05-03)
> > > >>> Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 15.10
> > > >>>
> > > >>> locale:
> > > >>> [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
> > > >>> [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
> > > >>> [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
> > > >>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN
> > LC_IDENTIFICATION=C
> > > >>>
> > > >>> attached base packages:
> > > >>> [1] stats     graphics  grDevices utils     datasets  methods
>  base
> > > >>>
> > > >>> other attached packages:
> > > >>> [1] car_2.1-2
> > > >>>
> > > >>> loaded via a namespace (and not attached):
> > > >>> [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
> > > >>> grid_3.3.0
> > > >>> [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
> > > >>> minqa_1.2.4
> > > >>> [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
> > > >>> lme4_1.1-12
> > > >>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
> > > >>> nnet_7.3-10
> > > >>> [17] quantreg_5.24
> > > >>>
> > > >>>>
> > > >>>>
> > > >>>    ## Not run:
> > > >>>> attach(UN)
> > > >>>>
> > > >>>> # enter the power-transformation parameter # start with 1 Ask(p,
> > > >>>> function(p) qq.plot(box.cox(gdp, p),
> > > >>>>
> > > >>> +         ylab=paste("transformed gdp, power =",p)))
> > > >>> Error: could not find function "Ask"
> > > >>>
> > > >>>>
> > > >>>>
> > > >>> What can I do to correct this?
> > > >>>
> > > >>
> > > >> What led you to believe that such a function exists (in the "car"
> > > package
> > > >> or anywhere else for that matter)?  And what exactly do you want it
> > > >> to
> > > do
> > > >> for you?
> > > >>
> > > >> cheers,
> > > >>
> > > >> Rolf Turner
> > > >>
> > > >> --
> > > >> Technical Editor ANZJS
> > > >> Department of Statistics
> > > >> University of Auckland
> > > >> Phone: +64-9-373-7599 ext. 88276
> > >
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Jun 22 07:17:22 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 22 Jun 2016 05:17:22 +0000
Subject: [R] [FORGED] Ask function missing in package car
In-Reply-To: <CAC8=1eqFCKkHWeBAo9wxXUmE01TEtqY=TSz9A9jM_fobswz1iw@mail.gmail.com>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
	<CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
	<356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>
	<CAC8=1eq2M1X4Tk1uwLJ14JU7bSsPvPZDB31jb9Vi0t_AfT66GA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653189D@FHSDB4H16-2.csu.mcmaster.ca>
	<CAC8=1eqFCKkHWeBAo9wxXUmE01TEtqY=TSz9A9jM_fobswz1iw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836531900@FHSDB4H16-2.csu.mcmaster.ca>

Dear Ashim,

> -----Original Message-----
> From: Ashim Kapoor [mailto:ashimkapoor at gmail.com]
> Sent: June 21, 2016 10:10 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Marc Schwartz <marc_schwartz at me.com>; R-help <r-help at r-project.org>
> Subject: Re: [R] [FORGED] Ask function missing in package car
> 
> Dear Sir,
> 
> 
> Many thanks for your reply. May I ask,was it replaced by another similar
> function? 

No.

> It seems interesting enough to have a function like that.

I guess it didn't seem that useful to us. You can simply modify commands in a programming editor.

Best,
 John

> 
> 
> Best Regards,
> 
> Ashim
> 
> 
> On Wed, Jun 22, 2016 at 10:35 AM, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Ashim and Marc,
> 
> 	Sorry to chime in late. As Marc suggests, the Ask() function went the
> way of the dodo before the second edition of the book (coauthored with Sandy
> Weisberg, and retitled "An R Companion to Applied Regression") was
> published.
> 
> 	Best,
> 	 John
> 
> 	-----------------------------
> 	John Fox, Professor
> 	McMaster University
> 	Hamilton, Ontario
> 	Canada L8S 4M4
> 	Web: socserv.mcmaster.ca/jfox <http://socserv.mcmaster.ca/jfox>
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] On Behalf Of Ashim
> 	> Kapoor
> 	> Sent: June 21, 2016 7:35 PM
> 	> To: Marc Schwartz <marc_schwartz at me.com
> <mailto:marc_schwartz at me.com> >
> 	> Cc: R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
> 	> Subject: Re: [R] [FORGED] Ask function missing in package car
> 	>
> 	> Dear Mark,
> 	>
> 	> Many thanks.
> 	>
> 	> Best Regards,
> 	> Ashim
> 	>
> 	> On Wed, Jun 22, 2016 at 7:45 AM, Marc Schwartz
> <marc_schwartz at me.com <mailto:marc_schwartz at me.com> >
> 	> wrote:
> 	>
> 	> > According to the NEWS file for the package:
> 	> >
> 	> >   https://cran.r-project.org/web/packages/car/NEWS
> 	> >
> 	> > the Ask() function was removed in car version 2.0-0, which was
> 	> > released on 2010-07-26. So it has been gone for about 6 years.
> 	> >
> 	> > The version of car that is used in the documentation that you are
> 	> > using is 1.2-16, which is from 2009-10-11.
> 	> >
> 	> > So the online documentation source is outdated.
> 	> >
> 	> > I see that the Ask() function is listed in the first edition of John's
> 	> > book, which I have on my shelf, but I don't have the second edition
> to
> 	> > know if that had been updated. A review of the index for the second
> 	> > edition on Amazon.com would suggest that it was removed for the
> second
> 	> edition.
> 	> >
> 	> > Regards,
> 	> >
> 	> > Marc Schwartz
> 	> >
> 	> >
> 	> > > On Jun 21, 2016, at 8:29 PM, Ashim Kapoor
> <ashimkapoor at gmail.com <mailto:ashimkapoor at gmail.com> >
> 	> wrote:
> 	> > >
> 	> > > I am reading the book An R and S plus companion to Applied
> 	> > > Regression
> 	> > and I
> 	> > > found this function there.
> 	> > >
> 	> > > Googling gave me the link [1].
> 	> > >
> 	> > > 1. http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html
> 	> > >
> 	> > > On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner
> 	> > > <r.turner at auckland.ac.nz <mailto:r.turner at auckland.ac.nz> >
> 	> > > wrote:
> 	> > >
> 	> > >> On 22/06/16 13:06, Ashim Kapoor wrote:
> 	> > >>
> 	> > >>> Dear All,
> 	> > >>>
> 	> > >>> my details:-
> 	> > >>>
> 	> > >>>> sessionInfo()
> 	> > >>>>
> 	> > >>> R version 3.3.0 (2016-05-03)
> 	> > >>> Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu
> 15.10
> 	> > >>>
> 	> > >>> locale:
> 	> > >>> [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
> 	> > >>> [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN
> LC_MESSAGES=en_IN
> 	> > >>> [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
> 	> > >>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN
> 	> LC_IDENTIFICATION=C
> 	> > >>>
> 	> > >>> attached base packages:
> 	> > >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> 	> > >>>
> 	> > >>> other attached packages:
> 	> > >>> [1] car_2.1-2
> 	> > >>>
> 	> > >>> loaded via a namespace (and not attached):
> 	> > >>> [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
> 	> > >>> grid_3.3.0
> 	> > >>> [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
> 	> > >>> minqa_1.2.4
> 	> > >>> [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
> 	> > >>> lme4_1.1-12
> 	> > >>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
> 	> > >>> nnet_7.3-10
> 	> > >>> [17] quantreg_5.24
> 	> > >>>
> 	> > >>>>
> 	> > >>>>
> 	> > >>>    ## Not run:
> 	> > >>>> attach(UN)
> 	> > >>>>
> 	> > >>>> # enter the power-transformation parameter # start with 1
> Ask(p,
> 	> > >>>> function(p) qq.plot(box.cox(gdp, p),
> 	> > >>>>
> 	> > >>> +         ylab=paste("transformed gdp, power =",p)))
> 	> > >>> Error: could not find function "Ask"
> 	> > >>>
> 	> > >>>>
> 	> > >>>>
> 	> > >>> What can I do to correct this?
> 	> > >>>
> 	> > >>
> 	> > >> What led you to believe that such a function exists (in the "car"
> 	> > package
> 	> > >> or anywhere else for that matter)?  And what exactly do you
> want it
> 	> > >> to
> 	> > do
> 	> > >> for you?
> 	> > >>
> 	> > >> cheers,
> 	> > >>
> 	> > >> Rolf Turner
> 	> > >>
> 	> > >> --
> 	> > >> Technical Editor ANZJS
> 	> > >> Department of Statistics
> 	> > >> University of Auckland
> 	> > >> Phone: +64-9-373-7599 ext. 88276
> 	> >
> 	> >
> 	>
> 
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> ______________________________________________
> 	> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list --
> To UNSUBSCRIBE and more, see
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-project.org/posting-
> 	> guide.html
> 	> and provide commented, minimal, self-contained, reproducible code.
> 
> 


From ashimkapoor at gmail.com  Wed Jun 22 07:34:44 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 22 Jun 2016 11:04:44 +0530
Subject: [R] [FORGED] Ask function missing in package car
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836531900@FHSDB4H16-2.csu.mcmaster.ca>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
	<CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
	<356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>
	<CAC8=1eq2M1X4Tk1uwLJ14JU7bSsPvPZDB31jb9Vi0t_AfT66GA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653189D@FHSDB4H16-2.csu.mcmaster.ca>
	<CAC8=1eqFCKkHWeBAo9wxXUmE01TEtqY=TSz9A9jM_fobswz1iw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC836531900@FHSDB4H16-2.csu.mcmaster.ca>
Message-ID: <CAC8=1eoyTy=fmBSgeOFG19umwtazxN_K0vMdJL4OdbPbWfT-qw@mail.gmail.com>

Dear Sir,

Thank you.

Best Regards,
Ashim

On Wed, Jun 22, 2016 at 10:47 AM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Ashim,
>
> > -----Original Message-----
> > From: Ashim Kapoor [mailto:ashimkapoor at gmail.com]
> > Sent: June 21, 2016 10:10 PM
> > To: Fox, John <jfox at mcmaster.ca>
> > Cc: Marc Schwartz <marc_schwartz at me.com>; R-help <r-help at r-project.org>
> > Subject: Re: [R] [FORGED] Ask function missing in package car
> >
> > Dear Sir,
> >
> >
> > Many thanks for your reply. May I ask,was it replaced by another similar
> > function?
>
> No.
>
> > It seems interesting enough to have a function like that.
>
> I guess it didn't seem that useful to us. You can simply modify commands
> in a programming editor.
>
> Best,
>  John
>
> >
> >
> > Best Regards,
> >
> > Ashim
> >
> >
> > On Wed, Jun 22, 2016 at 10:35 AM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Ashim and Marc,
> >
> >       Sorry to chime in late. As Marc suggests, the Ask() function went
> the
> > way of the dodo before the second edition of the book (coauthored with
> Sandy
> > Weisberg, and retitled "An R Companion to Applied Regression") was
> > published.
> >
> >       Best,
> >        John
> >
> >       -----------------------------
> >       John Fox, Professor
> >       McMaster University
> >       Hamilton, Ontario
> >       Canada L8S 4M4
> >       Web: socserv.mcmaster.ca/jfox <http://socserv.mcmaster.ca/jfox>
> >
> >
> >
> >       > -----Original Message-----
> >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:
> r-help-
> > bounces at r-project.org> ] On Behalf Of Ashim
> >       > Kapoor
> >       > Sent: June 21, 2016 7:35 PM
> >       > To: Marc Schwartz <marc_schwartz at me.com
> > <mailto:marc_schwartz at me.com> >
> >       > Cc: R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
> >       > Subject: Re: [R] [FORGED] Ask function missing in package car
> >       >
> >       > Dear Mark,
> >       >
> >       > Many thanks.
> >       >
> >       > Best Regards,
> >       > Ashim
> >       >
> >       > On Wed, Jun 22, 2016 at 7:45 AM, Marc Schwartz
> > <marc_schwartz at me.com <mailto:marc_schwartz at me.com> >
> >       > wrote:
> >       >
> >       > > According to the NEWS file for the package:
> >       > >
> >       > >   https://cran.r-project.org/web/packages/car/NEWS
> >       > >
> >       > > the Ask() function was removed in car version 2.0-0, which was
> >       > > released on 2010-07-26. So it has been gone for about 6 years.
> >       > >
> >       > > The version of car that is used in the documentation that you
> are
> >       > > using is 1.2-16, which is from 2009-10-11.
> >       > >
> >       > > So the online documentation source is outdated.
> >       > >
> >       > > I see that the Ask() function is listed in the first edition
> of John's
> >       > > book, which I have on my shelf, but I don't have the second
> edition
> > to
> >       > > know if that had been updated. A review of the index for the
> second
> >       > > edition on Amazon.com would suggest that it was removed for the
> > second
> >       > edition.
> >       > >
> >       > > Regards,
> >       > >
> >       > > Marc Schwartz
> >       > >
> >       > >
> >       > > > On Jun 21, 2016, at 8:29 PM, Ashim Kapoor
> > <ashimkapoor at gmail.com <mailto:ashimkapoor at gmail.com> >
> >       > wrote:
> >       > > >
> >       > > > I am reading the book An R and S plus companion to Applied
> >       > > > Regression
> >       > > and I
> >       > > > found this function there.
> >       > > >
> >       > > > Googling gave me the link [1].
> >       > > >
> >       > > > 1. http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html
> >       > > >
> >       > > > On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner
> >       > > > <r.turner at auckland.ac.nz <mailto:r.turner at auckland.ac.nz> >
> >       > > > wrote:
> >       > > >
> >       > > >> On 22/06/16 13:06, Ashim Kapoor wrote:
> >       > > >>
> >       > > >>> Dear All,
> >       > > >>>
> >       > > >>> my details:-
> >       > > >>>
> >       > > >>>> sessionInfo()
> >       > > >>>>
> >       > > >>> R version 3.3.0 (2016-05-03)
> >       > > >>> Platform: x86_64-pc-linux-gnu (64-bit) Running under:
> Ubuntu
> > 15.10
> >       > > >>>
> >       > > >>> locale:
> >       > > >>> [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
> >       > > >>> [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN
> > LC_MESSAGES=en_IN
> >       > > >>> [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
> >       > > >>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN
> >       > LC_IDENTIFICATION=C
> >       > > >>>
> >       > > >>> attached base packages:
> >       > > >>> [1] stats     graphics  grDevices utils     datasets
> methods   base
> >       > > >>>
> >       > > >>> other attached packages:
> >       > > >>> [1] car_2.1-2
> >       > > >>>
> >       > > >>> loaded via a namespace (and not attached):
> >       > > >>> [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
> >       > > >>> grid_3.3.0
> >       > > >>> [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
> >       > > >>> minqa_1.2.4
> >       > > >>> [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
> >       > > >>> lme4_1.1-12
> >       > > >>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
> >       > > >>> nnet_7.3-10
> >       > > >>> [17] quantreg_5.24
> >       > > >>>
> >       > > >>>>
> >       > > >>>>
> >       > > >>>    ## Not run:
> >       > > >>>> attach(UN)
> >       > > >>>>
> >       > > >>>> # enter the power-transformation parameter # start with 1
> > Ask(p,
> >       > > >>>> function(p) qq.plot(box.cox(gdp, p),
> >       > > >>>>
> >       > > >>> +         ylab=paste("transformed gdp, power =",p)))
> >       > > >>> Error: could not find function "Ask"
> >       > > >>>
> >       > > >>>>
> >       > > >>>>
> >       > > >>> What can I do to correct this?
> >       > > >>>
> >       > > >>
> >       > > >> What led you to believe that such a function exists (in the
> "car"
> >       > > package
> >       > > >> or anywhere else for that matter)?  And what exactly do you
> > want it
> >       > > >> to
> >       > > do
> >       > > >> for you?
> >       > > >>
> >       > > >> cheers,
> >       > > >>
> >       > > >> Rolf Turner
> >       > > >>
> >       > > >> --
> >       > > >> Technical Editor ANZJS
> >       > > >> Department of Statistics
> >       > > >> University of Auckland
> >       > > >> Phone: +64-9-373-7599 ext. 88276
> >       > >
> >       > >
> >       >
> >
> >       >       [[alternative HTML version deleted]]
> >       >
> >       > ______________________________________________
> >       > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list --
> > To UNSUBSCRIBE and more, see
> >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > PLEASE do read the posting guide
> http://www.R-project.org/posting-
> >       > guide.html
> >       > and provide commented, minimal, self-contained, reproducible
> code.
> >
> >
>
>

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Wed Jun 22 09:32:36 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Wed, 22 Jun 2016 07:32:36 +0000 (UTC)
Subject: [R] Generate list if sequence form two vector element
References: <1890354796.7443289.1466580756297.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>

Hi,
I want to do the follow thing 

Input : 
a <- c(1,3,6,9) 


b<-c(10,7,20,2) 


Expected outcome : 

d<-list(1:10,3:7,6:20,2:9) 



Thanks !!


 
Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com


From drjimlemon at gmail.com  Wed Jun 22 10:00:47 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 22 Jun 2016 18:00:47 +1000
Subject: [R] Generate list if sequence form two vector element
In-Reply-To: <1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>
References: <1890354796.7443289.1466580756297.JavaMail.yahoo.ref@mail.yahoo.com>
	<1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>

Hi Tanvir,
Not at all elegant, but:

make.seq<-function(x) return(seq(x[1],x[2]))
apply(matrix(c(a,b),ncol=2),1,make.seq)

Jim


On Wed, Jun 22, 2016 at 5:32 PM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Hi,
> I want to do the follow thing
>
> Input :
> a <- c(1,3,6,9)
>
>
> b<-c(10,7,20,2)
>
>
> Expected outcome :
>
> d<-list(1:10,3:7,6:20,2:9)
>
>
>
> Thanks !!
>
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Jun 22 10:14:34 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 22 Jun 2016 20:14:34 +1200
Subject: [R] [FORGED] Re: Generate list if sequence form two vector
 element
In-Reply-To: <CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>
References: <1890354796.7443289.1466580756297.JavaMail.yahoo.ref@mail.yahoo.com>
	<1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>
Message-ID: <84682533-cc76-0497-af00-6abf2206cc13@auckland.ac.nz>

On 22/06/16 20:00, Jim Lemon wrote:
> Hi Tanvir,
> Not at all elegant, but:
>
> make.seq<-function(x) return(seq(x[1],x[2]))
> apply(matrix(c(a,b),ncol=2),1,make.seq)

Not sure that this is more "elegant" but it's a one-liner:

  lapply(1:length(a),function(i,a,b){a[i]:b[i]},a=a,b=b)

cheers,

Rolf

> On Wed, Jun 22, 2016 at 5:32 PM, Mohammad Tanvir Ahamed via R-help
> <r-help at r-project.org> wrote:
>> Hi,
>> I want to do the follow thing
>>
>> Input :
>> a <- c(1,3,6,9)
>>
>>
>> b<-c(10,7,20,2)
>>
>>
>> Expected outcome :
>>
>> d<-list(1:10,3:7,6:20,2:9)


From drjimlemon at gmail.com  Wed Jun 22 10:42:07 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 22 Jun 2016 18:42:07 +1000
Subject: [R] [FORGED] Re: Generate list if sequence form two vector
	element
In-Reply-To: <84682533-cc76-0497-af00-6abf2206cc13@auckland.ac.nz>
References: <1890354796.7443289.1466580756297.JavaMail.yahoo.ref@mail.yahoo.com>
	<1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>
	<84682533-cc76-0497-af00-6abf2206cc13@auckland.ac.nz>
Message-ID: <CA+8X3fX1izEmUejWF=+zTkMeyL_iFNK1K=uxEZZHYwsw1acozw@mail.gmail.com>

Now why didn't I think of that?

apply(matrix(c(a,b),ncol=2),1,function(x)x[1]:x[2])

Jim

On Wed, Jun 22, 2016 at 6:14 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 22/06/16 20:00, Jim Lemon wrote:
>>
>> Hi Tanvir,
>> Not at all elegant, but:
>>
>> make.seq<-function(x) return(seq(x[1],x[2]))
>> apply(matrix(c(a,b),ncol=2),1,make.seq)
>
>
> Not sure that this is more "elegant" but it's a one-liner:
>
>  lapply(1:length(a),function(i,a,b){a[i]:b[i]},a=a,b=b)
>
> cheers,
>
> Rolf
>
>
>> On Wed, Jun 22, 2016 at 5:32 PM, Mohammad Tanvir Ahamed via R-help
>> <r-help at r-project.org> wrote:
>>>
>>> Hi,
>>> I want to do the follow thing
>>>
>>> Input :
>>> a <- c(1,3,6,9)
>>>
>>>
>>> b<-c(10,7,20,2)
>>>
>>>
>>> Expected outcome :
>>>
>>> d<-list(1:10,3:7,6:20,2:9)


From pdalgd at gmail.com  Wed Jun 22 11:23:17 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 22 Jun 2016 11:23:17 +0200
Subject: [R] [FORGED] Re: Generate list if sequence form two vector
	element
In-Reply-To: <CA+8X3fX1izEmUejWF=+zTkMeyL_iFNK1K=uxEZZHYwsw1acozw@mail.gmail.com>
References: <1890354796.7443289.1466580756297.JavaMail.yahoo.ref@mail.yahoo.com>
	<1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>
	<84682533-cc76-0497-af00-6abf2206cc13@auckland.ac.nz>
	<CA+8X3fX1izEmUejWF=+zTkMeyL_iFNK1K=uxEZZHYwsw1acozw@mail.gmail.com>
Message-ID: <687C7CF9-69AA-42D1-8B6B-0D28EECDB3E3@gmail.com>

There's also

mapply(a, b, FUN=seq, SIMPLIFY=FALSE)

(turn off simplication so that you don't unexpectedly get a matrix whenever all elements of results have same length. This also affects apply()-based solutions.)

...except that according to original spec, one should ensure a < b. So

myseq <- function(a,b) if(a<b) a:b else b:a
mapply(a, b, FUN=myseq, SIMPLIFY=FALSE)

-pd

> On 22 Jun 2016, at 10:42 , Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Now why didn't I think of that?
> 
> apply(matrix(c(a,b),ncol=2),1,function(x)x[1]:x[2])
> 
> Jim
> 
> On Wed, Jun 22, 2016 at 6:14 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 22/06/16 20:00, Jim Lemon wrote:
>>> 
>>> Hi Tanvir,
>>> Not at all elegant, but:
>>> 
>>> make.seq<-function(x) return(seq(x[1],x[2]))
>>> apply(matrix(c(a,b),ncol=2),1,make.seq)
>> 
>> 
>> Not sure that this is more "elegant" but it's a one-liner:
>> 
>> lapply(1:length(a),function(i,a,b){a[i]:b[i]},a=a,b=b)
>> 
>> cheers,
>> 
>> Rolf
>> 
>> 
>>> On Wed, Jun 22, 2016 at 5:32 PM, Mohammad Tanvir Ahamed via R-help
>>> <r-help at r-project.org> wrote:
>>>> 
>>>> Hi,
>>>> I want to do the follow thing
>>>> 
>>>> Input :
>>>> a <- c(1,3,6,9)
>>>> 
>>>> 
>>>> b<-c(10,7,20,2)
>>>> 
>>>> 
>>>> Expected outcome :
>>>> 
>>>> d<-list(1:10,3:7,6:20,2:9)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Keith.Jewell at campdenbri.co.uk  Wed Jun 22 11:54:34 2016
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Wed, 22 Jun 2016 10:54:34 +0100
Subject: [R] [FORGED] Re: Generate list if sequence form two vector
	element
In-Reply-To: <687C7CF9-69AA-42D1-8B6B-0D28EECDB3E3@gmail.com>
References: <1890354796.7443289.1466580756297.JavaMail.yahoo.ref@mail.yahoo.com>	<1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>	<CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>	<84682533-cc76-0497-af00-6abf2206cc13@auckland.ac.nz>	<CA+8X3fX1izEmUejWF=+zTkMeyL_iFNK1K=uxEZZHYwsw1acozw@mail.gmail.com>
	<687C7CF9-69AA-42D1-8B6B-0D28EECDB3E3@gmail.com>
Message-ID: <nkdn8q$u6v$1@ger.gmane.org>

or as a one-liner
mapply(pmin(a, b), pmax(a,b), FUN=seq, SIMPLIFY=FALSE)

On 22/06/2016 10:23, peter dalgaard wrote:
> There's also
>
> mapply(a, b, FUN=seq, SIMPLIFY=FALSE)
>
> (turn off simplication so that you don't unexpectedly get a matrix whenever all elements of results have same length. This also affects apply()-based solutions.)
>
> ...except that according to original spec, one should ensure a < b. So
>
> myseq <- function(a,b) if(a<b) a:b else b:a
> mapply(a, b, FUN=myseq, SIMPLIFY=FALSE)
>
> -pd
>
>> On 22 Jun 2016, at 10:42 , Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Now why didn't I think of that?
>>
>> apply(matrix(c(a,b),ncol=2),1,function(x)x[1]:x[2])
>>
>> Jim
>>
>> On Wed, Jun 22, 2016 at 6:14 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> On 22/06/16 20:00, Jim Lemon wrote:
>>>>
>>>> Hi Tanvir,
>>>> Not at all elegant, but:
>>>>
>>>> make.seq<-function(x) return(seq(x[1],x[2]))
>>>> apply(matrix(c(a,b),ncol=2),1,make.seq)
>>>
>>>
>>> Not sure that this is more "elegant" but it's a one-liner:
>>>
>>> lapply(1:length(a),function(i,a,b){a[i]:b[i]},a=a,b=b)
>>>
>>> cheers,
>>>
>>> Rolf
>>>
>>>
>>>> On Wed, Jun 22, 2016 at 5:32 PM, Mohammad Tanvir Ahamed via R-help
>>>> <r-help at r-project.org> wrote:
>>>>>
>>>>> Hi,
>>>>> I want to do the follow thing
>>>>>
>>>>> Input :
>>>>> a <- c(1,3,6,9)
>>>>>
>>>>>
>>>>> b<-c(10,7,20,2)
>>>>>
>>>>>
>>>>> Expected outcome :
>>>>>
>>>>> d<-list(1:10,3:7,6:20,2:9)


From mashranga at yahoo.com  Wed Jun 22 12:28:11 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Wed, 22 Jun 2016 10:28:11 +0000
Subject: [R] [FORGED] Re: Generate list if sequence form two
	vector	element
In-Reply-To: <nkdn8q$u6v$1@ger.gmane.org>
References: <1890354796.7443289.1466580756297.JavaMail.yahoo.ref@mail.yahoo.com>
	<1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>
	<84682533-cc76-0497-af00-6abf2206cc13@auckland.ac.nz>
	<CA+8X3fX1izEmUejWF=+zTkMeyL_iFNK1K=uxEZZHYwsw1acozw@mail.gmail.com>
	<687C7CF9-69AA-42D1-8B6B-0D28EECDB3E3@gmail.com>
	<nkdn8q$u6v$1@ger.gmane.org>
Message-ID: <1059988670.7467882.1466591291872.JavaMail.yahoo@mail.yahoo.com>

Thanks everyone for the solutions !!
Tanvir Ahamed 
G?teborg, Sweden   |  mashranga at yahoo.com 


----- Original Message -----
From: Keith Jewell <Keith.Jewell at campdenbri.co.uk>
To: r-help at stat.math.ethz.ch
Sent: Wednesday, 22 June 2016, 11:54
Subject: Re: [R] [FORGED] Re: Generate list if sequence form two vector	element

or as a one-liner
mapply(pmin(a, b), pmax(a,b), FUN=seq, SIMPLIFY=FALSE)


On 22/06/2016 10:23, peter dalgaard wrote:
> There's also
>
> mapply(a, b, FUN=seq, SIMPLIFY=FALSE)
>
> (turn off simplication so that you don't unexpectedly get a matrix whenever all elements of results have same length. This also affects apply()-based solutions.)
>
> ...except that according to original spec, one should ensure a < b. So
>
> myseq <- function(a,b) if(a<b) a:b else b:a
> mapply(a, b, FUN=myseq, SIMPLIFY=FALSE)
>
> -pd
>
>> On 22 Jun 2016, at 10:42 , Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Now why didn't I think of that?
>>
>> apply(matrix(c(a,b),ncol=2),1,function(x)x[1]:x[2])
>>
>> Jim
>>
>> On Wed, Jun 22, 2016 at 6:14 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> On 22/06/16 20:00, Jim Lemon wrote:
>>>>
>>>> Hi Tanvir,
>>>> Not at all elegant, but:
>>>>
>>>> make.seq<-function(x) return(seq(x[1],x[2]))
>>>> apply(matrix(c(a,b),ncol=2),1,make.seq)
>>>
>>>
>>> Not sure that this is more "elegant" but it's a one-liner:
>>>
>>> lapply(1:length(a),function(i,a,b){a[i]:b[i]},a=a,b=b)
>>>
>>> cheers,
>>>
>>> Rolf
>>>
>>>
>>>> On Wed, Jun 22, 2016 at 5:32 PM, Mohammad Tanvir Ahamed via R-help
>>>> <r-help at r-project.org> wrote:
>>>>>
>>>>> Hi,
>>>>> I want to do the follow thing
>>>>>
>>>>> Input :
>>>>> a <- c(1,3,6,9)
>>>>>
>>>>>
>>>>> b<-c(10,7,20,2)
>>>>>
>>>>>
>>>>> Expected outcome :
>>>>>
>>>>> d<-list(1:10,3:7,6:20,2:9)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From maillists at pp.inet.fi  Wed Jun 22 12:46:29 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Wed, 22 Jun 2016 13:46:29 +0300
Subject: [R] Y in Kohonen xyf function
In-Reply-To: <500416751.11999521.1466534016053.JavaMail.yahoo@mail.yahoo.com>
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
	<1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
	<840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>
	<95758e53-dde9-4a86-95d8-e1538f337845@pp.inet.fi>
	<171290742.7409726.1466087416379.JavaMail.yahoo@mail.yahoo.com>
	<928929ff-a9e9-3c7e-a4c1-c424e8318ef9@pp.inet.fi>
	<500416751.11999521.1466534016053.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <b9a527c6-0ed2-c968-5a4a-c2b13012a9ff@pp.inet.fi>

Hi again!

21.06.2016, 21:33, chalabi.elahe at yahoo.de wrote:
> Hi Kimmo, Thanks for your reply. I think now my problem is that I
> don't understand what does factor(df.classes[training]) do?

Sorry, my mistake, should habe been 'df$speed'. Please try the following:

--- snip ---

set.seed(7) training <- sample(nrow(df), 120)
Xtraining<- scale(df[training,])
Xtest <- scale(df[-training,], center = attr(Xtraining, 
"scaled:center"), scale = attr(Xtraining,
"scaled:scale"))
xyf.df <- xyf(Xtraining, factor(df$speed[training]), grid =
somgrid(5, 5, "hexagonal"))

--- snip ---

HTH,
Kimmo


From careyshan at gmail.com  Wed Jun 22 14:39:22 2016
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 22 Jun 2016 13:39:22 +0100
Subject: [R] biplot
Message-ID: <CA+jRDxDdgu-Zz1A04xJELaXe5TFr-H=rh5MVZ21au6C4=wm99g@mail.gmail.com>

Hey,

Does anyone know how to remove labels from a biplot? I want to input them
manually as they are currently overlapping.

Thanks

-- 
Le gach dea ghui,
Shane

	[[alternative HTML version deleted]]


From hadar.nomi at gmail.com  Wed Jun 22 15:47:57 2016
From: hadar.nomi at gmail.com (Nomi Hadar)
Date: Wed, 22 Jun 2016 16:47:57 +0300
Subject: [R] gbresolve function from the geiger package
In-Reply-To: <CAFnqqUZm3DgT8TyDSBY8JxenyNm1vukN5nr-Rn0tBTHfAWOzDA@mail.gmail.com>
References: <CAFnqqUZm3DgT8TyDSBY8JxenyNm1vukN5nr-Rn0tBTHfAWOzDA@mail.gmail.com>
Message-ID: <CAFnqqUYqkgMvwkGEesTxB3KsREb3vL4t5iovXT7wMqU0PtXKWg@mail.gmail.com>

o.k I found that I have to update my local  copy of ncbi,
but when I do:

*ncbit(update=TRUE)*

I get:

*"NCBI GenBank taxonomy assembled 2013-03-29"*

Why it was not updated?

Thanks
Nomi

2016-06-20 14:11 GMT+03:00 Nomi Hadar <hadar.nomi at gmail.com>:

> Hello,
>
> I have troubles with the gbresolve function from the *geiger *package,
> which works with the NCBI taxonomy.
> When I use it, there are genera that are not found although they *do
> appear *in the NCBI taxonomy browser.
> <http://www.ncbi.nlm.nih.gov/Taxonomy/taxonomyhome.html/>
>
> for example, when I run:
>
> library("ape")
> library("geiger")
>
> genus = "Christia"
> gbresolve(genus, rank= "genus", within = "Fabaceae")
>
> ("Christia" is a genus within a plants group called Fabaceae)
>
> I get:
>
> Error in tmp[[idx]] : subscript out of bounds
> In addition: Warning messages:
> 1: In FUN(X[[i]], ...) : Attempt one of the following:
> Bacterium purifaciens Christiansen 1917
> ...
> ...
> 2: In gbresolve.default(genus, rank = "genus", within = "Fabaceae") :
>   The following taxa were not encountered in the NCBI taxonomy:
> Christia
>
>
> And so for other genera such as "Pycnospora" / "Solori" /
> "Thailentadopsis" and more.
> You can see that "Christia" appears in browser
> <http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi>, and so I
> expect to get "Christia vespertilionis" as result.
>
> Why is that?
>
> Thank you very much!
> Nomi
>
>
> --
> *Nomi Hadar*
>
>


-- 
*Nomi Hadar*

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Jun 22 17:38:08 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 22 Jun 2016 15:38:08 +0000
Subject: [R] [FORGED] Ask function missing in package car
In-Reply-To: <CAC8=1eoyTy=fmBSgeOFG19umwtazxN_K0vMdJL4OdbPbWfT-qw@mail.gmail.com>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
	<CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
	<356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>
	<CAC8=1eq2M1X4Tk1uwLJ14JU7bSsPvPZDB31jb9Vi0t_AfT66GA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653189D@FHSDB4H16-2.csu.mcmaster.ca>
	<CAC8=1eqFCKkHWeBAo9wxXUmE01TEtqY=TSz9A9jM_fobswz1iw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC836531900@FHSDB4H16-2.csu.mcmaster.ca>
	<CAC8=1eoyTy=fmBSgeOFG19umwtazxN_K0vMdJL4OdbPbWfT-qw@mail.gmail.com>
Message-ID: <4857980816e74b8c83a5b2f25901f0fb@exch-2p-mbx-t2.ads.tamu.edu>

Since R is open source, the source code for packages is stored on CRAN mirrors. A little navigation gets us to 

https://cloud.r-project.org/src/contrib/Archive/car/

Loading car_1.2-16.tar.gz, the last version before car_2.0 gives the code for Ask():

# change an argument to a function interactively (J. Fox)

Ask<-function(arg, fun, ...){ 
    fun<-fun
    repeat{   
        value<-readline(paste("Enter",deparse(substitute(arg)),": "))
        if (value == "") break()
        eval(parse(text=paste("fun(",deparse(substitute(arg)),"=",value,",...)")))
        }
    }

Running this code will create the function.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim Kapoor
Sent: Wednesday, June 22, 2016 12:35 AM
To: Fox, John
Cc: R-help
Subject: Re: [R] [FORGED] Ask function missing in package car

Dear Sir,

Thank you.

Best Regards,
Ashim

On Wed, Jun 22, 2016 at 10:47 AM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Ashim,
>
> > -----Original Message-----
> > From: Ashim Kapoor [mailto:ashimkapoor at gmail.com]
> > Sent: June 21, 2016 10:10 PM
> > To: Fox, John <jfox at mcmaster.ca>
> > Cc: Marc Schwartz <marc_schwartz at me.com>; R-help <r-help at r-project.org>
> > Subject: Re: [R] [FORGED] Ask function missing in package car
> >
> > Dear Sir,
> >
> >
> > Many thanks for your reply. May I ask,was it replaced by another similar
> > function?
>
> No.
>
> > It seems interesting enough to have a function like that.
>
> I guess it didn't seem that useful to us. You can simply modify commands
> in a programming editor.
>
> Best,
>  John
>
> >
> >
> > Best Regards,
> >
> > Ashim
> >
> >
> > On Wed, Jun 22, 2016 at 10:35 AM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Ashim and Marc,
> >
> >       Sorry to chime in late. As Marc suggests, the Ask() function went
> the
> > way of the dodo before the second edition of the book (coauthored with
> Sandy
> > Weisberg, and retitled "An R Companion to Applied Regression") was
> > published.
> >
> >       Best,
> >        John
> >
> >       -----------------------------
> >       John Fox, Professor
> >       McMaster University
> >       Hamilton, Ontario
> >       Canada L8S 4M4
> >       Web: socserv.mcmaster.ca/jfox <http://socserv.mcmaster.ca/jfox>
> >
> >
> >
> >       > -----Original Message-----
> >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:
> r-help-
> > bounces at r-project.org> ] On Behalf Of Ashim
> >       > Kapoor
> >       > Sent: June 21, 2016 7:35 PM
> >       > To: Marc Schwartz <marc_schwartz at me.com
> > <mailto:marc_schwartz at me.com> >
> >       > Cc: R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
> >       > Subject: Re: [R] [FORGED] Ask function missing in package car
> >       >
> >       > Dear Mark,
> >       >
> >       > Many thanks.
> >       >
> >       > Best Regards,
> >       > Ashim
> >       >
> >       > On Wed, Jun 22, 2016 at 7:45 AM, Marc Schwartz
> > <marc_schwartz at me.com <mailto:marc_schwartz at me.com> >
> >       > wrote:
> >       >
> >       > > According to the NEWS file for the package:
> >       > >
> >       > >   https://cran.r-project.org/web/packages/car/NEWS
> >       > >
> >       > > the Ask() function was removed in car version 2.0-0, which was
> >       > > released on 2010-07-26. So it has been gone for about 6 years.
> >       > >
> >       > > The version of car that is used in the documentation that you
> are
> >       > > using is 1.2-16, which is from 2009-10-11.
> >       > >
> >       > > So the online documentation source is outdated.
> >       > >
> >       > > I see that the Ask() function is listed in the first edition
> of John's
> >       > > book, which I have on my shelf, but I don't have the second
> edition
> > to
> >       > > know if that had been updated. A review of the index for the
> second
> >       > > edition on Amazon.com would suggest that it was removed for the
> > second
> >       > edition.
> >       > >
> >       > > Regards,
> >       > >
> >       > > Marc Schwartz
> >       > >
> >       > >
> >       > > > On Jun 21, 2016, at 8:29 PM, Ashim Kapoor
> > <ashimkapoor at gmail.com <mailto:ashimkapoor at gmail.com> >
> >       > wrote:
> >       > > >
> >       > > > I am reading the book An R and S plus companion to Applied
> >       > > > Regression
> >       > > and I
> >       > > > found this function there.
> >       > > >
> >       > > > Googling gave me the link [1].
> >       > > >
> >       > > > 1. http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html
> >       > > >
> >       > > > On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner
> >       > > > <r.turner at auckland.ac.nz <mailto:r.turner at auckland.ac.nz> >
> >       > > > wrote:
> >       > > >
> >       > > >> On 22/06/16 13:06, Ashim Kapoor wrote:
> >       > > >>
> >       > > >>> Dear All,
> >       > > >>>
> >       > > >>> my details:-
> >       > > >>>
> >       > > >>>> sessionInfo()
> >       > > >>>>
> >       > > >>> R version 3.3.0 (2016-05-03)
> >       > > >>> Platform: x86_64-pc-linux-gnu (64-bit) Running under:
> Ubuntu
> > 15.10
> >       > > >>>
> >       > > >>> locale:
> >       > > >>> [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
> >       > > >>> [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN
> > LC_MESSAGES=en_IN
> >       > > >>> [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
> >       > > >>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN
> >       > LC_IDENTIFICATION=C
> >       > > >>>
> >       > > >>> attached base packages:
> >       > > >>> [1] stats     graphics  grDevices utils     datasets
> methods   base
> >       > > >>>
> >       > > >>> other attached packages:
> >       > > >>> [1] car_2.1-2
> >       > > >>>
> >       > > >>> loaded via a namespace (and not attached):
> >       > > >>> [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
> >       > > >>> grid_3.3.0
> >       > > >>> [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
> >       > > >>> minqa_1.2.4
> >       > > >>> [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
> >       > > >>> lme4_1.1-12
> >       > > >>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
> >       > > >>> nnet_7.3-10
> >       > > >>> [17] quantreg_5.24
> >       > > >>>
> >       > > >>>>
> >       > > >>>>
> >       > > >>>    ## Not run:
> >       > > >>>> attach(UN)
> >       > > >>>>
> >       > > >>>> # enter the power-transformation parameter # start with 1
> > Ask(p,
> >       > > >>>> function(p) qq.plot(box.cox(gdp, p),
> >       > > >>>>
> >       > > >>> +         ylab=paste("transformed gdp, power =",p)))
> >       > > >>> Error: could not find function "Ask"
> >       > > >>>
> >       > > >>>>
> >       > > >>>>
> >       > > >>> What can I do to correct this?
> >       > > >>>
> >       > > >>
> >       > > >> What led you to believe that such a function exists (in the
> "car"
> >       > > package
> >       > > >> or anywhere else for that matter)?  And what exactly do you
> > want it
> >       > > >> to
> >       > > do
> >       > > >> for you?
> >       > > >>
> >       > > >> cheers,
> >       > > >>
> >       > > >> Rolf Turner
> >       > > >>
> >       > > >> --
> >       > > >> Technical Editor ANZJS
> >       > > >> Department of Statistics
> >       > > >> University of Auckland
> >       > > >> Phone: +64-9-373-7599 ext. 88276
> >       > >
> >       > >
> >       >
> >
> >       >       [[alternative HTML version deleted]]
> >       >
> >       > ______________________________________________
> >       > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list --
> > To UNSUBSCRIBE and more, see
> >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > PLEASE do read the posting guide
> http://www.R-project.org/posting-
> >       > guide.html
> >       > and provide commented, minimal, self-contained, reproducible
> code.
> >
> >
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Wed Jun 22 17:40:40 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 22 Jun 2016 21:10:40 +0530
Subject: [R] [FORGED] Ask function missing in package car
In-Reply-To: <4857980816e74b8c83a5b2f25901f0fb@exch-2p-mbx-t2.ads.tamu.edu>
References: <CAC8=1eqA8iHrUVcO69Ujn7zUbO7CMXafieQgqRZfVFOJn8F3cw@mail.gmail.com>
	<833876d5-3d9d-7aac-4c0e-581bb36f9e49@auckland.ac.nz>
	<CAC8=1eqdn_5PV__3R2a6D5N4R3UwoxT+S9FQ82QLwVqKXV-wBg@mail.gmail.com>
	<356E4FCF-15D8-4D0C-9C2B-277F90AE5C4D@me.com>
	<CAC8=1eq2M1X4Tk1uwLJ14JU7bSsPvPZDB31jb9Vi0t_AfT66GA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653189D@FHSDB4H16-2.csu.mcmaster.ca>
	<CAC8=1eqFCKkHWeBAo9wxXUmE01TEtqY=TSz9A9jM_fobswz1iw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC836531900@FHSDB4H16-2.csu.mcmaster.ca>
	<CAC8=1eoyTy=fmBSgeOFG19umwtazxN_K0vMdJL4OdbPbWfT-qw@mail.gmail.com>
	<4857980816e74b8c83a5b2f25901f0fb@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CAC8=1eo1q3oy10kUkWz5i1ZxAy61OPMBgnu3Sje-Zp4sKLEi9g@mail.gmail.com>

wow. Cool.

Many thanks,
Ashim

On Wed, Jun 22, 2016 at 9:08 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> Since R is open source, the source code for packages is stored on CRAN
> mirrors. A little navigation gets us to
>
> https://cloud.r-project.org/src/contrib/Archive/car/
>
> Loading car_1.2-16.tar.gz, the last version before car_2.0 gives the code
> for Ask():
>
> # change an argument to a function interactively (J. Fox)
>
> Ask<-function(arg, fun, ...){
>     fun<-fun
>     repeat{
>         value<-readline(paste("Enter",deparse(substitute(arg)),": "))
>         if (value == "") break()
>
> eval(parse(text=paste("fun(",deparse(substitute(arg)),"=",value,",...)")))
>         }
>     }
>
> Running this code will create the function.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> Kapoor
> Sent: Wednesday, June 22, 2016 12:35 AM
> To: Fox, John
> Cc: R-help
> Subject: Re: [R] [FORGED] Ask function missing in package car
>
> Dear Sir,
>
> Thank you.
>
> Best Regards,
> Ashim
>
> On Wed, Jun 22, 2016 at 10:47 AM, Fox, John <jfox at mcmaster.ca> wrote:
>
> > Dear Ashim,
> >
> > > -----Original Message-----
> > > From: Ashim Kapoor [mailto:ashimkapoor at gmail.com]
> > > Sent: June 21, 2016 10:10 PM
> > > To: Fox, John <jfox at mcmaster.ca>
> > > Cc: Marc Schwartz <marc_schwartz at me.com>; R-help <r-help at r-project.org
> >
> > > Subject: Re: [R] [FORGED] Ask function missing in package car
> > >
> > > Dear Sir,
> > >
> > >
> > > Many thanks for your reply. May I ask,was it replaced by another
> similar
> > > function?
> >
> > No.
> >
> > > It seems interesting enough to have a function like that.
> >
> > I guess it didn't seem that useful to us. You can simply modify commands
> > in a programming editor.
> >
> > Best,
> >  John
> >
> > >
> > >
> > > Best Regards,
> > >
> > > Ashim
> > >
> > >
> > > On Wed, Jun 22, 2016 at 10:35 AM, Fox, John <jfox at mcmaster.ca
> > > <mailto:jfox at mcmaster.ca> > wrote:
> > >
> > >
> > >       Dear Ashim and Marc,
> > >
> > >       Sorry to chime in late. As Marc suggests, the Ask() function went
> > the
> > > way of the dodo before the second edition of the book (coauthored with
> > Sandy
> > > Weisberg, and retitled "An R Companion to Applied Regression") was
> > > published.
> > >
> > >       Best,
> > >        John
> > >
> > >       -----------------------------
> > >       John Fox, Professor
> > >       McMaster University
> > >       Hamilton, Ontario
> > >       Canada L8S 4M4
> > >       Web: socserv.mcmaster.ca/jfox <http://socserv.mcmaster.ca/jfox>
> > >
> > >
> > >
> > >       > -----Original Message-----
> > >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:
> > r-help-
> > > bounces at r-project.org> ] On Behalf Of Ashim
> > >       > Kapoor
> > >       > Sent: June 21, 2016 7:35 PM
> > >       > To: Marc Schwartz <marc_schwartz at me.com
> > > <mailto:marc_schwartz at me.com> >
> > >       > Cc: R-help <r-help at r-project.org <mailto:r-help at r-project.org>
> >
> > >       > Subject: Re: [R] [FORGED] Ask function missing in package car
> > >       >
> > >       > Dear Mark,
> > >       >
> > >       > Many thanks.
> > >       >
> > >       > Best Regards,
> > >       > Ashim
> > >       >
> > >       > On Wed, Jun 22, 2016 at 7:45 AM, Marc Schwartz
> > > <marc_schwartz at me.com <mailto:marc_schwartz at me.com> >
> > >       > wrote:
> > >       >
> > >       > > According to the NEWS file for the package:
> > >       > >
> > >       > >   https://cran.r-project.org/web/packages/car/NEWS
> > >       > >
> > >       > > the Ask() function was removed in car version 2.0-0, which
> was
> > >       > > released on 2010-07-26. So it has been gone for about 6
> years.
> > >       > >
> > >       > > The version of car that is used in the documentation that you
> > are
> > >       > > using is 1.2-16, which is from 2009-10-11.
> > >       > >
> > >       > > So the online documentation source is outdated.
> > >       > >
> > >       > > I see that the Ask() function is listed in the first edition
> > of John's
> > >       > > book, which I have on my shelf, but I don't have the second
> > edition
> > > to
> > >       > > know if that had been updated. A review of the index for the
> > second
> > >       > > edition on Amazon.com would suggest that it was removed for
> the
> > > second
> > >       > edition.
> > >       > >
> > >       > > Regards,
> > >       > >
> > >       > > Marc Schwartz
> > >       > >
> > >       > >
> > >       > > > On Jun 21, 2016, at 8:29 PM, Ashim Kapoor
> > > <ashimkapoor at gmail.com <mailto:ashimkapoor at gmail.com> >
> > >       > wrote:
> > >       > > >
> > >       > > > I am reading the book An R and S plus companion to Applied
> > >       > > > Regression
> > >       > > and I
> > >       > > > found this function there.
> > >       > > >
> > >       > > > Googling gave me the link [1].
> > >       > > >
> > >       > > > 1.
> http://svitsrv25.epfl.ch/R-doc/library/car/html/Ask.html
> > >       > > >
> > >       > > > On Wed, Jun 22, 2016 at 6:57 AM, Rolf Turner
> > >       > > > <r.turner at auckland.ac.nz <mailto:r.turner at auckland.ac.nz>
> >
> > >       > > > wrote:
> > >       > > >
> > >       > > >> On 22/06/16 13:06, Ashim Kapoor wrote:
> > >       > > >>
> > >       > > >>> Dear All,
> > >       > > >>>
> > >       > > >>> my details:-
> > >       > > >>>
> > >       > > >>>> sessionInfo()
> > >       > > >>>>
> > >       > > >>> R version 3.3.0 (2016-05-03)
> > >       > > >>> Platform: x86_64-pc-linux-gnu (64-bit) Running under:
> > Ubuntu
> > > 15.10
> > >       > > >>>
> > >       > > >>> locale:
> > >       > > >>> [1] LC_CTYPE=en_IN       LC_NUMERIC=C
>  LC_TIME=en_IN
> > >       > > >>> [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN
> > > LC_MESSAGES=en_IN
> > >       > > >>> [7] LC_PAPER=en_IN       LC_NAME=C
> LC_ADDRESS=C
> > >       > > >>> [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN
> > >       > LC_IDENTIFICATION=C
> > >       > > >>>
> > >       > > >>> attached base packages:
> > >       > > >>> [1] stats     graphics  grDevices utils     datasets
> > methods   base
> > >       > > >>>
> > >       > > >>> other attached packages:
> > >       > > >>> [1] car_2.1-2
> > >       > > >>>
> > >       > > >>> loaded via a namespace (and not attached):
> > >       > > >>> [1] Rcpp_0.12.5        lattice_0.20-33    MASS_7.3-43
> > >       > > >>> grid_3.3.0
> > >       > > >>> [5] nlme_3.1-128       MatrixModels_0.4-1 SparseM_1.7
> > >       > > >>> minqa_1.2.4
> > >       > > >>> [9] nloptr_1.0.4       Matrix_1.2-6       splines_3.3.0
> > >       > > >>> lme4_1.1-12
> > >       > > >>> [13] pbkrtest_0.4-6     parallel_3.3.0     mgcv_1.8-7
> > >       > > >>> nnet_7.3-10
> > >       > > >>> [17] quantreg_5.24
> > >       > > >>>
> > >       > > >>>>
> > >       > > >>>>
> > >       > > >>>    ## Not run:
> > >       > > >>>> attach(UN)
> > >       > > >>>>
> > >       > > >>>> # enter the power-transformation parameter # start with
> 1
> > > Ask(p,
> > >       > > >>>> function(p) qq.plot(box.cox(gdp, p),
> > >       > > >>>>
> > >       > > >>> +         ylab=paste("transformed gdp, power =",p)))
> > >       > > >>> Error: could not find function "Ask"
> > >       > > >>>
> > >       > > >>>>
> > >       > > >>>>
> > >       > > >>> What can I do to correct this?
> > >       > > >>>
> > >       > > >>
> > >       > > >> What led you to believe that such a function exists (in
> the
> > "car"
> > >       > > package
> > >       > > >> or anywhere else for that matter)?  And what exactly do
> you
> > > want it
> > >       > > >> to
> > >       > > do
> > >       > > >> for you?
> > >       > > >>
> > >       > > >> cheers,
> > >       > > >>
> > >       > > >> Rolf Turner
> > >       > > >>
> > >       > > >> --
> > >       > > >> Technical Editor ANZJS
> > >       > > >> Department of Statistics
> > >       > > >> University of Auckland
> > >       > > >> Phone: +64-9-373-7599 ext. 88276
> > >       > >
> > >       > >
> > >       >
> > >
> > >       >       [[alternative HTML version deleted]]
> > >       >
> > >       > ______________________________________________
> > >       > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> > list --
> > > To UNSUBSCRIBE and more, see
> > >       > https://stat.ethz.ch/mailman/listinfo/r-help
> > >       > PLEASE do read the posting guide
> > http://www.R-project.org/posting-
> > >       > guide.html
> > >       > and provide commented, minimal, self-contained, reproducible
> > code.
> > >
> > >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Jun 22 17:44:16 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 22 Jun 2016 15:44:16 +0000
Subject: [R] biplot
In-Reply-To: <CA+jRDxDdgu-Zz1A04xJELaXe5TFr-H=rh5MVZ21au6C4=wm99g@mail.gmail.com>
References: <CA+jRDxDdgu-Zz1A04xJELaXe5TFr-H=rh5MVZ21au6C4=wm99g@mail.gmail.com>
Message-ID: <95dd824a9f1343f8813ec253c86a7420@exch-2p-mbx-t2.ads.tamu.edu>

The xlabs= (rows) and ylabs= (columns) arguments handle the labels, but they do not recycle so you need to specify values for each row and each column:

> set.seed(42)
> x <- matrix(rnorm(500), 50, 10)
> biplot(prcomp(x), xlabs=rep("", 50), ylabs=rep("", 10))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shane Carey
Sent: Wednesday, June 22, 2016 7:39 AM
To: r-help at r-project.org
Subject: [R] biplot

Hey,

Does anyone know how to remove labels from a biplot? I want to input them
manually as they are currently overlapping.

Thanks

-- 
Le gach dea ghui,
Shane

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Jun 22 17:56:02 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 22 Jun 2016 15:56:02 +0000
Subject: [R] biplot
In-Reply-To: <95dd824a9f1343f8813ec253c86a7420@exch-2p-mbx-t2.ads.tamu.edu>
References: <CA+jRDxDdgu-Zz1A04xJELaXe5TFr-H=rh5MVZ21au6C4=wm99g@mail.gmail.com>
	<95dd824a9f1343f8813ec253c86a7420@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <6ac18df11cb343758b2eba8836d34120@exch-2p-mbx-t2.ads.tamu.edu>

I should have mentioned that the points are invisible without the labels and there is no way to use plot symbols. Something like this is probably what you wanted.

> biplot(prcomp(x), xlabs=rep("*", 50), ylabs=rep("", 10))

Gives you the arrows and asterisks for the points. But labeling them is not easy since the coordinates are based on the columns:

> par("usr")
[1] -6.705729  7.179791 -6.705729  7.179791

David C

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Wednesday, June 22, 2016 10:44 AM
To: Shane Carey; r-help at r-project.org
Subject: Re: [R] biplot

The xlabs= (rows) and ylabs= (columns) arguments handle the labels, but they do not recycle so you need to specify values for each row and each column:

> set.seed(42)
> x <- matrix(rnorm(500), 50, 10)
> biplot(prcomp(x), xlabs=rep("", 50), ylabs=rep("", 10))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shane Carey
Sent: Wednesday, June 22, 2016 7:39 AM
To: r-help at r-project.org
Subject: [R] biplot

Hey,

Does anyone know how to remove labels from a biplot? I want to input them
manually as they are currently overlapping.

Thanks

-- 
Le gach dea ghui,
Shane

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ruediger.port at gmail.com  Wed Jun 22 11:50:57 2016
From: ruediger.port at gmail.com (Ruediger Port)
Date: Wed, 22 Jun 2016 11:50:57 +0200 (CEST)
Subject: [R]  Problem with rJava
Message-ID: <alpine.LSU.2.20.1606221149060.4402@rport13.fritz.box>


Hit the same error message when trying  install.packages('rJava')
in R 3.2.2 under SuSE Linux, version Leap 42.1 :

------------ Begin of error message ------------------------------------

configure: error: One or more Java configuration variables are not set.
Make sure R is configured with full Java support (including JDK). Run
R CMD javareconf
as root to add Java support to R.

If you don't have root privileges, run
R CMD javareconf -e
to set all Java-related variables and then install rJava.

------------ End of error message --------------------------------------

Neither one of  "R CMD javareconf"  or  "R CMD javareconf -e" did help.
(Command has to be given within the same terminal window where the package
installation is tried - yet, no help.)

Remedy in my case:
------------------

         setenv JAVA_CPPFLAGS " "        (c-shell)
or      export JAVA_CPPFLAGS=" "        (bash)

Explanation, as far as I found out:
-----------------------------------

The install.packages() command downloads the rJava package,
e.g.  rJava_0.9-8.tar.gz ,  somewhere under  /tmp .  If you open it
( tar xvfz /tmp/Rtmp ... rJava_0.9-8.tar.gz ) you'll find
a "configure" script which is started by  install.packages()
and issues all those messages "checking for ...".  The infamous
error message is found in the configure script following a line
where it tests whether all of these Java environment variables
exist and do have non-zero length:

         JAVA JAVAC JAVAH JAVA_CPPFLAGS JAVA_LIBS JAR

If one of these doesn't exist or has zero length, the script
stops with the error message.  The one that was missing
in my case was  JAVA_CPPFLAGS .  Setting it to consist
of just one blank did the trick (see above).  With that,
the configure script ran successfully, as did the subsequent
installation.

With this, the  configure  script  runs smoothly,
as does  > install.packages('rJava').

Good luck!

Ruedi


From chalabi.elahe at yahoo.de  Wed Jun 22 21:00:55 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Wed, 22 Jun 2016 19:00:55 +0000 (UTC)
Subject: [R] Y in Kohonen xyf function
In-Reply-To: <b9a527c6-0ed2-c968-5a4a-c2b13012a9ff@pp.inet.fi>
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
	<1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
	<840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>
	<95758e53-dde9-4a86-95d8-e1538f337845@pp.inet.fi>
	<171290742.7409726.1466087416379.JavaMail.yahoo@mail.yahoo.com>
	<928929ff-a9e9-3c7e-a4c1-c424e8318ef9@pp.inet.fi>
	<500416751.11999521.1466534016053.JavaMail.yahoo@mail.yahoo.com>
	<b9a527c6-0ed2-c968-5a4a-c2b13012a9ff@pp.inet.fi>
Message-ID: <841170186.13161342.1466622055827.JavaMail.yahoo@mail.yahoo.com>

Dear Kimmo,
I already used df$speed[training] in df.xyf but I get this error:
   Error in xyf(Xtraining,factor(df$speed[training]),grid=somgrid(5, :
   NA/NaN/Inf in foreign function call (arg 1)





On Wednesday, June 22, 2016 3:48 AM, K. Elo <maillists at pp.inet.fi> wrote:
Hi again!

21.06.2016, 21:33, chalabi.elahe at yahoo.de wrote:
> Hi Kimmo, Thanks for your reply. I think now my problem is that I
> don't understand what does factor(df.classes[training]) do?

Sorry, my mistake, should habe been 'df$speed'. Please try the following:

--- snip ---

set.seed(7) training <- sample(nrow(df), 120)
Xtraining<- scale(df[training,])
Xtest <- scale(df[-training,], center = attr(Xtraining, 
"scaled:center"), scale = attr(Xtraining,
"scaled:scale"))
xyf.df <- xyf(Xtraining, factor(df$speed[training]), grid =

somgrid(5, 5, "hexagonal"))

--- snip ---

HTH,
Kimmo

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From site-ethz at alexandrathorn.com  Wed Jun 22 21:33:10 2016
From: site-ethz at alexandrathorn.com (Alex Thorn)
Date: Wed, 22 Jun 2016 15:33:10 -0400
Subject: [R] issues with R raster temporary files
Message-ID: <MTAwMDAxNC5hdGhvcm4.1466623996@quikprotect>

Hello.

I am running into difficulties running some older scripts I produced in
2014 to handle raster data using the R package "raster".  I have the
feeling that some behavior has changed with an upgrade but don't
remember what version I was using when I wrote the scripts.  Can
somebody help me troubleshoot and solve this?

The general problem seems to be that R is not recognizing automatically
generated temporary files I run `removeTmpFiles(h=0)`, so I end up
with lots of large .grd files that stick around.  Having looked at the
source code for `removeTmpFiles` and `showTmpFiles` and also looked at
the files sticking around, I think the problem is that temporary files
are being generated without a prefix (i.e. the file name just starts
with the date), but I'm not sure why this is happening or how to fix it.

Any advice?

Thanks,
Alex


From maillists at pp.inet.fi  Wed Jun 22 22:01:50 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Wed, 22 Jun 2016 23:01:50 +0300
Subject: [R] Y in Kohonen xyf function
In-Reply-To: <841170186.13161342.1466622055827.JavaMail.yahoo@mail.yahoo.com>
References: <1206744097.6151734.1465993132338.JavaMail.yahoo.ref@mail.yahoo.com>
	<1206744097.6151734.1465993132338.JavaMail.yahoo@mail.yahoo.com>
	<840508915.7277483.1466079218390.JavaMail.yahoo@mail.yahoo.com>
	<95758e53-dde9-4a86-95d8-e1538f337845@pp.inet.fi>
	<171290742.7409726.1466087416379.JavaMail.yahoo@mail.yahoo.com>
	<928929ff-a9e9-3c7e-a4c1-c424e8318ef9@pp.inet.fi>
	<500416751.11999521.1466534016053.JavaMail.yahoo@mail.yahoo.com>
	<b9a527c6-0ed2-c968-5a4a-c2b13012a9ff@pp.inet.fi>
	<841170186.13161342.1466622055827.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <a68bd6e9-9210-77d4-5d4b-71d8e52934d5@pp.inet.fi>

Hi!

22.06.2016, 22:00, chalabi.elahe at yahoo.de wrote:
> Dear Kimmo,
> I already used df$speed[training] in df.xyf but I get this error:
>    Error in xyf(Xtraining,factor(df$speed[training]),grid=somgrid(5, :
>    NA/NaN/Inf in foreign function call (arg 1)

Please check for zeros (0) and NAs in df$speed or Xtraining. They could 
be a problem here...

HTH,
Kimmo


From wdunlap at tibco.com  Wed Jun 22 22:41:05 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 22 Jun 2016 13:41:05 -0700
Subject: [R] issues with R raster temporary files
In-Reply-To: <MTAwMDAxNC5hdGhvcm4.1466623996@quikprotect>
References: <MTAwMDAxNC5hdGhvcm4.1466623996@quikprotect>
Message-ID: <CAF8bMcZP2Bn6AQDMHdk6fyK3U_8AFjLVBhwp5X_ADuY=TF=TFg@mail.gmail.com>

I think there is a bug in raster::removeTmpFiles().  Near the end it has
        f <- f[dif > h]
        if (length(f) > 1) {
            unlink(f, recursive = TRUE)
        }
so it only tries to remove the files listed in 'f' if there is more than
one of them.
Perhaps the author meant to use '>=' instead of '>', but unlink() works
fine if
given a zero-long vector of file names so the 'if' could be omitted.

You can report bugs in the raster package with the command
      bug.report(package="raster")



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jun 22, 2016 at 12:33 PM, Alex Thorn <site-ethz at alexandrathorn.com>
wrote:

> Hello.
>
> I am running into difficulties running some older scripts I produced in
> 2014 to handle raster data using the R package "raster".  I have the
> feeling that some behavior has changed with an upgrade but don't
> remember what version I was using when I wrote the scripts.  Can
> somebody help me troubleshoot and solve this?
>
> The general problem seems to be that R is not recognizing automatically
> generated temporary files I run `removeTmpFiles(h=0)`, so I end up
> with lots of large .grd files that stick around.  Having looked at the
> source code for `removeTmpFiles` and `showTmpFiles` and also looked at
> the files sticking around, I think the problem is that temporary files
> are being generated without a prefix (i.e. the file name just starts
> with the date), but I'm not sure why this is happening or how to fix it.
>
> Any advice?
>
> Thanks,
> Alex
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Pradip.Muhuri at ahrq.hhs.gov  Thu Jun 23 03:32:40 2016
From: Pradip.Muhuri at ahrq.hhs.gov (Muhuri, Pradip (AHRQ/CFACT))
Date: Thu, 23 Jun 2016 01:32:40 +0000
Subject: [R] svymean using the survey package - strata containing no
 subpopulation members
Message-ID: <BN1PR09MB0305DF41B9CE3C31519FBD50D32D0@BN1PR09MB0305.namprd09.prod.outlook.com>

Hi,

Below is a reproducible example that produces the estimate of "totexp13" (total health care expenditure 2013) for the subpopulation that includes "Asians with diabetes diagnosed" in MEPS. The R script below downloads file from the web for processing.

Issue/Question: The R/survey package does not seem to provide a NOTE regarding the number of strata containing NO SUBOPOPULATION MEMBERS (in this case - Asians with diabetes diagnosed in MEPS 2013). Is there a way to get this count or ask R to provide this information?  Any hints will be appreciated.

Acknowledgements:   The current R script is a tweaked-version of the code originally sent (on this forum) by Anthony Damico for another application.  Thanks to Anthony!

Good news: The estimate is almost the same as the estimates obtained from SAS, SUDAAN and STATA runs.

Additional Information:  STATA provides a NOTE that " 84 strata omitted because no subpopulation members".
SAS LOG (proc surveymeans) provides a NOTE that "Only one cluster in a stratum in domain Asian_with_diab for variable(s) TOTEXP13. The estimate of variance for TOTEXP13 will
      omit this stratum".


Thanks,

Pradip Muhuri




library(foreign)
library(survey)
library(dplyr)

tf <- tempfile()

download.file( "https://meps.ahrq.gov/mepsweb/data_files/pufs/h163ssp.zip", tf , mode = 'wb' )

z <- unzip( tf , exdir = tempdir() )

x <- read.xport( z )

names( x ) <- tolower( names( x ) )

mydata <- select(x, varstr, varpsu, perwt13f, diabdx, totexp13, racethx)

mydata[mydata <=0] <- NA

design <- svydesign(id=~varpsu,strat=~varstr, weights=~perwt13f, data=x, nest=TRUE)


# include missings as "No" values here
#design <-
#  update(design,
#        xbpchek53 = ifelse(bpchek53 ==1,'yes','no or missing'),
  #       xcholck53 = ifelse(cholck53 ==1, 'yes','no or missing')
  #)

# get the estimate for "totexp13" for the subset that includes Asians with diabetes diagnosed
svymean(~ totexp13, subset(design, racethx==4 & diabdx==1))

Pradip K. Muhuri,  AHRQ/CFACT
5600 Fishers Lane # 7N142A, Rockville, MD 20857
Tel: 301-427-1564




	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Thu Jun 23 05:54:38 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Wed, 22 Jun 2016 23:54:38 -0400
Subject: [R] svymean using the survey package - strata containing no
 subpopulation members
In-Reply-To: <BN1PR09MB0305DF41B9CE3C31519FBD50D32D0@BN1PR09MB0305.namprd09.prod.outlook.com>
References: <BN1PR09MB0305DF41B9CE3C31519FBD50D32D0@BN1PR09MB0305.namprd09.prod.outlook.com>
Message-ID: <CAOwvMDyFmfo8pPDEDhNNaz8nkxSnQDQD-Rr3j9AAGCP33zQtzQ@mail.gmail.com>

hi pradip, with meps you should be able to match precisely between r+survey
and those other languages[1]

if i had to guess, i would say that your sas and stata code is actually
doing the equivalent of this, which is not correct.  check the journal
article table #1 for syntax comparisons

    design <- svydesign(id=~varpsu,strat=~varstr, weights=~perwt13f,
data=subset(x, racethx==4 & diabdx==1), nest=TRUE)
    svymean(~ totexp13, design)
    #Error in onestrat(x[index, , drop = FALSE], clusters[index],
nPSU[index][1],  :
    #  Stratum (1004) has only one PSU at stage 1


more detailed discussion of lonely psu behavior at [2] including how to
override this error -- but i think it comes from faulty design
specification so should not be necessary?  thanks


[1] https://journal.r-project.org/archive/2009-2/RJournal_2009-2_Damico.pdf
[2] http://faculty.washington.edu/tlumley/old-survey/exmample-lonely.html





On Wed, Jun 22, 2016 at 9:32 PM, Muhuri, Pradip (AHRQ/CFACT) <
Pradip.Muhuri at ahrq.hhs.gov> wrote:

> Hi,
>
> Below is a reproducible example that produces the estimate of "totexp13"
> (total health care expenditure 2013) for the subpopulation that includes
> "Asians with diabetes diagnosed" in MEPS. The R script below downloads file
> from the web for processing.
>
> Issue/Question: The R/survey package does not seem to provide a NOTE
> regarding the number of strata containing NO SUBOPOPULATION MEMBERS (in
> this case - Asians with diabetes diagnosed in MEPS 2013). Is there a way to
> get this count or ask R to provide this information?  Any hints will be
> appreciated.
>
> Acknowledgements:   The current R script is a tweaked-version of the code
> originally sent (on this forum) by Anthony Damico for another application.
> Thanks to Anthony!
>
> Good news: The estimate is almost the same as the estimates obtained from
> SAS, SUDAAN and STATA runs.
>
> Additional Information:  STATA provides a NOTE that " 84 strata omitted
> because no subpopulation members".
> SAS LOG (proc surveymeans) provides a NOTE that "Only one cluster in a
> stratum in domain Asian_with_diab for variable(s) TOTEXP13. The estimate of
> variance for TOTEXP13 will
>       omit this stratum".
>
>
> Thanks,
>
> Pradip Muhuri
>
>
>
>
> library(foreign)
> library(survey)
> library(dplyr)
>
> tf <- tempfile()
>
> download.file( "https://meps.ahrq.gov/mepsweb/data_files/pufs/h163ssp.zip",
> tf , mode = 'wb' )
>
> z <- unzip( tf , exdir = tempdir() )
>
> x <- read.xport( z )
>
> names( x ) <- tolower( names( x ) )
>
> mydata <- select(x, varstr, varpsu, perwt13f, diabdx, totexp13, racethx)
>
> mydata[mydata <=0] <- NA
>
> design <- svydesign(id=~varpsu,strat=~varstr, weights=~perwt13f, data=x,
> nest=TRUE)
>
>
> # include missings as "No" values here
> #design <-
> #  update(design,
> #        xbpchek53 = ifelse(bpchek53 ==1,'yes','no or missing'),
>   #       xcholck53 = ifelse(cholck53 ==1, 'yes','no or missing')
>   #)
>
> # get the estimate for "totexp13" for the subset that includes Asians with
> diabetes diagnosed
> svymean(~ totexp13, subset(design, racethx==4 & diabdx==1))
>
> Pradip K. Muhuri,  AHRQ/CFACT
> 5600 Fishers Lane # 7N142A, Rockville, MD 20857
> Tel: 301-427-1564
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Jun 23 09:36:52 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 23 Jun 2016 07:36:52 +0000
Subject: [R] Generate list if sequence form two vector element
In-Reply-To: <CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>
References: <1890354796.7443289.1466580756297.JavaMail.yahoo.ref@mail.yahoo.com>
	<1890354796.7443289.1466580756297.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fWgvz-qp+jNVHBwwmduHh++HuPqosgEZSwqGfNuMTFWLg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032036@SRVEXCHMBX.precheza.cz>

Hi

what about

mapply(":", a, b)

Sometimes R can behave like a magic.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Wednesday, June 22, 2016 10:01 AM
> To: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
> Cc: R-help Mailing List <r-help at r-project.org>
> Subject: Re: [R] Generate list if sequence form two vector element
>
> Hi Tanvir,
> Not at all elegant, but:
>
> make.seq<-function(x) return(seq(x[1],x[2]))
> apply(matrix(c(a,b),ncol=2),1,make.seq)
>
> Jim
>
>
> On Wed, Jun 22, 2016 at 5:32 PM, Mohammad Tanvir Ahamed via R-help <r-
> help at r-project.org> wrote:
> > Hi,
> > I want to do the follow thing
> >
> > Input :
> > a <- c(1,3,6,9)
> >
> >
> > b<-c(10,7,20,2)
> >
> >
> > Expected outcome :
> >
> > d<-list(1:10,3:7,6:20,2:9)
> >
> >
> >
> > Thanks !!
> >
> >
> >
> > Tanvir Ahamed
> > G?teborg, Sweden  |  mashranga at yahoo.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From friendly at yorku.ca  Thu Jun 23 15:03:03 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 23 Jun 2016 09:03:03 -0400
Subject: [R] biplot
In-Reply-To: <CA+jRDxDdgu-Zz1A04xJELaXe5TFr-H=rh5MVZ21au6C4=wm99g@mail.gmail.com>
References: <CA+jRDxDdgu-Zz1A04xJELaXe5TFr-H=rh5MVZ21au6C4=wm99g@mail.gmail.com>
Message-ID: <2718cd52-3fa4-ad98-72ac-3b08fd51cba2@yorku.ca>

On 6/22/2016 8:39 AM, Shane Carey wrote:
> Hey,
>
> Does anyone know how to remove labels from a biplot? I want to input them
> manually as they are currently overlapping.
>

Rather than doing them manually,
you might have better luck with ggbiplot, and the ggrepel package 
designed to 'repel' point labels so they don't overlap.

install_github("vqv/ggbiplot")
https://cran.r-project.org/web/packages/ggrepel/vignettes/ggrepel.html

-Michael


From S.Ellison at LGCGroup.com  Thu Jun 23 15:05:54 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 23 Jun 2016 14:05:54 +0100
Subject: [R] biplot
In-Reply-To: <2718cd52-3fa4-ad98-72ac-3b08fd51cba2@yorku.ca>
References: <CA+jRDxDdgu-Zz1A04xJELaXe5TFr-H=rh5MVZ21au6C4=wm99g@mail.gmail.com>
	<2718cd52-3fa4-ad98-72ac-3b08fd51cba2@yorku.ca>
Message-ID: <1A8C1289955EF649A09086A153E2672403E1956067@GBTEDVPEXCMB04.corp.lgc-group.com>

> Rather than doing them manually,
> you might have better luck with ggbiplot, and the ggrepel package designed to
> 'repel' point labels so they don't overlap.


For base graphics, 'thigmophobe.lables' in the plotrix package also works to avoid label overlap.

Steve E



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From G.Maubach at weinwolf.de  Thu Jun 23 15:57:59 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 23 Jun 2016 15:57:59 +0200
Subject: [R] Subscripting problem with is.na()
Message-ID: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>

Hi All,

I would like to recode my NAs to 0. Using a single vector everything is 
fine.

But if I use a data.frame things go wrong:

-- cut --

var1 <- c(1:3, NA, 5:7, NA, 9:10)
var2 <- c(1:3, NA, 5:7, NA, 9:10)
ds_test <-
  data.frame(var1, var2)

test <- var1
test[is.na(test)] <- 0
test  # NA recoded OK

# First try
ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG

# Second try
ds_test[is.na("var1")] <- 0 
ds_test$var1  # not recoded WRONG

# Third try: to me the most intuitive approach
is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in 
integerOneIndex WRONG

# Fourth try
ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG

-- cut --
 
How can I do it correctly?

Where could I have found something about it?

Kind regards

Georg


From Pascal.Niklaus at ieu.uzh.ch  Thu Jun 23 08:29:09 2016
From: Pascal.Niklaus at ieu.uzh.ch (Pascal A. Niklaus)
Date: Thu, 23 Jun 2016 08:29:09 +0200
Subject: [R] import of data set and warning from R CMD check
In-Reply-To: <CAJuCY5zi6-LwVZyr=Jt+aTGDXOWj1=Qzf9V0kP3d+fX+uwH4JQ@mail.gmail.com>
References: <57641B0C.6030705@ieu.uzh.ch>
	<CAJuCY5zi6-LwVZyr=Jt+aTGDXOWj1=Qzf9V0kP3d+fX+uwH4JQ@mail.gmail.com>
Message-ID: <576B81B5.8020806@ieu.uzh.ch>

Dear Thierry,

Thanks, that indeed solved the warning.

Still, I think the message from R CMD check is confusing since the hint 
seems not to work with the current R version.

Pascal

On 2016-06-21 11:31, Thierry Onkelinx wrote:
> Dear Pascal,
>
> You could try to use data(CO2, package = "datasets") instead of data(CO2)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
>
> 2016-06-17 17:45 GMT+02:00 Pascal A. Niklaus <pascal.niklaus at ieu.uzh.ch
> <mailto:pascal.niklaus at ieu.uzh.ch>>:
>
>     Hi all,
>
>     When checking an R package, I get:
>
>     |Consider adding importFrom("datasets","CO2")
>
>     (this data set is used in some example code)
>
>     However, when I add the suggested 'importFrom' statement to NAMESPACE
>     (using roxygen2), I get
>     |
>     |Error :object ?CO2? is not exported by 'namespace:datasets'|
>     ||
>     |I understand that datasets are not exported, and the comment printed by
>     'R CMD check' seems not to have any consequences, but it nevertheless
>     seems inconsistent to me. But maybe I miss something here...
>
>     Pascal
>
>     |
>
>     --
>
>     Dr. Pascal A. Niklaus
>     Department of Evolutionary Biology and Environmental Studies
>     University of Zurich
>     Winterthurerstrasse 190
>     CH-8057 Zurich / Switzerland
>
>


From nikakar at gmail.com  Thu Jun 23 11:59:05 2016
From: nikakar at gmail.com (Nicole Karakin)
Date: Thu, 23 Jun 2016 10:59:05 +0100
Subject: [R] rgl and rglwidget: Weird behaviour than animating lines
Message-ID: <CABLazBb3XoCN_X6JJOwkLOVF+uf8D9JW2UQtFuArk_-4RBhtvA@mail.gmail.com>

I am trying to follow help and Internet examples to create a very
simple animation of a 3d-line in R. This is just a test and my final
goal is to use this functionality to visually verify results of some
geometrical transformations on 3d-movement data that I am analysing.
So basically I need nothing more than a ?3d-player? interface that
allows for usual interaction (rotation, zoom, play, stop, slide).

I figured out that rgl package does the job and I am able to use it
for the sphere/points animation. But now I need to use it on lines and
I get very strange results. In the example below there are 4 points
and two lines (cyan and red) that connect the same points but the red
line is for some reason in the ?wrong? place. The animation doesn?t
make sense neither. Now, I am thinking may be it is impossible to do
>> to animate more than one vertex with more than one attribute? But I
don?t see this in documentation and obviously it is possible because
line is animated! I spent quite a long time trying to figure out what
is going on and will appreciate any help/advise/directions on how i
can 'fix' this behaviour.
thanks, Nicole

Ps: the code below is a chunk in the markdown file and I am using Rstudio

#-----------------------------------------
require(rgl)
require(rglwidget)
p11=c(0,0,0)
p21=c(50,50,0)
p12=c(50,0,0)
p22=c(10,50,50)

saveopts <- options(rgl.useNULL = TRUE)
did=list()
did[[1]]=plot3d(rbind(p11,p21,p12,p22), type="s", alpha = 1, lwd = 5,
col = c('brown','darkgreen','orange','green'))
did[[2]]=spheres3d(c(100,100,100), alpha = 1, lwd = 5, col = "blue",radius=2)
did[[3]]=lines3d(rbind(p11,p21),lwd=8, col='cyan',alpha=.9)
did[[4]]=planes3d(0, 0, 1, 0, alpha=.4, col='green')
did[[5]]=lines3d(rbind(p11,p21),lwd=2, col='red')
aspect3d(1, 1, 1)
did[[6]]=grid3d(c("x-", "z-"),at = NULL,col = "gray",lwd = .5,lty = 1,n = 5)
sceneT = rglwidget(elementId = "plot3dT",width=500, height=300) #%>%
rgl.ids()
rgl.attrib(id=did[[3]],attrib = c(1:length(did[[3]])))

playwidget(sceneT,list(
  vertexControl(values = rbind(c(0,0,0,0,0,0),c(50,50,50,50,50,50)),
             vertices = 1:6, attributes = "z", objid = did[[4]], param
= 1:2,interp =T),
  vertexControl(values = r1,
             vertices = 1:2, attributes = c('x',"y","z",'x',"y","z"),
objid = did[[5]], param = 1:2,interp =T)),
  start = 1, stop = 2, step = .1, precision = 3)
options(saveopts)


From istazahn at gmail.com  Thu Jun 23 16:16:26 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 23 Jun 2016 10:16:26 -0400
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
Message-ID: <CA+vqiLGr1iRURAsSu+4cXEYrZsvYgWUU_wZmMjcmaWuZO0-C2Q@mail.gmail.com>

Suggestion: figure out the correct extraction syntax first. One you do that
replacement will be easy.

See ?Extract for all the messy details.

Best,
Ista
On Jun 23, 2016 10:00 AM, <G.Maubach at weinwolf.de> wrote:

> Hi All,
>
> I would like to recode my NAs to 0. Using a single vector everything is
> fine.
>
> But if I use a data.frame things go wrong:
>
> -- cut --
>
> var1 <- c(1:3, NA, 5:7, NA, 9:10)
> var2 <- c(1:3, NA, 5:7, NA, 9:10)
> ds_test <-
>   data.frame(var1, var2)
>
> test <- var1
> test[is.na(test)] <- 0
> test  # NA recoded OK
>
> # First try
> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>
> # Second try
> ds_test[is.na("var1")] <- 0
> ds_test$var1  # not recoded WRONG
>
> # Third try: to me the most intuitive approach
> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
> integerOneIndex WRONG
>
> # Fourth try
> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>
> -- cut --
>
> How can I do it correctly?
>
> Where could I have found something about it?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Jun 23 16:24:58 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 23 Jun 2016 15:24:58 +0100
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
Message-ID: <20160623152458.Horde.Zo0kSd0XEZDN7t01sICUEei@mail.sapo.pt>

Hello,

You could do

ds_test[is.na(ds_test$var1), ] <- 0? # note the comma

or, more generally,

ds_test[] <- lapply(ds_test, function(x) {x[is.na(x)] <- 0; x})

Hope this helps,

Rui Barradas
?

Citando G.Maubach at weinwolf.de:

> Hi All,
>
> I would like to recode my NAs to 0. Using a single vector everything is
> fine.
>
> But if I use a data.frame things go wrong:
>
> -- cut --
>
> var1 <- c(1:3, NA, 5:7, NA, 9:10)
> var2 <- c(1:3, NA, 5:7, NA, 9:10)
> ds_test <-
> data.frame(var1, var2)
>
> test <- var1
> test[is.na(test)] <- 0
> test? # NA recoded OK
>
> # First try
> ds_test[is.na(ds_test$var1)] <- 0? # duplicate subscripts WRONG
>
> # Second try
> ds_test[is.na("var1")] <- 0
> ds_test$var1? # not recoded WRONG
>
> # Third try: to me the most intuitive approach
> is.na(ds_test["var1"]) <- 0? # attempt to select less than one element in
> integerOneIndex WRONG
>
> # Fourth try
> ds_test[is.na(var1)] <- 0? # duplicate subscripts for columns WRONG
>
> -- cut --
>
> How can I do it correctly?
>
> Where could I have found something about it?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Thu Jun 23 16:27:49 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 23 Jun 2016 16:27:49 +0200
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
Message-ID: <5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>

Dear Georg,

You need to learn a bit more about the subsetting methods, depending on 
the object structure you're trying to subset.

More specifically, when you run this: ds_test[is.na(ds_test$var1)]
you get this error: "Error in `[.data.frame`(ds_test, 
is.na(ds_test$var1)) : undefined columns selected"

This means that R does not understand which column you're trying to 
select. But you're actually trying to select rows.

Using a single bracket '[' on a data.frame does the same as for 
matrices: you need to specify rows and columns, like this:
ds_test[is.na(ds_test$var1), ] ## notice the last comma
ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you 
didn't specify any after the comma

If you want it only for "var1", then you need to specify the column:
ds_test[is.na(ds_test$var1), "var1"] <- 0

It's the same problem with your 2nd and 4th tries (4th one has other 
problems). Your 3rd try does not change ds_test at all.

HTH,
Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
> Hi All,
>
> I would like to recode my NAs to 0. Using a single vector everything is
> fine.
>
> But if I use a data.frame things go wrong:
>
> -- cut --
>
> var1 <- c(1:3, NA, 5:7, NA, 9:10)
> var2 <- c(1:3, NA, 5:7, NA, 9:10)
> ds_test <-
>    data.frame(var1, var2)
>
> test <- var1
> test[is.na(test)] <- 0
> test  # NA recoded OK
>
> # First try
> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>
> # Second try
> ds_test[is.na("var1")] <- 0
> ds_test$var1  # not recoded WRONG
>
> # Third try: to me the most intuitive approach
> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
> integerOneIndex WRONG
>
> # Fourth try
> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>
> -- cut --
>   
> How can I do it correctly?
>
> Where could I have found something about it?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Thu Jun 23 16:28:25 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 23 Jun 2016 10:28:25 -0400
Subject: [R] rgl and rglwidget: Weird behaviour than animating lines
In-Reply-To: <CABLazBb3XoCN_X6JJOwkLOVF+uf8D9JW2UQtFuArk_-4RBhtvA@mail.gmail.com>
References: <CABLazBb3XoCN_X6JJOwkLOVF+uf8D9JW2UQtFuArk_-4RBhtvA@mail.gmail.com>
Message-ID: <d3f9097f-b101-a14f-1362-58a6e48472ab@gmail.com>

On 23/06/2016 5:59 AM, Nicole Karakin wrote:
> I am trying to follow help and Internet examples to create a very
> simple animation of a 3d-line in R. This is just a test and my final
> goal is to use this functionality to visually verify results of some
> geometrical transformations on 3d-movement data that I am analysing.
> So basically I need nothing more than a ?3d-player? interface that
> allows for usual interaction (rotation, zoom, play, stop, slide).
>
> I figured out that rgl package does the job and I am able to use it
> for the sphere/points animation. But now I need to use it on lines and
> I get very strange results. In the example below there are 4 points
> and two lines (cyan and red) that connect the same points but the red
> line is for some reason in the ?wrong? place. The animation doesn?t
> make sense neither. Now, I am thinking may be it is impossible to do
> >> to animate more than one vertex with more than one attribute? But I
> don?t see this in documentation and obviously it is possible because
> line is animated! I spent quite a long time trying to figure out what
> is going on and will appreciate any help/advise/directions on how i
> can 'fix' this behaviour.
> thanks, Nicole
>
> Ps: the code below is a chunk in the markdown file and I am using Rstudio
>
> #-----------------------------------------
> require(rgl)
> require(rglwidget)
> p11=c(0,0,0)
> p21=c(50,50,0)
> p12=c(50,0,0)
> p22=c(10,50,50)
>
> saveopts <- options(rgl.useNULL = TRUE)
> did=list()
> did[[1]]=plot3d(rbind(p11,p21,p12,p22), type="s", alpha = 1, lwd = 5,
> col = c('brown','darkgreen','orange','green'))
> did[[2]]=spheres3d(c(100,100,100), alpha = 1, lwd = 5, col = "blue",radius=2)
> did[[3]]=lines3d(rbind(p11,p21),lwd=8, col='cyan',alpha=.9)
> did[[4]]=planes3d(0, 0, 1, 0, alpha=.4, col='green')
> did[[5]]=lines3d(rbind(p11,p21),lwd=2, col='red')
> aspect3d(1, 1, 1)
> did[[6]]=grid3d(c("x-", "z-"),at = NULL,col = "gray",lwd = .5,lty = 1,n = 5)
> sceneT = rglwidget(elementId = "plot3dT",width=500, height=300) #%>%
> rgl.ids()
> rgl.attrib(id=did[[3]],attrib = c(1:length(did[[3]])))
>
> playwidget(sceneT,list(
>    vertexControl(values = rbind(c(0,0,0,0,0,0),c(50,50,50,50,50,50)),
>               vertices = 1:6, attributes = "z", objid = did[[4]], param
> = 1:2,interp =T),
>    vertexControl(values = r1,
>               vertices = 1:2, attributes = c('x',"y","z",'x',"y","z"),
> objid = did[[5]], param = 1:2,interp =T)),
>    start = 1, stop = 2, step = .1, precision = 3)
> options(saveopts)

You can run rglwidget-using scripts in RStudio (or other front ends) and 
they'll generally work more or less the same as they do in a Markdown 
document.  However, when I try to do that with this one, it fails, 
because you use r1 without defining it.
You might want to think about deleting everything unnecessary as well:  
if you want to illustrate problems with lines, just show lines.

You should also say what versions of rgl and rglwidget you're using; the 
ones on R-forge are quite a bit newer than the ones on CRAN.

Duncan Murdoch


From ivan.calandra at univ-reims.fr  Thu Jun 23 16:34:30 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 23 Jun 2016 16:34:30 +0200
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
Message-ID: <fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>

My statement "Using a single bracket '[' on a data.frame does the same 
as for matrices: you need to specify rows and columns" was not correct.


When you use a single bracket on a list with only one argument in 
between, then R extracts "elements", i.e. columns in the case of a 
data.frame. This explains your errors.

But it is possible to use a single bracket on a data.frame with 2 
arguments (rows, columns) separated by a comma, as with matrices. This 
is the solution you received.

Ivan


--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
> Dear Georg,
>
> You need to learn a bit more about the subsetting methods, depending 
> on the object structure you're trying to subset.
>
> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
> you get this error: "Error in `[.data.frame`(ds_test, 
> is.na(ds_test$var1)) : undefined columns selected"
>
> This means that R does not understand which column you're trying to 
> select. But you're actually trying to select rows.
>
> Using a single bracket '[' on a data.frame does the same as for 
> matrices: you need to specify rows and columns, like this:
> ds_test[is.na(ds_test$var1), ] ## notice the last comma
> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because 
> you didn't specify any after the comma
>
> If you want it only for "var1", then you need to specify the column:
> ds_test[is.na(ds_test$var1), "var1"] <- 0
>
> It's the same problem with your 2nd and 4th tries (4th one has other 
> problems). Your 3rd try does not change ds_test at all.
>
> HTH,
> Ivan
>
> -- 
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> -- 
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>> Hi All,
>>
>> I would like to recode my NAs to 0. Using a single vector everything is
>> fine.
>>
>> But if I use a data.frame things go wrong:
>>
>> -- cut --
>>
>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>> ds_test <-
>>    data.frame(var1, var2)
>>
>> test <- var1
>> test[is.na(test)] <- 0
>> test  # NA recoded OK
>>
>> # First try
>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>>
>> # Second try
>> ds_test[is.na("var1")] <- 0
>> ds_test$var1  # not recoded WRONG
>>
>> # Third try: to me the most intuitive approach
>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one 
>> element in
>> integerOneIndex WRONG
>>
>> # Fourth try
>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>>
>> -- cut --
>>   How can I do it correctly?
>>
>> Where could I have found something about it?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Thu Jun 23 17:06:13 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 23 Jun 2016 08:06:13 -0700
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
Message-ID: <CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>

Sorry, Ivan, your statement is incorrect:

"When you use a single bracket on a list with only one argument in
between, then R extracts "elements", i.e. columns in the case of a
data.frame. This explains your errors. "

e.g.

> ex <- data.frame(a = 1:3, b = letters[1:3])
> a <- 1:3

> identical(ex[1], a)
[1] FALSE

> class(ex[1])
[1] "data.frame"
> class(a)
[1] "integer"

Compare:

> identical(ex[[1]], a)
[1] TRUE

Why? Single bracket extraction on a list results in a list; double
bracket extraction results in the element of the list ( a "column" in
the case of a data frame, which is a specific kind of list). The
relevant sections of ?Extract are:

"Indexing by [ is similar to atomic vectors and selects a **list** of
the specified element(s).

Both [[ and $ select a **single element of the list**. "


Hope this clarifies this often-confused issue.


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
<ivan.calandra at univ-reims.fr> wrote:
> My statement "Using a single bracket '[' on a data.frame does the same as
> for matrices: you need to specify rows and columns" was not correct.
>
>
> When you use a single bracket on a list with only one argument in between,
> then R extracts "elements", i.e. columns in the case of a data.frame. This
> explains your errors.
>
> But it is possible to use a single bracket on a data.frame with 2 arguments
> (rows, columns) separated by a comma, as with matrices. This is the solution
> you received.
>
> Ivan
>
>
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>>
>> Dear Georg,
>>
>> You need to learn a bit more about the subsetting methods, depending on
>> the object structure you're trying to subset.
>>
>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
>> : undefined columns selected"
>>
>> This means that R does not understand which column you're trying to
>> select. But you're actually trying to select rows.
>>
>> Using a single bracket '[' on a data.frame does the same as for matrices:
>> you need to specify rows and columns, like this:
>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
>> didn't specify any after the comma
>>
>> If you want it only for "var1", then you need to specify the column:
>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>>
>> It's the same problem with your 2nd and 4th tries (4th one has other
>> problems). Your 3rd try does not change ds_test at all.
>>
>> HTH,
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> Scientific Mediator
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>>>
>>> Hi All,
>>>
>>> I would like to recode my NAs to 0. Using a single vector everything is
>>> fine.
>>>
>>> But if I use a data.frame things go wrong:
>>>
>>> -- cut --
>>>
>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>>> ds_test <-
>>>    data.frame(var1, var2)
>>>
>>> test <- var1
>>> test[is.na(test)] <- 0
>>> test  # NA recoded OK
>>>
>>> # First try
>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>>>
>>> # Second try
>>> ds_test[is.na("var1")] <- 0
>>> ds_test$var1  # not recoded WRONG
>>>
>>> # Third try: to me the most intuitive approach
>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
>>> integerOneIndex WRONG
>>>
>>> # Fourth try
>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>>>
>>> -- cut --
>>>   How can I do it correctly?
>>>
>>> Where could I have found something about it?
>>>
>>> Kind regards
>>>
>>> Georg
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at univ-reims.fr  Thu Jun 23 17:13:39 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 23 Jun 2016 17:13:39 +0200
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
Message-ID: <671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>

Thank you Bert for this clarification. It is indeed an important point.

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
> Sorry, Ivan, your statement is incorrect:
>
> "When you use a single bracket on a list with only one argument in
> between, then R extracts "elements", i.e. columns in the case of a
> data.frame. This explains your errors. "
>
> e.g.
>
>> ex <- data.frame(a = 1:3, b = letters[1:3])
>> a <- 1:3
>> identical(ex[1], a)
> [1] FALSE
>
>> class(ex[1])
> [1] "data.frame"
>> class(a)
> [1] "integer"
>
> Compare:
>
>> identical(ex[[1]], a)
> [1] TRUE
>
> Why? Single bracket extraction on a list results in a list; double
> bracket extraction results in the element of the list ( a "column" in
> the case of a data frame, which is a specific kind of list). The
> relevant sections of ?Extract are:
>
> "Indexing by [ is similar to atomic vectors and selects a **list** of
> the specified element(s).
>
> Both [[ and $ select a **single element of the list**. "
>
>
> Hope this clarifies this often-confused issue.
>
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
> <ivan.calandra at univ-reims.fr> wrote:
>> My statement "Using a single bracket '[' on a data.frame does the same as
>> for matrices: you need to specify rows and columns" was not correct.
>>
>>
>> When you use a single bracket on a list with only one argument in between,
>> then R extracts "elements", i.e. columns in the case of a data.frame. This
>> explains your errors.
>>
>> But it is possible to use a single bracket on a data.frame with 2 arguments
>> (rows, columns) separated by a comma, as with matrices. This is the solution
>> you received.
>>
>> Ivan
>>
>>
>> --
>> Ivan Calandra, PhD
>> Scientific Mediator
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>>> Dear Georg,
>>>
>>> You need to learn a bit more about the subsetting methods, depending on
>>> the object structure you're trying to subset.
>>>
>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
>>> : undefined columns selected"
>>>
>>> This means that R does not understand which column you're trying to
>>> select. But you're actually trying to select rows.
>>>
>>> Using a single bracket '[' on a data.frame does the same as for matrices:
>>> you need to specify rows and columns, like this:
>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
>>> didn't specify any after the comma
>>>
>>> If you want it only for "var1", then you need to specify the column:
>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>>>
>>> It's the same problem with your 2nd and 4th tries (4th one has other
>>> problems). Your 3rd try does not change ds_test at all.
>>>
>>> HTH,
>>> Ivan
>>>
>>> --
>>> Ivan Calandra, PhD
>>> Scientific Mediator
>>> University of Reims Champagne-Ardenne
>>> GEGENAA - EA 3795
>>> CREA - 2 esplanade Roland Garros
>>> 51100 Reims, France
>>> +33(0)3 26 77 36 89
>>> ivan.calandra at univ-reims.fr
>>> --
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>> https://publons.com/author/705639/
>>>
>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>>>> Hi All,
>>>>
>>>> I would like to recode my NAs to 0. Using a single vector everything is
>>>> fine.
>>>>
>>>> But if I use a data.frame things go wrong:
>>>>
>>>> -- cut --
>>>>
>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>>>> ds_test <-
>>>>     data.frame(var1, var2)
>>>>
>>>> test <- var1
>>>> test[is.na(test)] <- 0
>>>> test  # NA recoded OK
>>>>
>>>> # First try
>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>>>>
>>>> # Second try
>>>> ds_test[is.na("var1")] <- 0
>>>> ds_test$var1  # not recoded WRONG
>>>>
>>>> # Third try: to me the most intuitive approach
>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
>>>> integerOneIndex WRONG
>>>>
>>>> # Fourth try
>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>>>>
>>>> -- cut --
>>>>    How can I do it correctly?
>>>>
>>>> Where could I have found something about it?
>>>>
>>>> Kind regards
>>>>
>>>> Georg
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Jun 23 17:46:13 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 23 Jun 2016 15:46:13 +0000
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
Message-ID: <17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>

The function is.na() returns a matrix when applied to a data.frame so you can easily convert all the NAs to 0's:

> ds_test
   var1 var2
1     1    1
2     2    2
3     3    3
4    NA   NA
5     5    5
6     6    6
7     7    7
8    NA   NA
9     9    9
10   10   10
> is.na(ds_test)
       var1  var2
 [1,] FALSE FALSE
 [2,] FALSE FALSE
 [3,] FALSE FALSE
 [4,]  TRUE  TRUE
 [5,] FALSE FALSE
 [6,] FALSE FALSE
 [7,] FALSE FALSE
 [8,]  TRUE  TRUE
 [9,] FALSE FALSE
[10,] FALSE FALSE
> ds_test[is.na(ds_test)] <- 0
> ds_test
   var1 var2
1     1    1
2     2    2
3     3    3
4     0    0
5     5    5
6     6    6
7     7    7
8     0    0
9     9    9
10   10   10

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
Sent: Thursday, June 23, 2016 10:14 AM
To: R Help
Subject: Re: [R] Subscripting problem with is.na()

Thank you Bert for this clarification. It is indeed an important point.

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
> Sorry, Ivan, your statement is incorrect:
>
> "When you use a single bracket on a list with only one argument in
> between, then R extracts "elements", i.e. columns in the case of a
> data.frame. This explains your errors. "
>
> e.g.
>
>> ex <- data.frame(a = 1:3, b = letters[1:3])
>> a <- 1:3
>> identical(ex[1], a)
> [1] FALSE
>
>> class(ex[1])
> [1] "data.frame"
>> class(a)
> [1] "integer"
>
> Compare:
>
>> identical(ex[[1]], a)
> [1] TRUE
>
> Why? Single bracket extraction on a list results in a list; double
> bracket extraction results in the element of the list ( a "column" in
> the case of a data frame, which is a specific kind of list). The
> relevant sections of ?Extract are:
>
> "Indexing by [ is similar to atomic vectors and selects a **list** of
> the specified element(s).
>
> Both [[ and $ select a **single element of the list**. "
>
>
> Hope this clarifies this often-confused issue.
>
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
> <ivan.calandra at univ-reims.fr> wrote:
>> My statement "Using a single bracket '[' on a data.frame does the same as
>> for matrices: you need to specify rows and columns" was not correct.
>>
>>
>> When you use a single bracket on a list with only one argument in between,
>> then R extracts "elements", i.e. columns in the case of a data.frame. This
>> explains your errors.
>>
>> But it is possible to use a single bracket on a data.frame with 2 arguments
>> (rows, columns) separated by a comma, as with matrices. This is the solution
>> you received.
>>
>> Ivan
>>
>>
>> --
>> Ivan Calandra, PhD
>> Scientific Mediator
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>>> Dear Georg,
>>>
>>> You need to learn a bit more about the subsetting methods, depending on
>>> the object structure you're trying to subset.
>>>
>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
>>> : undefined columns selected"
>>>
>>> This means that R does not understand which column you're trying to
>>> select. But you're actually trying to select rows.
>>>
>>> Using a single bracket '[' on a data.frame does the same as for matrices:
>>> you need to specify rows and columns, like this:
>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
>>> didn't specify any after the comma
>>>
>>> If you want it only for "var1", then you need to specify the column:
>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>>>
>>> It's the same problem with your 2nd and 4th tries (4th one has other
>>> problems). Your 3rd try does not change ds_test at all.
>>>
>>> HTH,
>>> Ivan
>>>
>>> --
>>> Ivan Calandra, PhD
>>> Scientific Mediator
>>> University of Reims Champagne-Ardenne
>>> GEGENAA - EA 3795
>>> CREA - 2 esplanade Roland Garros
>>> 51100 Reims, France
>>> +33(0)3 26 77 36 89
>>> ivan.calandra at univ-reims.fr
>>> --
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>> https://publons.com/author/705639/
>>>
>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>>>> Hi All,
>>>>
>>>> I would like to recode my NAs to 0. Using a single vector everything is
>>>> fine.
>>>>
>>>> But if I use a data.frame things go wrong:
>>>>
>>>> -- cut --
>>>>
>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>>>> ds_test <-
>>>>     data.frame(var1, var2)
>>>>
>>>> test <- var1
>>>> test[is.na(test)] <- 0
>>>> test  # NA recoded OK
>>>>
>>>> # First try
>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>>>>
>>>> # Second try
>>>> ds_test[is.na("var1")] <- 0
>>>> ds_test$var1  # not recoded WRONG
>>>>
>>>> # Third try: to me the most intuitive approach
>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
>>>> integerOneIndex WRONG
>>>>
>>>> # Fourth try
>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>>>>
>>>> -- cut --
>>>>    How can I do it correctly?
>>>>
>>>> Where could I have found something about it?
>>>>
>>>> Kind regards
>>>>
>>>> Georg
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From awawaed at yahoo.com  Thu Jun 23 19:15:15 2016
From: awawaed at yahoo.com (A A)
Date: Thu, 23 Jun 2016 17:15:15 +0000 (UTC)
Subject: [R] Saving .eps files with Times New Roman font
References: <229458692.358983.1466702115543.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <229458692.358983.1466702115543.JavaMail.yahoo@mail.yahoo.com>

In RGui, I'm running the following bit of code:
windowsFonts(A=windowsFont("Times New Roman"))
plot(0,0, ylab='y axis', xlab='x axis',main='title',family="A")
The labels and title appear in Times New Roman font. So far, so good. However, when I right click the figure and select 'Save as postscript...', I get a .eps file of the plot, but without the font formatting that I applied. Is there any way to apply the formatting so that it gets saved?

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Jun 23 19:26:23 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 23 Jun 2016 10:26:23 -0700
Subject: [R] Saving .eps files with Times New Roman font
In-Reply-To: <229458692.358983.1466702115543.JavaMail.yahoo@mail.yahoo.com>
References: <229458692.358983.1466702115543.JavaMail.yahoo.ref@mail.yahoo.com>
	<229458692.358983.1466702115543.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CD7F423D-6183-4050-8EA7-CF60D84E8E8A@comcast.net>


> On Jun 23, 2016, at 10:15 AM, A A via R-help <r-help at r-project.org> wrote:
> 
> In RGui, I'm running the following bit of code:
> windowsFonts(A=windowsFont("Times New Roman"))
> plot(0,0, ylab='y axis', xlab='x axis',main='title',family="A")
> The labels and title appear in Times New Roman font. So far, so good. However, when I right click the figure and select 'Save as postscript...', I get a .eps file of the plot, but without the font formatting that I applied. Is there any way to apply the formatting so that it gets saved?

I'm now a Windows user but I expect that the windowsFonts function is setting the fonts for the interactive graphics device rather than the postscript device. You should try reviewing:

?postscriptFonts
?postscript   # if you want to control the device settings

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Thu Jun 23 19:31:13 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 23 Jun 2016 10:31:13 -0700
Subject: [R] Saving .eps files with Times New Roman font
In-Reply-To: <229458692.358983.1466702115543.JavaMail.yahoo@mail.yahoo.com>
References: <229458692.358983.1466702115543.JavaMail.yahoo.ref@mail.yahoo.com>
	<229458692.358983.1466702115543.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <DF8C8CB8-4AC0-4904-BDCD-8C2DF31D76F6@dcn.davis.ca.us>

Not that I am an expert, but you should probably be using the direct approach rather than pointing and clicking. 

?postscript
?cairo_ps
-- 
Sent from my phone. Please excuse my brevity.

On June 23, 2016 10:15:15 AM PDT, A A via R-help <r-help at r-project.org> wrote:
>In RGui, I'm running the following bit of code:
>windowsFonts(A=windowsFont("Times New Roman"))
>plot(0,0, ylab='y axis', xlab='x axis',main='title',family="A")
>The labels and title appear in Times New Roman font. So far, so good.
>However, when I right click the figure and select 'Save as
>postscript...', I get a .eps file of the plot, but without the font
>formatting that I applied. Is there any way to apply the formatting so
>that it gets saved?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From yixuan.qiu at cos.name  Thu Jun 23 19:45:40 2016
From: yixuan.qiu at cos.name (Yixuan Qiu)
Date: Thu, 23 Jun 2016 13:45:40 -0400
Subject: [R] Saving .eps files with Times New Roman font
In-Reply-To: <229458692.358983.1466702115543.JavaMail.yahoo@mail.yahoo.com>
References: <229458692.358983.1466702115543.JavaMail.yahoo.ref@mail.yahoo.com>
	<229458692.358983.1466702115543.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAFr_7yHGaLPOC0K6MSr05dYo+zNHXy8wPb8Vvaw41La-SdT6-w@mail.gmail.com>

You may want to use the showtext package that converts fonts into
curves in your graph. Below is the sample code:


library(showtext)
## Load Times New Roman fonts on Windows
font.add("times", regular = "times.ttf", bold = "timesbd.ttf")
showtext.auto()

setEPS()
postscript("test.eps")
par(family = "times")
plot(rnorm(100), main = "Test Font")
dev.off()


Best,
Yixuan

2016-06-23 13:15 GMT-04:00 A A via R-help <r-help at r-project.org>:
> In RGui, I'm running the following bit of code:
> windowsFonts(A=windowsFont("Times New Roman"))
> plot(0,0, ylab='y axis', xlab='x axis',main='title',family="A")
> The labels and title appear in Times New Roman font. So far, so good. However, when I right click the figure and select 'Save as postscript...', I get a .eps file of the plot, but without the font formatting that I applied. Is there any way to apply the formatting so that it gets saved?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Yixuan Qiu <yixuan.qiu at cos.name>
Department of Statistics,
Purdue University


From bgunter.4567 at gmail.com  Thu Jun 23 20:47:48 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 23 Jun 2016 11:47:48 -0700
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>

Not in general, David:

e.g.

> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))

> is.na(test)
         a     b    c
[1,] FALSE FALSE TRUE
[2,]  TRUE FALSE TRUE
[3,] FALSE  TRUE TRUE

> test[is.na(test)]
[1] NA NA NA NA NA

> test[is.na(test)] <- 0
Warning message:
In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
  invalid factor level, NA generated

> test
  a    b c
1 1    A 0
2 0    b 0
3 2 <NA> 0


The problem is the default conversion to factors and the replacement
operation for factors. So:

> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c= rep(NA,3))
> class(test$b)
[1] "AsIs"  ## so NOT a factor

> test[is.na(test)] <- 0 # now works as you describe
> test
  a b c
1 1 A 0
2 0 b 0
3 2 0 0

Of course the OP (and you) probably had a data frame of all numerics
in mind, so the problem doesn't arise. But I think one needs to make
the distinction and issue clear.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> The function is.na() returns a matrix when applied to a data.frame so you can easily convert all the NAs to 0's:
>
>> ds_test
>    var1 var2
> 1     1    1
> 2     2    2
> 3     3    3
> 4    NA   NA
> 5     5    5
> 6     6    6
> 7     7    7
> 8    NA   NA
> 9     9    9
> 10   10   10
>> is.na(ds_test)
>        var1  var2
>  [1,] FALSE FALSE
>  [2,] FALSE FALSE
>  [3,] FALSE FALSE
>  [4,]  TRUE  TRUE
>  [5,] FALSE FALSE
>  [6,] FALSE FALSE
>  [7,] FALSE FALSE
>  [8,]  TRUE  TRUE
>  [9,] FALSE FALSE
> [10,] FALSE FALSE
>> ds_test[is.na(ds_test)] <- 0
>> ds_test
>    var1 var2
> 1     1    1
> 2     2    2
> 3     3    3
> 4     0    0
> 5     5    5
> 6     6    6
> 7     7    7
> 8     0    0
> 9     9    9
> 10   10   10
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
> Sent: Thursday, June 23, 2016 10:14 AM
> To: R Help
> Subject: Re: [R] Subscripting problem with is.na()
>
> Thank you Bert for this clarification. It is indeed an important point.
>
> Ivan
>
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
>> Sorry, Ivan, your statement is incorrect:
>>
>> "When you use a single bracket on a list with only one argument in
>> between, then R extracts "elements", i.e. columns in the case of a
>> data.frame. This explains your errors. "
>>
>> e.g.
>>
>>> ex <- data.frame(a = 1:3, b = letters[1:3])
>>> a <- 1:3
>>> identical(ex[1], a)
>> [1] FALSE
>>
>>> class(ex[1])
>> [1] "data.frame"
>>> class(a)
>> [1] "integer"
>>
>> Compare:
>>
>>> identical(ex[[1]], a)
>> [1] TRUE
>>
>> Why? Single bracket extraction on a list results in a list; double
>> bracket extraction results in the element of the list ( a "column" in
>> the case of a data frame, which is a specific kind of list). The
>> relevant sections of ?Extract are:
>>
>> "Indexing by [ is similar to atomic vectors and selects a **list** of
>> the specified element(s).
>>
>> Both [[ and $ select a **single element of the list**. "
>>
>>
>> Hope this clarifies this often-confused issue.
>>
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
>> <ivan.calandra at univ-reims.fr> wrote:
>>> My statement "Using a single bracket '[' on a data.frame does the same as
>>> for matrices: you need to specify rows and columns" was not correct.
>>>
>>>
>>> When you use a single bracket on a list with only one argument in between,
>>> then R extracts "elements", i.e. columns in the case of a data.frame. This
>>> explains your errors.
>>>
>>> But it is possible to use a single bracket on a data.frame with 2 arguments
>>> (rows, columns) separated by a comma, as with matrices. This is the solution
>>> you received.
>>>
>>> Ivan
>>>
>>>
>>> --
>>> Ivan Calandra, PhD
>>> Scientific Mediator
>>> University of Reims Champagne-Ardenne
>>> GEGENAA - EA 3795
>>> CREA - 2 esplanade Roland Garros
>>> 51100 Reims, France
>>> +33(0)3 26 77 36 89
>>> ivan.calandra at univ-reims.fr
>>> --
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>> https://publons.com/author/705639/
>>>
>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>>>> Dear Georg,
>>>>
>>>> You need to learn a bit more about the subsetting methods, depending on
>>>> the object structure you're trying to subset.
>>>>
>>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>>>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
>>>> : undefined columns selected"
>>>>
>>>> This means that R does not understand which column you're trying to
>>>> select. But you're actually trying to select rows.
>>>>
>>>> Using a single bracket '[' on a data.frame does the same as for matrices:
>>>> you need to specify rows and columns, like this:
>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
>>>> didn't specify any after the comma
>>>>
>>>> If you want it only for "var1", then you need to specify the column:
>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>>>>
>>>> It's the same problem with your 2nd and 4th tries (4th one has other
>>>> problems). Your 3rd try does not change ds_test at all.
>>>>
>>>> HTH,
>>>> Ivan
>>>>
>>>> --
>>>> Ivan Calandra, PhD
>>>> Scientific Mediator
>>>> University of Reims Champagne-Ardenne
>>>> GEGENAA - EA 3795
>>>> CREA - 2 esplanade Roland Garros
>>>> 51100 Reims, France
>>>> +33(0)3 26 77 36 89
>>>> ivan.calandra at univ-reims.fr
>>>> --
>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>> https://publons.com/author/705639/
>>>>
>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>>>>> Hi All,
>>>>>
>>>>> I would like to recode my NAs to 0. Using a single vector everything is
>>>>> fine.
>>>>>
>>>>> But if I use a data.frame things go wrong:
>>>>>
>>>>> -- cut --
>>>>>
>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>>>>> ds_test <-
>>>>>     data.frame(var1, var2)
>>>>>
>>>>> test <- var1
>>>>> test[is.na(test)] <- 0
>>>>> test  # NA recoded OK
>>>>>
>>>>> # First try
>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>>>>>
>>>>> # Second try
>>>>> ds_test[is.na("var1")] <- 0
>>>>> ds_test$var1  # not recoded WRONG
>>>>>
>>>>> # Third try: to me the most intuitive approach
>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
>>>>> integerOneIndex WRONG
>>>>>
>>>>> # Fourth try
>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>>>>>
>>>>> -- cut --
>>>>>    How can I do it correctly?
>>>>>
>>>>> Where could I have found something about it?
>>>>>
>>>>> Kind regards
>>>>>
>>>>> Georg
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Jun 23 21:14:06 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 23 Jun 2016 19:14:06 +0000
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
Message-ID: <a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>

Good point. I did not think about factors. Also your example raises another issue since column c is logical, but gets silently converted to numeric. This would seem to get the job done assuming the conversion is intended for numeric columns only:

> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> sapply(test, class)
        a         b         c 
"numeric"  "factor" "logical" 
> num <- sapply(test, is.numeric)
> test[, num][is.na(test[, num])] <- 0
> test
  a    b  c
1 1    A NA
2 0    b NA
3 2 <NA> NA

David C

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Thursday, June 23, 2016 1:48 PM
To: David L Carlson
Cc: Ivan Calandra; R Help
Subject: Re: [R] Subscripting problem with is.na()

Not in general, David:

e.g.

> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))

> is.na(test)
         a     b    c
[1,] FALSE FALSE TRUE
[2,]  TRUE FALSE TRUE
[3,] FALSE  TRUE TRUE

> test[is.na(test)]
[1] NA NA NA NA NA

> test[is.na(test)] <- 0
Warning message:
In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
  invalid factor level, NA generated

> test
  a    b c
1 1    A 0
2 0    b 0
3 2 <NA> 0


The problem is the default conversion to factors and the replacement
operation for factors. So:

> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c= rep(NA,3))
> class(test$b)
[1] "AsIs"  ## so NOT a factor

> test[is.na(test)] <- 0 # now works as you describe
> test
  a b c
1 1 A 0
2 0 b 0
3 2 0 0

Of course the OP (and you) probably had a data frame of all numerics
in mind, so the problem doesn't arise. But I think one needs to make
the distinction and issue clear.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> The function is.na() returns a matrix when applied to a data.frame so you can easily convert all the NAs to 0's:
>
>> ds_test
>    var1 var2
> 1     1    1
> 2     2    2
> 3     3    3
> 4    NA   NA
> 5     5    5
> 6     6    6
> 7     7    7
> 8    NA   NA
> 9     9    9
> 10   10   10
>> is.na(ds_test)
>        var1  var2
>  [1,] FALSE FALSE
>  [2,] FALSE FALSE
>  [3,] FALSE FALSE
>  [4,]  TRUE  TRUE
>  [5,] FALSE FALSE
>  [6,] FALSE FALSE
>  [7,] FALSE FALSE
>  [8,]  TRUE  TRUE
>  [9,] FALSE FALSE
> [10,] FALSE FALSE
>> ds_test[is.na(ds_test)] <- 0
>> ds_test
>    var1 var2
> 1     1    1
> 2     2    2
> 3     3    3
> 4     0    0
> 5     5    5
> 6     6    6
> 7     7    7
> 8     0    0
> 9     9    9
> 10   10   10
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
> Sent: Thursday, June 23, 2016 10:14 AM
> To: R Help
> Subject: Re: [R] Subscripting problem with is.na()
>
> Thank you Bert for this clarification. It is indeed an important point.
>
> Ivan
>
> --
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> --
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
>> Sorry, Ivan, your statement is incorrect:
>>
>> "When you use a single bracket on a list with only one argument in
>> between, then R extracts "elements", i.e. columns in the case of a
>> data.frame. This explains your errors. "
>>
>> e.g.
>>
>>> ex <- data.frame(a = 1:3, b = letters[1:3])
>>> a <- 1:3
>>> identical(ex[1], a)
>> [1] FALSE
>>
>>> class(ex[1])
>> [1] "data.frame"
>>> class(a)
>> [1] "integer"
>>
>> Compare:
>>
>>> identical(ex[[1]], a)
>> [1] TRUE
>>
>> Why? Single bracket extraction on a list results in a list; double
>> bracket extraction results in the element of the list ( a "column" in
>> the case of a data frame, which is a specific kind of list). The
>> relevant sections of ?Extract are:
>>
>> "Indexing by [ is similar to atomic vectors and selects a **list** of
>> the specified element(s).
>>
>> Both [[ and $ select a **single element of the list**. "
>>
>>
>> Hope this clarifies this often-confused issue.
>>
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
>> <ivan.calandra at univ-reims.fr> wrote:
>>> My statement "Using a single bracket '[' on a data.frame does the same as
>>> for matrices: you need to specify rows and columns" was not correct.
>>>
>>>
>>> When you use a single bracket on a list with only one argument in between,
>>> then R extracts "elements", i.e. columns in the case of a data.frame. This
>>> explains your errors.
>>>
>>> But it is possible to use a single bracket on a data.frame with 2 arguments
>>> (rows, columns) separated by a comma, as with matrices. This is the solution
>>> you received.
>>>
>>> Ivan
>>>
>>>
>>> --
>>> Ivan Calandra, PhD
>>> Scientific Mediator
>>> University of Reims Champagne-Ardenne
>>> GEGENAA - EA 3795
>>> CREA - 2 esplanade Roland Garros
>>> 51100 Reims, France
>>> +33(0)3 26 77 36 89
>>> ivan.calandra at univ-reims.fr
>>> --
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>> https://publons.com/author/705639/
>>>
>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>>>> Dear Georg,
>>>>
>>>> You need to learn a bit more about the subsetting methods, depending on
>>>> the object structure you're trying to subset.
>>>>
>>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>>>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
>>>> : undefined columns selected"
>>>>
>>>> This means that R does not understand which column you're trying to
>>>> select. But you're actually trying to select rows.
>>>>
>>>> Using a single bracket '[' on a data.frame does the same as for matrices:
>>>> you need to specify rows and columns, like this:
>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
>>>> didn't specify any after the comma
>>>>
>>>> If you want it only for "var1", then you need to specify the column:
>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>>>>
>>>> It's the same problem with your 2nd and 4th tries (4th one has other
>>>> problems). Your 3rd try does not change ds_test at all.
>>>>
>>>> HTH,
>>>> Ivan
>>>>
>>>> --
>>>> Ivan Calandra, PhD
>>>> Scientific Mediator
>>>> University of Reims Champagne-Ardenne
>>>> GEGENAA - EA 3795
>>>> CREA - 2 esplanade Roland Garros
>>>> 51100 Reims, France
>>>> +33(0)3 26 77 36 89
>>>> ivan.calandra at univ-reims.fr
>>>> --
>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>> https://publons.com/author/705639/
>>>>
>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>>>>> Hi All,
>>>>>
>>>>> I would like to recode my NAs to 0. Using a single vector everything is
>>>>> fine.
>>>>>
>>>>> But if I use a data.frame things go wrong:
>>>>>
>>>>> -- cut --
>>>>>
>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>>>>> ds_test <-
>>>>>     data.frame(var1, var2)
>>>>>
>>>>> test <- var1
>>>>> test[is.na(test)] <- 0
>>>>> test  # NA recoded OK
>>>>>
>>>>> # First try
>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>>>>>
>>>>> # Second try
>>>>> ds_test[is.na("var1")] <- 0
>>>>> ds_test$var1  # not recoded WRONG
>>>>>
>>>>> # Third try: to me the most intuitive approach
>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
>>>>> integerOneIndex WRONG
>>>>>
>>>>> # Fourth try
>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>>>>>
>>>>> -- cut --
>>>>>    How can I do it correctly?
>>>>>
>>>>> Where could I have found something about it?
>>>>>
>>>>> Kind regards
>>>>>
>>>>> Georg
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From G.Maubach at weinwolf.de  Thu Jun 23 16:14:40 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 23 Jun 2016 16:14:40 +0200
Subject: [R] r_toolbox: Update
Message-ID: <OF41FDA36D.5B93BB0D-ONC1257FDB.004DBAF6-C1257FDB.004E4585@lotus.hawesko.de>

Hi folks,

I have updated the functions of the r_toolbox.R set of utilities:

https://sourceforge.net/projects/r-project-utilities/files/?source=navbar

Naming was changed with some functions to reflect similar functions in SAS 
or SPSS, e. g. t_n_miss, t_n_valid. In addition I added functions for 
reporting memory usage, selecting variables by type and getting an 
overview over the levels of factors.

I hope you find these functions useful.

Please get back to me if you have suggestions or encounter any 
difficulties.

Kind regards

Georg


From s.sana.f at gmail.com  Thu Jun 23 16:50:26 2016
From: s.sana.f at gmail.com (Sana Fatima)
Date: Thu, 23 Jun 2016 10:50:26 -0400
Subject: [R] R help needed
Message-ID: <CAH5Cth-sVdeFWT7aapbXEZBKPnA9=NM8o2nPjs3qr7w3f=cv+g@mail.gmail.com>

 Hello everyone,
I am trying to create an shiny app that could be used for ~ 700 different
user names and passwords. Each username and password would lead to a
different set of data being pulled in, however the tabs and fields with in
the app will be the same. Just that different username would display
different data.I have the basic app running but would appreciate help with
the program for the login/password part.

I have tried incorporating the example code(
http://shiny.rstudio.com/articles/permissions.html) to my program ( see
portion of my code below). However, when I ran the app, it gives me a blank
screen for this tab. This is because the user = NULL but i don't get an
option to enter the username and password information. Where and how do we
get the login form at the beginning of the application? Is there a way to
have the login in form and the application linked together so that when the
application is run it automatically takes u to the login page where user
can enter their info and see the info accordingly. Would really appreciate
your help on this. Thanks in advance

server <- function(input, output, session) {

user <- reactive({
session$user
})


table <- formattable(tab1, list(
"NumberServed" = formatter(
"span",
style = x ~ style(color = ifelse(x<tab1$NumberServed_prev,'red',
ifelse(x>tab1$NumberServed_prev,'green','orange')), font.weight = "bold"),
x ~ icontext(ifelse(x < tab1$NumberServed_pr_goal,
"arrow-down",ifelse(x>tab1$NumberServed_pr_goal,'arrow-up','')),x)),
"NumberExited" = formatter(
"span",
style = x ~ style(color = ifelse(x<tab1$NumberExited_prev,'red',
ifelse(x>tab1$NumberExited_prev,'green','orange')), font.weight = "bold"),
x ~ icontext(ifelse(x < tab1$NumberExited_pr_goal,
"arrow-down",ifelse(x>tab1$NumberExited_pr_goal,'arrow-up','')),x)),

"PercentWithBarriers" = formatter(
"span",
style = x ~ style(color = ifelse(x<tab1$PercentWithBarriers_prev,'red',
ifelse(x>tab1$PercentWithBarriers_prev,'green','orange')), font.weight =
"bold"),
x ~ icontext(ifelse(x < tab1$PercentWithBarriers_pr_goal,
"arrow-down",ifelse(x>tab1$PercentWithBarriers_pr_goal,'arrow-up','')),x)),

"EmploymentQ2" = formatter(
"span",
style = x ~ style(color = ifelse(x<tab1$EmploymentQ2_prev,'red',
ifelse(x>tab1$EmploymentQ2_prev,'green','orange')), font.weight = "bold"),
x ~ icontext(ifelse(x < tab1$EmploymentQ2_pr_goal,
"arrow-down",ifelse(x>tab1$EmploymentQ2_pr_goal,'arrow-up','')),x)),

"EmploymentQ4" = formatter(
"span",
style = x ~ style(color = ifelse(x<tab1$EmploymentQ4_prev,'red',
ifelse(x>tab1$EmploymentQ4_prev,'green','orange')), font.weight = "bold"),
x ~ icontext(ifelse(x < tab1$EmploymentQ4_pr_goal,
"arrow-down",ifelse(x>tab1$EmploymentQ4_pr_goal,'arrow-up','')),x)),
"WagesQ2" = formatter(
"span",
style = x ~ style(color = ifelse(x<tab1$WagesQ2_prev,'red',
ifelse(x>tab1$WagesQ2_prev,'green','orange')), font.weight = "bold"),
x ~ icontext(ifelse(x < tab1$WagesQ2_pr_goal,
"arrow-down",ifelse(x>tab1$WagesQ2_pr_goal,'arrow-up','')),x)),
"CredentialRate" = formatter(
"span",
style = x ~ style(color = ifelse(x<tab1$CredentialRate_prev,'red',
ifelse(x>tab1$CredentialRate_prev,'green','orange')), font.weight = "bold"),
x ~ icontext(ifelse(x < tab1$CredentialRate_pr_goal,
"arrow-down",ifelse(x>tab1$CredentialRate_pr_goal,'arrow-up','')),x))

))

table$WagesQ2<-currency(table$WagesQ2,symbol = "$", digits = 0)
table$NumberServed<-accounting(table$NumberServed,digits=0)
table$NumberExited<-accounting(table$NumberExited,digits=0)
table$PercentWithBarriers<-percent(table$PercentWithBarriers,digits=2)
table$EmploymentQ2<-percent(table$EmploymentQ2,digits=2)
table$EmploymentQ4<-percent(table$EmploymentQ4,digits=2)
table$CredentialRate<-percent(table$CredentialRate,digits=2)
table$NumberServed_prev=NULL
table$NumberExited_prev=NULL
table$PercentWithBarriers_prev=NULL
table$EmploymentQ2_prev=NULL
table$EmploymentQ4_prev=NULL
table$WagesQ2_prev=NULL
table$CredentialRate_prev=NULL
table$NumberServed_pr_goal=NULL
table$NumberExited_pr_goal=NULL
table$PercentWithBarriers_pr_goal=NULL
table$EmploymentQ2_pr_goal=NULL
table$EmploymentQ4_pr_goal=NULL
table$WagesQ2_pr_goal=NULL
table$CredentialRate_pr_goal=NULL

myData <- reactive({
if (isManager()){
# If a manager, show everything.
return(table)
} else{
# If a regular salesperson, only show their own sales.
return(table[table$dist == user(),])
}
})


isManager <- reactive({
if (user() == "manager"){
return(TRUE)
} else{
return(FALSE)
}
})

output$results1 <- renderFormattable({
if(is.null(user())){return()}
myData()
})
)

}

-- 
Syeda Sana Fatima

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Jun 23 22:45:06 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 23 Jun 2016 15:45:06 -0500
Subject: [R] R help needed
In-Reply-To: <CAH5Cth-sVdeFWT7aapbXEZBKPnA9=NM8o2nPjs3qr7w3f=cv+g@mail.gmail.com>
References: <CAH5Cth-sVdeFWT7aapbXEZBKPnA9=NM8o2nPjs3qr7w3f=cv+g@mail.gmail.com>
Message-ID: <5663A8E0-4376-471F-B342-4F0D833B3B0C@me.com>


> On Jun 23, 2016, at 9:50 AM, Sana Fatima <s.sana.f at gmail.com> wrote:
> 
> Hello everyone,
> I am trying to create an shiny app that could be used for ~ 700 different
> user names and passwords. Each username and password would lead to a
> different set of data being pulled in, however the tabs and fields with in
> the app will be the same. Just that different username would display
> different data.I have the basic app running but would appreciate help with
> the program for the login/password part.
> 
> I have tried incorporating the example code(
> http://shiny.rstudio.com/articles/permissions.html) to my program ( see
> portion of my code below). However, when I ran the app, it gives me a blank
> screen for this tab. This is because the user = NULL but i don't get an
> option to enter the username and password information. Where and how do we
> get the login form at the beginning of the application? Is there a way to
> have the login in form and the application linked together so that when the
> application is run it automatically takes u to the login page where user
> can enter their info and see the info accordingly. Would really appreciate
> your help on this. Thanks in advance

<code snipped>

> -- 
> Syeda Sana Fatima


Hi,

Shiny is a third party application that has its own dedicated support vehicles at:

  http://shiny.rstudio.com/help/

You should leverage those resources, as it is off-topic for R-Help.

Regards,

Marc Schwartz


From bgunter.4567 at gmail.com  Thu Jun 23 23:55:51 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 23 Jun 2016 14:55:51 -0700
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>

... actually, FWIW, I would say that this little discussion mostly
demonstrates why the OP's request is probably not a good idea in the
first place. Usually, NA's should be left as NA's to be dealt with
properly by R and packages. In biological measurements, for example,
NA's often mean "below the ability to reliably measure." Biologists
with whom I've worked over many years often want to convert these to 0
or omit the cases, both of which lead to biased estimates and/or
underestimates of variability and excess claims of "statistical
significance" (for those who belong to this religious persuasion). One
should never say never, but I suspect that there are relatively few
circumstances where the conversion the OP requested is actually wise.

Feel free to ignore/reject such extraneous comments of course.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 23, 2016 at 12:14 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> Good point. I did not think about factors. Also your example raises another issue since column c is logical, but gets silently converted to numeric. This would seem to get the job done assuming the conversion is intended for numeric columns only:
>
>> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>> sapply(test, class)
>         a         b         c
> "numeric"  "factor" "logical"
>> num <- sapply(test, is.numeric)
>> test[, num][is.na(test[, num])] <- 0
>> test
>   a    b  c
> 1 1    A NA
> 2 0    b NA
> 3 2 <NA> NA
>
> David C
>
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Thursday, June 23, 2016 1:48 PM
> To: David L Carlson
> Cc: Ivan Calandra; R Help
> Subject: Re: [R] Subscripting problem with is.na()
>
> Not in general, David:
>
> e.g.
>
>> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>
>> is.na(test)
>          a     b    c
> [1,] FALSE FALSE TRUE
> [2,]  TRUE FALSE TRUE
> [3,] FALSE  TRUE TRUE
>
>> test[is.na(test)]
> [1] NA NA NA NA NA
>
>> test[is.na(test)] <- 0
> Warning message:
> In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
>   invalid factor level, NA generated
>
>> test
>   a    b c
> 1 1    A 0
> 2 0    b 0
> 3 2 <NA> 0
>
>
> The problem is the default conversion to factors and the replacement
> operation for factors. So:
>
>> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c= rep(NA,3))
>> class(test$b)
> [1] "AsIs"  ## so NOT a factor
>
>> test[is.na(test)] <- 0 # now works as you describe
>> test
>   a b c
> 1 1 A 0
> 2 0 b 0
> 3 2 0 0
>
> Of course the OP (and you) probably had a data frame of all numerics
> in mind, so the problem doesn't arise. But I think one needs to make
> the distinction and issue clear.
>
> Cheers,
> Bert
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> The function is.na() returns a matrix when applied to a data.frame so you can easily convert all the NAs to 0's:
>>
>>> ds_test
>>    var1 var2
>> 1     1    1
>> 2     2    2
>> 3     3    3
>> 4    NA   NA
>> 5     5    5
>> 6     6    6
>> 7     7    7
>> 8    NA   NA
>> 9     9    9
>> 10   10   10
>>> is.na(ds_test)
>>        var1  var2
>>  [1,] FALSE FALSE
>>  [2,] FALSE FALSE
>>  [3,] FALSE FALSE
>>  [4,]  TRUE  TRUE
>>  [5,] FALSE FALSE
>>  [6,] FALSE FALSE
>>  [7,] FALSE FALSE
>>  [8,]  TRUE  TRUE
>>  [9,] FALSE FALSE
>> [10,] FALSE FALSE
>>> ds_test[is.na(ds_test)] <- 0
>>> ds_test
>>    var1 var2
>> 1     1    1
>> 2     2    2
>> 3     3    3
>> 4     0    0
>> 5     5    5
>> 6     6    6
>> 7     7    7
>> 8     0    0
>> 9     9    9
>> 10   10   10
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
>> Sent: Thursday, June 23, 2016 10:14 AM
>> To: R Help
>> Subject: Re: [R] Subscripting problem with is.na()
>>
>> Thank you Bert for this clarification. It is indeed an important point.
>>
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> Scientific Mediator
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
>>> Sorry, Ivan, your statement is incorrect:
>>>
>>> "When you use a single bracket on a list with only one argument in
>>> between, then R extracts "elements", i.e. columns in the case of a
>>> data.frame. This explains your errors. "
>>>
>>> e.g.
>>>
>>>> ex <- data.frame(a = 1:3, b = letters[1:3])
>>>> a <- 1:3
>>>> identical(ex[1], a)
>>> [1] FALSE
>>>
>>>> class(ex[1])
>>> [1] "data.frame"
>>>> class(a)
>>> [1] "integer"
>>>
>>> Compare:
>>>
>>>> identical(ex[[1]], a)
>>> [1] TRUE
>>>
>>> Why? Single bracket extraction on a list results in a list; double
>>> bracket extraction results in the element of the list ( a "column" in
>>> the case of a data frame, which is a specific kind of list). The
>>> relevant sections of ?Extract are:
>>>
>>> "Indexing by [ is similar to atomic vectors and selects a **list** of
>>> the specified element(s).
>>>
>>> Both [[ and $ select a **single element of the list**. "
>>>
>>>
>>> Hope this clarifies this often-confused issue.
>>>
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
>>> <ivan.calandra at univ-reims.fr> wrote:
>>>> My statement "Using a single bracket '[' on a data.frame does the same as
>>>> for matrices: you need to specify rows and columns" was not correct.
>>>>
>>>>
>>>> When you use a single bracket on a list with only one argument in between,
>>>> then R extracts "elements", i.e. columns in the case of a data.frame. This
>>>> explains your errors.
>>>>
>>>> But it is possible to use a single bracket on a data.frame with 2 arguments
>>>> (rows, columns) separated by a comma, as with matrices. This is the solution
>>>> you received.
>>>>
>>>> Ivan
>>>>
>>>>
>>>> --
>>>> Ivan Calandra, PhD
>>>> Scientific Mediator
>>>> University of Reims Champagne-Ardenne
>>>> GEGENAA - EA 3795
>>>> CREA - 2 esplanade Roland Garros
>>>> 51100 Reims, France
>>>> +33(0)3 26 77 36 89
>>>> ivan.calandra at univ-reims.fr
>>>> --
>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>> https://publons.com/author/705639/
>>>>
>>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>>>>> Dear Georg,
>>>>>
>>>>> You need to learn a bit more about the subsetting methods, depending on
>>>>> the object structure you're trying to subset.
>>>>>
>>>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>>>>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
>>>>> : undefined columns selected"
>>>>>
>>>>> This means that R does not understand which column you're trying to
>>>>> select. But you're actually trying to select rows.
>>>>>
>>>>> Using a single bracket '[' on a data.frame does the same as for matrices:
>>>>> you need to specify rows and columns, like this:
>>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
>>>>> didn't specify any after the comma
>>>>>
>>>>> If you want it only for "var1", then you need to specify the column:
>>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>>>>>
>>>>> It's the same problem with your 2nd and 4th tries (4th one has other
>>>>> problems). Your 3rd try does not change ds_test at all.
>>>>>
>>>>> HTH,
>>>>> Ivan
>>>>>
>>>>> --
>>>>> Ivan Calandra, PhD
>>>>> Scientific Mediator
>>>>> University of Reims Champagne-Ardenne
>>>>> GEGENAA - EA 3795
>>>>> CREA - 2 esplanade Roland Garros
>>>>> 51100 Reims, France
>>>>> +33(0)3 26 77 36 89
>>>>> ivan.calandra at univ-reims.fr
>>>>> --
>>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>>> https://publons.com/author/705639/
>>>>>
>>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>>>>>> Hi All,
>>>>>>
>>>>>> I would like to recode my NAs to 0. Using a single vector everything is
>>>>>> fine.
>>>>>>
>>>>>> But if I use a data.frame things go wrong:
>>>>>>
>>>>>> -- cut --
>>>>>>
>>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>>>>>> ds_test <-
>>>>>>     data.frame(var1, var2)
>>>>>>
>>>>>> test <- var1
>>>>>> test[is.na(test)] <- 0
>>>>>> test  # NA recoded OK
>>>>>>
>>>>>> # First try
>>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>>>>>>
>>>>>> # Second try
>>>>>> ds_test[is.na("var1")] <- 0
>>>>>> ds_test$var1  # not recoded WRONG
>>>>>>
>>>>>> # Third try: to me the most intuitive approach
>>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
>>>>>> integerOneIndex WRONG
>>>>>>
>>>>>> # Fourth try
>>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>>>>>>
>>>>>> -- cut --
>>>>>>    How can I do it correctly?
>>>>>>
>>>>>> Where could I have found something about it?
>>>>>>
>>>>>> Kind regards
>>>>>>
>>>>>> Georg
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From marius.hofert at uwaterloo.ca  Fri Jun 24 04:29:45 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Thu, 23 Jun 2016 22:29:45 -0400
Subject: [R] What's box() (exactly) doing?
Message-ID: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>

Hi,

I would like to replicate the behavior of box() with rect() (don't ask why).
However, my rect()angles are always too small. I looked a bit into the
internal C_box but
couldn't figure out how to solve the problem. Below is a minimal
working (and a slightly bigger) example.

Cheers,
Marius

## MWE
plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80") #
should match box()
box()

## Extended example

## Basic plot
my_rect <- function()
{
    plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
    rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
# should match box()
    box()
}

## Layout
lay <- matrix(0, nrow = 3, ncol = 3, byrow = TRUE)
lay[1,1] <- 1
lay[2,1] <- 2
lay[2,2] <- 3
lay[2,3] <- 4
lay[3,3] <- 5
layout(lay, heights = c(1, 10, 1), widths = c(10, 1, 10))
layout.show(5) # => no space between rectangles; calls box() to draw the boxes

## Fill layout
par(oma = rep(0, 4), mar = rep(0, 4))
my_rect()
my_rect()
my_rect()
my_rect()
my_rect()
## => spaces between rectangles => why?/how to avoid?


From dwinsemius at comcast.net  Fri Jun 24 04:53:34 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 23 Jun 2016 19:53:34 -0700
Subject: [R] What's box() (exactly) doing?
In-Reply-To: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
References: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
Message-ID: <C3ECEB90-DFB4-4F1C-A4AB-609FFE14A4E6@comcast.net>


> On Jun 23, 2016, at 7:29 PM, Marius Hofert <marius.hofert at uwaterloo.ca> wrote:
> 
> Hi,
> 
> I would like to replicate the behavior of box() with rect() (don't ask why).
> However, my rect()angles are always too small. I looked a bit into the
> internal C_box but
> couldn't figure out how to solve the problem. Below is a minimal
> working (and a slightly bigger) example.

Are you aware that the range of the plot area is expanded by a factor of something on the order of 1.04 so that data "points" will appear whole? If my memory serves you can call plot with the parameter plot=FALSE and then recover the par(usr) values for the plot area.

-- 
David.
> 
> Cheers,
> Marius
> 
> ## MWE
> plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80") #
> should match box()
> box()
> 
> ## Extended example
> 
> ## Basic plot
> my_rect <- function()
> {
>    plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
>    rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
> # should match box()
>    box()
> }
> 
> ## Layout
> lay <- matrix(0, nrow = 3, ncol = 3, byrow = TRUE)
> lay[1,1] <- 1
> lay[2,1] <- 2
> lay[2,2] <- 3
> lay[2,3] <- 4
> lay[3,3] <- 5
> layout(lay, heights = c(1, 10, 1), widths = c(10, 1, 10))
> layout.show(5) # => no space between rectangles; calls box() to draw the boxes
> 
> ## Fill layout
> par(oma = rep(0, 4), mar = rep(0, 4))
> my_rect()
> my_rect()
> my_rect()
> my_rect()
> my_rect()
> ## => spaces between rectangles => why?/how to avoid?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Fri Jun 24 05:06:39 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 24 Jun 2016 13:06:39 +1000
Subject: [R] What's box() (exactly) doing?
In-Reply-To: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
References: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
Message-ID: <CA+8X3fW+4J8Cqaq1xU1hNoKY4QLshFdfMS15WvWuSS+=VP6jcw@mail.gmail.com>

Hi Marius,
There are a few things that are happening here. First, the plot area
is not going to be the same as your x and y limits unless you say so:

# run your first example
par("usr")
[1] -0.04  1.04 -0.04  1.04

# but
plot(NA, type = "n", ann = FALSE, axes = FALSE,
 xlim = 0:1, ylim = 0:1,xaxs="i",yaxs="i")
box()
rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
par("usr")
[1] 0 1 0 1

Second, the "rect" function is automatically clipped to the plot area,
so you may lose a bit at the edges if you don't override this:

par(xpd=TRUE)
rect(...)
par(xpd=FALSE)

Finally your second example simply multiplies the first problem by
specifying a layout of more than one plot. Applying the "xaxs" and
"yaxs" parameters before you start plotting will fix this:

par(xaxs="i",yaxs="i")

Jim

On Fri, Jun 24, 2016 at 12:29 PM, Marius Hofert
<marius.hofert at uwaterloo.ca> wrote:
> Hi,
>
> I would like to replicate the behavior of box() with rect() (don't ask why).
> However, my rect()angles are always too small. I looked a bit into the
> internal C_box but
> couldn't figure out how to solve the problem. Below is a minimal
> working (and a slightly bigger) example.
>
> Cheers,
> Marius
>
> ## MWE
> plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80") #
> should match box()
> box()
>
> ## Extended example
>
> ## Basic plot
> my_rect <- function()
> {
>     plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
>     rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
> # should match box()
>     box()
> }
>
> ## Layout
> lay <- matrix(0, nrow = 3, ncol = 3, byrow = TRUE)
> lay[1,1] <- 1
> lay[2,1] <- 2
> lay[2,2] <- 3
> lay[2,3] <- 4
> lay[3,3] <- 5
> layout(lay, heights = c(1, 10, 1), widths = c(10, 1, 10))
> layout.show(5) # => no space between rectangles; calls box() to draw the boxes
>
> ## Fill layout
> par(oma = rep(0, 4), mar = rep(0, 4))
> my_rect()
> my_rect()
> my_rect()
> my_rect()
> my_rect()
> ## => spaces between rectangles => why?/how to avoid?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at gmx.de  Fri Jun 24 09:14:35 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Fri, 24 Jun 2016 09:14:35 +0200
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>,
	<CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
Message-ID: <trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>

Hi Bert,

many thanks for all your help and your comments. I learn at lot this way.

My question was about is.na() at the first sight but the actual task looks like this:

I have two variables in my customer data that signal if the customer accout was closed by master data management or by sales. Say these variables are closed_mdm and closed_sls. They contain NA if the customer account is still open or a closing code from "01" to "08" if the customer account was closed and why.

For my analysis I need a variable that combines the two variables closed_mdm and closed_sls to set a filter easily on those who are closed not matter what the reason was nor who closed the account.

As I always encounter problems when dealing with ifelse statements and NA I decided to merge these two variables to one variable containing 0 = not closed and 1 = closed. In my context this seems to be - at least to me - a reasonable approach.

Replacement of missing values and merging the variables is the easiest way for me.

-- cut --

cust_id <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)
closed_mdm <- c("01", NA, NA, NA, "08", "07", NA, NA, "05", NA, NA, NA, "04", NA, NA, NA, NA, NA, NA, NA)
closed_sls <- c(NA, "08", NA, NA, "08", "07", NA, NA, NA, NA, "03", NA, NA, NA, "05", NA, NA, NA, NA, NA)

# 1st try
ds_temp1 <- data.frame(cust_id, closed_mdm, closed_sls)
ds_temp1

ds_temp1$closed <- closed_mdm | closed_sls  # WRONG

# 2nd try
closed_mdm_fac1 <- as.factor(closed_mdm)
closed_sls_fac1 <- as.factor(closed_sls)

ds_temp2 <- data.frame(cust_id, closed_mdm_fac1, closed_sls_fac1)
ds_temp2

ds_temp2$closed <- ds_temp$closed_mdm_fac1 | ds_temp$closed_sls_fac1  # WRONG

# 3rd try
closed_mdm_num1 <- as.numeric(closed_mdm)  # OK
closed_sls_num1 <- as.numeric(closed_sls)  # OK

ds_temp3 <- data.frame(cust_id, closed_mdm_num1, closed_sls_num1)
ds_temp3

ds_temp3$closed <- ds_temp$closed_mdm_num1 | ds_temp$closed_sls_num1  # WRONG

# 4th try
ds_temp4 <- ds_temp3
ds_temp4

# Does not run due to not allowed NA in subscripts
ds_temp4[is.na(ds_temp4$closed_mdm_num1), ds_temp4$closed_mdm_num1] <- 0
ds_temp4[is.na(ds_temp4$closed_sls_num1), ds_temp4$closed_sls_num1] <- 0

# 5th try
ds_temp4$closed_mdm_num1 <- ifelse(is.na(ds_temp4$closed_mdm_num1), 1, 0)
ds_temp4$closed_sls_num1 <- ifelse(is.na(ds_temp4$closed_sls_num1), 1, 0)
ds_temp4

ds_temp4$closed <- ifelse(ds_temp4$closed_mdm_num1 == 1 | ds_temp4$closed_sls_num1 == 1, 1, 0)
ds_temp4

-- cut --

Is there a better way to do it?

Kind regards

Georg


> Gesendet: Donnerstag, 23. Juni 2016 um 23:55 Uhr
> Von: "Bert Gunter" <bgunter.4567 at gmail.com>
> An: "David L Carlson" <dcarlson at tamu.edu>
> Cc: "R Help" <r-help at r-project.org>
> Betreff: Re: [R] Subscripting problem with is.na()
>
> ... actually, FWIW, I would say that this little discussion mostly
> demonstrates why the OP's request is probably not a good idea in the
> first place. Usually, NA's should be left as NA's to be dealt with
> properly by R and packages. In biological measurements, for example,
> NA's often mean "below the ability to reliably measure." Biologists
> with whom I've worked over many years often want to convert these to 0
> or omit the cases, both of which lead to biased estimates and/or
> underestimates of variability and excess claims of "statistical
> significance" (for those who belong to this religious persuasion). One
> should never say never, but I suspect that there are relatively few
> circumstances where the conversion the OP requested is actually wise.
> 
> Feel free to ignore/reject such extraneous comments of course.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Jun 23, 2016 at 12:14 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> > Good point. I did not think about factors. Also your example raises another issue since column c is logical, but gets silently converted to numeric. This would seem to get the job done assuming the conversion is intended for numeric columns only:
> >
> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> >> sapply(test, class)
> >         a         b         c
> > "numeric"  "factor" "logical"
> >> num <- sapply(test, is.numeric)
> >> test[, num][is.na(test[, num])] <- 0
> >> test
> >   a    b  c
> > 1 1    A NA
> > 2 0    b NA
> > 3 2 <NA> NA
> >
> > David C
> >
> > -----Original Message-----
> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > Sent: Thursday, June 23, 2016 1:48 PM
> > To: David L Carlson
> > Cc: Ivan Calandra; R Help
> > Subject: Re: [R] Subscripting problem with is.na()
> >
> > Not in general, David:
> >
> > e.g.
> >
> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> >
> >> is.na(test)
> >          a     b    c
> > [1,] FALSE FALSE TRUE
> > [2,]  TRUE FALSE TRUE
> > [3,] FALSE  TRUE TRUE
> >
> >> test[is.na(test)]
> > [1] NA NA NA NA NA
> >
> >> test[is.na(test)] <- 0
> > Warning message:
> > In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
> >   invalid factor level, NA generated
> >
> >> test
> >   a    b c
> > 1 1    A 0
> > 2 0    b 0
> > 3 2 <NA> 0
> >
> >
> > The problem is the default conversion to factors and the replacement
> > operation for factors. So:
> >
> >> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c= rep(NA,3))
> >> class(test$b)
> > [1] "AsIs"  ## so NOT a factor
> >
> >> test[is.na(test)] <- 0 # now works as you describe
> >> test
> >   a b c
> > 1 1 A 0
> > 2 0 b 0
> > 3 2 0 0
> >
> > Of course the OP (and you) probably had a data frame of all numerics
> > in mind, so the problem doesn't arise. But I think one needs to make
> > the distinction and issue clear.
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> >> The function is.na() returns a matrix when applied to a data.frame so you can easily convert all the NAs to 0's:
> >>
> >>> ds_test
> >>    var1 var2
> >> 1     1    1
> >> 2     2    2
> >> 3     3    3
> >> 4    NA   NA
> >> 5     5    5
> >> 6     6    6
> >> 7     7    7
> >> 8    NA   NA
> >> 9     9    9
> >> 10   10   10
> >>> is.na(ds_test)
> >>        var1  var2
> >>  [1,] FALSE FALSE
> >>  [2,] FALSE FALSE
> >>  [3,] FALSE FALSE
> >>  [4,]  TRUE  TRUE
> >>  [5,] FALSE FALSE
> >>  [6,] FALSE FALSE
> >>  [7,] FALSE FALSE
> >>  [8,]  TRUE  TRUE
> >>  [9,] FALSE FALSE
> >> [10,] FALSE FALSE
> >>> ds_test[is.na(ds_test)] <- 0
> >>> ds_test
> >>    var1 var2
> >> 1     1    1
> >> 2     2    2
> >> 3     3    3
> >> 4     0    0
> >> 5     5    5
> >> 6     6    6
> >> 7     7    7
> >> 8     0    0
> >> 9     9    9
> >> 10   10   10
> >>
> >> -------------------------------------
> >> David L Carlson
> >> Department of Anthropology
> >> Texas A&M University
> >> College Station, TX 77840-4352
> >>
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
> >> Sent: Thursday, June 23, 2016 10:14 AM
> >> To: R Help
> >> Subject: Re: [R] Subscripting problem with is.na()
> >>
> >> Thank you Bert for this clarification. It is indeed an important point.
> >>
> >> Ivan
> >>
> >> --
> >> Ivan Calandra, PhD
> >> Scientific Mediator
> >> University of Reims Champagne-Ardenne
> >> GEGENAA - EA 3795
> >> CREA - 2 esplanade Roland Garros
> >> 51100 Reims, France
> >> +33(0)3 26 77 36 89
> >> ivan.calandra at univ-reims.fr
> >> --
> >> https://www.researchgate.net/profile/Ivan_Calandra
> >> https://publons.com/author/705639/
> >>
> >> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
> >>> Sorry, Ivan, your statement is incorrect:
> >>>
> >>> "When you use a single bracket on a list with only one argument in
> >>> between, then R extracts "elements", i.e. columns in the case of a
> >>> data.frame. This explains your errors. "
> >>>
> >>> e.g.
> >>>
> >>>> ex <- data.frame(a = 1:3, b = letters[1:3])
> >>>> a <- 1:3
> >>>> identical(ex[1], a)
> >>> [1] FALSE
> >>>
> >>>> class(ex[1])
> >>> [1] "data.frame"
> >>>> class(a)
> >>> [1] "integer"
> >>>
> >>> Compare:
> >>>
> >>>> identical(ex[[1]], a)
> >>> [1] TRUE
> >>>
> >>> Why? Single bracket extraction on a list results in a list; double
> >>> bracket extraction results in the element of the list ( a "column" in
> >>> the case of a data frame, which is a specific kind of list). The
> >>> relevant sections of ?Extract are:
> >>>
> >>> "Indexing by [ is similar to atomic vectors and selects a **list** of
> >>> the specified element(s).
> >>>
> >>> Both [[ and $ select a **single element of the list**. "
> >>>
> >>>
> >>> Hope this clarifies this often-confused issue.
> >>>
> >>>
> >>> Cheers,
> >>> Bert
> >>> Bert Gunter
> >>>
> >>> "The trouble with having an open mind is that people keep coming along
> >>> and sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>>
> >>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
> >>> <ivan.calandra at univ-reims.fr> wrote:
> >>>> My statement "Using a single bracket '[' on a data.frame does the same as
> >>>> for matrices: you need to specify rows and columns" was not correct.
> >>>>
> >>>>
> >>>> When you use a single bracket on a list with only one argument in between,
> >>>> then R extracts "elements", i.e. columns in the case of a data.frame. This
> >>>> explains your errors.
> >>>>
> >>>> But it is possible to use a single bracket on a data.frame with 2 arguments
> >>>> (rows, columns) separated by a comma, as with matrices. This is the solution
> >>>> you received.
> >>>>
> >>>> Ivan
> >>>>
> >>>>
> >>>> --
> >>>> Ivan Calandra, PhD
> >>>> Scientific Mediator
> >>>> University of Reims Champagne-Ardenne
> >>>> GEGENAA - EA 3795
> >>>> CREA - 2 esplanade Roland Garros
> >>>> 51100 Reims, France
> >>>> +33(0)3 26 77 36 89
> >>>> ivan.calandra at univ-reims.fr
> >>>> --
> >>>> https://www.researchgate.net/profile/Ivan_Calandra
> >>>> https://publons.com/author/705639/
> >>>>
> >>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
> >>>>> Dear Georg,
> >>>>>
> >>>>> You need to learn a bit more about the subsetting methods, depending on
> >>>>> the object structure you're trying to subset.
> >>>>>
> >>>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
> >>>>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
> >>>>> : undefined columns selected"
> >>>>>
> >>>>> This means that R does not understand which column you're trying to
> >>>>> select. But you're actually trying to select rows.
> >>>>>
> >>>>> Using a single bracket '[' on a data.frame does the same as for matrices:
> >>>>> you need to specify rows and columns, like this:
> >>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
> >>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
> >>>>> didn't specify any after the comma
> >>>>>
> >>>>> If you want it only for "var1", then you need to specify the column:
> >>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
> >>>>>
> >>>>> It's the same problem with your 2nd and 4th tries (4th one has other
> >>>>> problems). Your 3rd try does not change ds_test at all.
> >>>>>
> >>>>> HTH,
> >>>>> Ivan
> >>>>>
> >>>>> --
> >>>>> Ivan Calandra, PhD
> >>>>> Scientific Mediator
> >>>>> University of Reims Champagne-Ardenne
> >>>>> GEGENAA - EA 3795
> >>>>> CREA - 2 esplanade Roland Garros
> >>>>> 51100 Reims, France
> >>>>> +33(0)3 26 77 36 89
> >>>>> ivan.calandra at univ-reims.fr
> >>>>> --
> >>>>> https://www.researchgate.net/profile/Ivan_Calandra
> >>>>> https://publons.com/author/705639/
> >>>>>
> >>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
> >>>>>> Hi All,
> >>>>>>
> >>>>>> I would like to recode my NAs to 0. Using a single vector everything is
> >>>>>> fine.
> >>>>>>
> >>>>>> But if I use a data.frame things go wrong:
> >>>>>>
> >>>>>> -- cut --
> >>>>>>
> >>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
> >>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
> >>>>>> ds_test <-
> >>>>>>     data.frame(var1, var2)
> >>>>>>
> >>>>>> test <- var1
> >>>>>> test[is.na(test)] <- 0
> >>>>>> test  # NA recoded OK
> >>>>>>
> >>>>>> # First try
> >>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
> >>>>>>
> >>>>>> # Second try
> >>>>>> ds_test[is.na("var1")] <- 0
> >>>>>> ds_test$var1  # not recoded WRONG
> >>>>>>
> >>>>>> # Third try: to me the most intuitive approach
> >>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
> >>>>>> integerOneIndex WRONG
> >>>>>>
> >>>>>> # Fourth try
> >>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
> >>>>>>
> >>>>>> -- cut --
> >>>>>>    How can I do it correctly?
> >>>>>>
> >>>>>> Where could I have found something about it?
> >>>>>>
> >>>>>> Kind regards
> >>>>>>
> >>>>>> Georg
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Jun 24 11:19:38 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 24 Jun 2016 09:19:38 +0000
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>,
	<CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
	<trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032336@SRVEXCHMBX.precheza.cz>

Hi

I do not consider changing NA to 0 as a reasonable approach ( maybe only in some special case, which is not yours).

rowSums(is.na(ds_temp1[,2:3]))
 [1] 1 1 2 2 0 0 2 2 1 2 1 2 1 2 1 2 2 2 2 2

gives you vector of numbers which is equal 2 only if they are both NA. So

ds_temp1$open <- rowSums(is.na(ds_temp1[,2:3]))==2

gives you column which is TRUE if the account is open and FALSE in other situation.

You can use similar approach for testing the state of account closing.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at gmx.de
> Sent: Friday, June 24, 2016 9:15 AM
> To: Bert Gunter <bgunter.4567 at gmail.com>
> Cc: R Help <r-help at r-project.org>
> Subject: Re: [R] Subscripting problem with is.na()
>
> Hi Bert,
>
> many thanks for all your help and your comments. I learn at lot this way.
>
> My question was about is.na() at the first sight but the actual task looks like
> this:
>
> I have two variables in my customer data that signal if the customer accout
> was closed by master data management or by sales. Say these variables are
> closed_mdm and closed_sls. They contain NA if the customer account is still
> open or a closing code from "01" to "08" if the customer account was closed
> and why.
>
> For my analysis I need a variable that combines the two variables
> closed_mdm and closed_sls to set a filter easily on those who are closed not
> matter what the reason was nor who closed the account.
>
> As I always encounter problems when dealing with ifelse statements and NA
> I decided to merge these two variables to one variable containing 0 = not
> closed and 1 = closed. In my context this seems to be - at least to me - a
> reasonable approach.
>
> Replacement of missing values and merging the variables is the easiest way
> for me.
>
> -- cut --
>
> cust_id <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)
> closed_mdm <- c("01", NA, NA, NA, "08", "07", NA, NA, "05", NA, NA, NA,
> "04", NA, NA, NA, NA, NA, NA, NA)
> closed_sls <- c(NA, "08", NA, NA, "08", "07", NA, NA, NA, NA, "03", NA, NA,
> NA, "05", NA, NA, NA, NA, NA)
>
> # 1st try
> ds_temp1 <- data.frame(cust_id, closed_mdm, closed_sls)
> ds_temp1
>
> ds_temp1$closed <- closed_mdm | closed_sls  # WRONG
>
> # 2nd try
> closed_mdm_fac1 <- as.factor(closed_mdm)
> closed_sls_fac1 <- as.factor(closed_sls)
>
> ds_temp2 <- data.frame(cust_id, closed_mdm_fac1, closed_sls_fac1)
> ds_temp2
>
> ds_temp2$closed <- ds_temp$closed_mdm_fac1 |
> ds_temp$closed_sls_fac1  # WRONG
>
> # 3rd try
> closed_mdm_num1 <- as.numeric(closed_mdm)  # OK
> closed_sls_num1 <- as.numeric(closed_sls)  # OK
>
> ds_temp3 <- data.frame(cust_id, closed_mdm_num1, closed_sls_num1)
> ds_temp3
>
> ds_temp3$closed <- ds_temp$closed_mdm_num1 |
> ds_temp$closed_sls_num1  # WRONG
>
> # 4th try
> ds_temp4 <- ds_temp3
> ds_temp4
>
> # Does not run due to not allowed NA in subscripts
> ds_temp4[is.na(ds_temp4$closed_mdm_num1),
> ds_temp4$closed_mdm_num1] <- 0
> ds_temp4[is.na(ds_temp4$closed_sls_num1), ds_temp4$closed_sls_num1]
> <- 0
>
> # 5th try
> ds_temp4$closed_mdm_num1 <-
> ifelse(is.na(ds_temp4$closed_mdm_num1), 1, 0)
> ds_temp4$closed_sls_num1 <- ifelse(is.na(ds_temp4$closed_sls_num1), 1,
> 0)
> ds_temp4
>
> ds_temp4$closed <- ifelse(ds_temp4$closed_mdm_num1 == 1 |
> ds_temp4$closed_sls_num1 == 1, 1, 0)
> ds_temp4
>
> -- cut --
>
> Is there a better way to do it?
>
> Kind regards
>
> Georg
>
>
> > Gesendet: Donnerstag, 23. Juni 2016 um 23:55 Uhr
> > Von: "Bert Gunter" <bgunter.4567 at gmail.com>
> > An: "David L Carlson" <dcarlson at tamu.edu>
> > Cc: "R Help" <r-help at r-project.org>
> > Betreff: Re: [R] Subscripting problem with is.na()
> >
> > ... actually, FWIW, I would say that this little discussion mostly
> > demonstrates why the OP's request is probably not a good idea in the
> > first place. Usually, NA's should be left as NA's to be dealt with
> > properly by R and packages. In biological measurements, for example,
> > NA's often mean "below the ability to reliably measure." Biologists
> > with whom I've worked over many years often want to convert these to 0
> > or omit the cases, both of which lead to biased estimates and/or
> > underestimates of variability and excess claims of "statistical
> > significance" (for those who belong to this religious persuasion). One
> > should never say never, but I suspect that there are relatively few
> > circumstances where the conversion the OP requested is actually wise.
> >
> > Feel free to ignore/reject such extraneous comments of course.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Thu, Jun 23, 2016 at 12:14 PM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> > > Good point. I did not think about factors. Also your example raises
> another issue since column c is logical, but gets silently converted to numeric.
> This would seem to get the job done assuming the conversion is intended for
> numeric columns only:
> > >
> > >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> > >> sapply(test, class)
> > >         a         b         c
> > > "numeric"  "factor" "logical"
> > >> num <- sapply(test, is.numeric)
> > >> test[, num][is.na(test[, num])] <- 0
> > >> test
> > >   a    b  c
> > > 1 1    A NA
> > > 2 0    b NA
> > > 3 2 <NA> NA
> > >
> > > David C
> > >
> > > -----Original Message-----
> > > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > > Sent: Thursday, June 23, 2016 1:48 PM
> > > To: David L Carlson
> > > Cc: Ivan Calandra; R Help
> > > Subject: Re: [R] Subscripting problem with is.na()
> > >
> > > Not in general, David:
> > >
> > > e.g.
> > >
> > >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> > >
> > >> is.na(test)
> > >          a     b    c
> > > [1,] FALSE FALSE TRUE
> > > [2,]  TRUE FALSE TRUE
> > > [3,] FALSE  TRUE TRUE
> > >
> > >> test[is.na(test)]
> > > [1] NA NA NA NA NA
> > >
> > >> test[is.na(test)] <- 0
> > > Warning message:
> > > In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
> > >   invalid factor level, NA generated
> > >
> > >> test
> > >   a    b c
> > > 1 1    A 0
> > > 2 0    b 0
> > > 3 2 <NA> 0
> > >
> > >
> > > The problem is the default conversion to factors and the replacement
> > > operation for factors. So:
> > >
> > >> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c=
> rep(NA,3))
> > >> class(test$b)
> > > [1] "AsIs"  ## so NOT a factor
> > >
> > >> test[is.na(test)] <- 0 # now works as you describe
> > >> test
> > >   a b c
> > > 1 1 A 0
> > > 2 0 b 0
> > > 3 2 0 0
> > >
> > > Of course the OP (and you) probably had a data frame of all numerics
> > > in mind, so the problem doesn't arise. But I think one needs to make
> > > the distinction and issue clear.
> > >
> > > Cheers,
> > > Bert
> > >
> > >
> > >
> > >
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> > > and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> > >> The function is.na() returns a matrix when applied to a data.frame so
> you can easily convert all the NAs to 0's:
> > >>
> > >>> ds_test
> > >>    var1 var2
> > >> 1     1    1
> > >> 2     2    2
> > >> 3     3    3
> > >> 4    NA   NA
> > >> 5     5    5
> > >> 6     6    6
> > >> 7     7    7
> > >> 8    NA   NA
> > >> 9     9    9
> > >> 10   10   10
> > >>> is.na(ds_test)
> > >>        var1  var2
> > >>  [1,] FALSE FALSE
> > >>  [2,] FALSE FALSE
> > >>  [3,] FALSE FALSE
> > >>  [4,]  TRUE  TRUE
> > >>  [5,] FALSE FALSE
> > >>  [6,] FALSE FALSE
> > >>  [7,] FALSE FALSE
> > >>  [8,]  TRUE  TRUE
> > >>  [9,] FALSE FALSE
> > >> [10,] FALSE FALSE
> > >>> ds_test[is.na(ds_test)] <- 0
> > >>> ds_test
> > >>    var1 var2
> > >> 1     1    1
> > >> 2     2    2
> > >> 3     3    3
> > >> 4     0    0
> > >> 5     5    5
> > >> 6     6    6
> > >> 7     7    7
> > >> 8     0    0
> > >> 9     9    9
> > >> 10   10   10
> > >>
> > >> -------------------------------------
> > >> David L Carlson
> > >> Department of Anthropology
> > >> Texas A&M University
> > >> College Station, TX 77840-4352
> > >>
> > >> -----Original Message-----
> > >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
> Calandra
> > >> Sent: Thursday, June 23, 2016 10:14 AM
> > >> To: R Help
> > >> Subject: Re: [R] Subscripting problem with is.na()
> > >>
> > >> Thank you Bert for this clarification. It is indeed an important point.
> > >>
> > >> Ivan
> > >>
> > >> --
> > >> Ivan Calandra, PhD
> > >> Scientific Mediator
> > >> University of Reims Champagne-Ardenne
> > >> GEGENAA - EA 3795
> > >> CREA - 2 esplanade Roland Garros
> > >> 51100 Reims, France
> > >> +33(0)3 26 77 36 89
> > >> ivan.calandra at univ-reims.fr
> > >> --
> > >> https://www.researchgate.net/profile/Ivan_Calandra
> > >> https://publons.com/author/705639/
> > >>
> > >> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
> > >>> Sorry, Ivan, your statement is incorrect:
> > >>>
> > >>> "When you use a single bracket on a list with only one argument in
> > >>> between, then R extracts "elements", i.e. columns in the case of a
> > >>> data.frame. This explains your errors. "
> > >>>
> > >>> e.g.
> > >>>
> > >>>> ex <- data.frame(a = 1:3, b = letters[1:3])
> > >>>> a <- 1:3
> > >>>> identical(ex[1], a)
> > >>> [1] FALSE
> > >>>
> > >>>> class(ex[1])
> > >>> [1] "data.frame"
> > >>>> class(a)
> > >>> [1] "integer"
> > >>>
> > >>> Compare:
> > >>>
> > >>>> identical(ex[[1]], a)
> > >>> [1] TRUE
> > >>>
> > >>> Why? Single bracket extraction on a list results in a list; double
> > >>> bracket extraction results in the element of the list ( a "column" in
> > >>> the case of a data frame, which is a specific kind of list). The
> > >>> relevant sections of ?Extract are:
> > >>>
> > >>> "Indexing by [ is similar to atomic vectors and selects a **list** of
> > >>> the specified element(s).
> > >>>
> > >>> Both [[ and $ select a **single element of the list**. "
> > >>>
> > >>>
> > >>> Hope this clarifies this often-confused issue.
> > >>>
> > >>>
> > >>> Cheers,
> > >>> Bert
> > >>> Bert Gunter
> > >>>
> > >>> "The trouble with having an open mind is that people keep coming
> along
> > >>> and sticking things into it."
> > >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>>
> > >>>
> > >>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
> > >>> <ivan.calandra at univ-reims.fr> wrote:
> > >>>> My statement "Using a single bracket '[' on a data.frame does the
> same as
> > >>>> for matrices: you need to specify rows and columns" was not correct.
> > >>>>
> > >>>>
> > >>>> When you use a single bracket on a list with only one argument in
> between,
> > >>>> then R extracts "elements", i.e. columns in the case of a data.frame.
> This
> > >>>> explains your errors.
> > >>>>
> > >>>> But it is possible to use a single bracket on a data.frame with 2
> arguments
> > >>>> (rows, columns) separated by a comma, as with matrices. This is the
> solution
> > >>>> you received.
> > >>>>
> > >>>> Ivan
> > >>>>
> > >>>>
> > >>>> --
> > >>>> Ivan Calandra, PhD
> > >>>> Scientific Mediator
> > >>>> University of Reims Champagne-Ardenne
> > >>>> GEGENAA - EA 3795
> > >>>> CREA - 2 esplanade Roland Garros
> > >>>> 51100 Reims, France
> > >>>> +33(0)3 26 77 36 89
> > >>>> ivan.calandra at univ-reims.fr
> > >>>> --
> > >>>> https://www.researchgate.net/profile/Ivan_Calandra
> > >>>> https://publons.com/author/705639/
> > >>>>
> > >>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
> > >>>>> Dear Georg,
> > >>>>>
> > >>>>> You need to learn a bit more about the subsetting methods,
> depending on
> > >>>>> the object structure you're trying to subset.
> > >>>>>
> > >>>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
> > >>>>> you get this error: "Error in `[.data.frame`(ds_test,
> is.na(ds_test$var1))
> > >>>>> : undefined columns selected"
> > >>>>>
> > >>>>> This means that R does not understand which column you're trying
> to
> > >>>>> select. But you're actually trying to select rows.
> > >>>>>
> > >>>>> Using a single bracket '[' on a data.frame does the same as for
> matrices:
> > >>>>> you need to specify rows and columns, like this:
> > >>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
> > >>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because
> you
> > >>>>> didn't specify any after the comma
> > >>>>>
> > >>>>> If you want it only for "var1", then you need to specify the column:
> > >>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
> > >>>>>
> > >>>>> It's the same problem with your 2nd and 4th tries (4th one has other
> > >>>>> problems). Your 3rd try does not change ds_test at all.
> > >>>>>
> > >>>>> HTH,
> > >>>>> Ivan
> > >>>>>
> > >>>>> --
> > >>>>> Ivan Calandra, PhD
> > >>>>> Scientific Mediator
> > >>>>> University of Reims Champagne-Ardenne
> > >>>>> GEGENAA - EA 3795
> > >>>>> CREA - 2 esplanade Roland Garros
> > >>>>> 51100 Reims, France
> > >>>>> +33(0)3 26 77 36 89
> > >>>>> ivan.calandra at univ-reims.fr
> > >>>>> --
> > >>>>> https://www.researchgate.net/profile/Ivan_Calandra
> > >>>>> https://publons.com/author/705639/
> > >>>>>
> > >>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
> > >>>>>> Hi All,
> > >>>>>>
> > >>>>>> I would like to recode my NAs to 0. Using a single vector everything
> is
> > >>>>>> fine.
> > >>>>>>
> > >>>>>> But if I use a data.frame things go wrong:
> > >>>>>>
> > >>>>>> -- cut --
> > >>>>>>
> > >>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
> > >>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
> > >>>>>> ds_test <-
> > >>>>>>     data.frame(var1, var2)
> > >>>>>>
> > >>>>>> test <- var1
> > >>>>>> test[is.na(test)] <- 0
> > >>>>>> test  # NA recoded OK
> > >>>>>>
> > >>>>>> # First try
> > >>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
> > >>>>>>
> > >>>>>> # Second try
> > >>>>>> ds_test[is.na("var1")] <- 0
> > >>>>>> ds_test$var1  # not recoded WRONG
> > >>>>>>
> > >>>>>> # Third try: to me the most intuitive approach
> > >>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one
> element in
> > >>>>>> integerOneIndex WRONG
> > >>>>>>
> > >>>>>> # Fourth try
> > >>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns
> WRONG
> > >>>>>>
> > >>>>>> -- cut --
> > >>>>>>    How can I do it correctly?
> > >>>>>>
> > >>>>>> Where could I have found something about it?
> > >>>>>>
> > >>>>>> Kind regards
> > >>>>>>
> > >>>>>> Georg
> > >>>>>>
> > >>>>>> ______________________________________________
> > >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>> PLEASE do read the posting guide
> > >>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> > >>>>>>
> > >>>>> ______________________________________________
> > >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>> PLEASE do read the posting guide
> > >>>>> http://www.R-project.org/posting-guide.html
> > >>>>> and provide commented, minimal, self-contained, reproducible
> code.
> > >>>>>
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > >>>> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From tr206 at kent.ac.uk  Fri Jun 24 12:32:43 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 24 Jun 2016 10:32:43 +0000
Subject: [R] How to use seas()
Message-ID: <1466764363804.94336@kent.ac.uk>

Dear all,

I am trying to run the seas() function. In doing so, I need an object of class "ts". I tried to generate an ts object using the ts() function but it does not work.
Does anyone have an idea how to generate an ts object. In addition, I get the error that there are too many observations in the file. How can I cope with that?

library(seasonal)
> data<-Shiller_data[,2]

s<-ts(data,start = c(1871, 01))

> s

Time Series:

Start = 1871

End = 3610

Frequency = 1

   [1]    4.44    4.50    4.61    4.74    4.86    4.82    4.73    4.79    4.84    4.59    4.64    4.74    4.86

  [14]    4.88    5.04    5.18    5.18    5.13    5.10    5.04    4.95    4.97    4.95    5.07    5.11    5.15

  [27]    5.11    5.04    5.05    4.98    4.97    4.97    4.59    4.19    4.04    4.42    4.66    4.80    4.73



> SP <- seas(s)

Error: X-13 run failed



Errors:

- Problem reading C:\Users\tr206\AppData\Local\Temp\Rtmp4Qtc08\x1312202a115399/data.dta. Too

  many observations in file.

- Problem reading C:\Users\tr206\AppData\Local\Temp\Rtmp4Qtc08\x1312202a115399/data.dta. Check

  your input file and format.

- Time series could not be read due to previously found errors

- Specify series before user-defined adjustments

- Need to specify a series to identify outliers



Thanks for your help.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Jun 24 15:44:21 2016
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 24 Jun 2016 13:44:21 +0000
Subject: [R] Effect size measures for GLM
References: <20160621122355.Horde.Jnth7jq6y-9QM9jvB5TE-w2@webmail.unipa.it>
Message-ID: <loom.20160624T153642-31@post.gmane.org>

Gianfranco Lovison <gianfranco.lovison <at> unipa.it> writes:

> 
> Is there a library for (friendly) calculation of effect size measures for
> Generalized Linear Models? I have found "compute.es", but it seems to be
> suitable only for Linear Models. A library taking a glm object and 
> computing
> partial R^2-type statistics, appropriate for GLMs, would be enough, but I have
> bee unable to find it!
> 
> 

  I don't know about *partial* R^2 statistics, but as a starting point try
library("sos"); findFn("nagelkerke") for example.


From JSorkin at grecc.umaryland.edu  Fri Jun 24 15:45:33 2016
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 24 Jun 2016 09:45:33 -0400
Subject: [R] Add column to the output of summary(glht).
Message-ID: <576D013D020000CB00158D67@smtp.medicine.umaryland.edu>


I am trying to make the leap from an R users to an R aficionado . . .
 
I am trying to understand how add a column to the output of summary (and to understand how summary() works).
 
I have run a glmer
fit0 <- glmer(Fall ~ Group+(1|PID),family=poisson(link="log"),data=data[data[,"Group"]!=0,])
 
and I want to perform adjusted multiple comparisons:
 
SumTukey <- summary(glht(fit0, linfct= mcp(Group="Tukey")))
 
which gives beautiful output:
 
> SumTukey

	 Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: glmer(formula = Fall ~ Group + (1 | PID), data = data[data[, 
    "Group"] != 0, ], family = poisson(link = "log"))

Linear Hypotheses:
           Estimate Std. Error z value Pr(>|z|)
2 - 1 == 0   0.5320     0.5075   1.048    0.717
3 - 1 == 0   0.6554     0.5000   1.311    0.551
4 - 1 == 0   0.9357     0.4655   2.010    0.181
3 - 2 == 0   0.1234     0.4174   0.296    0.991
4 - 2 == 0   0.4037     0.3754   1.075    0.700
4 - 3 == 0   0.2803     0.3651   0.768    0.867
(Adjusted p values reported -- single-step method)
 
I want to add a column to the output (unadjusted p-values), but I don't see how this might be done. The output
is not a dataframe, nor is it a matix. 
> class(SumTukey)
[1] "summary.glht" "glht"  

It is some class of objects that I don't understand and know nothing
about. How can I add a column to the output of SumTukey [a.k.a. summary(glht(fit0, linfct= mcp(Group="Tukey")))] ?
 
Thank you
John
 
 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From dcarlson at tamu.edu  Fri Jun 24 16:04:12 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 24 Jun 2016 14:04:12 +0000
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
Message-ID: <0a733adc674b4cfd85501b95c4b87bad@exch-2p-mbx-t1.ads.tamu.edu>

Yes, measurements below detection should be treated differently. I thought about the missing data issue, but there is another context in which spreadsheet data containing count data where 0 entries are deliberately left blank for readability or economy. In that case it is easier to import and use R to replace the missing 0s than to fill the missing cell entries in the spreadsheet before importing it.

David C

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Thursday, June 23, 2016 4:56 PM
To: David L Carlson
Cc: Ivan Calandra; R Help
Subject: Re: [R] Subscripting problem with is.na()

... actually, FWIW, I would say that this little discussion mostly
demonstrates why the OP's request is probably not a good idea in the
first place. Usually, NA's should be left as NA's to be dealt with
properly by R and packages. In biological measurements, for example,
NA's often mean "below the ability to reliably measure." Biologists
with whom I've worked over many years often want to convert these to 0
or omit the cases, both of which lead to biased estimates and/or
underestimates of variability and excess claims of "statistical
significance" (for those who belong to this religious persuasion). One
should never say never, but I suspect that there are relatively few
circumstances where the conversion the OP requested is actually wise.

Feel free to ignore/reject such extraneous comments of course.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 23, 2016 at 12:14 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> Good point. I did not think about factors. Also your example raises another issue since column c is logical, but gets silently converted to numeric. This would seem to get the job done assuming the conversion is intended for numeric columns only:
>
>> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>> sapply(test, class)
>         a         b         c
> "numeric"  "factor" "logical"
>> num <- sapply(test, is.numeric)
>> test[, num][is.na(test[, num])] <- 0
>> test
>   a    b  c
> 1 1    A NA
> 2 0    b NA
> 3 2 <NA> NA
>
> David C
>
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Thursday, June 23, 2016 1:48 PM
> To: David L Carlson
> Cc: Ivan Calandra; R Help
> Subject: Re: [R] Subscripting problem with is.na()
>
> Not in general, David:
>
> e.g.
>
>> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>
>> is.na(test)
>          a     b    c
> [1,] FALSE FALSE TRUE
> [2,]  TRUE FALSE TRUE
> [3,] FALSE  TRUE TRUE
>
>> test[is.na(test)]
> [1] NA NA NA NA NA
>
>> test[is.na(test)] <- 0
> Warning message:
> In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
>   invalid factor level, NA generated
>
>> test
>   a    b c
> 1 1    A 0
> 2 0    b 0
> 3 2 <NA> 0
>
>
> The problem is the default conversion to factors and the replacement
> operation for factors. So:
>
>> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c= rep(NA,3))
>> class(test$b)
> [1] "AsIs"  ## so NOT a factor
>
>> test[is.na(test)] <- 0 # now works as you describe
>> test
>   a b c
> 1 1 A 0
> 2 0 b 0
> 3 2 0 0
>
> Of course the OP (and you) probably had a data frame of all numerics
> in mind, so the problem doesn't arise. But I think one needs to make
> the distinction and issue clear.
>
> Cheers,
> Bert
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> The function is.na() returns a matrix when applied to a data.frame so you can easily convert all the NAs to 0's:
>>
>>> ds_test
>>    var1 var2
>> 1     1    1
>> 2     2    2
>> 3     3    3
>> 4    NA   NA
>> 5     5    5
>> 6     6    6
>> 7     7    7
>> 8    NA   NA
>> 9     9    9
>> 10   10   10
>>> is.na(ds_test)
>>        var1  var2
>>  [1,] FALSE FALSE
>>  [2,] FALSE FALSE
>>  [3,] FALSE FALSE
>>  [4,]  TRUE  TRUE
>>  [5,] FALSE FALSE
>>  [6,] FALSE FALSE
>>  [7,] FALSE FALSE
>>  [8,]  TRUE  TRUE
>>  [9,] FALSE FALSE
>> [10,] FALSE FALSE
>>> ds_test[is.na(ds_test)] <- 0
>>> ds_test
>>    var1 var2
>> 1     1    1
>> 2     2    2
>> 3     3    3
>> 4     0    0
>> 5     5    5
>> 6     6    6
>> 7     7    7
>> 8     0    0
>> 9     9    9
>> 10   10   10
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
>> Sent: Thursday, June 23, 2016 10:14 AM
>> To: R Help
>> Subject: Re: [R] Subscripting problem with is.na()
>>
>> Thank you Bert for this clarification. It is indeed an important point.
>>
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> Scientific Mediator
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
>>> Sorry, Ivan, your statement is incorrect:
>>>
>>> "When you use a single bracket on a list with only one argument in
>>> between, then R extracts "elements", i.e. columns in the case of a
>>> data.frame. This explains your errors. "
>>>
>>> e.g.
>>>
>>>> ex <- data.frame(a = 1:3, b = letters[1:3])
>>>> a <- 1:3
>>>> identical(ex[1], a)
>>> [1] FALSE
>>>
>>>> class(ex[1])
>>> [1] "data.frame"
>>>> class(a)
>>> [1] "integer"
>>>
>>> Compare:
>>>
>>>> identical(ex[[1]], a)
>>> [1] TRUE
>>>
>>> Why? Single bracket extraction on a list results in a list; double
>>> bracket extraction results in the element of the list ( a "column" in
>>> the case of a data frame, which is a specific kind of list). The
>>> relevant sections of ?Extract are:
>>>
>>> "Indexing by [ is similar to atomic vectors and selects a **list** of
>>> the specified element(s).
>>>
>>> Both [[ and $ select a **single element of the list**. "
>>>
>>>
>>> Hope this clarifies this often-confused issue.
>>>
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
>>> <ivan.calandra at univ-reims.fr> wrote:
>>>> My statement "Using a single bracket '[' on a data.frame does the same as
>>>> for matrices: you need to specify rows and columns" was not correct.
>>>>
>>>>
>>>> When you use a single bracket on a list with only one argument in between,
>>>> then R extracts "elements", i.e. columns in the case of a data.frame. This
>>>> explains your errors.
>>>>
>>>> But it is possible to use a single bracket on a data.frame with 2 arguments
>>>> (rows, columns) separated by a comma, as with matrices. This is the solution
>>>> you received.
>>>>
>>>> Ivan
>>>>
>>>>
>>>> --
>>>> Ivan Calandra, PhD
>>>> Scientific Mediator
>>>> University of Reims Champagne-Ardenne
>>>> GEGENAA - EA 3795
>>>> CREA - 2 esplanade Roland Garros
>>>> 51100 Reims, France
>>>> +33(0)3 26 77 36 89
>>>> ivan.calandra at univ-reims.fr
>>>> --
>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>> https://publons.com/author/705639/
>>>>
>>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>>>>> Dear Georg,
>>>>>
>>>>> You need to learn a bit more about the subsetting methods, depending on
>>>>> the object structure you're trying to subset.
>>>>>
>>>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>>>>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
>>>>> : undefined columns selected"
>>>>>
>>>>> This means that R does not understand which column you're trying to
>>>>> select. But you're actually trying to select rows.
>>>>>
>>>>> Using a single bracket '[' on a data.frame does the same as for matrices:
>>>>> you need to specify rows and columns, like this:
>>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
>>>>> didn't specify any after the comma
>>>>>
>>>>> If you want it only for "var1", then you need to specify the column:
>>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>>>>>
>>>>> It's the same problem with your 2nd and 4th tries (4th one has other
>>>>> problems). Your 3rd try does not change ds_test at all.
>>>>>
>>>>> HTH,
>>>>> Ivan
>>>>>
>>>>> --
>>>>> Ivan Calandra, PhD
>>>>> Scientific Mediator
>>>>> University of Reims Champagne-Ardenne
>>>>> GEGENAA - EA 3795
>>>>> CREA - 2 esplanade Roland Garros
>>>>> 51100 Reims, France
>>>>> +33(0)3 26 77 36 89
>>>>> ivan.calandra at univ-reims.fr
>>>>> --
>>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>>> https://publons.com/author/705639/
>>>>>
>>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>>>>>> Hi All,
>>>>>>
>>>>>> I would like to recode my NAs to 0. Using a single vector everything is
>>>>>> fine.
>>>>>>
>>>>>> But if I use a data.frame things go wrong:
>>>>>>
>>>>>> -- cut --
>>>>>>
>>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>>>>>> ds_test <-
>>>>>>     data.frame(var1, var2)
>>>>>>
>>>>>> test <- var1
>>>>>> test[is.na(test)] <- 0
>>>>>> test  # NA recoded OK
>>>>>>
>>>>>> # First try
>>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>>>>>>
>>>>>> # Second try
>>>>>> ds_test[is.na("var1")] <- 0
>>>>>> ds_test$var1  # not recoded WRONG
>>>>>>
>>>>>> # Third try: to me the most intuitive approach
>>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
>>>>>> integerOneIndex WRONG
>>>>>>
>>>>>> # Fourth try
>>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>>>>>>
>>>>>> -- cut --
>>>>>>    How can I do it correctly?
>>>>>>
>>>>>> Where could I have found something about it?
>>>>>>
>>>>>> Kind regards
>>>>>>
>>>>>> Georg
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From petr.pikal at precheza.cz  Fri Jun 24 16:07:43 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 24 Jun 2016 14:07:43 +0000
Subject: [R] Add column to the output of summary(glht).
In-Reply-To: <576D013D020000CB00158D67@smtp.medicine.umaryland.edu>
References: <576D013D020000CB00158D67@smtp.medicine.umaryland.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032427@SRVEXCHMBX.precheza.cz>

Hi

you can check structure of any object by str so

str(fit0)

should give you an insight how fit0 is structured and

str(SumTukey)

gives you structure of SumTukey object (which is probably list). You can manipulate with the output as you wish according to the rules of R.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John
> Sorkin
> Sent: Friday, June 24, 2016 3:46 PM
> To: r-help at r-project.org
> Subject: [R] Add column to the output of summary(glht).
>
>
> I am trying to make the leap from an R users to an R aficionado . . .
>
> I am trying to understand how add a column to the output of summary (and
> to understand how summary() works).
>
> I have run a glmer
> fit0 <- glmer(Fall ~
> Group+(1|PID),family=poisson(link="log"),data=data[data[,"Group"]!=0,])
>
> and I want to perform adjusted multiple comparisons:
>
> SumTukey <- summary(glht(fit0, linfct= mcp(Group="Tukey")))
>
> which gives beautiful output:
>
> > SumTukey
>
>        Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: glmer(formula = Fall ~ Group + (1 | PID), data = data[data[,
>     "Group"] != 0, ], family = poisson(link = "log"))
>
> Linear Hypotheses:
>            Estimate Std. Error z value Pr(>|z|)
> 2 - 1 == 0   0.5320     0.5075   1.048    0.717
> 3 - 1 == 0   0.6554     0.5000   1.311    0.551
> 4 - 1 == 0   0.9357     0.4655   2.010    0.181
> 3 - 2 == 0   0.1234     0.4174   0.296    0.991
> 4 - 2 == 0   0.4037     0.3754   1.075    0.700
> 4 - 3 == 0   0.2803     0.3651   0.768    0.867
> (Adjusted p values reported -- single-step method)
>
> I want to add a column to the output (unadjusted p-values), but I don't see
> how this might be done. The output is not a dataframe, nor is it a matix.
> > class(SumTukey)
> [1] "summary.glht" "glht"
>
> It is some class of objects that I don't understand and know nothing about.
> How can I add a column to the output of SumTukey [a.k.a. summary(glht(fit0,
> linfct= mcp(Group="Tukey")))] ?
>
> Thank you
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the
> intended recipient(s) and may contain confidential and privileged
> information. Any unauthorized use, disclosure or distribution is prohibited. If
> you are not the intended recipient, please contact the sender by reply email
> and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From marc_schwartz at me.com  Fri Jun 24 16:13:08 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 24 Jun 2016 09:13:08 -0500
Subject: [R] Add column to the output of summary(glht).
In-Reply-To: <576D013D020000CB00158D67@smtp.medicine.umaryland.edu>
References: <576D013D020000CB00158D67@smtp.medicine.umaryland.edu>
Message-ID: <35DF0CB4-4D8A-43D7-9A18-98FE8E3EB60F@me.com>


> On Jun 24, 2016, at 8:45 AM, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
> 
> 
> I am trying to make the leap from an R users to an R aficionado . . .
> 
> I am trying to understand how add a column to the output of summary (and to understand how summary() works).
> 
> I have run a glmer
> fit0 <- glmer(Fall ~ Group+(1|PID),family=poisson(link="log"),data=data[data[,"Group"]!=0,])
> 
> and I want to perform adjusted multiple comparisons:
> 
> SumTukey <- summary(glht(fit0, linfct= mcp(Group="Tukey")))
> 
> which gives beautiful output:
> 
>> SumTukey
> 
> 	 Simultaneous Tests for General Linear Hypotheses
> 
> Multiple Comparisons of Means: Tukey Contrasts
> 
> 
> Fit: glmer(formula = Fall ~ Group + (1 | PID), data = data[data[, 
>    "Group"] != 0, ], family = poisson(link = "log"))
> 
> Linear Hypotheses:
>           Estimate Std. Error z value Pr(>|z|)
> 2 - 1 == 0   0.5320     0.5075   1.048    0.717
> 3 - 1 == 0   0.6554     0.5000   1.311    0.551
> 4 - 1 == 0   0.9357     0.4655   2.010    0.181
> 3 - 2 == 0   0.1234     0.4174   0.296    0.991
> 4 - 2 == 0   0.4037     0.3754   1.075    0.700
> 4 - 3 == 0   0.2803     0.3651   0.768    0.867
> (Adjusted p values reported -- single-step method)
> 
> I want to add a column to the output (unadjusted p-values), but I don't see how this might be done. The output
> is not a dataframe, nor is it a matix. 
>> class(SumTukey)
> [1] "summary.glht" "glht"  
> 
> It is some class of objects that I don't understand and know nothing
> about. How can I add a column to the output of SumTukey [a.k.a. summary(glht(fit0, linfct= mcp(Group="Tukey")))] ?
> 
> Thank you
> John


Hi John,

Two things that can be helpful are to review the structure of the object returned by summary.glht(), which in your code above would be (see ?str):

 str(SumTukey)

and also review the print method for the object that actually generates the console output. In this case, using:

  multcomp:::print.summary.glht

or 

 getAnywhere(print.summary.glht)

will reveal the code that is used to generate the output that you see above. The print method is not exported from the package's namespace. 

You can review the print method code to see which components of 'SumTukey' are then used to create the output and what internal functions are used to do that.

Once you understand the structure of the object and how that object's content is formatted and output for display by the associated print method for the object class, you can modify things to fit your need by creating, if need be, your own functions to modify the required part or parts of the object itself and then output them.

If you want to understand what summary.glht() is doing, take the same approach as above for the print method, since it is not exported either:

  multcomp:::summary.glht

or 

  getAnywhere(summary.glht)


Regards,

Marc Schwartz


From macqueen1 at llnl.gov  Fri Jun 24 17:19:35 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 24 Jun 2016 15:19:35 +0000
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
	<trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>
Message-ID: <D3929A54.17C74F%macqueen1@llnl.gov>

See insert below.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/24/16, 12:14 AM, "R-help on behalf of G.Maubach at gmx.de"
<r-help-bounces at r-project.org on behalf of G.Maubach at gmx.de> wrote:

>Hi Bert,
>
>many thanks for all your help and your comments. I learn at lot this way.
>
>My question was about is.na() at the first sight but the actual task
>looks like this:
>
>I have two variables in my customer data that signal if the customer
>accout was closed by master data management or by sales. Say these
>variables are closed_mdm and closed_sls. They contain NA if the customer
>account is still open or a closing code from "01" to "08" if the customer
>account was closed and why.
>
>For my analysis I need a variable that combines the two variables
>closed_mdm and closed_sls to set a filter easily on those who are closed
>not matter what the reason was nor who closed the account.

Given that description, this would seem to do the job:

cust.id <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
        13, 14, 15, 16, 17, 18, 19, 20)

closed.mdm <- c("01", NA, NA, NA, "08", "07", NA, NA, "05",
       NA, NA, NA, "04", NA, NA, NA, NA, NA, NA, NA)

closed.sls <- c(NA, "08", NA, NA, "08", "07", NA, NA, NA, NA,
      "03", NA, NA, NA, "05", NA, NA, NA, NA, NA)

df <- data.frame(cust.id, closed.mdm, closed.sls,
                 stringsAsFactors=FALSE)



df$opcl <- ifelse( is.na(closed.mdm) & is.na(closed.sls) ,
                   'open','closed')


Then use the opcl column to filter, e.g.,

subset(df, opcl=='open')

If you want to operate directly on one of the 'closed' column, perhaps
these examples will help
## does not work due to the NAs
df[ df$closed.sls == '08',]
## workd
subset(df, closed.sls=='08')
## works
df[ !is.na(df$closed.sls) & df$closed.sls == '08',]




>
>As I always encounter problems when dealing with ifelse statements and NA
>I decided to merge these two variables to one variable containing 0 = not
>closed and 1 = closed. In my context this seems to be - at least to me -
>a reasonable approach.
>
>Replacement of missing values and merging the variables is the easiest
>way for me.
>
>-- cut --
>
>cust_id <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,
>18, 19, 20)
>closed_mdm <- c("01", NA, NA, NA, "08", "07", NA, NA, "05", NA, NA, NA,
>"04", NA, NA, NA, NA, NA, NA, NA)
>closed_sls <- c(NA, "08", NA, NA, "08", "07", NA, NA, NA, NA, "03", NA,
>NA, NA, "05", NA, NA, NA, NA, NA)
>
># 1st try
>ds_temp1 <- data.frame(cust_id, closed_mdm, closed_sls)
>ds_temp1
>
>ds_temp1$closed <- closed_mdm | closed_sls  # WRONG
>
># 2nd try
>closed_mdm_fac1 <- as.factor(closed_mdm)
>closed_sls_fac1 <- as.factor(closed_sls)
>
>ds_temp2 <- data.frame(cust_id, closed_mdm_fac1, closed_sls_fac1)
>ds_temp2
>
>ds_temp2$closed <- ds_temp$closed_mdm_fac1 | ds_temp$closed_sls_fac1  #
>WRONG
>
># 3rd try
>closed_mdm_num1 <- as.numeric(closed_mdm)  # OK
>closed_sls_num1 <- as.numeric(closed_sls)  # OK
>
>ds_temp3 <- data.frame(cust_id, closed_mdm_num1, closed_sls_num1)
>ds_temp3
>
>ds_temp3$closed <- ds_temp$closed_mdm_num1 | ds_temp$closed_sls_num1  #
>WRONG
>
># 4th try
>ds_temp4 <- ds_temp3
>ds_temp4
>
># Does not run due to not allowed NA in subscripts
>ds_temp4[is.na(ds_temp4$closed_mdm_num1), ds_temp4$closed_mdm_num1] <- 0
>ds_temp4[is.na(ds_temp4$closed_sls_num1), ds_temp4$closed_sls_num1] <- 0
>
># 5th try
>ds_temp4$closed_mdm_num1 <- ifelse(is.na(ds_temp4$closed_mdm_num1), 1, 0)
>ds_temp4$closed_sls_num1 <- ifelse(is.na(ds_temp4$closed_sls_num1), 1, 0)
>ds_temp4
>
>ds_temp4$closed <- ifelse(ds_temp4$closed_mdm_num1 == 1 |
>ds_temp4$closed_sls_num1 == 1, 1, 0)
>ds_temp4
>
>-- cut --
>
>Is there a better way to do it?
>
>Kind regards
>
>Georg
>
>
>> Gesendet: Donnerstag, 23. Juni 2016 um 23:55 Uhr
>> Von: "Bert Gunter" <bgunter.4567 at gmail.com>
>> An: "David L Carlson" <dcarlson at tamu.edu>
>> Cc: "R Help" <r-help at r-project.org>
>> Betreff: Re: [R] Subscripting problem with is.na()
>>
>> ... actually, FWIW, I would say that this little discussion mostly
>> demonstrates why the OP's request is probably not a good idea in the
>> first place. Usually, NA's should be left as NA's to be dealt with
>> properly by R and packages. In biological measurements, for example,
>> NA's often mean "below the ability to reliably measure." Biologists
>> with whom I've worked over many years often want to convert these to 0
>> or omit the cases, both of which lead to biased estimates and/or
>> underestimates of variability and excess claims of "statistical
>> significance" (for those who belong to this religious persuasion). One
>> should never say never, but I suspect that there are relatively few
>> circumstances where the conversion the OP requested is actually wise.
>> 
>> Feel free to ignore/reject such extraneous comments of course.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Jun 23, 2016 at 12:14 PM, David L Carlson <dcarlson at tamu.edu>
>>wrote:
>> > Good point. I did not think about factors. Also your example raises
>>another issue since column c is logical, but gets silently converted to
>>numeric. This would seem to get the job done assuming the conversion is
>>intended for numeric columns only:
>> >
>> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>> >> sapply(test, class)
>> >         a         b         c
>> > "numeric"  "factor" "logical"
>> >> num <- sapply(test, is.numeric)
>> >> test[, num][is.na(test[, num])] <- 0
>> >> test
>> >   a    b  c
>> > 1 1    A NA
>> > 2 0    b NA
>> > 3 2 <NA> NA
>> >
>> > David C
>> >
>> > -----Original Message-----
>> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> > Sent: Thursday, June 23, 2016 1:48 PM
>> > To: David L Carlson
>> > Cc: Ivan Calandra; R Help
>> > Subject: Re: [R] Subscripting problem with is.na()
>> >
>> > Not in general, David:
>> >
>> > e.g.
>> >
>> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>> >
>> >> is.na(test)
>> >          a     b    c
>> > [1,] FALSE FALSE TRUE
>> > [2,]  TRUE FALSE TRUE
>> > [3,] FALSE  TRUE TRUE
>> >
>> >> test[is.na(test)]
>> > [1] NA NA NA NA NA
>> >
>> >> test[is.na(test)] <- 0
>> > Warning message:
>> > In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
>> >   invalid factor level, NA generated
>> >
>> >> test
>> >   a    b c
>> > 1 1    A 0
>> > 2 0    b 0
>> > 3 2 <NA> 0
>> >
>> >
>> > The problem is the default conversion to factors and the replacement
>> > operation for factors. So:
>> >
>> >> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c=
>>rep(NA,3))
>> >> class(test$b)
>> > [1] "AsIs"  ## so NOT a factor
>> >
>> >> test[is.na(test)] <- 0 # now works as you describe
>> >> test
>> >   a b c
>> > 1 1 A 0
>> > 2 0 b 0
>> > 3 2 0 0
>> >
>> > Of course the OP (and you) probably had a data frame of all numerics
>> > in mind, so the problem doesn't arise. But I think one needs to make
>> > the distinction and issue clear.
>> >
>> > Cheers,
>> > Bert
>> >
>> >
>> >
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> > and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu>
>>wrote:
>> >> The function is.na() returns a matrix when applied to a data.frame
>>so you can easily convert all the NAs to 0's:
>> >>
>> >>> ds_test
>> >>    var1 var2
>> >> 1     1    1
>> >> 2     2    2
>> >> 3     3    3
>> >> 4    NA   NA
>> >> 5     5    5
>> >> 6     6    6
>> >> 7     7    7
>> >> 8    NA   NA
>> >> 9     9    9
>> >> 10   10   10
>> >>> is.na(ds_test)
>> >>        var1  var2
>> >>  [1,] FALSE FALSE
>> >>  [2,] FALSE FALSE
>> >>  [3,] FALSE FALSE
>> >>  [4,]  TRUE  TRUE
>> >>  [5,] FALSE FALSE
>> >>  [6,] FALSE FALSE
>> >>  [7,] FALSE FALSE
>> >>  [8,]  TRUE  TRUE
>> >>  [9,] FALSE FALSE
>> >> [10,] FALSE FALSE
>> >>> ds_test[is.na(ds_test)] <- 0
>> >>> ds_test
>> >>    var1 var2
>> >> 1     1    1
>> >> 2     2    2
>> >> 3     3    3
>> >> 4     0    0
>> >> 5     5    5
>> >> 6     6    6
>> >> 7     7    7
>> >> 8     0    0
>> >> 9     9    9
>> >> 10   10   10
>> >>
>> >> -------------------------------------
>> >> David L Carlson
>> >> Department of Anthropology
>> >> Texas A&M University
>> >> College Station, TX 77840-4352
>> >>
>> >> -----Original Message-----
>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
>>Calandra
>> >> Sent: Thursday, June 23, 2016 10:14 AM
>> >> To: R Help
>> >> Subject: Re: [R] Subscripting problem with is.na()
>> >>
>> >> Thank you Bert for this clarification. It is indeed an important
>>point.
>> >>
>> >> Ivan
>> >>
>> >> --
>> >> Ivan Calandra, PhD
>> >> Scientific Mediator
>> >> University of Reims Champagne-Ardenne
>> >> GEGENAA - EA 3795
>> >> CREA - 2 esplanade Roland Garros
>> >> 51100 Reims, France
>> >> +33(0)3 26 77 36 89
>> >> ivan.calandra at univ-reims.fr
>> >> --
>> >> https://www.researchgate.net/profile/Ivan_Calandra
>> >> https://publons.com/author/705639/
>> >>
>> >> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
>> >>> Sorry, Ivan, your statement is incorrect:
>> >>>
>> >>> "When you use a single bracket on a list with only one argument in
>> >>> between, then R extracts "elements", i.e. columns in the case of a
>> >>> data.frame. This explains your errors. "
>> >>>
>> >>> e.g.
>> >>>
>> >>>> ex <- data.frame(a = 1:3, b = letters[1:3])
>> >>>> a <- 1:3
>> >>>> identical(ex[1], a)
>> >>> [1] FALSE
>> >>>
>> >>>> class(ex[1])
>> >>> [1] "data.frame"
>> >>>> class(a)
>> >>> [1] "integer"
>> >>>
>> >>> Compare:
>> >>>
>> >>>> identical(ex[[1]], a)
>> >>> [1] TRUE
>> >>>
>> >>> Why? Single bracket extraction on a list results in a list; double
>> >>> bracket extraction results in the element of the list ( a "column"
>>in
>> >>> the case of a data frame, which is a specific kind of list). The
>> >>> relevant sections of ?Extract are:
>> >>>
>> >>> "Indexing by [ is similar to atomic vectors and selects a **list**
>>of
>> >>> the specified element(s).
>> >>>
>> >>> Both [[ and $ select a **single element of the list**. "
>> >>>
>> >>>
>> >>> Hope this clarifies this often-confused issue.
>> >>>
>> >>>
>> >>> Cheers,
>> >>> Bert
>> >>> Bert Gunter
>> >>>
>> >>> "The trouble with having an open mind is that people keep coming
>>along
>> >>> and sticking things into it."
>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>
>> >>>
>> >>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
>> >>> <ivan.calandra at univ-reims.fr> wrote:
>> >>>> My statement "Using a single bracket '[' on a data.frame does the
>>same as
>> >>>> for matrices: you need to specify rows and columns" was not
>>correct.
>> >>>>
>> >>>>
>> >>>> When you use a single bracket on a list with only one argument in
>>between,
>> >>>> then R extracts "elements", i.e. columns in the case of a
>>data.frame. This
>> >>>> explains your errors.
>> >>>>
>> >>>> But it is possible to use a single bracket on a data.frame with 2
>>arguments
>> >>>> (rows, columns) separated by a comma, as with matrices. This is
>>the solution
>> >>>> you received.
>> >>>>
>> >>>> Ivan
>> >>>>
>> >>>>
>> >>>> --
>> >>>> Ivan Calandra, PhD
>> >>>> Scientific Mediator
>> >>>> University of Reims Champagne-Ardenne
>> >>>> GEGENAA - EA 3795
>> >>>> CREA - 2 esplanade Roland Garros
>> >>>> 51100 Reims, France
>> >>>> +33(0)3 26 77 36 89
>> >>>> ivan.calandra at univ-reims.fr
>> >>>> --
>> >>>> https://www.researchgate.net/profile/Ivan_Calandra
>> >>>> https://publons.com/author/705639/
>> >>>>
>> >>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>> >>>>> Dear Georg,
>> >>>>>
>> >>>>> You need to learn a bit more about the subsetting methods,
>>depending on
>> >>>>> the object structure you're trying to subset.
>> >>>>>
>> >>>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>> >>>>> you get this error: "Error in `[.data.frame`(ds_test,
>>is.na(ds_test$var1))
>> >>>>> : undefined columns selected"
>> >>>>>
>> >>>>> This means that R does not understand which column you're trying
>>to
>> >>>>> select. But you're actually trying to select rows.
>> >>>>>
>> >>>>> Using a single bracket '[' on a data.frame does the same as for
>>matrices:
>> >>>>> you need to specify rows and columns, like this:
>> >>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>> >>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns
>>because you
>> >>>>> didn't specify any after the comma
>> >>>>>
>> >>>>> If you want it only for "var1", then you need to specify the
>>column:
>> >>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>> >>>>>
>> >>>>> It's the same problem with your 2nd and 4th tries (4th one has
>>other
>> >>>>> problems). Your 3rd try does not change ds_test at all.
>> >>>>>
>> >>>>> HTH,
>> >>>>> Ivan
>> >>>>>
>> >>>>> --
>> >>>>> Ivan Calandra, PhD
>> >>>>> Scientific Mediator
>> >>>>> University of Reims Champagne-Ardenne
>> >>>>> GEGENAA - EA 3795
>> >>>>> CREA - 2 esplanade Roland Garros
>> >>>>> 51100 Reims, France
>> >>>>> +33(0)3 26 77 36 89
>> >>>>> ivan.calandra at univ-reims.fr
>> >>>>> --
>> >>>>> https://www.researchgate.net/profile/Ivan_Calandra
>> >>>>> https://publons.com/author/705639/
>> >>>>>
>> >>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>> >>>>>> Hi All,
>> >>>>>>
>> >>>>>> I would like to recode my NAs to 0. Using a single vector
>>everything is
>> >>>>>> fine.
>> >>>>>>
>> >>>>>> But if I use a data.frame things go wrong:
>> >>>>>>
>> >>>>>> -- cut --
>> >>>>>>
>> >>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>> >>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>> >>>>>> ds_test <-
>> >>>>>>     data.frame(var1, var2)
>> >>>>>>
>> >>>>>> test <- var1
>> >>>>>> test[is.na(test)] <- 0
>> >>>>>> test  # NA recoded OK
>> >>>>>>
>> >>>>>> # First try
>> >>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>> >>>>>>
>> >>>>>> # Second try
>> >>>>>> ds_test[is.na("var1")] <- 0
>> >>>>>> ds_test$var1  # not recoded WRONG
>> >>>>>>
>> >>>>>> # Third try: to me the most intuitive approach
>> >>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one
>>element in
>> >>>>>> integerOneIndex WRONG
>> >>>>>>
>> >>>>>> # Fourth try
>> >>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns
>>WRONG
>> >>>>>>
>> >>>>>> -- cut --
>> >>>>>>    How can I do it correctly?
>> >>>>>>
>> >>>>>> Where could I have found something about it?
>> >>>>>>
>> >>>>>> Kind regards
>> >>>>>>
>> >>>>>> Georg
>> >>>>>>
>> >>>>>> ______________________________________________
>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>> PLEASE do read the posting guide
>> >>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>> and provide commented, minimal, self-contained, reproducible
>>code.
>> >>>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Jun 24 17:37:05 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Jun 2016 08:37:05 -0700
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
	<trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>
Message-ID: <CAGxFJbSYLi7VwF6+7mdcSOBT9JLHEusBoJRAOsZwr7UJDq_Gkg@mail.gmail.com>

As Petr and Don have shown you, changing NA to 0 is unnecessary to get
what you want. However, recoding to 0 may be OK, as NA has a specific
meaning in this context, and you are just adding an extra code to a
factor for a different level.

But it still might cause you trouble later. One of R's strengths is
it's ability to simply deal with NA's -- most of the time anyway .For
example note that you would have to make sure these columns are
factors (*not numerics*), if you wanted to, say, investigate how
category of closing related to other covariates via e.g. multinomial
logistic regression or even just to tabulate the "closed" categories.
Keeping NA as NA allows R's built-in facilities to simply handle (e.g.
omit) the data for the "still open" cases, but you will have to do it
explicitly yourself if you code to 0. That seems to be asking for
trouble to me.

As always, contrary views welcome. This discussion still seems on
(r-help) topic to me, but if not, please say so.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 24, 2016 at 12:14 AM,  <G.Maubach at gmx.de> wrote:
> Hi Bert,
>
> many thanks for all your help and your comments. I learn at lot this way.
>
> My question was about is.na() at the first sight but the actual task looks like this:
>
> I have two variables in my customer data that signal if the customer accout was closed by master data management or by sales. Say these variables are closed_mdm and closed_sls. They contain NA if the customer account is still open or a closing code from "01" to "08" if the customer account was closed and why.
>
> For my analysis I need a variable that combines the two variables closed_mdm and closed_sls to set a filter easily on those who are closed not matter what the reason was nor who closed the account.
>
> As I always encounter problems when dealing with ifelse statements and NA I decided to merge these two variables to one variable containing 0 = not closed and 1 = closed. In my context this seems to be - at least to me - a reasonable approach.
>
> Replacement of missing values and merging the variables is the easiest way for me.
>
> -- cut --
>
> cust_id <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)
> closed_mdm <- c("01", NA, NA, NA, "08", "07", NA, NA, "05", NA, NA, NA, "04", NA, NA, NA, NA, NA, NA, NA)
> closed_sls <- c(NA, "08", NA, NA, "08", "07", NA, NA, NA, NA, "03", NA, NA, NA, "05", NA, NA, NA, NA, NA)
>
> # 1st try
> ds_temp1 <- data.frame(cust_id, closed_mdm, closed_sls)
> ds_temp1
>
> ds_temp1$closed <- closed_mdm | closed_sls  # WRONG
>
> # 2nd try
> closed_mdm_fac1 <- as.factor(closed_mdm)
> closed_sls_fac1 <- as.factor(closed_sls)
>
> ds_temp2 <- data.frame(cust_id, closed_mdm_fac1, closed_sls_fac1)
> ds_temp2
>
> ds_temp2$closed <- ds_temp$closed_mdm_fac1 | ds_temp$closed_sls_fac1  # WRONG
>
> # 3rd try
> closed_mdm_num1 <- as.numeric(closed_mdm)  # OK
> closed_sls_num1 <- as.numeric(closed_sls)  # OK
>
> ds_temp3 <- data.frame(cust_id, closed_mdm_num1, closed_sls_num1)
> ds_temp3
>
> ds_temp3$closed <- ds_temp$closed_mdm_num1 | ds_temp$closed_sls_num1  # WRONG
>
> # 4th try
> ds_temp4 <- ds_temp3
> ds_temp4
>
> # Does not run due to not allowed NA in subscripts
> ds_temp4[is.na(ds_temp4$closed_mdm_num1), ds_temp4$closed_mdm_num1] <- 0
> ds_temp4[is.na(ds_temp4$closed_sls_num1), ds_temp4$closed_sls_num1] <- 0
>
> # 5th try
> ds_temp4$closed_mdm_num1 <- ifelse(is.na(ds_temp4$closed_mdm_num1), 1, 0)
> ds_temp4$closed_sls_num1 <- ifelse(is.na(ds_temp4$closed_sls_num1), 1, 0)
> ds_temp4
>
> ds_temp4$closed <- ifelse(ds_temp4$closed_mdm_num1 == 1 | ds_temp4$closed_sls_num1 == 1, 1, 0)
> ds_temp4
>
> -- cut --
>
> Is there a better way to do it?
>
> Kind regards
>
> Georg
>
>
>> Gesendet: Donnerstag, 23. Juni 2016 um 23:55 Uhr
>> Von: "Bert Gunter" <bgunter.4567 at gmail.com>
>> An: "David L Carlson" <dcarlson at tamu.edu>
>> Cc: "R Help" <r-help at r-project.org>
>> Betreff: Re: [R] Subscripting problem with is.na()
>>
>> ... actually, FWIW, I would say that this little discussion mostly
>> demonstrates why the OP's request is probably not a good idea in the
>> first place. Usually, NA's should be left as NA's to be dealt with
>> properly by R and packages. In biological measurements, for example,
>> NA's often mean "below the ability to reliably measure." Biologists
>> with whom I've worked over many years often want to convert these to 0
>> or omit the cases, both of which lead to biased estimates and/or
>> underestimates of variability and excess claims of "statistical
>> significance" (for those who belong to this religious persuasion). One
>> should never say never, but I suspect that there are relatively few
>> circumstances where the conversion the OP requested is actually wise.
>>
>> Feel free to ignore/reject such extraneous comments of course.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Jun 23, 2016 at 12:14 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> > Good point. I did not think about factors. Also your example raises another issue since column c is logical, but gets silently converted to numeric. This would seem to get the job done assuming the conversion is intended for numeric columns only:
>> >
>> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>> >> sapply(test, class)
>> >         a         b         c
>> > "numeric"  "factor" "logical"
>> >> num <- sapply(test, is.numeric)
>> >> test[, num][is.na(test[, num])] <- 0
>> >> test
>> >   a    b  c
>> > 1 1    A NA
>> > 2 0    b NA
>> > 3 2 <NA> NA
>> >
>> > David C
>> >
>> > -----Original Message-----
>> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> > Sent: Thursday, June 23, 2016 1:48 PM
>> > To: David L Carlson
>> > Cc: Ivan Calandra; R Help
>> > Subject: Re: [R] Subscripting problem with is.na()
>> >
>> > Not in general, David:
>> >
>> > e.g.
>> >
>> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>> >
>> >> is.na(test)
>> >          a     b    c
>> > [1,] FALSE FALSE TRUE
>> > [2,]  TRUE FALSE TRUE
>> > [3,] FALSE  TRUE TRUE
>> >
>> >> test[is.na(test)]
>> > [1] NA NA NA NA NA
>> >
>> >> test[is.na(test)] <- 0
>> > Warning message:
>> > In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
>> >   invalid factor level, NA generated
>> >
>> >> test
>> >   a    b c
>> > 1 1    A 0
>> > 2 0    b 0
>> > 3 2 <NA> 0
>> >
>> >
>> > The problem is the default conversion to factors and the replacement
>> > operation for factors. So:
>> >
>> >> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c= rep(NA,3))
>> >> class(test$b)
>> > [1] "AsIs"  ## so NOT a factor
>> >
>> >> test[is.na(test)] <- 0 # now works as you describe
>> >> test
>> >   a b c
>> > 1 1 A 0
>> > 2 0 b 0
>> > 3 2 0 0
>> >
>> > Of course the OP (and you) probably had a data frame of all numerics
>> > in mind, so the problem doesn't arise. But I think one needs to make
>> > the distinction and issue clear.
>> >
>> > Cheers,
>> > Bert
>> >
>> >
>> >
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> > and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>> >> The function is.na() returns a matrix when applied to a data.frame so you can easily convert all the NAs to 0's:
>> >>
>> >>> ds_test
>> >>    var1 var2
>> >> 1     1    1
>> >> 2     2    2
>> >> 3     3    3
>> >> 4    NA   NA
>> >> 5     5    5
>> >> 6     6    6
>> >> 7     7    7
>> >> 8    NA   NA
>> >> 9     9    9
>> >> 10   10   10
>> >>> is.na(ds_test)
>> >>        var1  var2
>> >>  [1,] FALSE FALSE
>> >>  [2,] FALSE FALSE
>> >>  [3,] FALSE FALSE
>> >>  [4,]  TRUE  TRUE
>> >>  [5,] FALSE FALSE
>> >>  [6,] FALSE FALSE
>> >>  [7,] FALSE FALSE
>> >>  [8,]  TRUE  TRUE
>> >>  [9,] FALSE FALSE
>> >> [10,] FALSE FALSE
>> >>> ds_test[is.na(ds_test)] <- 0
>> >>> ds_test
>> >>    var1 var2
>> >> 1     1    1
>> >> 2     2    2
>> >> 3     3    3
>> >> 4     0    0
>> >> 5     5    5
>> >> 6     6    6
>> >> 7     7    7
>> >> 8     0    0
>> >> 9     9    9
>> >> 10   10   10
>> >>
>> >> -------------------------------------
>> >> David L Carlson
>> >> Department of Anthropology
>> >> Texas A&M University
>> >> College Station, TX 77840-4352
>> >>
>> >> -----Original Message-----
>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan Calandra
>> >> Sent: Thursday, June 23, 2016 10:14 AM
>> >> To: R Help
>> >> Subject: Re: [R] Subscripting problem with is.na()
>> >>
>> >> Thank you Bert for this clarification. It is indeed an important point.
>> >>
>> >> Ivan
>> >>
>> >> --
>> >> Ivan Calandra, PhD
>> >> Scientific Mediator
>> >> University of Reims Champagne-Ardenne
>> >> GEGENAA - EA 3795
>> >> CREA - 2 esplanade Roland Garros
>> >> 51100 Reims, France
>> >> +33(0)3 26 77 36 89
>> >> ivan.calandra at univ-reims.fr
>> >> --
>> >> https://www.researchgate.net/profile/Ivan_Calandra
>> >> https://publons.com/author/705639/
>> >>
>> >> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
>> >>> Sorry, Ivan, your statement is incorrect:
>> >>>
>> >>> "When you use a single bracket on a list with only one argument in
>> >>> between, then R extracts "elements", i.e. columns in the case of a
>> >>> data.frame. This explains your errors. "
>> >>>
>> >>> e.g.
>> >>>
>> >>>> ex <- data.frame(a = 1:3, b = letters[1:3])
>> >>>> a <- 1:3
>> >>>> identical(ex[1], a)
>> >>> [1] FALSE
>> >>>
>> >>>> class(ex[1])
>> >>> [1] "data.frame"
>> >>>> class(a)
>> >>> [1] "integer"
>> >>>
>> >>> Compare:
>> >>>
>> >>>> identical(ex[[1]], a)
>> >>> [1] TRUE
>> >>>
>> >>> Why? Single bracket extraction on a list results in a list; double
>> >>> bracket extraction results in the element of the list ( a "column" in
>> >>> the case of a data frame, which is a specific kind of list). The
>> >>> relevant sections of ?Extract are:
>> >>>
>> >>> "Indexing by [ is similar to atomic vectors and selects a **list** of
>> >>> the specified element(s).
>> >>>
>> >>> Both [[ and $ select a **single element of the list**. "
>> >>>
>> >>>
>> >>> Hope this clarifies this often-confused issue.
>> >>>
>> >>>
>> >>> Cheers,
>> >>> Bert
>> >>> Bert Gunter
>> >>>
>> >>> "The trouble with having an open mind is that people keep coming along
>> >>> and sticking things into it."
>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>
>> >>>
>> >>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
>> >>> <ivan.calandra at univ-reims.fr> wrote:
>> >>>> My statement "Using a single bracket '[' on a data.frame does the same as
>> >>>> for matrices: you need to specify rows and columns" was not correct.
>> >>>>
>> >>>>
>> >>>> When you use a single bracket on a list with only one argument in between,
>> >>>> then R extracts "elements", i.e. columns in the case of a data.frame. This
>> >>>> explains your errors.
>> >>>>
>> >>>> But it is possible to use a single bracket on a data.frame with 2 arguments
>> >>>> (rows, columns) separated by a comma, as with matrices. This is the solution
>> >>>> you received.
>> >>>>
>> >>>> Ivan
>> >>>>
>> >>>>
>> >>>> --
>> >>>> Ivan Calandra, PhD
>> >>>> Scientific Mediator
>> >>>> University of Reims Champagne-Ardenne
>> >>>> GEGENAA - EA 3795
>> >>>> CREA - 2 esplanade Roland Garros
>> >>>> 51100 Reims, France
>> >>>> +33(0)3 26 77 36 89
>> >>>> ivan.calandra at univ-reims.fr
>> >>>> --
>> >>>> https://www.researchgate.net/profile/Ivan_Calandra
>> >>>> https://publons.com/author/705639/
>> >>>>
>> >>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>> >>>>> Dear Georg,
>> >>>>>
>> >>>>> You need to learn a bit more about the subsetting methods, depending on
>> >>>>> the object structure you're trying to subset.
>> >>>>>
>> >>>>> More specifically, when you run this: ds_test[is.na(ds_test$var1)]
>> >>>>> you get this error: "Error in `[.data.frame`(ds_test, is.na(ds_test$var1))
>> >>>>> : undefined columns selected"
>> >>>>>
>> >>>>> This means that R does not understand which column you're trying to
>> >>>>> select. But you're actually trying to select rows.
>> >>>>>
>> >>>>> Using a single bracket '[' on a data.frame does the same as for matrices:
>> >>>>> you need to specify rows and columns, like this:
>> >>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>> >>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns because you
>> >>>>> didn't specify any after the comma
>> >>>>>
>> >>>>> If you want it only for "var1", then you need to specify the column:
>> >>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>> >>>>>
>> >>>>> It's the same problem with your 2nd and 4th tries (4th one has other
>> >>>>> problems). Your 3rd try does not change ds_test at all.
>> >>>>>
>> >>>>> HTH,
>> >>>>> Ivan
>> >>>>>
>> >>>>> --
>> >>>>> Ivan Calandra, PhD
>> >>>>> Scientific Mediator
>> >>>>> University of Reims Champagne-Ardenne
>> >>>>> GEGENAA - EA 3795
>> >>>>> CREA - 2 esplanade Roland Garros
>> >>>>> 51100 Reims, France
>> >>>>> +33(0)3 26 77 36 89
>> >>>>> ivan.calandra at univ-reims.fr
>> >>>>> --
>> >>>>> https://www.researchgate.net/profile/Ivan_Calandra
>> >>>>> https://publons.com/author/705639/
>> >>>>>
>> >>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>> >>>>>> Hi All,
>> >>>>>>
>> >>>>>> I would like to recode my NAs to 0. Using a single vector everything is
>> >>>>>> fine.
>> >>>>>>
>> >>>>>> But if I use a data.frame things go wrong:
>> >>>>>>
>> >>>>>> -- cut --
>> >>>>>>
>> >>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>> >>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>> >>>>>> ds_test <-
>> >>>>>>     data.frame(var1, var2)
>> >>>>>>
>> >>>>>> test <- var1
>> >>>>>> test[is.na(test)] <- 0
>> >>>>>> test  # NA recoded OK
>> >>>>>>
>> >>>>>> # First try
>> >>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>> >>>>>>
>> >>>>>> # Second try
>> >>>>>> ds_test[is.na("var1")] <- 0
>> >>>>>> ds_test$var1  # not recoded WRONG
>> >>>>>>
>> >>>>>> # Third try: to me the most intuitive approach
>> >>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one element in
>> >>>>>> integerOneIndex WRONG
>> >>>>>>
>> >>>>>> # Fourth try
>> >>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns WRONG
>> >>>>>>
>> >>>>>> -- cut --
>> >>>>>>    How can I do it correctly?
>> >>>>>>
>> >>>>>> Where could I have found something about it?
>> >>>>>>
>> >>>>>> Kind regards
>> >>>>>>
>> >>>>>> Georg
>> >>>>>>
>> >>>>>> ______________________________________________
>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>> PLEASE do read the posting guide
>> >>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Jun 24 17:42:55 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 24 Jun 2016 08:42:55 -0700
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <CAGxFJbSYLi7VwF6+7mdcSOBT9JLHEusBoJRAOsZwr7UJDq_Gkg@mail.gmail.com>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
	<trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>
	<CAGxFJbSYLi7VwF6+7mdcSOBT9JLHEusBoJRAOsZwr7UJDq_Gkg@mail.gmail.com>
Message-ID: <CAF8bMcZ4DzFWtsa0Z1yP_Re3wHCHfn1BZ=opAo8Y8pngPH_nMg@mail.gmail.com>

Is part of the issue that in common parlance "NA" or "N/A" may
mean  either "not available" or "not applicable" (e.g., isPregnant
for a male) but in R NA means only "not available"?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 24, 2016 at 8:37 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> As Petr and Don have shown you, changing NA to 0 is unnecessary to get
> what you want. However, recoding to 0 may be OK, as NA has a specific
> meaning in this context, and you are just adding an extra code to a
> factor for a different level.
>
> But it still might cause you trouble later. One of R's strengths is
> it's ability to simply deal with NA's -- most of the time anyway .For
> example note that you would have to make sure these columns are
> factors (*not numerics*), if you wanted to, say, investigate how
> category of closing related to other covariates via e.g. multinomial
> logistic regression or even just to tabulate the "closed" categories.
> Keeping NA as NA allows R's built-in facilities to simply handle (e.g.
> omit) the data for the "still open" cases, but you will have to do it
> explicitly yourself if you code to 0. That seems to be asking for
> trouble to me.
>
> As always, contrary views welcome. This discussion still seems on
> (r-help) topic to me, but if not, please say so.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jun 24, 2016 at 12:14 AM,  <G.Maubach at gmx.de> wrote:
> > Hi Bert,
> >
> > many thanks for all your help and your comments. I learn at lot this way.
> >
> > My question was about is.na() at the first sight but the actual task
> looks like this:
> >
> > I have two variables in my customer data that signal if the customer
> accout was closed by master data management or by sales. Say these
> variables are closed_mdm and closed_sls. They contain NA if the customer
> account is still open or a closing code from "01" to "08" if the customer
> account was closed and why.
> >
> > For my analysis I need a variable that combines the two variables
> closed_mdm and closed_sls to set a filter easily on those who are closed
> not matter what the reason was nor who closed the account.
> >
> > As I always encounter problems when dealing with ifelse statements and
> NA I decided to merge these two variables to one variable containing 0 =
> not closed and 1 = closed. In my context this seems to be - at least to me
> - a reasonable approach.
> >
> > Replacement of missing values and merging the variables is the easiest
> way for me.
> >
> > -- cut --
> >
> > cust_id <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,
> 18, 19, 20)
> > closed_mdm <- c("01", NA, NA, NA, "08", "07", NA, NA, "05", NA, NA, NA,
> "04", NA, NA, NA, NA, NA, NA, NA)
> > closed_sls <- c(NA, "08", NA, NA, "08", "07", NA, NA, NA, NA, "03", NA,
> NA, NA, "05", NA, NA, NA, NA, NA)
> >
> > # 1st try
> > ds_temp1 <- data.frame(cust_id, closed_mdm, closed_sls)
> > ds_temp1
> >
> > ds_temp1$closed <- closed_mdm | closed_sls  # WRONG
> >
> > # 2nd try
> > closed_mdm_fac1 <- as.factor(closed_mdm)
> > closed_sls_fac1 <- as.factor(closed_sls)
> >
> > ds_temp2 <- data.frame(cust_id, closed_mdm_fac1, closed_sls_fac1)
> > ds_temp2
> >
> > ds_temp2$closed <- ds_temp$closed_mdm_fac1 | ds_temp$closed_sls_fac1  #
> WRONG
> >
> > # 3rd try
> > closed_mdm_num1 <- as.numeric(closed_mdm)  # OK
> > closed_sls_num1 <- as.numeric(closed_sls)  # OK
> >
> > ds_temp3 <- data.frame(cust_id, closed_mdm_num1, closed_sls_num1)
> > ds_temp3
> >
> > ds_temp3$closed <- ds_temp$closed_mdm_num1 | ds_temp$closed_sls_num1  #
> WRONG
> >
> > # 4th try
> > ds_temp4 <- ds_temp3
> > ds_temp4
> >
> > # Does not run due to not allowed NA in subscripts
> > ds_temp4[is.na(ds_temp4$closed_mdm_num1), ds_temp4$closed_mdm_num1] <- 0
> > ds_temp4[is.na(ds_temp4$closed_sls_num1), ds_temp4$closed_sls_num1] <- 0
> >
> > # 5th try
> > ds_temp4$closed_mdm_num1 <- ifelse(is.na(ds_temp4$closed_mdm_num1), 1,
> 0)
> > ds_temp4$closed_sls_num1 <- ifelse(is.na(ds_temp4$closed_sls_num1), 1,
> 0)
> > ds_temp4
> >
> > ds_temp4$closed <- ifelse(ds_temp4$closed_mdm_num1 == 1 |
> ds_temp4$closed_sls_num1 == 1, 1, 0)
> > ds_temp4
> >
> > -- cut --
> >
> > Is there a better way to do it?
> >
> > Kind regards
> >
> > Georg
> >
> >
> >> Gesendet: Donnerstag, 23. Juni 2016 um 23:55 Uhr
> >> Von: "Bert Gunter" <bgunter.4567 at gmail.com>
> >> An: "David L Carlson" <dcarlson at tamu.edu>
> >> Cc: "R Help" <r-help at r-project.org>
> >> Betreff: Re: [R] Subscripting problem with is.na()
> >>
> >> ... actually, FWIW, I would say that this little discussion mostly
> >> demonstrates why the OP's request is probably not a good idea in the
> >> first place. Usually, NA's should be left as NA's to be dealt with
> >> properly by R and packages. In biological measurements, for example,
> >> NA's often mean "below the ability to reliably measure." Biologists
> >> with whom I've worked over many years often want to convert these to 0
> >> or omit the cases, both of which lead to biased estimates and/or
> >> underestimates of variability and excess claims of "statistical
> >> significance" (for those who belong to this religious persuasion). One
> >> should never say never, but I suspect that there are relatively few
> >> circumstances where the conversion the OP requested is actually wise.
> >>
> >> Feel free to ignore/reject such extraneous comments of course.
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Thu, Jun 23, 2016 at 12:14 PM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> >> > Good point. I did not think about factors. Also your example raises
> another issue since column c is logical, but gets silently converted to
> numeric. This would seem to get the job done assuming the conversion is
> intended for numeric columns only:
> >> >
> >> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> >> >> sapply(test, class)
> >> >         a         b         c
> >> > "numeric"  "factor" "logical"
> >> >> num <- sapply(test, is.numeric)
> >> >> test[, num][is.na(test[, num])] <- 0
> >> >> test
> >> >   a    b  c
> >> > 1 1    A NA
> >> > 2 0    b NA
> >> > 3 2 <NA> NA
> >> >
> >> > David C
> >> >
> >> > -----Original Message-----
> >> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> >> > Sent: Thursday, June 23, 2016 1:48 PM
> >> > To: David L Carlson
> >> > Cc: Ivan Calandra; R Help
> >> > Subject: Re: [R] Subscripting problem with is.na()
> >> >
> >> > Not in general, David:
> >> >
> >> > e.g.
> >> >
> >> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> >> >
> >> >> is.na(test)
> >> >          a     b    c
> >> > [1,] FALSE FALSE TRUE
> >> > [2,]  TRUE FALSE TRUE
> >> > [3,] FALSE  TRUE TRUE
> >> >
> >> >> test[is.na(test)]
> >> > [1] NA NA NA NA NA
> >> >
> >> >> test[is.na(test)] <- 0
> >> > Warning message:
> >> > In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
> >> >   invalid factor level, NA generated
> >> >
> >> >> test
> >> >   a    b c
> >> > 1 1    A 0
> >> > 2 0    b 0
> >> > 3 2 <NA> 0
> >> >
> >> >
> >> > The problem is the default conversion to factors and the replacement
> >> > operation for factors. So:
> >> >
> >> >> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c=
> rep(NA,3))
> >> >> class(test$b)
> >> > [1] "AsIs"  ## so NOT a factor
> >> >
> >> >> test[is.na(test)] <- 0 # now works as you describe
> >> >> test
> >> >   a b c
> >> > 1 1 A 0
> >> > 2 0 b 0
> >> > 3 2 0 0
> >> >
> >> > Of course the OP (and you) probably had a data frame of all numerics
> >> > in mind, so the problem doesn't arise. But I think one needs to make
> >> > the distinction and issue clear.
> >> >
> >> > Cheers,
> >> > Bert
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > Bert Gunter
> >> >
> >> > "The trouble with having an open mind is that people keep coming along
> >> > and sticking things into it."
> >> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >
> >> >
> >> > On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> >> >> The function is.na() returns a matrix when applied to a data.frame
> so you can easily convert all the NAs to 0's:
> >> >>
> >> >>> ds_test
> >> >>    var1 var2
> >> >> 1     1    1
> >> >> 2     2    2
> >> >> 3     3    3
> >> >> 4    NA   NA
> >> >> 5     5    5
> >> >> 6     6    6
> >> >> 7     7    7
> >> >> 8    NA   NA
> >> >> 9     9    9
> >> >> 10   10   10
> >> >>> is.na(ds_test)
> >> >>        var1  var2
> >> >>  [1,] FALSE FALSE
> >> >>  [2,] FALSE FALSE
> >> >>  [3,] FALSE FALSE
> >> >>  [4,]  TRUE  TRUE
> >> >>  [5,] FALSE FALSE
> >> >>  [6,] FALSE FALSE
> >> >>  [7,] FALSE FALSE
> >> >>  [8,]  TRUE  TRUE
> >> >>  [9,] FALSE FALSE
> >> >> [10,] FALSE FALSE
> >> >>> ds_test[is.na(ds_test)] <- 0
> >> >>> ds_test
> >> >>    var1 var2
> >> >> 1     1    1
> >> >> 2     2    2
> >> >> 3     3    3
> >> >> 4     0    0
> >> >> 5     5    5
> >> >> 6     6    6
> >> >> 7     7    7
> >> >> 8     0    0
> >> >> 9     9    9
> >> >> 10   10   10
> >> >>
> >> >> -------------------------------------
> >> >> David L Carlson
> >> >> Department of Anthropology
> >> >> Texas A&M University
> >> >> College Station, TX 77840-4352
> >> >>
> >> >> -----Original Message-----
> >> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Ivan Calandra
> >> >> Sent: Thursday, June 23, 2016 10:14 AM
> >> >> To: R Help
> >> >> Subject: Re: [R] Subscripting problem with is.na()
> >> >>
> >> >> Thank you Bert for this clarification. It is indeed an important
> point.
> >> >>
> >> >> Ivan
> >> >>
> >> >> --
> >> >> Ivan Calandra, PhD
> >> >> Scientific Mediator
> >> >> University of Reims Champagne-Ardenne
> >> >> GEGENAA - EA 3795
> >> >> CREA - 2 esplanade Roland Garros
> >> >> 51100 Reims, France
> >> >> +33(0)3 26 77 36 89
> >> >> ivan.calandra at univ-reims.fr
> >> >> --
> >> >> https://www.researchgate.net/profile/Ivan_Calandra
> >> >> https://publons.com/author/705639/
> >> >>
> >> >> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
> >> >>> Sorry, Ivan, your statement is incorrect:
> >> >>>
> >> >>> "When you use a single bracket on a list with only one argument in
> >> >>> between, then R extracts "elements", i.e. columns in the case of a
> >> >>> data.frame. This explains your errors. "
> >> >>>
> >> >>> e.g.
> >> >>>
> >> >>>> ex <- data.frame(a = 1:3, b = letters[1:3])
> >> >>>> a <- 1:3
> >> >>>> identical(ex[1], a)
> >> >>> [1] FALSE
> >> >>>
> >> >>>> class(ex[1])
> >> >>> [1] "data.frame"
> >> >>>> class(a)
> >> >>> [1] "integer"
> >> >>>
> >> >>> Compare:
> >> >>>
> >> >>>> identical(ex[[1]], a)
> >> >>> [1] TRUE
> >> >>>
> >> >>> Why? Single bracket extraction on a list results in a list; double
> >> >>> bracket extraction results in the element of the list ( a "column"
> in
> >> >>> the case of a data frame, which is a specific kind of list). The
> >> >>> relevant sections of ?Extract are:
> >> >>>
> >> >>> "Indexing by [ is similar to atomic vectors and selects a **list**
> of
> >> >>> the specified element(s).
> >> >>>
> >> >>> Both [[ and $ select a **single element of the list**. "
> >> >>>
> >> >>>
> >> >>> Hope this clarifies this often-confused issue.
> >> >>>
> >> >>>
> >> >>> Cheers,
> >> >>> Bert
> >> >>> Bert Gunter
> >> >>>
> >> >>> "The trouble with having an open mind is that people keep coming
> along
> >> >>> and sticking things into it."
> >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >>>
> >> >>>
> >> >>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
> >> >>> <ivan.calandra at univ-reims.fr> wrote:
> >> >>>> My statement "Using a single bracket '[' on a data.frame does the
> same as
> >> >>>> for matrices: you need to specify rows and columns" was not
> correct.
> >> >>>>
> >> >>>>
> >> >>>> When you use a single bracket on a list with only one argument in
> between,
> >> >>>> then R extracts "elements", i.e. columns in the case of a
> data.frame. This
> >> >>>> explains your errors.
> >> >>>>
> >> >>>> But it is possible to use a single bracket on a data.frame with 2
> arguments
> >> >>>> (rows, columns) separated by a comma, as with matrices. This is
> the solution
> >> >>>> you received.
> >> >>>>
> >> >>>> Ivan
> >> >>>>
> >> >>>>
> >> >>>> --
> >> >>>> Ivan Calandra, PhD
> >> >>>> Scientific Mediator
> >> >>>> University of Reims Champagne-Ardenne
> >> >>>> GEGENAA - EA 3795
> >> >>>> CREA - 2 esplanade Roland Garros
> >> >>>> 51100 Reims, France
> >> >>>> +33(0)3 26 77 36 89
> >> >>>> ivan.calandra at univ-reims.fr
> >> >>>> --
> >> >>>> https://www.researchgate.net/profile/Ivan_Calandra
> >> >>>> https://publons.com/author/705639/
> >> >>>>
> >> >>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
> >> >>>>> Dear Georg,
> >> >>>>>
> >> >>>>> You need to learn a bit more about the subsetting methods,
> depending on
> >> >>>>> the object structure you're trying to subset.
> >> >>>>>
> >> >>>>> More specifically, when you run this: ds_test[is.na
> (ds_test$var1)]
> >> >>>>> you get this error: "Error in `[.data.frame`(ds_test, is.na
> (ds_test$var1))
> >> >>>>> : undefined columns selected"
> >> >>>>>
> >> >>>>> This means that R does not understand which column you're trying
> to
> >> >>>>> select. But you're actually trying to select rows.
> >> >>>>>
> >> >>>>> Using a single bracket '[' on a data.frame does the same as for
> matrices:
> >> >>>>> you need to specify rows and columns, like this:
> >> >>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
> >> >>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns
> because you
> >> >>>>> didn't specify any after the comma
> >> >>>>>
> >> >>>>> If you want it only for "var1", then you need to specify the
> column:
> >> >>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
> >> >>>>>
> >> >>>>> It's the same problem with your 2nd and 4th tries (4th one has
> other
> >> >>>>> problems). Your 3rd try does not change ds_test at all.
> >> >>>>>
> >> >>>>> HTH,
> >> >>>>> Ivan
> >> >>>>>
> >> >>>>> --
> >> >>>>> Ivan Calandra, PhD
> >> >>>>> Scientific Mediator
> >> >>>>> University of Reims Champagne-Ardenne
> >> >>>>> GEGENAA - EA 3795
> >> >>>>> CREA - 2 esplanade Roland Garros
> >> >>>>> 51100 Reims, France
> >> >>>>> +33(0)3 26 77 36 89
> >> >>>>> ivan.calandra at univ-reims.fr
> >> >>>>> --
> >> >>>>> https://www.researchgate.net/profile/Ivan_Calandra
> >> >>>>> https://publons.com/author/705639/
> >> >>>>>
> >> >>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
> >> >>>>>> Hi All,
> >> >>>>>>
> >> >>>>>> I would like to recode my NAs to 0. Using a single vector
> everything is
> >> >>>>>> fine.
> >> >>>>>>
> >> >>>>>> But if I use a data.frame things go wrong:
> >> >>>>>>
> >> >>>>>> -- cut --
> >> >>>>>>
> >> >>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
> >> >>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
> >> >>>>>> ds_test <-
> >> >>>>>>     data.frame(var1, var2)
> >> >>>>>>
> >> >>>>>> test <- var1
> >> >>>>>> test[is.na(test)] <- 0
> >> >>>>>> test  # NA recoded OK
> >> >>>>>>
> >> >>>>>> # First try
> >> >>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
> >> >>>>>>
> >> >>>>>> # Second try
> >> >>>>>> ds_test[is.na("var1")] <- 0
> >> >>>>>> ds_test$var1  # not recoded WRONG
> >> >>>>>>
> >> >>>>>> # Third try: to me the most intuitive approach
> >> >>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one
> element in
> >> >>>>>> integerOneIndex WRONG
> >> >>>>>>
> >> >>>>>> # Fourth try
> >> >>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns
> WRONG
> >> >>>>>>
> >> >>>>>> -- cut --
> >> >>>>>>    How can I do it correctly?
> >> >>>>>>
> >> >>>>>> Where could I have found something about it?
> >> >>>>>>
> >> >>>>>> Kind regards
> >> >>>>>>
> >> >>>>>> Georg
> >> >>>>>>
> >> >>>>>> ______________________________________________
> >> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>>> PLEASE do read the posting guide
> >> >>>>>> http://www.R-project.org/posting-guide.html
> >> >>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >> >>>>>>
> >> >>>>> ______________________________________________
> >> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>> PLEASE do read the posting guide
> >> >>>>> http://www.R-project.org/posting-guide.html
> >> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >> >>>>>
> >> >>>> ______________________________________________
> >> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> >>>> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun 24 17:58:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Jun 2016 08:58:54 -0700
Subject: [R] Subscripting problem with is.na()
In-Reply-To: <CAF8bMcZ4DzFWtsa0Z1yP_Re3wHCHfn1BZ=opAo8Y8pngPH_nMg@mail.gmail.com>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbT6GLTKG5NgNVdxOSNAx=P2Hh3XO2T_j7XM_-H5RYLEdg@mail.gmail.com>
	<trinity-92d10cf2-21e2-4401-9ff7-b02b9d6e394c-1466752474925@3capp-gmx-bs20>
	<CAGxFJbSYLi7VwF6+7mdcSOBT9JLHEusBoJRAOsZwr7UJDq_Gkg@mail.gmail.com>
	<CAF8bMcZ4DzFWtsa0Z1yP_Re3wHCHfn1BZ=opAo8Y8pngPH_nMg@mail.gmail.com>
Message-ID: <CAGxFJbTE8zE+-bUUoD8=nveqPhXJ2=Tx0jKao_oStqE06o_hgQ@mail.gmail.com>

I would tend to agree. But NA is still preferable for both, no?

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 24, 2016 at 8:42 AM, William Dunlap <wdunlap at tibco.com> wrote:
> Is part of the issue that in common parlance "NA" or "N/A" may
> mean  either "not available" or "not applicable" (e.g., isPregnant
> for a male) but in R NA means only "not available"?
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Jun 24, 2016 at 8:37 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> As Petr and Don have shown you, changing NA to 0 is unnecessary to get
>> what you want. However, recoding to 0 may be OK, as NA has a specific
>> meaning in this context, and you are just adding an extra code to a
>> factor for a different level.
>>
>> But it still might cause you trouble later. One of R's strengths is
>> it's ability to simply deal with NA's -- most of the time anyway .For
>> example note that you would have to make sure these columns are
>> factors (*not numerics*), if you wanted to, say, investigate how
>> category of closing related to other covariates via e.g. multinomial
>> logistic regression or even just to tabulate the "closed" categories.
>> Keeping NA as NA allows R's built-in facilities to simply handle (e.g.
>> omit) the data for the "still open" cases, but you will have to do it
>> explicitly yourself if you code to 0. That seems to be asking for
>> trouble to me.
>>
>> As always, contrary views welcome. This discussion still seems on
>> (r-help) topic to me, but if not, please say so.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Jun 24, 2016 at 12:14 AM,  <G.Maubach at gmx.de> wrote:
>> > Hi Bert,
>> >
>> > many thanks for all your help and your comments. I learn at lot this
>> > way.
>> >
>> > My question was about is.na() at the first sight but the actual task
>> > looks like this:
>> >
>> > I have two variables in my customer data that signal if the customer
>> > accout was closed by master data management or by sales. Say these variables
>> > are closed_mdm and closed_sls. They contain NA if the customer account is
>> > still open or a closing code from "01" to "08" if the customer account was
>> > closed and why.
>> >
>> > For my analysis I need a variable that combines the two variables
>> > closed_mdm and closed_sls to set a filter easily on those who are closed not
>> > matter what the reason was nor who closed the account.
>> >
>> > As I always encounter problems when dealing with ifelse statements and
>> > NA I decided to merge these two variables to one variable containing 0 = not
>> > closed and 1 = closed. In my context this seems to be - at least to me - a
>> > reasonable approach.
>> >
>> > Replacement of missing values and merging the variables is the easiest
>> > way for me.
>> >
>> > -- cut --
>> >
>> > cust_id <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,
>> > 18, 19, 20)
>> > closed_mdm <- c("01", NA, NA, NA, "08", "07", NA, NA, "05", NA, NA, NA,
>> > "04", NA, NA, NA, NA, NA, NA, NA)
>> > closed_sls <- c(NA, "08", NA, NA, "08", "07", NA, NA, NA, NA, "03", NA,
>> > NA, NA, "05", NA, NA, NA, NA, NA)
>> >
>> > # 1st try
>> > ds_temp1 <- data.frame(cust_id, closed_mdm, closed_sls)
>> > ds_temp1
>> >
>> > ds_temp1$closed <- closed_mdm | closed_sls  # WRONG
>> >
>> > # 2nd try
>> > closed_mdm_fac1 <- as.factor(closed_mdm)
>> > closed_sls_fac1 <- as.factor(closed_sls)
>> >
>> > ds_temp2 <- data.frame(cust_id, closed_mdm_fac1, closed_sls_fac1)
>> > ds_temp2
>> >
>> > ds_temp2$closed <- ds_temp$closed_mdm_fac1 | ds_temp$closed_sls_fac1  #
>> > WRONG
>> >
>> > # 3rd try
>> > closed_mdm_num1 <- as.numeric(closed_mdm)  # OK
>> > closed_sls_num1 <- as.numeric(closed_sls)  # OK
>> >
>> > ds_temp3 <- data.frame(cust_id, closed_mdm_num1, closed_sls_num1)
>> > ds_temp3
>> >
>> > ds_temp3$closed <- ds_temp$closed_mdm_num1 | ds_temp$closed_sls_num1  #
>> > WRONG
>> >
>> > # 4th try
>> > ds_temp4 <- ds_temp3
>> > ds_temp4
>> >
>> > # Does not run due to not allowed NA in subscripts
>> > ds_temp4[is.na(ds_temp4$closed_mdm_num1), ds_temp4$closed_mdm_num1] <- 0
>> > ds_temp4[is.na(ds_temp4$closed_sls_num1), ds_temp4$closed_sls_num1] <- 0
>> >
>> > # 5th try
>> > ds_temp4$closed_mdm_num1 <- ifelse(is.na(ds_temp4$closed_mdm_num1), 1,
>> > 0)
>> > ds_temp4$closed_sls_num1 <- ifelse(is.na(ds_temp4$closed_sls_num1), 1,
>> > 0)
>> > ds_temp4
>> >
>> > ds_temp4$closed <- ifelse(ds_temp4$closed_mdm_num1 == 1 |
>> > ds_temp4$closed_sls_num1 == 1, 1, 0)
>> > ds_temp4
>> >
>> > -- cut --
>> >
>> > Is there a better way to do it?
>> >
>> > Kind regards
>> >
>> > Georg
>> >
>> >
>> >> Gesendet: Donnerstag, 23. Juni 2016 um 23:55 Uhr
>> >> Von: "Bert Gunter" <bgunter.4567 at gmail.com>
>> >> An: "David L Carlson" <dcarlson at tamu.edu>
>> >> Cc: "R Help" <r-help at r-project.org>
>> >> Betreff: Re: [R] Subscripting problem with is.na()
>> >>
>> >> ... actually, FWIW, I would say that this little discussion mostly
>> >> demonstrates why the OP's request is probably not a good idea in the
>> >> first place. Usually, NA's should be left as NA's to be dealt with
>> >> properly by R and packages. In biological measurements, for example,
>> >> NA's often mean "below the ability to reliably measure." Biologists
>> >> with whom I've worked over many years often want to convert these to 0
>> >> or omit the cases, both of which lead to biased estimates and/or
>> >> underestimates of variability and excess claims of "statistical
>> >> significance" (for those who belong to this religious persuasion). One
>> >> should never say never, but I suspect that there are relatively few
>> >> circumstances where the conversion the OP requested is actually wise.
>> >>
>> >> Feel free to ignore/reject such extraneous comments of course.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along
>> >> and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Thu, Jun 23, 2016 at 12:14 PM, David L Carlson <dcarlson at tamu.edu>
>> >> wrote:
>> >> > Good point. I did not think about factors. Also your example raises
>> >> > another issue since column c is logical, but gets silently converted to
>> >> > numeric. This would seem to get the job done assuming the conversion is
>> >> > intended for numeric columns only:
>> >> >
>> >> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>> >> >> sapply(test, class)
>> >> >         a         b         c
>> >> > "numeric"  "factor" "logical"
>> >> >> num <- sapply(test, is.numeric)
>> >> >> test[, num][is.na(test[, num])] <- 0
>> >> >> test
>> >> >   a    b  c
>> >> > 1 1    A NA
>> >> > 2 0    b NA
>> >> > 3 2 <NA> NA
>> >> >
>> >> > David C
>> >> >
>> >> > -----Original Message-----
>> >> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> >> > Sent: Thursday, June 23, 2016 1:48 PM
>> >> > To: David L Carlson
>> >> > Cc: Ivan Calandra; R Help
>> >> > Subject: Re: [R] Subscripting problem with is.na()
>> >> >
>> >> > Not in general, David:
>> >> >
>> >> > e.g.
>> >> >
>> >> >> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>> >> >
>> >> >> is.na(test)
>> >> >          a     b    c
>> >> > [1,] FALSE FALSE TRUE
>> >> > [2,]  TRUE FALSE TRUE
>> >> > [3,] FALSE  TRUE TRUE
>> >> >
>> >> >> test[is.na(test)]
>> >> > [1] NA NA NA NA NA
>> >> >
>> >> >> test[is.na(test)] <- 0
>> >> > Warning message:
>> >> > In `[<-.factor`(`*tmp*`, thisvar, value = 0) :
>> >> >   invalid factor level, NA generated
>> >> >
>> >> >> test
>> >> >   a    b c
>> >> > 1 1    A 0
>> >> > 2 0    b 0
>> >> > 3 2 <NA> 0
>> >> >
>> >> >
>> >> > The problem is the default conversion to factors and the replacement
>> >> > operation for factors. So:
>> >> >
>> >> >> test <- data.frame(a=c(1,NA,2), b = I(c("A","b",NA_character_)), c=
>> >> >> rep(NA,3))
>> >> >> class(test$b)
>> >> > [1] "AsIs"  ## so NOT a factor
>> >> >
>> >> >> test[is.na(test)] <- 0 # now works as you describe
>> >> >> test
>> >> >   a b c
>> >> > 1 1 A 0
>> >> > 2 0 b 0
>> >> > 3 2 0 0
>> >> >
>> >> > Of course the OP (and you) probably had a data frame of all numerics
>> >> > in mind, so the problem doesn't arise. But I think one needs to make
>> >> > the distinction and issue clear.
>> >> >
>> >> > Cheers,
>> >> > Bert
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > Bert Gunter
>> >> >
>> >> > "The trouble with having an open mind is that people keep coming
>> >> > along
>> >> > and sticking things into it."
>> >> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >> >
>> >> >
>> >> > On Thu, Jun 23, 2016 at 8:46 AM, David L Carlson <dcarlson at tamu.edu>
>> >> > wrote:
>> >> >> The function is.na() returns a matrix when applied to a data.frame
>> >> >> so you can easily convert all the NAs to 0's:
>> >> >>
>> >> >>> ds_test
>> >> >>    var1 var2
>> >> >> 1     1    1
>> >> >> 2     2    2
>> >> >> 3     3    3
>> >> >> 4    NA   NA
>> >> >> 5     5    5
>> >> >> 6     6    6
>> >> >> 7     7    7
>> >> >> 8    NA   NA
>> >> >> 9     9    9
>> >> >> 10   10   10
>> >> >>> is.na(ds_test)
>> >> >>        var1  var2
>> >> >>  [1,] FALSE FALSE
>> >> >>  [2,] FALSE FALSE
>> >> >>  [3,] FALSE FALSE
>> >> >>  [4,]  TRUE  TRUE
>> >> >>  [5,] FALSE FALSE
>> >> >>  [6,] FALSE FALSE
>> >> >>  [7,] FALSE FALSE
>> >> >>  [8,]  TRUE  TRUE
>> >> >>  [9,] FALSE FALSE
>> >> >> [10,] FALSE FALSE
>> >> >>> ds_test[is.na(ds_test)] <- 0
>> >> >>> ds_test
>> >> >>    var1 var2
>> >> >> 1     1    1
>> >> >> 2     2    2
>> >> >> 3     3    3
>> >> >> 4     0    0
>> >> >> 5     5    5
>> >> >> 6     6    6
>> >> >> 7     7    7
>> >> >> 8     0    0
>> >> >> 9     9    9
>> >> >> 10   10   10
>> >> >>
>> >> >> -------------------------------------
>> >> >> David L Carlson
>> >> >> Department of Anthropology
>> >> >> Texas A&M University
>> >> >> College Station, TX 77840-4352
>> >> >>
>> >> >> -----Original Message-----
>> >> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ivan
>> >> >> Calandra
>> >> >> Sent: Thursday, June 23, 2016 10:14 AM
>> >> >> To: R Help
>> >> >> Subject: Re: [R] Subscripting problem with is.na()
>> >> >>
>> >> >> Thank you Bert for this clarification. It is indeed an important
>> >> >> point.
>> >> >>
>> >> >> Ivan
>> >> >>
>> >> >> --
>> >> >> Ivan Calandra, PhD
>> >> >> Scientific Mediator
>> >> >> University of Reims Champagne-Ardenne
>> >> >> GEGENAA - EA 3795
>> >> >> CREA - 2 esplanade Roland Garros
>> >> >> 51100 Reims, France
>> >> >> +33(0)3 26 77 36 89
>> >> >> ivan.calandra at univ-reims.fr
>> >> >> --
>> >> >> https://www.researchgate.net/profile/Ivan_Calandra
>> >> >> https://publons.com/author/705639/
>> >> >>
>> >> >> Le 23/06/2016 ? 17:06, Bert Gunter a ?crit :
>> >> >>> Sorry, Ivan, your statement is incorrect:
>> >> >>>
>> >> >>> "When you use a single bracket on a list with only one argument in
>> >> >>> between, then R extracts "elements", i.e. columns in the case of a
>> >> >>> data.frame. This explains your errors. "
>> >> >>>
>> >> >>> e.g.
>> >> >>>
>> >> >>>> ex <- data.frame(a = 1:3, b = letters[1:3])
>> >> >>>> a <- 1:3
>> >> >>>> identical(ex[1], a)
>> >> >>> [1] FALSE
>> >> >>>
>> >> >>>> class(ex[1])
>> >> >>> [1] "data.frame"
>> >> >>>> class(a)
>> >> >>> [1] "integer"
>> >> >>>
>> >> >>> Compare:
>> >> >>>
>> >> >>>> identical(ex[[1]], a)
>> >> >>> [1] TRUE
>> >> >>>
>> >> >>> Why? Single bracket extraction on a list results in a list; double
>> >> >>> bracket extraction results in the element of the list ( a "column"
>> >> >>> in
>> >> >>> the case of a data frame, which is a specific kind of list). The
>> >> >>> relevant sections of ?Extract are:
>> >> >>>
>> >> >>> "Indexing by [ is similar to atomic vectors and selects a **list**
>> >> >>> of
>> >> >>> the specified element(s).
>> >> >>>
>> >> >>> Both [[ and $ select a **single element of the list**. "
>> >> >>>
>> >> >>>
>> >> >>> Hope this clarifies this often-confused issue.
>> >> >>>
>> >> >>>
>> >> >>> Cheers,
>> >> >>> Bert
>> >> >>> Bert Gunter
>> >> >>>
>> >> >>> "The trouble with having an open mind is that people keep coming
>> >> >>> along
>> >> >>> and sticking things into it."
>> >> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >> >>>
>> >> >>>
>> >> >>> On Thu, Jun 23, 2016 at 7:34 AM, Ivan Calandra
>> >> >>> <ivan.calandra at univ-reims.fr> wrote:
>> >> >>>> My statement "Using a single bracket '[' on a data.frame does the
>> >> >>>> same as
>> >> >>>> for matrices: you need to specify rows and columns" was not
>> >> >>>> correct.
>> >> >>>>
>> >> >>>>
>> >> >>>> When you use a single bracket on a list with only one argument in
>> >> >>>> between,
>> >> >>>> then R extracts "elements", i.e. columns in the case of a
>> >> >>>> data.frame. This
>> >> >>>> explains your errors.
>> >> >>>>
>> >> >>>> But it is possible to use a single bracket on a data.frame with 2
>> >> >>>> arguments
>> >> >>>> (rows, columns) separated by a comma, as with matrices. This is
>> >> >>>> the solution
>> >> >>>> you received.
>> >> >>>>
>> >> >>>> Ivan
>> >> >>>>
>> >> >>>>
>> >> >>>> --
>> >> >>>> Ivan Calandra, PhD
>> >> >>>> Scientific Mediator
>> >> >>>> University of Reims Champagne-Ardenne
>> >> >>>> GEGENAA - EA 3795
>> >> >>>> CREA - 2 esplanade Roland Garros
>> >> >>>> 51100 Reims, France
>> >> >>>> +33(0)3 26 77 36 89
>> >> >>>> ivan.calandra at univ-reims.fr
>> >> >>>> --
>> >> >>>> https://www.researchgate.net/profile/Ivan_Calandra
>> >> >>>> https://publons.com/author/705639/
>> >> >>>>
>> >> >>>> Le 23/06/2016 ? 16:27, Ivan Calandra a ?crit :
>> >> >>>>> Dear Georg,
>> >> >>>>>
>> >> >>>>> You need to learn a bit more about the subsetting methods,
>> >> >>>>> depending on
>> >> >>>>> the object structure you're trying to subset.
>> >> >>>>>
>> >> >>>>> More specifically, when you run this:
>> >> >>>>> ds_test[is.na(ds_test$var1)]
>> >> >>>>> you get this error: "Error in `[.data.frame`(ds_test,
>> >> >>>>> is.na(ds_test$var1))
>> >> >>>>> : undefined columns selected"
>> >> >>>>>
>> >> >>>>> This means that R does not understand which column you're trying
>> >> >>>>> to
>> >> >>>>> select. But you're actually trying to select rows.
>> >> >>>>>
>> >> >>>>> Using a single bracket '[' on a data.frame does the same as for
>> >> >>>>> matrices:
>> >> >>>>> you need to specify rows and columns, like this:
>> >> >>>>> ds_test[is.na(ds_test$var1), ] ## notice the last comma
>> >> >>>>> ds_test[is.na(ds_test$var1), ] <- 0 ## works on all columns
>> >> >>>>> because you
>> >> >>>>> didn't specify any after the comma
>> >> >>>>>
>> >> >>>>> If you want it only for "var1", then you need to specify the
>> >> >>>>> column:
>> >> >>>>> ds_test[is.na(ds_test$var1), "var1"] <- 0
>> >> >>>>>
>> >> >>>>> It's the same problem with your 2nd and 4th tries (4th one has
>> >> >>>>> other
>> >> >>>>> problems). Your 3rd try does not change ds_test at all.
>> >> >>>>>
>> >> >>>>> HTH,
>> >> >>>>> Ivan
>> >> >>>>>
>> >> >>>>> --
>> >> >>>>> Ivan Calandra, PhD
>> >> >>>>> Scientific Mediator
>> >> >>>>> University of Reims Champagne-Ardenne
>> >> >>>>> GEGENAA - EA 3795
>> >> >>>>> CREA - 2 esplanade Roland Garros
>> >> >>>>> 51100 Reims, France
>> >> >>>>> +33(0)3 26 77 36 89
>> >> >>>>> ivan.calandra at univ-reims.fr
>> >> >>>>> --
>> >> >>>>> https://www.researchgate.net/profile/Ivan_Calandra
>> >> >>>>> https://publons.com/author/705639/
>> >> >>>>>
>> >> >>>>> Le 23/06/2016 ? 15:57, G.Maubach at weinwolf.de a ?crit :
>> >> >>>>>> Hi All,
>> >> >>>>>>
>> >> >>>>>> I would like to recode my NAs to 0. Using a single vector
>> >> >>>>>> everything is
>> >> >>>>>> fine.
>> >> >>>>>>
>> >> >>>>>> But if I use a data.frame things go wrong:
>> >> >>>>>>
>> >> >>>>>> -- cut --
>> >> >>>>>>
>> >> >>>>>> var1 <- c(1:3, NA, 5:7, NA, 9:10)
>> >> >>>>>> var2 <- c(1:3, NA, 5:7, NA, 9:10)
>> >> >>>>>> ds_test <-
>> >> >>>>>>     data.frame(var1, var2)
>> >> >>>>>>
>> >> >>>>>> test <- var1
>> >> >>>>>> test[is.na(test)] <- 0
>> >> >>>>>> test  # NA recoded OK
>> >> >>>>>>
>> >> >>>>>> # First try
>> >> >>>>>> ds_test[is.na(ds_test$var1)] <- 0  # duplicate subscripts WRONG
>> >> >>>>>>
>> >> >>>>>> # Second try
>> >> >>>>>> ds_test[is.na("var1")] <- 0
>> >> >>>>>> ds_test$var1  # not recoded WRONG
>> >> >>>>>>
>> >> >>>>>> # Third try: to me the most intuitive approach
>> >> >>>>>> is.na(ds_test["var1"]) <- 0  # attempt to select less than one
>> >> >>>>>> element in
>> >> >>>>>> integerOneIndex WRONG
>> >> >>>>>>
>> >> >>>>>> # Fourth try
>> >> >>>>>> ds_test[is.na(var1)] <- 0  # duplicate subscripts for columns
>> >> >>>>>> WRONG
>> >> >>>>>>
>> >> >>>>>> -- cut --
>> >> >>>>>>    How can I do it correctly?
>> >> >>>>>>
>> >> >>>>>> Where could I have found something about it?
>> >> >>>>>>
>> >> >>>>>> Kind regards
>> >> >>>>>>
>> >> >>>>>> Georg
>> >> >>>>>>
>> >> >>>>>> ______________________________________________
>> >> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >>>>>> see
>> >> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>>>> PLEASE do read the posting guide
>> >> >>>>>> http://www.R-project.org/posting-guide.html
>> >> >>>>>> and provide commented, minimal, self-contained, reproducible
>> >> >>>>>> code.
>> >> >>>>>>
>> >> >>>>> ______________________________________________
>> >> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>>> PLEASE do read the posting guide
>> >> >>>>> http://www.R-project.org/posting-guide.html
>> >> >>>>> and provide commented, minimal, self-contained, reproducible
>> >> >>>>> code.
>> >> >>>>>
>> >> >>>> ______________________________________________
>> >> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>> PLEASE do read the posting guide
>> >> >>>> http://www.R-project.org/posting-guide.html
>> >> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From JSorkin at grecc.umaryland.edu  Fri Jun 24 18:01:14 2016
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 24 Jun 2016 12:01:14 -0400
Subject: [R] Add column to the output of summary(glht).
Message-ID: <576D210A020000CB00158DC7@smtp.medicine.umaryland.edu>


I am trying to make the leap from an R users to an R aficionado . . .
 
I am trying to understand how add a column to the output of summary (and to understand how summary() works).
 
I have run a glmer
fit0 <- glmer(Fall ~ Group+(1|PID),family=poisson(link="log"),data=data[data[,"Group"]!=0,])
 
and I want to perform adjusted multiple comparisons:
 
SumTukey <- summary(glht(fit0, linfct= mcp(Group="Tukey")))
 
which gives beautiful output:
 
> SumTukey Simultaneous Tests for General Linear HypothesesMultiple Comparisons of Means: Tukey ContrastsFit: glmer(formula = Fall ~ Group + (1 | PID), data = data[data[,     "Group"] != 0, ], family = poisson(link = "log"))Linear Hypotheses:           Estimate Std. Error z value Pr(>|z|)2 - 1 == 0   0.5320     0.5075   1.048    0.7173 - 1 == 0   0.6554     0.5000   1.311    0.5514 - 1 == 0   0.9357     0.4655   2.010    0.1813 - 2 == 0   0.1234     0.4174   0.296    0.9914 - 2 == 0   0.4037     0.3754   1.075    0.7004 - 3 == 0   0.2803     0.3651   0.768    0.867(Adjusted p values reported -- single-step method)
 
I want to add a column to the output (unadjusted p-values), but I don't see how this might be done. The output
is not a dataframe, nor is it a matix. 
> class(SumTukey)[1] "summary.glht" "glht"  

It is some class of objects that I don't understand and know nothing
about. How can I add a column to the output of SumTukey [a.k.a. summary(glht(fit0, linfct= mcp(Group="Tukey")))] ?
 
Thank you
John
 
 



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 





Call

Call from mobile

Send SMS

Add to Skype

You'll need Skype CreditFree via Skype
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From andrluis at ualberta.ca  Fri Jun 24 18:05:08 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Fri, 24 Jun 2016 10:05:08 -0600
Subject: [R] How to do it in R
Message-ID: <CAHxKz8a1PGrA1+z2CLFASSaAOJkmUJ6zMMXiaSgMUDx35gtHqQ@mail.gmail.com>

Dear all,

I`ve got to calculate the ratio of methanogens to bacteria, but I wouldn`t
like to divide the total copy numbers of methanogens ( on average 10^8) by
bacteria (10^10) because they have different exponents and bases. So, my
idea is to standardize both microorganisms counts to 10^3.

Hypothetical example of what I`d like to do:

Total Methanogens: 28 x 10^3
Total bacteria: 710 x 10^3


Total: 710 + 28= 738 x 10^3

Met/bac Ratio : (28/738)*100 = 3.79%

How could I perform this calculation in R?

Thanks,

-- 
Andre

	[[alternative HTML version deleted]]


From leonardof at leonardof.med.br  Fri Jun 24 18:21:59 2016
From: leonardof at leonardof.med.br (Leonardo Fontenelle)
Date: Fri, 24 Jun 2016 13:21:59 -0300
Subject: [R] How to do it in R
In-Reply-To: <CAHxKz8a1PGrA1+z2CLFASSaAOJkmUJ6zMMXiaSgMUDx35gtHqQ@mail.gmail.com>
References: <CAHxKz8a1PGrA1+z2CLFASSaAOJkmUJ6zMMXiaSgMUDx35gtHqQ@mail.gmail.com>
Message-ID: <1466785319.3938473.647573289.0685178A@webmail.messagingengine.com>

myfun <- function(a, b) a/(a + b)

Leonardo Ferreira Fontenelle

Em Sex 24 jun. 2016, ?s 13:05, Andr? Luis Neves escreveu:
> Dear all,
> 
> I`ve got to calculate the ratio of methanogens to bacteria, but I
> wouldn`t
> like to divide the total copy numbers of methanogens ( on average 10^8)
> by
> bacteria (10^10) because they have different exponents and bases. So, my
> idea is to standardize both microorganisms counts to 10^3.
> 
> Hypothetical example of what I`d like to do:
> 
> Total Methanogens: 28 x 10^3
> Total bacteria: 710 x 10^3
> 
> 
> Total: 710 + 28= 738 x 10^3
> 
> Met/bac Ratio : (28/738)*100 = 3.79%
> 
> How could I perform this calculation in R?
> 
> Thanks,
> 
> -- 
> Andre
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Fri Jun 24 18:25:27 2016
From: jholtman at gmail.com (jim holtman)
Date: Fri, 24 Jun 2016 12:25:27 -0400
Subject: [R] How to do it in R
In-Reply-To: <CAHxKz8a1PGrA1+z2CLFASSaAOJkmUJ6zMMXiaSgMUDx35gtHqQ@mail.gmail.com>
References: <CAHxKz8a1PGrA1+z2CLFASSaAOJkmUJ6zMMXiaSgMUDx35gtHqQ@mail.gmail.com>
Message-ID: <CAAxdm-6DGhuPJvqgLtJqSP6ptJPBz=EHa-tOiGeCaCd0QNLOsw@mail.gmail.com>

pretty simple:

> t_m <- 28e3
> t_b <- 710e3
> ratio <- t_m / (t_m + t_b) * 100
> ratio
[1] 3.794038


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Jun 24, 2016 at 12:05 PM, Andr? Luis Neves <andrluis at ualberta.ca>
wrote:

> Dear all,
>
> I`ve got to calculate the ratio of methanogens to bacteria, but I wouldn`t
> like to divide the total copy numbers of methanogens ( on average 10^8) by
> bacteria (10^10) because they have different exponents and bases. So, my
> idea is to standardize both microorganisms counts to 10^3.
>
> Hypothetical example of what I`d like to do:
>
> Total Methanogens: 28 x 10^3
> Total bacteria: 710 x 10^3
>
>
> Total: 710 + 28= 738 x 10^3
>
> Met/bac Ratio : (28/738)*100 = 3.79%
>
> How could I perform this calculation in R?
>
> Thanks,
>
> --
> Andre
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun 24 18:34:56 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Jun 2016 09:34:56 -0700
Subject: [R] How to do it in R
In-Reply-To: <CAHxKz8a1PGrA1+z2CLFASSaAOJkmUJ6zMMXiaSgMUDx35gtHqQ@mail.gmail.com>
References: <CAHxKz8a1PGrA1+z2CLFASSaAOJkmUJ6zMMXiaSgMUDx35gtHqQ@mail.gmail.com>
Message-ID: <CAGxFJbRqwBXt3KJivWt3UYGAEWseURwFTh8BHU2BWeyZbWOAqA@mail.gmail.com>

This is very basic. Have you gone through any R tutorials? There are
many good ones on the web. e.g., see here:
https://www.rstudio.com/online-learning/#R

In any case, you should not expect this list to teach you basic R. You
*should* expect it to help you learn and improve your own efforts. I
realize that there is a gray area where these things may overlap.

Also see inline below.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 24, 2016 at 9:05 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Dear all,
>
> I`ve got to calculate the ratio of methanogens to bacteria, but I wouldn`t
> like to divide the total copy numbers of methanogens ( on average 10^8) by
> bacteria (10^10) because they have different exponents and bases. So, my
> idea is to standardize both microorganisms counts to 10^3.

Why can't you use scientific notation? What form are your data in?

e.g.

> a <- 6.2E8; b <- 5.4E10
> a/b
[1] 0.01148148

>
> Hypothetical example of what I`d like to do:
>
> Total Methanogens: 28 x 10^3
> Total bacteria: 710 x 10^3
>
>
> Total: 710 + 28= 738 x 10^3
>
> Met/bac Ratio : (28/738)*100 = 3.79%
>
> How could I perform this calculation in R?
>
> Thanks,
>
> --
> Andre
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fgoetz at whoi.edu  Fri Jun 24 19:45:07 2016
From: fgoetz at whoi.edu (fgoetz)
Date: Fri, 24 Jun 2016 13:45:07 -0400
Subject: [R] Fwd: Fwd: RE: Heatmap.2 Breaks argument
In-Reply-To: <cc050fec-6de6-9c4b-54c1-d0543c8e7786@whoi.edu>
References: <cc050fec-6de6-9c4b-54c1-d0543c8e7786@whoi.edu>
Message-ID: <24fab935-996c-636b-80f6-d92171077c68@whoi.edu>

Dear Mr. or Mrs.,

Please see the previous messages for information. I had a problem with 
the heatmap.2 breaks argument and was wondering if someone could help me 
with that problem. I could not find information for the other authors of 
heatmap.2 to contact them.
Could you provide help or contact information?

Best regards,

Florian Goetz

Phd candidate

Woods Hole Oceanographic Institution

508 289 3715



-------- Weitergeleitete Nachricht --------
Betreff: 	RE: Heatmap.2 Breaks argument
Datum: 	Fri, 24 Jun 2016 13:16:53 -0400
Von: 	Liaw, Andy <andy_liaw at merck.com>
An: 	fgoetz <fgoetz at whoi.edu>



Hi Florian,

I wrote the original version of heatmap(), but not heatmap.2().  Also, heatmap() was modified by R Core before being included into base R, and is now supported by R Core.  Please contact the author of heatmap.2() first.  Thanks!

Best,
Andy

> -----Original Message-----
> From: fgoetz [mailto:fgoetz at whoi.edu]
> Sent: Friday, June 24, 2016 10:21 AM
> To: Liaw, Andy
> Subject: Heatmap.2 Breaks argument
>
> Dear Mr. Liaw,
>
> I am a Phd student at the Woods Hole Oceanographic Institution, MA, USA.
> I found a problem with the breaks argument in the Heatmap.2 function,
> which I dont understand. When I create a Heatmap with the following code
> I have trouble to open the pdf because it takes a long time to load the
> Histogram. When I leave out the break argument I have no problem at all.
> Why is the break argument giving me this problem. I could not find any
> information on that problem so I decided to write to you directly.
>
> Thank you very much for any help!
>
> Best regards,
>
> Florian Goetz
>
>      value_breaks
> <-c(seq(0,0.0001,length=1),seq(0.0002,3,length=10),seq(3.01,6.5,length=10))
>      ###     color breaks
>
> my_palette<-colorRampPalette(c("white","darkblue","yellow"),
> (n=length(value_breaks)-1))#
>
>
>      pdf(file.choose(new=TRUE),width=5,height=10)
>      #par(oma=c(2, 2, 2, 2))
>      par(mar=c(20,10,15,5))
>
>
>      heatmap.2(heatmapmatrix,
>      breaks=value_breaks,
>      symm=FALSE,trace="none",
>      col = my_palette,cexRow=0.5,cexCol=1,srtCol=45,
>      margins=c(10,8),
>      hclustfun = function(x) hclust(x,method = 'ward.D'),
>      distfun = function(x) vegdist(x,method = 'euclidean'))
>
>
>
> dev.off()    #Close the pdf file

Notice:  This e-mail message, together with any attachme...{{dropped:15}}


From istazahn at gmail.com  Fri Jun 24 20:30:24 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 24 Jun 2016 14:30:24 -0400
Subject: [R] Add column to the output of summary(glht).
In-Reply-To: <576D013D020000CB00158D67@smtp.medicine.umaryland.edu>
References: <576D013D020000CB00158D67@smtp.medicine.umaryland.edu>
Message-ID: <CA+vqiLHmFVJ6tVrTekuh4hDfC6mqiT5mxmD5t0YZzpW3M9NMkw@mail.gmail.com>

This won't make you an R aficionado, but depending on your needs

library(broom)
tidy(SumTukey)

might be useful. This converts the output to a familiar data.frame, making
it much easier to work with.

Best,
Ista
On Jun 24, 2016 9:48 AM, "John Sorkin" <JSorkin at grecc.umaryland.edu> wrote:

>
> I am trying to make the leap from an R users to an R aficionado . . .
>
> I am trying to understand how add a column to the output of summary (and
> to understand how summary() works).
>
> I have run a glmer
> fit0 <- glmer(Fall ~
> Group+(1|PID),family=poisson(link="log"),data=data[data[,"Group"]!=0,])
>
> and I want to perform adjusted multiple comparisons:
>
> SumTukey <- summary(glht(fit0, linfct= mcp(Group="Tukey")))
>
> which gives beautiful output:
>
> > SumTukey
>
>          Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: glmer(formula = Fall ~ Group + (1 | PID), data = data[data[,
>     "Group"] != 0, ], family = poisson(link = "log"))
>
> Linear Hypotheses:
>            Estimate Std. Error z value Pr(>|z|)
> 2 - 1 == 0   0.5320     0.5075   1.048    0.717
> 3 - 1 == 0   0.6554     0.5000   1.311    0.551
> 4 - 1 == 0   0.9357     0.4655   2.010    0.181
> 3 - 2 == 0   0.1234     0.4174   0.296    0.991
> 4 - 2 == 0   0.4037     0.3754   1.075    0.700
> 4 - 3 == 0   0.2803     0.3651   0.768    0.867
> (Adjusted p values reported -- single-step method)
>
> I want to add a column to the output (unadjusted p-values), but I don't
> see how this might be done. The output
> is not a dataframe, nor is it a matix.
> > class(SumTukey)
> [1] "summary.glht" "glht"
>
> It is some class of objects that I don't understand and know nothing
> about. How can I add a column to the output of SumTukey [a.k.a.
> summary(glht(fit0, linfct= mcp(Group="Tukey")))] ?
>
> Thank you
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From devazresearch at gmail.com  Fri Jun 24 20:49:32 2016
From: devazresearch at gmail.com (deva d)
Date: Fri, 24 Jun 2016 19:49:32 +0100
Subject: [R] Rattle
Message-ID: <CAKuYVCUHrsVea8yfAEmUqR=gaK6PHxdnGwYmJTN0MkCJb5yEiA@mail.gmail.com>

hi all,

i am getting stuck while using Rattle - specifically, I am unable to get
the graphics.

i am using R 3.2.5 and some packages do not work in that.

can someone pl help ?




*....*

*Deva*


...............



*in search of knowledge, everyday something is added ....*

*in search of wisdom, everyday something is dropped  ... an old Chinese
Proverb*
:::::::::::::::::::::::::

On Fri, Jun 24, 2016 at 5:34 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> This is very basic. Have you gone through any R tutorials? There are
> many good ones on the web. e.g., see here:
> https://www.rstudio.com/online-learning/#R
>
> In any case, you should not expect this list to teach you basic R. You
> *should* expect it to help you learn and improve your own efforts. I
> realize that there is a gray area where these things may overlap.
>
> Also see inline below.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jun 24, 2016 at 9:05 AM, Andr? Luis Neves <andrluis at ualberta.ca>
> wrote:
> > Dear all,
> >
> > I`ve got to calculate the ratio of methanogens to bacteria, but I
> wouldn`t
> > like to divide the total copy numbers of methanogens ( on average 10^8)
> by
> > bacteria (10^10) because they have different exponents and bases. So, my
> > idea is to standardize both microorganisms counts to 10^3.
>
> Why can't you use scientific notation? What form are your data in?
>
> e.g.
>
> > a <- 6.2E8; b <- 5.4E10
> > a/b
> [1] 0.01148148
>
> >
> > Hypothetical example of what I`d like to do:
> >
> > Total Methanogens: 28 x 10^3
> > Total bacteria: 710 x 10^3
> >
> >
> > Total: 710 + 28= 738 x 10^3
> >
> > Met/bac Ratio : (28/738)*100 = 3.79%
> >
> > How could I perform this calculation in R?
> >
> > Thanks,
> >
> > --
> > Andre
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From devazresearch at gmail.com  Fri Jun 24 20:51:30 2016
From: devazresearch at gmail.com (deva d)
Date: Fri, 24 Jun 2016 19:51:30 +0100
Subject: [R] R package updating
Message-ID: <CAKuYVCXSe2NAxHOGpvDz4v14LCwwxizRX677Ag5PTm5GjFYPkQ@mail.gmail.com>

hi all,

i notice that the R package available at CRAN is a more recent one compared
to what I have.

but i failed to update my machine and unfortunately, R does not work any
more.

can someone kindly suggest what is a way to update the R ver.

is there a good way to retain all R files and update it without upsetting
other settings.

would be happy to hear.

regds,


*....*

*D*


...............



*in search of knowledge, everyday something is added ....*

*in search of wisdom, everyday something is dropped  ... an old Chinese
Proverb*
:::::::::::::::::::::::::

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Fri Jun 24 22:55:49 2016
From: syen04 at gmail.com (Steven Yen)
Date: Fri, 24 Jun 2016 16:55:49 -0400
Subject: [R] Reading csv file with missing value
Message-ID: <cb44d7e4-8409-0267-b7d9-5814204bd92f@gmail.com>

I read a csv file (with read.csv) containing missing values (as shown 
below). Is there a convenient way to set these NA into zeros?
Better yet, is there an option to assign zeros to these blank cells in 
reading the csv file? Thank you!

NA  -1  NA  NA  NA   1  NA
NA  NA  NA  NA  NA  NA  NA
NA  NA  NA  NA  NA  NA  NA
NA  -1  NA  NA  NA  NA  NA



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Jun 24 23:05:28 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Jun 2016 14:05:28 -0700
Subject: [R] Reading csv file with missing value
In-Reply-To: <cb44d7e4-8409-0267-b7d9-5814204bd92f@gmail.com>
References: <cb44d7e4-8409-0267-b7d9-5814204bd92f@gmail.com>
Message-ID: <CAGxFJbTadqCJyroxosQjSZ23XD3F-izw-2KNdfKUv8Bm9-1WUQ@mail.gmail.com>

Read yesterday's and today's archives.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 24, 2016 at 1:55 PM, Steven Yen <syen04 at gmail.com> wrote:
> I read a csv file (with read.csv) containing missing values (as shown
> below). Is there a convenient way to set these NA into zeros?
> Better yet, is there an option to assign zeros to these blank cells in
> reading the csv file? Thank you!
>
> NA  -1  NA  NA  NA   1  NA
> NA  NA  NA  NA  NA  NA  NA
> NA  NA  NA  NA  NA  NA  NA
> NA  -1  NA  NA  NA  NA  NA
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Jun 24 23:08:11 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 24 Jun 2016 14:08:11 -0700
Subject: [R] Fwd: Fwd: RE: Heatmap.2 Breaks argument
In-Reply-To: <24fab935-996c-636b-80f6-d92171077c68@whoi.edu>
References: <cc050fec-6de6-9c4b-54c1-d0543c8e7786@whoi.edu>
	<24fab935-996c-636b-80f6-d92171077c68@whoi.edu>
Message-ID: <49646560-B9B6-4B4F-8644-E1ADCB096111@dcn.davis.ca.us>

Did you try the maintainer() function? 
-- 
Sent from my phone. Please excuse my brevity.

On June 24, 2016 10:45:07 AM PDT, fgoetz <fgoetz at whoi.edu> wrote:
>Dear Mr. or Mrs.,
>
>Please see the previous messages for information. I had a problem with 
>the heatmap.2 breaks argument and was wondering if someone could help
>me 
>with that problem. I could not find information for the other authors
>of 
>heatmap.2 to contact them.
>Could you provide help or contact information?
>
>Best regards,
>
>Florian Goetz
>
>Phd candidate
>
>Woods Hole Oceanographic Institution
>
>508 289 3715
>
>
>
>-------- Weitergeleitete Nachricht --------
>Betreff: 	RE: Heatmap.2 Breaks argument
>Datum: 	Fri, 24 Jun 2016 13:16:53 -0400
>Von: 	Liaw, Andy <andy_liaw at merck.com>
>An: 	fgoetz <fgoetz at whoi.edu>
>
>
>
>Hi Florian,
>
>I wrote the original version of heatmap(), but not heatmap.2().  Also,
>heatmap() was modified by R Core before being included into base R, and
>is now supported by R Core.  Please contact the author of heatmap.2()
>first.  Thanks!
>
>Best,
>Andy
>
>> -----Original Message-----
>> From: fgoetz [mailto:fgoetz at whoi.edu]
>> Sent: Friday, June 24, 2016 10:21 AM
>> To: Liaw, Andy
>> Subject: Heatmap.2 Breaks argument
>>
>> Dear Mr. Liaw,
>>
>> I am a Phd student at the Woods Hole Oceanographic Institution, MA,
>USA.
>> I found a problem with the breaks argument in the Heatmap.2 function,
>> which I dont understand. When I create a Heatmap with the following
>code
>> I have trouble to open the pdf because it takes a long time to load
>the
>> Histogram. When I leave out the break argument I have no problem at
>all.
>> Why is the break argument giving me this problem. I could not find
>any
>> information on that problem so I decided to write to you directly.
>>
>> Thank you very much for any help!
>>
>> Best regards,
>>
>> Florian Goetz
>>
>>      value_breaks
>>
><-c(seq(0,0.0001,length=1),seq(0.0002,3,length=10),seq(3.01,6.5,length=10))
>>      ###     color breaks
>>
>> my_palette<-colorRampPalette(c("white","darkblue","yellow"),
>> (n=length(value_breaks)-1))#
>>
>>
>>      pdf(file.choose(new=TRUE),width=5,height=10)
>>      #par(oma=c(2, 2, 2, 2))
>>      par(mar=c(20,10,15,5))
>>
>>
>>      heatmap.2(heatmapmatrix,
>>      breaks=value_breaks,
>>      symm=FALSE,trace="none",
>>      col = my_palette,cexRow=0.5,cexCol=1,srtCol=45,
>>      margins=c(10,8),
>>      hclustfun = function(x) hclust(x,method = 'ward.D'),
>>      distfun = function(x) vegdist(x,method = 'euclidean'))
>>
>>
>>
>> dev.off()    #Close the pdf file
>
>Notice:  This e-mail message, together with any
>attachme...{{dropped:15}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Jun 24 23:13:56 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 24 Jun 2016 14:13:56 -0700
Subject: [R] Rattle
In-Reply-To: <CAKuYVCUHrsVea8yfAEmUqR=gaK6PHxdnGwYmJTN0MkCJb5yEiA@mail.gmail.com>
References: <CAKuYVCUHrsVea8yfAEmUqR=gaK6PHxdnGwYmJTN0MkCJb5yEiA@mail.gmail.com>
Message-ID: <57AFD8FD-2EF7-4EDE-B7CF-616DF4F65EFB@dcn.davis.ca.us>

This is like asking, "My car doesn't work. Can anyone tell me what is wrong?"

Please spend some time reading (and paying attention to) the Posting Guide before sending any more emails here. 
-- 
Sent from my phone. Please excuse my brevity.

On June 24, 2016 11:49:32 AM PDT, deva d <devazresearch at gmail.com> wrote:
>hi all,
>
>i am getting stuck while using Rattle - specifically, I am unable to
>get
>the graphics.
>
>i am using R 3.2.5 and some packages do not work in that.
>
>can someone pl help ?
>
>
>
>
>*....*
>
>*Deva*
>
>
>...............
>
>
>
>*in search of knowledge, everyday something is added ....*
>
>*in search of wisdom, everyday something is dropped  ... an old Chinese
>Proverb*
>:::::::::::::::::::::::::
>
>On Fri, Jun 24, 2016 at 5:34 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>
>> This is very basic. Have you gone through any R tutorials? There are
>> many good ones on the web. e.g., see here:
>> https://www.rstudio.com/online-learning/#R
>>
>> In any case, you should not expect this list to teach you basic R.
>You
>> *should* expect it to help you learn and improve your own efforts. I
>> realize that there is a gray area where these things may overlap.
>>
>> Also see inline below.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Jun 24, 2016 at 9:05 AM, Andr? Luis Neves
><andrluis at ualberta.ca>
>> wrote:
>> > Dear all,
>> >
>> > I`ve got to calculate the ratio of methanogens to bacteria, but I
>> wouldn`t
>> > like to divide the total copy numbers of methanogens ( on average
>10^8)
>> by
>> > bacteria (10^10) because they have different exponents and bases.
>So, my
>> > idea is to standardize both microorganisms counts to 10^3.
>>
>> Why can't you use scientific notation? What form are your data in?
>>
>> e.g.
>>
>> > a <- 6.2E8; b <- 5.4E10
>> > a/b
>> [1] 0.01148148
>>
>> >
>> > Hypothetical example of what I`d like to do:
>> >
>> > Total Methanogens: 28 x 10^3
>> > Total bacteria: 710 x 10^3
>> >
>> >
>> > Total: 710 + 28= 738 x 10^3
>> >
>> > Met/bac Ratio : (28/738)*100 = 3.79%
>> >
>> > How could I perform this calculation in R?
>> >
>> > Thanks,
>> >
>> > --
>> > Andre
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sat Jun 25 00:55:59 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 25 Jun 2016 10:55:59 +1200
Subject: [R] [FORGED] Re:  Rattle
In-Reply-To: <57AFD8FD-2EF7-4EDE-B7CF-616DF4F65EFB@dcn.davis.ca.us>
References: <CAKuYVCUHrsVea8yfAEmUqR=gaK6PHxdnGwYmJTN0MkCJb5yEiA@mail.gmail.com>
	<57AFD8FD-2EF7-4EDE-B7CF-616DF4F65EFB@dcn.davis.ca.us>
Message-ID: <dc96ecda-6370-d7eb-748b-a032e7fe4225@auckland.ac.nz>

On 25/06/16 09:13, Jeff Newmiller wrote:
> This is like asking, "My car doesn't work. Can anyone tell me what is wrong?"

<SNIP>

Fortune nomination!

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From marius.hofert at uwaterloo.ca  Sat Jun 25 02:40:35 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Fri, 24 Jun 2016 20:40:35 -0400
Subject: [R] What's box() (exactly) doing?
In-Reply-To: <137eccf8762b48a793527114f21ce677@CONNHUB3.connect.uwaterloo.ca>
References: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
	<137eccf8762b48a793527114f21ce677@CONNHUB3.connect.uwaterloo.ca>
Message-ID: <CAM3-KjayGettZV63qv77uiXuc6JVEv=CnwYawMwug+3rHT9Cbw@mail.gmail.com>

Hi Jim,

Thanks a lot, exactly what I was looking for.

Cheers,
Marius



On Thu, Jun 23, 2016 at 11:06 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Marius,
> There are a few things that are happening here. First, the plot area
> is not going to be the same as your x and y limits unless you say so:
>
> # run your first example
> par("usr")
> [1] -0.04  1.04 -0.04  1.04
>
> # but
> plot(NA, type = "n", ann = FALSE, axes = FALSE,
>  xlim = 0:1, ylim = 0:1,xaxs="i",yaxs="i")
> box()
> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
> par("usr")
> [1] 0 1 0 1
>
> Second, the "rect" function is automatically clipped to the plot area,
> so you may lose a bit at the edges if you don't override this:
>
> par(xpd=TRUE)
> rect(...)
> par(xpd=FALSE)
>
> Finally your second example simply multiplies the first problem by
> specifying a layout of more than one plot. Applying the "xaxs" and
> "yaxs" parameters before you start plotting will fix this:
>
> par(xaxs="i",yaxs="i")
>
> Jim
>
> On Fri, Jun 24, 2016 at 12:29 PM, Marius Hofert
> <marius.hofert at uwaterloo.ca> wrote:
>> Hi,
>>
>> I would like to replicate the behavior of box() with rect() (don't ask why).
>> However, my rect()angles are always too small. I looked a bit into the
>> internal C_box but
>> couldn't figure out how to solve the problem. Below is a minimal
>> working (and a slightly bigger) example.
>>
>> Cheers,
>> Marius
>>
>> ## MWE
>> plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
>> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80") #
>> should match box()
>> box()
>>
>> ## Extended example
>>
>> ## Basic plot
>> my_rect <- function()
>> {
>>     plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
>>     rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
>> # should match box()
>>     box()
>> }
>>
>> ## Layout
>> lay <- matrix(0, nrow = 3, ncol = 3, byrow = TRUE)
>> lay[1,1] <- 1
>> lay[2,1] <- 2
>> lay[2,2] <- 3
>> lay[2,3] <- 4
>> lay[3,3] <- 5
>> layout(lay, heights = c(1, 10, 1), widths = c(10, 1, 10))
>> layout.show(5) # => no space between rectangles; calls box() to draw the boxes
>>
>> ## Fill layout
>> par(oma = rep(0, 4), mar = rep(0, 4))
>> my_rect()
>> my_rect()
>> my_rect()
>> my_rect()
>> my_rect()
>> ## => spaces between rectangles => why?/how to avoid?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From marius.hofert at uwaterloo.ca  Sat Jun 25 04:19:05 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Fri, 24 Jun 2016 22:19:05 -0400
Subject: [R] What's box() (exactly) doing?
In-Reply-To: <CAM3-KjayGettZV63qv77uiXuc6JVEv=CnwYawMwug+3rHT9Cbw@mail.gmail.com>
References: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
	<137eccf8762b48a793527114f21ce677@CONNHUB3.connect.uwaterloo.ca>
	<CAM3-KjayGettZV63qv77uiXuc6JVEv=CnwYawMwug+3rHT9Cbw@mail.gmail.com>
Message-ID: <CAM3-KjYPbjAyztSsTH-2w9LcRHgs28SykcZd-RhuHH715hRc2Q@mail.gmail.com>

Hi Jim,

Here is a follow-up question: How would you replicate box("figure")
(instead of box() = box("plot"))?
I tried to fill the plotted box but there seems to be no argument to
box("figure") that does that. If that's indeed the case, one could
work again with rect() (thus replicating box("figure")), but how can
one specify the exact location/width/height of the rectangle? (see
example below)

Cheers,
M

plot(NA, type = "n", ann = TRUE, axes = TRUE, xlim = 0:1, ylim = 0:1)
box("figure", col = "red", lwd = 2) # how to fill?

par(xpd = TRUE)
width = 1.4 # obviously not correct...
height <- width
loc.x <- 0.5
loc.y <- 0.5
xleft <- loc.x-width/2
xright <- loc.x+width/2
ybottom <- loc.y-height/2
ytop <- loc.y+height/2
rect(xleft = xleft, ybottom = ybottom, xright = xright, ytop = ytop,
     col = adjustcolor("grey80", alpha.f = 0.5))
par(xpd = FALSE)

On Fri, Jun 24, 2016 at 8:40 PM, Marius Hofert
<marius.hofert at uwaterloo.ca> wrote:
> Hi Jim,
>
> Thanks a lot, exactly what I was looking for.
>
> Cheers,
> Marius
>
>
>
> On Thu, Jun 23, 2016 at 11:06 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi Marius,
>> There are a few things that are happening here. First, the plot area
>> is not going to be the same as your x and y limits unless you say so:
>>
>> # run your first example
>> par("usr")
>> [1] -0.04  1.04 -0.04  1.04
>>
>> # but
>> plot(NA, type = "n", ann = FALSE, axes = FALSE,
>>  xlim = 0:1, ylim = 0:1,xaxs="i",yaxs="i")
>> box()
>> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
>> par("usr")
>> [1] 0 1 0 1
>>
>> Second, the "rect" function is automatically clipped to the plot area,
>> so you may lose a bit at the edges if you don't override this:
>>
>> par(xpd=TRUE)
>> rect(...)
>> par(xpd=FALSE)
>>
>> Finally your second example simply multiplies the first problem by
>> specifying a layout of more than one plot. Applying the "xaxs" and
>> "yaxs" parameters before you start plotting will fix this:
>>
>> par(xaxs="i",yaxs="i")
>>
>> Jim
>>
>> On Fri, Jun 24, 2016 at 12:29 PM, Marius Hofert
>> <marius.hofert at uwaterloo.ca> wrote:
>>> Hi,
>>>
>>> I would like to replicate the behavior of box() with rect() (don't ask why).
>>> However, my rect()angles are always too small. I looked a bit into the
>>> internal C_box but
>>> couldn't figure out how to solve the problem. Below is a minimal
>>> working (and a slightly bigger) example.
>>>
>>> Cheers,
>>> Marius
>>>
>>> ## MWE
>>> plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
>>> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80") #
>>> should match box()
>>> box()
>>>
>>> ## Extended example
>>>
>>> ## Basic plot
>>> my_rect <- function()
>>> {
>>>     plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
>>>     rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
>>> # should match box()
>>>     box()
>>> }
>>>
>>> ## Layout
>>> lay <- matrix(0, nrow = 3, ncol = 3, byrow = TRUE)
>>> lay[1,1] <- 1
>>> lay[2,1] <- 2
>>> lay[2,2] <- 3
>>> lay[2,3] <- 4
>>> lay[3,3] <- 5
>>> layout(lay, heights = c(1, 10, 1), widths = c(10, 1, 10))
>>> layout.show(5) # => no space between rectangles; calls box() to draw the boxes
>>>
>>> ## Fill layout
>>> par(oma = rep(0, 4), mar = rep(0, 4))
>>> my_rect()
>>> my_rect()
>>> my_rect()
>>> my_rect()
>>> my_rect()
>>> ## => spaces between rectangles => why?/how to avoid?
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Jun 25 06:14:21 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 24 Jun 2016 21:14:21 -0700
Subject: [R] What's box() (exactly) doing?
In-Reply-To: <CAM3-KjYPbjAyztSsTH-2w9LcRHgs28SykcZd-RhuHH715hRc2Q@mail.gmail.com>
References: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
	<137eccf8762b48a793527114f21ce677@CONNHUB3.connect.uwaterloo.ca>
	<CAM3-KjayGettZV63qv77uiXuc6JVEv=CnwYawMwug+3rHT9Cbw@mail.gmail.com>
	<CAM3-KjYPbjAyztSsTH-2w9LcRHgs28SykcZd-RhuHH715hRc2Q@mail.gmail.com>
Message-ID: <CAF8bMcbKtU1t5LjFPkEVdNExKxb=+e4rsVSTD=RqQw4miKHqrg@mail.gmail.com>

Try this one:

myBox <- function (which = c("plot", "figure"), ...) {
   # draw filled rectangle where box() would draw open rectangle
    which <- match.arg(which)
    oldXpd <- par("xpd")
    on.exit(par(oldXpd))
    if (which == "plot") {
        do.call("rect", c(as.list(par("usr")[c(1, 3, 2, 4)]),
            list(...)))
    }
    else {
        mapLinearly <- function(x, from, to) {
            stopifnot(length(from) == 2, length(to) == 2)
            diff(to)/diff(from) * (x - from[1]) + to[1]
        }
        figX <- mapLinearly(c(0, 1), par("plt")[1:2], par("usr")[1:2])
        figY <- mapLinearly(c(0, 1), par("plt")[3:4], par("usr")[3:4])
        do.call("rect", c(as.list(c(figX, figY)[c(1, 3, 2, 4)]),
            list(...)))
    }
}

as in

> par(mfrow=c(3,3))
> for(i in 1:4)frame()
> plot(sunspots)
> box(which="plot", col="blue", lwd=5)
> box(which="fig", col="red", lwd=5)
> myBox(which="plot", col=adjustcolor("lightblue", alpha.f=0.3))
> myBox(which="fig", col=adjustcolor("pink", alpha.f=0.3))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 24, 2016 at 7:19 PM, Marius Hofert <marius.hofert at uwaterloo.ca>
wrote:

> Hi Jim,
>
> Here is a follow-up question: How would you replicate box("figure")
> (instead of box() = box("plot"))?
> I tried to fill the plotted box but there seems to be no argument to
> box("figure") that does that. If that's indeed the case, one could
> work again with rect() (thus replicating box("figure")), but how can
> one specify the exact location/width/height of the rectangle? (see
> example below)
>
> Cheers,
> M
>
> plot(NA, type = "n", ann = TRUE, axes = TRUE, xlim = 0:1, ylim = 0:1)
> box("figure", col = "red", lwd = 2) # how to fill?
>
> par(xpd = TRUE)
> width = 1.4 # obviously not correct...
> height <- width
> loc.x <- 0.5
> loc.y <- 0.5
> xleft <- loc.x-width/2
> xright <- loc.x+width/2
> ybottom <- loc.y-height/2
> ytop <- loc.y+height/2
> rect(xleft = xleft, ybottom = ybottom, xright = xright, ytop = ytop,
>      col = adjustcolor("grey80", alpha.f = 0.5))
> par(xpd = FALSE)
>
> On Fri, Jun 24, 2016 at 8:40 PM, Marius Hofert
> <marius.hofert at uwaterloo.ca> wrote:
> > Hi Jim,
> >
> > Thanks a lot, exactly what I was looking for.
> >
> > Cheers,
> > Marius
> >
> >
> >
> > On Thu, Jun 23, 2016 at 11:06 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >> Hi Marius,
> >> There are a few things that are happening here. First, the plot area
> >> is not going to be the same as your x and y limits unless you say so:
> >>
> >> # run your first example
> >> par("usr")
> >> [1] -0.04  1.04 -0.04  1.04
> >>
> >> # but
> >> plot(NA, type = "n", ann = FALSE, axes = FALSE,
> >>  xlim = 0:1, ylim = 0:1,xaxs="i",yaxs="i")
> >> box()
> >> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
> >> par("usr")
> >> [1] 0 1 0 1
> >>
> >> Second, the "rect" function is automatically clipped to the plot area,
> >> so you may lose a bit at the edges if you don't override this:
> >>
> >> par(xpd=TRUE)
> >> rect(...)
> >> par(xpd=FALSE)
> >>
> >> Finally your second example simply multiplies the first problem by
> >> specifying a layout of more than one plot. Applying the "xaxs" and
> >> "yaxs" parameters before you start plotting will fix this:
> >>
> >> par(xaxs="i",yaxs="i")
> >>
> >> Jim
> >>
> >> On Fri, Jun 24, 2016 at 12:29 PM, Marius Hofert
> >> <marius.hofert at uwaterloo.ca> wrote:
> >>> Hi,
> >>>
> >>> I would like to replicate the behavior of box() with rect() (don't ask
> why).
> >>> However, my rect()angles are always too small. I looked a bit into the
> >>> internal C_box but
> >>> couldn't figure out how to solve the problem. Below is a minimal
> >>> working (and a slightly bigger) example.
> >>>
> >>> Cheers,
> >>> Marius
> >>>
> >>> ## MWE
> >>> plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
> >>> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80") #
> >>> should match box()
> >>> box()
> >>>
> >>> ## Extended example
> >>>
> >>> ## Basic plot
> >>> my_rect <- function()
> >>> {
> >>>     plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim =
> 0:1)
> >>>     rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
> >>> # should match box()
> >>>     box()
> >>> }
> >>>
> >>> ## Layout
> >>> lay <- matrix(0, nrow = 3, ncol = 3, byrow = TRUE)
> >>> lay[1,1] <- 1
> >>> lay[2,1] <- 2
> >>> lay[2,2] <- 3
> >>> lay[2,3] <- 4
> >>> lay[3,3] <- 5
> >>> layout(lay, heights = c(1, 10, 1), widths = c(10, 1, 10))
> >>> layout.show(5) # => no space between rectangles; calls box() to draw
> the boxes
> >>>
> >>> ## Fill layout
> >>> par(oma = rep(0, 4), mar = rep(0, 4))
> >>> my_rect()
> >>> my_rect()
> >>> my_rect()
> >>> my_rect()
> >>> my_rect()
> >>> ## => spaces between rectangles => why?/how to avoid?
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Sat Jun 25 15:52:55 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 25 Jun 2016 13:52:55 +0000
Subject: [R] Error using function seas()
Message-ID: <31e8e0312b5948bd97a799f164bab582@ex13-live-mbn1.ad.kent.ac.uk>

Dear all,

I am trying to run the seas() function. If I run the seas() function as shown below I get following errors. What is wrong with my code?


> data<-Shiller_data[,2]

> ts<-ts(data,start=c(1871, 01), end=c(2015, 12), frequency=12)

> ts

         Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep     Oct

1871    4.44    4.50    4.61    4.74    4.86    4.82    4.73    4.79    4.84    4.59

1872    4.86    4.88    5.04    5.18    5.18    5.13    5.10    5.04    4.95    4.97

1873    5.11    5.15    5.11    5.04    5.05    4.98    4.97    4.97    4.59    4.19

1874    4.66    4.80    4.73    4.60    4.48    4.46    4.46    4.47    4.54    4.53

1875    4.54    4.53    4.59    4.65    4.47    4.38    4.39    4.41    4.37    4.30

1876    4.46    4.52    4.51    4.34    4.18    4.15    4.10    3.93    3.69    3.67

1877    3.55    3.34    3.17    2.94    2.94    2.73    2.85    3.05    3.24    3.31

1878    3.25    3.18    3.24    3.33    3.34    3.41    3.48    3.45    3.52    3.48

1879    3.58    3.71    3.65    3.77    3.94    3.96    4.04    4.07    4.22    4.68

1880    5.11    5.20    5.30    5.18    4.77    4.79    5.01    5.19    5.18    5.33

1881    6.19    6.17    6.24    6.22    6.50    6.58    6.35    6.20    6.25    6.15

1882    5.92    5.79    5.78    5.78    5.71    5.68    6.00    6.18    6.24    6.07

1883    5.81    5.68    5.75    5.87    5.77    5.82    5.73    5.47    5.53    5.38

1884    5.18    5.32    5.30    5.06    4.65    4.46    4.46    4.74    4.59    4.44

1885    4.24    4.37    4.38    4.37    4.32    4.30    4.46    4.71    4.65    4.92

1886    5.20    5.30    5.19    5.12    5.02    5.25    5.33    5.37    5.51    5.65

1887    5.58    5.54    5.67    5.80    5.90    5.73    5.59    5.45    5.38    5.20

1888    5.31    5.28    5.08    5.10    5.17    5.01    5.14    5.25    5.38    5.35

1889    5.24    5.30    5.19    5.18    5.32    5.41    5.30    5.37    5.50    5.40

1890    5.38    5.32    5.28    5.39    5.62    5.58    5.54    5.41    5.32    5.08

1891    4.84    4.90    4.81    4.97    4.95    4.85    4.77    4.93    5.33    5.33

1892    5.51    5.52    5.58    5.57    5.57    5.54    5.54    5.62    5.48    5.59

1893    5.61    5.51    5.31    5.31    4.84    4.61    4.18    4.08    4.37    4.50

1894    4.32    4.38    4.51    4.57    4.40    4.34    4.25    4.41    4.48    4.34

1895    4.25    4.19    4.19    4.37    4.61    4.70    4.72    4.79    4.82    4.75

1896    4.27    4.45    4.38    4.42    4.40    4.32    4.04    3.81    4.01    4.10

1897    4.22    4.18    4.19    4.06    4.08    4.27    4.46    4.75    4.98    4.82

1898    4.88    4.87    4.65    4.57    4.87    5.06    5.08    5.27    5.26    5.15

1899    6.08    6.31    6.40    6.48    6.21    6.07    6.28    6.44    6.37    6.34

1900    6.10    6.21    6.26    6.34    6.04    5.86    5.86    5.94    5.80    6.01



> SP <- seas(ts)

Error: X-13 run failed



Errors:

- Problem reading C:\Users\tr206\AppData\Local\Temp\Rtmp4Qtc08\x1312202a115399/data.dta. Too

  many observations in file.

- Problem reading C:\Users\tr206\AppData\Local\Temp\Rtmp4Qtc08\x1312202a115399/data.dta. Check

  your input file and format.

- Time series could not be read due to previously found errors

- Specify series before user-defined adjustments

- Need to specify a series to identify outliers





Thanks for your help.


	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Sat Jun 25 21:05:45 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sun, 26 Jun 2016 00:35:45 +0530
Subject: [R] Help with the Cut Function
Message-ID: <CAB=p7SoXKFJYSygkNLXkhDkx4W67DoXHnbGoj5D4WthawQNA7g@mail.gmail.com>

Dear Team,

Please see the code below:

Age1<- cut(desc$Age, breaks = c(20,30,40,Inf),labels = c("Low","Mid","Top"))
here i am creating three categories as mentioned from the age var from desc
data set.
All the values are set correctly however the values which are below 20 are
set to NA.
Is there anything i am doing incorrect.

Regards, Shivi

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Sat Jun 25 21:22:07 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 25 Jun 2016 21:22:07 +0200 (CEST)
Subject: [R] [FORGED] Re:  Rattle
In-Reply-To: <dc96ecda-6370-d7eb-748b-a032e7fe4225@auckland.ac.nz>
References: <CAKuYVCUHrsVea8yfAEmUqR=gaK6PHxdnGwYmJTN0MkCJb5yEiA@mail.gmail.com>
	<57AFD8FD-2EF7-4EDE-B7CF-616DF4F65EFB@dcn.davis.ca.us>
	<dc96ecda-6370-d7eb-748b-a032e7fe4225@auckland.ac.nz>
Message-ID: <alpine.DEB.2.20.1606252121520.7112@paninaro>



On Sat, 25 Jun 2016, Rolf Turner wrote:

> On 25/06/16 09:13, Jeff Newmiller wrote:
>> This is like asking, "My car doesn't work. Can anyone tell me what is 
>> wrong?"
>
> <SNIP>
>
> Fortune nomination!

On R-Forge now.
Z

> cheers,
>
> Rolf
>
>
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>


From r.turner at auckland.ac.nz  Sat Jun 25 23:49:02 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 26 Jun 2016 09:49:02 +1200
Subject: [R] [FORGED]  Help with the Cut Function
In-Reply-To: <CAB=p7SoXKFJYSygkNLXkhDkx4W67DoXHnbGoj5D4WthawQNA7g@mail.gmail.com>
References: <CAB=p7SoXKFJYSygkNLXkhDkx4W67DoXHnbGoj5D4WthawQNA7g@mail.gmail.com>
Message-ID: <e2453193-ae1e-235b-f7e4-d4e828dff6e6@auckland.ac.nz>

On 26/06/16 07:05, Shivi Bhatia wrote:
> Dear Team,
>
> Please see the code below:
>
> Age1<- cut(desc$Age, breaks = c(20,30,40,Inf),labels = c("Low","Mid","Top"))
> here i am creating three categories as mentioned from the age var from desc
> data set.
> All the values are set correctly however the values which are below 20 are
> set to NA.
> Is there anything i am doing incorrect.

No.  What is the problem?  This seems to me to be exactly what one would 
expect.

If you don't want NAs, set your lower break to be less than the minimum 
of desc$Age, e.g. -Inf.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Sat Jun 25 23:51:53 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 26 Jun 2016 09:51:53 +1200
Subject: [R] Error using function seas()
In-Reply-To: <31e8e0312b5948bd97a799f164bab582@ex13-live-mbn1.ad.kent.ac.uk>
References: <31e8e0312b5948bd97a799f164bab582@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <d8854a18-e1af-c789-e894-f047155080ad@auckland.ac.nz>


This is identical to the question that you previously asked and you 
still have not addressed the problem of making your example *reproducible*.

cheers,

Rolf Turner

On 26/06/16 01:52, T.Riedle wrote:
> Dear all,
>
> I am trying to run the seas() function. If I run the seas() function as shown below I get following errors. What is wrong with my code?
>
>
>> data<-Shiller_data[,2]
>
>> ts<-ts(data,start=c(1871, 01), end=c(2015, 12), frequency=12)
>
>> ts
>
>          Jan     Feb     Mar     Apr     May     Jun     Jul     Aug     Sep     Oct
>
> 1871    4.44    4.50    4.61    4.74    4.86    4.82    4.73    4.79    4.84    4.59
>
> 1872    4.86    4.88    5.04    5.18    5.18    5.13    5.10    5.04    4.95    4.97
>
> 1873    5.11    5.15    5.11    5.04    5.05    4.98    4.97    4.97    4.59    4.19
>
> 1874    4.66    4.80    4.73    4.60    4.48    4.46    4.46    4.47    4.54    4.53
>
> 1875    4.54    4.53    4.59    4.65    4.47    4.38    4.39    4.41    4.37    4.30
>
> 1876    4.46    4.52    4.51    4.34    4.18    4.15    4.10    3.93    3.69    3.67
>
> 1877    3.55    3.34    3.17    2.94    2.94    2.73    2.85    3.05    3.24    3.31
>
> 1878    3.25    3.18    3.24    3.33    3.34    3.41    3.48    3.45    3.52    3.48
>
> 1879    3.58    3.71    3.65    3.77    3.94    3.96    4.04    4.07    4.22    4.68
>
> 1880    5.11    5.20    5.30    5.18    4.77    4.79    5.01    5.19    5.18    5.33
>
> 1881    6.19    6.17    6.24    6.22    6.50    6.58    6.35    6.20    6.25    6.15
>
> 1882    5.92    5.79    5.78    5.78    5.71    5.68    6.00    6.18    6.24    6.07
>
> 1883    5.81    5.68    5.75    5.87    5.77    5.82    5.73    5.47    5.53    5.38
>
> 1884    5.18    5.32    5.30    5.06    4.65    4.46    4.46    4.74    4.59    4.44
>
> 1885    4.24    4.37    4.38    4.37    4.32    4.30    4.46    4.71    4.65    4.92
>
> 1886    5.20    5.30    5.19    5.12    5.02    5.25    5.33    5.37    5.51    5.65
>
> 1887    5.58    5.54    5.67    5.80    5.90    5.73    5.59    5.45    5.38    5.20
>
> 1888    5.31    5.28    5.08    5.10    5.17    5.01    5.14    5.25    5.38    5.35
>
> 1889    5.24    5.30    5.19    5.18    5.32    5.41    5.30    5.37    5.50    5.40
>
> 1890    5.38    5.32    5.28    5.39    5.62    5.58    5.54    5.41    5.32    5.08
>
> 1891    4.84    4.90    4.81    4.97    4.95    4.85    4.77    4.93    5.33    5.33
>
> 1892    5.51    5.52    5.58    5.57    5.57    5.54    5.54    5.62    5.48    5.59
>
> 1893    5.61    5.51    5.31    5.31    4.84    4.61    4.18    4.08    4.37    4.50
>
> 1894    4.32    4.38    4.51    4.57    4.40    4.34    4.25    4.41    4.48    4.34
>
> 1895    4.25    4.19    4.19    4.37    4.61    4.70    4.72    4.79    4.82    4.75
>
> 1896    4.27    4.45    4.38    4.42    4.40    4.32    4.04    3.81    4.01    4.10
>
> 1897    4.22    4.18    4.19    4.06    4.08    4.27    4.46    4.75    4.98    4.82
>
> 1898    4.88    4.87    4.65    4.57    4.87    5.06    5.08    5.27    5.26    5.15
>
> 1899    6.08    6.31    6.40    6.48    6.21    6.07    6.28    6.44    6.37    6.34
>
> 1900    6.10    6.21    6.26    6.34    6.04    5.86    5.86    5.94    5.80    6.01
>
>
>
>> SP <- seas(ts)
>
> Error: X-13 run failed
>
>
>
> Errors:
>
> - Problem reading C:\Users\tr206\AppData\Local\Temp\Rtmp4Qtc08\x1312202a115399/data.dta. Too
>
>   many observations in file.
>
> - Problem reading C:\Users\tr206\AppData\Local\Temp\Rtmp4Qtc08\x1312202a115399/data.dta. Check
>
>   your input file and format.
>
> - Time series could not be read due to previously found errors
>
> - Specify series before user-defined adjustments
>
> - Need to specify a series to identify outliers


From dwinsemius at comcast.net  Sat Jun 25 23:55:00 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 25 Jun 2016 14:55:00 -0700
Subject: [R] Help with the Cut Function
In-Reply-To: <CAB=p7SoXKFJYSygkNLXkhDkx4W67DoXHnbGoj5D4WthawQNA7g@mail.gmail.com>
References: <CAB=p7SoXKFJYSygkNLXkhDkx4W67DoXHnbGoj5D4WthawQNA7g@mail.gmail.com>
Message-ID: <74AD5151-A63A-4FE9-BE6C-48C3679DCA40@comcast.net>


> On Jun 25, 2016, at 12:05 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> 
> Dear Team,
> 
> Please see the code below:
> 
> Age1<- cut(desc$Age, breaks = c(20,30,40,Inf),labels = c("Low","Mid","Top"))

Try instead:

Age1<- cut(desc$Age, breaks = c(-Inf, 20,30,40,Inf),labels = c("Low","Mid","Top"))

Do note that values that are <= 20 will be in the lowest category. (You wrote only <20 whereas values of 20 would have not been in any interval.)  The cut function also has a use.lowest argument, whose actions I don't fully understand but I usually set to to TRUE whereas is default is FALSE. I prefer the Hmisc::cut2 functions because its defaults mirror my usual interests. Like cut2, the findInterval function has closed intervals on the left.

> here i am creating three categories as mentioned from the age var from desc
> data set.
> All the values are set correctly however the values which are below 20 are
> set to NA.
> Is there anything i am doing incorrect.
> 
> Regards, Shivi
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From gferraz29 at gmail.com  Sat Jun 25 16:13:54 2016
From: gferraz29 at gmail.com (=?utf-8?Q?Gon=C3=A7alo_Ferraz?=)
Date: Sat, 25 Jun 2016 11:13:54 -0300
Subject: [R] strange behavior of lchoose in combinatorics problem
Message-ID: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>

Hi,

I am working on interactions between animals, studying whether animal 1 is attracted to animal 2 (or vice-versa). I looked for the two animals in N=2178 sampling occasions, finding animal 1 a total of N1=165 times, and animal 2 a total of N2=331 times. In J=97 occasions, I saw both animals at the same time. 

The more frequently I see the two animals in the same sampling occasion, the more I will believe that they are attracted to each other. Therefore, I want to calculate the probability of finding J<=97 when the two animals are moving around independently of each other. The higher this probability, the stronger the attraction.

Following Veech (Journal of Biogeography 2014, 41: 1029-1035) I compute the log probability of obtaining a number n of encounters between animals as ?lpn? in the function lveech:

lveech <- function(N,N1,N2,n) {
    a <- lchoose(N,n)
    b <- lchoose(N-n,N2-n)
    c <- lchoose(N-N2,N1-n)
    d <- lchoose(N,N2)
    e <- lchoose(N,N1)
    lpn <- (a+b+c)-(d+e)
    return(lpn)
}

I have tested this function with shorter, intuitive numbers, and it works as expected. I use log probabilities to stay away from intractable numbers.

Next, I use function lveech to obtain a vector ?lpvec? that gives me all the log probabilities of getting n=0,1,2,?,97 simultaneous observations of the two animals:

lpvec <- rep(NA,J+1)
for(i in 1:(J+1)) lpvec[i] <- lveech(N,N1,N2,nseq[i])

PROBLEM: the sum of the probabilities in lpvec should be <=1, but it is not. The sum is something on the order of 1.48e-13. That happens whether I sum exp(lpvec) or use a function for summing probabilities in log-prob space. In most applications of lveech, the sum of the probabilities is <=1, as it should be, but occasionally I get this problem. Why should this be? Does anyone know of any issues with lchoose that could explain this?

I want to solve this because if I round up the sum to 1 I will not be able to quantify the attraction between animals and compare it with the attractions between other pairs of animals in my data.

Thank you so much for reading the long question.

G.








I have two binary vectors, v1 and v2, both with length N=2178. The sum of vector v1 is N1=165 and the sum of vector v2 is N2=331. I need to compute the probability that 

From shivipmp82 at gmail.com  Sun Jun 26 01:24:37 2016
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sun, 26 Jun 2016 04:54:37 +0530
Subject: [R] Help with the Cut Function
In-Reply-To: <74AD5151-A63A-4FE9-BE6C-48C3679DCA40@comcast.net>
References: <CAB=p7SoXKFJYSygkNLXkhDkx4W67DoXHnbGoj5D4WthawQNA7g@mail.gmail.com>
	<74AD5151-A63A-4FE9-BE6C-48C3679DCA40@comcast.net>
Message-ID: <CAB=p7Sov7WhgsA3U9vSCHna747g7kWBT0G6rjW7z_aqjgsPYgQ@mail.gmail.com>

Hi David,

I tried as suggested however with this code:
Age11<- cut(desc$Age, breaks = c(-Inf, 20,30,40,Inf),labels =
c("Low","Mid","Top")) i receive an error message as below:

lengths of 'breaks' and 'labels' differ. Now as a result i have values
exceeding 40 as N/A.

On Sun, Jun 26, 2016 at 3:25 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jun 25, 2016, at 12:05 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> >
> > Dear Team,
> >
> > Please see the code below:
> >
> > Age1<- cut(desc$Age, breaks = c(20,30,40,Inf),labels =
> c("Low","Mid","Top"))
>
> Try instead:
>
> Age1<- cut(desc$Age, breaks = c(-Inf, 20,30,40,Inf),labels =
> c("Low","Mid","Top"))
>
> Do note that values that are <= 20 will be in the lowest category. (You
> wrote only <20 whereas values of 20 would have not been in any interval.)
> The cut function also has a use.lowest argument, whose actions I don't
> fully understand but I usually set to to TRUE whereas is default is FALSE.
> I prefer the Hmisc::cut2 functions because its defaults mirror my usual
> interests. Like cut2, the findInterval function has closed intervals on the
> left.
>
> > here i am creating three categories as mentioned from the age var from
> desc
> > data set.
> > All the values are set correctly however the values which are below 20
> are
> > set to NA.
> > Is there anything i am doing incorrect.
> >
> > Regards, Shivi
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Sun Jun 26 01:26:17 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 25 Jun 2016 19:26:17 -0400
Subject: [R] strange behavior of lchoose in combinatorics problem
In-Reply-To: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>
References: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>
Message-ID: <CAGx1TMAEVt2-puxCO17E3eypWhVNgHNKJ+fyv=pFjBYBWA=qUg@mail.gmail.com>

Floating point numbers are rounded to 53 significant bits.  When you
use logs of integers you are using
floating point numbers.

> .3 + .6 == .9
[1] FALSE
> (.3 + .6) - .9
[1] -1.110223e-16

See FAQ 7.31 for more discussion.

On Sat, Jun 25, 2016 at 10:13 AM, Gon?alo Ferraz <gferraz29 at gmail.com> wrote:
> Hi,
>
> I am working on interactions between animals, studying whether animal 1 is attracted to animal 2 (or vice-versa). I looked for the two animals in N=2178 sampling occasions, finding animal 1 a total of N1=165 times, and animal 2 a total of N2=331 times. In J=97 occasions, I saw both animals at the same time.
>
> The more frequently I see the two animals in the same sampling occasion, the more I will believe that they are attracted to each other. Therefore, I want to calculate the probability of finding J<=97 when the two animals are moving around independently of each other. The higher this probability, the stronger the attraction.
>
> Following Veech (Journal of Biogeography 2014, 41: 1029-1035) I compute the log probability of obtaining a number n of encounters between animals as ?lpn? in the function lveech:
>
> lveech <- function(N,N1,N2,n) {
>     a <- lchoose(N,n)
>     b <- lchoose(N-n,N2-n)
>     c <- lchoose(N-N2,N1-n)
>     d <- lchoose(N,N2)
>     e <- lchoose(N,N1)
>     lpn <- (a+b+c)-(d+e)
>     return(lpn)
> }
>
> I have tested this function with shorter, intuitive numbers, and it works as expected. I use log probabilities to stay away from intractable numbers.
>
> Next, I use function lveech to obtain a vector ?lpvec? that gives me all the log probabilities of getting n=0,1,2,?,97 simultaneous observations of the two animals:
>
> lpvec <- rep(NA,J+1)
> for(i in 1:(J+1)) lpvec[i] <- lveech(N,N1,N2,nseq[i])
>
> PROBLEM: the sum of the probabilities in lpvec should be <=1, but it is not. The sum is something on the order of 1.48e-13. That happens whether I sum exp(lpvec) or use a function for summing probabilities in log-prob space. In most applications of lveech, the sum of the probabilities is <=1, as it should be, but occasionally I get this problem. Why should this be? Does anyone know of any issues with lchoose that could explain this?
>
> I want to solve this because if I round up the sum to 1 I will not be able to quantify the attraction between animals and compare it with the attractions between other pairs of animals in my data.
>
> Thank you so much for reading the long question.
>
> G.
>
>
>
>
>
>
>
>
> I have two binary vectors, v1 and v2, both with length N=2178. The sum of vector v1 is N1=165 and the sum of vector v2 is N2=331. I need to compute the probability that
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jun 26 02:10:53 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 25 Jun 2016 17:10:53 -0700
Subject: [R] Help with the Cut Function
In-Reply-To: <CAB=p7Sov7WhgsA3U9vSCHna747g7kWBT0G6rjW7z_aqjgsPYgQ@mail.gmail.com>
References: <CAB=p7SoXKFJYSygkNLXkhDkx4W67DoXHnbGoj5D4WthawQNA7g@mail.gmail.com>
	<74AD5151-A63A-4FE9-BE6C-48C3679DCA40@comcast.net>
	<CAB=p7Sov7WhgsA3U9vSCHna747g7kWBT0G6rjW7z_aqjgsPYgQ@mail.gmail.com>
Message-ID: <A2C751EC-6C6E-4E02-ADB8-27A1A9E67ECB@comcast.net>


> On Jun 25, 2016, at 4:24 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> 
> Hi David, 
> 
> I tried as suggested however with this code:
> Age11<- cut(desc$Age, breaks = c(-Inf, 20,30,40,Inf),labels = c("Low","Mid","Top"))


Read the error message and add in another item to the 'labels' vector. Perhaps:

 c( "<= 20", "(20,30]", "(30,40], "> 40"")


> i receive an error message as below:
> 
> lengths of 'breaks' and 'labels' differ. Now as a result i have values exceeding 40 as N/A. 
> 
> On Sun, Jun 26, 2016 at 3:25 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Jun 25, 2016, at 12:05 PM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> >
> > Dear Team,
> >
> > Please see the code below:
> >
> > Age1<- cut(desc$Age, breaks = c(20,30,40,Inf),labels = c("Low","Mid","Top"))
> 
> Try instead:
> 
> Age1<- cut(desc$Age, breaks = c(-Inf, 20,30,40,Inf),labels = c("Low","Mid","Top"))
> 
> Do note that values that are <= 20 will be in the lowest category. (You wrote only <20 whereas values of 20 would have not been in any interval.)  The cut function also has a use.lowest argument, whose actions I don't fully understand but I usually set to to TRUE whereas is default is FALSE. I prefer the Hmisc::cut2 functions because its defaults mirror my usual interests. Like cut2, the findInterval function has closed intervals on the left.
> 
> > here i am creating three categories as mentioned from the age var from desc
> > data set.
> > All the values are set correctly however the values which are below 20 are
> > set to NA.
> > Is there anything i am doing incorrect.
> >
> > Regards, Shivi
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From jsorkin at grecc.umaryland.edu  Sun Jun 26 05:00:17 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 25 Jun 2016 23:00:17 -0400
Subject: [R] function for over dispersed poisson regression in the setting
 of a random effects model
Message-ID: <576F0D01020000CB00158F47@smtp.medicine.umaryland.edu>

Is there a function that will run a model appropriate for over dispersed data (such as a negative binomial or quasipoisson)
with a random effects (or mixed effects) model in R? GLMER will not accept:  
family=quasipoisson(link="log") or
family=negbinomial(link="log") 
 
I want to run something like the following:
fit0 <- glmer(Fall ~ Group+(1|PID)+offset(log(TimeYrs)),family=quasipoisson(link="log"),data=data)
Thank  you
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From pdalgd at gmail.com  Sun Jun 26 08:39:27 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 26 Jun 2016 08:39:27 +0200
Subject: [R] strange behavior of lchoose in combinatorics problem
In-Reply-To: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>
References: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>
Message-ID: <0BC53929-B722-4FBD-A278-1AD8B636130C@gmail.com>


> On 25 Jun 2016, at 16:13 , Gon?alo Ferraz <gferraz29 at gmail.com> wrote:
> 
> PROBLEM: the sum of the probabilities in lpvec should be <=1, but it is not. The sum is something on the order of 1.48e-13. 

Um, in which sense is 1.48e-13 not <=1 ???

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From stefanML at collocations.de  Sun Jun 26 14:35:15 2016
From: stefanML at collocations.de (Stefan Evert)
Date: Sun, 26 Jun 2016 14:35:15 +0200
Subject: [R] strange behavior of lchoose in combinatorics problem
In-Reply-To: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>
References: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>
Message-ID: <58375192-5926-43BF-950B-281B52D44DC3@collocations.de>

Why do you want to do this? Why not simply use Fisher's exact test?

N <- 2178
N1 <- 165
N2 <- 331
J <- 97
ct <- rbind(c(J, N1-J), c(N2-J, N-N1-N2+J))
fisher.test(ct)

Background explanation:

 - Your formula computes the log hypergeometric probability for a contingency table as ct above, but with k instead of J.

 - It does so in an unnecessarily complicated way: three terms would be enough (cf. the equation at http://www.collocations.de/AM/section3.html; with C1=N1, C2=N-C1, R1=N2).

 - If you want to test for a positive association between the two animals, you should be adding up the probabilities for k >= J to obtain a p-value, rather than k <= J (what would this sum of probabilities tell you?).

 - lpvec doesn't contain probabilities, but log probabilities. What sense would there be in adding those up? In any case, you should obtain a negative value because all the individual logs are negative.

Best,
Stefan



> On 25 Jun 2016, at 16:13, Gon?alo Ferraz <gferraz29 at gmail.com> wrote:
> 
> I am working on interactions between animals, studying whether animal 1 is attracted to animal 2 (or vice-versa). I looked for the two animals in N=2178 sampling occasions, finding animal 1 a total of N1=165 times, and animal 2 a total of N2=331 times. In J=97 occasions, I saw both animals at the same time. 
> 
> The more frequently I see the two animals in the same sampling occasion, the more I will believe that they are attracted to each other. Therefore, I want to calculate the probability of finding J<=97 when the two animals are moving around independently of each other. The higher this probability, the stronger the attraction.
> 
> Following Veech (Journal of Biogeography 2014, 41: 1029-1035) I compute the log probability of obtaining a number n of encounters between animals as ?lpn? in the function lveech:
> 


From rezvan.hatami_iut at yahoo.com  Sun Jun 26 12:23:19 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Sun, 26 Jun 2016 10:23:19 +0000 (UTC)
Subject: [R] How I can calculate the value of response variable
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>

?How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?


Cheers
Rezvan Hatami
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 26 17:20:48 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 26 Jun 2016 08:20:48 -0700
Subject: [R] How I can calculate the value of response variable
In-Reply-To: <1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6958432E-7840-4810-8A4D-C181236BF6DD@comcast.net>


> On Jun 26, 2016, at 3:23 AM, rezvan hatami via R-help <r-help at r-project.org> wrote:
> 
>  How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?
> 

   You should explain in more detail why the answer to this question is not just the `lm` function. See:

?lm
?predict.lm

    That would deliver (after suitable invocation of the `predict` function) not be the "value of the response variable" (since that would just be the values in your data), but rather the conditional expectation of the response variable given the values of the predictors.


> 
> Cheers
> Rezvan Hatami
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sun Jun 26 17:22:18 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 26 Jun 2016 08:22:18 -0700
Subject: [R] How I can calculate the value of response variable
In-Reply-To: <1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <79C62837-651F-4C7B-BD4E-D7FBFB8D1938@dcn.davis.ca.us>

Can you provide an example of what you mean?  This is not a statistical theory forum, so you should be able to describe the calculation clearly if you want help translating it into R.

Also, read the Posting Guide, which among other things warns you that this is a plain text mailing list so your HTML email is going to be damaged and we may not be able to understand your question if you don't post plain text. 
-- 
Sent from my phone. Please excuse my brevity.

On June 26, 2016 3:23:19 AM PDT, rezvan hatami via R-help <r-help at r-project.org> wrote:
>?How I can calculate the value of response variable in a linear model
>of a matrix of several variables?Can somebody please answer me?
>
>
>Cheers
>Rezvan Hatami
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lars52r at gmail.com  Sun Jun 26 18:27:18 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Sun, 26 Jun 2016 12:27:18 -0400
Subject: [R] Help please with error from nnet::multinom
Message-ID: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>

Hello,

I'd appreciate your help in spotting the reason for the error and warning
messages below.

library(nnet)
set.seed(1)
ysim <- gl(3, 100)
y <- model.matrix(~ysim -1)
X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)

fit <- multinom(y ~ X, trace = FALSE)
pred <- predict(fit, X_new, type = "probs")

Error in predict.multinom(fit, X_new, type = "probs") :
  NAs are not allowed in subscripted assignments
In addition: Warning message:
  'newdata' had 200 rows but variables found have 300 rows

Thanks,
Lars.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Jun 26 19:05:00 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 26 Jun 2016 10:05:00 -0700
Subject: [R] Help please with error from nnet::multinom
In-Reply-To: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
References: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
Message-ID: <CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>

Well, for one thing, there is no "probs" method for predict.nnet, at
least in my version: nnet_7.3-12

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 26, 2016 at 9:27 AM, Lars Bishop <lars52r at gmail.com> wrote:
> Hello,
>
> I'd appreciate your help in spotting the reason for the error and warning
> messages below.
>
> library(nnet)
> set.seed(1)
> ysim <- gl(3, 100)
> y <- model.matrix(~ysim -1)
> X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
> X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
>
> fit <- multinom(y ~ X, trace = FALSE)
> pred <- predict(fit, X_new, type = "probs")
>
> Error in predict.multinom(fit, X_new, type = "probs") :
>   NAs are not allowed in subscripted assignments
> In addition: Warning message:
>   'newdata' had 200 rows but variables found have 300 rows
>
> Thanks,
> Lars.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lars52r at gmail.com  Sun Jun 26 20:32:41 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Sun, 26 Jun 2016 14:32:41 -0400
Subject: [R] Help please with error from nnet::multinom
In-Reply-To: <CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>
References: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
	<CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>
Message-ID: <CAO7OmOgf=mO3hB6+_21X3UK0mKzO=X5jAxf=oJOE1zE50CBaug@mail.gmail.com>

Thanks Bert.

But I it doesn't complain when predict is used on X instead of X_new
(using nnet_7.3-12), which is even more puzzling to me:

pred <- predict(fit, X, type = "probs")
head(pred)
ysim1     ysim2     ysim3
1 0.3059421 0.3063284 0.3877295
2 0.3200219 0.3202551 0.3597230
3 0.3452414 0.3451460 0.3096125
4 0.3827077 0.3819603 0.2353320
5 0.2973288 0.2977994 0.4048718
6 0.3817027 0.3809759 0.2373214

Thanks again,
Lars.


On Sun, Jun 26, 2016 at 1:05 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Well, for one thing, there is no "probs" method for predict.nnet, at
> least in my version: nnet_7.3-12
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Jun 26, 2016 at 9:27 AM, Lars Bishop <lars52r at gmail.com> wrote:
> > Hello,
> >
> > I'd appreciate your help in spotting the reason for the error and warning
> > messages below.
> >
> > library(nnet)
> > set.seed(1)
> > ysim <- gl(3, 100)
> > y <- model.matrix(~ysim -1)
> > X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
> > X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
> >
> > fit <- multinom(y ~ X, trace = FALSE)
> > pred <- predict(fit, X_new, type = "probs")
> >
> > Error in predict.multinom(fit, X_new, type = "probs") :
> >   NAs are not allowed in subscripted assignments
> > In addition: Warning message:
> >   'newdata' had 200 rows but variables found have 300 rows
> >
> > Thanks,
> > Lars.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 26 21:14:27 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 26 Jun 2016 12:14:27 -0700
Subject: [R] Help please with error from nnet::multinom
In-Reply-To: <CAO7OmOgf=mO3hB6+_21X3UK0mKzO=X5jAxf=oJOE1zE50CBaug@mail.gmail.com>
References: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
	<CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>
	<CAO7OmOgf=mO3hB6+_21X3UK0mKzO=X5jAxf=oJOE1zE50CBaug@mail.gmail.com>
Message-ID: <AB476DF0-FFE1-49A5-B36D-F9F545F2C20F@comcast.net>


> On Jun 26, 2016, at 11:32 AM, Lars Bishop <lars52r at gmail.com> wrote:
> 
> Thanks Bert.
> 
> But I it doesn't complain when predict is used on X instead of X_new
> (using nnet_7.3-12), which is even more puzzling to me:
> 
> pred <- predict(fit, X, type = "probs")

Indeed: There is a predict.multinom function and it does have 'probs' as an acceptable argument to type:

I got success (or at least an absence of an error message) with:

#----------
 X <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3))
 X_new <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3))
 str(X)

'data.frame':	300 obs. of  3 variables:
 $ X1: num  0.797 1.116 1.719 2.725 0.605 ...
 $ X2: num  0.797 1.116 1.719 2.725 0.605 ...
 $ X3: num  0.797 1.116 1.719 2.725 0.605 ...

 fit <- multinom(y ~ ., data=X, trace = FALSE)
 pred <- predict(fit, setNames(X_new, names(X)), type = "probs")

> head(pred)
      ysim1     ysim2     ysim3
1 0.3519378 0.3517418 0.2963204
2 0.3135513 0.3138573 0.3725915
3 0.3603779 0.3600461 0.2795759
4 0.3572297 0.3569498 0.2858206
5 0.3481512 0.3480128 0.3038360
6 0.3813310 0.3806118 0.2380572

#------------


> head(pred)
> ysim1     ysim2     ysim3
> 1 0.3059421 0.3063284 0.3877295
> 2 0.3200219 0.3202551 0.3597230
> 3 0.3452414 0.3451460 0.3096125
> 4 0.3827077 0.3819603 0.2353320
> 5 0.2973288 0.2977994 0.4048718
> 6 0.3817027 0.3809759 0.2373214
> 
> Thanks again,
> Lars.
> 
> 
> On Sun, Jun 26, 2016 at 1:05 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> Well, for one thing, there is no "probs" method for predict.nnet, at
>> least in my version: nnet_7.3-12
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Sun, Jun 26, 2016 at 9:27 AM, Lars Bishop <lars52r at gmail.com> wrote:
>>> Hello,
>>> 
>>> I'd appreciate your help in spotting the reason for the error and warning
>>> messages below.
>>> 
>>> library(nnet)
>>> set.seed(1)
>>> ysim <- gl(3, 100)
>>> y <- model.matrix(~ysim -1)
>>> X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
>>> X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
>>> 
>>> fit <- multinom(y ~ X, trace = FALSE)
>>> pred <- predict(fit, X_new, type = "probs")
>>> 
>>> Error in predict.multinom(fit, X_new, type = "probs") :
>>>  NAs are not allowed in subscripted assignments
>>> In addition: Warning message:
>>>  'newdata' had 200 rows but variables found have 300 rows
>>> 
>>> Thanks,
>>> Lars.
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sun Jun 26 21:32:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 26 Jun 2016 12:32:43 -0700
Subject: [R] Help please with error from nnet::multinom
In-Reply-To: <AB476DF0-FFE1-49A5-B36D-F9F545F2C20F@comcast.net>
References: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
	<CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>
	<CAO7OmOgf=mO3hB6+_21X3UK0mKzO=X5jAxf=oJOE1zE50CBaug@mail.gmail.com>
	<AB476DF0-FFE1-49A5-B36D-F9F545F2C20F@comcast.net>
Message-ID: <CAGxFJbSRrB0wXQNy2-FkwZ7Q=Px_bXebDEw9yabX=SHEPBVV9g@mail.gmail.com>

Thanks, David.

That is very interesting, because ?multinom says that the value is:

"A nnet object with additional components: ..."

Of course I could have checked methods(predict), but I just took the
Help file at its word. Should it not be revised to say explicitly:

"An object of class 'multinom', which is a nnet object ... "

??

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 26, 2016 at 12:14 PM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
>> On Jun 26, 2016, at 11:32 AM, Lars Bishop <lars52r at gmail.com> wrote:
>>
>> Thanks Bert.
>>
>> But I it doesn't complain when predict is used on X instead of X_new
>> (using nnet_7.3-12), which is even more puzzling to me:
>>
>> pred <- predict(fit, X, type = "probs")
>
> Indeed: There is a predict.multinom function and it does have 'probs' as an acceptable argument to type:
>
> I got success (or at least an absence of an error message) with:
>
> #----------
>  X <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3))
>  X_new <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3))
>  str(X)
>
> 'data.frame':   300 obs. of  3 variables:
>  $ X1: num  0.797 1.116 1.719 2.725 0.605 ...
>  $ X2: num  0.797 1.116 1.719 2.725 0.605 ...
>  $ X3: num  0.797 1.116 1.719 2.725 0.605 ...
>
>  fit <- multinom(y ~ ., data=X, trace = FALSE)
>  pred <- predict(fit, setNames(X_new, names(X)), type = "probs")
>
>> head(pred)
>       ysim1     ysim2     ysim3
> 1 0.3519378 0.3517418 0.2963204
> 2 0.3135513 0.3138573 0.3725915
> 3 0.3603779 0.3600461 0.2795759
> 4 0.3572297 0.3569498 0.2858206
> 5 0.3481512 0.3480128 0.3038360
> 6 0.3813310 0.3806118 0.2380572
>
> #------------
>
>
>> head(pred)
>> ysim1     ysim2     ysim3
>> 1 0.3059421 0.3063284 0.3877295
>> 2 0.3200219 0.3202551 0.3597230
>> 3 0.3452414 0.3451460 0.3096125
>> 4 0.3827077 0.3819603 0.2353320
>> 5 0.2973288 0.2977994 0.4048718
>> 6 0.3817027 0.3809759 0.2373214
>>
>> Thanks again,
>> Lars.
>>
>>
>> On Sun, Jun 26, 2016 at 1:05 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>>> Well, for one thing, there is no "probs" method for predict.nnet, at
>>> least in my version: nnet_7.3-12
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sun, Jun 26, 2016 at 9:27 AM, Lars Bishop <lars52r at gmail.com> wrote:
>>>> Hello,
>>>>
>>>> I'd appreciate your help in spotting the reason for the error and warning
>>>> messages below.
>>>>
>>>> library(nnet)
>>>> set.seed(1)
>>>> ysim <- gl(3, 100)
>>>> y <- model.matrix(~ysim -1)
>>>> X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
>>>> X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
>>>>
>>>> fit <- multinom(y ~ X, trace = FALSE)
>>>> pred <- predict(fit, X_new, type = "probs")
>>>>
>>>> Error in predict.multinom(fit, X_new, type = "probs") :
>>>>  NAs are not allowed in subscripted assignments
>>>> In addition: Warning message:
>>>>  'newdata' had 200 rows but variables found have 300 rows
>>>>
>>>> Thanks,
>>>> Lars.
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From lars52r at gmail.com  Sun Jun 26 21:39:12 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Sun, 26 Jun 2016 15:39:12 -0400
Subject: [R] Help please with error from nnet::multinom
In-Reply-To: <AB476DF0-FFE1-49A5-B36D-F9F545F2C20F@comcast.net>
References: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
	<CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>
	<CAO7OmOgf=mO3hB6+_21X3UK0mKzO=X5jAxf=oJOE1zE50CBaug@mail.gmail.com>
	<AB476DF0-FFE1-49A5-B36D-F9F545F2C20F@comcast.net>
Message-ID: <CAO7OmOiSov+k1s--pipLoQXHa2s2MjF+2tfceOeQKbhZ1R5bAA@mail.gmail.com>

Many thanks David. That works. Looks then this error will always occur in
predict.multinom whenever the data argument is missing in the mutlinom fit,
but the data argument is optional as per documentation.

Best,
Lars.

On Sun, Jun 26, 2016 at 3:14 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jun 26, 2016, at 11:32 AM, Lars Bishop <lars52r at gmail.com> wrote:
> >
> > Thanks Bert.
> >
> > But I it doesn't complain when predict is used on X instead of X_new
> > (using nnet_7.3-12), which is even more puzzling to me:
> >
> > pred <- predict(fit, X, type = "probs")
>
> Indeed: There is a predict.multinom function and it does have 'probs' as
> an acceptable argument to type:
>
> I got success (or at least an absence of an error message) with:
>
> #----------
>  X <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3))
>  X_new <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 200, ncol =
> 3))
>  str(X)
>
> 'data.frame':   300 obs. of  3 variables:
>  $ X1: num  0.797 1.116 1.719 2.725 0.605 ...
>  $ X2: num  0.797 1.116 1.719 2.725 0.605 ...
>  $ X3: num  0.797 1.116 1.719 2.725 0.605 ...
>
>  fit <- multinom(y ~ ., data=X, trace = FALSE)
>  pred <- predict(fit, setNames(X_new, names(X)), type = "probs")
>
> > head(pred)
>       ysim1     ysim2     ysim3
> 1 0.3519378 0.3517418 0.2963204
> 2 0.3135513 0.3138573 0.3725915
> 3 0.3603779 0.3600461 0.2795759
> 4 0.3572297 0.3569498 0.2858206
> 5 0.3481512 0.3480128 0.3038360
> 6 0.3813310 0.3806118 0.2380572
>
> #------------
>
>
> > head(pred)
> > ysim1     ysim2     ysim3
> > 1 0.3059421 0.3063284 0.3877295
> > 2 0.3200219 0.3202551 0.3597230
> > 3 0.3452414 0.3451460 0.3096125
> > 4 0.3827077 0.3819603 0.2353320
> > 5 0.2973288 0.2977994 0.4048718
> > 6 0.3817027 0.3809759 0.2373214
> >
> > Thanks again,
> > Lars.
> >
> >
> > On Sun, Jun 26, 2016 at 1:05 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> Well, for one thing, there is no "probs" method for predict.nnet, at
> >> least in my version: nnet_7.3-12
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Sun, Jun 26, 2016 at 9:27 AM, Lars Bishop <lars52r at gmail.com> wrote:
> >>> Hello,
> >>>
> >>> I'd appreciate your help in spotting the reason for the error and
> warning
> >>> messages below.
> >>>
> >>> library(nnet)
> >>> set.seed(1)
> >>> ysim <- gl(3, 100)
> >>> y <- model.matrix(~ysim -1)
> >>> X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
> >>> X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
> >>>
> >>> fit <- multinom(y ~ X, trace = FALSE)
> >>> pred <- predict(fit, X_new, type = "probs")
> >>>
> >>> Error in predict.multinom(fit, X_new, type = "probs") :
> >>>  NAs are not allowed in subscripted assignments
> >>> In addition: Warning message:
> >>>  'newdata' had 200 rows but variables found have 300 rows
> >>>
> >>> Thanks,
> >>> Lars.
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 26 21:46:37 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 26 Jun 2016 12:46:37 -0700
Subject: [R] Help please with error from nnet::multinom
In-Reply-To: <CAO7OmOiSov+k1s--pipLoQXHa2s2MjF+2tfceOeQKbhZ1R5bAA@mail.gmail.com>
References: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
	<CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>
	<CAO7OmOgf=mO3hB6+_21X3UK0mKzO=X5jAxf=oJOE1zE50CBaug@mail.gmail.com>
	<AB476DF0-FFE1-49A5-B36D-F9F545F2C20F@comcast.net>
	<CAO7OmOiSov+k1s--pipLoQXHa2s2MjF+2tfceOeQKbhZ1R5bAA@mail.gmail.com>
Message-ID: <C9AAEC05-4066-448E-97FD-C4646F82C16E@comcast.net>


> On Jun 26, 2016, at 12:39 PM, Lars Bishop <lars52r at gmail.com> wrote:
> 
> Many thanks David. That works. Looks then this error will always occur in predict.multinom whenever the data argument is missing in the mutlinom fit, but the data argument is optional as per documentation. 

I don't agree with that analysis. The problem occurs because of a mismatch of names in the new data argument. With your original code this runs without error:

pred <- predict(fit, setNames(data.frame(X_new),c("X1","X2","X3") ), type = "probs")

-- 
David.
> 
> Best,
> Lars.
> 
> On Sun, Jun 26, 2016 at 3:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Jun 26, 2016, at 11:32 AM, Lars Bishop <lars52r at gmail.com> wrote:
> >
> > Thanks Bert.
> >
> > But I it doesn't complain when predict is used on X instead of X_new
> > (using nnet_7.3-12), which is even more puzzling to me:
> >
> > pred <- predict(fit, X, type = "probs")
> 
> Indeed: There is a predict.multinom function and it does have 'probs' as an acceptable argument to type:
> 
> I got success (or at least an absence of an error message) with:
> 
> #----------
>  X <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3))
>  X_new <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3))
>  str(X)
> 
> 'data.frame':   300 obs. of  3 variables:
>  $ X1: num  0.797 1.116 1.719 2.725 0.605 ...
>  $ X2: num  0.797 1.116 1.719 2.725 0.605 ...
>  $ X3: num  0.797 1.116 1.719 2.725 0.605 ...
> 
>  fit <- multinom(y ~ ., data=X, trace = FALSE)
>  pred <- predict(fit, setNames(X_new, names(X)), type = "probs")
> 
> > head(pred)
>       ysim1     ysim2     ysim3
> 1 0.3519378 0.3517418 0.2963204
> 2 0.3135513 0.3138573 0.3725915
> 3 0.3603779 0.3600461 0.2795759
> 4 0.3572297 0.3569498 0.2858206
> 5 0.3481512 0.3480128 0.3038360
> 6 0.3813310 0.3806118 0.2380572
> 
> #------------
> 
> 
> > head(pred)
> > ysim1     ysim2     ysim3
> > 1 0.3059421 0.3063284 0.3877295
> > 2 0.3200219 0.3202551 0.3597230
> > 3 0.3452414 0.3451460 0.3096125
> > 4 0.3827077 0.3819603 0.2353320
> > 5 0.2973288 0.2977994 0.4048718
> > 6 0.3817027 0.3809759 0.2373214
> >
> > Thanks again,
> > Lars.
> >
> >
> > On Sun, Jun 26, 2016 at 1:05 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> >> Well, for one thing, there is no "probs" method for predict.nnet, at
> >> least in my version: nnet_7.3-12
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Sun, Jun 26, 2016 at 9:27 AM, Lars Bishop <lars52r at gmail.com> wrote:
> >>> Hello,
> >>>
> >>> I'd appreciate your help in spotting the reason for the error and warning
> >>> messages below.
> >>>
> >>> library(nnet)
> >>> set.seed(1)
> >>> ysim <- gl(3, 100)
> >>> y <- model.matrix(~ysim -1)
> >>> X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
> >>> X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
> >>>
> >>> fit <- multinom(y ~ X, trace = FALSE)
> >>> pred <- predict(fit, X_new, type = "probs")
> >>>
> >>> Error in predict.multinom(fit, X_new, type = "probs") :
> >>>  NAs are not allowed in subscripted assignments
> >>> In addition: Warning message:
> >>>  'newdata' had 200 rows but variables found have 300 rows
> >>>
> >>> Thanks,
> >>> Lars.
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From lars52r at gmail.com  Sun Jun 26 22:03:43 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Sun, 26 Jun 2016 16:03:43 -0400
Subject: [R] Help please with error from nnet::multinom
In-Reply-To: <C9AAEC05-4066-448E-97FD-C4646F82C16E@comcast.net>
References: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
	<CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>
	<CAO7OmOgf=mO3hB6+_21X3UK0mKzO=X5jAxf=oJOE1zE50CBaug@mail.gmail.com>
	<AB476DF0-FFE1-49A5-B36D-F9F545F2C20F@comcast.net>
	<CAO7OmOiSov+k1s--pipLoQXHa2s2MjF+2tfceOeQKbhZ1R5bAA@mail.gmail.com>
	<C9AAEC05-4066-448E-97FD-C4646F82C16E@comcast.net>
Message-ID: <CAO7OmOjwHqy3W7BwuaNqZygLnGjKUfXsaLQ0REpqxkTbRyEsmA@mail.gmail.com>

Thanks, David. Sorry, do you mean this?

library(nnet)
set.seed(1)
ysim <- gl(3, 100)
y <- model.matrix(~ysim -1)
X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
fit <- multinom(y ~ X, trace = FALSE)
pred <- predict(fit, setNames(data.frame(X_new),c("X1","X2","X3") ), type =
"probs")

Error in predict.multinom(fit, setNames(data.frame(X_new), c("X1", "X2",  :
                                                               NAs are not
allowed in subscripted assignments
                                                             In addition:
Warning message:
                                                               'newdata'
had 200 rows but variables found have 300 rows

On Sun, Jun 26, 2016 at 3:46 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jun 26, 2016, at 12:39 PM, Lars Bishop <lars52r at gmail.com> wrote:
> >
> > Many thanks David. That works. Looks then this error will always occur
> in predict.multinom whenever the data argument is missing in the mutlinom
> fit, but the data argument is optional as per documentation.
>
> I don't agree with that analysis. The problem occurs because of a mismatch
> of names in the new data argument. With your original code this runs
> without error:
>
> pred <- predict(fit, setNames(data.frame(X_new),c("X1","X2","X3") ), type
> = "probs")
>
> --
> David.
> >
> > Best,
> > Lars.
> >
> > On Sun, Jun 26, 2016 at 3:14 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Jun 26, 2016, at 11:32 AM, Lars Bishop <lars52r at gmail.com> wrote:
> > >
> > > Thanks Bert.
> > >
> > > But I it doesn't complain when predict is used on X instead of X_new
> > > (using nnet_7.3-12), which is even more puzzling to me:
> > >
> > > pred <- predict(fit, X, type = "probs")
> >
> > Indeed: There is a predict.multinom function and it does have 'probs' as
> an acceptable argument to type:
> >
> > I got success (or at least an absence of an error message) with:
> >
> > #----------
> >  X <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3))
> >  X_new <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 200, ncol =
> 3))
> >  str(X)
> >
> > 'data.frame':   300 obs. of  3 variables:
> >  $ X1: num  0.797 1.116 1.719 2.725 0.605 ...
> >  $ X2: num  0.797 1.116 1.719 2.725 0.605 ...
> >  $ X3: num  0.797 1.116 1.719 2.725 0.605 ...
> >
> >  fit <- multinom(y ~ ., data=X, trace = FALSE)
> >  pred <- predict(fit, setNames(X_new, names(X)), type = "probs")
> >
> > > head(pred)
> >       ysim1     ysim2     ysim3
> > 1 0.3519378 0.3517418 0.2963204
> > 2 0.3135513 0.3138573 0.3725915
> > 3 0.3603779 0.3600461 0.2795759
> > 4 0.3572297 0.3569498 0.2858206
> > 5 0.3481512 0.3480128 0.3038360
> > 6 0.3813310 0.3806118 0.2380572
> >
> > #------------
> >
> >
> > > head(pred)
> > > ysim1     ysim2     ysim3
> > > 1 0.3059421 0.3063284 0.3877295
> > > 2 0.3200219 0.3202551 0.3597230
> > > 3 0.3452414 0.3451460 0.3096125
> > > 4 0.3827077 0.3819603 0.2353320
> > > 5 0.2973288 0.2977994 0.4048718
> > > 6 0.3817027 0.3809759 0.2373214
> > >
> > > Thanks again,
> > > Lars.
> > >
> > >
> > > On Sun, Jun 26, 2016 at 1:05 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > >
> > >> Well, for one thing, there is no "probs" method for predict.nnet, at
> > >> least in my version: nnet_7.3-12
> > >>
> > >> Cheers,
> > >> Bert
> > >>
> > >>
> > >> Bert Gunter
> > >>
> > >> "The trouble with having an open mind is that people keep coming along
> > >> and sticking things into it."
> > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>
> > >>
> > >> On Sun, Jun 26, 2016 at 9:27 AM, Lars Bishop <lars52r at gmail.com>
> wrote:
> > >>> Hello,
> > >>>
> > >>> I'd appreciate your help in spotting the reason for the error and
> warning
> > >>> messages below.
> > >>>
> > >>> library(nnet)
> > >>> set.seed(1)
> > >>> ysim <- gl(3, 100)
> > >>> y <- model.matrix(~ysim -1)
> > >>> X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
> > >>> X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
> > >>>
> > >>> fit <- multinom(y ~ X, trace = FALSE)
> > >>> pred <- predict(fit, X_new, type = "probs")
> > >>>
> > >>> Error in predict.multinom(fit, X_new, type = "probs") :
> > >>>  NAs are not allowed in subscripted assignments
> > >>> In addition: Warning message:
> > >>>  'newdata' had 200 rows but variables found have 300 rows
> > >>>
> > >>> Thanks,
> > >>> Lars.
> > >>>
> > >>>        [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Jun 26 22:57:51 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 26 Jun 2016 13:57:51 -0700
Subject: [R] Help please with error from nnet::multinom
In-Reply-To: <CAO7OmOjwHqy3W7BwuaNqZygLnGjKUfXsaLQ0REpqxkTbRyEsmA@mail.gmail.com>
References: <CAO7OmOh0DLw-0Sf49QqRSt2vPPG-1kxFHAjy5d=14-T3GfcTuQ@mail.gmail.com>
	<CAGxFJbQ-=2Qy6-tK-ZB=Fe65K34dKGkTNXo+xPqLws9E9Dmrzw@mail.gmail.com>
	<CAO7OmOgf=mO3hB6+_21X3UK0mKzO=X5jAxf=oJOE1zE50CBaug@mail.gmail.com>
	<AB476DF0-FFE1-49A5-B36D-F9F545F2C20F@comcast.net>
	<CAO7OmOiSov+k1s--pipLoQXHa2s2MjF+2tfceOeQKbhZ1R5bAA@mail.gmail.com>
	<C9AAEC05-4066-448E-97FD-C4646F82C16E@comcast.net>
	<CAO7OmOjwHqy3W7BwuaNqZygLnGjKUfXsaLQ0REpqxkTbRyEsmA@mail.gmail.com>
Message-ID: <068E1723-A08A-441F-87DE-9A992FDC31B1@comcast.net>


> On Jun 26, 2016, at 1:03 PM, Lars Bishop <lars52r at gmail.com> wrote:
> 
> Thanks, David. Sorry, do you mean this?
> 
> library(nnet)
> set.seed(1)
> ysim <- gl(3, 100)
> y <- model.matrix(~ysim -1)
> X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
> X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
> fit <- multinom(y ~ X, trace = FALSE)
> pred <- predict(fit, setNames(data.frame(X_new),c("X1","X2","X3") ), type = "probs")
> 
> Error in predict.multinom(fit, setNames(data.frame(X_new), c("X1", "X2",  : 
>                                                                NAs are not allowed in subscripted assignments
>                                                              In addition: Warning message:
>                                                                'newdata' had 200 rows but variables found have 300 rows 

Apparently I mixed some of your original code with some of my newer code that created dataframes. Using `str(fit)` we see that the model object does recognize that the argument named "X" is a matrix although it also considers the 'coefnames' to be: chr [1:4] "(Intercept)" "X1" "X2" "X3"

The $ terms        :Classes 'terms', 'formula'  language y ~ X
  .. ..- attr(*, "variables")= language list(y, X)
  .. ..- attr(*, "factors")= int [1:2, 1] 0 1
  .. .. ..- attr(*, "dimnames")=List of 2
  .. .. .. ..$ : chr [1:2] "y" "X"
  .. .. .. ..$ : chr "X"
  .. ..- attr(*, "term.labels")= chr "X"
  .. ..- attr(*, "order")= int 1
  .. ..- attr(*, "intercept")= int 1
  .. ..- attr(*, "response")= int 1
  .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv> 
  .. ..- attr(*, "predvars")= language list(y, X)
  .. ..- attr(*, "dataClasses")= Named chr [1:2] "nmatrix.3" "nmatrix.3"
  .. .. ..- attr(*, "names")= chr [1:2] "y" "X"
 $ weights      : num [1:300, 1] 1 1 1 1 1 1 1 1 1 1 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:300] "1" "2" "3" "4" ...
  .. ..$ : NULL
 $ deviance     : num 653
 $ rank         : int 2
 $ lab          : chr [1:3] "ysim1" "ysim2" "ysim3"
 $ coefnames    : chr [1:4] "(Intercept)" "X1" "X2" "X3"
 $ vcoefnames   : chr [1:4] "(Intercept)" "X1" "X2" "X3"

I haven't found a newdata argument that It may be that is is so difficult to match the various assignments that predict.multinom cannot be convinced that a new argument has all the correct attributes. This is the code that is used:

else {
        newdata <- as.data.frame(newdata)
        rn <- row.names(newdata)
        Terms <- delete.response(object$terms)
        m <- model.frame(Terms, newdata, na.action = na.omit, 
            xlev = object$xlevels)
        if (!is.null(cl <- attr(Terms, "dataClasses"))) 
            .checkMFClasses(cl, m)
        keep <- match(row.names(m), rn)
        X <- model.matrix(Terms, m, contrasts = object$contrasts)
        Y1 <- predict.nnet(object, X)
        Y <- matrix(NA, nrow(newdata), ncol(Y1), dimnames = list(rn, 
            colnames(Y1)))
        Y[keep, ] <- Y1
    }

I failed with both these:

> str( setNames(as.data.frame(X_new),c("X1","X2","X3") ) )
'data.frame':	200 obs. of  3 variables:
 $ X1: num  2.021 0.285 1.478 1.385 1.126 ...
 $ X2: num  1.66 2.06 1.97 1.99 1.42 ...
 $ X3: num  1.977 0.555 2.863 2.694 2.831 ...

> str( data.matrix( setNames(as.data.frame(X_new),c("X1","X2","X3") ) ) )
 num [1:200, 1:3] 2.021 0.285 1.478 1.385 1.126 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:3] "X1" "X2" "X3"




> 
> On Sun, Jun 26, 2016 at 3:46 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Jun 26, 2016, at 12:39 PM, Lars Bishop <lars52r at gmail.com> wrote:
> >
> > Many thanks David. That works. Looks then this error will always occur in predict.multinom whenever the data argument is missing in the mutlinom fit, but the data argument is optional as per documentation.
> 
> I don't agree with that analysis. The problem occurs because of a mismatch of names in the new data argument. With your original code this runs without error:
> 
> pred <- predict(fit, setNames(data.frame(X_new),c("X1","X2","X3") ), type = "probs")
> 
> --
> David.
> >
> > Best,
> > Lars.
> >
> > On Sun, Jun 26, 2016 at 3:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Jun 26, 2016, at 11:32 AM, Lars Bishop <lars52r at gmail.com> wrote:
> > >
> > > Thanks Bert.
> > >
> > > But I it doesn't complain when predict is used on X instead of X_new
> > > (using nnet_7.3-12), which is even more puzzling to me:
> > >
> > > pred <- predict(fit, X, type = "probs")
> >
> > Indeed: There is a predict.multinom function and it does have 'probs' as an acceptable argument to type:
> >
> > I got success (or at least an absence of an error message) with:
> >
> > #----------
> >  X <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3))
> >  X_new <- data.frame(matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3))
> >  str(X)
> >
> > 'data.frame':   300 obs. of  3 variables:
> >  $ X1: num  0.797 1.116 1.719 2.725 0.605 ...
> >  $ X2: num  0.797 1.116 1.719 2.725 0.605 ...
> >  $ X3: num  0.797 1.116 1.719 2.725 0.605 ...
> >
> >  fit <- multinom(y ~ ., data=X, trace = FALSE)
> >  pred <- predict(fit, setNames(X_new, names(X)), type = "probs")
> >
> > > head(pred)
> >       ysim1     ysim2     ysim3
> > 1 0.3519378 0.3517418 0.2963204
> > 2 0.3135513 0.3138573 0.3725915
> > 3 0.3603779 0.3600461 0.2795759
> > 4 0.3572297 0.3569498 0.2858206
> > 5 0.3481512 0.3480128 0.3038360
> > 6 0.3813310 0.3806118 0.2380572
> >
> > #------------
> >
> >
> > > head(pred)
> > > ysim1     ysim2     ysim3
> > > 1 0.3059421 0.3063284 0.3877295
> > > 2 0.3200219 0.3202551 0.3597230
> > > 3 0.3452414 0.3451460 0.3096125
> > > 4 0.3827077 0.3819603 0.2353320
> > > 5 0.2973288 0.2977994 0.4048718
> > > 6 0.3817027 0.3809759 0.2373214
> > >
> > > Thanks again,
> > > Lars.
> > >
> > >
> > > On Sun, Jun 26, 2016 at 1:05 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > >> Well, for one thing, there is no "probs" method for predict.nnet, at
> > >> least in my version: nnet_7.3-12
> > >>
> > >> Cheers,
> > >> Bert
> > >>
> > >>
> > >> Bert Gunter
> > >>
> > >> "The trouble with having an open mind is that people keep coming along
> > >> and sticking things into it."
> > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>
> > >>
> > >> On Sun, Jun 26, 2016 at 9:27 AM, Lars Bishop <lars52r at gmail.com> wrote:
> > >>> Hello,
> > >>>
> > >>> I'd appreciate your help in spotting the reason for the error and warning
> > >>> messages below.
> > >>>
> > >>> library(nnet)
> > >>> set.seed(1)
> > >>> ysim <- gl(3, 100)
> > >>> y <- model.matrix(~ysim -1)
> > >>> X <- matrix( 3 * runif(length(ysim)), nrow = 300, ncol = 3)
> > >>> X_new <- matrix( 3 * runif(length(ysim)), nrow = 200, ncol = 3)
> > >>>
> > >>> fit <- multinom(y ~ X, trace = FALSE)
> > >>> pred <- predict(fit, X_new, type = "probs")
> > >>>
> > >>> Error in predict.multinom(fit, X_new, type = "probs") :
> > >>>  NAs are not allowed in subscripted assignments
> > >>> In addition: Warning message:
> > >>>  'newdata' had 200 rows but variables found have 300 rows
> > >>>
> > >>> Thanks,
> > >>> Lars.
> > >>>
> > >>>        [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Mon Jun 27 00:07:07 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 27 Jun 2016 08:07:07 +1000
Subject: [R] How I can calculate the value of response variable
In-Reply-To: <1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fVKf2o6-1F9Gvv2GjqHvAcJYOgV8v0Mmp-XPqak0LWi2A@mail.gmail.com>

Hi Rezvan,
I'll take a guess that you have been presented with a matrix of
coefficients. You probably know that a linear model is going to look
something like this:

Y = ax1 + bx2 + cx3 ...

So I will further guess that you want to infer a distribution of Y
(the response variable) from more than one set of coefficients. If my
guesses are correct, then you should be able to send an example that
shows what you have and what you want to get.

Jim


On Sun, Jun 26, 2016 at 8:23 PM, rezvan hatami via R-help
<r-help at r-project.org> wrote:
>  How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?
>
>
> Cheers
> Rezvan Hatami
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From frainj at gmail.com  Mon Jun 27 02:03:43 2016
From: frainj at gmail.com (John C Frain)
Date: Mon, 27 Jun 2016 01:03:43 +0100
Subject: [R] Error using function seas()
In-Reply-To: <d8854a18-e1af-c789-e894-f047155080ad@auckland.ac.nz>
References: <31e8e0312b5948bd97a799f164bab582@ex13-live-mbn1.ad.kent.ac.uk>
	<d8854a18-e1af-c789-e894-f047155080ad@auckland.ac.nz>
Message-ID: <CAHrK514n3OmAycL+R9bfz0mgiojunjDRJxWJuu78KLzth8pATA@mail.gmail.com>

Check the manuals for the x13 program. There used to be a maximum length of
series that earlier versions of the program could manage. Your series is
almost certainly to long for x13. There is no way to change that in R.

This is identical to the question that you previously asked and you still
have not addressed the problem of making your example *reproducible*.

cheers,

Rolf Turner

On 26/06/16 01:52, T.Riedle wrote:

> Dear all,
>
> I am trying to run the seas() function. If I run the seas() function as
> shown below I get following errors. What is wrong with my code?
>
>
> data<-Shiller_data[,2]
>>
>
> ts<-ts(data,start=c(1871, 01), end=c(2015, 12), frequency=12)
>>
>
> ts
>>
>
>          Jan     Feb     Mar     Apr     May     Jun     Jul     Aug
>  Sep     Oct
>
> 1871    4.44    4.50    4.61    4.74    4.86    4.82    4.73    4.79
> 4.84    4.59
>
> 1872    4.86    4.88    5.04    5.18    5.18    5.13    5.10    5.04
> 4.95    4.97
>
> 1873    5.11    5.15    5.11    5.04    5.05    4.98    4.97    4.97
> 4.59    4.19
>
> 1874    4.66    4.80    4.73    4.60    4.48    4.46    4.46    4.47
> 4.54    4.53
>
> 1875    4.54    4.53    4.59    4.65    4.47    4.38    4.39    4.41
> 4.37    4.30
>
> 1876    4.46    4.52    4.51    4.34    4.18    4.15    4.10    3.93
> 3.69    3.67
>
> 1877    3.55    3.34    3.17    2.94    2.94    2.73    2.85    3.05
> 3.24    3.31
>
> 1878    3.25    3.18    3.24    3.33    3.34    3.41    3.48    3.45
> 3.52    3.48
>
> 1879    3.58    3.71    3.65    3.77    3.94    3.96    4.04    4.07
> 4.22    4.68
>
> 1880    5.11    5.20    5.30    5.18    4.77    4.79    5.01    5.19
> 5.18    5.33
>
> 1881    6.19    6.17    6.24    6.22    6.50    6.58    6.35    6.20
> 6.25    6.15
>
> 1882    5.92    5.79    5.78    5.78    5.71    5.68    6.00    6.18
> 6.24    6.07
>
> 1883    5.81    5.68    5.75    5.87    5.77    5.82    5.73    5.47
> 5.53    5.38
>
> 1884    5.18    5.32    5.30    5.06    4.65    4.46    4.46    4.74
> 4.59    4.44
>
> 1885    4.24    4.37    4.38    4.37    4.32    4.30    4.46    4.71
> 4.65    4.92
>
> 1886    5.20    5.30    5.19    5.12    5.02    5.25    5.33    5.37
> 5.51    5.65
>
> 1887    5.58    5.54    5.67    5.80    5.90    5.73    5.59    5.45
> 5.38    5.20
>
> 1888    5.31    5.28    5.08    5.10    5.17    5.01    5.14    5.25
> 5.38    5.35
>
> 1889    5.24    5.30    5.19    5.18    5.32    5.41    5.30    5.37
> 5.50    5.40
>
> 1890    5.38    5.32    5.28    5.39    5.62    5.58    5.54    5.41
> 5.32    5.08
>
> 1891    4.84    4.90    4.81    4.97    4.95    4.85    4.77    4.93
> 5.33    5.33
>
> 1892    5.51    5.52    5.58    5.57    5.57    5.54    5.54    5.62
> 5.48    5.59
>
> 1893    5.61    5.51    5.31    5.31    4.84    4.61    4.18    4.08
> 4.37    4.50
>
> 1894    4.32    4.38    4.51    4.57    4.40    4.34    4.25    4.41
> 4.48    4.34
>
> 1895    4.25    4.19    4.19    4.37    4.61    4.70    4.72    4.79
> 4.82    4.75
>
> 1896    4.27    4.45    4.38    4.42    4.40    4.32    4.04    3.81
> 4.01    4.10
>
> 1897    4.22    4.18    4.19    4.06    4.08    4.27    4.46    4.75
> 4.98    4.82
>
> 1898    4.88    4.87    4.65    4.57    4.87    5.06    5.08    5.27
> 5.26    5.15
>
> 1899    6.08    6.31    6.40    6.48    6.21    6.07    6.28    6.44
> 6.37    6.34
>
> 1900    6.10    6.21    6.26    6.34    6.04    5.86    5.86    5.94
> 5.80    6.01
>
>
>
> SP <- seas(ts)
>>
>
> Error: X-13 run failed
>
>
>
> Errors:
>
> - Problem reading
> C:\Users\tr206\AppData\Local\Temp\Rtmp4Qtc08\x1312202a115399/data.dta. Too
>
>   many observations in file.
>
> - Problem reading
> C:\Users\tr206\AppData\Local\Temp\Rtmp4Qtc08\x1312202a115399/data.dta. Check
>
>   your input file and format.
>
> - Time series could not be read due to previously found errors
>
> - Specify series before user-defined adjustments
>
> - Need to specify a series to identify outliers
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rezvan.hatami_iut at yahoo.com  Mon Jun 27 02:22:35 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Mon, 27 Jun 2016 00:22:35 +0000 (UTC)
Subject: [R] Fw:  How I can calculate the value of response variable
In-Reply-To: <1748641463.1489716.1466984687135.JavaMail.yahoo@mail.yahoo.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
	<6958432E-7840-4810-8A4D-C181236BF6DD@comcast.net>
	<1748641463.1489716.1466984687135.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1066443174.1505044.1466986955741.JavaMail.yahoo@mail.yahoo.com>



     
----- Forwarded Message -----
 From: rezvan hatami <rezvan.hatami_iut at yahoo.com>
 To: David Winsemius <dwinsemius at comcast.net> 
 Sent: Monday, 27 June 2016, 9:44
 Subject: Re: [R] How I can calculate the value of response variable
   
Dear DavidThank you for your answer. My equation is:
nitrate=0.9*fertilizer-0.02*flowrate+0.5*rain
my matrix:
| season | site | nitrate | fertilizer1 | flow rate |
| spring | site1 | 0.2 | 2 | 1 |
| spring | site2 | 1.2 | 3 | 1 |
| spring | site3 | 2.2 | 5 | 2 |
| summer | site1 | 3.2 | 1 | 2 |
| summer | site2 | 4.2 | 2 | 2 |
| summer | site3 | 5.2 | 3 | 2 |
| fall | site1 | 6.2 | 4 | 3 |
| fall | site2 | 7.2 | 5 | 3 |
| fall | site3 | 8.2 | 6 | 3 |
| winter | site1 | 9.2 | 4 | 4 |
| winter | site2 | 10.2 | 8 | 4 |
| winter | site3 | 11.2 | 9 | 4 |


I would like to know, what will be the values for variable "nitrate" if I divide the values of fertilizer by half and change the equation to:
nitrate=0.9*fertilizer2-0.02*flowrate+0.5*rain

in a matrix like:

| season | site | nitrate | fertilizer2 | flow rate |
| spring | site1 | 0.2 | 1 | 1 |
| spring | site2 | 1.2 | 1.5 | 1 |
| spring | site3 | 2.2 | 2.5 | 2 |
| summer | site1 | 3.2 | 0.5 | 2 |
| summer | site2 | 4.2 | 1 | 2 |
| summer | site3 | 5.2 | 1.5 | 2 |
| fall | site1 | 6.2 | 2 | 3 |
| fall | site2 | 7.2 | 2.5 | 3 |
| fall | site3 | 8.2 | 3 | 3 |
| winter | site1 | 9.2 | 2 | 4 |
| winter | site2 | 10.2 | 4 | 4 |
| winter | site3 | 11.2 | 4.5 | 4 |


Would you please tell me how I can do this in R?
Cheers
Rezvan
      From: David Winsemius <dwinsemius at comcast.net>
 To: rezvan hatami <rezvan.hatami_iut at yahoo.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org>
 Sent: Monday, 27 June 2016, 1:20
 Subject: Re: [R] How I can calculate the value of response variable
  

> On Jun 26, 2016, at 3:23 AM, rezvan hatami via R-help <r-help at r-project.org> wrote:
> 
>? How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?
> 

? You should explain in more detail why the answer to this question is not just the `lm` function. See:

?lm
?predict.lm

? ? That would deliver (after suitable invocation of the `predict` function) not be the "value of the response variable" (since that would just be the values in your data), but rather the conditional expectation of the response variable given the values of the predictors.


> 
> Cheers
> Rezvan Hatami
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


   

  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun 27 02:28:48 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 27 Jun 2016 10:28:48 +1000
Subject: [R] How I can calculate the value of response variable
In-Reply-To: <26756506.1552457.1466984626257.JavaMail.yahoo@mail.yahoo.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fVKf2o6-1F9Gvv2GjqHvAcJYOgV8v0Mmp-XPqak0LWi2A@mail.gmail.com>
	<26756506.1552457.1466984626257.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fV+r7X9x5mHHpxTwmO0bo9Vp=ZWDUqjtBJbQWN=Seg4TQ@mail.gmail.com>

Hi Rezvan,
This looks like a simple problem of solving linear equations (and very much
like a homework exercise). Therefore I won't actually give you the answer,
but suggest the steps for the solution. First you have to get the data into
R, so here is one way:

rhdat<-read.table(text="season,site,nitrate,fertilizer1,flowrate
spring,site1,0.2,2,1
spring,site2,1.2,3,1
spring,site3,2.2,5,2
summer,site1,3.2,1,2
summer,site2,4.2,2,2
summer,site3,5.2,3,2
fall,site1,6.2,4,3
fall,site2,7.2,5,3
fall,site3,8.2,6,3
winter,site1,9.2,4,4
winter,site2,10.2,8,4
winter,site3,11.2,9,4",sep=",",header=TRUE)

You now have a data frame (rhdat) containing the values in your table.

1) calculate values for rain, which are missing from the table, e.g.

rhdat$rain<-2*(rhdat$nitrate-0.9*rhdat$fertilizer+0.02*rhdat$flowrate)

the above is an R expression to calculate the values for rain.

2) You may want explicitly calculate new values for rhdat$fertilizer, and
you have indicated that you already know how to do that. The above should
give you enough information about R syntax to translate the simple equation.

3) Now calculate new values for nitrate based on the equation you supplied,
but substituting the calculated values for rain and the modified values for
fertilizer.

Jim


On Mon, Jun 27, 2016 at 9:43 AM, rezvan hatami <rezvan.hatami_iut at yahoo.com>
wrote:

> Hi Jim
> Thank you for your answer. nitrate=0.9*fertilizer-0.02*flowrate+0.5*rain
>
> my matrix:
> season site nitrate fertilizer1 flow rate
> spring site1 0.2 2 1
> spring site2 1.2 3 1
> spring site3 2.2 5 2
> summer site1 3.2 1 2
> summer site2 4.2 2 2
> summer site3 5.2 3 2
> fall site1 6.2 4 3
> fall site2 7.2 5 3
> fall site3 8.2 6 3
> winter site1 9.2 4 4
> winter site2 10.2 8 4
> winter site3 11.2 9 4
>
> I would like to know, what will be the values for variable "nitrate" if I
> divide the values of fertilizer by half and change the equation to:
>
> nitrate=0.9*fertilizer2-0.02*flowrate+0.5*rain
>
> in a matrix like:
>
> season site nitrate fertilizer2 flow rate
> spring site1 0.2 1 1
> spring site2 1.2 1.5 1
> spring site3 2.2 2.5 2
> summer site1 3.2 0.5 2
> summer site2 4.2 1 2
> summer site3 5.2 1.5 2
> fall site1 6.2 2 3
> fall site2 7.2 2.5 3
> fall site3 8.2 3 3
> winter site1 9.2 2 4
> winter site2 10.2 4 4
> winter site3 11.2 4.5 4
> Would you please tell me how I can do this in R?
>
> Cheers
>
> Rezvan
>
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *To:* rezvan hatami <rezvan.hatami_iut at yahoo.com>; r-help mailing list <
> r-help at r-project.org>
> *Sent:* Monday, 27 June 2016, 8:07
> *Subject:* Re: [R] How I can calculate the value of response variable
>
> Hi Rezvan,
> I'll take a guess that you have been presented with a matrix of
> coefficients. You probably know that a linear model is going to look
> something like this:
>
> Y = ax1 + bx2 + cx3 ...
>
> So I will further guess that you want to infer a distribution of Y
> (the response variable) from more than one set of coefficients. If my
> guesses are correct, then you should be able to send an example that
> shows what you have and what you want to get.
>
> Jim
>
>
> On Sun, Jun 26, 2016 at 8:23 PM, rezvan hatami via R-help
> <r-help at r-project.org> wrote:
> >  How I can calculate the value of response variable in a linear model of
> a matrix of several variables?Can somebody please answer me?
> >
> >
> > Cheers
> > Rezvan Hatami
>
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Jun 27 02:34:52 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 26 Jun 2016 17:34:52 -0700
Subject: [R] Fw: How I can calculate the value of response variable
In-Reply-To: <1066443174.1505044.1466986955741.JavaMail.yahoo@mail.yahoo.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
	<6958432E-7840-4810-8A4D-C181236BF6DD@comcast.net>
	<1748641463.1489716.1466984687135.JavaMail.yahoo@mail.yahoo.com>
	<1066443174.1505044.1466986955741.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTsYSYik_r40i+Wk7r2DS89ON2PDwWTgPBULQGo-kbL3w@mail.gmail.com>

Is this homework? This list tries to enforce  a no homework policy...

If not, it looks to me as if you have made no effort to learn R nor
have you read and followed the posting guide. We generally expect
posters to have made reasonable efforts to do both and demonstrate
what they have tried and how it has failed.

Cheers,
Bert Gunter





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 26, 2016 at 5:22 PM, rezvan hatami via R-help
<r-help at r-project.org> wrote:
>
>
>
> ----- Forwarded Message -----
>  From: rezvan hatami <rezvan.hatami_iut at yahoo.com>
>  To: David Winsemius <dwinsemius at comcast.net>
>  Sent: Monday, 27 June 2016, 9:44
>  Subject: Re: [R] How I can calculate the value of response variable
>
> Dear DavidThank you for your answer. My equation is:
> nitrate=0.9*fertilizer-0.02*flowrate+0.5*rain
> my matrix:
> | season | site | nitrate | fertilizer1 | flow rate |
> | spring | site1 | 0.2 | 2 | 1 |
> | spring | site2 | 1.2 | 3 | 1 |
> | spring | site3 | 2.2 | 5 | 2 |
> | summer | site1 | 3.2 | 1 | 2 |
> | summer | site2 | 4.2 | 2 | 2 |
> | summer | site3 | 5.2 | 3 | 2 |
> | fall | site1 | 6.2 | 4 | 3 |
> | fall | site2 | 7.2 | 5 | 3 |
> | fall | site3 | 8.2 | 6 | 3 |
> | winter | site1 | 9.2 | 4 | 4 |
> | winter | site2 | 10.2 | 8 | 4 |
> | winter | site3 | 11.2 | 9 | 4 |
>
>
> I would like to know, what will be the values for variable "nitrate" if I divide the values of fertilizer by half and change the equation to:
> nitrate=0.9*fertilizer2-0.02*flowrate+0.5*rain
>
> in a matrix like:
>
> | season | site | nitrate | fertilizer2 | flow rate |
> | spring | site1 | 0.2 | 1 | 1 |
> | spring | site2 | 1.2 | 1.5 | 1 |
> | spring | site3 | 2.2 | 2.5 | 2 |
> | summer | site1 | 3.2 | 0.5 | 2 |
> | summer | site2 | 4.2 | 1 | 2 |
> | summer | site3 | 5.2 | 1.5 | 2 |
> | fall | site1 | 6.2 | 2 | 3 |
> | fall | site2 | 7.2 | 2.5 | 3 |
> | fall | site3 | 8.2 | 3 | 3 |
> | winter | site1 | 9.2 | 2 | 4 |
> | winter | site2 | 10.2 | 4 | 4 |
> | winter | site3 | 11.2 | 4.5 | 4 |
>
>
> Would you please tell me how I can do this in R?
> Cheers
> Rezvan
>       From: David Winsemius <dwinsemius at comcast.net>
>  To: rezvan hatami <rezvan.hatami_iut at yahoo.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
>  Sent: Monday, 27 June 2016, 1:20
>  Subject: Re: [R] How I can calculate the value of response variable
>
>
>> On Jun 26, 2016, at 3:23 AM, rezvan hatami via R-help <r-help at r-project.org> wrote:
>>
>>  How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?
>>
>
>   You should explain in more detail why the answer to this question is not just the `lm` function. See:
>
> ?lm
> ?predict.lm
>
>     That would deliver (after suitable invocation of the `predict` function) not be the "value of the response variable" (since that would just be the values in your data), but rather the conditional expectation of the response variable given the values of the predictors.
>
>
>>
>> Cheers
>> Rezvan Hatami
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rezvan.hatami_iut at yahoo.com  Mon Jun 27 02:57:04 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Mon, 27 Jun 2016 00:57:04 +0000 (UTC)
Subject: [R] How I can calculate the value of response variable
In-Reply-To: <CA+8X3fV+r7X9x5mHHpxTwmO0bo9Vp=ZWDUqjtBJbQWN=Seg4TQ@mail.gmail.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fVKf2o6-1F9Gvv2GjqHvAcJYOgV8v0Mmp-XPqak0LWi2A@mail.gmail.com>
	<26756506.1552457.1466984626257.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fV+r7X9x5mHHpxTwmO0bo9Vp=ZWDUqjtBJbQWN=Seg4TQ@mail.gmail.com>
Message-ID: <1608027174.1514232.1466989024682.JavaMail.yahoo@mail.yahoo.com>

Hi Jim
Thank you for your answer. This is not a homework exercise ;). I amde it simple. Actually I have a matrix of 100 variables. I made it simple so that I can explain what I need to do. They are not my data and I made them up. I know how to change the amount of fertilizer but I was not sure what function I need to use for this. Thank you for calculating the rain, but it wasn't a part of my question.
Cheers

      From: Jim Lemon <drjimlemon at gmail.com>
 To: rezvan hatami <rezvan.hatami_iut at yahoo.com>; r-help mailing list <r-help at r-project.org> 
 Sent: Monday, 27 June 2016, 10:28
 Subject: Re: [R] How I can calculate the value of response variable
   
Hi Rezvan,This looks like a simple problem of solving linear equations (and very much like a homework exercise). Therefore I won't actually give you the answer, but suggest the steps for the solution. First you have to get the data into R, so here is one way:
rhdat<-read.table(text="season,site,nitrate,fertilizer1,flowratespring,site1,0.2,2,1spring,site2,1.2,3,1spring,site3,2.2,5,2summer,site1,3.2,1,2summer,site2,4.2,2,2summer,site3,5.2,3,2fall,site1,6.2,4,3fall,site2,7.2,5,3fall,site3,8.2,6,3winter,site1,9.2,4,4winter,site2,10.2,8,4winter,site3,11.2,9,4",sep=",",header=TRUE)
You now have a data frame (rhdat) containing the values in your table.
1) calculate values for rain, which are missing from the table, e.g.
rhdat$rain<-2*(rhdat$nitrate-0.9*rhdat$fertilizer+0.02*rhdat$flowrate)
the above is an R expression to calculate the values for rain.
2) You may want explicitly calculate new values for rhdat$fertilizer, and you have indicated that you already know how to do that. The above should give you enough information about R syntax to translate the simple equation.
3) Now calculate new values for nitrate based on the equation you supplied, but substituting the calculated values for rain and the modified values for fertilizer.
Jim

On Mon, Jun 27, 2016 at 9:43 AM, rezvan hatami <rezvan.hatami_iut at yahoo.com> wrote:

Hi JimThank you for your answer. nitrate=0.9*fertilizer-0.02*flowrate+0.5*rain
my matrix:
| season | site | nitrate | fertilizer1 | flow rate |
| spring | site1 | 0.2 | 2 | 1 |
| spring | site2 | 1.2 | 3 | 1 |
| spring | site3 | 2.2 | 5 | 2 |
| summer | site1 | 3.2 | 1 | 2 |
| summer | site2 | 4.2 | 2 | 2 |
| summer | site3 | 5.2 | 3 | 2 |
| fall | site1 | 6.2 | 4 | 3 |
| fall | site2 | 7.2 | 5 | 3 |
| fall | site3 | 8.2 | 6 | 3 |
| winter | site1 | 9.2 | 4 | 4 |
| winter | site2 | 10.2 | 8 | 4 |
| winter | site3 | 11.2 | 9 | 4 |


I would like to know, what will be the values for variable "nitrate" if I divide the values of fertilizer by half and change the equation to:
nitrate=0.9*fertilizer2-0.02*flowrate+0.5*rain

in a matrix like:

| season | site | nitrate | fertilizer2 | flow rate |
| spring | site1 | 0.2 | 1 | 1 |
| spring | site2 | 1.2 | 1.5 | 1 |
| spring | site3 | 2.2 | 2.5 | 2 |
| summer | site1 | 3.2 | 0.5 | 2 |
| summer | site2 | 4.2 | 1 | 2 |
| summer | site3 | 5.2 | 1.5 | 2 |
| fall | site1 | 6.2 | 2 | 3 |
| fall | site2 | 7.2 | 2.5 | 3 |
| fall | site3 | 8.2 | 3 | 3 |
| winter | site1 | 9.2 | 2 | 4 |
| winter | site2 | 10.2 | 4 | 4 |
| winter | site3 | 11.2 | 4.5 | 4 |


Would you please tell me how I can do this in R?
Cheers
Rezvan

      From: Jim Lemon <drjimlemon at gmail.com>
 To: rezvan hatami <rezvan.hatami_iut at yahoo.com>; r-help mailing list <r-help at r-project.org> 
 Sent: Monday, 27 June 2016, 8:07
 Subject: Re: [R] How I can calculate the value of response variable
  
Hi Rezvan,
I'll take a guess that you have been presented with a matrix of
coefficients. You probably know that a linear model is going to look
something like this:

Y = ax1 + bx2 + cx3 ...

So I will further guess that you want to infer a distribution of Y
(the response variable) from more than one set of coefficients. If my
guesses are correct, then you should be able to send an example that
shows what you have and what you want to get.

Jim


On Sun, Jun 26, 2016 at 8:23 PM, rezvan hatami via R-help
<r-help at r-project.org> wrote:
>? How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?
>
>
> Cheers
> Rezvan Hatami
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   



  
	[[alternative HTML version deleted]]


From rezvan.hatami_iut at yahoo.com  Mon Jun 27 03:00:01 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Mon, 27 Jun 2016 01:00:01 +0000 (UTC)
Subject: [R] Fw: How I can calculate the value of response variable
In-Reply-To: <CAGxFJbTsYSYik_r40i+Wk7r2DS89ON2PDwWTgPBULQGo-kbL3w@mail.gmail.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
	<6958432E-7840-4810-8A4D-C181236BF6DD@comcast.net>
	<1748641463.1489716.1466984687135.JavaMail.yahoo@mail.yahoo.com>
	<1066443174.1505044.1466986955741.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbTsYSYik_r40i+Wk7r2DS89ON2PDwWTgPBULQGo-kbL3w@mail.gmail.com>
Message-ID: <387683478.1528146.1466989201782.JavaMail.yahoo@mail.yahoo.com>

Dear Bert
It is not a homework. I made this example up to ask my question. I am working on it in R, but my equations are complicated and if I put the codes in R here, I have to explain my whole project. I simply wanted to know what is the function for this so that I can be sure that I am doing the right thing.
Cheers
      From: Bert Gunter <bgunter.4567 at gmail.com>
 To: rezvan hatami <rezvan.hatami_iut at yahoo.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org>
 Sent: Monday, 27 June 2016, 10:34
 Subject: Re: [R] Fw: How I can calculate the value of response variable
   
Is this homework? This list tries to enforce? a no homework policy...

If not, it looks to me as if you have made no effort to learn R nor
have you read and followed the posting guide. We generally expect
posters to have made reasonable efforts to do both and demonstrate
what they have tried and how it has failed.

Cheers,
Bert Gunter





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 26, 2016 at 5:22 PM, rezvan hatami via R-help
<r-help at r-project.org> wrote:
>
>
>
> ----- Forwarded Message -----
>? From: rezvan hatami <rezvan.hatami_iut at yahoo.com>
>? To: David Winsemius <dwinsemius at comcast.net>
>? Sent: Monday, 27 June 2016, 9:44
>? Subject: Re: [R] How I can calculate the value of response variable
>
> Dear DavidThank you for your answer. My equation is:
> nitrate=0.9*fertilizer-0.02*flowrate+0.5*rain
> my matrix:
> | season | site | nitrate | fertilizer1 | flow rate |
> | spring | site1 | 0.2 | 2 | 1 |
> | spring | site2 | 1.2 | 3 | 1 |
> | spring | site3 | 2.2 | 5 | 2 |
> | summer | site1 | 3.2 | 1 | 2 |
> | summer | site2 | 4.2 | 2 | 2 |
> | summer | site3 | 5.2 | 3 | 2 |
> | fall | site1 | 6.2 | 4 | 3 |
> | fall | site2 | 7.2 | 5 | 3 |
> | fall | site3 | 8.2 | 6 | 3 |
> | winter | site1 | 9.2 | 4 | 4 |
> | winter | site2 | 10.2 | 8 | 4 |
> | winter | site3 | 11.2 | 9 | 4 |
>
>
> I would like to know, what will be the values for variable "nitrate" if I divide the values of fertilizer by half and change the equation to:
> nitrate=0.9*fertilizer2-0.02*flowrate+0.5*rain
>
> in a matrix like:
>
> | season | site | nitrate | fertilizer2 | flow rate |
> | spring | site1 | 0.2 | 1 | 1 |
> | spring | site2 | 1.2 | 1.5 | 1 |
> | spring | site3 | 2.2 | 2.5 | 2 |
> | summer | site1 | 3.2 | 0.5 | 2 |
> | summer | site2 | 4.2 | 1 | 2 |
> | summer | site3 | 5.2 | 1.5 | 2 |
> | fall | site1 | 6.2 | 2 | 3 |
> | fall | site2 | 7.2 | 2.5 | 3 |
> | fall | site3 | 8.2 | 3 | 3 |
> | winter | site1 | 9.2 | 2 | 4 |
> | winter | site2 | 10.2 | 4 | 4 |
> | winter | site3 | 11.2 | 4.5 | 4 |
>
>
> Would you please tell me how I can do this in R?
> Cheers
> Rezvan
>? ? ? From: David Winsemius <dwinsemius at comcast.net>
>? To: rezvan hatami <rezvan.hatami_iut at yahoo.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
>? Sent: Monday, 27 June 2016, 1:20
>? Subject: Re: [R] How I can calculate the value of response variable
>
>
>> On Jun 26, 2016, at 3:23 AM, rezvan hatami via R-help <r-help at r-project.org> wrote:
>>
>>? How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?
>>
>
>? You should explain in more detail why the answer to this question is not just the `lm` function. See:
>
> ?lm
> ?predict.lm
>
>? ? That would deliver (after suitable invocation of the `predict` function) not be the "value of the response variable" (since that would just be the values in your data), but rather the conditional expectation of the response variable given the values of the predictors.
>
>
>>
>> Cheers
>> Rezvan Hatami
>>? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>
>
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From rezvan.hatami_iut at yahoo.com  Mon Jun 27 03:15:35 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Mon, 27 Jun 2016 01:15:35 +0000 (UTC)
Subject: [R] Fw: How I can calculate the value of response variable
In-Reply-To: <CAGxFJbTsYSYik_r40i+Wk7r2DS89ON2PDwWTgPBULQGo-kbL3w@mail.gmail.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
	<6958432E-7840-4810-8A4D-C181236BF6DD@comcast.net>
	<1748641463.1489716.1466984687135.JavaMail.yahoo@mail.yahoo.com>
	<1066443174.1505044.1466986955741.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbTsYSYik_r40i+Wk7r2DS89ON2PDwWTgPBULQGo-kbL3w@mail.gmail.com>
Message-ID: <2012822206.1518884.1466990135065.JavaMail.yahoo@mail.yahoo.com>

For the sake ofsimplicity, I use my example to explain what I have written:


nutrient<-lm(nitrate~0.9*fertilizer-0.02*flowrate+0.5*rain)

datafram=data1


Change the value offertelizer--? datafram=data2


predict(lm(nitrate~0.9*fertilizer2-0.02*flowrate+0.5*rain), datafram=data2
Is that better now?

      From: Bert Gunter <bgunter.4567 at gmail.com>
 To: rezvan hatami <rezvan.hatami_iut at yahoo.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org>
 Sent: Monday, 27 June 2016, 10:34
 Subject: Re: [R] Fw: How I can calculate the value of response variable
   
Is this homework? This list tries to enforce? a no homework policy...

If not, it looks to me as if you have made no effort to learn R nor
have you read and followed the posting guide. We generally expect
posters to have made reasonable efforts to do both and demonstrate
what they have tried and how it has failed.

Cheers,
Bert Gunter





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 26, 2016 at 5:22 PM, rezvan hatami via R-help
<r-help at r-project.org> wrote:
>
>
>
> ----- Forwarded Message -----
>? From: rezvan hatami <rezvan.hatami_iut at yahoo.com>
>? To: David Winsemius <dwinsemius at comcast.net>
>? Sent: Monday, 27 June 2016, 9:44
>? Subject: Re: [R] How I can calculate the value of response variable
>
> Dear DavidThank you for your answer. My equation is:
> nitrate=0.9*fertilizer-0.02*flowrate+0.5*rain
> my matrix:
> | season | site | nitrate | fertilizer1 | flow rate |
> | spring | site1 | 0.2 | 2 | 1 |
> | spring | site2 | 1.2 | 3 | 1 |
> | spring | site3 | 2.2 | 5 | 2 |
> | summer | site1 | 3.2 | 1 | 2 |
> | summer | site2 | 4.2 | 2 | 2 |
> | summer | site3 | 5.2 | 3 | 2 |
> | fall | site1 | 6.2 | 4 | 3 |
> | fall | site2 | 7.2 | 5 | 3 |
> | fall | site3 | 8.2 | 6 | 3 |
> | winter | site1 | 9.2 | 4 | 4 |
> | winter | site2 | 10.2 | 8 | 4 |
> | winter | site3 | 11.2 | 9 | 4 |
>
>
> I would like to know, what will be the values for variable "nitrate" if I divide the values of fertilizer by half and change the equation to:
> nitrate=0.9*fertilizer2-0.02*flowrate+0.5*rain
>
> in a matrix like:
>
> | season | site | nitrate | fertilizer2 | flow rate |
> | spring | site1 | 0.2 | 1 | 1 |
> | spring | site2 | 1.2 | 1.5 | 1 |
> | spring | site3 | 2.2 | 2.5 | 2 |
> | summer | site1 | 3.2 | 0.5 | 2 |
> | summer | site2 | 4.2 | 1 | 2 |
> | summer | site3 | 5.2 | 1.5 | 2 |
> | fall | site1 | 6.2 | 2 | 3 |
> | fall | site2 | 7.2 | 2.5 | 3 |
> | fall | site3 | 8.2 | 3 | 3 |
> | winter | site1 | 9.2 | 2 | 4 |
> | winter | site2 | 10.2 | 4 | 4 |
> | winter | site3 | 11.2 | 4.5 | 4 |
>
>
> Would you please tell me how I can do this in R?
> Cheers
> Rezvan
>? ? ? From: David Winsemius <dwinsemius at comcast.net>
>? To: rezvan hatami <rezvan.hatami_iut at yahoo.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
>? Sent: Monday, 27 June 2016, 1:20
>? Subject: Re: [R] How I can calculate the value of response variable
>
>
>> On Jun 26, 2016, at 3:23 AM, rezvan hatami via R-help <r-help at r-project.org> wrote:
>>
>>? How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?
>>
>
>? You should explain in more detail why the answer to this question is not just the `lm` function. See:
>
> ?lm
> ?predict.lm
>
>? ? That would deliver (after suitable invocation of the `predict` function) not be the "value of the response variable" (since that would just be the values in your data), but rather the conditional expectation of the response variable given the values of the predictors.
>
>
>>
>> Cheers
>> Rezvan Hatami
>>? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>
>
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From rezvan.hatami_iut at yahoo.com  Mon Jun 27 03:15:50 2016
From: rezvan.hatami_iut at yahoo.com (rezvan hatami)
Date: Mon, 27 Jun 2016 01:15:50 +0000 (UTC)
Subject: [R] How I can calculate the value of response variable
In-Reply-To: <CA+8X3fV+r7X9x5mHHpxTwmO0bo9Vp=ZWDUqjtBJbQWN=Seg4TQ@mail.gmail.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fVKf2o6-1F9Gvv2GjqHvAcJYOgV8v0Mmp-XPqak0LWi2A@mail.gmail.com>
	<26756506.1552457.1466984626257.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fV+r7X9x5mHHpxTwmO0bo9Vp=ZWDUqjtBJbQWN=Seg4TQ@mail.gmail.com>
Message-ID: <1982017226.1533471.1466990150883.JavaMail.yahoo@mail.yahoo.com>

For the sake of simplicity, I use my example to explain what I have written:


nutrient<-lm(nitrate~0.9*fertilizer-0.02*flowrate+0.5*rain)

datafram=data1


Change the value of fertelizer--??datafram=data2


predict(lm(nitrate~0.9*fertilizer2-0.02*flowrate+0.5*rain), datafram=data2

Is that better now?


      From: Jim Lemon <drjimlemon at gmail.com>
 To: rezvan hatami <rezvan.hatami_iut at yahoo.com>; r-help mailing list <r-help at r-project.org> 
 Sent: Monday, 27 June 2016, 10:28
 Subject: Re: [R] How I can calculate the value of response variable
   
Hi Rezvan,This looks like a simple problem of solving linear equations (and very much like a homework exercise). Therefore I won't actually give you the answer, but suggest the steps for the solution. First you have to get the data into R, so here is one way:
rhdat<-read.table(text="season,site,nitrate,fertilizer1,flowratespring,site1,0.2,2,1spring,site2,1.2,3,1spring,site3,2.2,5,2summer,site1,3.2,1,2summer,site2,4.2,2,2summer,site3,5.2,3,2fall,site1,6.2,4,3fall,site2,7.2,5,3fall,site3,8.2,6,3winter,site1,9.2,4,4winter,site2,10.2,8,4winter,site3,11.2,9,4",sep=",",header=TRUE)
You now have a data frame (rhdat) containing the values in your table.
1) calculate values for rain, which are missing from the table, e.g.
rhdat$rain<-2*(rhdat$nitrate-0.9*rhdat$fertilizer+0.02*rhdat$flowrate)
the above is an R expression to calculate the values for rain.
2) You may want explicitly calculate new values for rhdat$fertilizer, and you have indicated that you already know how to do that. The above should give you enough information about R syntax to translate the simple equation.
3) Now calculate new values for nitrate based on the equation you supplied, but substituting the calculated values for rain and the modified values for fertilizer.
Jim

On Mon, Jun 27, 2016 at 9:43 AM, rezvan hatami <rezvan.hatami_iut at yahoo.com> wrote:

Hi JimThank you for your answer. nitrate=0.9*fertilizer-0.02*flowrate+0.5*rain
my matrix:
| season | site | nitrate | fertilizer1 | flow rate |
| spring | site1 | 0.2 | 2 | 1 |
| spring | site2 | 1.2 | 3 | 1 |
| spring | site3 | 2.2 | 5 | 2 |
| summer | site1 | 3.2 | 1 | 2 |
| summer | site2 | 4.2 | 2 | 2 |
| summer | site3 | 5.2 | 3 | 2 |
| fall | site1 | 6.2 | 4 | 3 |
| fall | site2 | 7.2 | 5 | 3 |
| fall | site3 | 8.2 | 6 | 3 |
| winter | site1 | 9.2 | 4 | 4 |
| winter | site2 | 10.2 | 8 | 4 |
| winter | site3 | 11.2 | 9 | 4 |


I would like to know, what will be the values for variable "nitrate" if I divide the values of fertilizer by half and change the equation to:
nitrate=0.9*fertilizer2-0.02*flowrate+0.5*rain

in a matrix like:

| season | site | nitrate | fertilizer2 | flow rate |
| spring | site1 | 0.2 | 1 | 1 |
| spring | site2 | 1.2 | 1.5 | 1 |
| spring | site3 | 2.2 | 2.5 | 2 |
| summer | site1 | 3.2 | 0.5 | 2 |
| summer | site2 | 4.2 | 1 | 2 |
| summer | site3 | 5.2 | 1.5 | 2 |
| fall | site1 | 6.2 | 2 | 3 |
| fall | site2 | 7.2 | 2.5 | 3 |
| fall | site3 | 8.2 | 3 | 3 |
| winter | site1 | 9.2 | 2 | 4 |
| winter | site2 | 10.2 | 4 | 4 |
| winter | site3 | 11.2 | 4.5 | 4 |


Would you please tell me how I can do this in R?
Cheers
Rezvan

      From: Jim Lemon <drjimlemon at gmail.com>
 To: rezvan hatami <rezvan.hatami_iut at yahoo.com>; r-help mailing list <r-help at r-project.org> 
 Sent: Monday, 27 June 2016, 8:07
 Subject: Re: [R] How I can calculate the value of response variable
  
Hi Rezvan,
I'll take a guess that you have been presented with a matrix of
coefficients. You probably know that a linear model is going to look
something like this:

Y = ax1 + bx2 + cx3 ...

So I will further guess that you want to infer a distribution of Y
(the response variable) from more than one set of coefficients. If my
guesses are correct, then you should be able to send an example that
shows what you have and what you want to get.

Jim


On Sun, Jun 26, 2016 at 8:23 PM, rezvan hatami via R-help
<r-help at r-project.org> wrote:
>? How I can calculate the value of response variable in a linear model of a matrix of several variables?Can somebody please answer me?
>
>
> Cheers
> Rezvan Hatami
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   



  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Jun 27 03:22:30 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 27 Jun 2016 11:22:30 +1000
Subject: [R] How I can calculate the value of response variable
In-Reply-To: <1982017226.1533471.1466990150883.JavaMail.yahoo@mail.yahoo.com>
References: <1513703787.1356293.1466936599605.JavaMail.yahoo.ref@mail.yahoo.com>
	<1513703787.1356293.1466936599605.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fVKf2o6-1F9Gvv2GjqHvAcJYOgV8v0Mmp-XPqak0LWi2A@mail.gmail.com>
	<26756506.1552457.1466984626257.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fV+r7X9x5mHHpxTwmO0bo9Vp=ZWDUqjtBJbQWN=Seg4TQ@mail.gmail.com>
	<1982017226.1533471.1466990150883.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fV36sQkbifrwYRWV=_12Tv1J+5SVQ95o4q3uCeV2=QY5A@mail.gmail.com>

Hi Rezvan,
Yes, and you can get fertilizer2 like this:

data1$fertilizer2<-data1fertilizer1*0.5

If I have the right idea, you want to substitute "fertilizer2" for
"fertilizer1" in your new model of nitrate (concentration?). I don't think
you want to include the coefficients (which are calculated by lm) into the
formula for lm.

Jim



On Mon, Jun 27, 2016 at 11:15 AM, rezvan hatami <rezvan.hatami_iut at yahoo.com
> wrote:

> For the sake of simplicity, I use my example to explain what I have
> written:
>
> nutrient<-lm(nitrate~0.9*fertilizer-0.02*flowrate+0.5*rain)
> datafram=data1
>
> Change the value of fertelizer--? datafram=data2
>
> predict(lm(nitrate~0.9*fertilizer2-0.02*flowrate+0.5*rain), datafram=data2
>
> Is that better now?
>
>
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *To:* rezvan hatami <rezvan.hatami_iut at yahoo.com>; r-help mailing list <
> r-help at r-project.org>
> *Sent:* Monday, 27 June 2016, 10:28
>
> *Subject:* Re: [R] How I can calculate the value of response variable
>
> Hi Rezvan,
> This looks like a simple problem of solving linear equations (and very
> much like a homework exercise). Therefore I won't actually give you the
> answer, but suggest the steps for the solution. First you have to get the
> data into R, so here is one way:
>
> rhdat<-read.table(text="season,site,nitrate,fertilizer1,flowrate
> spring,site1,0.2,2,1
> spring,site2,1.2,3,1
> spring,site3,2.2,5,2
> summer,site1,3.2,1,2
> summer,site2,4.2,2,2
> summer,site3,5.2,3,2
> fall,site1,6.2,4,3
> fall,site2,7.2,5,3
> fall,site3,8.2,6,3
> winter,site1,9.2,4,4
> winter,site2,10.2,8,4
> winter,site3,11.2,9,4",sep=",",header=TRUE)
>
> You now have a data frame (rhdat) containing the values in your table.
>
> 1) calculate values for rain, which are missing from the table, e.g.
>
> rhdat$rain<-2*(rhdat$nitrate-0.9*rhdat$fertilizer+0.02*rhdat$flowrate)
>
> the above is an R expression to calculate the values for rain.
>
> 2) You may want explicitly calculate new values for rhdat$fertilizer, and
> you have indicated that you already know how to do that. The above should
> give you enough information about R syntax to translate the simple equation.
>
> 3) Now calculate new values for nitrate based on the equation you
> supplied, but substituting the calculated values for rain and the modified
> values for fertilizer.
>
> Jim
>
>
> On Mon, Jun 27, 2016 at 9:43 AM, rezvan hatami <
> rezvan.hatami_iut at yahoo.com> wrote:
>
> Hi Jim
> Thank you for your answer. nitrate=0.9*fertilizer-0.02*flowrate+0.5*rain
>
> my matrix:
> season site nitrate fertilizer1 flow rate
> spring site1 0.2 2 1
> spring site2 1.2 3 1
> spring site3 2.2 5 2
> summer site1 3.2 1 2
> summer site2 4.2 2 2
> summer site3 5.2 3 2
> fall site1 6.2 4 3
> fall site2 7.2 5 3
> fall site3 8.2 6 3
> winter site1 9.2 4 4
> winter site2 10.2 8 4
> winter site3 11.2 9 4
>
> I would like to know, what will be the values for variable "nitrate" if I
> divide the values of fertilizer by half and change the equation to:
>
> nitrate=0.9*fertilizer2-0.02*flowrate+0.5*rain
>
> in a matrix like:
>
> season site nitrate fertilizer2 flow rate
> spring site1 0.2 1 1
> spring site2 1.2 1.5 1
> spring site3 2.2 2.5 2
> summer site1 3.2 0.5 2
> summer site2 4.2 1 2
> summer site3 5.2 1.5 2
> fall site1 6.2 2 3
> fall site2 7.2 2.5 3
> fall site3 8.2 3 3
> winter site1 9.2 2 4
> winter site2 10.2 4 4
> winter site3 11.2 4.5 4
> Would you please tell me how I can do this in R?
>
> Cheers
>
> Rezvan
>
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *To:* rezvan hatami <rezvan.hatami_iut at yahoo.com>; r-help mailing list <
> r-help at r-project.org>
> *Sent:* Monday, 27 June 2016, 8:07
> *Subject:* Re: [R] How I can calculate the value of response variable
>
> Hi Rezvan,
> I'll take a guess that you have been presented with a matrix of
> coefficients. You probably know that a linear model is going to look
> something like this:
>
> Y = ax1 + bx2 + cx3 ...
>
> So I will further guess that you want to infer a distribution of Y
> (the response variable) from more than one set of coefficients. If my
> guesses are correct, then you should be able to send an example that
> shows what you have and what you want to get.
>
> Jim
>
>
> On Sun, Jun 26, 2016 at 8:23 PM, rezvan hatami via R-help
> <r-help at r-project.org> wrote:
> >  How I can calculate the value of response variable in a linear model of
> a matrix of several variables?Can somebody please answer me?
> >
> >
> > Cheers
> > Rezvan Hatami
>
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From gferraz29 at gmail.com  Mon Jun 27 06:35:35 2016
From: gferraz29 at gmail.com (=?utf-8?Q?Gon=C3=A7alo_Ferraz?=)
Date: Mon, 27 Jun 2016 01:35:35 -0300
Subject: [R] strange behavior of lchoose in combinatorics problem
In-Reply-To: <58375192-5926-43BF-950B-281B52D44DC3@collocations.de>
References: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>
	<58375192-5926-43BF-950B-281B52D44DC3@collocations.de>
Message-ID: <6758A37B-694F-4F8F-8809-711009BC63FA@gmail.com>

Stefan,

I am sorry that I wasn?t more careful writing my question. I misrepresented my problem when I wrote ?the sum of the probabilities in lpvec should be <=1, but it is not. The sum is something on the order of 1.48e-13.?
It is absolutely right that lpvec doesn?t contain probabilities, it contains log-probabilities that are negative numbers. Also, clearly, the value of 1.48e-13 is <=1!
What I meant is that I wanted to add probabilities in the log-probability space and that I expected a negative value as a result. Instead, I am getting a positive value.

You are also right that if I wanted to test for a positive association I should add the probabilities of k>=J to obtain a p-value. This is clear to me, but I want a metric of the strength of association between animals that takes higher values when the association is stronger. A final result in the log-probability space is useful because I want to use the strength of association to build networks of individuals.

Finally, your idea of using Fisher?s exact test is very appealing for the simplicity and availability of a working function in R, but I am having trouble interpreting the result, or the result is different from that of my formula. Here?s a simple example:

Say N=2, N1=1, N2=1, and J=1. In this case, if the individuals are completely independent of each other, I expect to see them together with a probability of 0.5. That is the output from my function, in probability space. If I run Fisher?s exact test on the corresponding contingency table, however, I get a p-value of 1. This is what I did:

fisher.test(rbind(c(J,N1-J),c(N2-J,N-N1-N2+J)))

Why should this be, when the Fisher?s exact test is giving me the probability of obtaining the observed arrangement under the null hypothesis of no association between the animals. Am I interpreting the output incorrectly. Thank you for answer, it is great to find an even simpler way of addressing the problem.

Best,

Gon?alo

> On Jun 26, 2016, at 9:35 AM, Stefan Evert <stefanML at collocations.de> wrote:
> 
> Why do you want to do this? Why not simply use Fisher's exact test?
> 
> N <- 2178
> N1 <- 165
> N2 <- 331
> J <- 97
> ct <- rbind(c(J, N1-J), c(N2-J, N-N1-N2+J))
> fisher.test(ct)
> 
> Background explanation:
> 
> - Your formula computes the log hypergeometric probability for a contingency table as ct above, but with k instead of J.
> 
> - It does so in an unnecessarily complicated way: three terms would be enough (cf. the equation at http://www.collocations.de/AM/section3.html; with C1=N1, C2=N-C1, R1=N2).
> 
> - If you want to test for a positive association between the two animals, you should be adding up the probabilities for k >= J to obtain a p-value, rather than k <= J (what would this sum of probabilities tell you?).
> 
> - lpvec doesn't contain probabilities, but log probabilities. What sense would there be in adding those up? In any case, you should obtain a negative value because all the individual logs are negative.
> 
> Best,
> Stefan
> 
> 
> 
>> On 25 Jun 2016, at 16:13, Gon?alo Ferraz <gferraz29 at gmail.com> wrote:
>> 
>> I am working on interactions between animals, studying whether animal 1 is attracted to animal 2 (or vice-versa). I looked for the two animals in N=2178 sampling occasions, finding animal 1 a total of N1=165 times, and animal 2 a total of N2=331 times. In J=97 occasions, I saw both animals at the same time. 
>> 
>> The more frequently I see the two animals in the same sampling occasion, the more I will believe that they are attracted to each other. Therefore, I want to calculate the probability of finding J<=97 when the two animals are moving around independently of each other. The higher this probability, the stronger the attraction.
>> 
>> Following Veech (Journal of Biogeography 2014, 41: 1029-1035) I compute the log probability of obtaining a number n of encounters between animals as ?lpn? in the function lveech:
>> 
> 


From podolsky at yorku.ca  Mon Jun 27 05:02:12 2016
From: podolsky at yorku.ca (Mark Podolsky)
Date: Sun, 26 Jun 2016 23:02:12 -0400
Subject: [R] function for over dispersed poisson regression in the
	setting of a random effects model
In-Reply-To: <576F0D01020000CB00158F47@smtp.medicine.umaryland.edu>
References: <576F0D01020000CB00158F47@smtp.medicine.umaryland.edu>
Message-ID: <5186488A-A85C-43E3-985E-87F670D79DB1@yorku.ca>

Hi John,

The Gamlss.mx <http://gamlss.mx/> package can accommodate variables that follow negative binomial (and other) distributions in multilevel models.

Mark


> On Jun 25, 2016, at 11:00 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> Is there a function that will run a model appropriate for over dispersed data (such as a negative binomial or quasipoisson)
> with a random effects (or mixed effects) model in R? GLMER will not accept:  
> family=quasipoisson(link="log") or
> family=negbinomial(link="log") 
> 
> I want to run something like the following:
> fit0 <- glmer(Fall ~ Group+(1|PID)+offset(log(TimeYrs)),family=quasipoisson(link="log"),data=data)
> Thank  you
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From prerna.sawhney at nokia.com  Mon Jun 27 07:48:16 2016
From: prerna.sawhney at nokia.com (Sawhney, Prerna (Nokia - IN/Bangalore))
Date: Mon, 27 Jun 2016 05:48:16 +0000
Subject: [R] Right input mechanism to R for high amount of data
Message-ID: <DBXPR07MB1273CE4865967114F72EFCC9C210@DBXPR07MB127.eurprd07.prod.outlook.com>


Hi All,

I am currently loading 3B (20GB) events in my algorithm for processing. I am reading this data from postgresXL DB cluster (1 coordinator+4 datanodes (8cpu 61GB 200GB machines each)) total 1TB of space.

The whole data loading is taking too much time almost 5days before I can start running my algorithms.

Can you please help me in suggesting right technology to choose for inputting data? So clearly DB is the bottleneck right now

Should I move away from postgresXL ? Which is most suitable options DB, File, Paraquet File to load data efficiently in R?

Look forward to your responses

Thanks
Prerna

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Jun 27 09:22:16 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 27 Jun 2016 07:22:16 +0000
Subject: [R] Right input mechanism to R for high amount of data
In-Reply-To: <DBXPR07MB1273CE4865967114F72EFCC9C210@DBXPR07MB127.eurprd07.prod.outlook.com>
References: <DBXPR07MB1273CE4865967114F72EFCC9C210@DBXPR07MB127.eurprd07.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50327E2@SRVEXCHMBX.precheza.cz>

Hi

have you read something of these?

http://www.r-bloggers.com/five-ways-to-handle-big-data-in-r/
https://en.wikipedia.org/wiki/Programming_with_Big_Data_in_R
http://r-pbd.org/
http://www.columbia.edu/~sjm2186/EPIC_R/EPIC_R_BigData.pdf

I am not an expert in big data, however when reading your data takes days I wonder how do you want to do the analysis. AFAIK R keeps all read data in memory.

Maybe others can give you better answer.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sawhney,
> Prerna (Nokia - IN/Bangalore)
> Sent: Monday, June 27, 2016 7:48 AM
> To: r-help at r-project.org
> Subject: [R] Right input mechanism to R for high amount of data
>
>
> Hi All,
>
> I am currently loading 3B (20GB) events in my algorithm for processing. I am
> reading this data from postgresXL DB cluster (1 coordinator+4 datanodes
> (8cpu 61GB 200GB machines each)) total 1TB of space.
>
> The whole data loading is taking too much time almost 5days before I can
> start running my algorithms.
>
> Can you please help me in suggesting right technology to choose for
> inputting data? So clearly DB is the bottleneck right now
>
> Should I move away from postgresXL ? Which is most suitable options DB,
> File, Paraquet File to load data efficiently in R?
>
> Look forward to your responses
>
> Thanks
> Prerna
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From G.Maubach at weinwolf.de  Mon Jun 27 10:45:12 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 27 Jun 2016 10:45:12 +0200
Subject: [R] Antwort: Fw: Re:  Subscripting problem with is.na()
In-Reply-To: <trinity-295884d3-ac45-4e6d-96fe-edc75a94c75c-1466714673638@3capp-gmx-bs68>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>,
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<trinity-295884d3-ac45-4e6d-96fe-edc75a94c75c-1466714673638@3capp-gmx-bs68>
Message-ID: <OF447B1B12.0083A0FE-ONC1257FDF.002D6D2C-C1257FDF.003020B3@lotus.hawesko.de>

Hi David,
Hi Bert,

many thanks for the valuable discussion on NA in R (please see extract 
below). I follow your arguments leaving NA as they are for most of the 
time. In special occasions however I want to replace the NA with another 
value. To preserve the newly acquired knowledge for me I wrote this 
function:

-- cut --
t_replace_na <- function(dataset, variable, value) {
 if(inherits(dataset[[variable]], "factor") == TRUE) {
   dataset[variable] <- as.character(dataset[variable])
   print(class(dataset[variable]))
   dataset[, variable][is.na(dataset[, variable])] <- value
   dataset[variable] <- as.factor(dataset[variable])
   print(class(dataset[variable]))
 } else {
   dataset[, variable][is.na(dataset[, variable])] <- value
 }
 return(dataset)
}

ds_test <- data.frame(a=c(1,NA,2), b = rep(NA,3), c = c("A","b",NA))
print(sapply(ds_test, class))

t_replace_na(ds_test, "a", value = -1)
t_replace_na(ds_test, "b", value = -2)
t_replace_na(ds_test, "c", value = -3)
-- cut --

Unfortunately the if-statement does not work due to a wrong class 
definition within the function. When finding out what is going on I did 
this:

-- cut --
test_class <- function(dataset, variable) {
  if(inherits(dataset[, variable], "factor") == TRUE) {
    return(c(class(dataset[variable]), TRUE))
  } else {
    return(c(class(dataset[variable]), FALSE))
  }
}

ds_test <- data.frame(a=c(1,NA,2), b = rep(NA,3), c = c("A","b",NA))
print(sapply(ds_test, class))

# -- Test a --
class(ds_test[, "a"])
if(inherits(ds_test[, "a"], "factor")) {
  print(c(class(ds_test[, "a"]), "TRUE"))
} else {
  print(c(class(ds_test[, "a"]), "FALSE"))
}
test_class(ds_test, "a")
warning("'a' should be numeric NOT data.frame!")

# -- Test b --
if(inherits(ds_test[, "b"], "factor")) {
  print(c(class(ds_test[, "b"]), "TRUE"))
} else {
  print(c(class(ds_test[, "b"]), "FALSE"))
}
class(ds_test[, "b"])
test_class(ds_test, "b")
warning("'b' should be logical NOT data.frame!")

# -- Test c --
if(inherits(ds_test[, "c"], "factor")) {
  print(c(class(ds_test[, "c"]), "TRUE"))
} else {
  print(c(class(ds_test[, "c"]), "FALSE"))
}
class(ds_test[, "c"])
test_class(ds_test, "c")
warning("'c' should be factor NOT data.frame.
In addition data.frame != factor")
-- cut --

Why do I get different results for the same function if it is inside or 
outside my own function definition?

Kind regards

Georg

--------------------------------

> Gesendet: Donnerstag, 23. Juni 2016 um 21:14 Uhr
> Von: "David L Carlson" <dcarlson at tamu.edu>
> An: "Bert Gunter" <bgunter.4567 at gmail.com>
> Cc: "R Help" <r-help at r-project.org>
> Betreff: Re: [R] Subscripting problem with is.na()
>
> Good point. I did not think about factors. Also your example raises 
another issue since column c is logical, but gets silently converted to 
numeric. This would seem to get the job done assuming the conversion is 
intended for numeric columns only:
> 
> > test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> > sapply(test, class)
>         a         b         c 
> "numeric"  "factor" "logical" 
> > num <- sapply(test, is.numeric)
> > test[, num][is.na(test[, num])] <- 0
> > test
>   a    b  c
> 1 1    A NA
> 2 0    b NA
> 3 2 <NA> NA
> 
> David C


From petr.pikal at precheza.cz  Mon Jun 27 11:04:54 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 27 Jun 2016 09:04:54 +0000
Subject: [R] Antwort: Fw: Re:  Subscripting problem with is.na()
In-Reply-To: <OF447B1B12.0083A0FE-ONC1257FDF.002D6D2C-C1257FDF.003020B3@lotus.hawesko.de>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>,
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<trinity-295884d3-ac45-4e6d-96fe-edc75a94c75c-1466714673638@3capp-gmx-bs68>
	<OF447B1B12.0083A0FE-ONC1257FDF.002D6D2C-C1257FDF.003020B3@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032863@SRVEXCHMBX.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Monday, June 27, 2016 10:45 AM
> To: David L Carlson <dcarlson at tamu.edu>; Bert Gunter
> <bgunter.4567 at gmail.com>
> Cc: r-help at r-project.org
> Subject: [R] Antwort: Fw: Re: Subscripting problem with is.na()
>
> Hi David,
> Hi Bert,
>
> many thanks for the valuable discussion on NA in R (please see extract
> below). I follow your arguments leaving NA as they are for most of the
> time. In special occasions however I want to replace the NA with another
> value. To preserve the newly acquired knowledge for me I wrote this
> function:
>
> -- cut --
> t_replace_na <- function(dataset, variable, value) {
>  if(inherits(dataset[[variable]], "factor") == TRUE) {
>    dataset[variable] <- as.character(dataset[variable])
>    print(class(dataset[variable]))
>    dataset[, variable][is.na(dataset[, variable])] <- value
>    dataset[variable] <- as.factor(dataset[variable])
>    print(class(dataset[variable]))
>  } else {
>    dataset[, variable][is.na(dataset[, variable])] <- value
>  }
>  return(dataset)
> }
>

<snip>

> class(ds_test[, "c"])
> test_class(ds_test, "c")
> warning("'c' should be factor NOT data.frame.
> In addition data.frame != factor")
> -- cut --
>
> Why do I get different results for the same function if it is inside or
> outside my own function definition?

Because you still are missing the way how to subscript data frames.

test_class <- function(dataset, variable) {
  if(inherits(dataset[, variable], "factor") == TRUE) {
    return(c(class(dataset[,variable]), TRUE))
####                                 ^^^^
} else {
    return(c(class(dataset[,variable]), FALSE))
######                            ^^^^
  }
}

> test_class(ds_test, "a")
[1] "numeric" "FALSE"
> test_class(ds_test, "c")
[1] "factor" "TRUE"
>

If you properly arrange commas in your function you get desired result

p_replace_na <- function(dataset, variable, value) {
 if(inherits(dataset[,variable], "factor") == TRUE) {
   dataset[,variable] <- as.character(dataset[,variable])
   print(class(dataset[,variable]))
   dataset[, variable][is.na(dataset[, variable])] <- value
   dataset[, variable] <- as.factor(dataset[, variable])
   print(class(dataset[, variable]))
 } else {
   dataset[, variable][is.na(dataset[, variable])] <- value
 }
 return(dataset)
}

> p_replace_na(ds_test, "c", value = -3)
[1] "character"
[1] "factor"
   a  b  c
1  1 NA  A
2 NA NA  b
3  2 NA -3

> t_replace_na(ds_test, "c", value = -3)
[1] "data.frame"
Error in sort.list(y) : 'x' must be atomic for 'sort.list'
Have you called 'sort' on a list?
>

Cheers
Petr



>
> Kind regards
>
> Georg
>
> --------------------------------
>
> > Gesendet: Donnerstag, 23. Juni 2016 um 21:14 Uhr
> > Von: "David L Carlson" <dcarlson at tamu.edu>
> > An: "Bert Gunter" <bgunter.4567 at gmail.com>
> > Cc: "R Help" <r-help at r-project.org>
> > Betreff: Re: [R] Subscripting problem with is.na()
> >
> > Good point. I did not think about factors. Also your example raises
> another issue since column c is logical, but gets silently converted to
> numeric. This would seem to get the job done assuming the conversion is
> intended for numeric columns only:
> >
> > > test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> > > sapply(test, class)
> >         a         b         c
> > "numeric"  "factor" "logical"
> > > num <- sapply(test, is.numeric)
> > > test[, num][is.na(test[, num])] <- 0
> > > test
> >   a    b  c
> > 1 1    A NA
> > 2 0    b NA
> > 3 2 <NA> NA
> >
> > David C
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From G.Maubach at weinwolf.de  Mon Jun 27 13:43:13 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 27 Jun 2016 13:43:13 +0200
Subject: [R] Antwort: RE: Antwort: Fw: Re: Subscripting problem with is.na()
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032863@SRVEXCHMBX.precheza.cz>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>,
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<trinity-295884d3-ac45-4e6d-96fe-edc75a94c75c-1466714673638@3capp-gmx-bs68>
	<OF447B1B12.0083A0FE-ONC1257FDF.002D6D2C-C1257FDF.003020B3@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032863@SRVEXCHMBX.precheza.cz>
Message-ID: <OF85AA5AAB.BA56AC22-ONC1257FDF.00401D63-C1257FDF.00406CD4@lotus.hawesko.de>

Hi Petr,

many thanks for your reply and the examples.

My subscripting problems drive me nuts.

I have understood that dataset[variable] is semantically identical to 
dataset[, variable] cause dataset[variable] takes all cases because no 
other subscripts are given.

Where can I lookup the rules when to use the comma and when not?

Kind regards

Georg





Von:    PIKAL Petr <petr.pikal at precheza.cz>
An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, 
Kopie:  "r-help at r-project.org" <r-help at r-project.org>
Datum:  27.06.2016 11:03
Betreff:        RE: [R] Antwort: Fw: Re:  Subscripting problem with 
is.na()



Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Monday, June 27, 2016 10:45 AM
> To: David L Carlson <dcarlson at tamu.edu>; Bert Gunter
> <bgunter.4567 at gmail.com>
> Cc: r-help at r-project.org
> Subject: [R] Antwort: Fw: Re: Subscripting problem with is.na()
>
> Hi David,
> Hi Bert,
>
> many thanks for the valuable discussion on NA in R (please see extract
> below). I follow your arguments leaving NA as they are for most of the
> time. In special occasions however I want to replace the NA with another
> value. To preserve the newly acquired knowledge for me I wrote this
> function:
>
> -- cut --
> t_replace_na <- function(dataset, variable, value) {
>  if(inherits(dataset[[variable]], "factor") == TRUE) {
>    dataset[variable] <- as.character(dataset[variable])
>    print(class(dataset[variable]))
>    dataset[, variable][is.na(dataset[, variable])] <- value
>    dataset[variable] <- as.factor(dataset[variable])
>    print(class(dataset[variable]))
>  } else {
>    dataset[, variable][is.na(dataset[, variable])] <- value
>  }
>  return(dataset)
> }
>

<snip>

> class(ds_test[, "c"])
> test_class(ds_test, "c")
> warning("'c' should be factor NOT data.frame.
> In addition data.frame != factor")
> -- cut --
>
> Why do I get different results for the same function if it is inside or
> outside my own function definition?

Because you still are missing the way how to subscript data frames.

test_class <- function(dataset, variable) {
  if(inherits(dataset[, variable], "factor") == TRUE) {
    return(c(class(dataset[,variable]), TRUE))
####                                 ^^^^
} else {
    return(c(class(dataset[,variable]), FALSE))
######                            ^^^^
  }
}

> test_class(ds_test, "a")
[1] "numeric" "FALSE"
> test_class(ds_test, "c")
[1] "factor" "TRUE"
>

If you properly arrange commas in your function you get desired result

p_replace_na <- function(dataset, variable, value) {
 if(inherits(dataset[,variable], "factor") == TRUE) {
   dataset[,variable] <- as.character(dataset[,variable])
   print(class(dataset[,variable]))
   dataset[, variable][is.na(dataset[, variable])] <- value
   dataset[, variable] <- as.factor(dataset[, variable])
   print(class(dataset[, variable]))
 } else {
   dataset[, variable][is.na(dataset[, variable])] <- value
 }
 return(dataset)
}

> p_replace_na(ds_test, "c", value = -3)
[1] "character"
[1] "factor"
   a  b  c
1  1 NA  A
2 NA NA  b
3  2 NA -3

> t_replace_na(ds_test, "c", value = -3)
[1] "data.frame"
Error in sort.list(y) : 'x' must be atomic for 'sort.list'
Have you called 'sort' on a list?
>

Cheers
Petr



>
> Kind regards
>
> Georg
>
> --------------------------------
>
> > Gesendet: Donnerstag, 23. Juni 2016 um 21:14 Uhr
> > Von: "David L Carlson" <dcarlson at tamu.edu>
> > An: "Bert Gunter" <bgunter.4567 at gmail.com>
> > Cc: "R Help" <r-help at r-project.org>
> > Betreff: Re: [R] Subscripting problem with is.na()
> >
> > Good point. I did not think about factors. Also your example raises
> another issue since column c is logical, but gets silently converted to
> numeric. This would seem to get the job done assuming the conversion is
> intended for numeric columns only:
> >
> > > test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> > > sapply(test, class)
> >         a         b         c
> > "numeric"  "factor" "logical"
> > > num <- sapply(test, is.numeric)
> > > test[, num][is.na(test[, num])] <- 0
> > > test
> >   a    b  c
> > 1 1    A NA
> > 2 0    b NA
> > 3 2 <NA> NA
> >
> > David C
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Jun 27 13:57:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 27 Jun 2016 07:57:06 -0400
Subject: [R] Antwort: RE: Antwort: Fw: Re: Subscripting problem with
 is.na()
In-Reply-To: <OF85AA5AAB.BA56AC22-ONC1257FDF.00401D63-C1257FDF.00406CD4@lotus.hawesko.de>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<trinity-295884d3-ac45-4e6d-96fe-edc75a94c75c-1466714673638@3capp-gmx-bs68>
	<OF447B1B12.0083A0FE-ONC1257FDF.002D6D2C-C1257FDF.003020B3@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032863@SRVEXCHMBX.precheza.cz>
	<OF85AA5AAB.BA56AC22-ONC1257FDF.00401D63-C1257FDF.00406CD4@lotus.hawesko.de>
Message-ID: <32892d45-4c55-23a0-b54b-a53ab7a21ee5@gmail.com>

On 27/06/2016 7:43 AM, G.Maubach at weinwolf.de wrote:
> Hi Petr,
>
> many thanks for your reply and the examples.
>
> My subscripting problems drive me nuts.
>
> I have understood that dataset[variable] is semantically identical to
> dataset[, variable] cause dataset[variable] takes all cases because no
> other subscripts are given.
>
> Where can I lookup the rules when to use the comma and when not?

I don't think you'll find an explicit list of rules in the R 
documentation.  It does imply the rules, however, by saying that a data 
frame is a list which can be indexed as a matrix.

So if you want to treat your dataset as a list of columns, use single 
component list indexing:  dataset[columnname] to give another list, 
dataset[[columnname]] to extract the column as a vector.

If you want to treat it as a matrix of values, use two indices:

dataset[row, column]

to extract the entry (or entries, if row or column contains more than 
one value).

Duncan Murdoch

>
> Kind regards
>
> Georg
>
>
>
>
>
> Von:    PIKAL Petr <petr.pikal at precheza.cz>
> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
> Kopie:  "r-help at r-project.org" <r-help at r-project.org>
> Datum:  27.06.2016 11:03
> Betreff:        RE: [R] Antwort: Fw: Re:  Subscripting problem with
> is.na()
>
>
>
> Hi
>
> see in line
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> G.Maubach at weinwolf.de
>> Sent: Monday, June 27, 2016 10:45 AM
>> To: David L Carlson <dcarlson at tamu.edu>; Bert Gunter
>> <bgunter.4567 at gmail.com>
>> Cc: r-help at r-project.org
>> Subject: [R] Antwort: Fw: Re: Subscripting problem with is.na()
>>
>> Hi David,
>> Hi Bert,
>>
>> many thanks for the valuable discussion on NA in R (please see extract
>> below). I follow your arguments leaving NA as they are for most of the
>> time. In special occasions however I want to replace the NA with another
>> value. To preserve the newly acquired knowledge for me I wrote this
>> function:
>>
>> -- cut --
>> t_replace_na <- function(dataset, variable, value) {
>>  if(inherits(dataset[[variable]], "factor") == TRUE) {
>>    dataset[variable] <- as.character(dataset[variable])
>>    print(class(dataset[variable]))
>>    dataset[, variable][is.na(dataset[, variable])] <- value
>>    dataset[variable] <- as.factor(dataset[variable])
>>    print(class(dataset[variable]))
>>  } else {
>>    dataset[, variable][is.na(dataset[, variable])] <- value
>>  }
>>  return(dataset)
>> }
>>
>
> <snip>
>
>> class(ds_test[, "c"])
>> test_class(ds_test, "c")
>> warning("'c' should be factor NOT data.frame.
>> In addition data.frame != factor")
>> -- cut --
>>
>> Why do I get different results for the same function if it is inside or
>> outside my own function definition?
>
> Because you still are missing the way how to subscript data frames.
>
> test_class <- function(dataset, variable) {
>   if(inherits(dataset[, variable], "factor") == TRUE) {
>     return(c(class(dataset[,variable]), TRUE))
> ####                                 ^^^^
> } else {
>     return(c(class(dataset[,variable]), FALSE))
> ######                            ^^^^
>   }
> }
>
>> test_class(ds_test, "a")
> [1] "numeric" "FALSE"
>> test_class(ds_test, "c")
> [1] "factor" "TRUE"
>>
>
> If you properly arrange commas in your function you get desired result
>
> p_replace_na <- function(dataset, variable, value) {
>  if(inherits(dataset[,variable], "factor") == TRUE) {
>    dataset[,variable] <- as.character(dataset[,variable])
>    print(class(dataset[,variable]))
>    dataset[, variable][is.na(dataset[, variable])] <- value
>    dataset[, variable] <- as.factor(dataset[, variable])
>    print(class(dataset[, variable]))
>  } else {
>    dataset[, variable][is.na(dataset[, variable])] <- value
>  }
>  return(dataset)
> }
>
>> p_replace_na(ds_test, "c", value = -3)
> [1] "character"
> [1] "factor"
>    a  b  c
> 1  1 NA  A
> 2 NA NA  b
> 3  2 NA -3
>
>> t_replace_na(ds_test, "c", value = -3)
> [1] "data.frame"
> Error in sort.list(y) : 'x' must be atomic for 'sort.list'
> Have you called 'sort' on a list?
>>
>
> Cheers
> Petr
>
>
>
>>
>> Kind regards
>>
>> Georg
>>
>> --------------------------------
>>
>>> Gesendet: Donnerstag, 23. Juni 2016 um 21:14 Uhr
>>> Von: "David L Carlson" <dcarlson at tamu.edu>
>>> An: "Bert Gunter" <bgunter.4567 at gmail.com>
>>> Cc: "R Help" <r-help at r-project.org>
>>> Betreff: Re: [R] Subscripting problem with is.na()
>>>
>>> Good point. I did not think about factors. Also your example raises
>> another issue since column c is logical, but gets silently converted to
>> numeric. This would seem to get the job done assuming the conversion is
>> intended for numeric columns only:
>>>
>>>> test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
>>>> sapply(test, class)
>>>         a         b         c
>>> "numeric"  "factor" "logical"
>>>> num <- sapply(test, is.numeric)
>>>> test[, num][is.na(test[, num])] <- 0
>>>> test
>>>   a    b  c
>>> 1 1    A NA
>>> 2 0    b NA
>>> 3 2 <NA> NA
>>>
>>> David C
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From G.Maubach at weinwolf.de  Mon Jun 27 14:52:12 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 27 Jun 2016 14:52:12 +0200
Subject: [R] Antwort: RE: Antwort: Fw: Re: Subscripting problem with is.na()
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032863@SRVEXCHMBX.precheza.cz>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>,
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<trinity-295884d3-ac45-4e6d-96fe-edc75a94c75c-1466714673638@3capp-gmx-bs68>
	<OF447B1B12.0083A0FE-ONC1257FDF.002D6D2C-C1257FDF.003020B3@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032863@SRVEXCHMBX.precheza.cz>
Message-ID: <OF3003BF48.6F589E97-ONC1257FDF.00436B27-C1257FDF.0046BD8E@lotus.hawesko.de>

Hi All,

Petr, Bert, David, Ivan, Duncan and Rui helped me to develop a function 
able to replace NA's in variables IF NEEDED:

#-------------------------------------------------------------------------------
# Module        : t_replace_na.R
# Author        : Georg Maubach
# Date          : 2016-06-27
# Update        : 2016-06-27
# Description   : Replace NA with another value
# Source System : R 3.3.0 (64 Bit)
# Target System : R 3.3.0 (64 Bit)
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#--------1---------2---------3---------4---------5---------6---------7---------8

t_version = "2016-06-27"
t_module_name = "t_replace_na.R"

cat(
  paste0("\n",
         t_module_name, " (Version: ", t_version, ")", "\n", "\n",
         "This software comes with ABSOLUTELY NO WARRANTY.",
         "\n", "\n"))

# If do_test is not defined globally define it here locally by 
un-commenting it
t_do_test <- FALSE

# [ Function Defintion 
]--------------------------------------------------------
t_replace_na <- function(dataset, variables, value) {
  # Replace NA with another given value
  #
  # Args:
  #   dataset (data frame, data table):
  #     Object with dimnames, e.g. data frame, data table.
  #   variables (character vector):
  #     List of variable names.
  #
  # Operation:
  #   NA is replaced by the value given with the parameter "value".
  #
  #   A factor is converted explicitly with as.character(), the missing 
value
  #   replacement is done and then the character vector is converted back 
with
  #   as.factor(). Thus NA becomes a category of the new factor variable.
  #
  # Caution:
  #   Please check your data in case you replace NA within factors due to
  #   explicit type conversion. Tests were done only for the below given
  #   dataset.
  #
  # Returns:
  #   Original dataset.
  #
  # Error handling:
  #   None.
  #
  # Credits: 
https://www.mail-archive.com/r-help at r-project.org/msg236537.html

  for (variable in variables) {
    if (inherits(dataset[, variable], "factor") == TRUE) {
      dataset[, variable] <- as.character(dataset[, variable])
      print(class(dataset[, variable]))
      dataset[, variable][is.na(dataset[, variable])] <- value
      dataset[, variable] <- as.factor(dataset[, variable])
      print(class(dataset[, variable]))
    } else {
      dataset[, variable][is.na(dataset[, variable])] <- value
    }
  }
  return(dataset)
}

# [ Test Defintion 
]------------------------------------------------------------
t_test <- function(do_test = FALSE) {
  if (do_test == TRUE) {
    cat("\n", "\n", "Test function t_count_na()", "\n", "\n")
 
    # Example dataset
    ds_example <- data.frame(a=c(1,NA,2), b = rep(NA,3), c = 
c("A","b",NA))
 
    cat("\n", "\n", "Example dataset before function call", "\n", "\n")
    cat("Variables and their classes:\n")
    print(sapply(ds_example, class))
    cat("Dataset:\n")
    print(ds_example)
 
    cat("\n", "\n", "Function call", "\n", "\n")
    ds_result <- t_replace_na(ds_example, "a", value = -1)
    cat("\n", "\n", "Dataset after function call", "\n", "\n") 
    print(ds_result)
 
    cat("\n", "\n", "Function call", "\n", "\n")
    ds_result <- t_replace_na(ds_example, "b", value = -2)
    cat("\n", "\n", "Example dataset after function call", "\n", "\n") 
    print(ds_result)

    cat("\n", "\n", "Function call", "\n", "\n") 
    ds_result <- t_replace_na(ds_example, "c", value = -3)
    cat("\n", "\n", "Example dataset after function call", "\n", "\n") 
    print(ds_result) 
  }
}

# [ Test Run 
]------------------------------------------------------------------
t_test(do_test = t_do_test)

# [ Clean up 
]------------------------------------------------------------------
rm("t_module_name", "t_version", "t_do_test", "t_test")

# EOF .

Please note: R has capabilities to handle NA correctly. There is often no 
need to recode NA. Also NA might or might not have meaning. You have to 
decide with regard to the meaning of the original data and the business 
problem.

Kind regards

Georg




Von:    PIKAL Petr <petr.pikal at precheza.cz>
An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, 
Kopie:  "r-help at r-project.org" <r-help at r-project.org>
Datum:  27.06.2016 11:03
Betreff:        RE: [R] Antwort: Fw: Re:  Subscripting problem with 
is.na()



Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Monday, June 27, 2016 10:45 AM
> To: David L Carlson <dcarlson at tamu.edu>; Bert Gunter
> <bgunter.4567 at gmail.com>
> Cc: r-help at r-project.org
> Subject: [R] Antwort: Fw: Re: Subscripting problem with is.na()
>
> Hi David,
> Hi Bert,
>
> many thanks for the valuable discussion on NA in R (please see extract
> below). I follow your arguments leaving NA as they are for most of the
> time. In special occasions however I want to replace the NA with another
> value. To preserve the newly acquired knowledge for me I wrote this
> function:
>
> -- cut --
> t_replace_na <- function(dataset, variable, value) {
>  if(inherits(dataset[[variable]], "factor") == TRUE) {
>    dataset[variable] <- as.character(dataset[variable])
>    print(class(dataset[variable]))
>    dataset[, variable][is.na(dataset[, variable])] <- value
>    dataset[variable] <- as.factor(dataset[variable])
>    print(class(dataset[variable]))
>  } else {
>    dataset[, variable][is.na(dataset[, variable])] <- value
>  }
>  return(dataset)
> }
>

<snip>

> class(ds_test[, "c"])
> test_class(ds_test, "c")
> warning("'c' should be factor NOT data.frame.
> In addition data.frame != factor")
> -- cut --
>
> Why do I get different results for the same function if it is inside or
> outside my own function definition?

Because you still are missing the way how to subscript data frames.

test_class <- function(dataset, variable) {
  if(inherits(dataset[, variable], "factor") == TRUE) {
    return(c(class(dataset[,variable]), TRUE))
####                                 ^^^^
} else {
    return(c(class(dataset[,variable]), FALSE))
######                            ^^^^
  }
}

> test_class(ds_test, "a")
[1] "numeric" "FALSE"
> test_class(ds_test, "c")
[1] "factor" "TRUE"
>

If you properly arrange commas in your function you get desired result

p_replace_na <- function(dataset, variable, value) {
 if(inherits(dataset[,variable], "factor") == TRUE) {
   dataset[,variable] <- as.character(dataset[,variable])
   print(class(dataset[,variable]))
   dataset[, variable][is.na(dataset[, variable])] <- value
   dataset[, variable] <- as.factor(dataset[, variable])
   print(class(dataset[, variable]))
 } else {
   dataset[, variable][is.na(dataset[, variable])] <- value
 }
 return(dataset)
}

> p_replace_na(ds_test, "c", value = -3)
[1] "character"
[1] "factor"
   a  b  c
1  1 NA  A
2 NA NA  b
3  2 NA -3

> t_replace_na(ds_test, "c", value = -3)
[1] "data.frame"
Error in sort.list(y) : 'x' must be atomic for 'sort.list'
Have you called 'sort' on a list?
>

Cheers
Petr



>
> Kind regards
>
> Georg
>
> --------------------------------
>
> > Gesendet: Donnerstag, 23. Juni 2016 um 21:14 Uhr
> > Von: "David L Carlson" <dcarlson at tamu.edu>
> > An: "Bert Gunter" <bgunter.4567 at gmail.com>
> > Cc: "R Help" <r-help at r-project.org>
> > Betreff: Re: [R] Subscripting problem with is.na()
> >
> > Good point. I did not think about factors. Also your example raises
> another issue since column c is logical, but gets silently converted to
> numeric. This would seem to get the job done assuming the conversion is
> intended for numeric columns only:
> >
> > > test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> > > sapply(test, class)
> >         a         b         c
> > "numeric"  "factor" "logical"
> > > num <- sapply(test, is.numeric)
> > > test[, num][is.na(test[, num])] <- 0
> > > test
> >   a    b  c
> > 1 1    A NA
> > 2 0    b NA
> > 3 2 <NA> NA
> >
> > David C
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter 
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization 
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.


From christian at echoffmann.ch  Mon Jun 27 09:52:51 2016
From: christian at echoffmann.ch (Christian Hoffmann)
Date: Mon, 27 Jun 2016 09:52:51 +0200
Subject: [R] object 'add.expr' not found
Message-ID: <fa497576-3fe0-ab12-9ca3-4806a1baee0c@echoffmann.ch>

Since the change to R-3.2.1 I seem to be unable to compile and install 
my package cwhmisc. One evidence is the appearance of th messages in R 
CMD build and install:

* installing *source* package 'cwhmisc' ...
** R
** inst
** preparing package for lazy loading
Error in eval(expr, envir, enclos) : object 'add.expr' not found

Can anyone give me a pointer to where I should investigate my problem 
further?

C.

-- 
Christian W. Hoffmann
CH - 8915 Hausen am Albis, Schweiz
Rigiblickstrasse 15 b, Tel.+41-44-7640853
mailto: christian at echoffmann.ch
home: www.echoffmann.ch


From murdoch.duncan at gmail.com  Mon Jun 27 15:54:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 27 Jun 2016 09:54:06 -0400
Subject: [R] object 'add.expr' not found
In-Reply-To: <fa497576-3fe0-ab12-9ca3-4806a1baee0c@echoffmann.ch>
References: <fa497576-3fe0-ab12-9ca3-4806a1baee0c@echoffmann.ch>
Message-ID: <f991e221-aae2-8b68-bcb4-c01b8ca8c9d2@gmail.com>

On 27/06/2016 3:52 AM, Christian Hoffmann wrote:
> Since the change to R-3.2.1 I seem to be unable to compile and install
> my package cwhmisc. One evidence is the appearance of th messages in R
> CMD build and install:
>
> * installing *source* package 'cwhmisc' ...
> ** R
> ** inst
> ** preparing package for lazy loading
> Error in eval(expr, envir, enclos) : object 'add.expr' not found
>
> Can anyone give me a pointer to where I should investigate my problem
> further?
>
> C.
>
"add.expr" is an argument to the heatmap() function.  If you're using 
that, make sure your calls are okay.  If not, you'll need to find what 
other function is using add.expr; there are no other base functions that 
use it.

Duncan Murdoch


From petr.pikal at precheza.cz  Mon Jun 27 16:14:29 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 27 Jun 2016 14:14:29 +0000
Subject: [R] Antwort: RE: Antwort: Fw: Re: Subscripting problem with
 is.na()
In-Reply-To: <OF85AA5AAB.BA56AC22-ONC1257FDF.00401D63-C1257FDF.00406CD4@lotus.hawesko.de>
References: <OF5D8DC470.822F0CDD-ONC1257FDB.004C7792-C1257FDB.004CBEAA@lotus.hawesko.de>
	<16649_1466692168_576BF248_16649_462_1_5f1bbadc-5ebe-5244-bfa8-284e0e4ffa34@univ-reims.fr>
	<fd270e80-9f33-6cf9-0faa-3d9677f2babd@univ-reims.fr>
	<CAGxFJbQQzfqXzo1xFa4NJBBgiBHs4Z0ytBRV2u+WZpkE-eowJg@mail.gmail.com>
	<671dbfbf-e884-aaa4-1e0c-8f0c2e7b9f5f@univ-reims.fr>
	<17bbb42bc74543efb4e789697cb7fb00@exch-2p-mbx-t2.ads.tamu.edu>
	<CAGxFJbRKoiWc0HkWXibDc9UA5McbnR_4rO4uw2mq9dqaxWqzyQ@mail.gmail.com>,
	<a2f68f7b95b648c888bf1120a6c5f070@exch-2p-mbx-t2.ads.tamu.edu>
	<trinity-295884d3-ac45-4e6d-96fe-edc75a94c75c-1466714673638@3capp-gmx-bs68>
	<OF447B1B12.0083A0FE-ONC1257FDF.002D6D2C-C1257FDF.003020B3@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032863@SRVEXCHMBX.precheza.cz>
	<OF85AA5AAB.BA56AC22-ONC1257FDF.00401D63-C1257FDF.00406CD4@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C503290A@SRVEXCHMBX.precheza.cz>

Hi

On top of what Duncan wrote you can check results yourself

> str(iris[,"Sepal.Length"])
num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...

here you get vector and data.frame class is lost. The result is same as
> str(iris$Sepal.Length)
num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...

However

> str(iris["Sepal.Length"])
'data.frame':   150 obs. of  1 variable:
$ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...

here the data frame class is preserved.

I subscript rectangular objects (arrays, matricex, data, frames) exclusively by

object[ , , something, ] or in case of data frame object.df[sub, ]

and lists with

object.l[sub] or object.l[[sub]]

so I never had problems with it.

Cheers
Petr


From: G.Maubach at weinwolf.de [mailto:G.Maubach at weinwolf.de]
Sent: Monday, June 27, 2016 1:43 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help at r-project.org
Subject: Antwort: RE: [R] Antwort: Fw: Re: Subscripting problem with is.na()

Hi Petr,

many thanks for your reply and the examples.

My subscripting problems drive me nuts.

I have understood that dataset[variable] is semantically identical to dataset[, variable] cause dataset[variable] takes all cases because no other subscripts are given.

Where can I lookup the rules when to use the comma and when not?

Kind regards

Georg





Von:        PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
An:        "G.Maubach at weinwolf.de<mailto:G.Maubach at weinwolf.de>" <G.Maubach at weinwolf.de<mailto:G.Maubach at weinwolf.de>>,
Kopie:        "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>
Datum:        27.06.2016 11:03
Betreff:        RE: [R] Antwort: Fw: Re:  Subscripting problem with is.na()
________________________________



Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de<mailto:G.Maubach at weinwolf.de>
> Sent: Monday, June 27, 2016 10:45 AM
> To: David L Carlson <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>>; Bert Gunter
> <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Antwort: Fw: Re: Subscripting problem with is.na()
>
> Hi David,
> Hi Bert,
>
> many thanks for the valuable discussion on NA in R (please see extract
> below). I follow your arguments leaving NA as they are for most of the
> time. In special occasions however I want to replace the NA with another
> value. To preserve the newly acquired knowledge for me I wrote this
> function:
>
> -- cut --
> t_replace_na <- function(dataset, variable, value) {
>  if(inherits(dataset[[variable]], "factor") == TRUE) {
>    dataset[variable] <- as.character(dataset[variable])
>    print(class(dataset[variable]))
>    dataset[, variable][is.na(dataset[, variable])] <- value
>    dataset[variable] <- as.factor(dataset[variable])
>    print(class(dataset[variable]))
>  } else {
>    dataset[, variable][is.na(dataset[, variable])] <- value
>  }
>  return(dataset)
> }
>

<snip>

> class(ds_test[, "c"])
> test_class(ds_test, "c")
> warning("'c' should be factor NOT data.frame.
> In addition data.frame != factor")
> -- cut --
>
> Why do I get different results for the same function if it is inside or
> outside my own function definition?

Because you still are missing the way how to subscript data frames.

test_class <- function(dataset, variable) {
 if(inherits(dataset[, variable], "factor") == TRUE) {
   return(c(class(dataset[,variable]), TRUE))
####                                 ^^^^
} else {
   return(c(class(dataset[,variable]), FALSE))
######                            ^^^^
 }
}

> test_class(ds_test, "a")
[1] "numeric" "FALSE"
> test_class(ds_test, "c")
[1] "factor" "TRUE"
>

If you properly arrange commas in your function you get desired result

p_replace_na <- function(dataset, variable, value) {
if(inherits(dataset[,variable], "factor") == TRUE) {
  dataset[,variable] <- as.character(dataset[,variable])
  print(class(dataset[,variable]))
  dataset[, variable][is.na(dataset[, variable])] <- value
  dataset[, variable] <- as.factor(dataset[, variable])
  print(class(dataset[, variable]))
} else {
  dataset[, variable][is.na(dataset[, variable])] <- value
}
return(dataset)
}

> p_replace_na(ds_test, "c", value = -3)
[1] "character"
[1] "factor"
  a  b  c
1  1 NA  A
2 NA NA  b
3  2 NA -3

> t_replace_na(ds_test, "c", value = -3)
[1] "data.frame"
Error in sort.list(y) : 'x' must be atomic for 'sort.list'
Have you called 'sort' on a list?
>

Cheers
Petr



>
> Kind regards
>
> Georg
>
> --------------------------------
>
> > Gesendet: Donnerstag, 23. Juni 2016 um 21:14 Uhr
> > Von: "David L Carlson" <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>>
> > An: "Bert Gunter" <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
> > Cc: "R Help" <r-help at r-project.org<mailto:r-help at r-project.org>>
> > Betreff: Re: [R] Subscripting problem with is.na()
> >
> > Good point. I did not think about factors. Also your example raises
> another issue since column c is logical, but gets silently converted to
> numeric. This would seem to get the job done assuming the conversion is
> intended for numeric columns only:
> >
> > > test <- data.frame(a=c(1,NA,2), b = c("A","b",NA), c= rep(NA,3))
> > > sapply(test, class)
> >         a         b         c
> > "numeric"  "factor" "logical"
> > > num <- sapply(test, is.numeric)
> > > test[, num][is.na(test[, num])] <- 0
> > > test
> >   a    b  c
> > 1 1    A NA
> > 2 0    b NA
> > 3 2 <NA> NA
> >
> > David C
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-<http://www.r-project.org/posting->
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Mon Jun 27 16:25:24 2016
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 27 Jun 2016 09:25:24 -0500
Subject: [R] API key at start-up
Message-ID: <160EA301-7575-4D8B-B5C8-F38C2040180D@me.com>

All,

Is there a way to assign an API key to a value FREDAPI which is loaded and available once a R session is has started?

Glenn

From jdnewmil at dcn.davis.ca.us  Mon Jun 27 16:37:41 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Jun 2016 07:37:41 -0700
Subject: [R] Fwd: Fwd: RE: Heatmap.2 Breaks argument
In-Reply-To: <3b84e76c-1db6-ec3e-ed88-99e4d1a6fc42@whoi.edu>
References: <cc050fec-6de6-9c4b-54c1-d0543c8e7786@whoi.edu>
	<24fab935-996c-636b-80f6-d92171077c68@whoi.edu>
	<49646560-B9B6-4B4F-8644-E1ADCB096111@dcn.davis.ca.us>
	<3b84e76c-1db6-ec3e-ed88-99e4d1a6fc42@whoi.edu>
Message-ID: <05A36B0B-9557-4600-8794-722E4A4B6E77@dcn.davis.ca.us>

Please use Reply-All to keep the mailing list included in the conversation. I don't do private consulting via the Internet, and others can correct me if I give bad advice. 

I doubt the maintaner function "doesn't work"... more likely you did not read the help file to learn how to use it:

?maintainer

and tried to give it the name of a function instead of the name of the package containing that function:

# correct usage
maintainer( "gplots" )

You can confirm which package a function like heatmap.2 is in by reading the help file for that function:

?heatmap.2

or

help.search( "heatmap.2" )

if you have installed that package but not yet loaded it using library().
-- 
Sent from my phone. Please excuse my brevity.

On June 27, 2016 7:14:01 AM PDT, fgoetz <fgoetz at whoi.edu> wrote:
>Hi Jeff,
>
>I just tried the maintainerfunction but it did not work for heatmap.2.
>
>Best,
>
>Florian
>
>
>Am 24.06.2016 um 17:08 schrieb Jeff Newmiller:
>> Did you try the maintainer() function?


From jdnewmil at dcn.davis.ca.us  Mon Jun 27 16:44:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Jun 2016 07:44:38 -0700
Subject: [R] API key at start-up
In-Reply-To: <160EA301-7575-4D8B-B5C8-F38C2040180D@me.com>
References: <160EA301-7575-4D8B-B5C8-F38C2040180D@me.com>
Message-ID: <959D7461-3CFF-42DD-8FF8-B0548DDB4671@dcn.davis.ca.us>

"Assign ... key to a value" defies my understanding of those terms, and includes no context (API is a very vague term). We are not (necessarily) subject area experts in your preferred domain of jargon. 

Doing things when you start up your session is typically done as described in

?Startup
-- 
Sent from my phone. Please excuse my brevity.

On June 27, 2016 7:25:24 AM PDT, Glenn Schultz <glennmschultz at me.com> wrote:
>All,
>
>Is there a way to assign an API key to a value FREDAPI which is loaded
>and available once a R session is has started?
>
>Glenn
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wewolski at gmail.com  Mon Jun 27 17:51:17 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 27 Jun 2016 17:51:17 +0200
Subject: [R] performance of do.call("rbind")
Message-ID: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>

I have a list (variable name data.list) with approx 200k data.frames
with dim(data.frame) approx 100x3.

a call

data <-do.call("rbind", data.list)

does not complete - run time is prohibitive (I killed the rsession
after 5 minutes).

I would think that merging data.frame's is a common operation. Is
there a better function (more performant) that I could use?

Thank you.
Witold




-- 
Witold Eryk Wolski


From wewolski at gmail.com  Mon Jun 27 18:34:39 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 27 Jun 2016 18:34:39 +0200
Subject: [R] refclasses question - Defining accessor function
Message-ID: <CAAjnpdi0CJoa=2vSEpF6KNTn2=wDhjas_YU70u1msvzaQR2z8g@mail.gmail.com>

Are accessors a fancy feature that do not work?

I wanted to use accessor functions in a R refclass to hide the classes
implementation where I am using sqlite.

What I did observe is, that if I access in a method any of the fields
(in the example below field .data in method printExample) all the
accessor functions are called (even those not accessed by the function
: in this case funnydata is not accessed).

That means if any of the accessor functions is slow (in the example
the funnydata accessor sleeps for 3 s) all the fields and all
functions accessing any fields will be slow.
In the example below accessing .data or calling printExample will take 3s.

It's easy enough not to use accessor functions, so not a big deal.
Still, I lost quite a bit of time wondering what is happening.



Test <-setRefClass("Test",
                   fields = list( .data = "list",
                                  funnydata = function(x){
                                    Sys.sleep(3)
                                    if(missing(x)){
                                      Sys.sleep(3)
                                    }
                                  }
                   ),
                   methods = list(
                     initialise=function(){ .data <<- list(a="a")},

                     printExample = function(){
                       print("print Example")
                       print(.data)}
                     )
)

test<-Test()
test$printExample()
test$.data

-- 
Witold Eryk Wolski


From bgunter.4567 at gmail.com  Mon Jun 27 18:49:40 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 27 Jun 2016 09:49:40 -0700
Subject: [R] performance of do.call("rbind")
In-Reply-To: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
Message-ID: <CAGxFJbSsb8Wj8us62=6KKw347A+3WBBm-JB0FYuVOj9dvD2JhA@mail.gmail.com>

The following might be nonsense, as I have no understanding of R
internals; but ....

"Growing" structures in R by iteratively adding new pieces is often
warned to be inefficient when the number of iterations is large, and
your rbind() invocation might fall under this rubric. If so, you might
try  issuing the call say, 20 times, over 10k disjoint subsets of the
list, and then rbinding up the 20 large frames.

Again, caveat emptor.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 27, 2016 at 8:51 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> I have a list (variable name data.list) with approx 200k data.frames
> with dim(data.frame) approx 100x3.
>
> a call
>
> data <-do.call("rbind", data.list)
>
> does not complete - run time is prohibitive (I killed the rsession
> after 5 minutes).
>
> I would think that merging data.frame's is a common operation. Is
> there a better function (more performant) that I could use?
>
> Thank you.
> Witold
>
>
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Jun 27 18:51:59 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 27 Jun 2016 12:51:59 -0400
Subject: [R] performance of do.call("rbind")
In-Reply-To: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
Message-ID: <CAM_vjumT5-t6B9f6yaEsmvHa5hT5MF=TA__gu9S3503xzP7_9Q@mail.gmail.com>

There is a substantial overhead in rbind.dataframe() because of the
need to check the column types. Converting to matrix makes a huge
difference in speed, but be careful of type coercion.

testdf <- data.frame(matrix(runif(300), nrow=100, ncol=3))
testdf.list <- lapply(1:10000, function(x)testdf)

system.time(r.df <- do.call("rbind", testdf.list))

system.time({
testm.list <- lapply(testdf.list, as.matrix)
r.m <- do.call("rbind", testm.list)
})


> testdf <- data.frame(matrix(runif(300), nrow=100, ncol=3))
> testdf.list <- lapply(1:10000, function(x)testdf)
>
> system.time(r.df <- do.call("rbind", testdf.list))
   user  system elapsed
195.105  36.419 231.930
>
> system.time({
+ testm.list <- lapply(testdf.list, as.matrix)
+ r.m <- do.call("rbind", testm.list)
+ })
   user  system elapsed
  0.603   0.009   0.612

Sarah

On Mon, Jun 27, 2016 at 11:51 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> I have a list (variable name data.list) with approx 200k data.frames
> with dim(data.frame) approx 100x3.
>
> a call
>
> data <-do.call("rbind", data.list)
>
> does not complete - run time is prohibitive (I killed the rsession
> after 5 minutes).
>
> I would think that merging data.frame's is a common operation. Is
> there a better function (more performant) that I could use?
>
> Thank you.
> Witold
>
>
>


From wewolski at gmail.com  Mon Jun 27 18:54:50 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 27 Jun 2016 18:54:50 +0200
Subject: [R] performance of do.call("rbind")
In-Reply-To: <CAGxFJbSsb8Wj8us62=6KKw347A+3WBBm-JB0FYuVOj9dvD2JhA@mail.gmail.com>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
	<CAGxFJbSsb8Wj8us62=6KKw347A+3WBBm-JB0FYuVOj9dvD2JhA@mail.gmail.com>
Message-ID: <CAAjnpdjSOUcObQST08CDCzH3gfStg95XnJyiX0wYWN7qpHbYSw@mail.gmail.com>

Hi Bert,

You are most likely right. I just thought that do.call("rbind", is
somehow more clever and allocates the memory up front. My error. After
more searching I did find rbind.fill from plyr which seems to do the
job (it computes the size of the result data.frame and allocates it
first).

best

On 27 June 2016 at 18:49, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> The following might be nonsense, as I have no understanding of R
> internals; but ....
>
> "Growing" structures in R by iteratively adding new pieces is often
> warned to be inefficient when the number of iterations is large, and
> your rbind() invocation might fall under this rubric. If so, you might
> try  issuing the call say, 20 times, over 10k disjoint subsets of the
> list, and then rbinding up the 20 large frames.
>
> Again, caveat emptor.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 27, 2016 at 8:51 AM, Witold E Wolski <wewolski at gmail.com> wrote:
>> I have a list (variable name data.list) with approx 200k data.frames
>> with dim(data.frame) approx 100x3.
>>
>> a call
>>
>> data <-do.call("rbind", data.list)
>>
>> does not complete - run time is prohibitive (I killed the rsession
>> after 5 minutes).
>>
>> I would think that merging data.frame's is a common operation. Is
>> there a better function (more performant) that I could use?
>>
>> Thank you.
>> Witold
>>
>>
>>
>>
>> --
>> Witold Eryk Wolski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Witold Eryk Wolski


From jdnewmil at dcn.davis.ca.us  Mon Jun 27 19:00:32 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Jun 2016 10:00:32 -0700
Subject: [R] performance of do.call("rbind")
In-Reply-To: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
Message-ID: <FFAF98F1-9764-49C5-9F83-C73B05D3A779@dcn.davis.ca.us>

Your description of the data frames as "approx" puts the solution to considerable difficulty and speed penalty. If you want better performance you need a better handle on the data you are working with. 

For example, if you knew that every data frame had exactly three columns named identically and exactly 100 rows, then you could preallocate the result data frame and loop through the input data copying values directly to the appropriate destination locations in the result. 

To the extent that you can figure out things like the union of all column names or the total number of rows prior to starting copying data, you can adapt the above approach even if the input data frames are not identical. The key is not having to restructure/reallocate your result data frame as you go. 

The bind_rows function in the dplyr package can do a lot of this for you... but being a general-purpose function it may not be as optimized as you could do yourself with better knowledge of your data. 
-- 
Sent from my phone. Please excuse my brevity.

On June 27, 2016 8:51:17 AM PDT, Witold E Wolski <wewolski at gmail.com> wrote:
>I have a list (variable name data.list) with approx 200k data.frames
>with dim(data.frame) approx 100x3.
>
>a call
>
>data <-do.call("rbind", data.list)
>
>does not complete - run time is prohibitive (I killed the rsession
>after 5 minutes).
>
>I would think that merging data.frame's is a common operation. Is
>there a better function (more performant) that I could use?
>
>Thank you.
>Witold


From marc_schwartz at me.com  Mon Jun 27 19:05:40 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 27 Jun 2016 12:05:40 -0500
Subject: [R] performance of do.call("rbind")
In-Reply-To: <CAAjnpdjSOUcObQST08CDCzH3gfStg95XnJyiX0wYWN7qpHbYSw@mail.gmail.com>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
	<CAGxFJbSsb8Wj8us62=6KKw347A+3WBBm-JB0FYuVOj9dvD2JhA@mail.gmail.com>
	<CAAjnpdjSOUcObQST08CDCzH3gfStg95XnJyiX0wYWN7qpHbYSw@mail.gmail.com>
Message-ID: <E0F69270-7FF7-48EA-98B1-9C336D549A1F@me.com>

Hi,

Just to add my tuppence, which might not even be worth that these days...

I found the following blog post from 2013, which is likely dated to some extent, but provided some benchmarks for a few methods:

  http://rcrastinate.blogspot.com/2013/05/the-rbinding-race-for-vs-docall-vs.html

There is also a comment with a reference there to using the data.table package, which I don't use, but may be something to evaluate.

As Bert and Sarah hinted at, there is overhead in taking the repetitive piecemeal approach.

If all of your data frames are of the exact same column structure (column order, column types), it may be prudent to do your own pre-allocation of a data frame that is the target row total size and then "insert" each "sub" data frame by using row indexing into the target structure.

Regards,

Marc Schwartz


> On Jun 27, 2016, at 11:54 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> 
> Hi Bert,
> 
> You are most likely right. I just thought that do.call("rbind", is
> somehow more clever and allocates the memory up front. My error. After
> more searching I did find rbind.fill from plyr which seems to do the
> job (it computes the size of the result data.frame and allocates it
> first).
> 
> best
> 
> On 27 June 2016 at 18:49, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> The following might be nonsense, as I have no understanding of R
>> internals; but ....
>> 
>> "Growing" structures in R by iteratively adding new pieces is often
>> warned to be inefficient when the number of iterations is large, and
>> your rbind() invocation might fall under this rubric. If so, you might
>> try  issuing the call say, 20 times, over 10k disjoint subsets of the
>> list, and then rbinding up the 20 large frames.
>> 
>> Again, caveat emptor.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Mon, Jun 27, 2016 at 8:51 AM, Witold E Wolski <wewolski at gmail.com> wrote:
>>> I have a list (variable name data.list) with approx 200k data.frames
>>> with dim(data.frame) approx 100x3.
>>> 
>>> a call
>>> 
>>> data <-do.call("rbind", data.list)
>>> 
>>> does not complete - run time is prohibitive (I killed the rsession
>>> after 5 minutes).
>>> 
>>> I would think that merging data.frame's is a common operation. Is
>>> there a better function (more performant) that I could use?
>>> 
>>> Thank you.
>>> Witold
>>> 
>>> 
>>> 
>>> 
>>> --
>>> Witold Eryk Wolski
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Witold Eryk Wolski
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Jun 27 21:33:06 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 27 Jun 2016 15:33:06 -0400
Subject: [R] performance of do.call("rbind")
In-Reply-To: <E0F69270-7FF7-48EA-98B1-9C336D549A1F@me.com>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
	<CAGxFJbSsb8Wj8us62=6KKw347A+3WBBm-JB0FYuVOj9dvD2JhA@mail.gmail.com>
	<CAAjnpdjSOUcObQST08CDCzH3gfStg95XnJyiX0wYWN7qpHbYSw@mail.gmail.com>
	<E0F69270-7FF7-48EA-98B1-9C336D549A1F@me.com>
Message-ID: <CAM_vju=q-CrCasQrwq1UqxD+jn2nuUb6SWJND81c2LmjWgV87A@mail.gmail.com>

That's not what I said, though, and it's not necessarily true. Growing
an object within a loop _is_ a slow process, but that's not the
problem here. The problem is using data frames instead of matrices.
The need to manage column classes is very costly. Converting to
matrices will almost always be enormously faster.

Here's an expansion of the previous example I posted, in four parts:
1. do.call with data frame - very slow - 34.317 s elapsed time for
2000 data frames
2. do.call with matrix - very fast - 0.311 s elapsed
3. pre-allocated loop with data frame - even slower (!) - 82.162 s
4. pre-allocated loop with matrix - very fast - 68.009 s

It matters whether the columns are converted to numeric or character,
and the time doesn't scale linearly with list length. For a particular
problem, the best solution may vary greatly (and I didn't even include
packages beyond the base functionality). In general, though, using
matrices is faster than using data frames, and using do.call is faster
than using a pre-allocated loop, which is much faster than growing an
object.

Sarah

> testsize <- 5000
>
> set.seed(1234)
> testdf <- data.frame(matrix(runif(300), nrow=100, ncol=3))
> testdf.list <- lapply(seq_len(testsize), function(x)testdf)
>
> system.time(r.df <- do.call("rbind", testdf.list))
   user  system elapsed
 34.280   0.009  34.317
>
> system.time({
+ testm.list <- lapply(testdf.list, as.matrix)
+ r.m <- do.call("rbind", testm.list)
+ })
   user  system elapsed
  0.310   0.000   0.311
>
> system.time({
+ l.df <- data.frame(matrix(NA, nrow=100 * testsize, ncol=3))
+ for(i in seq_len(testsize)) {
+ start <- (i-1)*100 + 1
+ end <- i*100
+ l.df[start:end, ] <- testdf.list[[i]]
+ }
+ })
   user  system elapsed
 81.890   0.069  82.162
>
> system.time({
+ l.m <- data.frame(matrix(NA, nrow=100 * testsize, ncol=3))
+ testm.list <- lapply(testdf.list, as.matrix)
+ for(i in seq_len(testsize)) {
+ start <- (i-1)*100 + 1
+ end <- i*100
+ l.m[start:end, ] <- testm.list[[i]]
+ }
+ })
   user  system elapsed
 67.664   0.047  68.009




On Mon, Jun 27, 2016 at 1:05 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> Hi,
>
> Just to add my tuppence, which might not even be worth that these days...
>
> I found the following blog post from 2013, which is likely dated to some extent, but provided some benchmarks for a few methods:
>
>   http://rcrastinate.blogspot.com/2013/05/the-rbinding-race-for-vs-docall-vs.html
>
> There is also a comment with a reference there to using the data.table package, which I don't use, but may be something to evaluate.
>
> As Bert and Sarah hinted at, there is overhead in taking the repetitive piecemeal approach.
>
> If all of your data frames are of the exact same column structure (column order, column types), it may be prudent to do your own pre-allocation of a data frame that is the target row total size and then "insert" each "sub" data frame by using row indexing into the target structure.
>
> Regards,
>
> Marc Schwartz
>
>
>> On Jun 27, 2016, at 11:54 AM, Witold E Wolski <wewolski at gmail.com> wrote:
>>
>> Hi Bert,
>>
>> You are most likely right. I just thought that do.call("rbind", is
>> somehow more clever and allocates the memory up front. My error. After
>> more searching I did find rbind.fill from plyr which seems to do the
>> job (it computes the size of the result data.frame and allocates it
>> first).
>>
>> best
>>
>> On 27 June 2016 at 18:49, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> The following might be nonsense, as I have no understanding of R
>>> internals; but ....
>>>
>>> "Growing" structures in R by iteratively adding new pieces is often
>>> warned to be inefficient when the number of iterations is large, and
>>> your rbind() invocation might fall under this rubric. If so, you might
>>> try  issuing the call say, 20 times, over 10k disjoint subsets of the
>>> list, and then rbinding up the 20 large frames.
>>>
>>> Again, caveat emptor.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Jun 27, 2016 at 8:51 AM, Witold E Wolski <wewolski at gmail.com> wrote:
>>>> I have a list (variable name data.list) with approx 200k data.frames
>>>> with dim(data.frame) approx 100x3.
>>>>
>>>> a call
>>>>
>>>> data <-do.call("rbind", data.list)
>>>>
>>>> does not complete - run time is prohibitive (I killed the rsession
>>>> after 5 minutes).
>>>>
>>>> I would think that merging data.frame's is a common operation. Is
>>>> there a better function (more performant) that I could use?
>>>>
>>>> Thank you.
>>>> Witold
>>>>


From hpages at fredhutch.org  Mon Jun 27 21:58:42 2016
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 27 Jun 2016 12:58:42 -0700
Subject: [R] performance of do.call("rbind")
In-Reply-To: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
Message-ID: <57718572.6040201@fredhutch.org>

Hi,

Note that if your list of 200k data frames is the result of splitting
a big data frame, then trying to rbind the result of the split is
equivalent to reordering the orginal big data frame. More precisely,

   do.call(rbind, unname(split(df, f)))

is equivalent to

   df[order(f), , drop=FALSE]

(except for the rownames), but the latter is *much* faster!

Cheers,
H.


On 06/27/2016 08:51 AM, Witold E Wolski wrote:
> I have a list (variable name data.list) with approx 200k data.frames
> with dim(data.frame) approx 100x3.
>
> a call
>
> data <-do.call("rbind", data.list)
>
> does not complete - run time is prohibitive (I killed the rsession
> after 5 minutes).
>
> I would think that merging data.frame's is a common operation. Is
> there a better function (more performant) that I could use?
>
> Thank you.
> Witold
>
>
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From 538280 at gmail.com  Mon Jun 27 23:42:35 2016
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 27 Jun 2016 15:42:35 -0600
Subject: [R] What's box() (exactly) doing?
In-Reply-To: <CAM3-KjYPbjAyztSsTH-2w9LcRHgs28SykcZd-RhuHH715hRc2Q@mail.gmail.com>
References: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
	<137eccf8762b48a793527114f21ce677@CONNHUB3.connect.uwaterloo.ca>
	<CAM3-KjayGettZV63qv77uiXuc6JVEv=CnwYawMwug+3rHT9Cbw@mail.gmail.com>
	<CAM3-KjYPbjAyztSsTH-2w9LcRHgs28SykcZd-RhuHH715hRc2Q@mail.gmail.com>
Message-ID: <CAFEqCdzJzWBY3E3GeGTL-YLay6fLL+SLyiBv_-5tN=yqtUY+Bg@mail.gmail.com>

You can use the grconvertX and grconvertY functions to find the
coordinates (in user coordinates to pass to rect) of the figure region
(or other regions).

Probably something like:
grconvertX(c(0,1), from='nfc', to='user')
grconvertY(c(0,1), from='nfc', to='user')




On Fri, Jun 24, 2016 at 8:19 PM, Marius Hofert
<marius.hofert at uwaterloo.ca> wrote:
> Hi Jim,
>
> Here is a follow-up question: How would you replicate box("figure")
> (instead of box() = box("plot"))?
> I tried to fill the plotted box but there seems to be no argument to
> box("figure") that does that. If that's indeed the case, one could
> work again with rect() (thus replicating box("figure")), but how can
> one specify the exact location/width/height of the rectangle? (see
> example below)
>
> Cheers,
> M
>
> plot(NA, type = "n", ann = TRUE, axes = TRUE, xlim = 0:1, ylim = 0:1)
> box("figure", col = "red", lwd = 2) # how to fill?
>
> par(xpd = TRUE)
> width = 1.4 # obviously not correct...
> height <- width
> loc.x <- 0.5
> loc.y <- 0.5
> xleft <- loc.x-width/2
> xright <- loc.x+width/2
> ybottom <- loc.y-height/2
> ytop <- loc.y+height/2
> rect(xleft = xleft, ybottom = ybottom, xright = xright, ytop = ytop,
>      col = adjustcolor("grey80", alpha.f = 0.5))
> par(xpd = FALSE)
>
> On Fri, Jun 24, 2016 at 8:40 PM, Marius Hofert
> <marius.hofert at uwaterloo.ca> wrote:
>> Hi Jim,
>>
>> Thanks a lot, exactly what I was looking for.
>>
>> Cheers,
>> Marius
>>
>>
>>
>> On Thu, Jun 23, 2016 at 11:06 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> Hi Marius,
>>> There are a few things that are happening here. First, the plot area
>>> is not going to be the same as your x and y limits unless you say so:
>>>
>>> # run your first example
>>> par("usr")
>>> [1] -0.04  1.04 -0.04  1.04
>>>
>>> # but
>>> plot(NA, type = "n", ann = FALSE, axes = FALSE,
>>>  xlim = 0:1, ylim = 0:1,xaxs="i",yaxs="i")
>>> box()
>>> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
>>> par("usr")
>>> [1] 0 1 0 1
>>>
>>> Second, the "rect" function is automatically clipped to the plot area,
>>> so you may lose a bit at the edges if you don't override this:
>>>
>>> par(xpd=TRUE)
>>> rect(...)
>>> par(xpd=FALSE)
>>>
>>> Finally your second example simply multiplies the first problem by
>>> specifying a layout of more than one plot. Applying the "xaxs" and
>>> "yaxs" parameters before you start plotting will fix this:
>>>
>>> par(xaxs="i",yaxs="i")
>>>
>>> Jim
>>>
>>> On Fri, Jun 24, 2016 at 12:29 PM, Marius Hofert
>>> <marius.hofert at uwaterloo.ca> wrote:
>>>> Hi,
>>>>
>>>> I would like to replicate the behavior of box() with rect() (don't ask why).
>>>> However, my rect()angles are always too small. I looked a bit into the
>>>> internal C_box but
>>>> couldn't figure out how to solve the problem. Below is a minimal
>>>> working (and a slightly bigger) example.
>>>>
>>>> Cheers,
>>>> Marius
>>>>
>>>> ## MWE
>>>> plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
>>>> rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80") #
>>>> should match box()
>>>> box()
>>>>
>>>> ## Extended example
>>>>
>>>> ## Basic plot
>>>> my_rect <- function()
>>>> {
>>>>     plot(NA, type = "n", ann = FALSE, axes = FALSE, xlim = 0:1, ylim = 0:1)
>>>>     rect(xleft = 0, ybottom = 0, xright = 1, ytop = 1, col = "grey80")
>>>> # should match box()
>>>>     box()
>>>> }
>>>>
>>>> ## Layout
>>>> lay <- matrix(0, nrow = 3, ncol = 3, byrow = TRUE)
>>>> lay[1,1] <- 1
>>>> lay[2,1] <- 2
>>>> lay[2,2] <- 3
>>>> lay[2,3] <- 4
>>>> lay[3,3] <- 5
>>>> layout(lay, heights = c(1, 10, 1), widths = c(10, 1, 10))
>>>> layout.show(5) # => no space between rectangles; calls box() to draw the boxes
>>>>
>>>> ## Fill layout
>>>> par(oma = rep(0, 4), mar = rep(0, 4))
>>>> my_rect()
>>>> my_rect()
>>>> my_rect()
>>>> my_rect()
>>>> my_rect()
>>>> ## => spaces between rectangles => why?/how to avoid?
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From vwkv13 at mun.ca  Tue Jun 28 00:40:53 2016
From: vwkv13 at mun.ca (Kodalore Vijayan, Vineetha W)
Date: Mon, 27 Jun 2016 16:40:53 -0600
Subject: [R] Call subroutine init_random_seed () in R
Message-ID: <CALStW+r3W8YVZkVLUWqF8RG2cEy638EFyeoXttcT9S2TanDN0g@mail.gmail.com>

I want to call the subroutine init_random_seed() in R. The subroutine is
defined as an example in the following link.

https://gcc.gnu.org/onlinedocs/gfortran/RANDOM_005fSEED.html

subroutine init_random_seed()
        use iso_fortran_env, only: int64
        implicit none
        integer, allocatable :: seed(:)
        integer :: i, n, un, istat, dt(8), pid
        integer(int64) :: t

        call random_seed(size = n)
        allocate(seed(n))
        ! First try if the OS provides a random number generator
        open(newunit=un, file="/dev/urandom", access="stream", &
             form="unformatted", action="read", status="old", iostat=istat)
        if (istat == 0) then
           read(un) seed
           close(un)
        .............
        .......

    end subroutine init_random_seed

I do not know what variable goes in when you write the function
.fortran () in R. Any guidance is appreciated.

	[[alternative HTML version deleted]]


From marius.hofert at uwaterloo.ca  Tue Jun 28 04:24:36 2016
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Mon, 27 Jun 2016 22:24:36 -0400
Subject: [R] What's box() (exactly) doing?
In-Reply-To: <df7431a64ef64817871077441cbe3a66@CONNHUB3.connect.uwaterloo.ca>
References: <CAM3-KjZ0wLs1gJ5jom4KKJGJ2YkKy+0e+nL+G1pcZ_z73rTyLA@mail.gmail.com>
	<137eccf8762b48a793527114f21ce677@CONNHUB3.connect.uwaterloo.ca>
	<CAM3-KjayGettZV63qv77uiXuc6JVEv=CnwYawMwug+3rHT9Cbw@mail.gmail.com>
	<CAM3-KjYPbjAyztSsTH-2w9LcRHgs28SykcZd-RhuHH715hRc2Q@mail.gmail.com>
	<df7431a64ef64817871077441cbe3a66@CONNHUB3.connect.uwaterloo.ca>
Message-ID: <CAM3-KjaXXngy0gCmbtuhjkaDD3tWximpLy1ffX4=o1J=UmgEBw@mail.gmail.com>

On Mon, Jun 27, 2016 at 5:42 PM, Greg Snow <538280 at gmail.com> wrote:
> You can use the grconvertX and grconvertY functions to find the
> coordinates (in user coordinates to pass to rect) of the figure region
> (or other regions).
>
> Probably something like:
> grconvertX(c(0,1), from='nfc', to='user')
> grconvertY(c(0,1), from='nfc', to='user')

Hi Greg,

Thanks, that's good to know.

Cheers,
Marius


From p_connolly at slingshot.co.nz  Tue Jun 28 04:59:07 2016
From: p_connolly at slingshot.co.nz (p_connolly)
Date: Tue, 28 Jun 2016 14:59:07 +1200
Subject: [R] > Understanding strip.default & strip.custom
Message-ID: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>

I'm having difficulty following the help for those functions.

My plot has a single conditioning factor with 12 levels.  My
factor.levels in a call to strip.default looks like this:

  factor.levels = expression(Needles~ "::"~alpha -pinene,
                             Stems~ "::"~alpha -pinene,
                             Needles~ "::"~beta -pinene,
                             Stems~ "::"~beta -pinene,
                             Needles~ ":: B?Phellandrene",
                             Stems~ ":: B?Phellandrene",
                             Needles~ ":: Camphene",
                             Stems~ ":: Camphene",
                             Needles~ ":: Myrcene",
                             Stems~ ":: Myrcene",
                             Needles~ ":: Limonene",
                             Stems~ "::Limonene")

Since there is only one factor, which.given must be 1.
Likewise, var.name must be of length 1.

What I can't understand is the argument which.panel.  The help says:

which.panel: vector of integers as long as the number of conditioning
           variables. The contents are indices specifying the current
           levels of each of the conditioning variables (thus, this
           would be unique for each distinct packet).  This is identical
           to the return value of ?which.packet?, which is a more
           accurate name.

So, that must be of length 1 also, according to the first sentence,
but if I set it to 1, I get the first strip label repeated 12 times.
Set it to 2, I get the second one 12 times.  Set it to 1:2, it
attempts to squash 2 strips in the space of 1, labelling the first
one.   I don't understand the second sentence at all.

What do I do to get all 12 in their correct order?

I couldn't find an example remotely like what I'm trying to do.  Are
there any pointers?

TIA
Patrick


From jdnewmil at dcn.davis.ca.us  Tue Jun 28 05:34:53 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Jun 2016 20:34:53 -0700 (PDT)
Subject: [R] performance of do.call("rbind")
In-Reply-To: <CAM_vju=q-CrCasQrwq1UqxD+jn2nuUb6SWJND81c2LmjWgV87A@mail.gmail.com>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
	<CAGxFJbSsb8Wj8us62=6KKw347A+3WBBm-JB0FYuVOj9dvD2JhA@mail.gmail.com>
	<CAAjnpdjSOUcObQST08CDCzH3gfStg95XnJyiX0wYWN7qpHbYSw@mail.gmail.com>
	<E0F69270-7FF7-48EA-98B1-9C336D549A1F@me.com>
	<CAM_vju=q-CrCasQrwq1UqxD+jn2nuUb6SWJND81c2LmjWgV87A@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1606271646300.64634@pedal.dcn.davis.ca.us>

Sarah, you make it sound as though everyone should be using matrices, even 
though they have distinct disadvantages for many types of analysis.

You are right that rbind on data frames is slow, but dplyr::bind_rows 
handles data frames almost as fast as your rbind-ing matrices solution.

And if you apply knowledge of your data frames and don't do the error 
checking that bind_rows does, you can beat both of them without converting 
to matrices, as the "tm.dfcolcat" solution below illustrates. (Not for 
everyday use, but if you have a big job and the data are clean this may 
make a difference.)

Data frames, handled properly, are only slightly slower than matrices for 
most purposes. I have seen numerical solutions of partial differential 
equations run lightning fast using pre-allocated data frames and vector 
calculations, so even traditional "matrix" calculation domains don't have 
use matrices to be competitive.

######################
testsize <- 5000
N <- 20

set.seed(1234)
testdf.list <- lapply( seq_len( testsize )
                      , function( x ) {
                         data.frame( matrix( runif( 300 ), nrow=100 ) )
                        }
                      )

tm.rbind <- function( x = 0 ) {
   system.time( r.df <- do.call( "rbind", testdf.list ) )
}
#toss the first one
tm.rbind()
tms.rbind <- data.frame( do.call( rbind
                                 , lapply( 1:N
                                         , tm.rbind
                                         )
                                 )
                        , which = "rbind"
                        )

tm.rbindm <- function( x = 0 ) {
   system.time({
     testm.list <- lapply( testdf.list, as.matrix )
     r.m <- do.call( rbind, testm.list )
   })
}
#toss the first one
tm.rbindm()
tms.rbindm <- data.frame( do.call( rbind
                                  , lapply( 1:N
                                          , tm.rbindm
                                          )
                                  )
                         , which = "rbindm"
                         )

tm.dfcopy <- function(x=0) {
   system.time({
     l.df <- data.frame( matrix( NA
                               , nrow=100 * testsize
                               , ncol=3
                               )
                       )
     for ( i in seq_len( testsize ) ) {
       start <- ( i - 1 ) * 100 + 1
       end <- i * 100
       l.df[ start:end, ] <- testdf.list[[ i ]]
     }
   })
}
#toss the first one
tm.dfcopy()
tms.dfcopy <- data.frame( do.call( rbind
                                  , lapply( 1:N
                                          , tm.dfcopy
                                          )
                                  )
                         , which = "dfcopy"
                         )

tm.dfmatcopy <- function(x=0) {
   system.time({
     l.m <- data.frame( matrix( NA
                              , nrow=100 * testsize
                              , ncol = 3
                              )
                      )
     testm.list <- lapply( testdf.list, as.matrix )
     for ( i in seq_len( testsize ) ) {
       start <- ( i - 1 ) * 100 + 1
       end <- i * 100
       l.m[ start:end, ] <- testm.list[[ i ]]
     }
   })
}
#toss the first one
tm.dfmatcopy()
tms.dfmatcopy <- data.frame( do.call( rbind
                                     , lapply( 1:N
                                             , tm.dfmatcopy
                                             )
                                     )
                            , which = "dfmatcopy"
                            )

tm.bind_rows <- function(x=0) {
   system.time({
     dplyr::bind_rows( testdf.list )
   })
}
#toss the first one
tm.bind_rows()
tms.bind_rows <- data.frame( do.call( rbind
                                     , lapply( 1:N
                                             , tm.bind_rows
                                             )
                                     )
                            , which = "bind_rows"
                            )

tm.dfcolcat <- function(x=0) {
   system.time({
     mycolnames <- names( testdf.list[[ 1 ]] )
     result <-
       setNames( data.frame( lapply( mycolnames
                                   , function( colidx ) {
                                       do.call( c
                                              , lapply( testdf.list
                                                      , function( v ) {
                                                          v[[ colidx ]]
                                                        }
                                                      )
                                              )
                                     }
                                   )
                           )
               , mycolnames
               )
       })
}
#toss the first one
tm.dfcolcat()
tms.dfcolcat <- data.frame( do.call( rbind, lapply( 1:N
                                                   , tm.dfcolcat
                                                   )
                                    )
                           , which = "dfcolcat"
                           )

tms.sarah <- read.table( text=
"   user  system elapsed  which
   34.280   0.009  34.317  tm.rbind
    0.310   0.000   0.311  tm.rbindm
   81.890   0.069  82.162  tm.dfcopy
   67.664   0.047  68.009  tm.dfmatcopy
", header = TRUE, as.is=TRUE )
mergetms <- rbind( tms.rbind
                  , tms.rbindm
                  , tms.dfcopy
                  , tms.dfmatcopy
                  , tms.bind_rows
                  , tms.dfcolcat
                  )
mergetms$which <- factor( mergetms$which
                         , levels = c( "rbind"
                                     , "rbindm"
                                     , "dfcopy"
                                     , "dfmatcopy"
                                     , "bind_rows"
                                     , "dfcolcat"
                                     )
                         )
plot( user.self ~ which, data=mergetms )
plot( user.self ~ which, data=mergetms, ylim=c(0,4) )

summary( tms.rbind )
#   user.self        sys.self         elapsed        user.child    sys.child
# Min.   :18.84   Min.   :0.0000   Min.   :18.92   Min.   : NA   Min.   : NA
# 1st Qu.:20.83   1st Qu.:0.0275   1st Qu.:20.96   1st Qu.: NA   1st Qu.: NA
# Median :22.91   Median :0.0400   Median :23.00   Median : NA   Median : NA
# Mean   :25.06   Mean   :0.0430   Mean   :25.21   Mean   :NaN   Mean   :NaN
# 3rd Qu.:24.29   3rd Qu.:0.0600   3rd Qu.:24.39   3rd Qu.: NA   3rd Qu.: NA
# Max.   :39.36   Max.   :0.1000   Max.   :39.94   Max.   : NA   Max.   : NA
#                                                  NA's   :20    NA's   :20

summary( tms.rbindm )
#   user.self         sys.self    elapsed         user.child    sys.child
# Min.   :0.2200   Min.   :0   Min.   :0.2200   Min.   : NA   Min.   : NA
# 1st Qu.:0.5600   1st Qu.:0   1st Qu.:0.5800   1st Qu.: NA   1st Qu.: NA
# Median :0.5850   Median :0   Median :0.5900   Median : NA   Median : NA
# Mean   :0.5465   Mean   :0   Mean   :0.5555   Mean   :NaN   Mean   :NaN
# 3rd Qu.:0.5900   3rd Qu.:0   3rd Qu.:0.5925   3rd Qu.: NA   3rd Qu.: NA
# Max.   :0.6100   Max.   :0   Max.   :0.6100   Max.   : NA   Max.   : NA
#                                               NA's   :20    NA's   :20

summary( tms.dfcopy )
#   user.self        sys.self         elapsed        user.child    sys.child
# Min.   :114.2   Min.   :0.0000   Min.   :114.3   Min.   : NA   Min.   : NA
# 1st Qu.:122.7   1st Qu.:0.0000   1st Qu.:123.0   1st Qu.: NA   1st Qu.: NA
# Median :128.3   Median :0.0050   Median :128.4   Median : NA   Median : NA
# Mean   :134.5   Mean   :0.0185   Mean   :134.8   Mean   :NaN   Mean   :NaN
# 3rd Qu.:134.7   3rd Qu.:0.0325   3rd Qu.:134.8   3rd Qu.: NA   3rd Qu.: NA
# Max.   :261.5   Max.   :0.0800   Max.   :263.4   Max.   : NA   Max.   : NA
#                                                  NA's   :20    NA's   :20

summary( tms.dfmatcopy )
#   user.self         sys.self         elapsed        user.child    sys.child
# Min.   : 98.15   Min.   : 0.050   Min.   :102.0   Min.   : NA   Min.   : NA
# 1st Qu.:136.47   1st Qu.: 3.495   1st Qu.:144.6   1st Qu.: NA   1st Qu.: NA
# Median :147.53   Median : 7.135   Median :158.3   Median : NA   Median : NA
# Mean   :177.10   Mean   : 7.030   Mean   :185.2   Mean   :NaN   Mean   :NaN
# 3rd Qu.:159.12   3rd Qu.:10.932   3rd Qu.:166.9   3rd Qu.: NA   3rd Qu.: NA
# Max.   :362.95   Max.   :16.100   Max.   :364.3   Max.   : NA   Max.   : NA
#                                                   NA's   :20    NA's

summary( tms.bind_rows )
#   user.self         sys.self    elapsed         user.child    sys.child
# Min.   :0.8200   Min.   :0   Min.   :0.8200   Min.   : NA   Min.   : NA
# 1st Qu.:0.8300   1st Qu.:0   1st Qu.:0.8375   1st Qu.: NA   1st Qu.: NA
# Median :0.8400   Median :0   Median :0.8400   Median : NA   Median : NA
# Mean   :0.8460   Mean   :0   Mean   :0.8480   Mean   :NaN   Mean   :NaN
# 3rd Qu.:0.8525   3rd Qu.:0   3rd Qu.:0.8525   3rd Qu.: NA   3rd Qu.: NA
# Max.   :0.9400   Max.   :0   Max.   :0.9900   Max.   : NA   Max.   : NA
#                                               NA's   :20    NA's   :20

summary( tms.dfcolcat )
# user.self        sys.self    elapsed        user.child    sys.child
# Min.   :0.340   Min.   :0   Min.   :0.340   Min.   : NA   Min.   : NA
# 1st Qu.:0.350   1st Qu.:0   1st Qu.:0.350   1st Qu.: NA   1st Qu.: NA
# Median :0.360   Median :0   Median :0.360   Median : NA   Median : NA
# Mean   :0.358   Mean   :0   Mean   :0.357   Mean   :NaN   Mean   :NaN
# 3rd Qu.:0.360   3rd Qu.:0   3rd Qu.:0.360   3rd Qu.: NA   3rd Qu.: NA
# Max.   :0.380   Max.   :0   Max.   :0.380   Max.   : NA   Max.   : NA
#                                             NA's   :20    NA's   :20


######################

On Mon, 27 Jun 2016, Sarah Goslee wrote:

> That's not what I said, though, and it's not necessarily true. Growing
> an object within a loop _is_ a slow process, but that's not the
> problem here. The problem is using data frames instead of matrices.
> The need to manage column classes is very costly. Converting to
> matrices will almost always be enormously faster.
>
> Here's an expansion of the previous example I posted, in four parts:
> 1. do.call with data frame - very slow - 34.317 s elapsed time for
> 2000 data frames
> 2. do.call with matrix - very fast - 0.311 s elapsed
> 3. pre-allocated loop with data frame - even slower (!) - 82.162 s
> 4. pre-allocated loop with matrix - very fast - 68.009 s
>
> It matters whether the columns are converted to numeric or character,
> and the time doesn't scale linearly with list length. For a particular
> problem, the best solution may vary greatly (and I didn't even include
> packages beyond the base functionality). In general, though, using
> matrices is faster than using data frames, and using do.call is faster
> than using a pre-allocated loop, which is much faster than growing an
> object.
>
> Sarah
>
>> testsize <- 5000
>>
>> set.seed(1234)
>> testdf <- data.frame(matrix(runif(300), nrow=100, ncol=3))
>> testdf.list <- lapply(seq_len(testsize), function(x)testdf)
>>
>> system.time(r.df <- do.call("rbind", testdf.list))
>   user  system elapsed
> 34.280   0.009  34.317
>>
>> system.time({
> + testm.list <- lapply(testdf.list, as.matrix)
> + r.m <- do.call("rbind", testm.list)
> + })
>   user  system elapsed
>  0.310   0.000   0.311
>>
>> system.time({
> + l.df <- data.frame(matrix(NA, nrow=100 * testsize, ncol=3))
> + for(i in seq_len(testsize)) {
> + start <- (i-1)*100 + 1
> + end <- i*100
> + l.df[start:end, ] <- testdf.list[[i]]
> + }
> + })
>   user  system elapsed
> 81.890   0.069  82.162
>>
>> system.time({
> + l.m <- data.frame(matrix(NA, nrow=100 * testsize, ncol=3))
> + testm.list <- lapply(testdf.list, as.matrix)
> + for(i in seq_len(testsize)) {
> + start <- (i-1)*100 + 1
> + end <- i*100
> + l.m[start:end, ] <- testm.list[[i]]
> + }
> + })
>   user  system elapsed
> 67.664   0.047  68.009
>
>
>
>
> On Mon, Jun 27, 2016 at 1:05 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>> Hi,
>>
>> Just to add my tuppence, which might not even be worth that these days...
>>
>> I found the following blog post from 2013, which is likely dated to some extent, but provided some benchmarks for a few methods:
>>
>>   http://rcrastinate.blogspot.com/2013/05/the-rbinding-race-for-vs-docall-vs.html
>>
>> There is also a comment with a reference there to using the data.table package, which I don't use, but may be something to evaluate.
>>
>> As Bert and Sarah hinted at, there is overhead in taking the repetitive piecemeal approach.
>>
>> If all of your data frames are of the exact same column structure (column order, column types), it may be prudent to do your own pre-allocation of a data frame that is the target row total size and then "insert" each "sub" data frame by using row indexing into the target structure.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>>> On Jun 27, 2016, at 11:54 AM, Witold E Wolski <wewolski at gmail.com> wrote:
>>>
>>> Hi Bert,
>>>
>>> You are most likely right. I just thought that do.call("rbind", is
>>> somehow more clever and allocates the memory up front. My error. After
>>> more searching I did find rbind.fill from plyr which seems to do the
>>> job (it computes the size of the result data.frame and allocates it
>>> first).
>>>
>>> best
>>>
>>> On 27 June 2016 at 18:49, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> The following might be nonsense, as I have no understanding of R
>>>> internals; but ....
>>>>
>>>> "Growing" structures in R by iteratively adding new pieces is often
>>>> warned to be inefficient when the number of iterations is large, and
>>>> your rbind() invocation might fall under this rubric. If so, you might
>>>> try  issuing the call say, 20 times, over 10k disjoint subsets of the
>>>> list, and then rbinding up the 20 large frames.
>>>>
>>>> Again, caveat emptor.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Mon, Jun 27, 2016 at 8:51 AM, Witold E Wolski <wewolski at gmail.com> wrote:
>>>>> I have a list (variable name data.list) with approx 200k data.frames
>>>>> with dim(data.frame) approx 100x3.
>>>>>
>>>>> a call
>>>>>
>>>>> data <-do.call("rbind", data.list)
>>>>>
>>>>> does not complete - run time is prohibitive (I killed the rsession
>>>>> after 5 minutes).
>>>>>
>>>>> I would think that merging data.frame's is a common operation. Is
>>>>> there a better function (more performant) that I could use?
>>>>>
>>>>> Thank you.
>>>>> Witold
>>>>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From kmnanus at gmail.com  Tue Jun 28 03:12:20 2016
From: kmnanus at gmail.com (KMNanus)
Date: Mon, 27 Jun 2016 21:12:20 -0400
Subject: [R] Turning a variable name into a function argument
Message-ID: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>

I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.  

I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.


myfun <- function(myvar, new.name){
  function(new.name){return(as.character(substitute(new.name)))}
  ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
  geom_point() + 
  geom_line()+
  xlab("Minimum Games" ) +
  ylab(paste(new.name, ?Average Change"))+
  ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
  theme_bw()

When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.

I want ggplot to automatically insert Tuesday into ylab and ggtitle.

Can anyone help me with this?  Thanks for your patience.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)




From bgunter.4567 at gmail.com  Tue Jun 28 07:17:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 27 Jun 2016 22:17:54 -0700
Subject: [R] > Understanding strip.default & strip.custom
In-Reply-To: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>
References: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>
Message-ID: <CAGxFJbTVAG7kEv6eLLAu2eVn-2QJgVMrBF_SSSE4=hMKKmCTWA@mail.gmail.com>

It's a vector of **length** 1, not **value** 1. In your case it gives
the index (1 to 12) of the level being drawn in the panel, which is
used to draw the strip according to other strip parameters, esp.
style.

You seem to be making this way more difficult than you should.
strip.default is the **function** being used to draw the strips in
each panel. Generally speaking, you should not have to mess with
arguments like which.panel and should probably use strip.custom()
instead.  Do carefully go through the examples in ?strip and ?xyplot.
That may help.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 27, 2016 at 7:59 PM, p_connolly <p_connolly at slingshot.co.nz> wrote:
> I'm having difficulty following the help for those functions.
>
> My plot has a single conditioning factor with 12 levels.  My
> factor.levels in a call to strip.default looks like this:
>
>  factor.levels = expression(Needles~ "::"~alpha -pinene,
>                             Stems~ "::"~alpha -pinene,
>                             Needles~ "::"~beta -pinene,
>                             Stems~ "::"~beta -pinene,
>                             Needles~ ":: B?Phellandrene",
>                             Stems~ ":: B?Phellandrene",
>                             Needles~ ":: Camphene",
>                             Stems~ ":: Camphene",
>                             Needles~ ":: Myrcene",
>                             Stems~ ":: Myrcene",
>                             Needles~ ":: Limonene",
>                             Stems~ "::Limonene")
>
> Since there is only one factor, which.given must be 1.
> Likewise, var.name must be of length 1.
>
> What I can't understand is the argument which.panel.  The help says:
>
> which.panel: vector of integers as long as the number of conditioning
>           variables. The contents are indices specifying the current
>           levels of each of the conditioning variables (thus, this
>           would be unique for each distinct packet).  This is identical
>           to the return value of ?which.packet?, which is a more
>           accurate name.
>
> So, that must be of length 1 also, according to the first sentence,
> but if I set it to 1, I get the first strip label repeated 12 times.
> Set it to 2, I get the second one 12 times.  Set it to 1:2, it
> attempts to squash 2 strips in the space of 1, labelling the first
> one.   I don't understand the second sentence at all.
>
> What do I do to get all 12 in their correct order?
>
> I couldn't find an example remotely like what I'm trying to do.  Are
> there any pointers?
>
> TIA
> Patrick
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue Jun 28 08:55:10 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 28 Jun 2016 16:55:10 +1000
Subject: [R] > Understanding strip.default & strip.custom
In-Reply-To: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>
References: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>
Message-ID: <000a01d1d10a$03bad8b0$0b308a10$@bigpond.com>

Hi Patrick

does this help?

  dat <-
  data.frame(x = rnorm(12*5,0,1),
             y = rnorm(12*5,0,1),
             gp = factor(1:12))
  dat$NS = ifelse(sapply(dat$gp, pmatch,flN, nomatch = 0) > 0, "Needles","Stems")
   dat = dat[order(dat[,"NS"]),]
  dat$GP = factor(1:6)

xyplot(y ~ x|gp, data = dat,
      par.settings = list(strip.background = list(col = "transparent")
                     ),
  strip    = strip.custom(factor.levels = expression(Needles~ "::"~alpha -pinene,
                             Stems~ "::"~alpha -pinene,
                             Needles~ "::"~beta -pinene,
                             Stems~ "::"~beta -pinene,
                             Needles~ ":: B?Phellandrene",
                             Stems~ ":: B?Phellandrene",
                             Needles~ ":: Camphene",
                             Stems~ ":: Camphene",
                             Needles~ ":: Myrcene",
                             Stems~ ":: Myrcene",
                             Needles~ ":: Limonene",
                             Stems~ "::Limonene"),
   par.strip.text = list(cex = 0.65) ))
   
library(latticeExtra)
  useOuterStrips(strip    = strip.custom(factor.levels = expression("::"~alpha -pinene,
                               "::"~beta -pinene,
                               ":: B?Phellandrene",
                               ":: Camphene",
                               ":: Myrcene",
                               ":: Limonene")),
 xyplot(y ~ x|GP*NS, data = dat,
      drop.unused = T,
      par.settings = list(strip.background = list(col = "transparent")
                     ),
     par.strip.text = list(cex = 0.65) )
 ) 
   
If you want to change the order of the factors assign the factor levels to a vector and order accordingly

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of p_connolly
Sent: Tuesday, 28 June 2016 12:59
To: r-help at stat.math.ethz.ch
Subject: [R] > Understanding strip.default & strip.custom

I'm having difficulty following the help for those functions.

My plot has a single conditioning factor with 12 levels.  My
factor.levels in a call to strip.default looks like this:

  factor.levels = expression(Needles~ "::"~alpha -pinene,
                             Stems~ "::"~alpha -pinene,
                             Needles~ "::"~beta -pinene,
                             Stems~ "::"~beta -pinene,
                             Needles~ ":: B?Phellandrene",
                             Stems~ ":: B?Phellandrene",
                             Needles~ ":: Camphene",
                             Stems~ ":: Camphene",
                             Needles~ ":: Myrcene",
                             Stems~ ":: Myrcene",
                             Needles~ ":: Limonene",
                             Stems~ "::Limonene")

Since there is only one factor, which.given must be 1.
Likewise, var.name must be of length 1.

What I can't understand is the argument which.panel.  The help says:

which.panel: vector of integers as long as the number of conditioning
           variables. The contents are indices specifying the current
           levels of each of the conditioning variables (thus, this
           would be unique for each distinct packet).  This is identical
           to the return value of ?which.packet?, which is a more
           accurate name.

So, that must be of length 1 also, according to the first sentence,
but if I set it to 1, I get the first strip label repeated 12 times.
Set it to 2, I get the second one 12 times.  Set it to 1:2, it
attempts to squash 2 strips in the space of 1, labelling the first
one.   I don't understand the second sentence at all.

What do I do to get all 12 in their correct order?

I couldn't find an example remotely like what I'm trying to do.  Are
there any pointers?

TIA
Patrick

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From david.lindholm at outlook.com  Tue Jun 28 08:33:14 2016
From: david.lindholm at outlook.com (David .)
Date: Tue, 28 Jun 2016 06:33:14 +0000
Subject: [R] R Crashes with .C
Message-ID: <DB5PR05MB11899854EC8ED307886A199085220@DB5PR05MB1189.eurprd05.prod.outlook.com>

Hi everyone,


I'm a beginner in R and I'm trying to load a .dll file, named dll.dll, that's written in C, into R. It seems to work, now I want to use the functions that are stored in the .dll file and I encounter problems.

I've searched for a solution or other method in manuals, here and on google. Would be very thankful if I could get a suggestion of what to use or any idea!

My code:

setwd("C:/Users/MyUser/R")
dyn.load("dll.dll")
is.loaded("DLL_FUNK")
# For some reason True with capital letters, not in lower case
output <- .C("DLL_FUNK", in9 = as.integer(7))
#output # R Crashes before I can write this.
# R Crashes
# In outdata.txt: "in-value=   139375128"

The function should return a number, 1955. But I can't seem to get to that value. What am I doing wrong?

Update with code (Fortran runned as C), this is the code in dll.dll:

subroutine  dll_funk(in9)
implicit none

!+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
!***      Declarations: variables, functions
!+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
integer(4) :: in9
!integer :: in9


! Definitions of variables in the external function calls
!!dec$ attributes c,alias :'dll_funk' :: dll_funk
!dec$ attributes dllexport            :: dll_funk
!dec$ attributes value                :: in9

open(194,file='outdata.txt')
write(194,*) 'in-value=', in9
! in9 = 1955
close(194)

end subroutine
!end function

So now when it runs, R crashes but before it writes to my file (outdata.txt) but it't not my number, maybe some kind of address...

Another question, do you recommend me to run the code with .C and from C run the Fortran code or is it better to run it with .Fortran with only Fortran code? It seems like .Fortran have problem handling strings, or that's what I understood from: Interface func .C and .Fortran<https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Interface-functions-_002eC-and-_002eFortran>

Thanks for your time!

Best regards,
David



	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Tue Jun 28 09:03:11 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 28 Jun 2016 07:03:11 +0000 (UTC)
Subject: [R] Get the location of a numeric element in a list
References: <665703594.2703871.1467097391720.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <665703594.2703871.1467097391720.JavaMail.yahoo@mail.yahoo.com>

Can any one please help me. I will apply this for a very large list, about 400k vector in a list and vector size is unequal and large

Example : 
Input: 
a <- c(1,3,6,9,25,100) 
b<-c(10,7,20,2,25) 
c<-c(1,7,5,15,25,300,1000) 
d<-list(a,b,c) 

Expected outcome : 
# When looking for 1 in d
c(1,3)

# When looking for 7 in d

c(2,3)

# when looking for 25 in d
c(1,2,3)
# When looking for 50 in d
NULL or 0


Thanks in advance !!





Tanvir Ahamed 
G?teborg, Sweden  |  mashranga at yahoo.com


From drjimlemon at gmail.com  Tue Jun 28 10:14:29 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 28 Jun 2016 18:14:29 +1000
Subject: [R] Get the location of a numeric element in a list
In-Reply-To: <665703594.2703871.1467097391720.JavaMail.yahoo@mail.yahoo.com>
References: <665703594.2703871.1467097391720.JavaMail.yahoo.ref@mail.yahoo.com>
	<665703594.2703871.1467097391720.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fUe_k2a81bGtTfv9gcayqUss1tx=d5qPQe84BkK0TBiVA@mail.gmail.com>

Hi Tanvir,
How about this:

value<-1
(1:length(d))[unlist(lapply(lapply(d,"==",value),any))]

Jim


On Tue, Jun 28, 2016 at 5:03 PM, Mohammad Tanvir Ahamed via R-help
<r-help at r-project.org> wrote:
> Can any one please help me. I will apply this for a very large list, about 400k vector in a list and vector size is unequal and large
>
> Example :
> Input:
> a <- c(1,3,6,9,25,100)
> b<-c(10,7,20,2,25)
> c<-c(1,7,5,15,25,300,1000)
> d<-list(a,b,c)
>
> Expected outcome :
> # When looking for 1 in d
> c(1,3)
>
> # When looking for 7 in d
>
> c(2,3)
>
> # when looking for 25 in d
> c(1,2,3)
> # When looking for 50 in d
> NULL or 0
>
>
> Thanks in advance !!
>
>
>
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Jun 28 10:23:36 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 28 Jun 2016 08:23:36 +0000
Subject: [R] Get the location of a numeric element in a list
In-Reply-To: <665703594.2703871.1467097391720.JavaMail.yahoo@mail.yahoo.com>
References: <665703594.2703871.1467097391720.JavaMail.yahoo.ref@mail.yahoo.com>
	<665703594.2703871.1467097391720.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5032AA9@SRVEXCHMBX.precheza.cz>

Hi

This could give you desired result, however I am not sure about performance or elegancy.

which(sapply((lapply(d, "==", 1)), any))

Or you can transform it to a function

fff <- function(x,a) which(sapply((lapply(x, "==", a)), any))

> fff(d, 25)
[1] 1 2 3
> fff(d, 5)
[1] 3
> fff(d, 1)
[1] 1 3
> fff(d, 50)
integer(0)
>

Beware also the trap of floating point representation if your numbers are not integer (FAQ 7.31)

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Mohammad Tanvir Ahamed via R-help
> Sent: Tuesday, June 28, 2016 9:03 AM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] Get the location of a numeric element in a list
>
> Can any one please help me. I will apply this for a very large list, about 400k
> vector in a list and vector size is unequal and large
>
> Example :
> Input:
> a <- c(1,3,6,9,25,100)
> b<-c(10,7,20,2,25)
> c<-c(1,7,5,15,25,300,1000)
> d<-list(a,b,c)
>
> Expected outcome :
> # When looking for 1 in d
> c(1,3)
>
> # When looking for 7 in d
>
> c(2,3)
>
> # when looking for 25 in d
> c(1,2,3)
> # When looking for 50 in d
> NULL or 0
>
>
> Thanks in advance !!
>
>
>
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From martin.morgan at roswellpark.org  Tue Jun 28 11:07:59 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 28 Jun 2016 05:07:59 -0400
Subject: [R] Get the location of a numeric element in a list
In-Reply-To: <665703594.2703871.1467097391720.JavaMail.yahoo@mail.yahoo.com>
References: <665703594.2703871.1467097391720.JavaMail.yahoo.ref@mail.yahoo.com>
	<665703594.2703871.1467097391720.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <57723E6F.3090009@roswellpark.org>

On 06/28/2016 03:03 AM, Mohammad Tanvir Ahamed via R-help wrote:
> Can any one please help me. I will apply this for a very large list, about 400k vector in a list and vector size is unequal and large
>
> Example :
> Input:
> a <- c(1,3,6,9,25,100)
> b<-c(10,7,20,2,25)
> c<-c(1,7,5,15,25,300,1000)
> d<-list(a,b,c)
>
> Expected outcome :
> # When looking for 1 in d
> c(1,3)
>
> # When looking for 7 in d
>
> c(2,3)
>
> # when looking for 25 in d
> c(1,2,3)
> # When looking for 50 in d
> NULL or 0

Make a vector of queries

     queries = c(1, 7, 25, 50)

Create a factor of unlist(d), using queries as levels. Create a vector 
rep(seq_along(d), lengths(d)), and split it into groups defined by f

     f = factor(unlist(d, use.names=FALSE), levels=queries)
     split(rep(seq_along(d), lengths(d)), f)

Martin Morgan

>
>
> Thanks in advance !!
>
>
>
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From faradj.g at gmail.com  Tue Jun 28 13:34:55 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Tue, 28 Jun 2016 13:34:55 +0200
Subject: [R] How to create these variables in R?
Message-ID: <9F6EAA3D-6A01-4910-A125-DD648DF8CD84@gmail.com>

Dear all, 

Let?s say that I have a dataset that looks something like this: 


Subject Year    A   
    A   1990    1   
    A   1991    1   
    A   1992    1   
    A   1993    1   
    A   1994    0   
    A   1995    0   
    B   1990    1   
    B   1991    0   
    B   1992    1   
    B   1993    1   
    C   1991    1   
    C   1992    1   
    C   1993    0   
    C   1994    1   
    D   1991    0   
    D   1992    1  
    D   1993    1   
    D   1994    0   
    D   1995    0   
    D   1996    1   
    D   1997    1   


What I would like to do is to create the following three new variables: A1, A2, and A3 
The variable A1 should capture/count all 1?s in the variable A that are in a row (counting), for each subject-year ? but it  should restart counting if there 
are two 0?s in a row (displayed 
below). 

The variable A2 should capture 1-2?s (range) in the A1. Displayed in the example below.(subject-year) 

The variable A3 should capture all values in the variable A1 that are more than 2, also displayed in the example data below.(subject-year) 


See the example below for illustration of these variables


Subject Year    A   A1  A2  A3
    A   1990    1   1   1   0
    A   1991    1   2   1   0
    A   1992    1   3   0   1
    A   1993    1   4   0   1
    A   1994    0   0   0   0
    A   1995    0   0   0   0
    B   1990    1   1   1   0
    B   1991    0   1   1   0
    B   1992    1   2   1   0
    B   1993    1   3   0   1
    C   1991    1   1   1   0
    C   1992    1   2   1   0
    C   1993    0   2   1   0
    C   1994    1   3   0   1
    D   1991    0   0   0   0
    D   1992    1   1   1   0
    D   1993    1   2   1   0
    D   1994    0   0   0   0
    D   1995    0   0   0   0
    D   1996    1   1   1   0
    D   1997    1   2   1   0


I?ve no clue where to start at this stage ?I?d appreciate any suggestions and help. 



	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Jun 28 13:50:23 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Jun 2016 07:50:23 -0400
Subject: [R] How to create these variables in R?
In-Reply-To: <9F6EAA3D-6A01-4910-A125-DD648DF8CD84@gmail.com>
References: <9F6EAA3D-6A01-4910-A125-DD648DF8CD84@gmail.com>
Message-ID: <daead821-9ba2-883b-b4d5-3cb91a40ef6d@gmail.com>

On 28/06/2016 7:34 AM, Faradj Koliev wrote:
> Dear all,
>
> Let?s say that I have a dataset that looks something like this:
>
>
> Subject Year    A
>     A   1990    1
>     A   1991    1
>     A   1992    1
>     A   1993    1
>     A   1994    0
>     A   1995    0
>     B   1990    1
>     B   1991    0
>     B   1992    1
>     B   1993    1
>     C   1991    1
>     C   1992    1
>     C   1993    0
>     C   1994    1
>     D   1991    0
>     D   1992    1
>     D   1993    1
>     D   1994    0
>     D   1995    0
>     D   1996    1
>     D   1997    1
>
>
> What I would like to do is to create the following three new variables: A1, A2, and A3
> The variable A1 should capture/count all 1?s in the variable A that are in a row (counting), for each subject-year ? but it  should restart counting if there
> are two 0?s in a row (displayed
> below).
>
> The variable A2 should capture 1-2?s (range) in the A1. Displayed in the example below.(subject-year)
>
> The variable A3 should capture all values in the variable A1 that are more than 2, also displayed in the example data below.(subject-year)

A1 has a pretty complicated definition.  There's likely a vectorized way 
to write it, but it won't be easy to read.  I'd just use a loop.  Your 
rules are a little ambiguous (are 0 and 1 the only possible values?) so 
I won't try, but it should be straightforward for you to write the loop.

A2 and A3 are easy:

A2 <- as.numeric(A1 %in% 1:2)
A3 <- as.numeric(A1 > 2)

Duncan Murdoch

>
>
> See the example below for illustration of these variables
>
>
> Subject Year    A   A1  A2  A3
>     A   1990    1   1   1   0
>     A   1991    1   2   1   0
>     A   1992    1   3   0   1
>     A   1993    1   4   0   1
>     A   1994    0   0   0   0
>     A   1995    0   0   0   0
>     B   1990    1   1   1   0
>     B   1991    0   1   1   0
>     B   1992    1   2   1   0
>     B   1993    1   3   0   1
>     C   1991    1   1   1   0
>     C   1992    1   2   1   0
>     C   1993    0   2   1   0
>     C   1994    1   3   0   1
>     D   1991    0   0   0   0
>     D   1992    1   1   1   0
>     D   1993    1   2   1   0
>     D   1994    0   0   0   0
>     D   1995    0   0   0   0
>     D   1996    1   1   1   0
>     D   1997    1   2   1   0
>
>
> I?ve no clue where to start at this stage ?I?d appreciate any suggestions and help.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mashranga at yahoo.com  Tue Jun 28 14:26:43 2016
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 28 Jun 2016 12:26:43 +0000 (UTC)
Subject: [R] Get the location of a numeric element in a list
In-Reply-To: <57723E6F.3090009@roswellpark.org>
References: <665703594.2703871.1467097391720.JavaMail.yahoo.ref@mail.yahoo.com>
	<665703594.2703871.1467097391720.JavaMail.yahoo@mail.yahoo.com>
	<57723E6F.3090009@roswellpark.org>
Message-ID: <1669550016.2839696.1467116803411.JavaMail.yahoo@mail.yahoo.com>

Thanks Martin Morgan. Thats works excellent on a large data . 
 Tanvir Ahamed 
G?teborg, Sweden   |  mashranga at yahoo.com 


----- Original Message -----
From: Martin Morgan <martin.morgan at roswellpark.org>
To: Mohammad Tanvir Ahamed <mashranga at yahoo.com>; R-help Mailing List <r-help at r-project.org>
Sent: Tuesday, 28 June 2016, 11:07
Subject: Re: [R] Get the location of a numeric element in a list

On 06/28/2016 03:03 AM, Mohammad Tanvir Ahamed via R-help wrote:
> Can any one please help me. I will apply this for a very large list, about 400k vector in a list and vector size is unequal and large
>
> Example :
> Input:
> a <- c(1,3,6,9,25,100)
> b<-c(10,7,20,2,25)
> c<-c(1,7,5,15,25,300,1000)
> d<-list(a,b,c)
>
> Expected outcome :
> # When looking for 1 in d
> c(1,3)
>
> # When looking for 7 in d
>
> c(2,3)
>
> # when looking for 25 in d
> c(1,2,3)
> # When looking for 50 in d
> NULL or 0

Make a vector of queries

     queries = c(1, 7, 25, 50)

Create a factor of unlist(d), using queries as levels. Create a vector 
rep(seq_along(d), lengths(d)), and split it into groups defined by f

     f = factor(unlist(d, use.names=FALSE), levels=queries)
     split(rep(seq_along(d), lengths(d)), f)

Martin Morgan


>
>
> Thanks in advance !!
>
>
>
>
>
> Tanvir Ahamed
> G?teborg, Sweden  |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From chalabi.elahe at yahoo.de  Tue Jun 28 16:48:30 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Tue, 28 Jun 2016 14:48:30 +0000 (UTC)
Subject: [R] R intersect()
References: <1706928832.4857357.1467125310695.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1706928832.4857357.1467125310695.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I have the following df:


    licenseY      :int  41006 41013 41044 41046 41067 41166 41202 41262 41274 41290
    licenseZ      :int  41006 41013 41018 41044 41046 41067 41111 41200 41262 41272
I needed the common values in both license columns so I used :
    

    intersect(df$licenseY,df$licenseZ)
now I want a command to return me values from licenseY that are not in intersect(). Does anyone know how should I do this?
Thanks for any help!
Elahe


From sarah.goslee at gmail.com  Tue Jun 28 16:55:22 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 28 Jun 2016 10:55:22 -0400
Subject: [R] performance of do.call("rbind")
In-Reply-To: <alpine.BSF.2.00.1606271646300.64634@pedal.dcn.davis.ca.us>
References: <CAAjnpdiOPR3t5KB5LBvu5gYVdThuDZNuRxZumAi8zNrGO7uLuA@mail.gmail.com>
	<CAGxFJbSsb8Wj8us62=6KKw347A+3WBBm-JB0FYuVOj9dvD2JhA@mail.gmail.com>
	<CAAjnpdjSOUcObQST08CDCzH3gfStg95XnJyiX0wYWN7qpHbYSw@mail.gmail.com>
	<E0F69270-7FF7-48EA-98B1-9C336D549A1F@me.com>
	<CAM_vju=q-CrCasQrwq1UqxD+jn2nuUb6SWJND81c2LmjWgV87A@mail.gmail.com>
	<alpine.BSF.2.00.1606271646300.64634@pedal.dcn.davis.ca.us>
Message-ID: <CAM_vjukTify1h7pv52fiQdmG25jH6ZOdcn7mZY_=L5s7G6sOJQ@mail.gmail.com>

On Mon, Jun 27, 2016 at 11:34 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Sarah, you make it sound as though everyone should be using matrices, even
> though they have distinct disadvantages for many types of analysis.

I'm saying that if you don't need the special features of a data
frame, many operations are enormously faster on matrices.

Sarah


From S.Ellison at LGCGroup.com  Tue Jun 28 17:02:15 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 28 Jun 2016 16:02:15 +0100
Subject: [R] R intersect()
In-Reply-To: <1706928832.4857357.1467125310695.JavaMail.yahoo@mail.yahoo.com>
References: <1706928832.4857357.1467125310695.JavaMail.yahoo.ref@mail.yahoo.com>
	<1706928832.4857357.1467125310695.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403EADE0CC2@GBTEDVPEXCMB04.corp.lgc-group.com>


>     licenseY      :int  41006 41013 41044 41046 41067 41166 41202 41262 41274 41290
>     licenseZ      :int  41006 41013 41018 41044 41046 41067 41111 41200 41262 41272
> ... I want a command to return me values from licenseY that are not in
> intersect(). Does anyone know how should I do this?

Consider 
setdiff( licenseY, licenseX) 

or, more or less equivalently,
licenseY[ (!licenseY %in% licenseX) ]

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From chalabi.elahe at yahoo.de  Tue Jun 28 17:04:10 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Tue, 28 Jun 2016 15:04:10 +0000 (UTC)
Subject: [R] R intersect()
In-Reply-To: <3a327548-2809-2f6e-a4d9-7197a4feff38@gmail.com>
References: <1706928832.4857357.1467125310695.JavaMail.yahoo.ref@mail.yahoo.com>
	<1706928832.4857357.1467125310695.JavaMail.yahoo@mail.yahoo.com>
	<3a327548-2809-2f6e-a4d9-7197a4feff38@gmail.com>
Message-ID: <1084541282.4822450.1467126251008.JavaMail.yahoo@mail.yahoo.com>

Yes, found it. Thanks


On Tuesday, June 28, 2016 4:57 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
On 28/06/2016 10:48 AM, ch.elahe via R-help wrote:

> Hi all,
> I have the following df:
>
>
>      licenseY      :int  41006 41013 41044 41046 41067 41166 41202 41262 41274 41290
>      licenseZ      :int  41006 41013 41018 41044 41046 41067 41111 41200 41262 41272
> I needed the common values in both license columns so I used :
>      
>
>      intersect(df$licenseY,df$licenseZ)
> now I want a command to return me values from licenseY that are not in intersect(). Does anyone know how should I do this?

setdiff() is documented on the same page as intersect().

Duncan Murdoch


From e.monse11 at hotmail.es  Tue Jun 28 11:46:19 2016
From: e.monse11 at hotmail.es (=?iso-8859-1?Q?Monse_Buena=F1o?=)
Date: Tue, 28 Jun 2016 09:46:19 +0000
Subject: [R] (sin asunto)
Message-ID: <SN2PR16MB10222D0F64DCCDA7E307729889220@SN2PR16MB1022.namprd16.prod.outlook.com>

Excuse me, I want to change my e-mail adress, where I receive your e-mails. Can you help me?

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Jun 28 18:20:13 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 28 Jun 2016 09:20:13 -0700
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
Message-ID: <8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>


> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com> wrote:
> 
> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.  
> 
> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.
> 
> 
> myfun <- function(myvar, new.name){
>  function(new.name){return(as.character(substitute(new.name)))}
>  ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>  geom_point() + 
>  geom_line()+
>  xlab("Minimum Games" ) +
>  ylab(paste(new.name, ?Average Change"))+
>  ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
>  theme_bw()
> 
> When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.

Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name` in the calling environment. Sounds unlikely that you are typing:

myfun(myvar, new.name)  ## ?, so was there a loop/lapply calling method?


Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name` in the calling environment.)

Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.

-- 
David.


> 
> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
> 
> Can anyone help me with this?  Thanks for your patience.
> 
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From syen04 at gmail.com  Tue Jun 28 18:26:52 2016
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 28 Jun 2016 12:26:52 -0400
Subject: [R] t-test for regression estimate
Message-ID: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>

test option for linearHypothesis in library(car) include "Chisq" and 
"F". I prefer a simple t-test so that I can retrieve the standard error. 
Any options other than linearHypothesis to test the linear hypothesis 
(with 1 restriction/degree of freedom)?

 > summary(ols1)

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept) -0.20013    0.09199  -2.176   0.0298 *
age          0.04054    0.01721   2.355   0.0187 *
suburb       0.01911    0.05838   0.327   0.7435
smcity      -0.29969    0.19175  -1.563   0.1184
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

 > linearHypothesis(ols1,"suburb")
Linear hypothesis test

Hypothesis:
suburb = 0

Model 1: restricted model
Model 2: polideo ~ age + suburb + smcity

   Res.Df    RSS Df Sum of Sq      F Pr(>F)
1    888 650.10
2    887 650.02  1  0.078534 0.1072 0.7435


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Jun 28 18:31:03 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Jun 2016 12:31:03 -0400
Subject: [R] (sin asunto)
In-Reply-To: <SN2PR16MB10222D0F64DCCDA7E307729889220@SN2PR16MB1022.namprd16.prod.outlook.com>
References: <SN2PR16MB10222D0F64DCCDA7E307729889220@SN2PR16MB1022.namprd16.prod.outlook.com>
Message-ID: <03c2985a-ad9e-0b96-8776-9c46226857c6@gmail.com>

On 28/06/2016 5:46 AM, Monse Buena?o wrote:
> Excuse me, I want to change my e-mail adress, where I receive your e-mails. Can you help me?

Follow the link below:
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

Duncan Murdoch


From jdnewmil at dcn.davis.ca.us  Tue Jun 28 18:53:21 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 28 Jun 2016 09:53:21 -0700
Subject: [R] (sin asunto)
In-Reply-To: <SN2PR16MB10222D0F64DCCDA7E307729889220@SN2PR16MB1022.namprd16.prod.outlook.com>
References: <SN2PR16MB10222D0F64DCCDA7E307729889220@SN2PR16MB1022.namprd16.prod.outlook.com>
Message-ID: <8E08D886-B992-49C0-B107-D6AB9CAFA029@dcn.davis.ca.us>

Follow the listinfo link in the footer. You should be in possession of a password with which to make changes to your subscription there.
-- 
Sent from my phone. Please excuse my brevity.

On June 28, 2016 2:46:19 AM PDT, "Monse Buena?o" <e.monse11 at hotmail.es> wrote:
>Excuse me, I want to change my e-mail adress, where I receive your
>e-mails. Can you help me?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Jun 28 19:18:27 2016
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 28 Jun 2016 17:18:27 +0000
Subject: [R] t-test for regression estimate
In-Reply-To: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
Message-ID: <5e1da62cf6b94aa29105fa1ee82e0e19@UM-MAIL3216.unimaas.nl>

But the second column in coef(summary(ols1)) gives you the SE, so why not use that? Otherwise, you may want to look into the 'multcomp' package and its glht() function.

Best,
Wolfgang

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven
> Yen
> Sent: Tuesday, June 28, 2016 18:27
> To: R-help
> Subject: [R] t-test for regression estimate
> 
> test option for linearHypothesis in library(car) include "Chisq" and
> "F". I prefer a simple t-test so that I can retrieve the standard error.
> Any options other than linearHypothesis to test the linear hypothesis
> (with 1 restriction/degree of freedom)?
> 
>  > summary(ols1)
> 
> Coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept) -0.20013    0.09199  -2.176   0.0298 *
> age          0.04054    0.01721   2.355   0.0187 *
> suburb       0.01911    0.05838   0.327   0.7435
> smcity      -0.29969    0.19175  -1.563   0.1184
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
>  > linearHypothesis(ols1,"suburb")
> Linear hypothesis test
> 
> Hypothesis:
> suburb = 0
> 
> Model 1: restricted model
> Model 2: polideo ~ age + suburb + smcity
> 
>    Res.Df    RSS Df Sum of Sq      F Pr(>F)
> 1    888 650.10
> 2    887 650.02  1  0.078534 0.1072 0.7435

From kmnanus at gmail.com  Tue Jun 28 20:10:43 2016
From: kmnanus at gmail.com (KMNanus)
Date: Tue, 28 Jun 2016 14:10:43 -0400
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
	<8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
Message-ID: <70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>

Thanks for getting back to me, I?m sorry if I was unclear.

What I?m trying to figure out is the equivalent of ?find and replace? in Word.

I have a function - 

myfun <- function(z){
ggplot(df, aes(x,y)+
geom_point() + 
ggtitle (?_______ quick brown fox jumped over the lazy dog?)}

Calling myfun(z) works perfectly.  What I?m trying to do is add a string to myfun so that it would read:  function(z, ?string?){

Then I could call myfun(z, ?string?) to replace the space in ggtitle.  Is there a straightforward way to do that?

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Jun 28, 2016, at 12:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com> wrote:
>> 
>> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.  
>> 
>> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.
>> 
>> 
>> myfun <- function(myvar, new.name){
>> function(new.name){return(as.character(substitute(new.name)))}
>> ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>> geom_point() + 
>> geom_line()+
>> xlab("Minimum Games" ) +
>> ylab(paste(new.name, ?Average Change"))+
>> ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
>> theme_bw()
>> 
>> When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.
> 
> Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name` in the calling environment. Sounds unlikely that you are typing:
> 
> myfun(myvar, new.name)  ## ?, so was there a loop/lapply calling method?
> 
> 
> Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name` in the calling environment.)
> 
> Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.
> 
> -- 
> David.
> 
> 
>> 
>> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
>> 
>> Can anyone help me with this?  Thanks for your patience.
>> 
>> Ken
>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA


From 538280 at gmail.com  Tue Jun 28 21:42:09 2016
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 28 Jun 2016 13:42:09 -0600
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
	<8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
	<70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>
Message-ID: <CAFEqCdxZ6RHiFms=YST71pna151jZdkrcVLJhE1orWXdW6HcwQ@mail.gmail.com>

There are several options.  The option that is most like search and
replace is to use the `sub` or `gsub` function (or similar functions
in added packages).  But you may be able to accomplish what you want
even simpler by using the `paste`, `paste0`, or `sprintf` functions.

On Tue, Jun 28, 2016 at 12:10 PM, KMNanus <kmnanus at gmail.com> wrote:
> Thanks for getting back to me, I?m sorry if I was unclear.
>
> What I?m trying to figure out is the equivalent of ?find and replace? in Word.
>
> I have a function -
>
> myfun <- function(z){
> ggplot(df, aes(x,y)+
> geom_point() +
> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}
>
> Calling myfun(z) works perfectly.  What I?m trying to do is add a string to myfun so that it would read:  function(z, ?string?){
>
> Then I could call myfun(z, ?string?) to replace the space in ggtitle.  Is there a straightforward way to do that?
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
>> On Jun 28, 2016, at 12:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>>
>>> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>
>>> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.
>>>
>>> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.
>>>
>>>
>>> myfun <- function(myvar, new.name){
>>> function(new.name){return(as.character(substitute(new.name)))}
>>> ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>>> geom_point() +
>>> geom_line()+
>>> xlab("Minimum Games" ) +
>>> ylab(paste(new.name, ?Average Change"))+
>>> ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
>>> theme_bw()
>>>
>>> When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.
>>
>> Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name` in the calling environment. Sounds unlikely that you are typing:
>>
>> myfun(myvar, new.name)  ## ?, so was there a loop/lapply calling method?
>>
>>
>> Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name` in the calling environment.)
>>
>> Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.
>>
>> --
>> David.
>>
>>
>>>
>>> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
>>>
>>> Can anyone help me with this?  Thanks for your patience.
>>>
>>> Ken
>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>> 914-450-0816 (tel)
>>> 347-730-4813 (fax)
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From vivek4 at mail.usf.edu  Tue Jun 28 22:36:47 2016
From: vivek4 at mail.usf.edu (Vivek Singh)
Date: Tue, 28 Jun 2016 16:36:47 -0400
Subject: [R] Not able to install RODBC package
Message-ID: <CAJGK8=_do_e7AHaiqr09TQ5QBF=aYn6HXP7WgMM5Yj4JEhB1yw@mail.gmail.com>

> install.packages('RODBC')
Installing package into ?/home/vivek/R/x86_64-pc-linux-gnu-library/3.0?
(as ?lib? is unspecified)
Warning: unable to access index for repository
https://cloud.r-project.org/src/contrib
Warning message:
package ?RODBC? is not available (for R version 3.0.2)

Please suggest any way to either install the package or use another package
to connect MySQL database from R.


Regards,

Vivek Kumar Singh

PhD student,
Information Systems Decision Sciences,
MUMA College of Business,
USF
Phone- (813) 5809131
Web: http://vivek4.myweb.usf.edu/

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Tue Jun 28 22:40:55 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 28 Jun 2016 20:40:55 +0000
Subject: [R] Calculating Value at Risk
Message-ID: <e1d5f0cee5ef4583b423a72c6377992d@ex13-live-mbn1.ad.kent.ac.uk>

Dear all,
As I am working on Value at Risk, I am looking for an appropriate package to calculate Value at Risk using different methods beyond the historical method. In doing so, I have found the package jvnVaR which provides several methods to calculate VaR. Nevertheless, I am interested in calculating the Monte Carlo VaR and the GARCH (1,1) VaR.

Does anybody know another package which provides  functions to calculate VaR?

Kind regards

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Jun 28 23:03:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 28 Jun 2016 14:03:06 -0700
Subject: [R] Calculating Value at Risk
In-Reply-To: <e1d5f0cee5ef4583b423a72c6377992d@ex13-live-mbn1.ad.kent.ac.uk>
References: <e1d5f0cee5ef4583b423a72c6377992d@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <CAGxFJbTD1y3Mi11=CsoW=dw+TtWnOCVNKQqO_w+OOo0Th9-uiQ@mail.gmail.com>

1. Search!
rseek.org is an R-centric search site that you should always try. A
quick search there turned up the PerformanceAnalytics package. There
may be others, too.

2. Search the cran task views. There are finance and econometrics task
views that should be relevant.

3. Post on a more appropriate mailing list, in this case
r-sig-finance, rather than here.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 28, 2016 at 1:40 PM, T.Riedle <tr206 at kent.ac.uk> wrote:
> Dear all,
> As I am working on Value at Risk, I am looking for an appropriate package to calculate Value at Risk using different methods beyond the historical method. In doing so, I have found the package jvnVaR which provides several methods to calculate VaR. Nevertheless, I am interested in calculating the Monte Carlo VaR and the GARCH (1,1) VaR.
>
> Does anybody know another package which provides  functions to calculate VaR?
>
> Kind regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Tue Jun 28 23:11:56 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 28 Jun 2016 16:11:56 -0500
Subject: [R] Not able to install RODBC package
In-Reply-To: <CAJGK8=_do_e7AHaiqr09TQ5QBF=aYn6HXP7WgMM5Yj4JEhB1yw@mail.gmail.com>
References: <CAJGK8=_do_e7AHaiqr09TQ5QBF=aYn6HXP7WgMM5Yj4JEhB1yw@mail.gmail.com>
Message-ID: <C32518BC-09AE-44B6-86C0-B54DD1779C7A@me.com>

On Jun 28, 2016, at 3:36 PM, Vivek Singh <vivek4 at mail.usf.edu> wrote:
> 
>> install.packages('RODBC')
> Installing package into ?/home/vivek/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> Warning: unable to access index for repository
> https://cloud.r-project.org/src/contrib
> Warning message:
> package ?RODBC? is not available (for R version 3.0.2)
> 
> Please suggest any way to either install the package or use another package
> to connect MySQL database from R.
> 
> 
> Regards,
> 
> Vivek Kumar Singh


Hi,

Typically that error is an indication of a problem accessing and reading files on the CRAN mirror, possibly due to a proxy/firewall issue on your end and/or perhaps that your R installation does not support HTTPS (secure http). If the former, you may need to check with your SysAdmin.

You might try to select a different CRAN mirror, including one that is not secure http (regular http:// URL) to see if that works.

Also, note that the version of R that you are running (3.0.2) is from Sep of 2013, so quite dated. The current version is 3.3.1, which was just released this month.

Regards,

Marc Schwartz


From vivek4 at mail.usf.edu  Tue Jun 28 23:27:20 2016
From: vivek4 at mail.usf.edu (Vivek Singh)
Date: Tue, 28 Jun 2016 17:27:20 -0400
Subject: [R] Not able to install RODBC package
In-Reply-To: <C32518BC-09AE-44B6-86C0-B54DD1779C7A@me.com>
References: <CAJGK8=_do_e7AHaiqr09TQ5QBF=aYn6HXP7WgMM5Yj4JEhB1yw@mail.gmail.com>
	<C32518BC-09AE-44B6-86C0-B54DD1779C7A@me.com>
Message-ID: <CAJGK8=_rkQb_svBR3sfQjH=Eh-vQ=vL3BLhBpNGRbsPSrcLpBQ@mail.gmail.com>

Got a small fix for this issue. Sharing so that it may help others in
future.

options(repos='http://cran.rstudio.com/')

Regards,

Vivek Kumar Singh

PhD student,
Information Systems Decision Sciences,
MUMA College of Business,
USF
Phone- (813) 5809131
Web: http://vivek4.myweb.usf.edu/

On Tue, Jun 28, 2016 at 5:11 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> On Jun 28, 2016, at 3:36 PM, Vivek Singh <vivek4 at mail.usf.edu> wrote:
> >
> >> install.packages('RODBC')
> > Installing package into ?/home/vivek/R/x86_64-pc-linux-gnu-library/3.0?
> > (as ?lib? is unspecified)
> > Warning: unable to access index for repository
> > https://cloud.r-project.org/src/contrib
> > Warning message:
> > package ?RODBC? is not available (for R version 3.0.2)
> >
> > Please suggest any way to either install the package or use another
> package
> > to connect MySQL database from R.
> >
> >
> > Regards,
> >
> > Vivek Kumar Singh
>
>
> Hi,
>
> Typically that error is an indication of a problem accessing and reading
> files on the CRAN mirror, possibly due to a proxy/firewall issue on your
> end and/or perhaps that your R installation does not support HTTPS (secure
> http). If the former, you may need to check with your SysAdmin.
>
> You might try to select a different CRAN mirror, including one that is not
> secure http (regular http:// URL) to see if that works.
>
> Also, note that the version of R that you are running (3.0.2) is from Sep
> of 2013, so quite dated. The current version is 3.3.1, which was just
> released this month.
>
> Regards,
>
> Marc Schwartz
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Jun 29 00:23:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 28 Jun 2016 15:23:22 -0700
Subject: [R] Not able to install RODBC package
In-Reply-To: <CAJGK8=_do_e7AHaiqr09TQ5QBF=aYn6HXP7WgMM5Yj4JEhB1yw@mail.gmail.com>
References: <CAJGK8=_do_e7AHaiqr09TQ5QBF=aYn6HXP7WgMM5Yj4JEhB1yw@mail.gmail.com>
Message-ID: <10569573-0477-4CA7-AB00-409E5084E9BF@dcn.davis.ca.us>

Try another mirror?
Try the RMySQL package instead? 
Ask on R-sig-db?
-- 
Sent from my phone. Please excuse my brevity.

On June 28, 2016 1:36:47 PM PDT, Vivek Singh <vivek4 at mail.usf.edu> wrote:
>> install.packages('RODBC')
>Installing package into ?/home/vivek/R/x86_64-pc-linux-gnu-library/3.0?
>(as ?lib? is unspecified)
>Warning: unable to access index for repository
>https://cloud.r-project.org/src/contrib
>Warning message:
>package ?RODBC? is not available (for R version 3.0.2)
>
>Please suggest any way to either install the package or use another
>package
>to connect MySQL database from R.
>
>
>Regards,
>
>Vivek Kumar Singh
>
>PhD student,
>Information Systems Decision Sciences,
>MUMA College of Business,
>USF
>Phone- (813) 5809131
>Web: http://vivek4.myweb.usf.edu/
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Wed Jun 29 00:28:08 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 28 Jun 2016 22:28:08 +0000
Subject: [R] t-test for regression estimate
In-Reply-To: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>

Dear Steven,

The reason that linearHypothesis() computes a Wald F or chisquare test rather than a t or z test is that the (numerator) df for the linear hypothesis need not be 1. 

In your case (as has been pointed out) you can get the coefficient standard error directly from the model summary. 

More generally, with some work, you could solve for the the SE for a 1 df linear hypothesis in terms of the value of the linear function of coefficients and the F or chisquare. That said, I'm not sure why you want to do this.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
> Sent: June 28, 2016 9:27 AM
> To: R-help <r-help at r-project.org>
> Subject: [R] t-test for regression estimate
> 
> test option for linearHypothesis in library(car) include "Chisq" and "F". I prefer
> a simple t-test so that I can retrieve the standard error.
> Any options other than linearHypothesis to test the linear hypothesis (with 1
> restriction/degree of freedom)?
> 
>  > summary(ols1)
> 
> Coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept) -0.20013    0.09199  -2.176   0.0298 *
> age          0.04054    0.01721   2.355   0.0187 *
> suburb       0.01911    0.05838   0.327   0.7435
> smcity      -0.29969    0.19175  -1.563   0.1184
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
>  > linearHypothesis(ols1,"suburb")
> Linear hypothesis test
> 
> Hypothesis:
> suburb = 0
> 
> Model 1: restricted model
> Model 2: polideo ~ age + suburb + smcity
> 
>    Res.Df    RSS Df Sum of Sq      F Pr(>F)
> 1    888 650.10
> 2    887 650.02  1  0.078534 0.1072 0.7435
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jcthompson at redlobster.com  Tue Jun 28 22:26:59 2016
From: jcthompson at redlobster.com (Thompson, James)
Date: Tue, 28 Jun 2016 20:26:59 +0000
Subject: [R] Rpart plot produces no text
Message-ID: <BN3PR1001MB1124B718C0B581D494D951C5A2220@BN3PR1001MB1124.namprd10.prod.outlook.com>

I am using R Studio and am able to fit a tree with RPlot, however, the tree in the viewer has no text (see image attached).

Jim Thompson
This e-mail message is for the sole use of the intended recipient and may contain information that is confidential, proprietary or privileged. Any unauthorized review, use, distribution, copying or disclosure is strictly prohibited. If you are not the intended recipient, or the employee or agent responsible for delivering it to the intended recipient, please notify sender of the delivery error by replying to this message and then delete it from your system. Receipt by anyone other than the intended recipient is not a waiver of confidentiality or privilege.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot_test.png
Type: image/png
Size: 5236 bytes
Desc: Rplot_test.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160628/4da519eb/attachment.png>

From kmnanus at gmail.com  Tue Jun 28 22:46:14 2016
From: kmnanus at gmail.com (KMNanus)
Date: Tue, 28 Jun 2016 16:46:14 -0400
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <CAFEqCdxZ6RHiFms=YST71pna151jZdkrcVLJhE1orWXdW6HcwQ@mail.gmail.com>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
	<8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
	<70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>
	<CAFEqCdxZ6RHiFms=YST71pna151jZdkrcVLJhE1orWXdW6HcwQ@mail.gmail.com>
Message-ID: <DC9907EB-1984-4B38-B781-8B61C55C3232@gmail.com>

Thanks for getting back to me.  None of them work, because I?m trying to use the string in the function  call - myfun(z, ?string?) to replace the empty space in ggtitle.

When I call myfun(z, gsub(?______?, ?string (or any word)?, myfun), I get an error msg because gsub is looking for a data frame, not a function.

Paste or paste0 doesn?t work, either because I still have to replace the space in ggtitle with something.

In short, I want to put another argument into the function that will enable me to call it and fill that space.

I?m stumped.


Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Jun 28, 2016, at 3:42 PM, Greg Snow <538280 at gmail.com> wrote:
> 
> There are several options.  The option that is most like search and
> replace is to use the `sub` or `gsub` function (or similar functions
> in added packages).  But you may be able to accomplish what you want
> even simpler by using the `paste`, `paste0`, or `sprintf` functions.
> 
> On Tue, Jun 28, 2016 at 12:10 PM, KMNanus <kmnanus at gmail.com> wrote:
>> Thanks for getting back to me, I?m sorry if I was unclear.
>> 
>> What I?m trying to figure out is the equivalent of ?find and replace? in Word.
>> 
>> I have a function -
>> 
>> myfun <- function(z){
>> ggplot(df, aes(x,y)+
>> geom_point() +
>> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}
>> 
>> Calling myfun(z) works perfectly.  What I?m trying to do is add a string to myfun so that it would read:  function(z, ?string?){
>> 
>> Then I could call myfun(z, ?string?) to replace the space in ggtitle.  Is there a straightforward way to do that?
>> 
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>> 
>> 
>> 
>>> On Jun 28, 2016, at 12:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>>> 
>>>> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>> 
>>>> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.
>>>> 
>>>> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.
>>>> 
>>>> 
>>>> myfun <- function(myvar, new.name){
>>>> function(new.name){return(as.character(substitute(new.name)))}
>>>> ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>>>> geom_point() +
>>>> geom_line()+
>>>> xlab("Minimum Games" ) +
>>>> ylab(paste(new.name, ?Average Change"))+
>>>> ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
>>>> theme_bw()
>>>> 
>>>> When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.
>>> 
>>> Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name` in the calling environment. Sounds unlikely that you are typing:
>>> 
>>> myfun(myvar, new.name)  ## ?, so was there a loop/lapply calling method?
>>> 
>>> 
>>> Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name` in the calling environment.)
>>> 
>>> Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.
>>> 
>>> --
>>> David.
>>> 
>>> 
>>>> 
>>>> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
>>>> 
>>>> Can anyone help me with this?  Thanks for your patience.
>>>> 
>>>> Ken
>>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>>> 914-450-0816 (tel)
>>>> 347-730-4813 (fax)
>>>> 
>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com


From Eric.Goodwin at cawthron.org.nz  Tue Jun 28 22:53:09 2016
From: Eric.Goodwin at cawthron.org.nz (Eric Goodwin)
Date: Tue, 28 Jun 2016 20:53:09 +0000
Subject: [R] termplot intervals - SE or CI?
Message-ID: <E0D9C5E15741224AB7AA910ECEB678E50A4C7C61@ci011.cawthron.org.nz>

Hello,

A reviewer queried what the intervals were on the termplot I provided in a report.  The help file for termplot() suggests they're standard errors (se=T), but in the code the se.fit values from predict() are multiplied by 2, suggesting it's a rough 95% confidence interval, is that right?

Many thanks,

Eric Goodwin
Scientific data analyst | Coastal and Freshwater Group
Cawthron Institute
Phone +64 (0)3 548 2319 | Mobile 027 439 1141
eric.goodwin at cawthron.org.nz<mailto:eric.goodwin at cawthron.org.nz> | www.cawthron.org.nz<http://www.cawthron.org.nz/>


#####################################################################################

Note:
This message is for the named person's use only.  It may...{{dropped:18}}


From kmnanus at gmail.com  Tue Jun 28 23:43:19 2016
From: kmnanus at gmail.com (KMNanus)
Date: Tue, 28 Jun 2016 17:43:19 -0400
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <CAFEqCdwqgGeZu+j_uyOt6wkRgSHWq1n2GAc=+P7cT+D0HWUB=Q@mail.gmail.com>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
	<8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
	<70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>
	<CAFEqCdxZ6RHiFms=YST71pna151jZdkrcVLJhE1orWXdW6HcwQ@mail.gmail.com>
	<DC9907EB-1984-4B38-B781-8B61C55C3232@gmail.com>
	<CAFEqCdwqgGeZu+j_uyOt6wkRgSHWq1n2GAc=+P7cT+D0HWUB=Q@mail.gmail.com>
Message-ID: <33A54609-ACC2-4C49-86C9-D94F4CEEACEE@gmail.com>

I?m trying to modify the function from outside, i.e., when I call the function.

Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Jun 28, 2016, at 5:07 PM, Greg Snow <538280 at gmail.com> wrote:
> 
> Can you edit the source of the function?  or are you trying to modify an existing function without working on the source?
> 
> On Tue, Jun 28, 2016 at 2:46 PM, KMNanus <kmnanus at gmail.com <mailto:kmnanus at gmail.com>> wrote:
> Thanks for getting back to me.  None of them work, because I?m trying to use the string in the function  call - myfun(z, ?string?) to replace the empty space in ggtitle.
> 
> When I call myfun(z, gsub(?______?, ?string (or any word)?, myfun), I get an error msg because gsub is looking for a data frame, not a function.
> 
> Paste or paste0 doesn?t work, either because I still have to replace the space in ggtitle with something.
> 
> In short, I want to put another argument into the function that will enable me to call it and fill that space.
> 
> I?m stumped.
> 
> 
> Ken
> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
> 914-450-0816 (tel)
> 347-730-4813 (fax)
> 
> <image001.jpg>
> 
>> On Jun 28, 2016, at 3:42 PM, Greg Snow <538280 at gmail.com <mailto:538280 at gmail.com>> wrote:
>> 
>> There are several options.  The option that is most like search and
>> replace is to use the `sub` or `gsub` function (or similar functions
>> in added packages).  But you may be able to accomplish what you want
>> even simpler by using the `paste`, `paste0`, or `sprintf` functions.
>> 
>> On Tue, Jun 28, 2016 at 12:10 PM, KMNanus <kmnanus at gmail.com <mailto:kmnanus at gmail.com>> wrote:
>>> Thanks for getting back to me, I?m sorry if I was unclear.
>>> 
>>> What I?m trying to figure out is the equivalent of ?find and replace? in Word.
>>> 
>>> I have a function -
>>> 
>>> myfun <- function(z){
>>> ggplot(df, aes(x,y)+
>>> geom_point() +
>>> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}
>>> 
>>> Calling myfun(z) works perfectly.  What I?m trying to do is add a string to myfun so that it would read:  function(z, ?string?){
>>> 
>>> Then I could call myfun(z, ?string?) to replace the space in ggtitle.  Is there a straightforward way to do that?
>>> 
>>> Ken
>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>> 914-450-0816 (tel)
>>> 347-730-4813 (fax)
>>> 
>>> 
>>> 
>>>> On Jun 28, 2016, at 12:20 PM, David Winsemius <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>>>> 
>>>>> 
>>>>> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com <mailto:kmnanus at gmail.com>> wrote:
>>>>> 
>>>>> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.
>>>>> 
>>>>> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name <http://new.name/>, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name <http://new.name/>))and also using the code you see below.
>>>>> 
>>>>> 
>>>>> myfun <- function(myvar, new.name <http://new.name/>){
>>>>> function(new.name <http://new.name/>){return(as.character(substitute(new.name <http://new.name/>)))}
>>>>> ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>>>>> geom_point() +
>>>>> geom_line()+
>>>>> xlab("Minimum Games" ) +
>>>>> ylab(paste(new.name <http://new.name/>, ?Average Change"))+
>>>>> ggtitle(new.name <http://new.name/>, "Change \n as a Function of Minimum Number of Games?)+
>>>>> theme_bw()
>>>>> 
>>>>> When call myfun(myvar, new.name <http://new.name/>), I get an error msg ?new.name <http://new.name/> is not found? whether I call new.name <http://new.name/> or Tuesday.
>>>> 
>>>> Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name <http://new.name/>` in the calling environment. Sounds unlikely that you are typing:
>>>> 
>>>> myfun(myvar, new.name <http://new.name/>)  ## ?, so was there a loop/lapply calling method?
>>>> 
>>>> 
>>>> Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name <http://new.name/>`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name <http://new.name/>` in the calling environment.)
>>>> 
>>>> Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.
>>>> 
>>>> --
>>>> David.
>>>> 
>>>> 
>>>>> 
>>>>> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
>>>>> 
>>>>> Can anyone help me with this?  Thanks for your patience.
>>>>> 
>>>>> Ken
>>>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com> <mailto:kmnanus at gmail.com <mailto:kmnanus at gmail.com>>
>>>>> 914-450-0816 (tel)
>>>>> 347-730-4813 (fax)
>>>>> 
>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> -- 
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com <mailto:538280 at gmail.com>
> 
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com <mailto:538280 at gmail.com>


From syen04 at gmail.com  Wed Jun 29 00:43:30 2016
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 28 Jun 2016 18:43:30 -0400
Subject: [R] t-test for regression estimate
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <b86a1527-ecd3-6749-a137-865482d30136@gmail.com>

Thanks John. Reason is I am doing linear transformations of many 
coefficients (e.g., bi / scalar). Of course I can uncover the 
t-statistic from the F statistic and then the standard error. Simply 
scaling the estimated coefficients I can also transform the standard 
errors. I have since found deltaMethod from library "car" useful. Its 
just that, if linearHypothesis had provide the standard errors and 
t-statistics then the operation would have been easier, with a one-line 
command for each coefficient. Thank you again.

On 6/28/2016 6:28 PM, Fox, John wrote:
> Dear Steven,
>
> The reason that linearHypothesis() computes a Wald F or chisquare test rather than a t or z test is that the (numerator) df for the linear hypothesis need not be 1.
>
> In your case (as has been pointed out) you can get the coefficient standard error directly from the model summary.
>
> More generally, with some work, you could solve for the the SE for a 1 df linear hypothesis in terms of the value of the linear function of coefficients and the F or chisquare. That said, I'm not sure why you want to do this.
>
> I hope this helps,
>   John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
>> Sent: June 28, 2016 9:27 AM
>> To: R-help <r-help at r-project.org>
>> Subject: [R] t-test for regression estimate
>>
>> test option for linearHypothesis in library(car) include "Chisq" and "F". I prefer
>> a simple t-test so that I can retrieve the standard error.
>> Any options other than linearHypothesis to test the linear hypothesis (with 1
>> restriction/degree of freedom)?
>>
>>   > summary(ols1)
>>
>> Coefficients:
>>               Estimate Std. Error t value Pr(>|t|)
>> (Intercept) -0.20013    0.09199  -2.176   0.0298 *
>> age          0.04054    0.01721   2.355   0.0187 *
>> suburb       0.01911    0.05838   0.327   0.7435
>> smcity      -0.29969    0.19175  -1.563   0.1184
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>   > linearHypothesis(ols1,"suburb")
>> Linear hypothesis test
>>
>> Hypothesis:
>> suburb = 0
>>
>> Model 1: restricted model
>> Model 2: polideo ~ age + suburb + smcity
>>
>>     Res.Df    RSS Df Sum of Sq      F Pr(>F)
>> 1    888 650.10
>> 2    887 650.02  1  0.078534 0.1072 0.7435
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Wed Jun 29 00:53:53 2016
From: miaojpm at gmail.com (John)
Date: Tue, 28 Jun 2016 15:53:53 -0700
Subject: [R] Can R read Word fonts and comments?
Message-ID: <CABcx46D0gNOHEau_iEd_F-hMM1MA=J0r41sLwoFY8SMgE47nZw@mail.gmail.com>

Hi,

   From time to time I highlight the word documents with red/blue color or
italic/bold fonts, and I also add comments to a file. Is there a
package/function to let R extract the italic/bold blue/red words and
comments from a docx/doc file?

   I am aware that there are a few packages reading Word, but don't know
which one is able to do it.

   Thanks,

John

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Jun 29 01:48:51 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 28 Jun 2016 16:48:51 -0700
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <DC9907EB-1984-4B38-B781-8B61C55C3232@gmail.com>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
	<8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
	<70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>
	<CAFEqCdxZ6RHiFms=YST71pna151jZdkrcVLJhE1orWXdW6HcwQ@mail.gmail.com>
	<DC9907EB-1984-4B38-B781-8B61C55C3232@gmail.com>
Message-ID: <CAGxFJbQti9LjJMSQqQ_s9bqtdqKzmm_=eTvdfw-ydqfDxSKqbw@mail.gmail.com>

I frankly don't know what the heck you are doing but,

(inline below)
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 28, 2016 at 1:46 PM, KMNanus <kmnanus at gmail.com> wrote:
> Thanks for getting back to me.  None of them work, because I?m trying to use the string in the function  call - myfun(z, ?string?) to replace the empty space in ggtitle.
>
> ***When I call myfun(z, gsub(?______?, ?string (or any word)?, myfun), I get an error msg because gsub is looking for a data frame, not a function.***

That is absolutely, unequivocally, positively, FALSE. See ?gsub for
what gsub() *does* want.

This suggests to me that you may also not understand functions and/or
function arguments, so I would recommend that you try a web tutorial
or two on R function to see where your confusion may lie. However, I
freely admit (see my initial remark) that I may not understand what
you are trying to do, so maybe that's not it. I will say if I wanted
to give an arbitrary character string to a function that called a
title function, titleFUN, I'd do it like this:

myfun <- function(..., mytitle){

## lots of stuff

titleFUN(mytitle)

## more stuff

}

and call it by:

myfun(..., "myReallyCuteTitle")


I do not use ggplot and so do not know its detailed syntax; but I
would be surprised if it did not accept something along these lines...

Cheers,
Bert






>
> Paste or paste0 doesn?t work, either because I still have to replace the space in ggtitle with something.
>
> In short, I want to put another argument into the function that will enable me to call it and fill that space.
>
> I?m stumped.
>
>
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
>
>
>
>> On Jun 28, 2016, at 3:42 PM, Greg Snow <538280 at gmail.com> wrote:
>>
>> There are several options.  The option that is most like search and
>> replace is to use the `sub` or `gsub` function (or similar functions
>> in added packages).  But you may be able to accomplish what you want
>> even simpler by using the `paste`, `paste0`, or `sprintf` functions.
>>
>> On Tue, Jun 28, 2016 at 12:10 PM, KMNanus <kmnanus at gmail.com> wrote:
>>> Thanks for getting back to me, I?m sorry if I was unclear.
>>>
>>> What I?m trying to figure out is the equivalent of ?find and replace? in Word.
>>>
>>> I have a function -
>>>
>>> myfun <- function(z){
>>> ggplot(df, aes(x,y)+
>>> geom_point() +
>>> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}
>>>
>>> Calling myfun(z) works perfectly.  What I?m trying to do is add a string to myfun so that it would read:  function(z, ?string?){
>>>
>>> Then I could call myfun(z, ?string?) to replace the space in ggtitle.  Is there a straightforward way to do that?
>>>
>>> Ken
>>> kmnanus at gmail.com
>>> 914-450-0816 (tel)
>>> 347-730-4813 (fax)
>>>
>>>
>>>
>>>> On Jun 28, 2016, at 12:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>>>
>>>>> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>>>
>>>>> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.
>>>>>
>>>>> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.
>>>>>
>>>>>
>>>>> myfun <- function(myvar, new.name){
>>>>> function(new.name){return(as.character(substitute(new.name)))}
>>>>> ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>>>>> geom_point() +
>>>>> geom_line()+
>>>>> xlab("Minimum Games" ) +
>>>>> ylab(paste(new.name, ?Average Change"))+
>>>>> ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
>>>>> theme_bw()
>>>>>
>>>>> When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.
>>>>
>>>> Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name` in the calling environment. Sounds unlikely that you are typing:
>>>>
>>>> myfun(myvar, new.name)  ## ?, so was there a loop/lapply calling method?
>>>>
>>>>
>>>> Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name` in the calling environment.)
>>>>
>>>> Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.
>>>>
>>>> --
>>>> David.
>>>>
>>>>
>>>>>
>>>>> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
>>>>>
>>>>> Can anyone help me with this?  Thanks for your patience.
>>>>>
>>>>> Ken
>>>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>>>> 914-450-0816 (tel)
>>>>> 347-730-4813 (fax)
>>>>>
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Jun 29 01:50:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 28 Jun 2016 16:50:27 -0700
Subject: [R] Can R read Word fonts and comments?
In-Reply-To: <CABcx46D0gNOHEau_iEd_F-hMM1MA=J0r41sLwoFY8SMgE47nZw@mail.gmail.com>
References: <CABcx46D0gNOHEau_iEd_F-hMM1MA=J0r41sLwoFY8SMgE47nZw@mail.gmail.com>
Message-ID: <CAGxFJbSSnMK7_cCfAMXVMT1fM3zWUQsjmNwfgtb_fh5XzRRdCQ@mail.gmail.com>

Did you try searching before posting here? -- e.g. a web search or on
rseek.org ?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 28, 2016 at 3:53 PM, John <miaojpm at gmail.com> wrote:
> Hi,
>
>    From time to time I highlight the word documents with red/blue color or
> italic/bold fonts, and I also add comments to a file. Is there a
> package/function to let R extract the italic/bold blue/red words and
> comments from a docx/doc file?
>
>    I am aware that there are a few packages reading Word, but don't know
> which one is able to do it.
>
>    Thanks,
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Jun 29 02:02:29 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Jun 2016 20:02:29 -0400
Subject: [R] termplot intervals - SE or CI?
In-Reply-To: <E0D9C5E15741224AB7AA910ECEB678E50A4C7C61@ci011.cawthron.org.nz>
References: <E0D9C5E15741224AB7AA910ECEB678E50A4C7C61@ci011.cawthron.org.nz>
Message-ID: <e9bb293e-bf66-6684-9efc-b15b8dcd6042@gmail.com>

On 28/06/2016 4:53 PM, Eric Goodwin wrote:
> Hello,
>
> A reviewer queried what the intervals were on the termplot I provided in a report.  The help file for termplot() suggests they're standard errors (se=T), but in the code the se.fit values from predict() are multiplied by 2, suggesting it's a rough 95% confidence interval, is that right?

I would assume they are what the help file says, but if I wasn't sure, 
I'd work them out for a simple case from first principles, and compare 
to what the code gives.

Duncan Murdoch


> Many thanks,
>
> Eric Goodwin
> Scientific data analyst | Coastal and Freshwater Group
> Cawthron Institute
> Phone +64 (0)3 548 2319 | Mobile 027 439 1141
> eric.goodwin at cawthron.org.nz<mailto:eric.goodwin at cawthron.org.nz> | www.cawthron.org.nz<http://www.cawthron.org.nz/>
>
>
> #####################################################################################
>
> Note:
> This message is for the named person's use only.  It may...{{dropped:18}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Wed Jun 29 02:53:00 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 29 Jun 2016 10:53:00 +1000
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <CAGxFJbQti9LjJMSQqQ_s9bqtdqKzmm_=eTvdfw-ydqfDxSKqbw@mail.gmail.com>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
	<8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
	<70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>
	<CAFEqCdxZ6RHiFms=YST71pna151jZdkrcVLJhE1orWXdW6HcwQ@mail.gmail.com>
	<DC9907EB-1984-4B38-B781-8B61C55C3232@gmail.com>
	<CAGxFJbQti9LjJMSQqQ_s9bqtdqKzmm_=eTvdfw-ydqfDxSKqbw@mail.gmail.com>
Message-ID: <CA+8X3fVn7P_t=7akt8f9tovM1-=H5DwkkZq-8EU+GiLRsj9kcg@mail.gmail.com>

Hi Ken,
As far as I can see, ggtitle accepts a single string. The help page is
a bit obscure, implying that you can change the title with the "labs"
function(?), but using the same explicit string in the "ggtitle" line,
perhaps for didactic purposes. You seem to be asking to substitute
your own version of a string that is popping out in ggplot
automatically, e.g. "Tue" -> "Tuesday". The help page doesn't discuss
whether it is possible to access the string that will be automatically
used as the title. If ggtitle automatically uses the name of the
object that you are plotting, something like this may work:

my_x<-1:5
myfun<-function(x,mytitle) {
 plot(x)
 old_title<-deparse(substitute(x))
 title(gsub("x",mytitle,old_title))
}
myfun(my_x,"wonderful X")

The reason that I have done this in base graphics is that I could not
get an equivalent plot in ggplot.

Jim


On Wed, Jun 29, 2016 at 9:48 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I frankly don't know what the heck you are doing but,
>
> (inline below)
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Jun 28, 2016 at 1:46 PM, KMNanus <kmnanus at gmail.com> wrote:
>> Thanks for getting back to me.  None of them work, because I?m trying to use the string in the function  call - myfun(z, ?string?) to replace the empty space in ggtitle.
>>
>> ***When I call myfun(z, gsub(?______?, ?string (or any word)?, myfun), I get an error msg because gsub is looking for a data frame, not a function.***
>
> That is absolutely, unequivocally, positively, FALSE. See ?gsub for
> what gsub() *does* want.
>
> This suggests to me that you may also not understand functions and/or
> function arguments, so I would recommend that you try a web tutorial
> or two on R function to see where your confusion may lie. However, I
> freely admit (see my initial remark) that I may not understand what
> you are trying to do, so maybe that's not it. I will say if I wanted
> to give an arbitrary character string to a function that called a
> title function, titleFUN, I'd do it like this:
>
> myfun <- function(..., mytitle){
>
> ## lots of stuff
>
> titleFUN(mytitle)
>
> ## more stuff
>
> }
>
> and call it by:
>
> myfun(..., "myReallyCuteTitle")
>
>
> I do not use ggplot and so do not know its detailed syntax; but I
> would be surprised if it did not accept something along these lines...
>
> Cheers,
> Bert
>
>
>
>
>
>
>>
>> Paste or paste0 doesn?t work, either because I still have to replace the space in ggtitle with something.
>>
>> In short, I want to put another argument into the function that will enable me to call it and fill that space.
>>
>> I?m stumped.
>>
>>
>> Ken
>> kmnanus at gmail.com
>> 914-450-0816 (tel)
>> 347-730-4813 (fax)
>>
>>
>>
>>> On Jun 28, 2016, at 3:42 PM, Greg Snow <538280 at gmail.com> wrote:
>>>
>>> There are several options.  The option that is most like search and
>>> replace is to use the `sub` or `gsub` function (or similar functions
>>> in added packages).  But you may be able to accomplish what you want
>>> even simpler by using the `paste`, `paste0`, or `sprintf` functions.
>>>
>>> On Tue, Jun 28, 2016 at 12:10 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>> Thanks for getting back to me, I?m sorry if I was unclear.
>>>>
>>>> What I?m trying to figure out is the equivalent of ?find and replace? in Word.
>>>>
>>>> I have a function -
>>>>
>>>> myfun <- function(z){
>>>> ggplot(df, aes(x,y)+
>>>> geom_point() +
>>>> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}
>>>>
>>>> Calling myfun(z) works perfectly.  What I?m trying to do is add a string to myfun so that it would read:  function(z, ?string?){
>>>>
>>>> Then I could call myfun(z, ?string?) to replace the space in ggtitle.  Is there a straightforward way to do that?
>>>>
>>>> Ken
>>>> kmnanus at gmail.com
>>>> 914-450-0816 (tel)
>>>> 347-730-4813 (fax)
>>>>
>>>>
>>>>
>>>>> On Jun 28, 2016, at 12:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>
>>>>>>
>>>>>> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>>>>
>>>>>> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.
>>>>>>
>>>>>> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.
>>>>>>
>>>>>>
>>>>>> myfun <- function(myvar, new.name){
>>>>>> function(new.name){return(as.character(substitute(new.name)))}
>>>>>> ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>>>>>> geom_point() +
>>>>>> geom_line()+
>>>>>> xlab("Minimum Games" ) +
>>>>>> ylab(paste(new.name, ?Average Change"))+
>>>>>> ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
>>>>>> theme_bw()
>>>>>>
>>>>>> When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.
>>>>>
>>>>> Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name` in the calling environment. Sounds unlikely that you are typing:
>>>>>
>>>>> myfun(myvar, new.name)  ## ?, so was there a loop/lapply calling method?
>>>>>
>>>>>
>>>>> Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name` in the calling environment.)
>>>>>
>>>>> Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.
>>>>>
>>>>> --
>>>>> David.
>>>>>
>>>>>
>>>>>>
>>>>>> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
>>>>>>
>>>>>> Can anyone help me with this?  Thanks for your patience.
>>>>>>
>>>>>> Ken
>>>>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>>>>> 914-450-0816 (tel)
>>>>>> 347-730-4813 (fax)
>>>>>>
>>>>>>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> --
>>> Gregory (Greg) L. Snow Ph.D.
>>> 538280 at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From vivek4 at mail.usf.edu  Wed Jun 29 03:25:20 2016
From: vivek4 at mail.usf.edu (Vivek Singh)
Date: Tue, 28 Jun 2016 21:25:20 -0400
Subject: [R] Not able to install RODBC package
In-Reply-To: <10569573-0477-4CA7-AB00-409E5084E9BF@dcn.davis.ca.us>
References: <CAJGK8=_do_e7AHaiqr09TQ5QBF=aYn6HXP7WgMM5Yj4JEhB1yw@mail.gmail.com>
	<10569573-0477-4CA7-AB00-409E5084E9BF@dcn.davis.ca.us>
Message-ID: <CAJGK8=89r2kK804+jtBQO2BP5e40WbVNkWM2YjFBcBzC4yxydQ@mail.gmail.com>

Thanks Jeff. I used RMySQL instead  and is working great.

Regards,

Vivek Kumar Singh

PhD student,
Information Systems Decision Sciences,
MUMA College of Business,
USF
Phone- (813) 5809131
Web: http://vivek4.myweb.usf.edu/

On Tue, Jun 28, 2016 at 6:23 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Try another mirror?
> Try the RMySQL package instead?
> Ask on R-sig-db?
> --
> Sent from my phone. Please excuse my brevity.
>
> On June 28, 2016 1:36:47 PM PDT, Vivek Singh <vivek4 at mail.usf.edu> wrote:
> >> install.packages('RODBC')
> >Installing package into ?/home/vivek/R/x86_64-pc-linux-gnu-library/3.0?
> >(as ?lib? is unspecified)
> >Warning: unable to access index for repository
> >https://cloud.r-project.org/src/contrib
> >Warning message:
> >package ?RODBC? is not available (for R version 3.0.2)
> >
> >Please suggest any way to either install the package or use another
> >package
> >to connect MySQL database from R.
> >
> >
> >Regards,
> >
> >Vivek Kumar Singh
> >
> >PhD student,
> >Information Systems Decision Sciences,
> >MUMA College of Business,
> >USF
> >Phone- (813) 5809131
> >Web: http://vivek4.myweb.usf.edu/
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From gratebill at yahoo.gr  Wed Jun 29 02:27:33 2016
From: gratebill at yahoo.gr (Vasilis Bardakos)
Date: Wed, 29 Jun 2016 00:27:33 +0000 (UTC)
Subject: [R] Shorting Matrices
References: <631060338.5318506.1467160053075.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <631060338.5318506.1467160053075.JavaMail.yahoo@mail.yahoo.com>

Hello,
I'm a newbie in R and I tried to run a regression, but the data I imported are quarterly, weekly and daily.In order to simplify my task I set vars = Matrix[,2] to exclude the Dates and then I tried to short the data quarterly so I did the following
k = var[seq(1,"total # of data",22)]

Is this even correct?
Also, for some reason when I set var = Matrix[,2] somehow the values changed from rationals to integers.
Thank you in advance
	[[alternative HTML version deleted]]


From kmnanus at gmail.com  Wed Jun 29 03:19:00 2016
From: kmnanus at gmail.com (KMNanus)
Date: Tue, 28 Jun 2016 21:19:00 -0400
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <CA+8X3fVn7P_t=7akt8f9tovM1-=H5DwkkZq-8EU+GiLRsj9kcg@mail.gmail.com>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
	<8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
	<70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>
	<CAFEqCdxZ6RHiFms=YST71pna151jZdkrcVLJhE1orWXdW6HcwQ@mail.gmail.com>
	<DC9907EB-1984-4B38-B781-8B61C55C3232@gmail.com>
	<CAGxFJbQti9LjJMSQqQ_s9bqtdqKzmm_=eTvdfw-ydqfDxSKqbw@mail.gmail.com>
	<CA+8X3fVn7P_t=7akt8f9tovM1-=H5DwkkZq-8EU+GiLRsj9kcg@mail.gmail.com>
Message-ID: <6236F5BA-9C0F-4180-BCC4-62F2C26B6912@gmail.com>

You?ve stated my intent perfectly.  I tried depress(substitute(x)) within ggplot and it didn?t work.

However, the solution (which I discovered about 10 minutes ago), turned out to remarkably easy - I just assigned the new variable and it ran perfectly.  It looks like this - 

myfun<- function(z, q = ?new.name){
 function(new.name){return(as.character(substitute(new.name)))}
ggplot(df, aes(x,y))+
geom_point()+
ggtitle(paste(q, ?quick brown fox?.?))

Not sure why assigning ?new.name? to q makes the difference, but it did.

Thanks.



>>>>> myfun <- function(z){
>>>>> ggplot(df, aes(x,y)+
>>>>> geom_point() +
>>>>> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}




Ken
kmnanus at gmail.com
914-450-0816 (tel)
347-730-4813 (fax)



> On Jun 28, 2016, at 8:53 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Ken,
> As far as I can see, ggtitle accepts a single string. The help page is
> a bit obscure, implying that you can change the title with the "labs"
> function(?), but using the same explicit string in the "ggtitle" line,
> perhaps for didactic purposes. You seem to be asking to substitute
> your own version of a string that is popping out in ggplot
> automatically, e.g. "Tue" -> "Tuesday". The help page doesn't discuss
> whether it is possible to access the string that will be automatically
> used as the title. If ggtitle automatically uses the name of the
> object that you are plotting, something like this may work:
> 
> my_x<-1:5
> myfun<-function(x,mytitle) {
> plot(x)
> old_title<-deparse(substitute(x))
> title(gsub("x",mytitle,old_title))
> }
> myfun(my_x,"wonderful X")
> 
> The reason that I have done this in base graphics is that I could not
> get an equivalent plot in ggplot.
> 
> Jim
> 
> 
> On Wed, Jun 29, 2016 at 9:48 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> I frankly don't know what the heck you are doing but,
>> 
>> (inline below)
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Tue, Jun 28, 2016 at 1:46 PM, KMNanus <kmnanus at gmail.com> wrote:
>>> Thanks for getting back to me.  None of them work, because I?m trying to use the string in the function  call - myfun(z, ?string?) to replace the empty space in ggtitle.
>>> 
>>> ***When I call myfun(z, gsub(?______?, ?string (or any word)?, myfun), I get an error msg because gsub is looking for a data frame, not a function.***
>> 
>> That is absolutely, unequivocally, positively, FALSE. See ?gsub for
>> what gsub() *does* want.
>> 
>> This suggests to me that you may also not understand functions and/or
>> function arguments, so I would recommend that you try a web tutorial
>> or two on R function to see where your confusion may lie. However, I
>> freely admit (see my initial remark) that I may not understand what
>> you are trying to do, so maybe that's not it. I will say if I wanted
>> to give an arbitrary character string to a function that called a
>> title function, titleFUN, I'd do it like this:
>> 
>> myfun <- function(..., mytitle){
>> 
>> ## lots of stuff
>> 
>> titleFUN(mytitle)
>> 
>> ## more stuff
>> 
>> }
>> 
>> and call it by:
>> 
>> myfun(..., "myReallyCuteTitle")
>> 
>> 
>> I do not use ggplot and so do not know its detailed syntax; but I
>> would be surprised if it did not accept something along these lines...
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> 
>> 
>> 
>>> 
>>> Paste or paste0 doesn?t work, either because I still have to replace the space in ggtitle with something.
>>> 
>>> In short, I want to put another argument into the function that will enable me to call it and fill that space.
>>> 
>>> I?m stumped.
>>> 
>>> 
>>> Ken
>>> kmnanus at gmail.com
>>> 914-450-0816 (tel)
>>> 347-730-4813 (fax)
>>> 
>>> 
>>> 
>>>> On Jun 28, 2016, at 3:42 PM, Greg Snow <538280 at gmail.com> wrote:
>>>> 
>>>> There are several options.  The option that is most like search and
>>>> replace is to use the `sub` or `gsub` function (or similar functions
>>>> in added packages).  But you may be able to accomplish what you want
>>>> even simpler by using the `paste`, `paste0`, or `sprintf` functions.
>>>> 
>>>> On Tue, Jun 28, 2016 at 12:10 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>>> Thanks for getting back to me, I?m sorry if I was unclear.
>>>>> 
>>>>> What I?m trying to figure out is the equivalent of ?find and replace? in Word.
>>>>> 
>>>>> I have a function -
>>>>> 
>>>>> myfun <- function(z){
>>>>> ggplot(df, aes(x,y)+
>>>>> geom_point() +
>>>>> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}
>>>>> 
>>>>> Calling myfun(z) works perfectly.  What I?m trying to do is add a string to myfun so that it would read:  function(z, ?string?){
>>>>> 
>>>>> Then I could call myfun(z, ?string?) to replace the space in ggtitle.  Is there a straightforward way to do that?
>>>>> 
>>>>> Ken
>>>>> kmnanus at gmail.com
>>>>> 914-450-0816 (tel)
>>>>> 347-730-4813 (fax)
>>>>> 
>>>>> 
>>>>> 
>>>>>> On Jun 28, 2016, at 12:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>> 
>>>>>>> 
>>>>>>> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>>>>> 
>>>>>>> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.
>>>>>>> 
>>>>>>> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.
>>>>>>> 
>>>>>>> 
>>>>>>> myfun <- function(myvar, new.name){
>>>>>>> function(new.name){return(as.character(substitute(new.name)))}
>>>>>>> ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>>>>>>> geom_point() +
>>>>>>> geom_line()+
>>>>>>> xlab("Minimum Games" ) +
>>>>>>> ylab(paste(new.name, ?Average Change"))+
>>>>>>> ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
>>>>>>> theme_bw()
>>>>>>> 
>>>>>>> When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.
>>>>>> 
>>>>>> Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name` in the calling environment. Sounds unlikely that you are typing:
>>>>>> 
>>>>>> myfun(myvar, new.name)  ## ?, so was there a loop/lapply calling method?
>>>>>> 
>>>>>> 
>>>>>> Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name` in the calling environment.)
>>>>>> 
>>>>>> Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.
>>>>>> 
>>>>>> --
>>>>>> David.
>>>>>> 
>>>>>> 
>>>>>>> 
>>>>>>> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
>>>>>>> 
>>>>>>> Can anyone help me with this?  Thanks for your patience.
>>>>>>> 
>>>>>>> Ken
>>>>>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>>>>>> 914-450-0816 (tel)
>>>>>>> 347-730-4813 (fax)
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>> 
>>>> --
>>>> Gregory (Greg) L. Snow Ph.D.
>>>> 538280 at gmail.com
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Jun 29 05:32:41 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 29 Jun 2016 13:32:41 +1000
Subject: [R] Shorting Matrices
In-Reply-To: <631060338.5318506.1467160053075.JavaMail.yahoo@mail.yahoo.com>
References: <631060338.5318506.1467160053075.JavaMail.yahoo.ref@mail.yahoo.com>
	<631060338.5318506.1467160053075.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fU3aSDmXqyPYpE+XhJfBCyF=A=V=C4C1tk8YhX77K3k=g@mail.gmail.com>

Hi Vasilis,
Your question has more to do with telepathy than statistics, but I
will attempt an answer anyway. You have in your possession a matrix
(perhaps) named Matrix. Within are at least two columns of something,
one of which contains dates. You have revealed that the other column
contains numeric values. Given these two admissions, I am convinced
that Matrix, despite its name, is a data frame [1].

The question "Is this even correct?" can be answered three times.
No - you have created a vector "vars" and then tried to do something with "var"
No - you have asked for a sequence of numbers from 1 to the length of
Matrix[,2] with intervals of 22 in the attempt to transform the date
component of each observation into quarterly values. No matter if the
date intervals are days, weeks or quarters, this will not produce the
intervals you want.
No - Your result will be 1/22 as long as the original column of dates
and will contain values that at best express the index order of the
original values.

Now for the good news. As the values in Matrix[,2] are probably dates,
you may be able to calculate a new set of values that will represent
the quarter in which they fell. Assume that your dates are character
strings as below:

# make up two years of daily level dates
datestrings<-paste(rep(2001:2002,each=12),
 rep(1:12,2),sample(1:28,24),sep="-")
dates<-as.Date(datestrings,"%Y-%m-%d")
qdates<-factor(paste(format(dates,"%Y"),"Q",
 floor(as.numeric(format(dates,"%m"))/4)+1,
 sep=""))

Now you have a factor value for each date that indicates the quarter
in which that date fell. My telepathic expertise does not extend to
what you wanted to do next.

Jim



[1] The values in a matrix must all be of the same data type, and
dates as either character strings or factors are not numbers. It is
possible to coerce dates to numbers, but this is unlikely given the
subsequent information.

On Wed, Jun 29, 2016 at 10:27 AM, Vasilis Bardakos via R-help
<r-help at r-project.org> wrote:
> Hello,
> I'm a newbie in R and I tried to run a regression, but the data I imported are quarterly, weekly and daily.In order to simplify my task I set vars = Matrix[,2] to exclude the Dates and then I tried to short the data quarterly so I did the following
> k = var[seq(1,"total # of data",22)]
>
> Is this even correct?
> Also, for some reason when I set var = Matrix[,2] somehow the values changed from rationals to integers.
> Thank you in advance
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jun 29 07:04:51 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 28 Jun 2016 22:04:51 -0700
Subject: [R] Turning a variable name into a function argument
In-Reply-To: <6236F5BA-9C0F-4180-BCC4-62F2C26B6912@gmail.com>
References: <CA0A0CB5-CE09-41DF-9DA5-EAA4BA6353A5@gmail.com>
	<8D4E76F9-634B-4B76-9CE5-F90DFCB5A048@comcast.net>
	<70D19C3D-81ED-4944-9C26-304175C2F9C0@gmail.com>
	<CAFEqCdxZ6RHiFms=YST71pna151jZdkrcVLJhE1orWXdW6HcwQ@mail.gmail.com>
	<DC9907EB-1984-4B38-B781-8B61C55C3232@gmail.com>
	<CAGxFJbQti9LjJMSQqQ_s9bqtdqKzmm_=eTvdfw-ydqfDxSKqbw@mail.gmail.com>
	<CA+8X3fVn7P_t=7akt8f9tovM1-=H5DwkkZq-8EU+GiLRsj9kcg@mail.gmail.com>
	<6236F5BA-9C0F-4180-BCC4-62F2C26B6912@gmail.com>
Message-ID: <24CAC628-8BC9-4FB5-BFF3-E5AC10289CE5@comcast.net>


> On Jun 28, 2016, at 6:19 PM, KMNanus <kmnanus at gmail.com> wrote:
> 
> You?ve stated my intent perfectly.  I tried depress(substitute(x)) within ggplot and it didn?t work.
> 
> However, the solution (which I discovered about 10 minutes ago), turned out to remarkably easy - I just assigned the new variable and it ran perfectly.  It looks like this - 
> 
> myfun<- function(z, q = ?new.name){

You have used "smart-quotes". Not valid R syntax. Throws an error with the parser. Also would need a closing double quote and proper double quotes below as well.

> function(new.name){return(as.character(substitute(new.name)))}
> ggplot(df, aes(x,y))+
> geom_point()+
> ggtitle(paste(q, ?quick brown fox?.?))

Presumably you have also failed to include the final "}".

> 
> Not sure why assigning ?new.name? to q makes the difference, but it did.

As soon as this function is called, (and not when it is defined), the name `q` is given a (character) value of "new.name". When than value is later looked up by `paste`, it is able to be evaluated and "new.name" is appended to the other character values. The "new.name" value, and the `q` name will be garbage-collectable after the function call.

The line:

 function(new.name){return(as.character(substitute(new.name)))}

... does ... absolutely  ... nothing ... as was implied in my response to your duplicate message that appeared on the server this morning.

-- 
David


> 
> Thanks.
> 
> 
> 
>>>>>> myfun <- function(z){
>>>>>> ggplot(df, aes(x,y)+
>>>>>> geom_point() +
>>>>>> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}
> 
> 
> 
> 
> Ken
> kmnanus at gmail.com
> 914-450-0816 (tel)
> 347-730-4813 (fax)
> 
> 
> 
>> On Jun 28, 2016, at 8:53 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> 
>> Hi Ken,
>> As far as I can see, ggtitle accepts a single string. The help page is
>> a bit obscure, implying that you can change the title with the "labs"
>> function(?), but using the same explicit string in the "ggtitle" line,
>> perhaps for didactic purposes. You seem to be asking to substitute
>> your own version of a string that is popping out in ggplot
>> automatically, e.g. "Tue" -> "Tuesday". The help page doesn't discuss
>> whether it is possible to access the string that will be automatically
>> used as the title. If ggtitle automatically uses the name of the
>> object that you are plotting, something like this may work:
>> 
>> my_x<-1:5
>> myfun<-function(x,mytitle) {
>> plot(x)
>> old_title<-deparse(substitute(x))
>> title(gsub("x",mytitle,old_title))
>> }
>> myfun(my_x,"wonderful X")
>> 
>> The reason that I have done this in base graphics is that I could not
>> get an equivalent plot in ggplot.
>> 
>> Jim
>> 
>> 
>> On Wed, Jun 29, 2016 at 9:48 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> I frankly don't know what the heck you are doing but,
>>> 
>>> (inline below)
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Tue, Jun 28, 2016 at 1:46 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>> Thanks for getting back to me.  None of them work, because I?m trying to use the string in the function  call - myfun(z, ?string?) to replace the empty space in ggtitle.
>>>> 
>>>> ***When I call myfun(z, gsub(?______?, ?string (or any word)?, myfun), I get an error msg because gsub is looking for a data frame, not a function.***
>>> 
>>> That is absolutely, unequivocally, positively, FALSE. See ?gsub for
>>> what gsub() *does* want.
>>> 
>>> This suggests to me that you may also not understand functions and/or
>>> function arguments, so I would recommend that you try a web tutorial
>>> or two on R function to see where your confusion may lie. However, I
>>> freely admit (see my initial remark) that I may not understand what
>>> you are trying to do, so maybe that's not it. I will say if I wanted
>>> to give an arbitrary character string to a function that called a
>>> title function, titleFUN, I'd do it like this:
>>> 
>>> myfun <- function(..., mytitle){
>>> 
>>> ## lots of stuff
>>> 
>>> titleFUN(mytitle)
>>> 
>>> ## more stuff
>>> 
>>> }
>>> 
>>> and call it by:
>>> 
>>> myfun(..., "myReallyCuteTitle")
>>> 
>>> 
>>> I do not use ggplot and so do not know its detailed syntax; but I
>>> would be surprised if it did not accept something along these lines...
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>> 
>>>> Paste or paste0 doesn?t work, either because I still have to replace the space in ggtitle with something.
>>>> 
>>>> In short, I want to put another argument into the function that will enable me to call it and fill that space.
>>>> 
>>>> I?m stumped.
>>>> 
>>>> 
>>>> Ken
>>>> kmnanus at gmail.com
>>>> 914-450-0816 (tel)
>>>> 347-730-4813 (fax)
>>>> 
>>>> 
>>>> 
>>>>> On Jun 28, 2016, at 3:42 PM, Greg Snow <538280 at gmail.com> wrote:
>>>>> 
>>>>> There are several options.  The option that is most like search and
>>>>> replace is to use the `sub` or `gsub` function (or similar functions
>>>>> in added packages).  But you may be able to accomplish what you want
>>>>> even simpler by using the `paste`, `paste0`, or `sprintf` functions.
>>>>> 
>>>>> On Tue, Jun 28, 2016 at 12:10 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>>>> Thanks for getting back to me, I?m sorry if I was unclear.
>>>>>> 
>>>>>> What I?m trying to figure out is the equivalent of ?find and replace? in Word.
>>>>>> 
>>>>>> I have a function -
>>>>>> 
>>>>>> myfun <- function(z){
>>>>>> ggplot(df, aes(x,y)+
>>>>>> geom_point() +
>>>>>> ggtitle (?_______ quick brown fox jumped over the lazy dog?)}
>>>>>> 
>>>>>> Calling myfun(z) works perfectly.  What I?m trying to do is add a string to myfun so that it would read:  function(z, ?string?){
>>>>>> 
>>>>>> Then I could call myfun(z, ?string?) to replace the space in ggtitle.  Is there a straightforward way to do that?
>>>>>> 
>>>>>> Ken
>>>>>> kmnanus at gmail.com
>>>>>> 914-450-0816 (tel)
>>>>>> 347-730-4813 (fax)
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>>> On Jun 28, 2016, at 12:20 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>>> 
>>>>>>>> 
>>>>>>>> On Jun 27, 2016, at 6:12 PM, KMNanus <kmnanus at gmail.com> wrote:
>>>>>>>> 
>>>>>>>> I?m inexperience but am trying to get my head around using functions to make a number of ggplots easier to do.
>>>>>>>> 
>>>>>>>> I have a function that creates a ggplot taking one input variable as an argument. The variable name is shorthand for the actual variable (variable name = tue, Actual name = Tuesday).  Since I want to use the actual variable name in ylab and ggtitle, I?d like to add a second argument, new.name, to the function which would allow me to utilize both inputs as arguments but have not been successful.  I tried creating a function within the function to accomplish this, using deparse(substitute(new.name))and also using the code you see below.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> myfun <- function(myvar, new.name){
>>>>>>>> function(new.name){return(as.character(substitute(new.name)))}
>>>>>>>> ggplot(b12.2, aes(x= games,  y = myvar, col = Group))+
>>>>>>>> geom_point() +
>>>>>>>> geom_line()+
>>>>>>>> xlab("Minimum Games" ) +
>>>>>>>> ylab(paste(new.name, ?Average Change"))+
>>>>>>>> ggtitle(new.name, "Change \n as a Function of Minimum Number of Games?)+
>>>>>>>> theme_bw()
>>>>>>>> 
>>>>>>>> When call myfun(myvar, new.name), I get an error msg ?new.name is not found? whether I call new.name or Tuesday.
>>>>>>> 
>>>>>>> Q1: At the moment we have no idea _how_ you might be "calling" this function. We also do not know what might be assigned to `myvar` or `new.name` in the calling environment. Sounds unlikely that you are typing:
>>>>>>> 
>>>>>>> myfun(myvar, new.name)  ## ?, so was there a loop/lapply calling method?
>>>>>>> 
>>>>>>> 
>>>>>>> Q2: You should not imagine that the inner anonymous function would be altering the value of `new.name`. (That function is only defined and never called, and even if it were called, it would not change the value of the `new.name` in the calling environment.)
>>>>>>> 
>>>>>>> Since more than 12 hours have passed with no response, we can surmise that many people have passed the question over after concluding there was an incomplete problem description. You should post code that can be cut-pasted into a session and produce the error you are getting. It would include data setup and a loop or loop equivalent to show how the function is being called.
>>>>>>> 
>>>>>>> --
>>>>>>> David.
>>>>>>> 
>>>>>>> 
>>>>>>>> 
>>>>>>>> I want ggplot to automatically insert Tuesday into ylab and ggtitle.
>>>>>>>> 
>>>>>>>> Can anyone help me with this?  Thanks for your patience.
>>>>>>>> 
>>>>>>>> Ken
>>>>>>>> kmnanus at gmail.com <mailto:kmnanus at gmail.com>
>>>>>>>> 914-450-0816 (tel)
>>>>>>>> 347-730-4813 (fax)
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> David Winsemius
>>>>>>> Alameda, CA, USA
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> Gregory (Greg) L. Snow Ph.D.
>>>>> 538280 at gmail.com
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From stefanML at collocations.de  Wed Jun 29 08:43:08 2016
From: stefanML at collocations.de (Stefan Evert)
Date: Wed, 29 Jun 2016 08:43:08 +0200
Subject: [R] strange behavior of lchoose in combinatorics problem
In-Reply-To: <6758A37B-694F-4F8F-8809-711009BC63FA@gmail.com>
References: <EDA3FADA-A4E2-4F04-8A9C-2617DE0C9B2F@gmail.com>
	<58375192-5926-43BF-950B-281B52D44DC3@collocations.de>
	<6758A37B-694F-4F8F-8809-711009BC63FA@gmail.com>
Message-ID: <1BBCB7CE-5B0A-4C8E-BD81-F905ED6C19A7@collocations.de>

Dear Gon?alo,

thanks for the additional information ? I think I get now what you're trying to do.

> On 27 Jun 2016, at 06:35, Gon?alo Ferraz <gferraz29 at gmail.com> wrote:
> 
> probabilities in lpvec should be <=1, but it is not. The sum is something on the order of 1.48e-13.?
> It is absolutely right that lpvec doesn?t contain probabilities, it contains log-probabilities that are negative numbers. Also, clearly, the value of 1.48e-13 is <=1!
> What I meant is that I wanted to add probabilities in the log-probability space

Does that make any sense?  Adding log probabilities corresponds to taking the product of the probabilities for k = 0 .. J-1, and I can't think of a reasonable interpretation of this product. 

Or do you perform a log-space addition, so you actually compute the log of the sum of probabilities?

> and that I expected a negative value as a result. Instead, I am getting a positive value.

If you're performing log-space addition, then that's no surprise at all.  The cumulative probability for k <= J that you're computing is equal to 1 up to 43 decimal places ? a difference much smaller than the rounding errors you're accumulating with your formula (which unnecessarily uses 5 terms instead of the normal 3 in lveech, making things even worse).

If you're directly adding the log probabilities, then I can't reproduce your result at all:

> sum(lpvec)
[1] -2835.86

In this case, I suspect that there's a mistake in the parts of the code you didn't show us.

> You are also right that if I wanted to test for a positive association I should add the probabilities of k>=J to obtain a p-value. This is clear to me, but I want a metric of the strength of association between animals that takes higher values when the association is stronger. A final result in the log-probability space is useful because I want to use the strength of association to build networks of individuals.

What we usually do in computational linguistics is to take -log(p-value) as a measure of association because it has the desired properties: large values indicate stronger association, and it's measured in log-probability space (again, http://www.collocations.de/AM/section3.html explains this approach near the top of the page).

This measure ? and Dunning's related log-likelihood ratio ? are used quite successfully for co-occurrences of words in my field.

> Finally, your idea of using Fisher?s exact test is very appealing for the simplicity and availability of a working function in R, but I am having trouble interpreting the result, or the result is different from that of my formula. Here?s a simple example:
> 
> Say N=2, N1=1, N2=1, and J=1. In this case, if the individuals are completely independent of each other, I expect to see them together with a probability of 0.5. That is the output from my function, in probability space. If I run Fisher?s exact test on the corresponding contingency table, however, I get a p-value of 1.

There are two possible outcomes of this experiment, J=0 and J=1, with equal probability 0.5.  Fisher's test computes the tail probability of the observed outcome + all equally or less probable outcomes, i.e. P(J=1) + P(J=0) = 1.

If you carry out a one-sided test, you'll get p=0.5.

> Why should this be, when the Fisher?s exact test is giving me the probability of obtaining the observed arrangement under the null hypothesis of no association between the animals.

A p-value isn't the probability of the observed arrangement, but the cumulative probability of the observed table + all more "extreme" tables that could have been observed (i.e. those which deviate further from the null hypothesis).


If you need your p-values in log-space, you can't use fisher.test() but need to compute the hypergeometric distribution directly with dhyper() / phyper().  This is easy for a one-sided test (for positive association, i.e. atlernative="greater"):

	fisher.test(ct, alternative="greater")$p.value

is the same as

	phyper(J-1, N1, N-N1, N2, lower.tail=FALSE)

You can then instruct phyper() to return log probabilities and use

	-phyper(J-1, N1, N-N1, N2, lower.tail=FALSE, log.p=TRUE)

as a measure of association strength.

Best,
Stefan

From adriens_cachan at yahoo.fr  Wed Jun 29 08:52:45 2016
From: adriens_cachan at yahoo.fr (BONACHE Adrien)
Date: Wed, 29 Jun 2016 06:52:45 +0000 (UTC)
Subject: [R] t-test for regression estimate
In-Reply-To: <b86a1527-ecd3-6749-a137-865482d30136@gmail.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>
	<b86a1527-ecd3-6749-a137-865482d30136@gmail.com>
Message-ID: <1880386755.5433647.1467183165615.JavaMail.yahoo@mail.yahoo.com>

Dear Steven,
I understand your request now. Maybe you could try to change the function lm and create another function enabling you to have the information you want really quickly. 
Use lm() to see the code of this command and change this one marginally to get what you want to. Once this is done, copy paste the code in a new function and save your code.
Regards,
Adrien.
      De?: Steven Yen <syen04 at gmail.com>
 ??: "Fox, John" <jfox at mcmaster.ca> 
Cc?: R-help <r-help at r-project.org>
 Envoy? le : Mercredi 29 juin 2016 0h43
 Objet?: Re: [R] t-test for regression estimate
   
Thanks John. Reason is I am doing linear transformations of many 
coefficients (e.g., bi / scalar). Of course I can uncover the 
t-statistic from the F statistic and then the standard error. Simply 
scaling the estimated coefficients I can also transform the standard 
errors. I have since found deltaMethod from library "car" useful. Its 
just that, if linearHypothesis had provide the standard errors and 
t-statistics then the operation would have been easier, with a one-line 
command for each coefficient. Thank you again.

On 6/28/2016 6:28 PM, Fox, John wrote:
> Dear Steven,
>
> The reason that linearHypothesis() computes a Wald F or chisquare test rather than a t or z test is that the (numerator) df for the linear hypothesis need not be 1.
>
> In your case (as has been pointed out) you can get the coefficient standard error directly from the model summary.
>
> More generally, with some work, you could solve for the the SE for a 1 df linear hypothesis in terms of the value of the linear function of coefficients and the F or chisquare. That said, I'm not sure why you want to do this.
>
> I hope this helps,
>? John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
>> Sent: June 28, 2016 9:27 AM
>> To: R-help <r-help at r-project.org>
>> Subject: [R] t-test for regression estimate
>>
>> test option for linearHypothesis in library(car) include "Chisq" and "F". I prefer
>> a simple t-test so that I can retrieve the standard error.
>> Any options other than linearHypothesis to test the linear hypothesis (with 1
>> restriction/degree of freedom)?
>>
>>? > summary(ols1)
>>
>> Coefficients:
>>? ? ? ? ? ? ? Estimate Std. Error t value Pr(>|t|)
>> (Intercept) -0.20013? ? 0.09199? -2.176? 0.0298 *
>> age? ? ? ? ? 0.04054? ? 0.01721? 2.355? 0.0187 *
>> suburb? ? ? 0.01911? ? 0.05838? 0.327? 0.7435
>> smcity? ? ? -0.29969? ? 0.19175? -1.563? 0.1184
>> ---
>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>? > linearHypothesis(ols1,"suburb")
>> Linear hypothesis test
>>
>> Hypothesis:
>> suburb = 0
>>
>> Model 1: restricted model
>> Model 2: polideo ~ age + suburb + smcity
>>
>>? ? Res.Df? ? RSS Df Sum of Sq? ? ? F Pr(>F)
>> 1? ? 888 650.10
>> 2? ? 887 650.02? 1? 0.078534 0.1072 0.7435
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From p_connolly at slingshot.co.nz  Wed Jun 29 10:29:30 2016
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 29 Jun 2016 20:29:30 +1200
Subject: [R] > Understanding strip.default & strip.custom
In-Reply-To: <CAGxFJbTVAG7kEv6eLLAu2eVn-2QJgVMrBF_SSSE4=hMKKmCTWA@mail.gmail.com>
References: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>
	<CAGxFJbTVAG7kEv6eLLAu2eVn-2QJgVMrBF_SSSE4=hMKKmCTWA@mail.gmail.com>
Message-ID: <20160629082930.GA16087@slingshot.co.nz>

On Mon, 27-Jun-2016 at 10:17PM -0700, Bert Gunter wrote:

[...]

|> 
|> You seem to be making this way more difficult than you should.

Though I didn't get any closer to an understanding of which.panel, the
question I asked was simply answered by

panel.custom(factor.levels = <as before>)

Thanks to Duncan Mackay also.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From wewolski at gmail.com  Wed Jun 29 11:16:56 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 29 Jun 2016 11:16:56 +0200
Subject: [R] Splitting data.frame into a list of small data.frames given
	indices
Message-ID: <CAAjnpdispjvZL_hBzR-vFLqdh-JPW1p67vUmN5AEar5j7cSY1g@mail.gmail.com>

It's the inverse problem to merging a list of data.frames into a large
data.frame just discussed in the "performance of do.call("rbind")"
thread

I would like to split a data.frame into a list of data.frames
according to first column.
This SEEMS to be easily possible with the function base::by. However,
as soon as the data.frame has a few million rows this function CAN NOT
BE USED (except you have A PLENTY OF TIME).

for 'by' runtime ~ nrow^2, or formally O(n^2)  (see benchmark below).

So basically I am looking for a similar function with better complexity.


 > nrows <- c(1e5,1e6,2e6,3e6,5e6)
> timing <- list()
> for(i in nrows){
+ dum <- peaks[1:i,]
+ timing[[length(timing)+1]] <- system.time(x<- by(dum[,2:3],
INDICES=list(dum[,1]), FUN=function(x){x}, simplify = FALSE))
+ }
> names(timing)<- nrows
> timing
$`1e+05`
   user  system elapsed
   0.05    0.00    0.05

$`1e+06`
   user  system elapsed
   1.48    2.98    4.46

$`2e+06`
   user  system elapsed
   7.25   11.39   18.65

$`3e+06`
   user  system elapsed
  16.15   25.81   41.99

$`5e+06`
   user  system elapsed
  43.22   74.72  118.09





-- 
Witold Eryk Wolski


From G.Maubach at weinwolf.de  Wed Jun 29 11:49:13 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 29 Jun 2016 11:49:13 +0200
Subject: [R] Installing from source on Windows 7: tibble
Message-ID: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>

Hi All,

I would like to install R packages from source on Windows 7 64-Bit. 
Currently my settings are:

-- cut --
> sessionInfo()
R version 3.3.0 (2016-05-03)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252 
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C 
[5] LC_TIME=German_Germany.1252 

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base 

loaded via a namespace (and not attached):
[1] tools_3.3.0
-- cut --

The environment variable PATH on Windows 7 is set to:

C:\R-Project\Rtools\mingw_32\bin;C:\R-Project\Rtools\mingw_64\bin;C:\R-Project\Rtools\bin;C:\R-Project\Rtools\gcc-4.6.3\bin;C:\Program 
Files\Python 3.5\Scripts\;C:\Program Files\Python 
3.5\;C:\Python27\;C:\Python27\Scripts; etc. etc.

RTools is installed in C:\R-Project\RTools

The call of

C:\R-Project\Rtools\mingw_64\bin\g++.exe --version

results in

g++ (x86_64-posix-seh, Built by MinGW-W64 project) 4.9.3

If I do


> install.packages("tibble", type = "source")

I get

-- cut --
trying URL 'https://cran.uni-muenster.de/src/contrib/tibble_1.0.tar.gz'
Content type 'application/x-gzip' length 38038 bytes (37 KB)
downloaded 37 KB

* installing *source* package 'tibble' ...
** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
** libs

*** arch - i386
c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG 
-I"C:/R-Project/R-3.3.0/library/Rcpp/include" 
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c 
RcppExports.cpp -o RcppExports.o
c:/Rtools/mingw_32/bin/g++: not found
make: *** [RcppExports.o] Error 127
Warnung: Ausf?hrung von Kommando 'make -f 
"C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f 
"C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk" 
SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)' 
SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab 
Status 2
ERROR: compilation failed for package 'tibble'
* removing 'C:/R-Project/R-3.3.0/library/tibble'
* restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
Warning in install.packages :
  running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l 
"C:\R-Project\R-3.3.0\library" 
C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\Rtmp23SQxM/downloaded_packages/tibble_1.0.tar.gz' 
had status 1
Warning in install.packages :
  installation of package ?tibble? had non-zero exit status
-- cut --

There is no make.conf in "C:\R-Project\Rtools\mingw_64\etc". I found "
Makeconf" in "C:\R-Project\R-3.3.0\etc\x64". Do I need it? How do I need 
to configure the settings in this file?

I searched old aunt Google but did not understand what to do and how to 
configure R environment variables correctly.

What do I need to do to install packages from source?

Kind regards

Georg



From r.turner at auckland.ac.nz  Wed Jun 29 12:00:58 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 29 Jun 2016 22:00:58 +1200
Subject: [R] [FORGED] Splitting data.frame into a list of small
 data.frames given indices
In-Reply-To: <CAAjnpdispjvZL_hBzR-vFLqdh-JPW1p67vUmN5AEar5j7cSY1g@mail.gmail.com>
References: <CAAjnpdispjvZL_hBzR-vFLqdh-JPW1p67vUmN5AEar5j7cSY1g@mail.gmail.com>
Message-ID: <545dedd7-2bdb-2fbd-651d-bc6bd43f8df6@auckland.ac.nz>

On 29/06/16 21:16, Witold E Wolski wrote:
> It's the inverse problem to merging a list of data.frames into a large
> data.frame just discussed in the "performance of do.call("rbind")"
> thread
>
> I would like to split a data.frame into a list of data.frames
> according to first column.
> This SEEMS to be easily possible with the function base::by. However,
> as soon as the data.frame has a few million rows this function CAN NOT
> BE USED (except you have A PLENTY OF TIME).
>
> for 'by' runtime ~ nrow^2, or formally O(n^2)  (see benchmark below).
>
> So basically I am looking for a similar function with better complexity.
>
>
>  > nrows <- c(1e5,1e6,2e6,3e6,5e6)
>> timing <- list()
>> for(i in nrows){
> + dum <- peaks[1:i,]
> + timing[[length(timing)+1]] <- system.time(x<- by(dum[,2:3],
> INDICES=list(dum[,1]), FUN=function(x){x}, simplify = FALSE))
> + }
>> names(timing)<- nrows
>> timing
> $`1e+05`
>    user  system elapsed
>    0.05    0.00    0.05
>
> $`1e+06`
>    user  system elapsed
>    1.48    2.98    4.46
>
> $`2e+06`
>    user  system elapsed
>    7.25   11.39   18.65
>
> $`3e+06`
>    user  system elapsed
>   16.15   25.81   41.99
>
> $`5e+06`
>    user  system elapsed
>   43.22   74.72  118.09

I'm not sure that I follow what you're doing, and your example is not 
reproducible, since we have no idea what "peaks" is, but on a toy 
example with 5e6 rows in the data frame I got a timing result of

    user  system elapsed
   0.379   0.025   0.406

when I applied split().  Is this adequately fast? Seems to me that if 
you want to split something, split() would be a good place to start.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From c.jallet at laposte.net  Wed Jun 29 11:55:55 2016
From: c.jallet at laposte.net (c.jallet at laposte.net)
Date: Wed, 29 Jun 2016 11:55:55 +0200
Subject: [R] Understanding and predict round-off errors sign on simple
	functions
Message-ID: <002e01d1d1ec$70c99080$525cb180$@laposte.net>

Hi,

 

May be it is a basic thing but I would like to know if we can anticipate
round-off errors sign.

 

Here is an example :

 

# numerical matrix

m <- matrix(data=cbind(rnorm(10, 0), rnorm(10, 2), rnorm(10, 5)), nrow=10,
ncol=3)

 

> m

            [,1]      [,2]     [,3]

[1,]  0.4816247 1.1973502 3.855641

[2,] -1.2174937 0.7356427 4.393279

[3,]  0.8504074 2.5286509 2.689196

[4,]  1.8048642 1.8580804 6.665237

[5,] -0.6749397 1.0944277 4.838608

[6,]  0.8252034 1.5595268 3.681695

[7,]  1.3002208 0.9582693 4.561577

[8,]  1.6950923 3.5677921 6.005078

[9,]  0.6509285 0.9025964 5.082288

[10,] -0.5676040 1.3281102 4.446451

 

#weird moving average of period 1 !

mma <- apply(m, 2, SMA, n=1)

 

> mma

            [,1]      [,2]     [,3]

[1,]         NA        NA       NA

[2,] -1.2174937 0.7356427 4.393279

[3,]  0.8504074 2.5286509 2.689196

[4,]  1.8048642 1.8580804 6.665237

[5,] -0.6749397 1.0944277 4.838608

[6,]  0.8252034 1.5595268 3.681695

[7,]  1.3002208 0.9582693 4.561577

[8,]  1.6950923 3.5677921 6.005078

[9,]  0.6509285 0.9025964 5.082288

[10,] -0.5676040 1.3281102 4.446451

 

 

#difference should be 0 but here is the result

> m - mma 

               [,1]         [,2]          [,3]

[1,]            NA           NA            NA

[2,]  0.000000e+00 0.000000e+00 -8.881784e-16

[3,]  0.000000e+00 0.000000e+00 -8.881784e-16

[4,]  0.000000e+00 4.440892e-16 -8.881784e-16

[5,] -1.110223e-16 4.440892e-16 -8.881784e-16

[6,] -1.110223e-16 2.220446e-16 -4.440892e-16

[7,] -2.220446e-16 2.220446e-16  0.000000e+00

[8,] -2.220446e-16 0.000000e+00  0.000000e+00

[9,] -3.330669e-16 2.220446e-16 -8.881784e-16

[10,] -3.330669e-16 4.440892e-16 -8.881784e-16

 

SMA function use runMean 

# TTR / R / MovingAverages.R 

"SMA" <- function(x, n=10, ...) { # Simple Moving Average 

   ma <- runMean( x, n ) 

   if(!is.null(dim(ma))) { 

     colnames(ma) <- "SMA" 

   } 

  return(ma) 

}

 

 

Can anyone explain me that round error type?  

Is it possible to reproduce this same error generation in another language
like C++ or C# ?

 

Thanks in advance for your answers

 

Regards

 

Chris

 


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Jun 29 13:08:29 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Jun 2016 07:08:29 -0400
Subject: [R] Installing from source on Windows 7: tibble
In-Reply-To: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>
References: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>
Message-ID: <00cd6609-5782-1d21-4221-5176f498f981@gmail.com>

On 29/06/2016 5:49 AM, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I would like to install R packages from source on Windows 7 64-Bit.
> Currently my settings are:
>
> -- cut --
>> sessionInfo()
> R version 3.3.0 (2016-05-03)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.0
> -- cut --
>
> The environment variable PATH on Windows 7 is set to:
>
> C:\R-Project\Rtools\mingw_32\bin;C:\R-Project\Rtools\mingw_64\bin;C:\R-Project\Rtools\bin;C:\R-Project\Rtools\gcc-4.6.3\bin;C:\Program
> Files\Python 3.5\Scripts\;C:\Program Files\Python
> 3.5\;C:\Python27\;C:\Python27\Scripts; etc. etc.

Take the mingw_32, mingw_64 and gcc-4.6.3 directories off your path. 
They aren't needed; the first two could conceivably be harmful.

>
> RTools is installed in C:\R-Project\RTools
>
> The call of
>
> C:\R-Project\Rtools\mingw_64\bin\g++.exe --version
>
> results in
>
> g++ (x86_64-posix-seh, Built by MinGW-W64 project) 4.9.3
>
> If I do
>
>
>> install.packages("tibble", type = "source")
>
> I get
>
> -- cut --
> trying URL 'https://cran.uni-muenster.de/src/contrib/tibble_1.0.tar.gz'
> Content type 'application/x-gzip' length 38038 bytes (37 KB)
> downloaded 37 KB
>
> * installing *source* package 'tibble' ...
> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> ** libs
>
> *** arch - i386
> c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c
> RcppExports.cpp -o RcppExports.o
> c:/Rtools/mingw_32/bin/g++: not found
> make: *** [RcppExports.o] Error 127
> Warnung: Ausf?hrung von Kommando 'make -f
> "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> Status 2
> ERROR: compilation failed for package 'tibble'
> * removing 'C:/R-Project/R-3.3.0/library/tibble'
> * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> Warning in install.packages :
>   running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> "C:\R-Project\R-3.3.0\library"
> C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\Rtmp23SQxM/downloaded_packages/tibble_1.0.tar.gz'
> had status 1
> Warning in install.packages :
>   installation of package ?tibble? had non-zero exit status
> -- cut --
>
> There is no make.conf in "C:\R-Project\Rtools\mingw_64\etc". I found "
> Makeconf" in "C:\R-Project\R-3.3.0\etc\x64". Do I need it? How do I need
> to configure the settings in this file?

Yes, since you haven't installed Rtools in the default location, you 
should edit two Makeconf files.  In 
C:\R-Project\R-3.3.0\etc\x64\Makeconf, you want

BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_64/bin/

and in C:\R-Project\R-3.3.0\etc\i386\Makeconf you want

BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_32/bin/

You need to make sure you don't have an environment variable named 
BINPREF defined, or it will override these settings.  (If you were 
building just one architecture, you could do the setting by environment 
variable, but not if you are trying to build both archs in one call.)

Duncan Murdoch

>
> I searched old aunt Google but did not understand what to do and how to
> configure R environment variables correctly.
>
> What do I need to do to install packages from source?
>
> Kind regards
>
> Georg
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Wed Jun 29 13:18:35 2016
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 29 Jun 2016 03:18:35 -0800
Subject: [R] Rpart plot produces no text
In-Reply-To: <BN3PR1001MB1124B718C0B581D494D951C5A2220@BN3PR1001MB1124.namprd10.prod.outlook.com>
Message-ID: <FCC0EA1AB58.00000AC9jrkrideau@inbox.com>

What happens if you run the code in a terminal rather than RStudio? My experience is that very, very occasionally RStudio does something a bit funny with plots.  

And while this may sound funny just shut down RStudio, reload it and try again. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jcthompson at redlobster.com
> Sent: Tue, 28 Jun 2016 20:26:59 +0000
> To: r-help at r-project.org
> Subject: [R] Rpart plot produces no text
> 
> I am using R Studio and am able to fit a tree with RPlot, however, the
> tree in the viewer has no text (see image attached).
> 
> Jim Thompson
> This e-mail message is for the sole use of the intende...{{dropped:21}}


From dulcalma at bigpond.com  Wed Jun 29 14:15:14 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 29 Jun 2016 22:15:14 +1000
Subject: [R] > Understanding strip.default & strip.custom
In-Reply-To: <20160629082930.GA16087@slingshot.co.nz>
References: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>	<CAGxFJbTVAG7kEv6eLLAu2eVn-2QJgVMrBF_SSSE4=hMKKmCTWA@mail.gmail.com>
	<20160629082930.GA16087@slingshot.co.nz>
Message-ID: <000001d1d1ff$e4c35fd0$ae4a1f70$@bigpond.com>

Patrick

Have a look at 
https://stat.ethz.ch/pipermail/r-help/2006-August/110621.html
and
https://stat.ethz.ch/pipermail/r-help/2008-June/165279.html

I remember working it out with an example but I cannot remember any of the
details

Regards

Duncan


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Patrick
Connolly
Sent: Wednesday, 29 June 2016 18:30
To: Bert Gunter
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] > Understanding strip.default & strip.custom

On Mon, 27-Jun-2016 at 10:17PM -0700, Bert Gunter wrote:

[...]

|> 
|> You seem to be making this way more difficult than you should.

Though I didn't get any closer to an understanding of which.panel, the
question I asked was simply answered by

panel.custom(factor.levels = <as before>)

Thanks to Duncan Mackay also.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Wed Jun 29 14:27:49 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 29 Jun 2016 14:27:49 +0200 (CEST)
Subject: [R] Rpart plot produces no text
In-Reply-To: <FCC0EA1AB58.00000AC9jrkrideau@inbox.com>
References: <FCC0EA1AB58.00000AC9jrkrideau@inbox.com>
Message-ID: <alpine.DEB.2.20.1606291421210.30590@paninaro>

I don't think this is an RStudio issue. The plot() method for "rpart" 
objects draws no labels. The text() method has to be called additionally:

library("rpart")
rp <- rpart(Species ~ ., data = iris)
plot(rp)
text(rp)

As these plots produced by rpart itself are not very appealing, there are 
various approaches that allow drawing other displays, e.g.,

library("rpart.plot")
prp(rp)

library("rattle")
fancyRpartPlot(rp)

library("partykit")
plot(as.party(rp))

which show different amounts of detail and use different visual means to 
display the available information.

On Wed, 29 Jun 2016, John Kane wrote:

> What happens if you run the code in a terminal rather than RStudio? My experience is that very, very occasionally RStudio does something a bit funny with plots.
>
> And while this may sound funny just shut down RStudio, reload it and try again.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: jcthompson at redlobster.com
>> Sent: Tue, 28 Jun 2016 20:26:59 +0000
>> To: r-help at r-project.org
>> Subject: [R] Rpart plot produces no text
>>
>> I am using R Studio and am able to fit a tree with RPlot, however, the
>> tree in the viewer has no text (see image attached).
>>
>> Jim Thompson
>> This e-mail message is for the sole use of the intende...{{dropped:21}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chalabi.elahe at yahoo.de  Wed Jun 29 15:08:50 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Wed, 29 Jun 2016 13:08:50 +0000 (UTC)
Subject: [R] a new df with one combined column
References: <213311750.5859189.1467205730821.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <213311750.5859189.1467205730821.JavaMail.yahoo@mail.yahoo.com>

Hi all,
I have this column as a part of df:
 
    $License :   Factor W/384 levels "41005","41006","41034","41097","41200",...
and I have other column which is a part of other df lets say df2:

    $Diff    :   int  41166 41202 41290 41353 41503 41507 41548
these two columns df$License and df$Diff have different dimensions and I want to make a new df that is combinations of both i.e. I want a column which has both of these columns together as one column, but I don't know how to bring these two column in one as a new df. Does anyone know how should I do that?
Thanks for any help,
Elahe


From wewolski at gmail.com  Wed Jun 29 15:21:19 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 29 Jun 2016 15:21:19 +0200
Subject: [R] [FORGED] Splitting data.frame into a list of small
 data.frames given indices
In-Reply-To: <545dedd7-2bdb-2fbd-651d-bc6bd43f8df6@auckland.ac.nz>
References: <CAAjnpdispjvZL_hBzR-vFLqdh-JPW1p67vUmN5AEar5j7cSY1g@mail.gmail.com>
	<545dedd7-2bdb-2fbd-651d-bc6bd43f8df6@auckland.ac.nz>
Message-ID: <CAAjnpdiSMpPC+87LBXdu2fxRQx2dzWo9cDezJGa8zpwqdo5xuw@mail.gmail.com>

Hi,

Here is an complete example which shows the the complexity of split or
by is O(n^2)

nrows <- c(1e3,5e3, 1e4 ,5e4, 1e5 ,2e5)
res<-list()

for(i in nrows){
  dum <- data.frame(x = runif(i,1,1000), y=runif(i,1,1000))
  res[[length(res)+1]]<-(system.time(x<- split(dum, 1:nrow(dum))))
}
res <- do.call("rbind",res)
plot(nrows^2, res[,"elapsed"])

And I can't see a reason why this has to be so slow.


cheers







On 29 June 2016 at 12:00, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 29/06/16 21:16, Witold E Wolski wrote:
>>
>> It's the inverse problem to merging a list of data.frames into a large
>> data.frame just discussed in the "performance of do.call("rbind")"
>> thread
>>
>> I would like to split a data.frame into a list of data.frames
>> according to first column.
>> This SEEMS to be easily possible with the function base::by. However,
>> as soon as the data.frame has a few million rows this function CAN NOT
>> BE USED (except you have A PLENTY OF TIME).
>>
>> for 'by' runtime ~ nrow^2, or formally O(n^2)  (see benchmark below).
>>
>> So basically I am looking for a similar function with better complexity.
>>
>>
>>  > nrows <- c(1e5,1e6,2e6,3e6,5e6)
>>>
>>> timing <- list()
>>> for(i in nrows){
>>
>> + dum <- peaks[1:i,]
>> + timing[[length(timing)+1]] <- system.time(x<- by(dum[,2:3],
>> INDICES=list(dum[,1]), FUN=function(x){x}, simplify = FALSE))
>> + }
>>>
>>> names(timing)<- nrows
>>> timing
>>
>> $`1e+05`
>>    user  system elapsed
>>    0.05    0.00    0.05
>>
>> $`1e+06`
>>    user  system elapsed
>>    1.48    2.98    4.46
>>
>> $`2e+06`
>>    user  system elapsed
>>    7.25   11.39   18.65
>>
>> $`3e+06`
>>    user  system elapsed
>>   16.15   25.81   41.99
>>
>> $`5e+06`
>>    user  system elapsed
>>   43.22   74.72  118.09
>
>
> I'm not sure that I follow what you're doing, and your example is not
> reproducible, since we have no idea what "peaks" is, but on a toy example
> with 5e6 rows in the data frame I got a timing result of
>
>    user  system elapsed
>   0.379 0.025 0.406
>
> when I applied split().  Is this adequately fast? Seems to me that if you
> want to split something, split() would be a good place to start.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276



-- 
Witold Eryk Wolski


From ulrik.stervbo at gmail.com  Wed Jun 29 15:35:05 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 29 Jun 2016 13:35:05 +0000
Subject: [R] a new df with one combined column
In-Reply-To: <213311750.5859189.1467205730821.JavaMail.yahoo@mail.yahoo.com>
References: <213311750.5859189.1467205730821.JavaMail.yahoo.ref@mail.yahoo.com>
	<213311750.5859189.1467205730821.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKVAULOysAbw8Yy7XG13QVktkpAjA9J350UMteLQ9S1Khgv9CA@mail.gmail.com>

It looks like the function you are searching for is merge()

HTH
Ulrik

On Wed, 29 Jun 2016 at 15:11 ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi all,
> I have this column as a part of df:
>
>     $License :   Factor W/384 levels
> "41005","41006","41034","41097","41200",...
> and I have other column which is a part of other df lets say df2:
>
>     $Diff    :   int  41166 41202 41290 41353 41503 41507 41548
> these two columns df$License and df$Diff have different dimensions and I
> want to make a new df that is combinations of both i.e. I want a column
> which has both of these columns together as one column, but I don't know
> how to bring these two column in one as a new df. Does anyone know how
> should I do that?
> Thanks for any help,
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Wed Jun 29 15:54:20 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 29 Jun 2016 15:54:20 +0200
Subject: [R] [FORGED] Splitting data.frame into a list of small
 data.frames given indices
In-Reply-To: <CAAjnpdiSMpPC+87LBXdu2fxRQx2dzWo9cDezJGa8zpwqdo5xuw@mail.gmail.com>
References: <CAAjnpdispjvZL_hBzR-vFLqdh-JPW1p67vUmN5AEar5j7cSY1g@mail.gmail.com>
	<545dedd7-2bdb-2fbd-651d-bc6bd43f8df6@auckland.ac.nz>
	<CAAjnpdiSMpPC+87LBXdu2fxRQx2dzWo9cDezJGa8zpwqdo5xuw@mail.gmail.com>
Message-ID: <15947bbd-32dc-bbd5-41be-7c22f4a342d1@univ-reims.fr>

Hi,

I don't really understand why you split every row... This makes it very 
slow. Try with a more realistic example (with a factor to split).

Ivan

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 29/06/2016 ? 15:21, Witold E Wolski a ?crit :
> Hi,
>
> Here is an complete example which shows the the complexity of split or
> by is O(n^2)
>
> nrows <- c(1e3,5e3, 1e4 ,5e4, 1e5 ,2e5)
> res<-list()
>
> for(i in nrows){
>    dum <- data.frame(x = runif(i,1,1000), y=runif(i,1,1000))
>    res[[length(res)+1]]<-(system.time(x<- split(dum, 1:nrow(dum))))
> }
> res <- do.call("rbind",res)
> plot(nrows^2, res[,"elapsed"])
>
> And I can't see a reason why this has to be so slow.
>
>
> cheers
>
>
>
>
>
>
>
> On 29 June 2016 at 12:00, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 29/06/16 21:16, Witold E Wolski wrote:
>>> It's the inverse problem to merging a list of data.frames into a large
>>> data.frame just discussed in the "performance of do.call("rbind")"
>>> thread
>>>
>>> I would like to split a data.frame into a list of data.frames
>>> according to first column.
>>> This SEEMS to be easily possible with the function base::by. However,
>>> as soon as the data.frame has a few million rows this function CAN NOT
>>> BE USED (except you have A PLENTY OF TIME).
>>>
>>> for 'by' runtime ~ nrow^2, or formally O(n^2)  (see benchmark below).
>>>
>>> So basically I am looking for a similar function with better complexity.
>>>
>>>
>>>   > nrows <- c(1e5,1e6,2e6,3e6,5e6)
>>>> timing <- list()
>>>> for(i in nrows){
>>> + dum <- peaks[1:i,]
>>> + timing[[length(timing)+1]] <- system.time(x<- by(dum[,2:3],
>>> INDICES=list(dum[,1]), FUN=function(x){x}, simplify = FALSE))
>>> + }
>>>> names(timing)<- nrows
>>>> timing
>>> $`1e+05`
>>>     user  system elapsed
>>>     0.05    0.00    0.05
>>>
>>> $`1e+06`
>>>     user  system elapsed
>>>     1.48    2.98    4.46
>>>
>>> $`2e+06`
>>>     user  system elapsed
>>>     7.25   11.39   18.65
>>>
>>> $`3e+06`
>>>     user  system elapsed
>>>    16.15   25.81   41.99
>>>
>>> $`5e+06`
>>>     user  system elapsed
>>>    43.22   74.72  118.09
>>
>> I'm not sure that I follow what you're doing, and your example is not
>> reproducible, since we have no idea what "peaks" is, but on a toy example
>> with 5e6 rows in the data frame I got a timing result of
>>
>>     user  system elapsed
>>    0.379 0.025 0.406
>>
>> when I applied split().  Is this adequately fast? Seems to me that if you
>> want to split something, split() would be a good place to start.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>
>


From ulrik.stervbo at gmail.com  Wed Jun 29 16:08:19 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 29 Jun 2016 14:08:19 +0000
Subject: [R] a new df with one combined column
In-Reply-To: <190063059.5921924.1467207903107.JavaMail.yahoo@mail.yahoo.com>
References: <213311750.5859189.1467205730821.JavaMail.yahoo.ref@mail.yahoo.com>
	<213311750.5859189.1467205730821.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOysAbw8Yy7XG13QVktkpAjA9J350UMteLQ9S1Khgv9CA@mail.gmail.com>
	<190063059.5921924.1467207903107.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKVAULNTKzASukzExmyomaABmcZuEUUqedFspTYdD_ZCLH+vjw@mail.gmail.com>

Then I don't understand what you want to achieve. If you want to combine
the two columns you can do

c(df1$col1,  df2$col2)

Ulrik

<chalabi.elahe at yahoo.de> schrieb am Mi., 29. Juni 2016 15:45:

> Hi Ulrik,
> Thnaks for your reply, merge() does not give me one column, it returns two
> columns
>
>
> On Wednesday, June 29, 2016 3:35 PM, Ulrik Stervbo <
> ulrik.stervbo at gmail.com> wrote:
>
>
>
> It looks like the function you are searching for is merge()
>
> HTH
> Ulrik
>
>
> On Wed, 29 Jun 2016 at 15:11 ch.elahe via R-help <r-help at r-project.org>
> wrote:
>
> Hi all,
> >I have this column as a part of df:
> >
> >    $License :   Factor W/384 levels
> "41005","41006","41034","41097","41200",...
> >and I have other column which is a part of other df lets say df2:
> >
> >    $Diff    :   int  41166 41202 41290 41353 41503 41507 41548
> >these two columns df$License and df$Diff have different dimensions and I
> want to make a new df that is combinations of both i.e. I want a column
> which has both of these columns together as one column, but I don't know
> how to bring these two column in one as a new df. Does anyone know how
> should I do that?
> >Thanks for any help,
> >Elahe
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Jun 29 16:09:55 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 29 Jun 2016 14:09:55 +0000
Subject: [R] a new df with one combined column
In-Reply-To: <CAKVAULOysAbw8Yy7XG13QVktkpAjA9J350UMteLQ9S1Khgv9CA@mail.gmail.com>
References: <213311750.5859189.1467205730821.JavaMail.yahoo.ref@mail.yahoo.com>
	<213311750.5859189.1467205730821.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOysAbw8Yy7XG13QVktkpAjA9J350UMteLQ9S1Khgv9CA@mail.gmail.com>
Message-ID: <d0dafe425f1348f1b3df05b3ac4193e0@exch-2p-mbx-t2.ads.tamu.edu>

It looks like License was imported as character data and converted to a factor. I'm not sure I understand what you want, but to make them into a single column, you need to convert the factor back to numeric using as.numeric(as.character(License)), but you use the command levels(License) to look at the 384 values in License to be sure there are no non-numeric characters, e.g. 41,001. I there are, you will have to remove them.

> set.seed(42)
> License <- sample(40000:49999, 25)
> License <- factor(as.character(License))
> str(License)
 Factor w/ 25 levels "40822","41172",..: 19 21 6 17 12 10 16 3 13 14 ...
> Diff <- sample(40000:49999, 25)
> str(Diff)
 int [1:25] 45142 43901 49055 44468 48356 47372 48105 43878 46846 40039 ...
> Combined <- c(as.numeric(as.character(License)), Diff)
> str(Combined)
 num [1:50] 49148 49369 42860 48301 46414 ...
> Combined
 [1] 49148 49369 42860 48301 46414 45188 47361 41345 46564 47044 44572 47183 49335 42550
[15] 44616 49386 49766 41172 44741 45592 49022 41384 49867 49444 40822 45142 43901 49055
[29] 44468 48356 47372 48105 43878 46846 40039 48320 40073 42074 49054 46109 43789 44350
[43] 40373 49717 44309 49556 48858 46385 49687 46173


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ulrik Stervbo
Sent: Wednesday, June 29, 2016 8:35 AM
To: chalabi.elahe at yahoo.de; R-help Mailing List
Subject: Re: [R] a new df with one combined column

It looks like the function you are searching for is merge()

HTH
Ulrik

On Wed, 29 Jun 2016 at 15:11 ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi all,
> I have this column as a part of df:
>
>     $License :   Factor W/384 levels
> "41005","41006","41034","41097","41200",...
> and I have other column which is a part of other df lets say df2:
>
>     $Diff    :   int  41166 41202 41290 41353 41503 41507 41548
> these two columns df$License and df$Diff have different dimensions and I
> want to make a new df that is combinations of both i.e. I want a column
> which has both of these columns together as one column, but I don't know
> how to bring these two column in one as a new df. Does anyone know how
> should I do that?
> Thanks for any help,
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Jun 29 16:13:24 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 29 Jun 2016 07:13:24 -0700
Subject: [R] [FORGED] Splitting data.frame into a list of small
 data.frames given indices
In-Reply-To: <CAAjnpdiSMpPC+87LBXdu2fxRQx2dzWo9cDezJGa8zpwqdo5xuw@mail.gmail.com>
References: <CAAjnpdispjvZL_hBzR-vFLqdh-JPW1p67vUmN5AEar5j7cSY1g@mail.gmail.com>
	<545dedd7-2bdb-2fbd-651d-bc6bd43f8df6@auckland.ac.nz>
	<CAAjnpdiSMpPC+87LBXdu2fxRQx2dzWo9cDezJGa8zpwqdo5xuw@mail.gmail.com>
Message-ID: <CAF8bMcZbSRQqOr_WUJyQ_3nNoUoBiUFhrhxa1tFZo+vfksC=3w@mail.gmail.com>

I won't go into why splitting data.frames (or factors) uses time
proportional to the number of input rows times the number of
levels in the splitting factor, but you will get much better mileage
if you call split individually on each 'atomic' (numeric, character, ...)
variable and use mapply on the resulting lists.

The plyr and dplyr packages were developed to deal with this
sort of problem.  Check them out.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jun 29, 2016 at 6:21 AM, Witold E Wolski <wewolski at gmail.com> wrote:

> Hi,
>
> Here is an complete example which shows the the complexity of split or
> by is O(n^2)
>
> nrows <- c(1e3,5e3, 1e4 ,5e4, 1e5 ,2e5)
> res<-list()
>
> for(i in nrows){
>   dum <- data.frame(x = runif(i,1,1000), y=runif(i,1,1000))
>   res[[length(res)+1]]<-(system.time(x<- split(dum, 1:nrow(dum))))
> }
> res <- do.call("rbind",res)
> plot(nrows^2, res[,"elapsed"])
>
> And I can't see a reason why this has to be so slow.
>
>
> cheers
>
>
>
>
>
>
>
> On 29 June 2016 at 12:00, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> > On 29/06/16 21:16, Witold E Wolski wrote:
> >>
> >> It's the inverse problem to merging a list of data.frames into a large
> >> data.frame just discussed in the "performance of do.call("rbind")"
> >> thread
> >>
> >> I would like to split a data.frame into a list of data.frames
> >> according to first column.
> >> This SEEMS to be easily possible with the function base::by. However,
> >> as soon as the data.frame has a few million rows this function CAN NOT
> >> BE USED (except you have A PLENTY OF TIME).
> >>
> >> for 'by' runtime ~ nrow^2, or formally O(n^2)  (see benchmark below).
> >>
> >> So basically I am looking for a similar function with better complexity.
> >>
> >>
> >>  > nrows <- c(1e5,1e6,2e6,3e6,5e6)
> >>>
> >>> timing <- list()
> >>> for(i in nrows){
> >>
> >> + dum <- peaks[1:i,]
> >> + timing[[length(timing)+1]] <- system.time(x<- by(dum[,2:3],
> >> INDICES=list(dum[,1]), FUN=function(x){x}, simplify = FALSE))
> >> + }
> >>>
> >>> names(timing)<- nrows
> >>> timing
> >>
> >> $`1e+05`
> >>    user  system elapsed
> >>    0.05    0.00    0.05
> >>
> >> $`1e+06`
> >>    user  system elapsed
> >>    1.48    2.98    4.46
> >>
> >> $`2e+06`
> >>    user  system elapsed
> >>    7.25   11.39   18.65
> >>
> >> $`3e+06`
> >>    user  system elapsed
> >>   16.15   25.81   41.99
> >>
> >> $`5e+06`
> >>    user  system elapsed
> >>   43.22   74.72  118.09
> >
> >
> > I'm not sure that I follow what you're doing, and your example is not
> > reproducible, since we have no idea what "peaks" is, but on a toy example
> > with 5e6 rows in the data frame I got a timing result of
> >
> >    user  system elapsed
> >   0.379 0.025 0.406
> >
> > when I applied split().  Is this adequately fast? Seems to me that if you
> > want to split something, split() would be a good place to start.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
>
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed Jun 29 16:17:01 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 29 Jun 2016 16:17:01 +0200
Subject: [R] Antwort: Re:  Installing from source on Windows 7: tibble
In-Reply-To: <00cd6609-5782-1d21-4221-5176f498f981@gmail.com>
References: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>
	<00cd6609-5782-1d21-4221-5176f498f981@gmail.com>
Message-ID: <OFBA78FB36.C394761D-ONC1257FE1.004E039D-C1257FE1.004E806C@lotus.hawesko.de>

Hi Duncan,

many thanks for your reply.

I did insert die paths to the g++ compiler because I got the message about 
the not existent compiler.

I took the directories for the compiler out again:

C:\R-Project\Rtools\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program 
Files\Python 3.5\Scripts\;C:\Program Files\Python 
3.5\;C:\Python27\;C:\Python27\Scripts, etc. etc.

Calling

install.packages("tibble", type  = "source")


gives this message:

-- cut --
* installing *source* package 'tibble' ...
** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
** libs

*** arch - i386
c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG 
-I"C:/R-Project/R-3.3.0/library/Rcpp/include" 
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c 
RcppExports.cpp -o RcppExports.o
c:/Rtools/mingw_32/bin/g++: not found
make: *** [RcppExports.o] Error 127
Warnung: Ausf?hrung von Kommando 'make -f 
"C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f 
"C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk" 
SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)' 
SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab 
Status 2
ERROR: compilation failed for package 'tibble'
* removing 'C:/R-Project/R-3.3.0/library/tibble'
* restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
Warning in install.packages :
  running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l 
"C:\R-Project\R-3.3.0\library" 
C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\RtmpGqOlOW/downloaded_packages/tibble_1.0.tar.gz' 
had status 1
Warning in install.packages :
  installation of package ?tibble? had non-zero exit status
-- cut --

What else could I do?

Kind regards

Georg





Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
An:     G.Maubach at weinwolf.de, r-help at r-project.org, 
Datum:  29.06.2016 13:07
Betreff:        Re: [R] Installing from source on Windows 7: tibble



On 29/06/2016 5:49 AM, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I would like to install R packages from source on Windows 7 64-Bit.
> Currently my settings are:
>
> -- cut --
>> sessionInfo()
> R version 3.3.0 (2016-05-03)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.0
> -- cut --
>
> The environment variable PATH on Windows 7 is set to:
>
> 
C:\R-Project\Rtools\mingw_32\bin;C:\R-Project\Rtools\mingw_64\bin;C:\R-Project\Rtools\bin;C:\R-Project\Rtools\gcc-4.6.3\bin;C:\Program
> Files\Python 3.5\Scripts\;C:\Program Files\Python
> 3.5\;C:\Python27\;C:\Python27\Scripts; etc. etc.

Take the mingw_32, mingw_64 and gcc-4.6.3 directories off your path. 
They aren't needed; the first two could conceivably be harmful.

>
> RTools is installed in C:\R-Project\RTools
>
> The call of
>
> C:\R-Project\Rtools\mingw_64\bin\g++.exe --version
>
> results in
>
> g++ (x86_64-posix-seh, Built by MinGW-W64 project) 4.9.3
>
> If I do
>
>
>> install.packages("tibble", type = "source")
>
> I get
>
> -- cut --
> trying URL 'https://cran.uni-muenster.de/src/contrib/tibble_1.0.tar.gz'
> Content type 'application/x-gzip' length 38038 bytes (37 KB)
> downloaded 37 KB
>
> * installing *source* package 'tibble' ...
> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> ** libs
>
> *** arch - i386
> c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 
-c
> RcppExports.cpp -o RcppExports.o
> c:/Rtools/mingw_32/bin/g++: not found
> make: *** [RcppExports.o] Error 127
> Warnung: Ausf?hrung von Kommando 'make -f
> "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> Status 2
> ERROR: compilation failed for package 'tibble'
> * removing 'C:/R-Project/R-3.3.0/library/tibble'
> * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> Warning in install.packages :
>   running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> "C:\R-Project\R-3.3.0\library"
> 
C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\Rtmp23SQxM/downloaded_packages/tibble_1.0.tar.gz'
> had status 1
> Warning in install.packages :
>   installation of package ?tibble? had non-zero exit status
> -- cut --
>
> There is no make.conf in "C:\R-Project\Rtools\mingw_64\etc". I found "
> Makeconf" in "C:\R-Project\R-3.3.0\etc\x64". Do I need it? How do I need
> to configure the settings in this file?

Yes, since you haven't installed Rtools in the default location, you 
should edit two Makeconf files.  In 
C:\R-Project\R-3.3.0\etc\x64\Makeconf, you want

BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_64/bin/

and in C:\R-Project\R-3.3.0\etc\i386\Makeconf you want

BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_32/bin/

You need to make sure you don't have an environment variable named 
BINPREF defined, or it will override these settings.  (If you were 
building just one architecture, you could do the setting by environment 
variable, but not if you are trying to build both archs in one call.)

Duncan Murdoch

>
> I searched old aunt Google but did not understand what to do and how to
> configure R environment variables correctly.
>
> What do I need to do to install packages from source?
>
> Kind regards
>
> Georg
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>




From murdoch.duncan at gmail.com  Wed Jun 29 16:22:05 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Jun 2016 10:22:05 -0400
Subject: [R] Antwort: Re:  Installing from source on Windows 7: tibble
In-Reply-To: <OFBA78FB36.C394761D-ONC1257FE1.004E039D-C1257FE1.004E806C@lotus.hawesko.de>
References: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>
	<00cd6609-5782-1d21-4221-5176f498f981@gmail.com>
	<OFBA78FB36.C394761D-ONC1257FE1.004E039D-C1257FE1.004E806C@lotus.hawesko.de>
Message-ID: <efbcf687-38d8-f35e-b1bf-949ff0487789@gmail.com>

On 29/06/2016 10:17 AM, G.Maubach at weinwolf.de wrote:
> Hi Duncan,
>
> many thanks for your reply.
>
> I did insert die paths to the g++ compiler because I got the message about
> the not existent compiler.
>
> I took the directories for the compiler out again:
>
> C:\R-Project\Rtools\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program
> Files\Python 3.5\Scripts\;C:\Program Files\Python
> 3.5\;C:\Python27\;C:\Python27\Scripts, etc. etc.
>
> Calling
>
> install.packages("tibble", type  = "source")
>
>
> gives this message:
>
> -- cut --
> * installing *source* package 'tibble' ...
> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> ** libs
>
> *** arch - i386
> c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c
> RcppExports.cpp -o RcppExports.o
> c:/Rtools/mingw_32/bin/g++: not found
> make: *** [RcppExports.o] Error 127
> Warnung: Ausf?hrung von Kommando 'make -f
> "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> Status 2
> ERROR: compilation failed for package 'tibble'
> * removing 'C:/R-Project/R-3.3.0/library/tibble'
> * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> Warning in install.packages :
>    running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> "C:\R-Project\R-3.3.0\library"
> C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\RtmpGqOlOW/downloaded_packages/tibble_1.0.tar.gz'
> had status 1
> Warning in install.packages :
>    installation of package ?tibble? had non-zero exit status
> -- cut --
>
> What else could I do?

You seem to have missed the second part of my advice, describing what to 
do with the two Makeconf files.

Duncan Murdoch

>
> Kind regards
>
> Georg
>
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:  29.06.2016 13:07
> Betreff:        Re: [R] Installing from source on Windows 7: tibble
>
>
>
> On 29/06/2016 5:49 AM, G.Maubach at weinwolf.de wrote:
> > Hi All,
> >
> > I would like to install R packages from source on Windows 7 64-Bit.
> > Currently my settings are:
> >
> > -- cut --
> >> sessionInfo()
> > R version 3.3.0 (2016-05-03)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> > [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> > [5] LC_TIME=German_Germany.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.3.0
> > -- cut --
> >
> > The environment variable PATH on Windows 7 is set to:
> >
> >
> C:\R-Project\Rtools\mingw_32\bin;C:\R-Project\Rtools\mingw_64\bin;C:\R-Project\Rtools\bin;C:\R-Project\Rtools\gcc-4.6.3\bin;C:\Program
> > Files\Python 3.5\Scripts\;C:\Program Files\Python
> > 3.5\;C:\Python27\;C:\Python27\Scripts; etc. etc.
>
> Take the mingw_32, mingw_64 and gcc-4.6.3 directories off your path.
> They aren't needed; the first two could conceivably be harmful.
>
> >
> > RTools is installed in C:\R-Project\RTools
> >
> > The call of
> >
> > C:\R-Project\Rtools\mingw_64\bin\g++.exe --version
> >
> > results in
> >
> > g++ (x86_64-posix-seh, Built by MinGW-W64 project) 4.9.3
> >
> > If I do
> >
> >
> >> install.packages("tibble", type = "source")
> >
> > I get
> >
> > -- cut --
> > trying URL 'https://cran.uni-muenster.de/src/contrib/tibble_1.0.tar.gz'
> > Content type 'application/x-gzip' length 38038 bytes (37 KB)
> > downloaded 37 KB
> >
> > * installing *source* package 'tibble' ...
> > ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> > ** libs
> >
> > *** arch - i386
> > c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> > -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> > -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c
> > RcppExports.cpp -o RcppExports.o
> > c:/Rtools/mingw_32/bin/g++: not found
> > make: *** [RcppExports.o] Error 127
> > Warnung: Ausf?hrung von Kommando 'make -f
> > "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> > "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> > SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> > SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> > Status 2
> > ERROR: compilation failed for package 'tibble'
> > * removing 'C:/R-Project/R-3.3.0/library/tibble'
> > * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> > Warning in install.packages :
> >   running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> > "C:\R-Project\R-3.3.0\library"
> >
> C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\Rtmp23SQxM/downloaded_packages/tibble_1.0.tar.gz'
> > had status 1
> > Warning in install.packages :
> >   installation of package ?tibble? had non-zero exit status
> > -- cut --
> >
> > There is no make.conf in "C:\R-Project\Rtools\mingw_64\etc". I found "
> > Makeconf" in "C:\R-Project\R-3.3.0\etc\x64". Do I need it? How do I need
> > to configure the settings in this file?
>
> Yes, since you haven't installed Rtools in the default location, you
> should edit two Makeconf files.  In
> C:\R-Project\R-3.3.0\etc\x64\Makeconf, you want
>
> BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_64/bin/
>
> and in C:\R-Project\R-3.3.0\etc\i386\Makeconf you want
>
> BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_32/bin/
>
> You need to make sure you don't have an environment variable named
> BINPREF defined, or it will override these settings.  (If you were
> building just one architecture, you could do the setting by environment
> variable, but not if you are trying to build both archs in one call.)
>
> Duncan Murdoch
>
> >
> > I searched old aunt Google but did not understand what to do and how to
> > configure R environment variables correctly.
> >
> > What do I need to do to install packages from source?
> >
> > Kind regards
> >
> > Georg
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>


From ivan.calandra at univ-reims.fr  Wed Jun 29 16:22:38 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 29 Jun 2016 16:22:38 +0200
Subject: [R] [FORGED] Splitting data.frame into a list of small
 data.frames given indices
In-Reply-To: <CAAjnpdj7_ZfEiALuzubipA1XZOA+5P+fg1273VxVd=iCM1dzGQ@mail.gmail.com>
References: <CAAjnpdispjvZL_hBzR-vFLqdh-JPW1p67vUmN5AEar5j7cSY1g@mail.gmail.com>
	<545dedd7-2bdb-2fbd-651d-bc6bd43f8df6@auckland.ac.nz>
	<CAAjnpdiSMpPC+87LBXdu2fxRQx2dzWo9cDezJGa8zpwqdo5xuw@mail.gmail.com>
	<15947bbd-32dc-bbd5-41be-7c22f4a342d1@univ-reims.fr>
	<CAAjnpdj7_ZfEiALuzubipA1XZOA+5P+fg1273VxVd=iCM1dzGQ@mail.gmail.com>
Message-ID: <fa3876ae-392d-5049-9fb6-54ec56703ddf@univ-reims.fr>

Your answer did not make it to the list...

Le 29/06/2016 ? 16:06, Witold E Wolski a ?crit :
> If you do not understand than why do you reply?
>
>
> On 29 June 2016 at 15:54, Ivan Calandra <ivan.calandra at univ-reims.fr> wrote:
>> Hi,
>>
>> I don't really understand why you split every row... This makes it very
>> slow. Try with a more realistic example (with a factor to split).
>>
>> Ivan
>>
>> --
>> Ivan Calandra, PhD
>> Scientific Mediator
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> --
>> https://www.researchgate.net/profile/Ivan_Calandra
>> https://publons.com/author/705639/
>>
>>
>> Le 29/06/2016 ? 15:21, Witold E Wolski a ?crit :
>>> Hi,
>>>
>>> Here is an complete example which shows the the complexity of split or
>>> by is O(n^2)
>>>
>>> nrows <- c(1e3,5e3, 1e4 ,5e4, 1e5 ,2e5)
>>> res<-list()
>>>
>>> for(i in nrows){
>>>     dum <- data.frame(x = runif(i,1,1000), y=runif(i,1,1000))
>>>     res[[length(res)+1]]<-(system.time(x<- split(dum, 1:nrow(dum))))
>>> }
>>> res <- do.call("rbind",res)
>>> plot(nrows^2, res[,"elapsed"])
>>>
>>> And I can't see a reason why this has to be so slow.
>>>
>>>
>>> cheers
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> On 29 June 2016 at 12:00, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>> On 29/06/16 21:16, Witold E Wolski wrote:
>>>>> It's the inverse problem to merging a list of data.frames into a large
>>>>> data.frame just discussed in the "performance of do.call("rbind")"
>>>>> thread
>>>>>
>>>>> I would like to split a data.frame into a list of data.frames
>>>>> according to first column.
>>>>> This SEEMS to be easily possible with the function base::by. However,
>>>>> as soon as the data.frame has a few million rows this function CAN NOT
>>>>> BE USED (except you have A PLENTY OF TIME).
>>>>>
>>>>> for 'by' runtime ~ nrow^2, or formally O(n^2)  (see benchmark below).
>>>>>
>>>>> So basically I am looking for a similar function with better complexity.
>>>>>
>>>>>
>>>>>    > nrows <- c(1e5,1e6,2e6,3e6,5e6)
>>>>>> timing <- list()
>>>>>> for(i in nrows){
>>>>> + dum <- peaks[1:i,]
>>>>> + timing[[length(timing)+1]] <- system.time(x<- by(dum[,2:3],
>>>>> INDICES=list(dum[,1]), FUN=function(x){x}, simplify = FALSE))
>>>>> + }
>>>>>> names(timing)<- nrows
>>>>>> timing
>>>>> $`1e+05`
>>>>>      user  system elapsed
>>>>>      0.05    0.00    0.05
>>>>>
>>>>> $`1e+06`
>>>>>      user  system elapsed
>>>>>      1.48    2.98    4.46
>>>>>
>>>>> $`2e+06`
>>>>>      user  system elapsed
>>>>>      7.25   11.39   18.65
>>>>>
>>>>> $`3e+06`
>>>>>      user  system elapsed
>>>>>     16.15   25.81   41.99
>>>>>
>>>>> $`5e+06`
>>>>>      user  system elapsed
>>>>>     43.22   74.72  118.09
>>>>
>>>> I'm not sure that I follow what you're doing, and your example is not
>>>> reproducible, since we have no idea what "peaks" is, but on a toy example
>>>> with 5e6 rows in the data frame I got a timing result of
>>>>
>>>>      user  system elapsed
>>>>     0.379 0.025 0.406
>>>>
>>>> when I applied split().  Is this adequately fast? Seems to me that if you
>>>> want to split something, split() would be a good place to start.
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>> --
>>>> Technical Editor ANZJS
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From G.Maubach at weinwolf.de  Wed Jun 29 16:48:31 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 29 Jun 2016 16:48:31 +0200
Subject: [R] Antwort: Re: Antwort: Re: Installing from source on Windows 7:
	tibble [SOLVED]
In-Reply-To: <efbcf687-38d8-f35e-b1bf-949ff0487789@gmail.com>
References: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>
	<00cd6609-5782-1d21-4221-5176f498f981@gmail.com>
	<OFBA78FB36.C394761D-ONC1257FE1.004E039D-C1257FE1.004E806C@lotus.hawesko.de>
	<efbcf687-38d8-f35e-b1bf-949ff0487789@gmail.com>
Message-ID: <OF2A7ED79C.5360EFE0-ONC1257FE1.0050BCE4-C1257FE1.00516286@lotus.hawesko.de>

Hi Duncan,

indeed, I did not see the other part of your message.

I did

BINPREF ?= C:/R-Project/Rtools/mingw_32/bin/
COMPILED_BY = g++ # instead of gcc-4.9.3

in "C:\R-Project\R-3.3.0\etc\i386\Makeconf"

and

BINPREF ?= C:/R-Project/Rtools/mingw_64/bin/
COMPILED_BY = g++ # instead of gcc-4.9.3

in "C:\R-Project\R-3.3.0\etc\x64\Makeconf"

Now I could compile the package with no futher errors.

Messages are

-- cut --
* installing *source* package 'tibble' ...
** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
** libs

*** arch - i386
C:/R-Project/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" 
-DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include" 
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c 
RcppExports.cpp -o RcppExports.o
C:/R-Project/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" 
-DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include" 
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c 
matrixToDataFrame.cpp -o matrixToDataFrame.o
C:/R-Project/Rtools/mingw_32/bin/g++ -shared -s -static-libgcc -o 
tibble.dll tmp.def RcppExports.o matrixToDataFrame.o 
-Ld:/Compiler/gcc-4.9.3/local330/lib/i386 
-Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/R-PROJ~1/R-33~1.0/bin/i386 -lR
installing to C:/R-Project/R-3.3.0/library/tibble/libs/i386

*** arch - x64
C:/R-Project/Rtools/mingw_64/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" 
-DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include" 
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c 
RcppExports.cpp -o RcppExports.o
C:/R-Project/Rtools/mingw_64/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" 
-DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include" 
-I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c 
matrixToDataFrame.cpp -o matrixToDataFrame.o
C:/R-Project/Rtools/mingw_64/bin/g++ -shared -s -static-libgcc -o 
tibble.dll tmp.def RcppExports.o matrixToDataFrame.o 
-Ld:/Compiler/gcc-4.9.3/local330/lib/x64 
-Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/R-PROJ~1/R-33~1.0/bin/x64 -lR
installing to C:/R-Project/R-3.3.0/library/tibble/libs/x64
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
*** arch - i386
*** arch - x64
* DONE (tibble)
-- cut --

So - complete success.

Many thanks for your help.

One last questions: Why did Rtools.exe not create a directory named 
"gcc-4.9.3" in "C:\R-Project\Rtools" and putting "
C:\R-Project\Rtools\mingw_32" and "C:\R-Project\Rtools\mingw_64" directly 
in "C:\R-Project\Rtools\"? gcc-4.6.3 was installed that way.

Kind regards

Georg





Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help at r-project.org
Datum:  29.06.2016 16:21
Betreff:        Re: Antwort: Re: [R] Installing from source on Windows 7: 
tibble



On 29/06/2016 10:17 AM, G.Maubach at weinwolf.de wrote:
> Hi Duncan,
>
> many thanks for your reply.
>
> I did insert die paths to the g++ compiler because I got the message 
about
> the not existent compiler.
>
> I took the directories for the compiler out again:
>
> C:\R-Project\Rtools\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program
> Files\Python 3.5\Scripts\;C:\Program Files\Python
> 3.5\;C:\Python27\;C:\Python27\Scripts, etc. etc.
>
> Calling
>
> install.packages("tibble", type  = "source")
>
>
> gives this message:
>
> -- cut --
> * installing *source* package 'tibble' ...
> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> ** libs
>
> *** arch - i386
> c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 
-c
> RcppExports.cpp -o RcppExports.o
> c:/Rtools/mingw_32/bin/g++: not found
> make: *** [RcppExports.o] Error 127
> Warnung: Ausf?hrung von Kommando 'make -f
> "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> Status 2
> ERROR: compilation failed for package 'tibble'
> * removing 'C:/R-Project/R-3.3.0/library/tibble'
> * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> Warning in install.packages :
>    running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> "C:\R-Project\R-3.3.0\library"
> 
C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\RtmpGqOlOW/downloaded_packages/tibble_1.0.tar.gz'
> had status 1
> Warning in install.packages :
>    installation of package ?tibble? had non-zero exit status
> -- cut --
>
> What else could I do?

You seem to have missed the second part of my advice, describing what to 
do with the two Makeconf files.

Duncan Murdoch

>
> Kind regards
>
> Georg
>
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:  29.06.2016 13:07
> Betreff:        Re: [R] Installing from source on Windows 7: tibble
>
>
>
> On 29/06/2016 5:49 AM, G.Maubach at weinwolf.de wrote:
> > Hi All,
> >
> > I would like to install R packages from source on Windows 7 64-Bit.
> > Currently my settings are:
> >
> > -- cut --
> >> sessionInfo()
> > R version 3.3.0 (2016-05-03)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> > [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> > [5] LC_TIME=German_Germany.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.3.0
> > -- cut --
> >
> > The environment variable PATH on Windows 7 is set to:
> >
> >
> 
C:\R-Project\Rtools\mingw_32\bin;C:\R-Project\Rtools\mingw_64\bin;C:\R-Project\Rtools\bin;C:\R-Project\Rtools\gcc-4.6.3\bin;C:\Program
> > Files\Python 3.5\Scripts\;C:\Program Files\Python
> > 3.5\;C:\Python27\;C:\Python27\Scripts; etc. etc.
>
> Take the mingw_32, mingw_64 and gcc-4.6.3 directories off your path.
> They aren't needed; the first two could conceivably be harmful.
>
> >
> > RTools is installed in C:\R-Project\RTools
> >
> > The call of
> >
> > C:\R-Project\Rtools\mingw_64\bin\g++.exe --version
> >
> > results in
> >
> > g++ (x86_64-posix-seh, Built by MinGW-W64 project) 4.9.3
> >
> > If I do
> >
> >
> >> install.packages("tibble", type = "source")
> >
> > I get
> >
> > -- cut --
> > trying URL 
'https://cran.uni-muenster.de/src/contrib/tibble_1.0.tar.gz'
> > Content type 'application/x-gzip' length 38038 bytes (37 KB)
> > downloaded 37 KB
> >
> > * installing *source* package 'tibble' ...
> > ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> > ** libs
> >
> > *** arch - i386
> > c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> > -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> > -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c
> > RcppExports.cpp -o RcppExports.o
> > c:/Rtools/mingw_32/bin/g++: not found
> > make: *** [RcppExports.o] Error 127
> > Warnung: Ausf?hrung von Kommando 'make -f
> > "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> > "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> > SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> > SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> > Status 2
> > ERROR: compilation failed for package 'tibble'
> > * removing 'C:/R-Project/R-3.3.0/library/tibble'
> > * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> > Warning in install.packages :
> >   running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> > "C:\R-Project\R-3.3.0\library"
> >
> 
C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\Rtmp23SQxM/downloaded_packages/tibble_1.0.tar.gz'
> > had status 1
> > Warning in install.packages :
> >   installation of package ?tibble? had non-zero exit status
> > -- cut --
> >
> > There is no make.conf in "C:\R-Project\Rtools\mingw_64\etc". I found "
> > Makeconf" in "C:\R-Project\R-3.3.0\etc\x64". Do I need it? How do I 
need
> > to configure the settings in this file?
>
> Yes, since you haven't installed Rtools in the default location, you
> should edit two Makeconf files.  In
> C:\R-Project\R-3.3.0\etc\x64\Makeconf, you want
>
> BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_64/bin/
>
> and in C:\R-Project\R-3.3.0\etc\i386\Makeconf you want
>
> BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_32/bin/
>
> You need to make sure you don't have an environment variable named
> BINPREF defined, or it will override these settings.  (If you were
> building just one architecture, you could do the setting by environment
> variable, but not if you are trying to build both archs in one call.)
>
> Duncan Murdoch
>
> >
> > I searched old aunt Google but did not understand what to do and how 
to
> > configure R environment variables correctly.
> >
> > What do I need to do to install packages from source?
> >
> > Kind regards
> >
> > Georg
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>




From bgunter.4567 at gmail.com  Wed Jun 29 16:57:20 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 29 Jun 2016 07:57:20 -0700
Subject: [R] > Understanding strip.default & strip.custom
In-Reply-To: <20160629082930.GA16087@slingshot.co.nz>
References: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>
	<CAGxFJbTVAG7kEv6eLLAu2eVn-2QJgVMrBF_SSSE4=hMKKmCTWA@mail.gmail.com>
	<20160629082930.GA16087@slingshot.co.nz>
Message-ID: <CAGxFJbQ88+Ok9z1WdRBxLv5Mmj2Bu3AA8pH_aAa18=Uc7e9=+g@mail.gmail.com>

Did you mean: strip.custom(factor.levels...)  ?

(I know of no "panel.custom()" function)


-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 29, 2016 at 1:29 AM, Patrick Connolly
<p_connolly at slingshot.co.nz> wrote:
> On Mon, 27-Jun-2016 at 10:17PM -0700, Bert Gunter wrote:
>
> [...]
>
> |>
> |> You seem to be making this way more difficult than you should.
>
> Though I didn't get any closer to an understanding of which.panel, the
> question I asked was simply answered by
>
> panel.custom(factor.levels = <as before>)
>
> Thanks to Duncan Mackay also.
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From bgunter.4567 at gmail.com  Wed Jun 29 17:13:40 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 29 Jun 2016 08:13:40 -0700
Subject: [R] Understanding and predict round-off errors sign on simple
	functions
In-Reply-To: <002e01d1d1ec$70c99080$525cb180$@laposte.net>
References: <002e01d1d1ec$70c99080$525cb180$@laposte.net>
Message-ID: <CAGxFJbRoPRFtBLXu+_uvW6MjPRCd-W1o2n3vNKhJwbWS+TBqVg@mail.gmail.com>

I am certainly no expert, but I would assume that:

1. Roundoff errors depend on the exact numerical libraries and
versions that are used, and so general language comparisons are
impossible without that information;

2. Roundoff errors depend on the exact calculations being done and
machine precision and are very complicated to determine

So I would say the answer to your questions is no.

But you should probably address such a question to a numerical analyst
for an authoritative answer. Maybe try stats.stackexchange.com  .

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 29, 2016 at 2:55 AM, Sirhc via R-help <r-help at r-project.org> wrote:
> Hi,
>
>
>
> May be it is a basic thing but I would like to know if we can anticipate
> round-off errors sign.
>
>
>
> Here is an example :
>
>
>
> # numerical matrix
>
> m <- matrix(data=cbind(rnorm(10, 0), rnorm(10, 2), rnorm(10, 5)), nrow=10,
> ncol=3)
>
>
>
>> m
>
>             [,1]      [,2]     [,3]
>
> [1,]  0.4816247 1.1973502 3.855641
>
> [2,] -1.2174937 0.7356427 4.393279
>
> [3,]  0.8504074 2.5286509 2.689196
>
> [4,]  1.8048642 1.8580804 6.665237
>
> [5,] -0.6749397 1.0944277 4.838608
>
> [6,]  0.8252034 1.5595268 3.681695
>
> [7,]  1.3002208 0.9582693 4.561577
>
> [8,]  1.6950923 3.5677921 6.005078
>
> [9,]  0.6509285 0.9025964 5.082288
>
> [10,] -0.5676040 1.3281102 4.446451
>
>
>
> #weird moving average of period 1 !
>
> mma <- apply(m, 2, SMA, n=1)
>
>
>
>> mma
>
>             [,1]      [,2]     [,3]
>
> [1,]         NA        NA       NA
>
> [2,] -1.2174937 0.7356427 4.393279
>
> [3,]  0.8504074 2.5286509 2.689196
>
> [4,]  1.8048642 1.8580804 6.665237
>
> [5,] -0.6749397 1.0944277 4.838608
>
> [6,]  0.8252034 1.5595268 3.681695
>
> [7,]  1.3002208 0.9582693 4.561577
>
> [8,]  1.6950923 3.5677921 6.005078
>
> [9,]  0.6509285 0.9025964 5.082288
>
> [10,] -0.5676040 1.3281102 4.446451
>
>
>
>
>
> #difference should be 0 but here is the result
>
>> m - mma
>
>                [,1]         [,2]          [,3]
>
> [1,]            NA           NA            NA
>
> [2,]  0.000000e+00 0.000000e+00 -8.881784e-16
>
> [3,]  0.000000e+00 0.000000e+00 -8.881784e-16
>
> [4,]  0.000000e+00 4.440892e-16 -8.881784e-16
>
> [5,] -1.110223e-16 4.440892e-16 -8.881784e-16
>
> [6,] -1.110223e-16 2.220446e-16 -4.440892e-16
>
> [7,] -2.220446e-16 2.220446e-16  0.000000e+00
>
> [8,] -2.220446e-16 0.000000e+00  0.000000e+00
>
> [9,] -3.330669e-16 2.220446e-16 -8.881784e-16
>
> [10,] -3.330669e-16 4.440892e-16 -8.881784e-16
>
>
>
> SMA function use runMean
>
> # TTR / R / MovingAverages.R
>
> "SMA" <- function(x, n=10, ...) { # Simple Moving Average
>
>    ma <- runMean( x, n )
>
>    if(!is.null(dim(ma))) {
>
>      colnames(ma) <- "SMA"
>
>    }
>
>   return(ma)
>
> }
>
>
>
>
>
> Can anyone explain me that round error type?
>
> Is it possible to reproduce this same error generation in another language
> like C++ or C# ?
>
>
>
> Thanks in advance for your answers
>
>
>
> Regards
>
>
>
> Chris
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Jun 29 17:34:44 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Jun 2016 11:34:44 -0400
Subject: [R] Antwort: Re: Antwort: Re: Installing from source on Windows
 7: tibble [SOLVED]
In-Reply-To: <OF2A7ED79C.5360EFE0-ONC1257FE1.0050BCE4-C1257FE1.00516286@lotus.hawesko.de>
References: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>
	<00cd6609-5782-1d21-4221-5176f498f981@gmail.com>
	<OFBA78FB36.C394761D-ONC1257FE1.004E039D-C1257FE1.004E806C@lotus.hawesko.de>
	<efbcf687-38d8-f35e-b1bf-949ff0487789@gmail.com>
	<OF2A7ED79C.5360EFE0-ONC1257FE1.0050BCE4-C1257FE1.00516286@lotus.hawesko.de>
Message-ID: <39e820dd-635d-e9d6-4ad3-444438dfb657@gmail.com>

On 29/06/2016 10:48 AM, G.Maubach at weinwolf.de wrote:
> Hi Duncan,
>
> indeed, I did not see the other part of your message.
>
> I did
>
> BINPREF ?= C:/R-Project/Rtools/mingw_32/bin/
> COMPILED_BY = g++ # instead of gcc-4.9.3

I wouldn't change the COMPILED_BY; some packages use it to configure 
themselves for gcc-4.9.3, as opposed to the previous version gcc-4.6.3.

>
> in "C:\R-Project\R-3.3.0\etc\i386\Makeconf"
>
> and
>
> BINPREF ?= C:/R-Project/Rtools/mingw_64/bin/
> COMPILED_BY = g++ # instead of gcc-4.9.3
>
> in "C:\R-Project\R-3.3.0\etc\x64\Makeconf"
>
> Now I could compile the package with no futher errors.
>
> Messages are
>
> -- cut --
> * installing *source* package 'tibble' ...
> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> ** libs
>
> *** arch - i386
> C:/R-Project/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c
> RcppExports.cpp -o RcppExports.o
> C:/R-Project/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c
> matrixToDataFrame.cpp -o matrixToDataFrame.o
> C:/R-Project/Rtools/mingw_32/bin/g++ -shared -s -static-libgcc -o
> tibble.dll tmp.def RcppExports.o matrixToDataFrame.o
> -Ld:/Compiler/gcc-4.9.3/local330/lib/i386
> -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/R-PROJ~1/R-33~1.0/bin/i386 -lR
> installing to C:/R-Project/R-3.3.0/library/tibble/libs/i386
>
> *** arch - x64
> C:/R-Project/Rtools/mingw_64/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c
> RcppExports.cpp -o RcppExports.o
> C:/R-Project/Rtools/mingw_64/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 -c
> matrixToDataFrame.cpp -o matrixToDataFrame.o
> C:/R-Project/Rtools/mingw_64/bin/g++ -shared -s -static-libgcc -o
> tibble.dll tmp.def RcppExports.o matrixToDataFrame.o
> -Ld:/Compiler/gcc-4.9.3/local330/lib/x64
> -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/R-PROJ~1/R-33~1.0/bin/x64 -lR
> installing to C:/R-Project/R-3.3.0/library/tibble/libs/x64
> ** R
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> *** arch - i386
> *** arch - x64
> * DONE (tibble)
> -- cut --
>
> So - complete success.
>
> Many thanks for your help.
>
> One last questions: Why did Rtools.exe not create a directory named
> "gcc-4.9.3" in "C:\R-Project\Rtools" and putting"
> C:\R-Project\Rtools\mingw_32" and "C:\R-Project\Rtools\mingw_64" directly
> in "C:\R-Project\Rtools\"? gcc-4.6.3 was installed that way.

The 4.6.3 compiler was compiled for "multilib" operation:  the same 
compiler took command line options to distinguish between 32 bit and 64 
bit compiles.  The newer version doesn't support that, so we need two 
separate installs.

Duncan Murdoch

> Kind regards
>
> Georg
>
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help at r-project.org
> Datum:  29.06.2016 16:21
> Betreff:        Re: Antwort: Re: [R] Installing from source on Windows 7:
> tibble
>
>
>
> On 29/06/2016 10:17 AM, G.Maubach at weinwolf.de wrote:
> > Hi Duncan,
> >
> > many thanks for your reply.
> >
> > I did insert die paths to the g++ compiler because I got the message
> about
> > the not existent compiler.
> >
> > I took the directories for the compiler out again:
> >
> > C:\R-Project\Rtools\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program
> > Files\Python 3.5\Scripts\;C:\Program Files\Python
> > 3.5\;C:\Python27\;C:\Python27\Scripts, etc. etc.
> >
> > Calling
> >
> > install.packages("tibble", type  = "source")
> >
> >
> > gives this message:
> >
> > -- cut --
> > * installing *source* package 'tibble' ...
> > ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> > ** libs
> >
> > *** arch - i386
> > c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> > -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> > -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c
> > RcppExports.cpp -o RcppExports.o
> > c:/Rtools/mingw_32/bin/g++: not found
> > make: *** [RcppExports.o] Error 127
> > Warnung: Ausf?hrung von Kommando 'make -f
> > "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> > "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> > SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> > SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> > Status 2
> > ERROR: compilation failed for package 'tibble'
> > * removing 'C:/R-Project/R-3.3.0/library/tibble'
> > * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> > Warning in install.packages :
> >    running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> > "C:\R-Project\R-3.3.0\library"
> >
> C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\RtmpGqOlOW/downloaded_packages/tibble_1.0.tar.gz'
> > had status 1
> > Warning in install.packages :
> >    installation of package ?tibble? had non-zero exit status
> > -- cut --
> >
> > What else could I do?
>
> You seem to have missed the second part of my advice, describing what to
> do with the two Makeconf files.
>
> Duncan Murdoch
>
> >
> > Kind regards
> >
> > Georg
> >
> >
> >
> >
> >
> > Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> > An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> > Datum:  29.06.2016 13:07
> > Betreff:        Re: [R] Installing from source on Windows 7: tibble
> >
> >
> >
> > On 29/06/2016 5:49 AM, G.Maubach at weinwolf.de wrote:
> > > Hi All,
> > >
> > > I would like to install R packages from source on Windows 7 64-Bit.
> > > Currently my settings are:
> > >
> > > -- cut --
> > >> sessionInfo()
> > > R version 3.3.0 (2016-05-03)
> > > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > > Running under: Windows 7 x64 (build 7601) Service Pack 1
> > >
> > > locale:
> > > [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> > > [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> > > [5] LC_TIME=German_Germany.1252
> > >
> > > attached base packages:
> > > [1] stats     graphics  grDevices utils     datasets  methods   base
> > >
> > > loaded via a namespace (and not attached):
> > > [1] tools_3.3.0
> > > -- cut --
> > >
> > > The environment variable PATH on Windows 7 is set to:
> > >
> > >
> >
> C:\R-Project\Rtools\mingw_32\bin;C:\R-Project\Rtools\mingw_64\bin;C:\R-Project\Rtools\bin;C:\R-Project\Rtools\gcc-4.6.3\bin;C:\Program
> > > Files\Python 3.5\Scripts\;C:\Program Files\Python
> > > 3.5\;C:\Python27\;C:\Python27\Scripts; etc. etc.
> >
> > Take the mingw_32, mingw_64 and gcc-4.6.3 directories off your path.
> > They aren't needed; the first two could conceivably be harmful.
> >
> > >
> > > RTools is installed in C:\R-Project\RTools
> > >
> > > The call of
> > >
> > > C:\R-Project\Rtools\mingw_64\bin\g++.exe --version
> > >
> > > results in
> > >
> > > g++ (x86_64-posix-seh, Built by MinGW-W64 project) 4.9.3
> > >
> > > If I do
> > >
> > >
> > >> install.packages("tibble", type = "source")
> > >
> > > I get
> > >
> > > -- cut --
> > > trying URL
> 'https://cran.uni-muenster.de/src/contrib/tibble_1.0.tar.gz'
> > > Content type 'application/x-gzip' length 38038 bytes (37 KB)
> > > downloaded 37 KB
> > >
> > > * installing *source* package 'tibble' ...
> > > ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> > > ** libs
> > >
> > > *** arch - i386
> > > c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> > > -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> > > -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> > -c
> > > RcppExports.cpp -o RcppExports.o
> > > c:/Rtools/mingw_32/bin/g++: not found
> > > make: *** [RcppExports.o] Error 127
> > > Warnung: Ausf?hrung von Kommando 'make -f
> > > "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> > > "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> > > SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> > > SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> > > Status 2
> > > ERROR: compilation failed for package 'tibble'
> > > * removing 'C:/R-Project/R-3.3.0/library/tibble'
> > > * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> > > Warning in install.packages :
> > >   running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> > > "C:\R-Project\R-3.3.0\library"
> > >
> >
> C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\Rtmp23SQxM/downloaded_packages/tibble_1.0.tar.gz'
> > > had status 1
> > > Warning in install.packages :
> > >   installation of package ?tibble? had non-zero exit status
> > > -- cut --
> > >
> > > There is no make.conf in "C:\R-Project\Rtools\mingw_64\etc". I found "
> > > Makeconf" in "C:\R-Project\R-3.3.0\etc\x64". Do I need it? How do I
> need
> > > to configure the settings in this file?
> >
> > Yes, since you haven't installed Rtools in the default location, you
> > should edit two Makeconf files.  In
> > C:\R-Project\R-3.3.0\etc\x64\Makeconf, you want
> >
> > BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_64/bin/
> >
> > and in C:\R-Project\R-3.3.0\etc\i386\Makeconf you want
> >
> > BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_32/bin/
> >
> > You need to make sure you don't have an environment variable named
> > BINPREF defined, or it will override these settings.  (If you were
> > building just one architecture, you could do the setting by environment
> > variable, but not if you are trying to build both archs in one call.)
> >
> > Duncan Murdoch
> >
> > >
> > > I searched old aunt Google but did not understand what to do and how
> to
> > > configure R environment variables correctly.
> > >
> > > What do I need to do to install packages from source?
> > >
> > > Kind regards
> > >
> > > Georg
> > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> >
>
>
>


From jfox at mcmaster.ca  Wed Jun 29 17:56:56 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 29 Jun 2016 15:56:56 +0000
Subject: [R] t-test for regression estimate
In-Reply-To: <b86a1527-ecd3-6749-a137-865482d30136@gmail.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>
	<b86a1527-ecd3-6749-a137-865482d30136@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83653D929@FHSDB2D11-2.csu.mcmaster.ca>

Dear Steven,

OK -- that makes sense, and there was also a previous request for linearHypothesis() to return the value of the hypothesis and its covariance matrix. In your case, where there's only 1 numerator df, that would be the value and estimated sampling variance of the hypothesis.

I've now implemented that, using (at least provisionally) attributes in the development version of the car package on R-Forge, which you should be able to install via install.packages("car", repos="http://R-Forge.R-project.org"). Then see ?linearHypothesis for more information.

Best,
 John

> -----Original Message-----
> From: Steven Yen [mailto:syen04 at gmail.com]
> Sent: June 28, 2016 3:44 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] t-test for regression estimate
> 
> Thanks John. Reason is I am doing linear transformations of many coefficients
> (e.g., bi / scalar). Of course I can uncover the t-statistic from the F statistic and
> then the standard error. Simply scaling the estimated coefficients I can also
> transform the standard errors. I have since found deltaMethod from library
> "car" useful. Its just that, if linearHypothesis had provide the standard errors
> and t-statistics then the operation would have been easier, with a one-line
> command for each coefficient. Thank you again.
> 
> 
> On 6/28/2016 6:28 PM, Fox, John wrote:
> 
> 
> 	Dear Steven,
> 
> 	The reason that linearHypothesis() computes a Wald F or chisquare
> test rather than a t or z test is that the (numerator) df for the linear hypothesis
> need not be 1.
> 
> 	In your case (as has been pointed out) you can get the coefficient
> standard error directly from the model summary.
> 
> 	More generally, with some work, you could solve for the the SE for a 1
> df linear hypothesis in terms of the value of the linear function of coefficients
> and the F or chisquare. That said, I'm not sure why you want to do this.
> 
> 	I hope this helps,
> 	 John
> 
> 	-----------------------------
> 	John Fox, Professor
> 	McMaster University
> 	Hamilton, Ontario
> 	Canada L8S 4M4
> 	Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 		-----Original Message-----
> 		From: R-help [mailto:r-help-bounces at r-project.org] On Behalf
> Of Steven Yen
> 		Sent: June 28, 2016 9:27 AM
> 		To: R-help <r-help at r-project.org> <mailto:r-help at r-
> project.org>
> 		Subject: [R] t-test for regression estimate
> 
> 		test option for linearHypothesis in library(car) include "Chisq"
> and "F". I prefer
> 		a simple t-test so that I can retrieve the standard error.
> 		Any options other than linearHypothesis to test the linear
> hypothesis (with 1
> 		restriction/degree of freedom)?
> 
> 		 > summary(ols1)
> 
> 		Coefficients:
> 		             Estimate Std. Error t value Pr(>|t|)
> 		(Intercept) -0.20013    0.09199  -2.176   0.0298 *
> 		age          0.04054    0.01721   2.355   0.0187 *
> 		suburb       0.01911    0.05838   0.327   0.7435
> 		smcity      -0.29969    0.19175  -1.563   0.1184
> 		---
> 		Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 		 > linearHypothesis(ols1,"suburb")
> 		Linear hypothesis test
> 
> 		Hypothesis:
> 		suburb = 0
> 
> 		Model 1: restricted model
> 		Model 2: polideo ~ age + suburb + smcity
> 
> 		   Res.Df    RSS Df Sum of Sq      F Pr(>F)
> 		1    888 650.10
> 		2    887 650.02  1  0.078534 0.1072 0.7435
> 
> 
> 			[[alternative HTML version deleted]]
> 
> 		______________________________________________
> 		R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list -- To UNSUBSCRIBE and more, see
> 		https://stat.ethz.ch/mailman/listinfo/r-help
> 		PLEASE do read the posting guide http://www.R-
> project.org/posting-
> 		guide.html
> 		and provide commented, minimal, self-contained, reproducible
> code.
> 


From syen04 at gmail.com  Wed Jun 29 18:38:40 2016
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 29 Jun 2016 12:38:40 -0400
Subject: [R] t-test for regression estimate
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC83653D929@FHSDB2D11-2.csu.mcmaster.ca>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>
	<b86a1527-ecd3-6749-a137-865482d30136@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D929@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <a0026322-c6ae-698e-5221-698c3c1e3a8d@gmail.com>

Thanks John. Yes, by using verbose=T, I get the value of the hypothesis. 
But tell me again, how would I get the variance (standard error)?

On 6/29/2016 11:56 AM, Fox, John wrote:
> Dear Steven,
>
> OK -- that makes sense, and there was also a previous request for linearHypothesis() to return the value of the hypothesis and its covariance matrix. In your case, where there's only 1 numerator df, that would be the value and estimated sampling variance of the hypothesis.
>
> I've now implemented that, using (at least provisionally) attributes in the development version of the car package on R-Forge, which you should be able to install via install.packages("car", repos="http://R-Forge.R-project.org"). Then see ?linearHypothesis for more information.
>
> Best,
>   John
>
>> -----Original Message-----
>> From: Steven Yen [mailto:syen04 at gmail.com]
>> Sent: June 28, 2016 3:44 PM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: R-help <r-help at r-project.org>
>> Subject: Re: [R] t-test for regression estimate
>>
>> Thanks John. Reason is I am doing linear transformations of many coefficients
>> (e.g., bi / scalar). Of course I can uncover the t-statistic from the F statistic and
>> then the standard error. Simply scaling the estimated coefficients I can also
>> transform the standard errors. I have since found deltaMethod from library
>> "car" useful. Its just that, if linearHypothesis had provide the standard errors
>> and t-statistics then the operation would have been easier, with a one-line
>> command for each coefficient. Thank you again.
>>
>>
>> On 6/28/2016 6:28 PM, Fox, John wrote:
>>
>>
>> 	Dear Steven,
>>
>> 	The reason that linearHypothesis() computes a Wald F or chisquare
>> test rather than a t or z test is that the (numerator) df for the linear hypothesis
>> need not be 1.
>>
>> 	In your case (as has been pointed out) you can get the coefficient
>> standard error directly from the model summary.
>>
>> 	More generally, with some work, you could solve for the the SE for a 1
>> df linear hypothesis in terms of the value of the linear function of coefficients
>> and the F or chisquare. That said, I'm not sure why you want to do this.
>>
>> 	I hope this helps,
>> 	 John
>>
>> 	-----------------------------
>> 	John Fox, Professor
>> 	McMaster University
>> 	Hamilton, Ontario
>> 	Canada L8S 4M4
>> 	Web: socserv.mcmaster.ca/jfox
>>
>>
>>
>> 		-----Original Message-----
>> 		From: R-help [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Steven Yen
>> 		Sent: June 28, 2016 9:27 AM
>> 		To: R-help <r-help at r-project.org> <mailto:r-help at r-
>> project.org>
>> 		Subject: [R] t-test for regression estimate
>>
>> 		test option for linearHypothesis in library(car) include "Chisq"
>> and "F". I prefer
>> 		a simple t-test so that I can retrieve the standard error.
>> 		Any options other than linearHypothesis to test the linear
>> hypothesis (with 1
>> 		restriction/degree of freedom)?
>>
>> 		 > summary(ols1)
>>
>> 		Coefficients:
>> 		             Estimate Std. Error t value Pr(>|t|)
>> 		(Intercept) -0.20013    0.09199  -2.176   0.0298 *
>> 		age          0.04054    0.01721   2.355   0.0187 *
>> 		suburb       0.01911    0.05838   0.327   0.7435
>> 		smcity      -0.29969    0.19175  -1.563   0.1184
>> 		---
>> 		Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> 		 > linearHypothesis(ols1,"suburb")
>> 		Linear hypothesis test
>>
>> 		Hypothesis:
>> 		suburb = 0
>>
>> 		Model 1: restricted model
>> 		Model 2: polideo ~ age + suburb + smcity
>>
>> 		   Res.Df    RSS Df Sum of Sq      F Pr(>F)
>> 		1    888 650.10
>> 		2    887 650.02  1  0.078534 0.1072 0.7435
>>
>>
>> 			[[alternative HTML version deleted]]
>>
>> 		______________________________________________
>> 		R-help at r-project.org <mailto:R-help at r-project.org>  mailing
>> list -- To UNSUBSCRIBE and more, see
>> 		https://stat.ethz.ch/mailman/listinfo/r-help
>> 		PLEASE do read the posting guide http://www.R-
>> project.org/posting-
>> 		guide.html
>> 		and provide commented, minimal, self-contained, reproducible
>> code.
>>


	[[alternative HTML version deleted]]


From syen04 at gmail.com  Wed Jun 29 18:47:43 2016
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 29 Jun 2016 12:47:43 -0400
Subject: [R] t-test for regression estimate
In-Reply-To: <a0026322-c6ae-698e-5221-698c3c1e3a8d@gmail.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>
	<b86a1527-ecd3-6749-a137-865482d30136@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D929@FHSDB2D11-2.csu.mcmaster.ca>
	<a0026322-c6ae-698e-5221-698c3c1e3a8d@gmail.com>
Message-ID: <3ab097ba-e5f2-4f13-3b63-debb2ddf7216@gmail.com>

Also,
Is there a way to get the second command (hypothesis defined with 
externally scalars) below to work? Thanks.

linearHypothesis(U,"0.5*eq1_DQ+0.3*eq2_DQ",verbose=T)
w1<-0.5; w2<-0.3
linearHypothesis(U,"w1*eq1_DQ+w2*eq2_DQ",verbose=T) # does not work

On 6/29/2016 12:38 PM, Steven Yen wrote:
> Thanks John. Yes, by using verbose=T, I get the value of the 
> hypothesis. But tell me again, how would I get the variance (standard 
> error)?
>
> On 6/29/2016 11:56 AM, Fox, John wrote:
>> Dear Steven,
>>
>> OK -- that makes sense, and there was also a previous request for linearHypothesis() to return the value of the hypothesis and its covariance matrix. In your case, where there's only 1 numerator df, that would be the value and estimated sampling variance of the hypothesis.
>>
>> I've now implemented that, using (at least provisionally) attributes in the development version of the car package on R-Forge, which you should be able to install via install.packages("car", repos="http://R-Forge.R-project.org"). Then see ?linearHypothesis for more information.
>>
>> Best,
>>   John
>>
>>> -----Original Message-----
>>> From: Steven Yen [mailto:syen04 at gmail.com]
>>> Sent: June 28, 2016 3:44 PM
>>> To: Fox, John<jfox at mcmaster.ca>
>>> Cc: R-help<r-help at r-project.org>
>>> Subject: Re: [R] t-test for regression estimate
>>>
>>> Thanks John. Reason is I am doing linear transformations of many coefficients
>>> (e.g., bi / scalar). Of course I can uncover the t-statistic from the F statistic and
>>> then the standard error. Simply scaling the estimated coefficients I can also
>>> transform the standard errors. I have since found deltaMethod from library
>>> "car" useful. Its just that, if linearHypothesis had provide the standard errors
>>> and t-statistics then the operation would have been easier, with a one-line
>>> command for each coefficient. Thank you again.
>>>
>>>
>>> On 6/28/2016 6:28 PM, Fox, John wrote:
>>>
>>>
>>> 	Dear Steven,
>>>
>>> 	The reason that linearHypothesis() computes a Wald F or chisquare
>>> test rather than a t or z test is that the (numerator) df for the linear hypothesis
>>> need not be 1.
>>>
>>> 	In your case (as has been pointed out) you can get the coefficient
>>> standard error directly from the model summary.
>>>
>>> 	More generally, with some work, you could solve for the the SE for a 1
>>> df linear hypothesis in terms of the value of the linear function of coefficients
>>> and the F or chisquare. That said, I'm not sure why you want to do this.
>>>
>>> 	I hope this helps,
>>> 	 John
>>>
>>> 	-----------------------------
>>> 	John Fox, Professor
>>> 	McMaster University
>>> 	Hamilton, Ontario
>>> 	Canada L8S 4M4
>>> 	Web: socserv.mcmaster.ca/jfox
>>>
>>>
>>>
>>> 		-----Original Message-----
>>> 		From: R-help [mailto:r-help-bounces at r-project.org] On Behalf
>>> Of Steven Yen
>>> 		Sent: June 28, 2016 9:27 AM
>>> 		To: R-help<r-help at r-project.org>  <mailto:r-help at r- project.org>
>>> 		Subject: [R] t-test for regression estimate
>>>
>>> 		test option for linearHypothesis in library(car) include "Chisq"
>>> and "F". I prefer
>>> 		a simple t-test so that I can retrieve the standard error.
>>> 		Any options other than linearHypothesis to test the linear
>>> hypothesis (with 1
>>> 		restriction/degree of freedom)?
>>>
>>> 		 > summary(ols1)
>>>
>>> 		Coefficients:
>>> 		             Estimate Std. Error t value Pr(>|t|)
>>> 		(Intercept) -0.20013    0.09199  -2.176   0.0298 *
>>> 		age          0.04054    0.01721   2.355   0.0187 *
>>> 		suburb       0.01911    0.05838   0.327   0.7435
>>> 		smcity      -0.29969    0.19175  -1.563   0.1184
>>> 		---
>>> 		Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> 		 > linearHypothesis(ols1,"suburb")
>>> 		Linear hypothesis test
>>>
>>> 		Hypothesis:
>>> 		suburb = 0
>>>
>>> 		Model 1: restricted model
>>> 		Model 2: polideo ~ age + suburb + smcity
>>>
>>> 		   Res.Df    RSS Df Sum of Sq      F Pr(>F)
>>> 		1    888 650.10
>>> 		2    887 650.02  1  0.078534 0.1072 0.7435
>>>
>>>
>>> 			[[alternative HTML version deleted]]
>>>
>>> 		______________________________________________
>>> 		R-help at r-project.org  <mailto:R-help at r-project.org>   mailing
>>> list -- To UNSUBSCRIBE and more, see
>>> 		https://stat.ethz.ch/mailman/listinfo/r-help
>>> 		PLEASE do read the posting guidehttp://www.R-
>>> project.org/posting-
>>> 		guide.html
>>> 		and provide commented, minimal, self-contained, reproducible
>>> code.
>>>
>


	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Wed Jun 29 20:06:53 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 29 Jun 2016 13:06:53 -0500
Subject: [R] Understanding and predict round-off errors sign on simple
 functions
In-Reply-To: <CAGxFJbRoPRFtBLXu+_uvW6MjPRCd-W1o2n3vNKhJwbWS+TBqVg@mail.gmail.com>
References: <002e01d1d1ec$70c99080$525cb180$@laposte.net>
	<CAGxFJbRoPRFtBLXu+_uvW6MjPRCd-W1o2n3vNKhJwbWS+TBqVg@mail.gmail.com>
Message-ID: <F53BA2E3-7B45-431F-A1A8-7571E8C7A853@me.com>

Hi,

Just to augment Bert's comments, I presume that you are aware of the relevant R FAQ:

  https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

That you had an expectation of the difference being 0 suggested to me that you might not be, but my apologies if that is not the case.

That being said, there are some higher precision CRAN packages that may offer some additional functionality, with the potential limitations that Bert references below. More information is available in the Numerical Mathematics CRAN Task View:

  https://cran.r-project.org/web/views/NumericalMathematics.html

In addition, with the caveat that I have not used it, there is the 'propagate' package on CRAN that may be relevant to what you want to be able to anticipate, at some level:

  https://cran.r-project.org/web/packages/propagate/index.html

It has not been updated in a while and there are some notes for the CRAN package checks, that suggest that the maintainer may not be active at this point.

Regards,

Marc


> On Jun 29, 2016, at 10:13 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I am certainly no expert, but I would assume that:
> 
> 1. Roundoff errors depend on the exact numerical libraries and
> versions that are used, and so general language comparisons are
> impossible without that information;
> 
> 2. Roundoff errors depend on the exact calculations being done and
> machine precision and are very complicated to determine
> 
> So I would say the answer to your questions is no.
> 
> But you should probably address such a question to a numerical analyst
> for an authoritative answer. Maybe try stats.stackexchange.com  .
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Jun 29, 2016 at 2:55 AM, Sirhc via R-help <r-help at r-project.org> wrote:
>> Hi,
>> 
>> 
>> 
>> May be it is a basic thing but I would like to know if we can anticipate
>> round-off errors sign.
>> 
>> 
>> 
>> Here is an example :
>> 
>> 
>> 
>> # numerical matrix
>> 
>> m <- matrix(data=cbind(rnorm(10, 0), rnorm(10, 2), rnorm(10, 5)), nrow=10,
>> ncol=3)
>> 
>> 
>> 
>>> m
>> 
>>            [,1]      [,2]     [,3]
>> 
>> [1,]  0.4816247 1.1973502 3.855641
>> 
>> [2,] -1.2174937 0.7356427 4.393279
>> 
>> [3,]  0.8504074 2.5286509 2.689196
>> 
>> [4,]  1.8048642 1.8580804 6.665237
>> 
>> [5,] -0.6749397 1.0944277 4.838608
>> 
>> [6,]  0.8252034 1.5595268 3.681695
>> 
>> [7,]  1.3002208 0.9582693 4.561577
>> 
>> [8,]  1.6950923 3.5677921 6.005078
>> 
>> [9,]  0.6509285 0.9025964 5.082288
>> 
>> [10,] -0.5676040 1.3281102 4.446451
>> 
>> 
>> 
>> #weird moving average of period 1 !
>> 
>> mma <- apply(m, 2, SMA, n=1)
>> 
>> 
>> 
>>> mma
>> 
>>            [,1]      [,2]     [,3]
>> 
>> [1,]         NA        NA       NA
>> 
>> [2,] -1.2174937 0.7356427 4.393279
>> 
>> [3,]  0.8504074 2.5286509 2.689196
>> 
>> [4,]  1.8048642 1.8580804 6.665237
>> 
>> [5,] -0.6749397 1.0944277 4.838608
>> 
>> [6,]  0.8252034 1.5595268 3.681695
>> 
>> [7,]  1.3002208 0.9582693 4.561577
>> 
>> [8,]  1.6950923 3.5677921 6.005078
>> 
>> [9,]  0.6509285 0.9025964 5.082288
>> 
>> [10,] -0.5676040 1.3281102 4.446451
>> 
>> 
>> 
>> 
>> 
>> #difference should be 0 but here is the result
>> 
>>> m - mma
>> 
>>               [,1]         [,2]          [,3]
>> 
>> [1,]            NA           NA            NA
>> 
>> [2,]  0.000000e+00 0.000000e+00 -8.881784e-16
>> 
>> [3,]  0.000000e+00 0.000000e+00 -8.881784e-16
>> 
>> [4,]  0.000000e+00 4.440892e-16 -8.881784e-16
>> 
>> [5,] -1.110223e-16 4.440892e-16 -8.881784e-16
>> 
>> [6,] -1.110223e-16 2.220446e-16 -4.440892e-16
>> 
>> [7,] -2.220446e-16 2.220446e-16  0.000000e+00
>> 
>> [8,] -2.220446e-16 0.000000e+00  0.000000e+00
>> 
>> [9,] -3.330669e-16 2.220446e-16 -8.881784e-16
>> 
>> [10,] -3.330669e-16 4.440892e-16 -8.881784e-16
>> 
>> 
>> 
>> SMA function use runMean
>> 
>> # TTR / R / MovingAverages.R
>> 
>> "SMA" <- function(x, n=10, ...) { # Simple Moving Average
>> 
>>   ma <- runMean( x, n )
>> 
>>   if(!is.null(dim(ma))) {
>> 
>>     colnames(ma) <- "SMA"
>> 
>>   }
>> 
>>  return(ma)
>> 
>> }
>> 
>> 
>> 
>> 
>> 
>> Can anyone explain me that round error type?
>> 
>> Is it possible to reproduce this same error generation in another language
>> like C++ or C# ?
>> 
>> 
>> 
>> Thanks in advance for your answers
>> 
>> 
>> 
>> Regards
>> 
>> 
>> 
>> Chris


From jfox at mcmaster.ca  Wed Jun 29 22:48:17 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 29 Jun 2016 20:48:17 +0000
Subject: [R] t-test for regression estimate
In-Reply-To: <a0026322-c6ae-698e-5221-698c3c1e3a8d@gmail.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>
	<b86a1527-ecd3-6749-a137-865482d30136@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D929@FHSDB2D11-2.csu.mcmaster.ca>
	<a0026322-c6ae-698e-5221-698c3c1e3a8d@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83653DA1D@FHSDB2D11-2.csu.mcmaster.ca>

Dear Steven,

> -----Original Message-----
> From: Steven Yen [mailto:syen04 at gmail.com]
> Sent: June 29, 2016 9:39 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: R-help <r-help at r-project.org>; Sandy Weisberg (sandy at umn.edu)
> <sandy at umn.edu>
> Subject: Re: [R] t-test for regression estimate
> 
> Thanks John. Yes, by using verbose=T, I get the value of the hypothesis. But tell
> me again, how would I get the variance (standard error)?

Using verbose=TRUE *prints* the value of the hypothesis but doesn't save it in the returned object, making it inconvenient to compute on it. As well, when verbose is TRUE we should probably also print the covariance matrix for the hypothesis, which we don't do at present, but which I'll add when I have a chance.

From ?linearHypothesis in the development version of car: "The value of the linear hypothesis and its covariance matrix are returned respectively as "value" and "vcov" attributes of the object (but not printed)." Thus, for example,

---------------- snip ------------

> library(car)
> mod <- lm(prestige ~ income + education, data=Duncan)
> lh <- linearHypothesis(mod, "income = education"))

> attr(lh, "value")
                         [,1]
income = education 0.05289891

> attr(lh, "vcov")
                   income = education
income = education         0.04101096

---------------- snip ------------

The reason that l used attributes is that linearHypothesis() returns an "anova" object, which is printed by print.anova(). Adding components directly to that object would disturb printing it. I could introduce a new class of objects but, though that would be more intuitive, and though I may end up doing that, it is probably unwarranted given the rarity of wanting to access the value and covariance matrix of the hypothesis.

Best,
 John

> 
> 
> On 6/29/2016 11:56 AM, Fox, John wrote:
> 
> 
> 	Dear Steven,
> 
> 	OK -- that makes sense, and there was also a previous request for
> linearHypothesis() to return the value of the hypothesis and its covariance
> matrix. In your case, where there's only 1 numerator df, that would be the
> value and estimated sampling variance of the hypothesis.
> 
> 	I've now implemented that, using (at least provisionally) attributes in
> the development version of the car package on R-Forge, which you should be
> able to install via install.packages("car", repos="http://R-Forge.R-project.org"
> <http://R-Forge.R-project.org> ). Then see ?linearHypothesis for more
> information.
> 
> 	Best,
> 	 John
> 
> 
> 		-----Original Message-----
> 		From: Steven Yen [mailto:syen04 at gmail.com]
> 		Sent: June 28, 2016 3:44 PM
> 		To: Fox, John <jfox at mcmaster.ca>
> <mailto:jfox at mcmaster.ca>
> 		Cc: R-help <r-help at r-project.org> <mailto:r-help at r-
> project.org>
> 		Subject: Re: [R] t-test for regression estimate
> 
> 		Thanks John. Reason is I am doing linear transformations of
> many coefficients
> 		(e.g., bi / scalar). Of course I can uncover the t-statistic from
> the F statistic and
> 		then the standard error. Simply scaling the estimated
> coefficients I can also
> 		transform the standard errors. I have since found deltaMethod
> from library
> 		"car" useful. Its just that, if linearHypothesis had provide the
> standard errors
> 		and t-statistics then the operation would have been easier,
> with a one-line
> 		command for each coefficient. Thank you again.
> 
> 
> 		On 6/28/2016 6:28 PM, Fox, John wrote:
> 
> 
> 			Dear Steven,
> 
> 			The reason that linearHypothesis() computes a Wald F
> or chisquare
> 		test rather than a t or z test is that the (numerator) df for the
> linear hypothesis
> 		need not be 1.
> 
> 			In your case (as has been pointed out) you can get the
> coefficient
> 		standard error directly from the model summary.
> 
> 			More generally, with some work, you could solve for
> the the SE for a 1
> 		df linear hypothesis in terms of the value of the linear function
> of coefficients
> 		and the F or chisquare. That said, I'm not sure why you want to
> do this.
> 
> 			I hope this helps,
> 			 John
> 
> 			-----------------------------
> 			John Fox, Professor
> 			McMaster University
> 			Hamilton, Ontario
> 			Canada L8S 4M4
> 			Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 				-----Original Message-----
> 				From: R-help [mailto:r-help-bounces at r-
> project.org] On Behalf
> 		Of Steven Yen
> 				Sent: June 28, 2016 9:27 AM
> 				To: R-help <r-help at r-project.org> <mailto:r-
> help at r-project.org>  <mailto:r-help at r-
> 		project.org> <mailto:r-help at r-project.org>
> 				Subject: [R] t-test for regression estimate
> 
> 				test option for linearHypothesis in library(car)
> include "Chisq"
> 		and "F". I prefer
> 				a simple t-test so that I can retrieve the
> standard error.
> 				Any options other than linearHypothesis to
> test the linear
> 		hypothesis (with 1
> 				restriction/degree of freedom)?
> 
> 				 > summary(ols1)
> 
> 				Coefficients:
> 				             Estimate Std. Error t value Pr(>|t|)
> 				(Intercept) -0.20013    0.09199  -2.176   0.0298
> *
> 				age          0.04054    0.01721   2.355   0.0187 *
> 				suburb       0.01911    0.05838   0.327   0.7435
> 				smcity      -0.29969    0.19175  -1.563   0.1184
> 				---
> 				Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.?
> 0.1 ? ? 1
> 
> 				 > linearHypothesis(ols1,"suburb")
> 				Linear hypothesis test
> 
> 				Hypothesis:
> 				suburb = 0
> 
> 				Model 1: restricted model
> 				Model 2: polideo ~ age + suburb + smcity
> 
> 				   Res.Df    RSS Df Sum of Sq      F Pr(>F)
> 				1    888 650.10
> 				2    887 650.02  1  0.078534 0.1072 0.7435
> 
> 
> 					[[alternative HTML version deleted]]
> 
> 
> 	______________________________________________
> 				R-help at r-project.org <mailto:R-help at r-
> project.org>  <mailto:R-help at r-project.org> <mailto:R-help at r-project.org>
> mailing
> 		list -- To UNSUBSCRIBE and more, see
> 				https://stat.ethz.ch/mailman/listinfo/r-help
> 				PLEASE do read the posting guide
> http://www.R-
> 		project.org/posting-
> 				guide.html
> 				and provide commented, minimal, self-
> contained, reproducible
> 		code.
> 
> 
> 
> 


From dutangc at gmail.com  Wed Jun 29 22:49:35 2016
From: dutangc at gmail.com (Christophe Dutang)
Date: Wed, 29 Jun 2016 22:49:35 +0200
Subject: [R] linking vignettes in a man page
Message-ID: <964C15FE-9C8D-46A7-8E37-476C09102472@gmail.com>

Dear list,

How can I link a vignette of a package in a man page (Rd files)?

I try \link[=pkgname/doc/filename]{a name} without success. 

The link gives the following error message: Only help files, NEWS, DESCRIPTION and files under doc/ and demo/ in a package can be viewed

Thanks in advance

Kind regards, Christophe
---------------------------------------
Christophe Dutang
LMM, UdM, Le Mans, France
web: http://dutangc.free.fr


From jfox at mcmaster.ca  Wed Jun 29 22:51:48 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 29 Jun 2016 20:51:48 +0000
Subject: [R] t-test for regression estimate
In-Reply-To: <3ab097ba-e5f2-4f13-3b63-debb2ddf7216@gmail.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D492@FHSDB2D11-2.csu.mcmaster.ca>
	<b86a1527-ecd3-6749-a137-865482d30136@gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC83653D929@FHSDB2D11-2.csu.mcmaster.ca>
	<a0026322-c6ae-698e-5221-698c3c1e3a8d@gmail.com>
	<3ab097ba-e5f2-4f13-3b63-debb2ddf7216@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83653DA32@FHSDB2D11-2.csu.mcmaster.ca>

Dear Steven,

> -----Original Message-----
> From: Steven Yen [mailto:syen04 at gmail.com]
> Sent: June 29, 2016 9:48 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: R-help <r-help at r-project.org>; Sandy Weisberg (sandy at umn.edu)
> <sandy at umn.edu>
> Subject: Re: [R] t-test for regression estimate
> 
> Also,
> Is there a way to get the second command (hypothesis defined with externally
> scalars) below to work? Thanks.
> 
> linearHypothesis(U,"0.5*eq1_DQ+0.3*eq2_DQ",verbose=T)
> w1<-0.5; w2<-0.3
> linearHypothesis(U,"w1*eq1_DQ+w2*eq2_DQ",verbose=T) # does not work

You can specify the hypothesis matrix (a vector in the 1-df case). E.g.,

----------------- snip ---------------------	

> library(car)
> mod <- lm(prestige ~ income + education, data=Duncan)
> one <- 1
> minus.one <- -1
> linearHypothesis(mod, c(0, one, minus.one)) # 0 * the intercept
Linear hypothesis test

Hypothesis:
income - education = 0

Model 1: restricted model
Model 2: prestige ~ income + education

  Res.Df    RSS Df Sum of Sq      F Pr(>F)
1     43 7518.9                           
2     42 7506.7  1    12.195 0.0682 0.7952

----------------- snip ---------------------	

John

> 
> 
> On 6/29/2016 12:38 PM, Steven Yen wrote:
> 
> 
> 	Thanks John. Yes, by using verbose=T, I get the value of the hypothesis.
> But tell me again, how would I get the variance (standard error)?
> 
> 
> 	On 6/29/2016 11:56 AM, Fox, John wrote:
> 
> 
> 		Dear Steven,
> 
> 		OK -- that makes sense, and there was also a previous request
> for linearHypothesis() to return the value of the hypothesis and its covariance
> matrix. In your case, where there's only 1 numerator df, that would be the
> value and estimated sampling variance of the hypothesis.
> 
> 		I've now implemented that, using (at least provisionally)
> attributes in the development version of the car package on R-Forge, which you
> should be able to install via install.packages("car", repos="http://R-Forge.R-
> project.org" <http://R-Forge.R-project.org> ). Then see ?linearHypothesis for
> more information.
> 
> 		Best,
> 		 John
> 
> 
> 			-----Original Message-----
> 			From: Steven Yen [mailto:syen04 at gmail.com]
> 			Sent: June 28, 2016 3:44 PM
> 			To: Fox, John <jfox at mcmaster.ca>
> <mailto:jfox at mcmaster.ca>
> 			Cc: R-help <r-help at r-project.org> <mailto:r-help at r-
> project.org>
> 			Subject: Re: [R] t-test for regression estimate
> 
> 			Thanks John. Reason is I am doing linear
> transformations of many coefficients
> 			(e.g., bi / scalar). Of course I can uncover the t-statistic
> from the F statistic and
> 			then the standard error. Simply scaling the estimated
> coefficients I can also
> 			transform the standard errors. I have since found
> deltaMethod from library
> 			"car" useful. Its just that, if linearHypothesis had
> provide the standard errors
> 			and t-statistics then the operation would have been
> easier, with a one-line
> 			command for each coefficient. Thank you again.
> 
> 
> 			On 6/28/2016 6:28 PM, Fox, John wrote:
> 
> 
> 				Dear Steven,
> 
> 				The reason that linearHypothesis() computes a
> Wald F or chisquare
> 			test rather than a t or z test is that the (numerator) df
> for the linear hypothesis
> 			need not be 1.
> 
> 				In your case (as has been pointed out) you can
> get the coefficient
> 			standard error directly from the model summary.
> 
> 				More generally, with some work, you could
> solve for the the SE for a 1
> 			df linear hypothesis in terms of the value of the linear
> function of coefficients
> 			and the F or chisquare. That said, I'm not sure why you
> want to do this.
> 
> 				I hope this helps,
> 				 John
> 
> 				-----------------------------
> 				John Fox, Professor
> 				McMaster University
> 				Hamilton, Ontario
> 				Canada L8S 4M4
> 				Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 					-----Original Message-----
> 					From: R-help [mailto:r-help-
> bounces at r-project.org] On Behalf
> 			Of Steven Yen
> 					Sent: June 28, 2016 9:27 AM
> 					To: R-help <r-help at r-project.org>
> <mailto:r-help at r-project.org>  <mailto:r-help at r-
> 			project.org> <mailto:r-help at r-project.org>
> 					Subject: [R] t-test for regression
> estimate
> 
> 					test option for linearHypothesis in
> library(car) include "Chisq"
> 			and "F". I prefer
> 					a simple t-test so that I can retrieve
> the standard error.
> 					Any options other than
> linearHypothesis to test the linear
> 			hypothesis (with 1
> 					restriction/degree of freedom)?
> 
> 					 > summary(ols1)
> 
> 					Coefficients:
> 					             Estimate Std. Error t value
> Pr(>|t|)
> 					(Intercept) -0.20013    0.09199  -2.176
> 0.0298 *
> 					age          0.04054    0.01721   2.355
> 0.0187 *
> 					suburb       0.01911    0.05838   0.327
> 0.7435
> 					smcity      -0.29969    0.19175  -1.563
> 0.1184
> 					---
> 					Signif. codes:  0 ?***? 0.001 ?**? 0.01
> ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 					 > linearHypothesis(ols1,"suburb")
> 					Linear hypothesis test
> 
> 					Hypothesis:
> 					suburb = 0
> 
> 					Model 1: restricted model
> 					Model 2: polideo ~ age + suburb +
> smcity
> 
> 					   Res.Df    RSS Df Sum of Sq      F Pr(>F)
> 					1    888 650.10
> 					2    887 650.02  1  0.078534 0.1072
> 0.7435
> 
> 
> 						[[alternative HTML version
> deleted]]
> 
> 
> 	______________________________________________
> 					R-help at r-project.org <mailto:R-
> help at r-project.org>  <mailto:R-help at r-project.org> <mailto:R-help at r-
> project.org>   mailing
> 			list -- To UNSUBSCRIBE and more, see
> 
> 	https://stat.ethz.ch/mailman/listinfo/r-help
> 					PLEASE do read the posting guide
> http://www.R-
> 			project.org/posting-
> 					guide.html
> 					and provide commented, minimal,
> self-contained, reproducible
> 			code.
> 
> 
> 


From bgunter.4567 at gmail.com  Wed Jun 29 23:00:13 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 29 Jun 2016 14:00:13 -0700
Subject: [R] linking vignettes in a man page
In-Reply-To: <964C15FE-9C8D-46A7-8E37-476C09102472@gmail.com>
References: <964C15FE-9C8D-46A7-8E37-476C09102472@gmail.com>
Message-ID: <CAGxFJbSqBf1=oBuBwVcZvDCA2m5TvKitqgXej5tdYVtUqvZbCA@mail.gmail.com>

Please post this on R-package-devel, not here.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 29, 2016 at 1:49 PM, Christophe Dutang <dutangc at gmail.com> wrote:
> Dear list,
>
> How can I link a vignette of a package in a man page (Rd files)?
>
> I try \link[=pkgname/doc/filename]{a name} without success.
>
> The link gives the following error message: Only help files, NEWS, DESCRIPTION and files under doc/ and demo/ in a package can be viewed
>
> Thanks in advance
>
> Kind regards, Christophe
> ---------------------------------------
> Christophe Dutang
> LMM, UdM, Le Mans, France
> web: http://dutangc.free.fr
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From n.l.pace at utah.edu  Wed Jun 29 23:17:59 2016
From: n.l.pace at utah.edu (Nathan Pace)
Date: Wed, 29 Jun 2016 21:17:59 +0000
Subject: [R] ggplot2 stat_smooth
Message-ID: <5CC29EB1-05F6-49B9-8EAB-0D79EA0ACBE3@utah.edu>

I want to add a logistic plot to data.

My call to ggplot is:


ggplot(data = SSI.dt, aes(x = elapsed, y = 1 - control)) + geom_point() +
stat_smooth(method = 'glm', family = binomial) +
xlab('Surgery Duration (min)') + ylab('Probability SSI') +
labs(title = 'THA Surgical Site Infections')
ggsave(filename = 'Plots/SSI.Duration.pdf?)

An error message is returned: Unknown parameters: family

Removing ?family = binomial? returns a straight line with points appropriately placed on y = 0 and y = 1.

I found some previous messages on markmail that listed my call as the correct syntax structure.

I?d appreciate thoughts/pointers.


Nathan

-- 
Nathan Pace, MD, MStat
Department of Anesthesiology
University of Utah
801.581.6393
n.l.pace at utah.edu








From murdoch.duncan at gmail.com  Wed Jun 29 23:27:25 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Jun 2016 17:27:25 -0400
Subject: [R] linking vignettes in a man page
In-Reply-To: <964C15FE-9C8D-46A7-8E37-476C09102472@gmail.com>
References: <964C15FE-9C8D-46A7-8E37-476C09102472@gmail.com>
Message-ID: <789d0613-0371-b034-b454-4dcbb911f1ba@gmail.com>

On 29/06/2016 4:49 PM, Christophe Dutang wrote:
> Dear list,
>
> How can I link a vignette of a package in a man page (Rd files)?
>
> I try \link[=pkgname/doc/filename]{a name} without success.
>
> The link gives the following error message: Only help files, NEWS, DESCRIPTION and files under doc/ and demo/ in a package can be viewed


You can give \url{} style links, for example the grid package has

\url{../doc/grid.pdf}

in the package?grid help topic.  Similarly, ../../<pkg>/help/<alias> 
will link from a vignette to help topic ?alias.

Duncan Murdoch


From r.turner at auckland.ac.nz  Thu Jun 30 00:00:50 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 30 Jun 2016 10:00:50 +1200
Subject: [R] [FORGED] Re:  a new df with one combined column
In-Reply-To: <CAKVAULNTKzASukzExmyomaABmcZuEUUqedFspTYdD_ZCLH+vjw@mail.gmail.com>
References: <213311750.5859189.1467205730821.JavaMail.yahoo.ref@mail.yahoo.com>
	<213311750.5859189.1467205730821.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOysAbw8Yy7XG13QVktkpAjA9J350UMteLQ9S1Khgv9CA@mail.gmail.com>
	<190063059.5921924.1467207903107.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULNTKzASukzExmyomaABmcZuEUUqedFspTYdD_ZCLH+vjw@mail.gmail.com>
Message-ID: <0f215b8e-a5c3-a5f0-6e7b-f8e2408530cf@auckland.ac.nz>

On 30/06/16 02:08, Ulrik Stervbo wrote:
> Then I don't understand what you want to achieve. If you want to combine
> the two columns you can do
>
> c(df1$col1,  df2$col2)

It is indeed difficult to understand what the OP wants to do.  Perhaps 
he/she wants to *paste* the two columns together?

In which case he/she should see ?paste.

cheers,

Rolf Turner


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Thu Jun 30 00:10:29 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 29 Jun 2016 15:10:29 -0700
Subject: [R] ggplot2 stat_smooth
In-Reply-To: <5CC29EB1-05F6-49B9-8EAB-0D79EA0ACBE3@utah.edu>
References: <5CC29EB1-05F6-49B9-8EAB-0D79EA0ACBE3@utah.edu>
Message-ID: <14A37CC5-7DF7-4B23-84F4-3977CE507758@comcast.net>


> On Jun 29, 2016, at 2:17 PM, Nathan Pace <n.l.pace at utah.edu> wrote:
> 
> I want to add a logistic plot to data.
> 
> My call to ggplot is:
> 
> 
> ggplot(data = SSI.dt, aes(x = elapsed, y = 1 - control)) + geom_point() +
> stat_smooth(method = 'glm', family = binomial) +
> xlab('Surgery Duration (min)') + ylab('Probability SSI') +
> labs(title = 'THA Surgical Site Infections')
> ggsave(filename = 'Plots/SSI.Duration.pdf?)
> 
> An error message is returned: Unknown parameters: family

So you would have naturally looked at the acceptable arguments for the function, right?

> 
> Removing ?family = binomial? returns a straight line with points appropriately placed on y = 0 and y = 1.
> 
> I found some previous messages on markmail that listed my call as the correct syntax structure.

Perhaps they referred to older versions of the function.

Looking at:

?stat_smooth

 The current help page implements this by creating a helper function, binomial_smooth,  but using its example of the needed arguments I did just try:

... + stat_smooth(method = 'glm', method.args = list(family = "binomial"))


With success.

-- 
David.
> 
> I?d appreciate thoughts/pointers.
> 
> 
> Nathan
> 
> -- 
> Nathan Pace, MD, MStat
> Department of Anesthesiology
> University of Utah
> 801.581.6393
> n.l.pace at utah.edu
> 
> 
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From doug45290 at yahoo.com  Wed Jun 29 20:24:50 2016
From: doug45290 at yahoo.com (D Wolf)
Date: Wed, 29 Jun 2016 18:24:50 +0000 (UTC)
Subject: [R] Bestglm subset analysis
In-Reply-To: <5e1da62cf6b94aa29105fa1ee82e0e19@UM-MAIL3216.unimaas.nl>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<5e1da62cf6b94aa29105fa1ee82e0e19@UM-MAIL3216.unimaas.nl>
Message-ID: <1349199120.3832843.1467224690440.JavaMail.yahoo@mail.yahoo.com>

Hello All,
I am working on a linear regression model and trying to find the best subset of variables for my dataset. I have 21 predictors, 1 response variable, and 79 observations. I need to find the best 5 or 6 predictors for my model. I've used leaps for lm() and I'm now trying bestglm for glm(). I'm following this webpage, which gives the code below.?https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html
My code:library(bestglm)library(base)lbw.for.bestglm <- within(df_Chl, {y <- df_Chl$Chloro })res.bestglm <- bestglm(Xy = lbw.for.bestglm, family = gaussian, IC = "AIC", method = "exhaustive")
# get coefficientsres.bestglm$BestModelsHere is a sample of my results (I removed the 5th through 21st predictors for brevity).> res.bestglm$BestModels? ? R21 ? R31 ? R32 ? R41?1 FALSE FALSE FALSE FALSE ?2 FALSE ?TRUE FALSE FALSE ?3 FALSE FALSE FALSE FALSE?4 FALSE ?TRUE FALSE FALSE?5 FALSE ?TRUE FALSE FALSE ?Criterion1 ?326.73272 ?326.95253 ?327.06594 ?327.09125 ?327.8208
Is it correct to assume I should keep variables that are TRUE from 1 through 5? What do those five rows represent??
I know the AIC criterion result should be as low as possible. Is it possible to discern a good result for any of the IC criterion results, such as AIC, LOOCV, BICg, etc..? If BIC returns lower Criterion results, does that mean I need to use the BIC subset instead of the subset from AIC?
Thank You,
Doug

	[[alternative HTML version deleted]]


From marine.regis at hotmail.fr  Thu Jun 30 00:32:26 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Wed, 29 Jun 2016 22:32:26 +0000
Subject: [R] =?windows-1252?q?data=2Etable=3A_=93group_counter=94_with_NAs?=
Message-ID: <AMSPR07MB47008C9F30C298DEEADDD5CE2230@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,

I would like to add a counter column in a data frame based on a set of identical rows. To do this, I tested:

DF = data.table(x=c("a","a","a","b","c","d","e","f","f"), y=c(1,3,2,8,8,4,NA,NA,NA))

DF[ , Index := .GRP, by = c("y") ]

DF



However, the rows with NAs are considered to be identical.

So, how can I obtain:

   x  y Index

1: a  1     1

2: a  3     2

3: a  2     3

4: b  8     4

5: c  8     4

6: d  4     5

7: e NA     6

8: f NA     7

9: f NA     8



Instead of:

x  y Index

1: a  1     1

2: a  3     2

3: a  2     3

4: b  8     4

5: c  8     4

6: d  4     5

7: e NA     6

8: f NA     6

9: f NA     6





Thank you very much for your time.

Have a nice day

Marine


	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Jun 30 00:31:20 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 29 Jun 2016 22:31:20 +0000
Subject: [R] Understanding and predict round-off errors sign on simple
 functions
In-Reply-To: <002e01d1d1ec$70c99080$525cb180$@laposte.net>
References: <002e01d1d1ec$70c99080$525cb180$@laposte.net>
Message-ID: <D399978A.17CF7D%macqueen1@llnl.gov>

For all practical purposes, the differences are zero.

If you want them to also look like zero, try
  round( m - mma , 3)
or
  signif( m - mma , 3)

(or some number of digits other than three;  I picked 3 rather arbitrarily)


For anticipating the sign of these minuscule differences, I doubt there is
a way (but I don't know why it would matter, either). If you want them all
positive, use
  abs(round(m-mma,3))
or similar.

Other programming languages will produce similar very small numbers,
depending on how the calculation is done, but I would not expect exactly
the same very small numbers.

Finally, it would appear that your round-off errors are being generated
inside the runMean function, and we don't know where that function comes
from. It's not in base R. You could try
  x <- rnorm(1) ;   x - runMean(x , 1)
many times and see how often runMean does not return the value it was
supplied with, and then study the definition of runMean to try to
understand why it does not always return the value it was supplied with.

This all assumes I've accurately read your example code and and reduced it
to its core behavior.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/29/16, 2:55 AM, "R-help on behalf of Sirhc via R-help"
<r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

>Hi,
>
> 
>
>May be it is a basic thing but I would like to know if we can anticipate
>round-off errors sign.
>
> 
>
>Here is an example :
>
> 
>
># numerical matrix
>
>m <- matrix(data=cbind(rnorm(10, 0), rnorm(10, 2), rnorm(10, 5)), nrow=10,
>ncol=3)
>
> 
>
>> m
>
>            [,1]      [,2]     [,3]
>
>[1,]  0.4816247 1.1973502 3.855641
>
>[2,] -1.2174937 0.7356427 4.393279
>
>[3,]  0.8504074 2.5286509 2.689196
>
>[4,]  1.8048642 1.8580804 6.665237
>
>[5,] -0.6749397 1.0944277 4.838608
>
>[6,]  0.8252034 1.5595268 3.681695
>
>[7,]  1.3002208 0.9582693 4.561577
>
>[8,]  1.6950923 3.5677921 6.005078
>
>[9,]  0.6509285 0.9025964 5.082288
>
>[10,] -0.5676040 1.3281102 4.446451
>
> 
>
>#weird moving average of period 1 !
>
>mma <- apply(m, 2, SMA, n=1)
>
> 
>
>> mma
>
>            [,1]      [,2]     [,3]
>
>[1,]         NA        NA       NA
>
>[2,] -1.2174937 0.7356427 4.393279
>
>[3,]  0.8504074 2.5286509 2.689196
>
>[4,]  1.8048642 1.8580804 6.665237
>
>[5,] -0.6749397 1.0944277 4.838608
>
>[6,]  0.8252034 1.5595268 3.681695
>
>[7,]  1.3002208 0.9582693 4.561577
>
>[8,]  1.6950923 3.5677921 6.005078
>
>[9,]  0.6509285 0.9025964 5.082288
>
>[10,] -0.5676040 1.3281102 4.446451
>
> 
>
> 
>
>#difference should be 0 but here is the result
>
>> m - mma 
>
>               [,1]         [,2]          [,3]
>
>[1,]            NA           NA            NA
>
>[2,]  0.000000e+00 0.000000e+00 -8.881784e-16
>
>[3,]  0.000000e+00 0.000000e+00 -8.881784e-16
>
>[4,]  0.000000e+00 4.440892e-16 -8.881784e-16
>
>[5,] -1.110223e-16 4.440892e-16 -8.881784e-16
>
>[6,] -1.110223e-16 2.220446e-16 -4.440892e-16
>
>[7,] -2.220446e-16 2.220446e-16  0.000000e+00
>
>[8,] -2.220446e-16 0.000000e+00  0.000000e+00
>
>[9,] -3.330669e-16 2.220446e-16 -8.881784e-16
>
>[10,] -3.330669e-16 4.440892e-16 -8.881784e-16
>
> 
>
>SMA function use runMean
>
># TTR / R / MovingAverages.R
>
>"SMA" <- function(x, n=10, ...) { # Simple Moving Average
>
>   ma <- runMean( x, n )
>
>   if(!is.null(dim(ma))) {
>
>     colnames(ma) <- "SMA"
>
>   } 
>
>  return(ma) 
>
>}
>
> 
>
> 
>
>Can anyone explain me that round error type?
>
>Is it possible to reproduce this same error generation in another language
>like C++ or C# ?
>
> 
>
>Thanks in advance for your answers
>
> 
>
>Regards
>
> 
>
>Chris
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From n.l.pace at utah.edu  Thu Jun 30 00:51:51 2016
From: n.l.pace at utah.edu (Nathan Pace)
Date: Wed, 29 Jun 2016 22:51:51 +0000
Subject: [R] ggplot2 stat_smooth
In-Reply-To: <14A37CC5-7DF7-4B23-84F4-3977CE507758@comcast.net>
References: <5CC29EB1-05F6-49B9-8EAB-0D79EA0ACBE3@utah.edu>
	<14A37CC5-7DF7-4B23-84F4-3977CE507758@comcast.net>
Message-ID: <E1D411CD-D624-49CF-8149-7C26936BAFD5@utah.edu>

I appreciate the pointers.

I am using ggplot2 2.1.0, but I was looking at the wrong version of the web page example documentation.

The easiest way is to define the function

binomial_smooth <- function(...) {
  geom_smooth(method = "glm", method.args = list(family = "binomial"), ...)
}



And then call

ggplot(data = SSI.dt, aes(x = elapsed, y = 1 - control)) + geom_point() +

binomial_smooth()

Everything is now working smoothly.


Nathan
 





-----Original Message-----
From: David Winsemius <dwinsemius at comcast.net>
Date: Wednesday, June 29, 2016 at 16:10
To: Nathan L Pace <n.l.pace at utah.edu>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] ggplot2 stat_smooth

>
>> On Jun 29, 2016, at 2:17 PM, Nathan Pace <n.l.pace at utah.edu> wrote:
>> 
>> I want to add a logistic plot to data.
>> 
>> My call to ggplot is:
>> 
>> 
>> ggplot(data = SSI.dt, aes(x = elapsed, y = 1 - control)) + geom_point() +
>> stat_smooth(method = 'glm', family = binomial) +
>> xlab('Surgery Duration (min)') + ylab('Probability SSI') +
>> labs(title = 'THA Surgical Site Infections')
>> ggsave(filename = 'Plots/SSI.Duration.pdf?)
>> 
>> An error message is returned: Unknown parameters: family
>
>So you would have naturally looked at the acceptable arguments for the function, right?
>
>> 
>> Removing ?family = binomial? returns a straight line with points appropriately placed on y = 0 and y = 1.
>> 
>> I found some previous messages on markmail that listed my call as the correct syntax structure.
>
>Perhaps they referred to older versions of the function.
>
>Looking at:
>
>?stat_smooth
>
> The current help page implements this by creating a helper function, binomial_smooth,  but using its example of the needed arguments I did just try:
>
>... + stat_smooth(method = 'glm', method.args = list(family = "binomial"))
>
>
>With success.
>
>-- 
>David.
>> 
>> I?d appreciate thoughts/pointers.
>> 
>> 
>> Nathan
>> 
>> -- 
>> Nathan Pace, MD, MStat
>> Department of Anesthesiology
>> University of Utah
>> 801.581.6393
>> n.l.pace at utah.edu
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA
>

From bgunter.4567 at gmail.com  Thu Jun 30 01:28:33 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 29 Jun 2016 16:28:33 -0700
Subject: [R] Bestglm subset analysis
In-Reply-To: <1349199120.3832843.1467224690440.JavaMail.yahoo@mail.yahoo.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<5e1da62cf6b94aa29105fa1ee82e0e19@UM-MAIL3216.unimaas.nl>
	<1349199120.3832843.1467224690440.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbRDWNnLTviG=Ac=9=P23cdr8P5OLpdPp_kLHtPJPe_Jkw@mail.gmail.com>

This is a statistics question, which is largely off topic on this
list. However, I'll give you a very brief OT response:

I would strongly suggest you consult a local statistician to explain
to why what you are doing is likely to result in complete nonsense
(best subset of 5 or 6 from 21 predictors on 79 cases). Failing that,
try asking on a statistics site, like stats.stackexchange.com.

Note also: This is a plain text list. Please don't post in HTML.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 29, 2016 at 11:24 AM, D Wolf via R-help
<r-help at r-project.org> wrote:
> Hello All,
> I am working on a linear regression model and trying to find the best subset of variables for my dataset. I have 21 predictors, 1 response variable, and 79 observations. I need to find the best 5 or 6 predictors for my model. I've used leaps for lm() and I'm now trying bestglm for glm(). I'm following this webpage, which gives the code below. https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html
> My code:library(bestglm)library(base)lbw.for.bestglm <- within(df_Chl, {y <- df_Chl$Chloro })res.bestglm <- bestglm(Xy = lbw.for.bestglm, family = gaussian, IC = "AIC", method = "exhaustive")
> # get coefficientsres.bestglm$BestModelsHere is a sample of my results (I removed the 5th through 21st predictors for brevity).> res.bestglm$BestModels    R21   R31   R32   R41 1 FALSE FALSE FALSE FALSE  2 FALSE  TRUE FALSE FALSE  3 FALSE FALSE FALSE FALSE 4 FALSE  TRUE FALSE FALSE 5 FALSE  TRUE FALSE FALSE  Criterion1  326.73272  326.95253  327.06594  327.09125  327.8208
> Is it correct to assume I should keep variables that are TRUE from 1 through 5? What do those five rows represent?
> I know the AIC criterion result should be as low as possible. Is it possible to discern a good result for any of the IC criterion results, such as AIC, LOOCV, BICg, etc..? If BIC returns lower Criterion results, does that mean I need to use the BIC subset instead of the subset from AIC?
> Thank You,
> Doug
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Thu Jun 30 02:38:43 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 30 Jun 2016 12:38:43 +1200
Subject: [R] Can I increase the size of an asterisk in plotmath()?
Message-ID: <6a5aecfe-c095-780f-ee9d-c47ace0e2e8f@auckland.ac.nz>


I am trying to plot an expression of the form "p^*" --- a bold letter p 
with the asterisk as a superscript.

I can get *something* with code of the form

plot(1:10)
text(7.5,2.5,expression(paste(bolditalic(p)^"*")))

but the asterisk that appears is *tiny*.

Is there any way to increase its size?  (I expect not, but I just 
thought I'd ask!)

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon at gmail.com  Thu Jun 30 03:17:32 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 30 Jun 2016 11:17:32 +1000
Subject: [R] Bestglm subset analysis
In-Reply-To: <1349199120.3832843.1467224690440.JavaMail.yahoo@mail.yahoo.com>
References: <a797d93a-c2b8-4943-5f11-7c67c47f2f91@gmail.com>
	<5e1da62cf6b94aa29105fa1ee82e0e19@UM-MAIL3216.unimaas.nl>
	<1349199120.3832843.1467224690440.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fUO_nATWO1jVQyvVnZw8GPTi=NjXzm66=E6hbhgn6YwJA@mail.gmail.com>

Hi Doug,
To expand a bit on what Bert has written, all the the "best
subset/best model" procedures use random variation in the dataset to
produce a result. This means that you will almost certainly include
variables in your "best model" that cannot be replicated. Sometimes
you can see this as a variable that shouldn't make any difference to
the response variable on the basis of current knowledge is included.
You can often identify such problems with replication. Whenever you
use an automated procedure like this, it's up to you to provide
evidence that the result is not peculiar to the dataset, especially
when there are many measures taken, but on few cases.

Jim


On Thu, Jun 30, 2016 at 4:24 AM, D Wolf via R-help <r-help at r-project.org> wrote:
> Hello All,
> I am working on a linear regression model and trying to find the best subset of variables for my dataset. I have 21 predictors, 1 response variable, and 79 observations. I need to find the best 5 or 6 predictors for my model. I've used leaps for lm() and I'm now trying bestglm for glm(). I'm following this webpage, which gives the code below. https://rstudio-pubs-static.s3.amazonaws.com/2897_9220b21cfc0c43a396ff9abf122bb351.html
> My code:library(bestglm)library(base)lbw.for.bestglm <- within(df_Chl, {y <- df_Chl$Chloro })res.bestglm <- bestglm(Xy = lbw.for.bestglm, family = gaussian, IC = "AIC", method = "exhaustive")
> # get coefficientsres.bestglm$BestModelsHere is a sample of my results (I removed the 5th through 21st predictors for brevity).> res.bestglm$BestModels    R21   R31   R32   R41 1 FALSE FALSE FALSE FALSE  2 FALSE  TRUE FALSE FALSE  3 FALSE FALSE FALSE FALSE 4 FALSE  TRUE FALSE FALSE 5 FALSE  TRUE FALSE FALSE  Criterion1  326.73272  326.95253  327.06594  327.09125  327.8208
> Is it correct to assume I should keep variables that are TRUE from 1 through 5? What do those five rows represent?
> I know the AIC criterion result should be as low as possible. Is it possible to discern a good result for any of the IC criterion results, such as AIC, LOOCV, BICg, etc..? If BIC returns lower Criterion results, does that mean I need to use the BIC subset instead of the subset from AIC?
> Thank You,
> Doug
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Thu Jun 30 08:35:50 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 30 Jun 2016 08:35:50 +0200
Subject: [R] Antwort: Re: Antwort: Re: Antwort: Re: Installing from source
 on Windows 7: tibble [RE OPENED]
In-Reply-To: <39e820dd-635d-e9d6-4ad3-444438dfb657@gmail.com>
References: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>
	<00cd6609-5782-1d21-4221-5176f498f981@gmail.com>
	<OFBA78FB36.C394761D-ONC1257FE1.004E039D-C1257FE1.004E806C@lotus.hawesko.de>
	<efbcf687-38d8-f35e-b1bf-949ff0487789@gmail.com>
	<OF2A7ED79C.5360EFE0-ONC1257FE1.0050BCE4-C1257FE1.00516286@lotus.hawesko.de>
	<39e820dd-635d-e9d6-4ad3-444438dfb657@gmail.com>
Message-ID: <OFD698DD4E.746ED7C0-ONC1257FE2.00222D50-C1257FE2.00244756@lotus.hawesko.de>

Hi Duncan,

I would not have changed the COMPILED_BY option unless I thought I have 
to.

In my "C:\R-Project\Rtools\mingw_32\bin" I have 

c++.exe
g++.exe
gcc.exe
i686-w64-mingw32-c++.exe
i686-w64-mingw32-g++.exe
i686-w64-mingw32-gcc-4.9.3.exe
i686-w64-mingw32-gcc.exe

In my "C:\R-Project\Rtools\mingw_64\bin" I have

c++.exe
cpp.exe
g++.exe
gcc.exe
x86_64-w64-mingw32-c++.exe
x86_64-w64-mingw32-g++.exe
x86_64-w64-mingw32-gcc-4.9.3.exe
x86_64-w64-mingw32-gcc.exe

Which one should I configure and use?

Kind regards

Georg




Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help at r-project.org
Datum:  29.06.2016 17:34
Betreff:        Re: Antwort: Re: Antwort: Re: [R] Installing from source 
on Windows 7: tibble [SOLVED]



On 29/06/2016 10:48 AM, G.Maubach at weinwolf.de wrote:
> Hi Duncan,
>
> indeed, I did not see the other part of your message.
>
> I did
>
> BINPREF ?= C:/R-Project/Rtools/mingw_32/bin/
> COMPILED_BY = g++ # instead of gcc-4.9.3

I wouldn't change the COMPILED_BY; some packages use it to configure 
themselves for gcc-4.9.3, as opposed to the previous version gcc-4.6.3.

>
> in "C:\R-Project\R-3.3.0\etc\i386\Makeconf"
>
> and
>
> BINPREF ?= C:/R-Project/Rtools/mingw_64/bin/
> COMPILED_BY = g++ # instead of gcc-4.9.3
>
> in "C:\R-Project\R-3.3.0\etc\x64\Makeconf"
>
> Now I could compile the package with no futher errors.
>
> Messages are
>
> -- cut --
> * installing *source* package 'tibble' ...
> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> ** libs
>
> *** arch - i386
> C:/R-Project/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 
-c
> RcppExports.cpp -o RcppExports.o
> C:/R-Project/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 
-c
> matrixToDataFrame.cpp -o matrixToDataFrame.o
> C:/R-Project/Rtools/mingw_32/bin/g++ -shared -s -static-libgcc -o
> tibble.dll tmp.def RcppExports.o matrixToDataFrame.o
> -Ld:/Compiler/gcc-4.9.3/local330/lib/i386
> -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/R-PROJ~1/R-33~1.0/bin/i386 -lR
> installing to C:/R-Project/R-3.3.0/library/tibble/libs/i386
>
> *** arch - x64
> C:/R-Project/Rtools/mingw_64/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 
-c
> RcppExports.cpp -o RcppExports.o
> C:/R-Project/Rtools/mingw_64/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2 
-c
> matrixToDataFrame.cpp -o matrixToDataFrame.o
> C:/R-Project/Rtools/mingw_64/bin/g++ -shared -s -static-libgcc -o
> tibble.dll tmp.def RcppExports.o matrixToDataFrame.o
> -Ld:/Compiler/gcc-4.9.3/local330/lib/x64
> -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/R-PROJ~1/R-33~1.0/bin/x64 -lR
> installing to C:/R-Project/R-3.3.0/library/tibble/libs/x64
> ** R
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> *** arch - i386
> *** arch - x64
> * DONE (tibble)
> -- cut --
>
> So - complete success.
>
> Many thanks for your help.
>
> One last questions: Why did Rtools.exe not create a directory named
> "gcc-4.9.3" in "C:\R-Project\Rtools" and putting"
> C:\R-Project\Rtools\mingw_32" and "C:\R-Project\Rtools\mingw_64" 
directly
> in "C:\R-Project\Rtools\"? gcc-4.6.3 was installed that way.

The 4.6.3 compiler was compiled for "multilib" operation:  the same 
compiler took command line options to distinguish between 32 bit and 64 
bit compiles.  The newer version doesn't support that, so we need two 
separate installs.

Duncan Murdoch

> Kind regards
>
> Georg
>
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help at r-project.org
> Datum:  29.06.2016 16:21
> Betreff:        Re: Antwort: Re: [R] Installing from source on Windows 
7:
> tibble
>
>
>
> On 29/06/2016 10:17 AM, G.Maubach at weinwolf.de wrote:
> > Hi Duncan,
> >
> > many thanks for your reply.
> >
> > I did insert die paths to the g++ compiler because I got the message
> about
> > the not existent compiler.
> >
> > I took the directories for the compiler out again:
> >
> > C:\R-Project\Rtools\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program
> > Files\Python 3.5\Scripts\;C:\Program Files\Python
> > 3.5\;C:\Python27\;C:\Python27\Scripts, etc. etc.
> >
> > Calling
> >
> > install.packages("tibble", type  = "source")
> >
> >
> > gives this message:
> >
> > -- cut --
> > * installing *source* package 'tibble' ...
> > ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> > ** libs
> >
> > *** arch - i386
> > c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
> > -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> > -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c
> > RcppExports.cpp -o RcppExports.o
> > c:/Rtools/mingw_32/bin/g++: not found
> > make: *** [RcppExports.o] Error 127
> > Warnung: Ausf?hrung von Kommando 'make -f
> > "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> > "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> > SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> > SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
> > Status 2
> > ERROR: compilation failed for package 'tibble'
> > * removing 'C:/R-Project/R-3.3.0/library/tibble'
> > * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> > Warning in install.packages :
> >    running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> > "C:\R-Project\R-3.3.0\library"
> >
> 
C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\RtmpGqOlOW/downloaded_packages/tibble_1.0.tar.gz'
> > had status 1
> > Warning in install.packages :
> >    installation of package ?tibble? had non-zero exit status
> > -- cut --
> >
> > What else could I do?
>
> You seem to have missed the second part of my advice, describing what to
> do with the two Makeconf files.
>
> Duncan Murdoch
>
> >
> > Kind regards
> >
> > Georg
> >
> >
> >
> >
> >
> > Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> > An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> > Datum:  29.06.2016 13:07
> > Betreff:        Re: [R] Installing from source on Windows 7: tibble
> >
> >
> >
> > On 29/06/2016 5:49 AM, G.Maubach at weinwolf.de wrote:
> > > Hi All,
> > >
> > > I would like to install R packages from source on Windows 7 64-Bit.
> > > Currently my settings are:
> > >
> > > -- cut --
> > >> sessionInfo()
> > > R version 3.3.0 (2016-05-03)
> > > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > > Running under: Windows 7 x64 (build 7601) Service Pack 1
> > >
> > > locale:
> > > [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> > > [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> > > [5] LC_TIME=German_Germany.1252
> > >
> > > attached base packages:
> > > [1] stats     graphics  grDevices utils     datasets  methods   base
> > >
> > > loaded via a namespace (and not attached):
> > > [1] tools_3.3.0
> > > -- cut --
> > >
> > > The environment variable PATH on Windows 7 is set to:
> > >
> > >
> >
> 
C:\R-Project\Rtools\mingw_32\bin;C:\R-Project\Rtools\mingw_64\bin;C:\R-Project\Rtools\bin;C:\R-Project\Rtools\gcc-4.6.3\bin;C:\Program
> > > Files\Python 3.5\Scripts\;C:\Program Files\Python
> > > 3.5\;C:\Python27\;C:\Python27\Scripts; etc. etc.
> >
> > Take the mingw_32, mingw_64 and gcc-4.6.3 directories off your path.
> > They aren't needed; the first two could conceivably be harmful.
> >
> > >
> > > RTools is installed in C:\R-Project\RTools
> > >
> > > The call of
> > >
> > > C:\R-Project\Rtools\mingw_64\bin\g++.exe --version
> > >
> > > results in
> > >
> > > g++ (x86_64-posix-seh, Built by MinGW-W64 project) 4.9.3
> > >
> > > If I do
> > >
> > >
> > >> install.packages("tibble", type = "source")
> > >
> > > I get
> > >
> > > -- cut --
> > > trying URL
> 'https://cran.uni-muenster.de/src/contrib/tibble_1.0.tar.gz'
> > > Content type 'application/x-gzip' length 38038 bytes (37 KB)
> > > downloaded 37 KB
> > >
> > > * installing *source* package 'tibble' ...
> > > ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
> > > ** libs
> > >
> > > *** arch - i386
> > > c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" 
-DNDEBUG
> > > -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
> > > -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall 
-mtune=core2
> > -c
> > > RcppExports.cpp -o RcppExports.o
> > > c:/Rtools/mingw_32/bin/g++: not found
> > > make: *** [RcppExports.o] Error 127
> > > Warnung: Ausf?hrung von Kommando 'make -f
> > > "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
> > > "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
> > > SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
> > > SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' 
ergab
> > > Status 2
> > > ERROR: compilation failed for package 'tibble'
> > > * removing 'C:/R-Project/R-3.3.0/library/tibble'
> > > * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
> > > Warning in install.packages :
> > >   running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
> > > "C:\R-Project\R-3.3.0\library"
> > >
> >
> 
C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\Rtmp23SQxM/downloaded_packages/tibble_1.0.tar.gz'
> > > had status 1
> > > Warning in install.packages :
> > >   installation of package ?tibble? had non-zero exit status
> > > -- cut --
> > >
> > > There is no make.conf in "C:\R-Project\Rtools\mingw_64\etc". I found 
"
> > > Makeconf" in "C:\R-Project\R-3.3.0\etc\x64". Do I need it? How do I
> need
> > > to configure the settings in this file?
> >
> > Yes, since you haven't installed Rtools in the default location, you
> > should edit two Makeconf files.  In
> > C:\R-Project\R-3.3.0\etc\x64\Makeconf, you want
> >
> > BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_64/bin/
> >
> > and in C:\R-Project\R-3.3.0\etc\i386\Makeconf you want
> >
> > BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_32/bin/
> >
> > You need to make sure you don't have an environment variable named
> > BINPREF defined, or it will override these settings.  (If you were
> > building just one architecture, you could do the setting by 
environment
> > variable, but not if you are trying to build both archs in one call.)
> >
> > Duncan Murdoch
> >
> > >
> > > I searched old aunt Google but did not understand what to do and how
> to
> > > configure R environment variables correctly.
> > >
> > > What do I need to do to install packages from source?
> > >
> > > Kind regards
> > >
> > > Georg
> > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> >
>
>
>




From dutangc at gmail.com  Thu Jun 30 09:22:06 2016
From: dutangc at gmail.com (Christophe Dutang)
Date: Thu, 30 Jun 2016 09:22:06 +0200
Subject: [R] linking vignettes in a man page
In-Reply-To: <789d0613-0371-b034-b454-4dcbb911f1ba@gmail.com>
References: <964C15FE-9C8D-46A7-8E37-476C09102472@gmail.com>
	<789d0613-0371-b034-b454-4dcbb911f1ba@gmail.com>
Message-ID: <EFC867CD-CB8F-42F0-9840-3240D02CC18B@gmail.com>

Thanks both to your answer. 

In my case, I link both html and pdf vignetttes with \href, typically  \href{../doc/FAQ.html}{Frequently Asked Questions}.

Maybe Duncan, you could add your answer based on \url{../doc/<name>} and \url{../../<pkg>/help/<alias>} as a complement in Section 2.5 of Writing R extensions?

I spent quite a lot of time searching how to do this.

Regards, Christophe
---------------------------------------
Christophe Dutang
LMM, UdM, Le Mans, France
web: http://dutangc.free.fr <http://dutangc.free.fr/>
> Le 29 juin 2016 ? 23:27, Duncan Murdoch <murdoch.duncan at gmail.com> a ?crit :
> 
> On 29/06/2016 4:49 PM, Christophe Dutang wrote:
>> Dear list,
>> 
>> How can I link a vignette of a package in a man page (Rd files)?
>> 
>> I try \link[=pkgname/doc/filename]{a name} without success.
>> 
>> The link gives the following error message: Only help files, NEWS, DESCRIPTION and files under doc/ and demo/ in a package can be viewed
> 
> 
> You can give \url{} style links, for example the grid package has
> 
> \url{../doc/grid.pdf}
> 
> in the package?grid help topic.  Similarly, ../../<pkg>/help/<alias> will link from a vignette to help topic ?alias.
> 
> Duncan Murdoch
> 
> 
> 


	[[alternative HTML version deleted]]


From goran.brostrom at umu.se  Thu Jun 30 09:38:14 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Thu, 30 Jun 2016 09:38:14 +0200
Subject: [R] Can I increase the size of an asterisk in plotmath()?
In-Reply-To: <6a5aecfe-c095-780f-ee9d-c47ace0e2e8f@auckland.ac.nz>
References: <6a5aecfe-c095-780f-ee9d-c47ace0e2e8f@auckland.ac.nz>
Message-ID: <dd6eba2b-f08d-8be1-19da-dfaacb68607a@umu.se>

Rolf,

text(7.5,2.5,expression(paste(bolditalic(p),"*", sep = "")))

looks quite nice. On my Mac at least.

G?ran

On 30/06/16 02:38, Rolf Turner wrote:
>
> I am trying to plot an expression of the form "p^*" --- a bold letter p
> with the asterisk as a superscript.
>
> I can get *something* with code of the form
>
> plot(1:10)
> text(7.5,2.5,expression(paste(bolditalic(p)^"*")))
>
> but the asterisk that appears is *tiny*.
>
> Is there any way to increase its size?  (I expect not, but I just
> thought I'd ask!)
>
> cheers,
>
> Rolf Turner
>


From petr.pikal at precheza.cz  Thu Jun 30 10:08:09 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 30 Jun 2016 08:08:09 +0000
Subject: [R] a new df with one combined column
In-Reply-To: <d0dafe425f1348f1b3df05b3ac4193e0@exch-2p-mbx-t2.ads.tamu.edu>
References: <213311750.5859189.1467205730821.JavaMail.yahoo.ref@mail.yahoo.com>
	<213311750.5859189.1467205730821.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOysAbw8Yy7XG13QVktkpAjA9J350UMteLQ9S1Khgv9CA@mail.gmail.com>
	<d0dafe425f1348f1b3df05b3ac4193e0@exch-2p-mbx-t2.ads.tamu.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5033180@SRVEXCHMBX.precheza.cz>

Hi.

Hm. As OP has the variables in data frame, I think that the first answer by Ulrik was correct. However different class of those two columns prevents merge to result in one column.

After

df1$License is changed propperly to numeric.

df.merge <- merge(df1, df2, by.x="License", by.y="Diff", all=TRUE)

should result in one merged data frame with combined License/Diff column.

Cheers
Petr

P.S. I noticed that mode and typeof help pages does not have any pointer to class help page, OTOH class help page directs to mode. Maybe link to class could be added to mode help page.



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L
> Carlson
> Sent: Wednesday, June 29, 2016 4:10 PM
> To: Ulrik Stervbo <ulrik.stervbo at gmail.com>; chalabi.elahe at yahoo.de; R-
> help Mailing List <r-help at r-project.org>
> Subject: Re: [R] a new df with one combined column
>
> It looks like License was imported as character data and converted to a factor.
> I'm not sure I understand what you want, but to make them into a single
> column, you need to convert the factor back to numeric using
> as.numeric(as.character(License)), but you use the command levels(License)
> to look at the 384 values in License to be sure there are no non-numeric
> characters, e.g. 41,001. I there are, you will have to remove them.
>
> > set.seed(42)
> > License <- sample(40000:49999, 25)
> > License <- factor(as.character(License))
> > str(License)
>  Factor w/ 25 levels "40822","41172",..: 19 21 6 17 12 10 16 3 13 14 ...
> > Diff <- sample(40000:49999, 25)
> > str(Diff)
>  int [1:25] 45142 43901 49055 44468 48356 47372 48105 43878 46846 40039 ...
> > Combined <- c(as.numeric(as.character(License)), Diff)
> > str(Combined)
>  num [1:50] 49148 49369 42860 48301 46414 ...
> > Combined
>  [1] 49148 49369 42860 48301 46414 45188 47361 41345 46564 47044 44572
> 47183 49335 42550 [15] 44616 49386 49766 41172 44741 45592 49022 41384
> 49867 49444 40822 45142 43901 49055 [29] 44468 48356 47372 48105 43878
> 46846 40039 48320 40073 42074 49054 46109 43789 44350 [43] 40373 49717
> 44309 49556 48858 46385 49687 46173
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ulrik
> Stervbo
> Sent: Wednesday, June 29, 2016 8:35 AM
> To: chalabi.elahe at yahoo.de; R-help Mailing List
> Subject: Re: [R] a new df with one combined column
>
> It looks like the function you are searching for is merge()
>
> HTH
> Ulrik
>
> On Wed, 29 Jun 2016 at 15:11 ch.elahe via R-help <r-help at r-project.org>
> wrote:
>
> > Hi all,
> > I have this column as a part of df:
> >
> >     $License :   Factor W/384 levels
> > "41005","41006","41034","41097","41200",...
> > and I have other column which is a part of other df lets say df2:
> >
> >     $Diff    :   int  41166 41202 41290 41353 41503 41507 41548
> > these two columns df$License and df$Diff have different dimensions and
> > I want to make a new df that is combinations of both i.e. I want a
> > column which has both of these columns together as one column, but I
> > don't know how to bring these two column in one as a new df. Does
> > anyone know how should I do that?
> > Thanks for any help,
> > Elahe
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Jun 30 10:20:16 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 30 Jun 2016 08:20:16 +0000
Subject: [R] =?utf-8?b?ZGF0YS50YWJsZTog4oCcZ3JvdXAgY291bnRlcuKAnSB3aXRo?=
	=?utf-8?q?_NAs?=
In-Reply-To: <AMSPR07MB47008C9F30C298DEEADDD5CE2230@AMSPR07MB470.eurprd07.prod.outlook.com>
References: <AMSPR07MB47008C9F30C298DEEADDD5CE2230@AMSPR07MB470.eurprd07.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50331CE@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marine
> Regis
> Sent: Thursday, June 30, 2016 12:32 AM
> To: r-help at r-project.org
> Subject: [R] data.table: ?group counter? with NAs
>
> Hello,
>
> I would like to add a counter column in a data frame based on a set of
> identical rows. To do this, I tested:
>
> DF = data.table(x=c("a","a","a","b","c","d","e","f","f"),
> y=c(1,3,2,8,8,4,NA,NA,NA))
>
> DF[ , Index := .GRP, by = c("y") ]
>
> DF
>
>
>
> However, the rows with NAs are considered to be identical.

Why they shall not be considered identical if you consider rows 4 and 5 identical?

You can do

DF[ , Index := .GRP, by = c("x","y") ]

But in that case rows 4 and 5 are NOT identical.

So you should state your rules for identical rows a little bit more clearly.

Cheers
Petr


>
> So, how can I obtain:
>
>    x  y Index
>
> 1: a  1     1
>
> 2: a  3     2
>
> 3: a  2     3
>
> 4: b  8     4
>
> 5: c  8     4
>
> 6: d  4     5
>
> 7: e NA     6
>
> 8: f NA     7
>
> 9: f NA     8
>
>
>
> Instead of:
>
> x  y Index
>
> 1: a  1     1
>
> 2: a  3     2
>
> 3: a  2     3
>
> 4: b  8     4
>
> 5: c  8     4
>
> 6: d  4     5
>
> 7: e NA     6
>
> 8: f NA     6
>
> 9: f NA     6
>
>
>
>
>
> Thank you very much for your time.
>
> Have a nice day
>
> Marine
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From r.turner at auckland.ac.nz  Thu Jun 30 10:46:23 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 30 Jun 2016 20:46:23 +1200
Subject: [R] Can I increase the size of an asterisk in plotmath()?
In-Reply-To: <dd6eba2b-f08d-8be1-19da-dfaacb68607a@umu.se>
References: <6a5aecfe-c095-780f-ee9d-c47ace0e2e8f@auckland.ac.nz>
	<dd6eba2b-f08d-8be1-19da-dfaacb68607a@umu.se>
Message-ID: <eeb7ccc6-1e44-f665-530d-cd258a7128e8@auckland.ac.nz>

On 30/06/16 19:38, G?ran Brostr?m wrote:
> Rolf,
>
> text(7.5,2.5,expression(paste(bolditalic(p),"*", sep = "")))
>
> looks quite nice. On my Mac at least.

<SNIP>

Well, it didn't look nice on my laptop.  The asterisk was nearly invisible.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch.duncan at gmail.com  Thu Jun 30 11:29:32 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 30 Jun 2016 05:29:32 -0400
Subject: [R] Antwort: Re: Antwort: Re: Antwort: Re: Installing from
 source on Windows 7: tibble [RE OPENED]
In-Reply-To: <OFD698DD4E.746ED7C0-ONC1257FE2.00222D50-C1257FE2.00244756@lotus.hawesko.de>
References: <OF2BC5AC35.58563882-ONC1257FE1.0033F97E-C1257FE1.0035FBF7@lotus.hawesko.de>
	<00cd6609-5782-1d21-4221-5176f498f981@gmail.com>
	<OFBA78FB36.C394761D-ONC1257FE1.004E039D-C1257FE1.004E806C@lotus.hawesko.de>
	<efbcf687-38d8-f35e-b1bf-949ff0487789@gmail.com>
	<OF2A7ED79C.5360EFE0-ONC1257FE1.0050BCE4-C1257FE1.00516286@lotus.hawesko.de>
	<39e820dd-635d-e9d6-4ad3-444438dfb657@gmail.com>
	<OFD698DD4E.746ED7C0-ONC1257FE2.00222D50-C1257FE2.00244756@lotus.hawesko.de>
Message-ID: <549f6cc5-1b5b-d27b-415c-c18f24bff678@gmail.com>

On 30/06/2016 2:35 AM, G.Maubach at weinwolf.de wrote:
> Hi Duncan,
>
> I would not have changed the COMPILED_BY option unless I thought I have
> to.
>
> In my "C:\R-Project\Rtools\mingw_32\bin" I have
>
> c++.exe
> g++.exe
> gcc.exe
> i686-w64-mingw32-c++.exe
> i686-w64-mingw32-g++.exe
> i686-w64-mingw32-gcc-4.9.3.exe
> i686-w64-mingw32-gcc.exe
>
> In my "C:\R-Project\Rtools\mingw_64\bin" I have
>
> c++.exe
> cpp.exe
> g++.exe
> gcc.exe
> x86_64-w64-mingw32-c++.exe
> x86_64-w64-mingw32-g++.exe
> x86_64-w64-mingw32-gcc-4.9.3.exe
> x86_64-w64-mingw32-gcc.exe
>
> Which one should I configure and use?

You don't choose that, the Makefiles in R (or in your package, if you 
have one) chooses.  The COMPILED_BY definition is not involved in that 
decision.

Duncan Murdoch
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
> An:     G.Maubach at weinwolf.de,
> Kopie:  r-help at r-project.org
> Datum:  29.06.2016 17:34
> Betreff:        Re: Antwort: Re: Antwort: Re: [R] Installing from source
> on Windows 7: tibble [SOLVED]
>
>
>
> On 29/06/2016 10:48 AM, G.Maubach at weinwolf.de wrote:
>> Hi Duncan,
>>
>> indeed, I did not see the other part of your message.
>>
>> I did
>>
>> BINPREF ?= C:/R-Project/Rtools/mingw_32/bin/
>> COMPILED_BY = g++ # instead of gcc-4.9.3
>
> I wouldn't change the COMPILED_BY; some packages use it to configure
> themselves for gcc-4.9.3, as opposed to the previous version gcc-4.6.3.
>
>>
>> in "C:\R-Project\R-3.3.0\etc\i386\Makeconf"
>>
>> and
>>
>> BINPREF ?= C:/R-Project/Rtools/mingw_64/bin/
>> COMPILED_BY = g++ # instead of gcc-4.9.3
>>
>> in "C:\R-Project\R-3.3.0\etc\x64\Makeconf"
>>
>> Now I could compile the package with no futher errors.
>>
>> Messages are
>>
>> -- cut --
>> * installing *source* package 'tibble' ...
>> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
>> ** libs
>>
>> *** arch - i386
>> C:/R-Project/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
>> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c
>> RcppExports.cpp -o RcppExports.o
>> C:/R-Project/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
>> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c
>> matrixToDataFrame.cpp -o matrixToDataFrame.o
>> C:/R-Project/Rtools/mingw_32/bin/g++ -shared -s -static-libgcc -o
>> tibble.dll tmp.def RcppExports.o matrixToDataFrame.o
>> -Ld:/Compiler/gcc-4.9.3/local330/lib/i386
>> -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/R-PROJ~1/R-33~1.0/bin/i386 -lR
>> installing to C:/R-Project/R-3.3.0/library/tibble/libs/i386
>>
>> *** arch - x64
>> C:/R-Project/Rtools/mingw_64/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
>> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c
>> RcppExports.cpp -o RcppExports.o
>> C:/R-Project/Rtools/mingw_64/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
>> -DNDEBUG    -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
> -c
>> matrixToDataFrame.cpp -o matrixToDataFrame.o
>> C:/R-Project/Rtools/mingw_64/bin/g++ -shared -s -static-libgcc -o
>> tibble.dll tmp.def RcppExports.o matrixToDataFrame.o
>> -Ld:/Compiler/gcc-4.9.3/local330/lib/x64
>> -Ld:/Compiler/gcc-4.9.3/local330/lib -LC:/R-PROJ~1/R-33~1.0/bin/x64 -lR
>> installing to C:/R-Project/R-3.3.0/library/tibble/libs/x64
>> ** R
>> ** inst
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>> ** building package indices
>> ** installing vignettes
>> ** testing if installed package can be loaded
>> *** arch - i386
>> *** arch - x64
>> * DONE (tibble)
>> -- cut --
>>
>> So - complete success.
>>
>> Many thanks for your help.
>>
>> One last questions: Why did Rtools.exe not create a directory named
>> "gcc-4.9.3" in "C:\R-Project\Rtools" and putting"
>> C:\R-Project\Rtools\mingw_32" and "C:\R-Project\Rtools\mingw_64"
> directly
>> in "C:\R-Project\Rtools\"? gcc-4.6.3 was installed that way.
>
> The 4.6.3 compiler was compiled for "multilib" operation:  the same
> compiler took command line options to distinguish between 32 bit and 64
> bit compiles.  The newer version doesn't support that, so we need two
> separate installs.
>
> Duncan Murdoch
>
>> Kind regards
>>
>> Georg
>>
>>
>>
>>
>>
>> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
>> An:     G.Maubach at weinwolf.de,
>> Kopie:  r-help at r-project.org
>> Datum:  29.06.2016 16:21
>> Betreff:        Re: Antwort: Re: [R] Installing from source on Windows
> 7:
>> tibble
>>
>>
>>
>> On 29/06/2016 10:17 AM, G.Maubach at weinwolf.de wrote:
>>> Hi Duncan,
>>>
>>> many thanks for your reply.
>>>
>>> I did insert die paths to the g++ compiler because I got the message
>> about
>>> the not existent compiler.
>>>
>>> I took the directories for the compiler out again:
>>>
>>> C:\R-Project\Rtools\bin;C:\ProgramData\Oracle\Java\javapath;C:\Program
>>> Files\Python 3.5\Scripts\;C:\Program Files\Python
>>> 3.5\;C:\Python27\;C:\Python27\Scripts, etc. etc.
>>>
>>> Calling
>>>
>>> install.packages("tibble", type  = "source")
>>>
>>>
>>> gives this message:
>>>
>>> -- cut --
>>> * installing *source* package 'tibble' ...
>>> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
>>> ** libs
>>>
>>> *** arch - i386
>>> c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include" -DNDEBUG
>>> -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
>>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall  -mtune=core2
>> -c
>>> RcppExports.cpp -o RcppExports.o
>>> c:/Rtools/mingw_32/bin/g++: not found
>>> make: *** [RcppExports.o] Error 127
>>> Warnung: Ausf?hrung von Kommando 'make -f
>>> "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
>>> "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
>>> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
>>> SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"' ergab
>>> Status 2
>>> ERROR: compilation failed for package 'tibble'
>>> * removing 'C:/R-Project/R-3.3.0/library/tibble'
>>> * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
>>> Warning in install.packages :
>>>    running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
>>> "C:\R-Project\R-3.3.0\library"
>>>
>>
> C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\RtmpGqOlOW/downloaded_packages/tibble_1.0.tar.gz'
>>> had status 1
>>> Warning in install.packages :
>>>    installation of package ?tibble? had non-zero exit status
>>> -- cut --
>>>
>>> What else could I do?
>>
>> You seem to have missed the second part of my advice, describing what to
>> do with the two Makeconf files.
>>
>> Duncan Murdoch
>>
>>>
>>> Kind regards
>>>
>>> Georg
>>>
>>>
>>>
>>>
>>>
>>> Von:    Duncan Murdoch <murdoch.duncan at gmail.com>
>>> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
>>> Datum:  29.06.2016 13:07
>>> Betreff:        Re: [R] Installing from source on Windows 7: tibble
>>>
>>>
>>>
>>> On 29/06/2016 5:49 AM, G.Maubach at weinwolf.de wrote:
>>>> Hi All,
>>>>
>>>> I would like to install R packages from source on Windows 7 64-Bit.
>>>> Currently my settings are:
>>>>
>>>> -- cut --
>>>>> sessionInfo()
>>>> R version 3.3.0 (2016-05-03)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>>>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=German_Germany.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_3.3.0
>>>> -- cut --
>>>>
>>>> The environment variable PATH on Windows 7 is set to:
>>>>
>>>>
>>>
>>
> C:\R-Project\Rtools\mingw_32\bin;C:\R-Project\Rtools\mingw_64\bin;C:\R-Project\Rtools\bin;C:\R-Project\Rtools\gcc-4.6.3\bin;C:\Program
>>>> Files\Python 3.5\Scripts\;C:\Program Files\Python
>>>> 3.5\;C:\Python27\;C:\Python27\Scripts; etc. etc.
>>>
>>> Take the mingw_32, mingw_64 and gcc-4.6.3 directories off your path.
>>> They aren't needed; the first two could conceivably be harmful.
>>>
>>>>
>>>> RTools is installed in C:\R-Project\RTools
>>>>
>>>> The call of
>>>>
>>>> C:\R-Project\Rtools\mingw_64\bin\g++.exe --version
>>>>
>>>> results in
>>>>
>>>> g++ (x86_64-posix-seh, Built by MinGW-W64 project) 4.9.3
>>>>
>>>> If I do
>>>>
>>>>
>>>>> install.packages("tibble", type = "source")
>>>>
>>>> I get
>>>>
>>>> -- cut --
>>>> trying URL
>> 'https://cran.uni-muenster.de/src/contrib/tibble_1.0.tar.gz'
>>>> Content type 'application/x-gzip' length 38038 bytes (37 KB)
>>>> downloaded 37 KB
>>>>
>>>> * installing *source* package 'tibble' ...
>>>> ** Paket 'tibble' erfolgreich entpackt und MD5 Summen ?berpr?ft
>>>> ** libs
>>>>
>>>> *** arch - i386
>>>> c:/Rtools/mingw_32/bin/g++  -I"C:/R-PROJ~1/R-33~1.0/include"
> -DNDEBUG
>>>> -I"C:/R-Project/R-3.3.0/library/Rcpp/include"
>>>> -I"d:/Compiler/gcc-4.9.3/local330/include"     -O2 -Wall
> -mtune=core2
>>> -c
>>>> RcppExports.cpp -o RcppExports.o
>>>> c:/Rtools/mingw_32/bin/g++: not found
>>>> make: *** [RcppExports.o] Error 127
>>>> Warnung: Ausf?hrung von Kommando 'make -f
>>>> "C:/R-PROJ~1/R-33~1.0/etc/i386/Makeconf" -f
>>>> "C:/R-PROJ~1/R-33~1.0/share/make/winshlib.mk"
>>>> SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
>>>> SHLIB="tibble.dll" OBJECTS="RcppExports.o matrixToDataFrame.o"'
> ergab
>>>> Status 2
>>>> ERROR: compilation failed for package 'tibble'
>>>> * removing 'C:/R-Project/R-3.3.0/library/tibble'
>>>> * restoring previous 'C:/R-Project/R-3.3.0/library/tibble'
>>>> Warning in install.packages :
>>>>   running command '"C:/R-PROJ~1/R-33~1.0/bin/x64/R" CMD INSTALL -l
>>>> "C:\R-Project\R-3.3.0\library"
>>>>
>>>
>>
> C:\Users\MAUBAC~1.WEI\AppData\Local\Temp\Rtmp23SQxM/downloaded_packages/tibble_1.0.tar.gz'
>>>> had status 1
>>>> Warning in install.packages :
>>>>   installation of package ?tibble? had non-zero exit status
>>>> -- cut --
>>>>
>>>> There is no make.conf in "C:\R-Project\Rtools\mingw_64\etc". I found
> "
>>>> Makeconf" in "C:\R-Project\R-3.3.0\etc\x64". Do I need it? How do I
>> need
>>>> to configure the settings in this file?
>>>
>>> Yes, since you haven't installed Rtools in the default location, you
>>> should edit two Makeconf files.  In
>>> C:\R-Project\R-3.3.0\etc\x64\Makeconf, you want
>>>
>>> BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_64/bin/
>>>
>>> and in C:\R-Project\R-3.3.0\etc\i386\Makeconf you want
>>>
>>> BINPREF ?= c:/R-project/Rtools/gcc-4.9.3/mingw_32/bin/
>>>
>>> You need to make sure you don't have an environment variable named
>>> BINPREF defined, or it will override these settings.  (If you were
>>> building just one architecture, you could do the setting by
> environment
>>> variable, but not if you are trying to build both archs in one call.)
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> I searched old aunt Google but did not understand what to do and how
>> to
>>>> configure R environment variables correctly.
>>>>
>>>> What do I need to do to install packages from source?
>>>>
>>>> Kind regards
>>>>
>>>> Georg
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>
>>
>>
>
>
>


From p_connolly at slingshot.co.nz  Thu Jun 30 11:37:43 2016
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Thu, 30 Jun 2016 21:37:43 +1200
Subject: [R] > Understanding strip.default & strip.custom
In-Reply-To: <CAGxFJbQ88+Ok9z1WdRBxLv5Mmj2Bu3AA8pH_aAa18=Uc7e9=+g@mail.gmail.com>
References: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>
	<CAGxFJbTVAG7kEv6eLLAu2eVn-2QJgVMrBF_SSSE4=hMKKmCTWA@mail.gmail.com>
	<20160629082930.GA16087@slingshot.co.nz>
	<CAGxFJbQ88+Ok9z1WdRBxLv5Mmj2Bu3AA8pH_aAa18=Uc7e9=+g@mail.gmail.com>
Message-ID: <20160630093743.GB16087@slingshot.co.nz>

On Wed, 29-Jun-2016 at 07:57AM -0700, Bert Gunter wrote:

|> Did you mean: strip.custom(factor.levels...)  ?
|> 

Aaamm yes.  Must stop doing this stuff so late.............


|> (I know of no "panel.custom()" function)
|> 
|> 
|> -- Bert
|> Bert Gunter
|> 
|> "The trouble with having an open mind is that people keep coming along
|> and sticking things into it."
|> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
|> 
|> 
|> On Wed, Jun 29, 2016 at 1:29 AM, Patrick Connolly
|> <p_connolly at slingshot.co.nz> wrote:
|> > On Mon, 27-Jun-2016 at 10:17PM -0700, Bert Gunter wrote:
|> >
|> > [...]
|> >
|> > |>
|> > |> You seem to be making this way more difficult than you should.
|> >
|> > Though I didn't get any closer to an understanding of which.panel, the
|> > question I asked was simply answered by
|> >
|> > panel.custom(factor.levels = <as before>)
|> >
|> > Thanks to Duncan Mackay also.
|> >
|> > --
|> > ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >    ___    Patrick Connolly
|> >  {~._.~}                   Great minds discuss ideas
|> >  _( Y )_                 Average minds discuss events
|> > (:_~*~_:)                  Small minds discuss people
|> >  (_)-(_)                              ..... Eleanor Roosevelt
|> >
|> > ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From p_connolly at slingshot.co.nz  Thu Jun 30 11:41:04 2016
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Thu, 30 Jun 2016 21:41:04 +1200
Subject: [R] > Understanding strip.default & strip.custom
In-Reply-To: <000001d1d1ff$e4c35fd0$ae4a1f70$@bigpond.com>
References: <93f93263ddad3b1874d1cc75eae31d7a@slingshot.co.nz>
	<CAGxFJbTVAG7kEv6eLLAu2eVn-2QJgVMrBF_SSSE4=hMKKmCTWA@mail.gmail.com>
	<20160629082930.GA16087@slingshot.co.nz>
	<000001d1d1ff$e4c35fd0$ae4a1f70$@bigpond.com>
Message-ID: <20160630094104.GC16087@slingshot.co.nz>

On Wed, 29-Jun-2016 at 10:15PM +1000, Duncan Mackay wrote:

|> Patrick
|> 
|> Have a look at 
|> https://stat.ethz.ch/pipermail/r-help/2006-August/110621.html
|> and
|> https://stat.ethz.ch/pipermail/r-help/2008-June/165279.html
|> 
|> I remember working it out with an example but I cannot remember any of the
|> details

It would be amazing for anyone to remember those details. ;-)



|> 
|> Regards
|> 
|> Duncan
|> 
|> 
|> -----Original Message-----
|> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Patrick
|> Connolly
|> Sent: Wednesday, 29 June 2016 18:30
|> To: Bert Gunter
|> Cc: r-help at stat.math.ethz.ch
|> Subject: Re: [R] > Understanding strip.default & strip.custom
|> 
|> On Mon, 27-Jun-2016 at 10:17PM -0700, Bert Gunter wrote:
|> 
|> [...]
|> 
|> |> 
|> |> You seem to be making this way more difficult than you should.
|> 
|> Though I didn't get any closer to an understanding of which.panel, the
|> question I asked was simply answered by
|> 
|> panel.custom(factor.levels = <as before>)
|> 
|> Thanks to Duncan Mackay also.
|> 
|> -- 
|> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
|>    ___    Patrick Connolly   
|>  {~._.~}                   Great minds discuss ideas    
|>  _( Y )_  	         Average minds discuss events 
|> (:_~*~_:)                  Small minds discuss people  
|>  (_)-(_)  	                      ..... Eleanor Roosevelt
|> 	  
|> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From nilesh.dighe at monsanto.com  Thu Jun 30 14:02:05 2016
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Thu, 30 Jun 2016 12:02:05 +0000
Subject: [R] Understanding and predict round-off errors sign on simple
 functions
In-Reply-To: <F53BA2E3-7B45-431F-A1A8-7571E8C7A853@me.com>
References: <002e01d1d1ec$70c99080$525cb180$@laposte.net>
	<CAGxFJbRoPRFtBLXu+_uvW6MjPRCd-W1o2n3vNKhJwbWS+TBqVg@mail.gmail.com>
	<F53BA2E3-7B45-431F-A1A8-7571E8C7A853@me.com>
Message-ID: <24156952D190E841BF8E66CB59FAB94A4DE7C2AE@STLWEXMBXPRD14.na.ds.monsanto.com>

Using "runmean" function from caTools package within your SMA function appears to solve the issue.  Please see details below.

library(caTools)

> dput(m)
structure(c(-0.626453810742332, 0.183643324222082, -0.835628612410047, 
1.59528080213779, 0.329507771815361, -0.820468384118015, 0.487429052428485, 
0.738324705129217, 0.575781351653492, -0.305388387156356, 3.51178116845085, 
2.38984323641143, 1.3787594194582, -0.2146998871775, 3.12493091814311, 
1.95506639098477, 1.98380973690105, 2.9438362106853, 2.82122119509809, 
2.59390132121751, 5.91897737160822, 5.78213630073107, 5.07456498336519, 
3.01064830413663, 5.61982574789471, 4.943871260471, 4.84420449329467, 
3.52924761610073, 4.52184994489138, 5.4179415601997), .Dim = c(10L, 
3L))


> dput(SMA)
function (x, n = 10, ...) 
{
    ma <- runmean(x, n)
    if (!is.null(dim(ma))) {
        colnames(ma) <- "SMA"
    }
    return(ma)
}


mma <- apply(m, 2, SMA, n=1)

results<-mma-m

> dput(results)
structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(10L, 3L))


Nilesh
-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc Schwartz
Sent: Wednesday, June 29, 2016 1:07 PM
To: Bert Gunter
Cc: R-help
Subject: Re: [R] Understanding and predict round-off errors sign on simple functions

Hi,

Just to augment Bert's comments, I presume that you are aware of the relevant R FAQ:

  https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

That you had an expectation of the difference being 0 suggested to me that you might not be, but my apologies if that is not the case.

That being said, there are some higher precision CRAN packages that may offer some additional functionality, with the potential limitations that Bert references below. More information is available in the Numerical Mathematics CRAN Task View:

  https://cran.r-project.org/web/views/NumericalMathematics.html

In addition, with the caveat that I have not used it, there is the 'propagate' package on CRAN that may be relevant to what you want to be able to anticipate, at some level:

  https://cran.r-project.org/web/packages/propagate/index.html

It has not been updated in a while and there are some notes for the CRAN package checks, that suggest that the maintainer may not be active at this point.

Regards,

Marc


> On Jun 29, 2016, at 10:13 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I am certainly no expert, but I would assume that:
> 
> 1. Roundoff errors depend on the exact numerical libraries and 
> versions that are used, and so general language comparisons are 
> impossible without that information;
> 
> 2. Roundoff errors depend on the exact calculations being done and 
> machine precision and are very complicated to determine
> 
> So I would say the answer to your questions is no.
> 
> But you should probably address such a question to a numerical analyst 
> for an authoritative answer. Maybe try stats.stackexchange.com  .
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Jun 29, 2016 at 2:55 AM, Sirhc via R-help <r-help at r-project.org> wrote:
>> Hi,
>> 
>> 
>> 
>> May be it is a basic thing but I would like to know if we can 
>> anticipate round-off errors sign.
>> 
>> 
>> 
>> Here is an example :
>> 
>> 
>> 
>> # numerical matrix
>> 
>> m <- matrix(data=cbind(rnorm(10, 0), rnorm(10, 2), rnorm(10, 5)), 
>> nrow=10,
>> ncol=3)
>> 
>> 
>> 
>>> m
>> 
>>            [,1]      [,2]     [,3]
>> 
>> [1,]  0.4816247 1.1973502 3.855641
>> 
>> [2,] -1.2174937 0.7356427 4.393279
>> 
>> [3,]  0.8504074 2.5286509 2.689196
>> 
>> [4,]  1.8048642 1.8580804 6.665237
>> 
>> [5,] -0.6749397 1.0944277 4.838608
>> 
>> [6,]  0.8252034 1.5595268 3.681695
>> 
>> [7,]  1.3002208 0.9582693 4.561577
>> 
>> [8,]  1.6950923 3.5677921 6.005078
>> 
>> [9,]  0.6509285 0.9025964 5.082288
>> 
>> [10,] -0.5676040 1.3281102 4.446451
>> 
>> 
>> 
>> #weird moving average of period 1 !
>> 
>> mma <- apply(m, 2, SMA, n=1)
>> 
>> 
>> 
>>> mma
>> 
>>            [,1]      [,2]     [,3]
>> 
>> [1,]         NA        NA       NA
>> 
>> [2,] -1.2174937 0.7356427 4.393279
>> 
>> [3,]  0.8504074 2.5286509 2.689196
>> 
>> [4,]  1.8048642 1.8580804 6.665237
>> 
>> [5,] -0.6749397 1.0944277 4.838608
>> 
>> [6,]  0.8252034 1.5595268 3.681695
>> 
>> [7,]  1.3002208 0.9582693 4.561577
>> 
>> [8,]  1.6950923 3.5677921 6.005078
>> 
>> [9,]  0.6509285 0.9025964 5.082288
>> 
>> [10,] -0.5676040 1.3281102 4.446451
>> 
>> 
>> 
>> 
>> 
>> #difference should be 0 but here is the result
>> 
>>> m - mma
>> 
>>               [,1]         [,2]          [,3]
>> 
>> [1,]            NA           NA            NA
>> 
>> [2,]  0.000000e+00 0.000000e+00 -8.881784e-16
>> 
>> [3,]  0.000000e+00 0.000000e+00 -8.881784e-16
>> 
>> [4,]  0.000000e+00 4.440892e-16 -8.881784e-16
>> 
>> [5,] -1.110223e-16 4.440892e-16 -8.881784e-16
>> 
>> [6,] -1.110223e-16 2.220446e-16 -4.440892e-16
>> 
>> [7,] -2.220446e-16 2.220446e-16  0.000000e+00
>> 
>> [8,] -2.220446e-16 0.000000e+00  0.000000e+00
>> 
>> [9,] -3.330669e-16 2.220446e-16 -8.881784e-16
>> 
>> [10,] -3.330669e-16 4.440892e-16 -8.881784e-16
>> 
>> 
>> 
>> SMA function use runMean
>> 
>> # TTR / R / MovingAverages.R
>> 
>> "SMA" <- function(x, n=10, ...) { # Simple Moving Average
>> 
>>   ma <- runMean( x, n )
>> 
>>   if(!is.null(dim(ma))) {
>> 
>>     colnames(ma) <- "SMA"
>> 
>>   }
>> 
>>  return(ma)
>> 
>> }
>> 
>> 
>> 
>> 
>> 
>> Can anyone explain me that round error type?
>> 
>> Is it possible to reproduce this same error generation in another 
>> language like C++ or C# ?
>> 
>> 
>> 
>> Thanks in advance for your answers
>> 
>> 
>> 
>> Regards
>> 
>> 
>> 
>> Chris

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
This email and any attachments were sent from a Monsanto email account and may contain confidential and/or privileged information. If you are not the intended recipient, please contact the sender and delete this email and any attachments immediately. Any unauthorized use, including disclosing, printing, storing, copying or distributing this email, is prohibited. All emails and attachments sent to or from Monsanto email accounts may be subject to monitoring, reading, and archiving by Monsanto, including its affiliates and subsidiaries, as permitted by applicable law. Thank you.


From G.Maubach at weinwolf.de  Thu Jun 30 14:34:28 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 30 Jun 2016 14:34:28 +0200
Subject: [R] Writing a formula to Excel
Message-ID: <OFD4FC08B0.DD7A26D4-ONC1257FE2.00445D55-C1257FE2.00451CC2@lotus.hawesko.de>

Hi All,

I am using excel.link to work seemslessly with Excel.

In addition to values, like numbers and strings, I would like to insert a 
full operational formula into a cell.


xlc["G14"] <- print(paste("=G9*100/G6"), quote = FALSE)


The strings is put into the cell, but the cell is not evaluated. Thus the 
string is show as result of the computation.

If I open that cell b pressing "F2" or by double-clicking the cell and 
pressing RETURN will start the evaluation of the expession.


xlc["G14"] <- parse("=G9*100/G6") # does not run


How can I put a formula into Excel that is evaluated right away?

Kind regards

Georg


From sarah.goslee at gmail.com  Thu Jun 30 15:28:16 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 30 Jun 2016 09:28:16 -0400
Subject: [R] Can I increase the size of an asterisk in plotmath()?
In-Reply-To: <eeb7ccc6-1e44-f665-530d-cd258a7128e8@auckland.ac.nz>
References: <6a5aecfe-c095-780f-ee9d-c47ace0e2e8f@auckland.ac.nz>
	<dd6eba2b-f08d-8be1-19da-dfaacb68607a@umu.se>
	<eeb7ccc6-1e44-f665-530d-cd258a7128e8@auckland.ac.nz>
Message-ID: <CAM_vju=vwKv73zxeS0NSUOiwqW1AO--8NnM48Y1_Q+RAMSE0mQ@mail.gmail.com>

I don't know of an automatic way, but of course you can make it as
large as you'd like.


plot(1:10, type="n")
text(2, 8, expression(paste(bolditalic(p)^"*"))) #Rolf's original
text(2, 6,expression(paste(bolditalic(p),"*", sep = ""))) #Goran's suggestion


text(2, 3, expression(paste(bolditalic(p)^"*"))) # repeat Rolf's original
text(locator(1), "*", cex=3) # click on the asterisk: how big do you want it?

Sarah

On Thu, Jun 30, 2016 at 4:46 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 30/06/16 19:38, G?ran Brostr?m wrote:
>>
>> Rolf,
>>
>> text(7.5,2.5,expression(paste(bolditalic(p),"*", sep = "")))
>>
>> looks quite nice. On my Mac at least.
>
>
> <SNIP>
>
> Well, it didn't look nice on my laptop.  The asterisk was nearly invisible.
>
> cheers,
>
> Rolf
>


From C.Henry at westernsydney.edu.au  Thu Jun 30 04:04:22 2016
From: C.Henry at westernsydney.edu.au (Clemence Henry)
Date: Thu, 30 Jun 2016 02:04:22 +0000
Subject: [R] lineplot.CI xaxis scale change in sciplot?
Message-ID: <B3AB066D464A8D48999C6553F24153F96772A636@hall.AD.UWS.EDU.AU>

Hi,

I am trying to change the values of the tick marks on the xaxis of the following multipanel plot (see relevant bits of script below) to increments of 50 or to a custom scale (ie. 50, 100, 150, 200, 300...).
So far I tried using xaxp or xlim both in par() or lineplot.CI(), as well as axTicks and axisTicks but did not get it to work.
Suggestions?

#Plots average A/Ci for each day from ACi
#Parameters of the panels
par(mfcol=c(3,2), #row,col
    mar=c(2,2,1,1), #inner margin (bottom, left, top, right)
    oma=c(4,4,1,1), #outer margin (bottom, left, top, right)
    omd=c(0.1,0.8,0.1,0.95), #outer dimensions, values {0-1}, (x1, x2, y1, y2)
    xpd=NA)

...


#PAR = 1000, Day2
with(subset1000_2,
     lineplot.CI(x.factor=Ci.average,
                 response=Photo,
                 group=Treatment,
                 ylab=NA,
                 xlab=NA,
                 legend=FALSE,
                 type="p",
                 x.cont=TRUE, #continuous x axis (spacing proportional to values)
                 ylim=c(1,45), #range y axis
                 err.width=0.05,
                 pch = c(16,16,16), #symbols shape
                 col=c("gray84","black","gray48"),
                 fun=
     ))
mtext("Day2, PAR=1000", side = 3, line= -1, adj=0, at=1, cex=0.6) #subtitle

....

#legends
mtext("Ci", side = 1, line= 1, outer = TRUE, cex=0.7) #x legend
mtext("Photosynthetic rate", side = 2, line= 1, outer = TRUE, cex=0.7) #y legend
Thank you kindly for your support.

Clemence

	[[alternative HTML version deleted]]


From crm.maia at gmail.com  Thu Jun 30 17:02:50 2016
From: crm.maia at gmail.com (Carlos R. Moreira Maia)
Date: Thu, 30 Jun 2016 12:02:50 -0300
Subject: [R] Command to combine means?
Message-ID: <CAFh+_DzCWxJ8NAzLTS+dnOjjQGd0SdXzz6RcxT_hK-yd6FVcTg@mail.gmail.com>

Dear all,
I'm newbie with R (changing from STATA), and I can't find some commands.
One of those is the "combine", which I use to combine means like this:

--------------------------------------------
n1 m1 sd1  n2 m2 sd2

combine 12 3 1 34 45 4

Combine has calculated the following values:
    combined n = 46
    combined mean = 34.043478
    combined SD = 18.964829
--------------------------------------------

Does anybody knows a simmilar command in R to combine means?

Thanks in advance.

Carlos.

	[[alternative HTML version deleted]]


From parsa1.akbari at gmail.com  Thu Jun 30 15:15:42 2016
From: parsa1.akbari at gmail.com (Parsa Akbari)
Date: Thu, 30 Jun 2016 15:15:42 +0200
Subject: [R] rpart - plotcp find specificity and sensitivity
Message-ID: <CAJgYZPnEOu0pnb+Vmq+ZA9666OB5W-pZ9WehRorjq4d-FF=jmg@mail.gmail.com>

Hi,

I am using rpart to build a decision tree, I am then using printcp to find
the cross-validation error (xerror) of different splits of the decision
tree.

I was wondering how I can use the rpart package to find sensitivity (false
negative) and specificity (false positive) of cross-validation folds?

In addition I was wondering how many cross-validation folds does printcp
uses?

Thanks for your help.

Regards,
Parsa

	[[alternative HTML version deleted]]


From pitosalas at brandeis.edu  Thu Jun 30 16:51:05 2016
From: pitosalas at brandeis.edu (Pito Salas)
Date: Thu, 30 Jun 2016 10:51:05 -0400
Subject: [R] Documenting data
Message-ID: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>

I am studying statistics and using R in doing it. I come from software development where we document everything we do.

As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.? 

Is this a real problem? Is there a ?best practice? to address this?

Thanks!

Pito Salas
Brandeis Computer Science
Feldberg 131


From S.Ellison at LGCGroup.com  Thu Jun 30 17:37:57 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 30 Jun 2016 16:37:57 +0100
Subject: [R] Command to combine means?
In-Reply-To: <CAFh+_DzCWxJ8NAzLTS+dnOjjQGd0SdXzz6RcxT_hK-yd6FVcTg@mail.gmail.com>
References: <CAFh+_DzCWxJ8NAzLTS+dnOjjQGd0SdXzz6RcxT_hK-yd6FVcTg@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403EADE11D1@GBTEDVPEXCMB04.corp.lgc-group.com>

Stata's documentation lists this as a meta-analysis tool.
You may want to look at the rma function in the metafor package for various approaches to that problem.

S Ellison


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Carlos R.
> Moreira Maia
> Sent: 30 June 2016 16:03
> To: r-help at r-project.org
> Subject: [R] Command to combine means?
> 
> Dear all,
> I'm newbie with R (changing from STATA), and I can't find some commands.
> One of those is the "combine", which I use to combine means like this:
> 
> --------------------------------------------
> n1 m1 sd1  n2 m2 sd2
> 
> combine 12 3 1 34 45 4
> 
> Combine has calculated the following values:
>     combined n = 46
>     combined mean = 34.043478
>     combined SD = 18.964829
> --------------------------------------------
> 
> Does anybody knows a simmilar command in R to combine means?
> 
> Thanks in advance.
> 
> Carlos.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From cryan at binghamton.edu  Thu Jun 30 17:39:24 2016
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Thu, 30 Jun 2016 11:39:24 -0400
Subject: [R] Documenting data
In-Reply-To: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
Message-ID: <c652502e-ad90-4a20-924a-9bae401e5e33@typeapp.com>

Pito--

You describe excellent practices.

The R code itself, saved as a script, provides some documentation of how you got from original data to wherever you are.

Use # comments liberally. 

Whenever possible, save your raw data, however it was when you got it--avoid changing it--make all the changes on the objects in R. 

Have you looked into various "reproducible research" systems for R, like Sweave or knitr?? They allow you to include analysis code and text of a manuscript or report all together in one file.

Christopher W. Ryan
sent from my phone with BlueMail



On Jun 30, 2016, 11:30, at 11:30, Pito Salas <pitosalas at brandeis.edu> wrote:
>I am studying statistics and using R in doing it. I come from software
>development where we document everything we do.
>
>As I ?massage? my data, adding columns to a frame, computing on other
>data, perhaps cleaning, I feel the need to document in detail what the
>meaning, or background, or calculations, or whatever of the data is.
>After all it is now derived from my raw data (which may have been well
>documented) but it is ?new.? 
>
>Is this a real problem? Is there a ?best practice? to address this?
>
>Thanks!
>
>Pito Salas
>Brandeis Computer Science
>Feldberg 131
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rbaer at atsu.edu  Thu Jun 30 17:44:08 2016
From: rbaer at atsu.edu (Robert Baer)
Date: Thu, 30 Jun 2016 10:44:08 -0500
Subject: [R] Documenting data
In-Reply-To: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
Message-ID: <6ed71ffc-0f9c-c293-db28-3f8f78193484@atsu.edu>

You might look at:

http://stackoverflow.com/questions/7979609/automatic-documentation-of-datasets

You might also, try the  FIle | Compile Notebook  from within R-Studio 
(https://www.rstudio.com/) on your well-documented R-scripts to get a 
nice reproducible recording/report of data analysis workflow.  Similar 
functionality is available from basic R, but involves more work.  There 
are many other approaches, but the best choice depends on your precise 
needs.

And, as a programmer, you are probably already familiar with things like:
https://google.github.io/styleguide/Rguide.xml



On 6/30/2016 9:51 AM, Pito Salas wrote:
> I am studying statistics and using R in doing it. I come from software development where we document everything we do.
>
> As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.?
>
> Is this a real problem? Is there a ?best practice? to address this?
>
> Thanks!
>
> Pito Salas
> Brandeis Computer Science
> Feldberg 131
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Thu Jun 30 17:44:51 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 30 Jun 2016 15:44:51 +0000
Subject: [R] Documenting data
In-Reply-To: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
Message-ID: <CAKVAULOdiUi0KL2eHKwPBb1Txpk8F0Q+64w4Oo8kHEetHFyp7w@mail.gmail.com>

Vince Buffalo has covers this nicely in his book "Bioinformatics Data
Skills". The original data should stay the original data is immutable and
Vince then suggests that you have a text file in your data directory where
you explain where the data came from and which scripts you used to create a
modified version, when you did this and so on.

I find using roxygen comments and knitr extremely useful for keeping track
of what I intend to do and why because it allows me to export all the
reasoning, summary tables and plots to a format I can share with
collaborators that don't care about the R code for getting there.

HTH
Ulrik


On Thu, 30 Jun 2016 at 17:30 Pito Salas <pitosalas at brandeis.edu> wrote:

> I am studying statistics and using R in doing it. I come from software
> development where we document everything we do.
>
> As I ?massage? my data, adding columns to a frame, computing on other
> data, perhaps cleaning, I feel the need to document in detail what the
> meaning, or background, or calculations, or whatever of the data is. After
> all it is now derived from my raw data (which may have been well
> documented) but it is ?new.?
>
> Is this a real problem? Is there a ?best practice? to address this?
>
> Thanks!
>
> Pito Salas
> Brandeis Computer Science
> Feldberg 131
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Jun 30 18:24:40 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 30 Jun 2016 09:24:40 -0700
Subject: [R] Documenting data
In-Reply-To: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
Message-ID: <CAGxFJbR7x0oy-e8n_8jsYGj7BeAe0M_PjZhjzyzdS2bJkKOsLQ@mail.gmail.com>

In addition to what others have suggested, see ?history.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 30, 2016 at 7:51 AM, Pito Salas <pitosalas at brandeis.edu> wrote:
> I am studying statistics and using R in doing it. I come from software development where we document everything we do.
>
> As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.?
>
> Is this a real problem? Is there a ?best practice? to address this?
>
> Thanks!
>
> Pito Salas
> Brandeis Computer Science
> Feldberg 131
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jun 30 18:26:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 30 Jun 2016 09:26:54 -0700
Subject: [R] Command to combine means?
In-Reply-To: <CAFh+_DzCWxJ8NAzLTS+dnOjjQGd0SdXzz6RcxT_hK-yd6FVcTg@mail.gmail.com>
References: <CAFh+_DzCWxJ8NAzLTS+dnOjjQGd0SdXzz6RcxT_hK-yd6FVcTg@mail.gmail.com>
Message-ID: <CAGxFJbQ8chWRqSEi8eMtHO01sqCseA3d-qjeHayRaoMgHLkz2A@mail.gmail.com>

... Time to do your homework. Have you gone through any R tutorials?

Some recommendations here:  https://www.rstudio.com/online-learning/#R


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 30, 2016 at 8:02 AM, Carlos R. Moreira Maia
<crm.maia at gmail.com> wrote:
> Dear all,
> I'm newbie with R (changing from STATA), and I can't find some commands.
> One of those is the "combine", which I use to combine means like this:
>
> --------------------------------------------
> n1 m1 sd1  n2 m2 sd2
>
> combine 12 3 1 34 45 4
>
> Combine has calculated the following values:
>     combined n = 46
>     combined mean = 34.043478
>     combined SD = 18.964829
> --------------------------------------------
>
> Does anybody knows a simmilar command in R to combine means?
>
> Thanks in advance.
>
> Carlos.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pitosalas at brandeis.edu  Thu Jun 30 17:46:39 2016
From: pitosalas at brandeis.edu (Pito Salas)
Date: Thu, 30 Jun 2016 11:46:39 -0400
Subject: [R] Documenting data
In-Reply-To: <6ed71ffc-0f9c-c293-db28-3f8f78193484@atsu.edu>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
	<6ed71ffc-0f9c-c293-db28-3f8f78193484@atsu.edu>
Message-ID: <FFADC43E-85DF-40B9-950F-9E784ACF4FE4@brandeis.edu>

Thanks to you both. I think you?re saying/implying that once I ?test drive? a particular bit of cleaning I should capture it in a function which does it reproducibly against the raw data, and that becomes the best documentation for it. That makes sense.

Pito Salas
Brandeis Computer Science
Feldberg 131

> On Jun 30, 2016, at 11:44 AM, Robert Baer <rbaer at atsu.edu> wrote:
> 
> You might look at:
> 
> http://stackoverflow.com/questions/7979609/automatic-documentation-of-datasets
> 
> You might also, try the  FIle | Compile Notebook  from within R-Studio (https://www.rstudio.com/) on your well-documented R-scripts to get a nice reproducible recording/report of data analysis workflow.  Similar functionality is available from basic R, but involves more work.  There are many other approaches, but the best choice depends on your precise needs.
> 
> And, as a programmer, you are probably already familiar with things like:
> https://google.github.io/styleguide/Rguide.xml
> 
> 
> 
> On 6/30/2016 9:51 AM, Pito Salas wrote:
>> I am studying statistics and using R in doing it. I come from software development where we document everything we do.
>> 
>> As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.?
>> 
>> Is this a real problem? Is there a ?best practice? to address this?
>> 
>> Thanks!
>> 
>> Pito Salas
>> Brandeis Computer Science
>> Feldberg 131
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From bgunter.4567 at gmail.com  Thu Jun 30 18:43:01 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 30 Jun 2016 09:43:01 -0700
Subject: [R] Documenting data
In-Reply-To: <FFADC43E-85DF-40B9-950F-9E784ACF4FE4@brandeis.edu>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
	<6ed71ffc-0f9c-c293-db28-3f8f78193484@atsu.edu>
	<FFADC43E-85DF-40B9-950F-9E784ACF4FE4@brandeis.edu>
Message-ID: <CAGxFJbS+CWfs0Zmkyq6zWbHdGb0ohpQ7BXXCeund8AiFzmj7+Q@mail.gmail.com>

Private, since this is a trivial comment. Also, just my opinion, so
feel free to ignore.

Capture it, yes, but not necessarily as a function; just as a script
might do, and the tools mentioned can do this. As others have said,
your instincts are good, and you should just choose the methods that
work best for you.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 30, 2016 at 8:46 AM, Pito Salas <pitosalas at brandeis.edu> wrote:
> Thanks to you both. I think you?re saying/implying that once I ?test drive? a particular bit of cleaning I should capture it in a function which does it reproducibly against the raw data, and that becomes the best documentation for it. That makes sense.
>
> Pito Salas
> Brandeis Computer Science
> Feldberg 131
>
>> On Jun 30, 2016, at 11:44 AM, Robert Baer <rbaer at atsu.edu> wrote:
>>
>> You might look at:
>>
>> http://stackoverflow.com/questions/7979609/automatic-documentation-of-datasets
>>
>> You might also, try the  FIle | Compile Notebook  from within R-Studio (https://www.rstudio.com/) on your well-documented R-scripts to get a nice reproducible recording/report of data analysis workflow.  Similar functionality is available from basic R, but involves more work.  There are many other approaches, but the best choice depends on your precise needs.
>>
>> And, as a programmer, you are probably already familiar with things like:
>> https://google.github.io/styleguide/Rguide.xml
>>
>>
>>
>> On 6/30/2016 9:51 AM, Pito Salas wrote:
>>> I am studying statistics and using R in doing it. I come from software development where we document everything we do.
>>>
>>> As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.?
>>>
>>> Is this a real problem? Is there a ?best practice? to address this?
>>>
>>> Thanks!
>>>
>>> Pito Salas
>>> Brandeis Computer Science
>>> Feldberg 131
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at gmx.de  Thu Jun 30 19:10:32 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Thu, 30 Jun 2016 19:10:32 +0200
Subject: [R] Documenting data
In-Reply-To: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
Message-ID: <trinity-9bc14f42-2180-4066-9743-70afba1bc1db-1467306632070@3capp-gmx-bs54>

Hi Pito,
Dear Readers,

as other have already mentioned, there are good practices for documenting code and data. I would like to summarize them and add a few not mentioned earlier:

1. You should have always two things: your raw data and your R script/s. The raw data is immutable whereas the R script/s produce the results.

2. You might want to distinguish between documentating your CODE and documenting your DATA. Documenting code is similar to what you already know from your programmng experiences. Documenting data is somewhat different cause you store information about the meaning of you data directly in your data.

Example
You have a variable with codes ranging from 1 to 5. But what do they mean? Perhaps it could be

1 = Strongly agree
2 = Agree
3 = Neither agree/nor disagree
4 = Disagree
5 = Strongly Disagree

But it could also be the other way round:

1 = Strongly Disagree
2 = Disagree
3 = Nether agree/nor disagree
4 = Agree
5 = Strongly Agree

What the codes in your variable means depends on the systems oder processes you derived your data from.

Within R there are some limitations for storing the informtation about what a variable or a value within a variable means. Possibilities to store this information is in other software packages like SAS or SPSS much broader implemented. In R you can work with meaningful variable names and the data type/class factor which can store mappings between values and value descriptions.

Example
-- cut --
var1 <- c(rep(1:5, 3))
ds_example <- data.frame(var1)

var1_labels <- c("1 = Strongly Agree",
                "2 = Agree",
                "3 = Neither agree/nor disagree",
                "4 = Disagree",
                "5 = Strongly disagree")

ds_example[["var1"]] <- factor(ds_example[["var1"]],
                               levels = c(1, 2, 3, 4, 5),
                               labels = var1_labels)

summary(ds_example["var1"])
-- cut --

In addition you find methods to work with variable labels and value labels in the pacakges Hmisc and memisc. They can also produce a thing called codebook which contains all variable names, variable labels, values, value labels and summaries of the distribution of values within the variables.

3. In addition to this you could structure your script in a modular way according to the analysis process, e. g. 
importing, cleaning, preparation for analysis, analysis, reporting. Other structure may be more sufficient in your case. These modules could have a number in the file name indicating in which sequence the scripts should be run.

4. I find it valuable to use a software repository like Github, Sourceforge or others to keep the revisions save and seucre in case you would like to go back to a version with code you deleted before and figure out that you need it now again. The R Studio IDE has an interface to git if you like to go with that. Good commit message can help you track what has changed. Commits also help you to prepare precise steps when developing your scripts.

5. I have no experience with Sweave or knitr but you could also compile a simple documentation through copying comments to an Excel sheet using R-2-Excel libraries like excel.link or others.

Example
install.packages("excel.link")
library(excel.link)
xlc["A1"] <- "Project Documentation"
xlc["A2"] <- "Step XY"
xlc["A3"] <- "Some explanation about step xy"

This way you have the documentation in your code and in an external source.

Which approach you chose depends on your experience with R and its libraries as well as the size of your project and the need for documentation.

6. It can be helpful to store interim results in a format that can be read by non-R-users, e. g. Excel.

7. Documenting code can be done using roxygen2.

If there are different opinions to my suggestions please say so.

Kind regards

Georg


> Gesendet: Donnerstag, 30. Juni 2016 um 16:51 Uhr
> Von: "Pito Salas" <pitosalas at brandeis.edu>
> An: r-help at r-project.org
> Betreff: [R] Documenting data
>
> I am studying statistics and using R in doing it. I come from software development where we document everything we do.
> 
> As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.? 
> 
> Is this a real problem? Is there a ?best practice? to address this?
> 
> Thanks!
> 
> Pito Salas
> Brandeis Computer Science
> Feldberg 131
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jun 30 20:06:21 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 30 Jun 2016 11:06:21 -0700
Subject: [R] Documenting data
In-Reply-To: <trinity-9bc14f42-2180-4066-9743-70afba1bc1db-1467306632070@3capp-gmx-bs54>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
	<trinity-9bc14f42-2180-4066-9743-70afba1bc1db-1467306632070@3capp-gmx-bs54>
Message-ID: <CAGxFJbToLP+D1zTvG5jex-bGHZrBhX2TdR4FsFYFP5iwoDtX1A@mail.gmail.com>

I believe Georg's pronouncements are wrong. See inline below.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


"...

> Within R there are some limitations for storing the informtation about what a variable or a value within a variable means.

That is FALSE. There are no limitations. For example, just attach a
"doc" attribute to your data that says whatever you wish to about
them. e.g.

> somedata <- runif(10)
> attr(somedata,"doc") <- "Anything you want to say about the data"

> attr(somedata,"doc")
[1] "Anything you want to say about the data"


You can go as crazy as you want to with this, e.g. creating a (S3 or
S4 )class "documented" with appropriate methods for printing it from
classes that inherit from data frames, lists, etc. See also the
roxygen2 package for data documentation and R's ?promptData function
for data documentation file in Rd format.

R is Turing complete -- so it can do anything any other programming
language can do. You could program SAS in R if you wanted. The
difference is that SAS has pre-programmed some capabilities that R
leaves for users, including contributed packages -- like Sweave,
knitr, etc.  You may or may not like this extra flexibility (and extra
work, depending on whether someone else has already done the work for
you), and efficiency may or may not be an issue; but to say that R has
"limitations" is a gross misrepresentation, imho.



Possibilities to store this information is in other software packages
like SAS or SPSS much broader implemented. In R you can work with
meaningful variable names and the data type/class factor which can
store mappings between values and value descriptions.
>
> Example
> -- cut --
> var1 <- c(rep(1:5, 3))
> ds_example <- data.frame(var1)
>
> var1_labels <- c("1 = Strongly Agree",
>                 "2 = Agree",
>                 "3 = Neither agree/nor disagree",
>                 "4 = Disagree",
>                 "5 = Strongly disagree")
>
> ds_example[["var1"]] <- factor(ds_example[["var1"]],
>                                levels = c(1, 2, 3, 4, 5),
>                                labels = var1_labels)
>
> summary(ds_example["var1"])
> -- cut --
>
> In addition you find methods to work with variable labels and value labels in the pacakges Hmisc and memisc. They can also produce a thing called codebook which contains all variable names, variable labels, values, value labels and summaries of the distribution of values within the variables.
>
> 3. In addition to this you could structure your script in a modular way according to the analysis process, e. g.
> importing, cleaning, preparation for analysis, analysis, reporting. Other structure may be more sufficient in your case. These modules could have a number in the file name indicating in which sequence the scripts should be run.
>
> 4. I find it valuable to use a software repository like Github, Sourceforge or others to keep the revisions save and seucre in case you would like to go back to a version with code you deleted before and figure out that you need it now again. The R Studio IDE has an interface to git if you like to go with that. Good commit message can help you track what has changed. Commits also help you to prepare precise steps when developing your scripts.
>
> 5. I have no experience with Sweave or knitr but you could also compile a simple documentation through copying comments to an Excel sheet using R-2-Excel libraries like excel.link or others.
>
> Example
> install.packages("excel.link")
> library(excel.link)
> xlc["A1"] <- "Project Documentation"
> xlc["A2"] <- "Step XY"
> xlc["A3"] <- "Some explanation about step xy"
>
> This way you have the documentation in your code and in an external source.
>
> Which approach you chose depends on your experience with R and its libraries as well as the size of your project and the need for documentation.
>
> 6. It can be helpful to store interim results in a format that can be read by non-R-users, e. g. Excel.
>
> 7. Documenting code can be done using roxygen2.
>
> If there are different opinions to my suggestions please say so.
>
> Kind regards
>
> Georg
>
>
>> Gesendet: Donnerstag, 30. Juni 2016 um 16:51 Uhr
>> Von: "Pito Salas" <pitosalas at brandeis.edu>
>> An: r-help at r-project.org
>> Betreff: [R] Documenting data
>>
>> I am studying statistics and using R in doing it. I come from software development where we document everything we do.
>>
>> As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.?
>>
>> Is this a real problem? Is there a ?best practice? to address this?
>>
>> Thanks!
>>
>> Pito Salas
>> Brandeis Computer Science
>> Feldberg 131
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at gmx.de  Thu Jun 30 20:50:40 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Thu, 30 Jun 2016 20:50:40 +0200
Subject: [R] Documenting data
In-Reply-To: <CAGxFJbToLP+D1zTvG5jex-bGHZrBhX2TdR4FsFYFP5iwoDtX1A@mail.gmail.com>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
	<trinity-9bc14f42-2180-4066-9743-70afba1bc1db-1467306632070@3capp-gmx-bs54>,
	<CAGxFJbToLP+D1zTvG5jex-bGHZrBhX2TdR4FsFYFP5iwoDtX1A@mail.gmail.com>
Message-ID: <trinity-e99630f1-6c6e-4cb7-ba4d-d219d842aa30-1467312640178@3capp-gmx-bs54>

Hi Bert,
Hi Readers,

I did not know much about attributes in R and how to use them. If it is that flexible you are right and I have learnt something.

Kind regards

Georg

> Gesendet: Donnerstag, 30. Juni 2016 um 20:06 Uhr
> Von: "Bert Gunter" <bgunter.4567 at gmail.com>
> An: G.Maubach at gmx.de
> Cc: "Pito Salas" <pitosalas at brandeis.edu>, "R Help" <r-help at r-project.org>
> Betreff: Re: [R] Documenting data
>
> I believe Georg's pronouncements are wrong. See inline below.
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> "...
> 
> > Within R there are some limitations for storing the informtation about what a variable or a value within a variable means.
> 
> That is FALSE. There are no limitations. For example, just attach a
> "doc" attribute to your data that says whatever you wish to about
> them. e.g.
> 
> > somedata <- runif(10)
> > attr(somedata,"doc") <- "Anything you want to say about the data"
> 
> > attr(somedata,"doc")
> [1] "Anything you want to say about the data"
> 
> 
> You can go as crazy as you want to with this, e.g. creating a (S3 or
> S4 )class "documented" with appropriate methods for printing it from
> classes that inherit from data frames, lists, etc. See also the
> roxygen2 package for data documentation and R's ?promptData function
> for data documentation file in Rd format.
> 
> R is Turing complete -- so it can do anything any other programming
> language can do. You could program SAS in R if you wanted. The
> difference is that SAS has pre-programmed some capabilities that R
> leaves for users, including contributed packages -- like Sweave,
> knitr, etc.  You may or may not like this extra flexibility (and extra
> work, depending on whether someone else has already done the work for
> you), and efficiency may or may not be an issue; but to say that R has
> "limitations" is a gross misrepresentation, imho.
> 
> 
> 
> Possibilities to store this information is in other software packages
> like SAS or SPSS much broader implemented. In R you can work with
> meaningful variable names and the data type/class factor which can
> store mappings between values and value descriptions.
> >
> > Example
> > -- cut --
> > var1 <- c(rep(1:5, 3))
> > ds_example <- data.frame(var1)
> >
> > var1_labels <- c("1 = Strongly Agree",
> >                 "2 = Agree",
> >                 "3 = Neither agree/nor disagree",
> >                 "4 = Disagree",
> >                 "5 = Strongly disagree")
> >
> > ds_example[["var1"]] <- factor(ds_example[["var1"]],
> >                                levels = c(1, 2, 3, 4, 5),
> >                                labels = var1_labels)
> >
> > summary(ds_example["var1"])
> > -- cut --
> >
> > In addition you find methods to work with variable labels and value labels in the pacakges Hmisc and memisc. They can also produce a thing called codebook which contains all variable names, variable labels, values, value labels and summaries of the distribution of values within the variables.
> >
> > 3. In addition to this you could structure your script in a modular way according to the analysis process, e. g.
> > importing, cleaning, preparation for analysis, analysis, reporting. Other structure may be more sufficient in your case. These modules could have a number in the file name indicating in which sequence the scripts should be run.
> >
> > 4. I find it valuable to use a software repository like Github, Sourceforge or others to keep the revisions save and seucre in case you would like to go back to a version with code you deleted before and figure out that you need it now again. The R Studio IDE has an interface to git if you like to go with that. Good commit message can help you track what has changed. Commits also help you to prepare precise steps when developing your scripts.
> >
> > 5. I have no experience with Sweave or knitr but you could also compile a simple documentation through copying comments to an Excel sheet using R-2-Excel libraries like excel.link or others.
> >
> > Example
> > install.packages("excel.link")
> > library(excel.link)
> > xlc["A1"] <- "Project Documentation"
> > xlc["A2"] <- "Step XY"
> > xlc["A3"] <- "Some explanation about step xy"
> >
> > This way you have the documentation in your code and in an external source.
> >
> > Which approach you chose depends on your experience with R and its libraries as well as the size of your project and the need for documentation.
> >
> > 6. It can be helpful to store interim results in a format that can be read by non-R-users, e. g. Excel.
> >
> > 7. Documenting code can be done using roxygen2.
> >
> > If there are different opinions to my suggestions please say so.
> >
> > Kind regards
> >
> > Georg
> >
> >
> >> Gesendet: Donnerstag, 30. Juni 2016 um 16:51 Uhr
> >> Von: "Pito Salas" <pitosalas at brandeis.edu>
> >> An: r-help at r-project.org
> >> Betreff: [R] Documenting data
> >>
> >> I am studying statistics and using R in doing it. I come from software development where we document everything we do.
> >>
> >> As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.?
> >>
> >> Is this a real problem? Is there a ?best practice? to address this?
> >>
> >> Thanks!
> >>
> >> Pito Salas
> >> Brandeis Computer Science
> >> Feldberg 131
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From chocold12 at gmail.com  Thu Jun 30 21:26:07 2016
From: chocold12 at gmail.com (lily li)
Date: Thu, 30 Jun 2016 13:26:07 -0600
Subject: [R] Merge several datasets into one
Message-ID: <CAN5afy94Qgmqbnn1jMdzVAoP-H2jfw=njLOH4sUw3mSLCT_xog@mail.gmail.com>

Hi R users,

I'd like to ask that how to merge several datasets into one in R? I put
these csv files in one folder, and use the lapply function, but it says
that cannot open file 'xx.csv'. These files have different names, but end
with .csv extension, and the files have the same header. Thanks for your
help.

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Thu Jun 30 21:43:39 2016
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Thu, 30 Jun 2016 16:43:39 -0300
Subject: [R] mvpart package
Message-ID: <CAMM93=+dwGaCWnE+kQ71mpj3opv43dLFhUU6bKa+=Dj6mmeZTA@mail.gmail.com>

Does anybody know why mvpart package (for multivariate regression trees) is
not available on the web?
Thanks in advanced,
Joaqu?n.

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Jun 30 21:57:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 30 Jun 2016 12:57:47 -0700
Subject: [R] Merge several datasets into one
In-Reply-To: <CAN5afy94Qgmqbnn1jMdzVAoP-H2jfw=njLOH4sUw3mSLCT_xog@mail.gmail.com>
References: <CAN5afy94Qgmqbnn1jMdzVAoP-H2jfw=njLOH4sUw3mSLCT_xog@mail.gmail.com>
Message-ID: <CAGxFJbS6gQbzQNF1mD3A6pT1S9hhBkFSLeuH1jW9y=gof96Aqg@mail.gmail.com>

Lily:

If you mean that you have several csv files in a directory/folder on
your computer and you are using lapply() to do something with them,
then you do not have a clue about how R works and you need to go
through some tutorials to learn. There are many good ones on the web.
Some recommendations can be found here:
https://www.rstudio.com/online-learning/#R

We do expect posters here to have made some minimal effort to learn R
basics before posting.

If I have misunderstood, then you will either have to wait for a reply
from someone with greater insight or explain yourself more clearly.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 30, 2016 at 12:26 PM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I'd like to ask that how to merge several datasets into one in R? I put
> these csv files in one folder, and use the lapply function, but it says
> that cannot open file 'xx.csv'. These files have different names, but end
> with .csv extension, and the files have the same header. Thanks for your
> help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Jun 30 21:58:57 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 30 Jun 2016 12:58:57 -0700
Subject: [R] mvpart package
In-Reply-To: <CAMM93=+dwGaCWnE+kQ71mpj3opv43dLFhUU6bKa+=Dj6mmeZTA@mail.gmail.com>
References: <CAMM93=+dwGaCWnE+kQ71mpj3opv43dLFhUU6bKa+=Dj6mmeZTA@mail.gmail.com>
Message-ID: <CAGxFJbTgoL36M3A=QrUG5NRi1Lr-XW1ObTs3zD__8qWf6cP_vw@mail.gmail.com>

https://cran.r-project.org/web/packages/mvpart/index.html

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 30, 2016 at 12:43 PM, Joaqu?n Aldabe
<joaquin.aldabe at gmail.com> wrote:
> Does anybody know why mvpart package (for multivariate regression trees) is
> not available on the web?
> Thanks in advanced,
> Joaqu?n.
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Jun 30 22:38:17 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 30 Jun 2016 16:38:17 -0400
Subject: [R] Documenting data
In-Reply-To: <trinity-e99630f1-6c6e-4cb7-ba4d-d219d842aa30-1467312640178@3capp-gmx-bs54>
References: <7A11422D-8ADF-49CE-B209-54EF24695310@brandeis.edu>
	<trinity-9bc14f42-2180-4066-9743-70afba1bc1db-1467306632070@3capp-gmx-bs54>
	<CAGxFJbToLP+D1zTvG5jex-bGHZrBhX2TdR4FsFYFP5iwoDtX1A@mail.gmail.com>
	<trinity-e99630f1-6c6e-4cb7-ba4d-d219d842aa30-1467312640178@3capp-gmx-bs54>
Message-ID: <CA+vqiLHoHsBSa4KsZYCR8DOwQRUu226crKvgEPVGk3AUbqG2Nw@mail.gmail.com>

On Thu, Jun 30, 2016 at 2:50 PM,  <G.Maubach at gmx.de> wrote:
> Hi Bert,
> Hi Readers,
>
> I did not know much about attributes in R and how to use them. If it is that flexible you are right and I have learnt something.

It is that flexible, but there is a big limitation that makes them much less
useful than Bert suggests. Extending Bert's example:

somedata <- runif(10)
str(somedata)
num [1:10] 0.9393 0.59204 0.04016 0.00273 0.02146 ...

attr(somedata,"doc") <- "Anything you want to say about the data"
str(somedata)
## atomic [1:10] 0.9393 0.59204 0.04016 0.00273 0.02146 ...
## - attr(*, "doc")= chr "Anything you want to say about the data"

Notice that attaching attributes makes the output of str less informative.

The other main limitation is that attributes tend to get lost when you
manipulate the data:

somedata <- somedata[!is.na(somedata)]
attributes(somedata)
## NULL

Since attributes tend to disappear when you manipulate the data I tend
to avoid attaching them to the data directly.

You can work around this of course, and there are several packages
that do it for you, but the combination of these to drawbacks makes
the attributes system in R less useful for documenting data IMO.

Best,
Ista

>
> Kind regards
>
> Georg
>
>> Gesendet: Donnerstag, 30. Juni 2016 um 20:06 Uhr
>> Von: "Bert Gunter" <bgunter.4567 at gmail.com>
>> An: G.Maubach at gmx.de
>> Cc: "Pito Salas" <pitosalas at brandeis.edu>, "R Help" <r-help at r-project.org>
>> Betreff: Re: [R] Documenting data
>>
>> I believe Georg's pronouncements are wrong. See inline below.
>>
>> -- Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> "...
>>
>> > Within R there are some limitations for storing the informtation about what a variable or a value within a variable means.
>>
>> That is FALSE. There are no limitations. For example, just attach a
>> "doc" attribute to your data that says whatever you wish to about
>> them. e.g.
>>
>> > somedata <- runif(10)
>> > attr(somedata,"doc") <- "Anything you want to say about the data"
>>
>> > attr(somedata,"doc")
>> [1] "Anything you want to say about the data"
>>
>>
>> You can go as crazy as you want to with this, e.g. creating a (S3 or
>> S4 )class "documented" with appropriate methods for printing it from
>> classes that inherit from data frames, lists, etc. See also the
>> roxygen2 package for data documentation and R's ?promptData function
>> for data documentation file in Rd format.
>>
>> R is Turing complete -- so it can do anything any other programming
>> language can do. You could program SAS in R if you wanted. The
>> difference is that SAS has pre-programmed some capabilities that R
>> leaves for users, including contributed packages -- like Sweave,
>> knitr, etc.  You may or may not like this extra flexibility (and extra
>> work, depending on whether someone else has already done the work for
>> you), and efficiency may or may not be an issue; but to say that R has
>> "limitations" is a gross misrepresentation, imho.
>>
>>
>>
>> Possibilities to store this information is in other software packages
>> like SAS or SPSS much broader implemented. In R you can work with
>> meaningful variable names and the data type/class factor which can
>> store mappings between values and value descriptions.
>> >
>> > Example
>> > -- cut --
>> > var1 <- c(rep(1:5, 3))
>> > ds_example <- data.frame(var1)
>> >
>> > var1_labels <- c("1 = Strongly Agree",
>> >                 "2 = Agree",
>> >                 "3 = Neither agree/nor disagree",
>> >                 "4 = Disagree",
>> >                 "5 = Strongly disagree")
>> >
>> > ds_example[["var1"]] <- factor(ds_example[["var1"]],
>> >                                levels = c(1, 2, 3, 4, 5),
>> >                                labels = var1_labels)
>> >
>> > summary(ds_example["var1"])
>> > -- cut --
>> >
>> > In addition you find methods to work with variable labels and value labels in the pacakges Hmisc and memisc. They can also produce a thing called codebook which contains all variable names, variable labels, values, value labels and summaries of the distribution of values within the variables.
>> >
>> > 3. In addition to this you could structure your script in a modular way according to the analysis process, e. g.
>> > importing, cleaning, preparation for analysis, analysis, reporting. Other structure may be more sufficient in your case. These modules could have a number in the file name indicating in which sequence the scripts should be run.
>> >
>> > 4. I find it valuable to use a software repository like Github, Sourceforge or others to keep the revisions save and seucre in case you would like to go back to a version with code you deleted before and figure out that you need it now again. The R Studio IDE has an interface to git if you like to go with that. Good commit message can help you track what has changed. Commits also help you to prepare precise steps when developing your scripts.
>> >
>> > 5. I have no experience with Sweave or knitr but you could also compile a simple documentation through copying comments to an Excel sheet using R-2-Excel libraries like excel.link or others.
>> >
>> > Example
>> > install.packages("excel.link")
>> > library(excel.link)
>> > xlc["A1"] <- "Project Documentation"
>> > xlc["A2"] <- "Step XY"
>> > xlc["A3"] <- "Some explanation about step xy"
>> >
>> > This way you have the documentation in your code and in an external source.
>> >
>> > Which approach you chose depends on your experience with R and its libraries as well as the size of your project and the need for documentation.
>> >
>> > 6. It can be helpful to store interim results in a format that can be read by non-R-users, e. g. Excel.
>> >
>> > 7. Documenting code can be done using roxygen2.
>> >
>> > If there are different opinions to my suggestions please say so.
>> >
>> > Kind regards
>> >
>> > Georg
>> >
>> >
>> >> Gesendet: Donnerstag, 30. Juni 2016 um 16:51 Uhr
>> >> Von: "Pito Salas" <pitosalas at brandeis.edu>
>> >> An: r-help at r-project.org
>> >> Betreff: [R] Documenting data
>> >>
>> >> I am studying statistics and using R in doing it. I come from software development where we document everything we do.
>> >>
>> >> As I ?massage? my data, adding columns to a frame, computing on other data, perhaps cleaning, I feel the need to document in detail what the meaning, or background, or calculations, or whatever of the data is. After all it is now derived from my raw data (which may have been well documented) but it is ?new.?
>> >>
>> >> Is this a real problem? Is there a ?best practice? to address this?
>> >>
>> >> Thanks!
>> >>
>> >> Pito Salas
>> >> Brandeis Computer Science
>> >> Feldberg 131
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Lists at dewey.myzen.co.uk  Thu Jun 30 23:09:52 2016
From: Lists at dewey.myzen.co.uk (Lists at dewey.myzen.co.uk)
Date: Thu, 30 Jun 2016 21:09:52 +0000
Subject: [R] Merge several datasets into one
Message-ID: <Zen-1bIjDc-0000P9-Oi@smarthost03a.mail.zen.net.uk>

Lily Li <chocold12 at gmail.com> wrote :

I think you are going to have to give us some more detail. What commands did you execute? what are the names of the .csv files in your directory? Can you read one of them as asingle read.csv?

> Hi R users,
> 
> I'd like to ask that how to merge several datasets into one in R? I put
> these csv files in one folder, and use the lapply function, but it says
> that cannot open file 'xx.csv'. These files have different names, but end
> with .csv extension, and the files have the same header. Thanks for your
> help.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m.p.kosinski at gmail.com  Mon Jun 27 00:16:02 2016
From: m.p.kosinski at gmail.com (=?UTF-8?Q?Marcin_Kosi=C5=84ski?=)
Date: Mon, 27 Jun 2016 00:16:02 +0200
Subject: [R] [R-pkgs] archivist.github 0.2.1 on CRAN - Task View:
	Reproducible	Research
Message-ID: <CAL8y_Qw-EwAtUJ_Y=Kyqgtv6vsOppfMLyPAUq645vOfEBAZE9w@mail.gmail.com>

Hi all R devs,

archivist.github has appeared on CRAN in it's updated version.
You can check the last blog post on how has RHero saved the Backup City
with the power or archivist and GitHub
http://www.r-bloggers.com/r-hero-saves-backup-city-with-archivist-and-github/

There is also going to be a talk on useR2016 about it's core dependency -
archivist

How to use the archivist package to boost reproducibility of your research
<http://schedule.user2016.org/event/7BYx/how-to-use-the-archivist-package-to-boost-reproducibility-of-your-research>
<http://schedule.user2016.org/event/7BYx/how-to-use-the-archivist-package-to-boost-reproducibility-of-your-research>
<http://schedule.user2016.org/event/7BYx/how-to-use-the-archivist-package-to-boost-reproducibility-of-your-research>

If you would like to boost your reproducible engines then this is a talk
for you :)

Best,
archivist.github author
Marcin Kosi?ski

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

