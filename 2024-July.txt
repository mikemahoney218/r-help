From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Mon Jul  1 17:54:21 2024
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Mon, 1 Jul 2024 15:54:21 +0000
Subject: [R] Create matrix with variable number of columns AND CREATE NAMES
 FOR THE COLUMNS
Message-ID: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>

#I am trying to write code that will create a matrix with a variable number of columns where the #number of columns is 1+Grps
#I can do this:
NSims <- 4
Grps <- 5
DiffMeans <- matrix(nrow=NSims,ncol=1+Grps)
DiffMeans

#I have a problem when I try to name the columns of the matrix. I want the first column to be NSims, #and the other columns to be something like Value1, Value2, . . . Valuen where N=Grps

# I wrote a function to build a list of length Grps
createValuelist <- function(num_elements) {
  for (i in 1:num_elements) {
    cat("Item", i, "\n", sep = "")
  }
}
createValuelist(Grps)

# When I try to assign column names I receive an error:
#Error in dimnames(DiffMeans) <- list(NULL, c("NSim", createValuelist(Grps))) : 
# length of 'dimnames' [2] not equal to array extent
dimnames(DiffMeans) <- list(NULL,c("NSim",createValuelist(Grps)))
DiffMeans

# Thank you for your help!


John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;?
PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




From tebert @end|ng |rom u||@edu  Mon Jul  1 19:43:36 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Mon, 1 Jul 2024 17:43:36 +0000
Subject: [R] 
 Create matrix with variable number of columns AND CREATE NAMES
 FOR THE COLUMNS
In-Reply-To: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <CH3PR22MB45142BD4D2792E8AEAB11AF4CFD32@CH3PR22MB4514.namprd22.prod.outlook.com>

NSims <- 4
Grps <- 5
DiffMeans <- matrix(nrow=NSims,ncol=1+Grps)
DiffMeans

#I have a problem when I try to name the columns of the matrix. I want the first column to be NSims, #and the other columns to be something like Value1, Value2, . . . Valuen where N=Grps
Colnames <- as.vector("NSims")
num_elements <- ncol(DiffMeans)
for (i in 2:num_elements) {
  Colnames[i] <- paste0("Item",i)
}
colnames(DiffMeans) <- Colnames

You need the vector "Colnames" to have the same number of elements as columns in DiffMeans.
Colnames in created with the first element in place because that will not change.
The loop starts with the second element so that the first element is not overwritten by the for loop.


As a function it might look something like this:
# Name columns is a function that will take a matrix and two strings.
# The first string is the name of the first column.
# The second string is the base part of column names.
#     The function adds a number after the base part.
name_cols <- function(matrix, name1, name2){
  colnames <- as.vector(name1)
  num_elements <- ncol(DiffMeans)
  # I wrote a function to build a list of length Grps createValuelist <- function(num_elements) {
  for (i in 2:num_elements) {
    colnames[i] <- paste0(name2,i)
  }
}

colnames(DiffMeans) <- name_cols(DiffNames,"Book", "Cola")

You can now make the names anything you want for any specific use.
You could add some error checking like making sure the first parameter is a matrix and the other two parmeters are appropriate strings.
If the function will only be called once or twice it might be simpler to not use a function.


Tim
-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
Sent: Monday, July 1, 2024 11:54 AM
To: r-help at r-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] Create matrix with variable number of columns AND CREATE NAMES FOR THE COLUMNS

[External Email]

#I am trying to write code that will create a matrix with a variable number of columns where the #number of columns is 1+Grps #I can do this:
NSims <- 4
Grps <- 5
DiffMeans <- matrix(nrow=NSims,ncol=1+Grps) DiffMeans

#I have a problem when I try to name the columns of the matrix. I want the first column to be NSims, #and the other columns to be something like Value1, Value2, . . . Valuen where N=Grps

# I wrote a function to build a list of length Grps createValuelist <- function(num_elements) {
  for (i in 1:num_elements) {
    cat("Item", i, "\n", sep = "")
  }
}
createValuelist(Grps)

# When I try to assign column names I receive an error:
#Error in dimnames(DiffMeans) <- list(NULL, c("NSim", createValuelist(Grps))) :
# length of 'dimnames' [2] not equal to array extent
dimnames(DiffMeans) <- list(NULL,c("NSim",createValuelist(Grps)))
DiffMeans

# Thank you for your help!


John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine; Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center; PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center; Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jul  1 19:56:23 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 1 Jul 2024 18:56:23 +0100
Subject: [R] 
 Create matrix with variable number of columns AND CREATE NAMES
 FOR THE COLUMNS
In-Reply-To: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <78bf05fa-7f80-413e-aa6d-0c0f785c0c49@sapo.pt>

?s 16:54 de 01/07/2024, Sorkin, John escreveu:
> #I am trying to write code that will create a matrix with a variable number of columns where the #number of columns is 1+Grps
> #I can do this:
> NSims <- 4
> Grps <- 5
> DiffMeans <- matrix(nrow=NSims,ncol=1+Grps)
> DiffMeans
> 
> #I have a problem when I try to name the columns of the matrix. I want the first column to be NSims, #and the other columns to be something like Value1, Value2, . . . Valuen where N=Grps
> 
> # I wrote a function to build a list of length Grps
> createValuelist <- function(num_elements) {
>    for (i in 1:num_elements) {
>      cat("Item", i, "\n", sep = "")
>    }
> }
> createValuelist(Grps)
> 
> # When I try to assign column names I receive an error:
> #Error in dimnames(DiffMeans) <- list(NULL, c("NSim", createValuelist(Grps))) :
> # length of 'dimnames' [2] not equal to array extent
> dimnames(DiffMeans) <- list(NULL,c("NSim",createValuelist(Grps)))
> DiffMeans
> 
> # Thank you for your help!
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
> 
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Something like this?



names_cols <- function(x, First = "NSims", Prefix = "Value") {
   nms <- c(First, sprintf("%s%d", Prefix, seq_len(ncol(x) - 1L)))
   colnames(x) <- nms
   x
}

NSims <- 4
Grps <- 5
DiffMeans <- matrix(nrow=NSims,ncol=1+Grps)
names_cols(DiffMeans)
#>      NSims Value1 Value2 Value3 Value4 Value5
#> [1,]    NA     NA     NA     NA     NA     NA
#> [2,]    NA     NA     NA     NA     NA     NA
#> [3,]    NA     NA     NA     NA     NA     NA
#> [4,]    NA     NA     NA     NA     NA     NA



Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jul  1 20:05:32 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 1 Jul 2024 19:05:32 +0100
Subject: [R] 
 Create matrix with variable number of columns AND CREATE NAMES
 FOR THE COLUMNS
In-Reply-To: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <cbf9861a-2d11-4fb9-86c4-db6387b71af1@sapo.pt>

?s 16:54 de 01/07/2024, Sorkin, John escreveu:
> #I am trying to write code that will create a matrix with a variable number of columns where the #number of columns is 1+Grps
> #I can do this:
> NSims <- 4
> Grps <- 5
> DiffMeans <- matrix(nrow=NSims,ncol=1+Grps)
> DiffMeans
> 
> #I have a problem when I try to name the columns of the matrix. I want the first column to be NSims, #and the other columns to be something like Value1, Value2, . . . Valuen where N=Grps
> 
> # I wrote a function to build a list of length Grps
> createValuelist <- function(num_elements) {
>    for (i in 1:num_elements) {
>      cat("Item", i, "\n", sep = "")
>    }
> }
> createValuelist(Grps)
> 
> # When I try to assign column names I receive an error:
> #Error in dimnames(DiffMeans) <- list(NULL, c("NSim", createValuelist(Grps))) :
> # length of 'dimnames' [2] not equal to array extent
> dimnames(DiffMeans) <- list(NULL,c("NSim",createValuelist(Grps)))
> DiffMeans
> 
> # Thank you for your help!
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
> 
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Sorry for my first answer, I thought you only wanted to name the matrix 
columns. After reading the OP again, this time actually reading it, I 
realized you also want to create the matrix. This is even in the 
question title line :(.



create_matrix <- function(nsims, ngrps, First = "NSims", Prefix = "Value") {
   # could also be paste0(Prefix, seq_len(ngrps))
   grp_names <- sprintf("%s%d", Prefix, seq_len(ngrps))
   nms <- c(First, grp_names)
   matrix(nrow = nsims, ncol = 1L + ngrps, dimnames = list(NULL, nms))
}

NSims <- 4
Grps <- 5
create_matrix(NSims, Grps)
#>      NSims Value1 Value2 Value3 Value4 Value5
#> [1,]    NA     NA     NA     NA     NA     NA
#> [2,]    NA     NA     NA     NA     NA     NA
#> [3,]    NA     NA     NA     NA     NA     NA
#> [4,]    NA     NA     NA     NA     NA     NA



Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul  1 20:50:09 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 01 Jul 2024 11:50:09 -0700
Subject: [R] 
 Create matrix with variable number of columns AND CREATE NAMES
 FOR THE COLUMNS
In-Reply-To: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <F4ADB92D-420E-41C8-9EBB-119C1CCC397E@dcn.davis.ca.us>

I think you should reconsider your goal. Matrices must have all elements of the same type, and in this case you seem to be trying to mix a number of something (integer) with mean values (double). This would normally be stored together in a data frame or separately in a vector for counts and a matrix for means.

If you are just thinking about data presentation, a data frame would be a better choice than a single matrix.

On July 1, 2024 8:54:21 AM PDT, "Sorkin, John" <jsorkin at som.umaryland.edu> wrote:
>#I am trying to write code that will create a matrix with a variable number of columns where the #number of columns is 1+Grps
>#I can do this:
>NSims <- 4
>Grps <- 5
>DiffMeans <- matrix(nrow=NSims,ncol=1+Grps)
>DiffMeans
>
>#I have a problem when I try to name the columns of the matrix. I want the first column to be NSims, #and the other columns to be something like Value1, Value2, . . . Valuen where N=Grps
>
># I wrote a function to build a list of length Grps
>createValuelist <- function(num_elements) {
>  for (i in 1:num_elements) {
>    cat("Item", i, "\n", sep = "")
>  }
>}
>createValuelist(Grps)
>
># When I try to assign column names I receive an error:
>#Error in dimnames(DiffMeans) <- list(NULL, c("NSim", createValuelist(Grps))) : 
># length of 'dimnames' [2] not equal to array extent
>dimnames(DiffMeans) <- list(NULL,c("NSim",createValuelist(Grps)))
>DiffMeans
>
># Thank you for your help!
>
>
>John David Sorkin M.D., Ph.D.
>Professor of Medicine, University of Maryland School of Medicine;
>Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;?
>PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
>Senior Statistician University of Maryland Center for Vascular Research;
>
>Division of Gerontology and Paliative Care,
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>Cell phone 443-418-5382
>
>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From tuech|er @end|ng |rom gmx@@t  Mon Jul  1 20:55:07 2024
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Mon, 1 Jul 2024 20:55:07 +0200
Subject: [R] 
 Create matrix with variable number of columns AND CREATE NAMES
 FOR THE COLUMNS
In-Reply-To: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB50491491431A5556461E7BABE2D32@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <13d92624-cdc5-9cf2-60a5-f76285d93723@gmx.at>

Sorkin, John wrote/hat geschrieben on/am 01.07.2024 17:54:
> #I am trying to write code that will create a matrix with a variable number of columns where the #number of columns is 1+Grps
> #I can do this:
> NSims <- 4
> Grps <- 5
> DiffMeans <- matrix(nrow=NSims,ncol=1+Grps)
> DiffMeans
>
> #I have a problem when I try to name the columns of the matrix. I want the first column to be NSims, #and the other columns to be something like Value1, Value2, . . . Valuen where N=Grps
>
> # I wrote a function to build a list of length Grps
> createValuelist <- function(num_elements) {
>   for (i in 1:num_elements) {
>     cat("Item", i, "\n", sep = "")
>   }
> }
> createValuelist(Grps)
>
> # When I try to assign column names I receive an error:
> #Error in dimnames(DiffMeans) <- list(NULL, c("NSim", createValuelist(Grps))) :
> # length of 'dimnames' [2] not equal to array extent
> dimnames(DiffMeans) <- list(NULL,c("NSim",createValuelist(Grps)))
> DiffMeans
>
> # Thank you for your help!
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
maybe:
NSims <- 4
Grps <- 5
DiffMeans <-
     matrix(nrow=NSims,ncol=1+Grps,
            dimnames=list(NULL, c('Nsimn', paste('Item', 1:Grps, sep=''))))
DiffMeans

best,
Heinz

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @@uer @end|ng |rom |mb|@un|-he|de|berg@de  Mon Jul  1 15:33:43 2024
From: @@uer @end|ng |rom |mb|@un|-he|de|berg@de (Sauer, Lukas Daniel)
Date: Mon, 1 Jul 2024 13:33:43 +0000
Subject: [R] summaryRprof: Unexpected unit for memory profiling
Message-ID: <0ead849446304c87ac70ee9cdc492976@imbi.uni-heidelberg.de>

Hello,

I am profiling memory usage using utils::Rprof() and subsequently summarizing the profile using utils::summaryRprof(). According to the documentation ?summaryRprof, the option `memory = "both"` reports "memory consumption in Mb in addition to the timings", i.e. the unit is megabytes. However, looking at the source code (https://github.com/wch/r-source/blob/18652de8890d89563b923ff58b45ccb04d9955fe/src/library/utils/R/summRprof.R#L170) suggests that memory is reported in mebibytes (division by 1048576 and not by 100000). This is in line with the following minimal example:

use_mb <- function(){a <- runif(1000000)}
use_mib <- function(){b <- runif(1024^2)}
Rprof("Rprof.out", memory.profiling=TRUE)
use_mb()
use_mib()
Rprof(NULL)
summaryRprof("Rprof.out", memory="both")

Do not source this code, but execute it line by line. This example returns the output:

$by.self
        self.time self.pct total.time total.pct mem.total
"runif"      0.04      100       0.04       100      15.6

$by.total
          total.time total.pct mem.total self.time self.pct
"runif"         0.04       100      15.6      0.04      100
"use_mb"        0.02        50       7.6      0.00        0
"use_mib"       0.02        50       8.0      0.00        0

$sample.interval
[1] 0.02

$sampling.time
[1] 0.04

The example was run under:

R version 4.4.0 (2024-04-24 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

If the unit were megabytes, I would expect mem.total to be 16.4, 8.0, and 8.4 -- but rather it is 15.6, 7.6, and 8.0. Do you agree that this behavior is unexpected or did I overlook something? If yes, I will file a bug report and suggest that the documentation is changed to "memory consumption in MiB in addition to the timings".

Best regards,

Lukas D Sauer
Biometrician
Institute of Medical Biometry

Heidelberg University Hospital | Im Neuenheimer Feld 130.3 | D-69120 Heidelberg
Tel. +49 6221 56-35036 | Fax. +49 6221 56-4195 | E-Mail: sauer at imbi.uni-heidelberg.de
biometrie.uni-heidelberg.de | twitter.com/imbi_heidelberg


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul  2 09:05:53 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 02 Jul 2024 00:05:53 -0700
Subject: [R] summaryRprof: Unexpected unit for memory profiling
In-Reply-To: <0ead849446304c87ac70ee9cdc492976@imbi.uni-heidelberg.de>
References: <0ead849446304c87ac70ee9cdc492976@imbi.uni-heidelberg.de>
Message-ID: <EBF51C4A-6225-419C-B7B7-2EA1B7BB6E09@dcn.davis.ca.us>

There was a time when people pretty much ignored the distinction between MB and MiB in computer applications, and using the binary version was usually assumed because, well, this _is_ memory we are measuring. I think this is a leftover from that time.

On July 1, 2024 6:33:43 AM PDT, "Sauer, Lukas Daniel" <sauer at imbi.uni-heidelberg.de> wrote:
>Hello,
>
>I am profiling memory usage using utils::Rprof() and subsequently summarizing the profile using utils::summaryRprof(). According to the documentation ?summaryRprof, the option `memory = "both"` reports "memory consumption in Mb in addition to the timings", i.e. the unit is megabytes. However, looking at the source code (https://github.com/wch/r-source/blob/18652de8890d89563b923ff58b45ccb04d9955fe/src/library/utils/R/summRprof.R#L170) suggests that memory is reported in mebibytes (division by 1048576 and not by 100000). This is in line with the following minimal example:
>
>use_mb <- function(){a <- runif(1000000)}
>use_mib <- function(){b <- runif(1024^2)}
>Rprof("Rprof.out", memory.profiling=TRUE)
>use_mb()
>use_mib()
>Rprof(NULL)
>summaryRprof("Rprof.out", memory="both")
>
>Do not source this code, but execute it line by line. This example returns the output:
>
>$by.self
>        self.time self.pct total.time total.pct mem.total
>"runif"      0.04      100       0.04       100      15.6
>
>$by.total
>          total.time total.pct mem.total self.time self.pct
>"runif"         0.04       100      15.6      0.04      100
>"use_mb"        0.02        50       7.6      0.00        0
>"use_mib"       0.02        50       8.0      0.00        0
>
>$sample.interval
>[1] 0.02
>
>$sampling.time
>[1] 0.04
>
>The example was run under:
>
>R version 4.4.0 (2024-04-24 ucrt)
>Platform: x86_64-w64-mingw32/x64
>Running under: Windows 11 x64 (build 22631)
>
>If the unit were megabytes, I would expect mem.total to be 16.4, 8.0, and 8.4 -- but rather it is 15.6, 7.6, and 8.0. Do you agree that this behavior is unexpected or did I overlook something? If yes, I will file a bug report and suggest that the documentation is changed to "memory consumption in MiB in addition to the timings".
>
>Best regards,
>
>Lukas D Sauer
>Biometrician
>Institute of Medical Biometry
>
>Heidelberg University Hospital | Im Neuenheimer Feld 130.3 | D-69120 Heidelberg
>Tel. +49 6221 56-35036 | Fax. +49 6221 56-4195 | E-Mail: sauer at imbi.uni-heidelberg.de
>biometrie.uni-heidelberg.de | twitter.com/imbi_heidelberg
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From tr|ng @end|ng |rom gvdnet@dk  Wed Jul  3 10:13:59 2024
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Wed, 3 Jul 2024 10:13:59 +0200
Subject: [R] simple problem with unquoting argument
Message-ID: <5bd7164c-315e-458b-913a-164dfd336d4b@gvdnet.dk>

Hi? friends - I'm in problems finding out how to unquote - I have a 
series of vectors named adds1....adds11 and need to e.g. find the sum of 
each of them

So I try

SS <- c()

for (i in 1:11) {

e <- paste("adds",i,sep="")

SS[i]? <- sum(xx(e)) }

Now e looks right - but I have been unable to find out how to get the 
string e converted to the proper argument for sum()? - i.e. what? is 
function xx?

All best wishes
Troels Ring, Aalborg, Denmark


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jul  3 10:24:21 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 3 Jul 2024 09:24:21 +0100
Subject: [R] simple problem with unquoting argument
In-Reply-To: <5bd7164c-315e-458b-913a-164dfd336d4b@gvdnet.dk>
References: <5bd7164c-315e-458b-913a-164dfd336d4b@gvdnet.dk>
Message-ID: <26ef9ed0-e712-4847-8c09-c6fbd17a31c6@sapo.pt>

?s 09:13 de 03/07/2024, Troels Ring escreveu:
> Hi? friends - I'm in problems finding out how to unquote - I have a 
> series of vectors named adds1....adds11 and need to e.g. find the sum of 
> each of them
> 
> So I try
> 
> SS <- c()
> 
> for (i in 1:11) {
> 
> e <- paste("adds",i,sep="")
> 
> SS[i]? <- sum(xx(e)) }
> 
> Now e looks right - but I have been unable to find out how to get the 
> string e converted to the proper argument for sum()? - i.e. what? is 
> function xx?
> 
> All best wishes
> Troels Ring, Aalborg, Denmark
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Function xx is ?get or mget (same help page).
You can get the vectors adds all in one instruction with mget or one at 
a time with get.


adds1 <- 1:10
adds2 <- 2:10
adds3 <- 3:10
adds4 <- 4:10
adds5 <- 5:10

# create SS with the required length beforehand
SS <- numeric(5L)
for (i in 1:5) {
   e <- paste("adds",i,sep="")
   SS[i]  <- sum(get(e))
}
SS
#> [1] 55 54 52 49 45


Or all in one instruction with the assistance of ?ls.



# ls(pattern = "^adds") |> mget() |> lapply(sum)
ls(pattern = "^adds") |> mget() |> sapply(sum)
#> adds1 adds2 adds3 adds4 adds5
#>    55    54    52    49    45


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From |kry|ov @end|ng |rom d|@root@org  Wed Jul  3 10:25:02 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 3 Jul 2024 11:25:02 +0300
Subject: [R] simple problem with unquoting argument
In-Reply-To: <5bd7164c-315e-458b-913a-164dfd336d4b@gvdnet.dk>
References: <5bd7164c-315e-458b-913a-164dfd336d4b@gvdnet.dk>
Message-ID: <20240703112502.2fd088f3@Tarkus>

? Wed, 3 Jul 2024 10:13:59 +0200
Troels Ring <tring at gvdnet.dk> ?????:

> Now e looks right - but I have been unable to find out how to get the 
> string e converted to the proper argument for sum()? - i.e. what? is 
> function xx?

get(e) will return the value of the variable with the name stored in
the variable e.

A more idiomatic variant will require more changes:

1. Create the "adds" variable as a list, so that it could contain other
arbitrary R values:

adds <- list()

2. Instead of assigning adds1 <- something(), adds2 <-
something_else(), ..., assign to the elements of the list:

adds[[1]] <- something()
adds[[2]] <- something_else()
...

3. Now you can use the same syntax to access the elements of the list:

SS[i] <- sum(adds[[i]])

As a bonus, you can use the "apply" family of R functions that will
perform the loop for you: instead of SS <- c(); for (i in 1:11) SS[i]
<- sum(adds[[i]]) you can write

SS <- vapply(adds, sum, numeric(1))

...and it will perform the same loop inside it, verifying each time
that sum(adds[[i]]) returns a single number.

-- 
Best regards,
Ivan

P.S. I'm sorry for letting our project lapse.


From tr|ng @end|ng |rom gvdnet@dk  Wed Jul  3 16:16:23 2024
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Wed, 3 Jul 2024 16:16:23 +0200
Subject: [R] simple problem with unquoting argument
In-Reply-To: <20240703112502.2fd088f3@Tarkus>
References: <5bd7164c-315e-458b-913a-164dfd336d4b@gvdnet.dk>
 <20240703112502.2fd088f3@Tarkus>
Message-ID: <8364b241-9166-4b5a-bf9a-499a412e0e9e@gvdnet.dk>

Dear Ivan and Rui - thanks a lot for the effective help.

All best wishes Troels

Den 03-07-2024 kl. 10:25 skrev Ivan Krylov:
> ? Wed, 3 Jul 2024 10:13:59 +0200
> Troels Ring <tring at gvdnet.dk> ?????:
>
>> Now e looks right - but I have been unable to find out how to get the
>> string e converted to the proper argument for sum()? - i.e. what? is
>> function xx?
> get(e) will return the value of the variable with the name stored in
> the variable e.
>
> A more idiomatic variant will require more changes:
>
> 1. Create the "adds" variable as a list, so that it could contain other
> arbitrary R values:
>
> adds <- list()
>
> 2. Instead of assigning adds1 <- something(), adds2 <-
> something_else(), ..., assign to the elements of the list:
>
> adds[[1]] <- something()
> adds[[2]] <- something_else()
> ...
>
> 3. Now you can use the same syntax to access the elements of the list:
>
> SS[i] <- sum(adds[[i]])
>
> As a bonus, you can use the "apply" family of R functions that will
> perform the loop for you: instead of SS <- c(); for (i in 1:11) SS[i]
> <- sum(adds[[i]]) you can write
>
> SS <- vapply(adds, sum, numeric(1))
>
> ...and it will perform the same loop inside it, verifying each time
> that sum(adds[[i]]) returns a single number.
>


From r-m@||@ @end|ng |rom erez@h@org  Fri Jul  5 13:35:40 2024
From: r-m@||@ @end|ng |rom erez@h@org (Erez Shomron)
Date: Fri, 05 Jul 2024 14:35:40 +0300
Subject: [R] Bug? plot.formula does need support plot.first / plot.last
 param in plot.default
Message-ID: <a9dd2c4c-953d-4d3b-9480-06bc3454df7f@app.fastmail.com>

Is the following a bug in your opinion? I think so.

This works as expected:

```
with(mtcars, plot(wt, mpg, plot.first = {
    plot.window(range(wt), range(mpg))
    arrows(3, 15, 4, 30)
}))
```

This does not.

```
plot(mpg ~ wt, data = mtcars, plot.first = {
    plot.window(range(wt), range(mpg))
    arrows(3, 15, 4, 30)
})
```

With error:
```
Error in arrows(3, 15, 4, 30) : plot.new has not been called yet
```

The second example should work.

>From the docs:

?plot.formula
"     For the ?plot? method the formula can be of the form ?~ z + y +
     z?: the variables specified on the right-hand side are collected
     into a data frame, subsetted if specified, and displayed by
     ?plot.data.frame?.
"

?plot.data.frame
"     ...: further arguments to ?stripchart?, ?plot.default? or ?pairs?.
"

And plot.default has both plot.first and plot.last

It seems very arbitrary you can't use these parameters with the plot.formula method specifically.

> sessionInfo()
R version 4.4.1 (2024-06-14)
Platform: x86_64-suse-linux-gnu
Running under: openSUSE Tumbleweed
[...]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jul  6 00:05:50 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 5 Jul 2024 18:05:50 -0400
Subject: [R] Bug? plot.formula does need support plot.first / plot.last
 param in plot.default
In-Reply-To: <a9dd2c4c-953d-4d3b-9480-06bc3454df7f@app.fastmail.com>
References: <a9dd2c4c-953d-4d3b-9480-06bc3454df7f@app.fastmail.com>
Message-ID: <83c5f0f0-8193-436b-94b5-d4570d1db03f@gmail.com>

That definitely looks like a bug, but not one that anyone will be eager 
to fix.  It's very old code that tried to be clever, and that's the 
hardest kind of code to fix.

Remember Kernighan's Law:  "Everyone knows that debugging is twice as 
hard as writing a program in the first place. So if you?re as clever as 
you can be when you write it, how will you ever debug it?"

Duncan Murdoch

On 2024-07-05 7:35 a.m., Erez Shomron wrote:
> Is the following a bug in your opinion? I think so.
> 
> This works as expected:
> 
> ```
> with(mtcars, plot(wt, mpg, plot.first = {
>      plot.window(range(wt), range(mpg))
>      arrows(3, 15, 4, 30)
> }))
> ```
> 
> This does not.
> 
> ```
> plot(mpg ~ wt, data = mtcars, plot.first = {
>      plot.window(range(wt), range(mpg))
>      arrows(3, 15, 4, 30)
> })
> ```
> 
> With error:
> ```
> Error in arrows(3, 15, 4, 30) : plot.new has not been called yet
> ```
> 
> The second example should work.
> 
>  From the docs:
> 
> ?plot.formula
> "     For the ?plot? method the formula can be of the form ?~ z + y +
>       z?: the variables specified on the right-hand side are collected
>       into a data frame, subsetted if specified, and displayed by
>       ?plot.data.frame?.
> "
> 
> ?plot.data.frame
> "     ...: further arguments to ?stripchart?, ?plot.default? or ?pairs?.
> "
> 
> And plot.default has both plot.first and plot.last
> 
> It seems very arbitrary you can't use these parameters with the plot.formula method specifically.
> 
>> sessionInfo()
> R version 4.4.1 (2024-06-14)
> Platform: x86_64-suse-linux-gnu
> Running under: openSUSE Tumbleweed
> [...]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r-m@||@ @end|ng |rom erez@h@org  Sat Jul  6 08:15:56 2024
From: r-m@||@ @end|ng |rom erez@h@org (Erez Shomron)
Date: Sat, 06 Jul 2024 09:15:56 +0300
Subject: [R] Bug? plot.formula does need support plot.first / plot.last
 param in plot.default
In-Reply-To: <83c5f0f0-8193-436b-94b5-d4570d1db03f@gmail.com>
References: <a9dd2c4c-953d-4d3b-9480-06bc3454df7f@app.fastmail.com>
 <83c5f0f0-8193-436b-94b5-d4570d1db03f@gmail.com>
Message-ID: <453eb9fd-0a17-4b94-80c2-f679c0807dcc@app.fastmail.com>

Thanks for your answer.

Should I report in Bugzilla at least so it's tracked?

I can point that the issue is with line 6 of the function body:
```
    dots <- lapply(m$..., eval, md, eframe)
```

I assume the intention was to evaluate the arguments with the context of data passed to the function.
But the expression in panel.first / panel.last gets evaluated before plot.new is called (as the error indicates).

I believe the fix would be to somehow not evaluate line 6, or replace with `dots <- m$...`, and when `plot` is later called, to somehow evaluate it with the data passed to the function. I tried to add `envir` argument to `do.call` but it does not work as I expected.

I would've liked to contribute a patch but my R knowledge is limited and and this `plot.formula` code is a bit of my head frankly.

Kindly,
Erez


On Sat, Jul 6, 2024, at 1:05 AM, Duncan Murdoch wrote:
> That definitely looks like a bug, but not one that anyone will be eager 
> to fix.  It's very old code that tried to be clever, and that's the 
> hardest kind of code to fix.
> 
> Remember Kernighan's Law:  "Everyone knows that debugging is twice as 
> hard as writing a program in the first place. So if you?re as clever as 
> you can be when you write it, how will you ever debug it?"
> 
> Duncan Murdoch
> 
> On 2024-07-05 7:35 a.m., Erez Shomron wrote:
> > Is the following a bug in your opinion? I think so.
> > 
> > This works as expected:
> > 
> > ```
> > with(mtcars, plot(wt, mpg, plot.first = {
> >      plot.window(range(wt), range(mpg))
> >      arrows(3, 15, 4, 30)
> > }))
> > ```
> > 
> > This does not.
> > 
> > ```
> > plot(mpg ~ wt, data = mtcars, plot.first = {
> >      plot.window(range(wt), range(mpg))
> >      arrows(3, 15, 4, 30)
> > })
> > ```
> > 
> > With error:
> > ```
> > Error in arrows(3, 15, 4, 30) : plot.new has not been called yet
> > ```
> > 
> > The second example should work.
> > 
> >  From the docs:
> > 
> > ?plot.formula
> > "     For the ?plot? method the formula can be of the form ?~ z + y +
> >       z?: the variables specified on the right-hand side are collected
> >       into a data frame, subsetted if specified, and displayed by
> >       ?plot.data.frame?.
> > "
> > 
> > ?plot.data.frame
> > "     ...: further arguments to ?stripchart?, ?plot.default? or ?pairs?.
> > "
> > 
> > And plot.default has both plot.first and plot.last
> > 
> > It seems very arbitrary you can't use these parameters with the plot.formula method specifically.
> > 
> >> sessionInfo()
> > R version 4.4.1 (2024-06-14)
> > Platform: x86_64-suse-linux-gnu
> > Running under: openSUSE Tumbleweed
> > [...]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Sat Jul  6 15:02:48 2024
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Sat, 6 Jul 2024 13:02:48 +0000
Subject: [R] add only the 1st of May with POSIXct
In-Reply-To: <878qztdtz9.fsf@enricoschumann.net>
References: <e558a289b0ee415e83939fc5e9bfdb41@regione.marche.it>,
 <878qztdtz9.fsf@enricoschumann.net>
Message-ID: <e566396a3e7649c8a71a20c2558afff5@regione.marche.it>

Sorry for the delay of my answer.

Enrico and Rui, thank you for your help.

Both solutions worked well, in particular Enrico's hint is very easy to implement.


Thank you

Stefano


         (oo)
--oOO--( )--OOo--------------------------------------
Stefano Sofia PhD
Civil Protection - Marche Region - Italy
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona (AN)
Uff: +39 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------------------------------


________________________________
Da: Enrico Schumann <es at enricoschumann.net>
Inviato: mercoled? 29 maggio 2024 08:15
A: Stefano Sofia
Cc: r-help at R-project.org
Oggetto: Re: [R] add only the 1st of May with POSIXct

[Non ricevi spesso messaggi di posta elettronica da es at enricoschumann.net. Per informazioni sull'importanza di questo fatto, visita https://aka.ms/LearnAboutSenderIdentification.]

On Tue, 28 May 2024, Stefano Sofia writes:

> Dear R-list users,
>
> From an initial and a final date I create a sequence of days using POSIXct.
>
> If this interval covers all or only in part the months from May to October, I need to get rid of the days from the 2nd of May to the 31st of October:
>
>
> a <- as.POSIXct("2002-11-01", format = "%Y-%m-%d", tz="Etc/GMT-1")
>
> b <- as.POSIXct("2004-06-01", format = "%Y-%m-%d", tz="Etc/GMT-1")
>
> mydf <- data.frame(data_POSIX=seq(as.POSIXct(paste(format(a, "%Y-%m-%d"), "09:00:00", sep=""), format="%Y-%m-%d %H:%M:%S", tz="Etc/GMT-1"), as.POSIXct(paste(format(b, "%Y-%m-%d"), "09:00:00", sep=""), format="%Y-%m-%d %H:%M:%S", tz="Etc/GMT-1"), by="1 day"))
>
>
> If I execute
>
> as.data.frame(mydf[format(mydf$data_POSIX,"%m") %in% c("11", "12", "01", "02", "03", "04"), ])
>
> the interval will be
>
> from 2002-11-01 09:00:00 to 2003-04-30 09:00:00
>
> and from 2003-11-01 09:00:00 to 2004-04-30 09:00:00
>
>
> but I need also 2003-05-01 09:00:00 and 2004-05-01 09:00:00
>
>
> How can I solve this problem?
>
>
> Thank you for your attention and your help
>
> Stefano
>

I think this could be simplified a bit:

    a <- as.POSIXct("2002-11-01 09", format = "%Y-%m-%d %H", tz="Etc/GMT-1")
    b <- as.POSIXct("2004-06-01 09", format = "%Y-%m-%d %H", tz="Etc/GMT-1")

Create your sequence:

    S <- seq(a, b , by = "1 day")
    month.day <- format(S, "%m-%d")

Now subset S for those days that you want:

    S[month.day <= "05-01" | month.day > "10-31"]


--
Enrico Schumann
Lucerne, Switzerland
https://eur02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fenricoschumann.net%2F&data=05%7C02%7Cstefano.sofia%40regione.marche.it%7Cfb03eb5bf2e24b4b76b408dc7fa6b98e%7C295eaa1431a14b09bfe65a338b679f60%7C0%7C0%7C638525601265102204%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=46TUwFWwpLcdtZGARpDkhnuHhgZ546khJI%2FONPeYXe4%3D&reserved=0

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Sat Jul  6 16:24:38 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sat, 6 Jul 2024 17:24:38 +0300
Subject: [R] Bug? plot.formula does need support plot.first / plot.last
 param in plot.default
In-Reply-To: <a9dd2c4c-953d-4d3b-9480-06bc3454df7f@app.fastmail.com>
References: <a9dd2c4c-953d-4d3b-9480-06bc3454df7f@app.fastmail.com>
Message-ID: <20240706172438.2b4340c5@parabola>

? Fri, 05 Jul 2024 14:35:40 +0300
"Erez Shomron" <r-mails at erezsh.org> ?????:

> This works as expected:

> with(mtcars, plot(wt, mpg, plot.first = {
>     plot.window(range(wt), range(mpg))
>     arrows(3, 15, 4, 30)
> }))

I think you meant panel.first, not plot.first. At least I cannot find
any mention of plot.first in the R source code. In this example,
plot.first ends up being an argument of an internal call from
plot.default() to plot.window(), which evaluates its ellipsis
arguments. If your plot.first expression returned a non-NULL value, you
would also have received a warning:

plot.window(0:1, 0:1, plot.first = message('hello'))
# hello
plot.window(0:1, 0:1, plot.first = 123)
# Warning message:
# In plot.window(0:1, 0:1, plot.first = 123) :
#   "plot.first" is not a graphical parameter

It is indeed documented that "passing [panel.first] from other ?plot?
methods may well not work since it may be evaluated too early". The
plot.formula method deliberately evaluates the arguments in the
ellipsis, and the workaround suggested in
https://bugs.r-project.org/show_bug.cgi?id=14591 doesn't help because
the expression is then evaluated in an undesired environment (parent
frame, not data).

You are correct that plot.formula tries to evaluate all its remaining
arguments in the context of the data passed to the method. In order for
the lazy evaluation to work, plot.formula would have to (1) know and
skip all such arguments by name on line 6, minding partial matching, (2)
rewrite them into the form evalq(original_argument_expression,
model_frame, parent_frame) so that they would be able to access both
the data and the variables visible in the frame of the caller, and (3)
give these expressions to do.call() in place of the original ones.

(1) sounds especially brittle since plot.formula() may dispatch to
other plot.* methods. Additionally, great care will need to be taken
not to break existing code that calls plot.formula, even if it's
already full of workarounds for plot.formula's behaviour.

-- 
Best regards,
Ivan


From r-m@||@ @end|ng |rom erez@h@org  Sat Jul  6 16:55:34 2024
From: r-m@||@ @end|ng |rom erez@h@org (Erez Shomron)
Date: Sat, 06 Jul 2024 17:55:34 +0300
Subject: [R] Bug? plot.formula does need support plot.first / plot.last
 param in plot.default
In-Reply-To: <20240706172438.2b4340c5@parabola>
References: <a9dd2c4c-953d-4d3b-9480-06bc3454df7f@app.fastmail.com>
 <20240706172438.2b4340c5@parabola>
Message-ID: <308fc620-a977-4c0d-a305-64ac660b32cf@app.fastmail.com>

Thank you Ivan,

Yes I meant `panel.first`.
I fumbled the title and the examples, but the end result is the same:

```
# Works
with(mtcars, plot(wt, mpg, panel.first = {
    arrows(3, 15, 4, 30)
}))

# Doesn't work
plot(mpg ~ wt, data = mtcars, panel.first = {
    arrows(3, 15, 4, 30)
})

```

I saw the bug reported 13 years ago after-the-fact, and the paragraph I missed for the manual entry.
Thanks for clarifying both.

I do think making these arguments lazy evaluate would be a welcome change. It's especially confusing for new R users trying to use base graphics to plot their linear model. But I also understand this would be low priority as user workaround is simple (don't use the formula method), and because of the testing effort that would be required.

Maybe a warning would be nice, telling users that `panel.first` and `panel.last` are evaluated before plotting. I think users would check `?plot` before `?plot.formula` and would not see any reason not to try and pass these arguments.

Kind Regards,
Erez

On Sat, Jul 6, 2024, at 5:24 PM, Ivan Krylov wrote:
> ? Fri, 05 Jul 2024 14:35:40 +0300
> "Erez Shomron" <r-mails at erezsh.org> ?????:
> 
> > This works as expected:
> 
> > with(mtcars, plot(wt, mpg, plot.first = {
> >     plot.window(range(wt), range(mpg))
> >     arrows(3, 15, 4, 30)
> > }))
> 
> I think you meant panel.first, not plot.first. At least I cannot find
> any mention of plot.first in the R source code. In this example,
> plot.first ends up being an argument of an internal call from
> plot.default() to plot.window(), which evaluates its ellipsis
> arguments. If your plot.first expression returned a non-NULL value, you
> would also have received a warning:
> 
> plot.window(0:1, 0:1, plot.first = message('hello'))
> # hello
> plot.window(0:1, 0:1, plot.first = 123)
> # Warning message:
> # In plot.window(0:1, 0:1, plot.first = 123) :
> #   "plot.first" is not a graphical parameter
> 
> It is indeed documented that "passing [panel.first] from other ?plot?
> methods may well not work since it may be evaluated too early". The
> plot.formula method deliberately evaluates the arguments in the
> ellipsis, and the workaround suggested in
> https://bugs.r-project.org/show_bug.cgi?id=14591 doesn't help because
> the expression is then evaluated in an undesired environment (parent
> frame, not data).
> 
> You are correct that plot.formula tries to evaluate all its remaining
> arguments in the context of the data passed to the method. In order for
> the lazy evaluation to work, plot.formula would have to (1) know and
> skip all such arguments by name on line 6, minding partial matching, (2)
> rewrite them into the form evalq(original_argument_expression,
> model_frame, parent_frame) so that they would be able to access both
> the data and the variables visible in the frame of the caller, and (3)
> give these expressions to do.call() in place of the original ones.
> 
> (1) sounds especially brittle since plot.formula() may dispatch to
> other plot.* methods. Additionally, great care will need to be taken
> not to break existing code that calls plot.formula, even if it's
> already full of workarounds for plot.formula's behaviour.
> 
> -- 
> Best regards,
> Ivan
> 


From @j|thr@m@yy@n @end|ng |rom y@hoo@co@|n  Mon Jul  8 07:05:28 2024
From: @j|thr@m@yy@n @end|ng |rom y@hoo@co@|n (Ajith R)
Date: Mon, 8 Jul 2024 05:05:28 +0000 (UTC)
Subject: [R] package spline - default value of Boundary.knots of ns
In-Reply-To: <541091075.64659.1719894647788@mail.yahoo.com>
References: <541091075.64659.1719894647788.ref@mail.yahoo.com>
 <541091075.64659.1719894647788@mail.yahoo.com>
Message-ID: <2137603183.1626716.1720415128149@mail.yahoo.com>

Dear Maintainer,


Thanks for the excellent package splines. I am writing this email to request you to consider a suggestion I have with regards to the function ns.


While trying to rework an example from a textbook, I couldn't call ns with appropriate arguments to reproduce the results. The package documentation also couldn't help me find the problem. Finally, I found a stack exchange question (https://stats.stackexchange.com/questions/588769/natural-splines-in-r-with-ns)? which helped me understand the problem - the default values of boundary knots are not useful. The problem is described in the stack exchange question, which I request you to kindly read.


My suggestion is to change the default value of the argument Boundary.knots to NULL and calculate its values from? the extreme values of the argument knots inside the function body if it is NULL and otherwise to keep whatever numerical value it is assigned at call.


I think it is more intuitive to the user to specify one set of knots assuming that its minimum and maximum values would be used as the knots beyond which regression would be linear rather than to know that the function automatically calculates boundary knots which are not appropriate and so he needs to override them.


Just so that I am clear, an example. Assume that my variable *alcohol*? has values from 1 to 100 and I want to specify natural splines at knots 20,40 and 60, expecting linearity would hold below 20 and above 60. Currently, I have to specify knots as 40 and boundary knots as 20 and 60 as?ns(alcohol , knots = c(40), Boundary.knots = c(20,60))

If I incorrectly assume that correct values of boundary knots are calculated by default, I will specify knots as 20,40 and 60 as ns(alcohol , knots = c(20,40,60)) and get incorrect values for boundary knots as 1 and 100. (I have done this and the stack exchange post shows that I am not alone).


Hope my suggestion will be considered,


Thanks,
ajith


From @nupty@g| @end|ng |rom gm@||@com  Tue Jul  9 12:46:43 2024
From: @nupty@g| @end|ng |rom gm@||@com (Anupam Tyagi)
Date: Tue, 9 Jul 2024 16:16:43 +0530
Subject: [R] Automatic Knot selection in Piecewise linear splines
Message-ID: <CAFL9eukUVQzjkmY2fXiLH5LFbySusU6qZqrCd1dMxRHOFZBgFg@mail.gmail.com>

How can I do automatic knot selection while fitting piecewise linear
splines to two variables x and y? Which package to use to do it simply? I
also want to visualize the splines (and the scatter plot) with a graph.

Anupam

	[[alternative HTML version deleted]]


From |ter|emez @end|ng |rom e@k|@eh|r@edu@tr  Tue Jul  9 15:02:17 2024
From: |ter|emez @end|ng |rom e@k|@eh|r@edu@tr (Levent TERLEMEZ)
Date: Tue, 9 Jul 2024 13:02:17 +0000
Subject: [R] Weird R Studio behaviour...
Message-ID: <D8A08C72-70E9-4FB9-AACB-342AF657A944@contoso.com>

Hi,

Have a nice week. First of all, I know this is not R Studio forum but I want to ask here first, if you all do not mind. Well, I am away from my computer right now but, I have a strange problem (at least to me). My script worked perfectly for a year, and today, suddenly stop working because R Studio begins to warn me about illegal characters in the script.

System is on W 10, and R 3.4.1 is working with R Studio. R Studio is updated today to the latest one because of this problem with the hope of resolving the problem (but no luck) and they are used as their default installation settings. Anyway, the problem example may not be repoducable right now but if it is, I can give detailed one later.

While the original working code is this (there is no synax error, too in the code because it was working perfectly until today before updating R Studio, error also came out before this update as I mensioned before);

legend(c("Kapan??",""20 G?nl?k,"50 G?nl?k"),col=c("black"...

The warning is this;

Error: unexpected symbol inside:
" Encoding(kill3) <- "latin1" legend(c(kill1,kill2,"50 G?nl?k"),col=c("black"? and can be solved when converted ??? to ?u?. Addition to this another solution (at least for me) is this;

kill1<-"Kapan??"
Encoding(kill1) <- "UTF-8" (these two statements are not needed but fort he sake of code integrity, is applied to it, too. If kill1 is converted to latin1, this time it is broken)
kill2<-"22 G?nl?k MA"
Encoding(kill2) <- "latin1"
kill3<-"50 G?nl?k MA"
Encoding(kill3) <- "latin1"

And also it is set to ?ASK? and always ?UTF-8? is selected.

But, I also wonder why today and what changed so R Studio stops suddenly running the script? I can not following up the changes anymore as used to be and if this is a character set problem, it is coming back again and again. What is the permenant solution of this? This is like an endless problem?

With my best regards and thanks for your patience?.

Levent Terlemez.



________________________________
YASAL UYARI: Bu e-postan?n i?erdi?i bilgiler (ekleri de dahil olmak ?zere) gizlidir. Sahibinin onay? olmaks?z?n i?eri?i kopyalanamaz, ???nc? ki?ilere a??klanamaz veya iletilemez . Bu mesaj?n g?nderilmek istendi?i ki?i de?ilseniz (ya da bu e-postay? yanl??l?kla ald?ysan?z), l?tfen yollayan ki?iyi haberdar ediniz ve mesaj? sisteminizden derhal siliniz. Eski?ehir Teknik ?niversitesi, bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda bir garanti vermemektedir. Bu nedenle, bilgilerin ne ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan, saklanmas?ndan Eski?ehir Teknik ?niversitesi sorumlu de?ildir. Bu mesaj?n i?eri?i yazar?na ait olup, Eski?ehir Teknik ?niversitesi'nin g?r??lerini i?ermeyebilir. Bu e-posta bizce bilinen t?m bilgisayar vir?slerine kar?? taranm??t?r.

DISCLAIMER: This e-mail (including any attachments) may contain confidential and/or privileged information. Copying, disclosure or distribution of the material in this e-mail without owner authority is strictly forbidden. If you are not the intended recipient (or have received this e-mail in error), please notify the sender and delete it from your system immediately. Eskisehir Technical University makes no warranty as to the accuracy or completeness of any information contained in this message and hereby excludes any liability of any kind for the information contained therein or for the information transmission, reception, storage or use of such in any way whatsoever. Any opinions expressed in this message are those of the author and may not necessarily reflect the opinions of Eskisehir Technical University. This e-mail has been scanned for all computer viruses known to us.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jul  9 17:24:31 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 9 Jul 2024 08:24:31 -0700
Subject: [R] Weird R Studio behaviour...
In-Reply-To: <D8A08C72-70E9-4FB9-AACB-342AF657A944@contoso.com>
References: <D8A08C72-70E9-4FB9-AACB-342AF657A944@contoso.com>
Message-ID: <CAGxFJbSrY2mGXM88dCy2gmbd=gx7RU2r+v10VpsmSjuj6YKVyg@mail.gmail.com>

I think you should also update R to the latest version, as that *might* be
the source of the problem.

Other may be able to give you a specific diagnosis, but updating R is to a
(reasonably, at least) current version is good practice anyway.

Cheers,
Bert

On Tue, Jul 9, 2024 at 8:11?AM Levent TERLEMEZ via R-help <
r-help at r-project.org> wrote:

> Hi,
>
> Have a nice week. First of all, I know this is not R Studio forum but I
> want to ask here first, if you all do not mind. Well, I am away from my
> computer right now but, I have a strange problem (at least to me). My
> script worked perfectly for a year, and today, suddenly stop working
> because R Studio begins to warn me about illegal characters in the script.
>
> System is on W 10, and R 3.4.1 is working with R Studio. R Studio is
> updated today to the latest one because of this problem with the hope of
> resolving the problem (but no luck) and they are used as their default
> installation settings. Anyway, the problem example may not be repoducable
> right now but if it is, I can give detailed one later.
>
> While the original working code is this (there is no synax error, too in
> the code because it was working perfectly until today before updating R
> Studio, error also came out before this update as I mensioned before);
>
> legend(c("Kapan??",""20 G?nl?k,"50 G?nl?k"),col=c("black"...
>
> The warning is this;
>
> Error: unexpected symbol inside:
> " Encoding(kill3) <- "latin1" legend(c(kill1,kill2,"50
> G?nl?k"),col=c("black"? and can be solved when converted ??? to ?u?.
> Addition to this another solution (at least for me) is this;
>
> kill1<-"Kapan??"
> Encoding(kill1) <- "UTF-8" (these two statements are not needed but fort
> he sake of code integrity, is applied to it, too. If kill1 is converted to
> latin1, this time it is broken)
> kill2<-"22 G?nl?k MA"
> Encoding(kill2) <- "latin1"
> kill3<-"50 G?nl?k MA"
> Encoding(kill3) <- "latin1"
>
> And also it is set to ?ASK? and always ?UTF-8? is selected.
>
> But, I also wonder why today and what changed so R Studio stops suddenly
> running the script? I can not following up the changes anymore as used to
> be and if this is a character set problem, it is coming back again and
> again. What is the permenant solution of this? This is like an endless
> problem?
>
> With my best regards and thanks for your patience?.
>
> Levent Terlemez.
>
>
>
> ________________________________
> YASAL UYARI: Bu e-postan?n i?erdi?i bilgiler (ekleri de dahil olmak ?zere)
> gizlidir. Sahibinin onay? olmaks?z?n i?eri?i kopyalanamaz, ???nc? ki?ilere
> a??klanamaz veya iletilemez . Bu mesaj?n g?nderilmek istendi?i ki?i
> de?ilseniz (ya da bu e-postay? yanl??l?kla ald?ysan?z), l?tfen yollayan
> ki?iyi haberdar ediniz ve mesaj? sisteminizden derhal siliniz. Eski?ehir
> Teknik ?niversitesi, bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz
> oldu?u konusunda bir garanti vermemektedir. Bu nedenle, bilgilerin ne
> ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan,
> saklanmas?ndan Eski?ehir Teknik ?niversitesi sorumlu de?ildir. Bu mesaj?n
> i?eri?i yazar?na ait olup, Eski?ehir Teknik ?niversitesi'nin g?r??lerini
> i?ermeyebilir. Bu e-posta bizce bilinen t?m bilgisayar vir?slerine kar??
> taranm??t?r.
>
> DISCLAIMER: This e-mail (including any attachments) may contain
> confidential and/or privileged information. Copying, disclosure or
> distribution of the material in this e-mail without owner authority is
> strictly forbidden. If you are not the intended recipient (or have received
> this e-mail in error), please notify the sender and delete it from your
> system immediately. Eskisehir Technical University makes no warranty as to
> the accuracy or completeness of any information contained in this message
> and hereby excludes any liability of any kind for the information contained
> therein or for the information transmission, reception, storage or use of
> such in any way whatsoever. Any opinions expressed in this message are
> those of the author and may not necessarily reflect the opinions of
> Eskisehir Technical University. This e-mail has been scanned for all
> computer viruses known to us.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @erv|ce @end|ng |rom @hd@w@on@com  Tue Jul  9 18:56:11 2024
From: @erv|ce @end|ng |rom @hd@w@on@com (Stephen H. Dawson, DSL)
Date: Tue, 9 Jul 2024 12:56:11 -0400
Subject: [R] Weird R Studio behaviour...
In-Reply-To: <CAGxFJbSrY2mGXM88dCy2gmbd=gx7RU2r+v10VpsmSjuj6YKVyg@mail.gmail.com>
References: <D8A08C72-70E9-4FB9-AACB-342AF657A944@contoso.com>
 <CAGxFJbSrY2mGXM88dCy2gmbd=gx7RU2r+v10VpsmSjuj6YKVyg@mail.gmail.com>
Message-ID: <43a06824-2b3b-21d1-709a-84248783e7db@shdawson.com>

I disagree.

UTF-8 is far from new. The IDE cannot fail at the point of not handling 
a known technology without advancing the argument with further messaging.

What happens when you run the same code within R apart from the IDE?

What trace work have you accomplished with this special character in a 
separate test script?

It may be how Windows 10 is handling UTF-8 after the latest update of 
optional packages that Microsoft released last week. Run a test in CMD 
on UTF-8 and see what you discover.


*Stephen Dawson, DSL*
/Executive Strategy Consultant/
Business & Technology
+1 (865) 804-3454
http://www.shdawson.com


On 7/9/24 11:24, Bert Gunter wrote:
> I think you should also update R to the latest version, as that *might* be
> the source of the problem.
>
> Other may be able to give you a specific diagnosis, but updating R is to a
> (reasonably, at least) current version is good practice anyway.
>
> Cheers,
> Bert
>
> On Tue, Jul 9, 2024 at 8:11?AM Levent TERLEMEZ via R-help <
> r-help at r-project.org> wrote:
>
>> Hi,
>>
>> Have a nice week. First of all, I know this is not R Studio forum but I
>> want to ask here first, if you all do not mind. Well, I am away from my
>> computer right now but, I have a strange problem (at least to me). My
>> script worked perfectly for a year, and today, suddenly stop working
>> because R Studio begins to warn me about illegal characters in the script.
>>
>> System is on W 10, and R 3.4.1 is working with R Studio. R Studio is
>> updated today to the latest one because of this problem with the hope of
>> resolving the problem (but no luck) and they are used as their default
>> installation settings. Anyway, the problem example may not be repoducable
>> right now but if it is, I can give detailed one later.
>>
>> While the original working code is this (there is no synax error, too in
>> the code because it was working perfectly until today before updating R
>> Studio, error also came out before this update as I mensioned before);
>>
>> legend(c("Kapan??",""20 G?nl?k,"50 G?nl?k"),col=c("black"...
>>
>> The warning is this;
>>
>> Error: unexpected symbol inside:
>> " Encoding(kill3) <- "latin1" legend(c(kill1,kill2,"50
>> G?nl?k"),col=c("black"? and can be solved when converted ??? to ?u?.
>> Addition to this another solution (at least for me) is this;
>>
>> kill1<-"Kapan??"
>> Encoding(kill1) <- "UTF-8" (these two statements are not needed but fort
>> he sake of code integrity, is applied to it, too. If kill1 is converted to
>> latin1, this time it is broken)
>> kill2<-"22 G?nl?k MA"
>> Encoding(kill2) <- "latin1"
>> kill3<-"50 G?nl?k MA"
>> Encoding(kill3) <- "latin1"
>>
>> And also it is set to ?ASK? and always ?UTF-8? is selected.
>>
>> But, I also wonder why today and what changed so R Studio stops suddenly
>> running the script? I can not following up the changes anymore as used to
>> be and if this is a character set problem, it is coming back again and
>> again. What is the permenant solution of this? This is like an endless
>> problem?
>>
>> With my best regards and thanks for your patience?.
>>
>> Levent Terlemez.
>>
>>
>>
>> ________________________________
>> YASAL UYARI: Bu e-postan?n i?erdi?i bilgiler (ekleri de dahil olmak ?zere)
>> gizlidir. Sahibinin onay? olmaks?z?n i?eri?i kopyalanamaz, ???nc? ki?ilere
>> a??klanamaz veya iletilemez . Bu mesaj?n g?nderilmek istendi?i ki?i
>> de?ilseniz (ya da bu e-postay? yanl??l?kla ald?ysan?z), l?tfen yollayan
>> ki?iyi haberdar ediniz ve mesaj? sisteminizden derhal siliniz. Eski?ehir
>> Teknik ?niversitesi, bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz
>> oldu?u konusunda bir garanti vermemektedir. Bu nedenle, bilgilerin ne
>> ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan,
>> saklanmas?ndan Eski?ehir Teknik ?niversitesi sorumlu de?ildir. Bu mesaj?n
>> i?eri?i yazar?na ait olup, Eski?ehir Teknik ?niversitesi'nin g?r??lerini
>> i?ermeyebilir. Bu e-posta bizce bilinen t?m bilgisayar vir?slerine kar??
>> taranm??t?r.
>>
>> DISCLAIMER: This e-mail (including any attachments) may contain
>> confidential and/or privileged information. Copying, disclosure or
>> distribution of the material in this e-mail without owner authority is
>> strictly forbidden. If you are not the intended recipient (or have received
>> this e-mail in error), please notify the sender and delete it from your
>> system immediately. Eskisehir Technical University makes no warranty as to
>> the accuracy or completeness of any information contained in this message
>> and hereby excludes any liability of any kind for the information contained
>> therein or for the information transmission, reception, storage or use of
>> such in any way whatsoever. Any opinions expressed in this message are
>> those of the author and may not necessarily reflect the opinions of
>> Eskisehir Technical University. This e-mail has been scanned for all
>> computer viruses known to us.
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |kry|ov @end|ng |rom d|@root@org  Tue Jul  9 19:02:08 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 9 Jul 2024 20:02:08 +0300
Subject: [R] Weird R Studio behaviour...
In-Reply-To: <D8A08C72-70E9-4FB9-AACB-342AF657A944@contoso.com>
References: <D8A08C72-70E9-4FB9-AACB-342AF657A944@contoso.com>
Message-ID: <20240709200208.666d15d0@arachnoid>

? Tue, 9 Jul 2024 13:02:17 +0000
Levent TERLEMEZ via R-help <r-help at r-project.org> ?????:

> System is on W 10, and R 3.4.1 is working with R Studio. R Studio is
> updated today

https://posit.co/download/rstudio-desktop/ says "RStudio requires R
3.6.0+" so I'm afraid they don't support this configuration any more.

-- 
Best regards,
Ivan


From @@h|mk@poor @end|ng |rom gm@||@com  Wed Jul 10 10:58:28 2024
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 10 Jul 2024 14:28:28 +0530
Subject: [R] Implementation for selecting lag of a lag window spectral
 estimator using generalized cross validation (using deviance)
Message-ID: <CAC8=1epK=D7NBzfw3NiEWovQ9vbQUQvnsSUiq_-GbiOD0WKjpw@mail.gmail.com>

Dear All,

I am looking for:

A software to select the lag length for a lag window spectral estimator.
Also, I have a small query in the reprex given below.

Background for the above, from the book by Percival and Walden:

1. We are given X_1,...,X_n which is one realization of a stochastic process.
2. We may compute the periodogram using FFT, for example by the
function spectrum in R.
3. The above is badly biased so we taper X_1,...,X_n to reduce the
bias in the periodogram.
4. Now that the bias in under control, we focus on reducing the
variance. So we take a window like for eg. the Parzen window, and
choose
a lag length m which controls the amount of smoothing across frequencies.
5. One way of choosing m is mentioned in :
https://web.archive.org/web/20080221221221id_/http://www.stat.uiuc.edu/~ombao/PAPERS.dir/gcvbmka.pdf

I am looking for an R package which implements 5.

Here is a reprex:

# 1.  Periodogram which may be biased
plot(spectrum(lh,taper= 0, method="pgram"),log="dB")

# 2. Using the default in built cosine taper
plot(spectrum(lh,taper = .3, method="pgram"),log="dB")

# 2. Again, using slepian taper
library(multitaper)
# I choose: n = length(lh), k =1, nw=2
mytaper = dpss(n=length(lh), k=1 , nw=2, returnEigenvalues=TRUE)
# Tapered series
lh * mytaper$v
# I may compute the spectrum with reduced bias as:
plot(spectrum(lh*mytaper$v,method="pgram"),log="dB")

# We now focus on the variance
# For a fixed m = 10, using a Parzen window.
library(gsignal)
parzenwin(10)

# The following 2 lines of code, where I try to do the same thing in 2
different ways, did not work for me:

kernapply( spectrum(lh*mytaper$v,method="pgram")$spec,parzenwin(10),circular=TRUE)
spectrum(lh*mytaper$v,kernel  = parzenwin(10),method="pgram")

# ?spec.pgram says
kernel: alternatively, a kernel smoother of class ?"tskernel"?.

How can I see all available kernels of class tskernel ?

The important question here is how to choose m which implies a bias -
variance tradeoff. Ombao et al, have a generalized cross validation
method to choose m.
Please see point 5 above. Does that exist in R ?

Many thanks,
Ashim


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 10 15:39:41 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 10 Jul 2024 06:39:41 -0700
Subject: [R] Implementation for selecting lag of a lag window spectral
 estimator using generalized cross validation (using deviance)
In-Reply-To: <CAC8=1epK=D7NBzfw3NiEWovQ9vbQUQvnsSUiq_-GbiOD0WKjpw@mail.gmail.com>
References: <CAC8=1epK=D7NBzfw3NiEWovQ9vbQUQvnsSUiq_-GbiOD0WKjpw@mail.gmail.com>
Message-ID: <CAGxFJbQL1v2KpOhjoZH+JeZQ-4MSLQb3LTKbBwyxBDXo9WAn7w@mail.gmail.com>

Have a look at the CRAN Time Series Task View:

https://cran.r-project.org/web/views/TimeSeries.html

Generally speaking, R-help is for help on R programming, not detailed
statistical questions, so it is less likely that your query would receive a
useful answer here.

Cheers,
Bert

On Wed, Jul 10, 2024 at 1:59?AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear All,
>
> I am looking for:
>
> A software to select the lag length for a lag window spectral estimator.
> Also, I have a small query in the reprex given below.
>
> Background for the above, from the book by Percival and Walden:
>
> 1. We are given X_1,...,X_n which is one realization of a stochastic
> process.
> 2. We may compute the periodogram using FFT, for example by the
> function spectrum in R.
> 3. The above is badly biased so we taper X_1,...,X_n to reduce the
> bias in the periodogram.
> 4. Now that the bias in under control, we focus on reducing the
> variance. So we take a window like for eg. the Parzen window, and
> choose
> a lag length m which controls the amount of smoothing across frequencies.
> 5. One way of choosing m is mentioned in :
>
> https://web.archive.org/web/20080221221221id_/http://www.stat.uiuc.edu/~ombao/PAPERS.dir/gcvbmka.pdf
>
> I am looking for an R package which implements 5.
>
> Here is a reprex:
>
> # 1.  Periodogram which may be biased
> plot(spectrum(lh,taper= 0, method="pgram"),log="dB")
>
> # 2. Using the default in built cosine taper
> plot(spectrum(lh,taper = .3, method="pgram"),log="dB")
>
> # 2. Again, using slepian taper
> library(multitaper)
> # I choose: n = length(lh), k =1, nw=2
> mytaper = dpss(n=length(lh), k=1 , nw=2, returnEigenvalues=TRUE)
> # Tapered series
> lh * mytaper$v
> # I may compute the spectrum with reduced bias as:
> plot(spectrum(lh*mytaper$v,method="pgram"),log="dB")
>
> # We now focus on the variance
> # For a fixed m = 10, using a Parzen window.
> library(gsignal)
> parzenwin(10)
>
> # The following 2 lines of code, where I try to do the same thing in 2
> different ways, did not work for me:
>
> kernapply(
> spectrum(lh*mytaper$v,method="pgram")$spec,parzenwin(10),circular=TRUE)
> spectrum(lh*mytaper$v,kernel  = parzenwin(10),method="pgram")
>
> # ?spec.pgram says
> kernel: alternatively, a kernel smoother of class ?"tskernel"?.
>
> How can I see all available kernels of class tskernel ?
>
> The important question here is how to choose m which implies a bias -
> variance tradeoff. Ombao et al, have a generalized cross validation
> method to choose m.
> Please see point 5 above. Does that exist in R ?
>
> Many thanks,
> Ashim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Fri Jul 12 10:54:03 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 12 Jul 2024 16:54:03 +0800
Subject: [R] grep
Message-ID: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>

Below is part a regression printout. How can I use "grep" to identify 
rows headed by variables (first column) with a certain label. In this 
case, I like to find variables containing "somewhath", 
"veryh",?"somewhatm", "verym", "somewhatc", "veryc","somewhatl", 
"veryl". The result should be an index 6:13 or 6,7,8,9,10,11,12,13. Note 
that they all contain "somewhat" and "very". Thanks.

est se t p g sig x.1.age 0.0341 0.0138 2.4766 0.0133 -3.8835e-04 ** 
x.1.sleep -0.1108 0.0059 -18.6277 0.0000 -4.4572e-04 *** x.1.primary 
-0.0694 0.0289 -2.4002 0.0164 -9.9638e-06 ** x.1.middle -0.2909 0.0356 
-8.1657 0.0000 -1.4913e-05 *** x.1.high -0.4267 0.0463 -9.2118 0.0000 
-3.6246e-05 *** x.1.somewhath -0.6188 0.0256 -24.1971 0.0000 -3.1337e-05 
*** x.1.veryh -0.7580 0.0331 -22.8695 0.0000 -2.9558e-05 *** 
x.1.somewhatm -0.3413 0.0426 -8.0112 0.0000 -1.8920e-05 *** x.1.verym 
-0.3813 0.0446 -8.5413 0.0000 -4.4029e-05 *** x.1.somewhatc -0.3101 
0.0649 -4.7783 0.0000 -1.4353e-05 *** x.1.veryc -0.2977 0.0648 -4.5910 
0.0000 -4.8986e-05 *** x.1.somewhatl -0.6310 0.0424 -14.8846 0.0000 
-1.9543e-05 *** x.1.veryl -0.9132 0.0462 -19.7525 0.0000 -4.4603e-05 *** 
...

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Jul 12 11:09:32 2024
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 12 Jul 2024 11:09:32 +0200
Subject: [R] grep
In-Reply-To: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>
References: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>
Message-ID: <b0700c60-74ca-4b02-a813-68202010f634@statistik.tu-dortmund.de>



On 12.07.2024 10:54, Steven Yen wrote:
> Below is part a regression printout. How can I use "grep" to identify
> rows headed by variables (first column) with a certain label. In this
> case, I like to find variables containing "somewhath",
> "veryh",?"somewhatm", "verym", "somewhatc", "veryc","somewhatl",
> "veryl". The result should be an index 6:13 or 6,7,8,9,10,11,12,13. Note
> that they all contain "somewhat" and "very". Thanks.

Sounds like homework?

which(grep("very|somewhat", x))

Best,
Uwe Ligges


> est se t p g sig x.1.age 0.0341 0.0138 2.4766 0.0133 -3.8835e-04 **
> x.1.sleep -0.1108 0.0059 -18.6277 0.0000 -4.4572e-04 *** x.1.primary
> -0.0694 0.0289 -2.4002 0.0164 -9.9638e-06 ** x.1.middle -0.2909 0.0356
> -8.1657 0.0000 -1.4913e-05 *** x.1.high -0.4267 0.0463 -9.2118 0.0000
> -3.6246e-05 *** x.1.somewhath -0.6188 0.0256 -24.1971 0.0000 -3.1337e-05
> *** x.1.veryh -0.7580 0.0331 -22.8695 0.0000 -2.9558e-05 ***
> x.1.somewhatm -0.3413 0.0426 -8.0112 0.0000 -1.8920e-05 *** x.1.verym
> -0.3813 0.0446 -8.5413 0.0000 -4.4029e-05 *** x.1.somewhatc -0.3101
> 0.0649 -4.7783 0.0000 -1.4353e-05 *** x.1.veryc -0.2977 0.0648 -4.5910
> 0.0000 -4.8986e-05 *** x.1.somewhatl -0.6310 0.0424 -14.8846 0.0000
> -1.9543e-05 *** x.1.veryl -0.9132 0.0462 -19.7525 0.0000 -4.4603e-05 ***
> ...
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @tyen @end|ng |rom ntu@edu@tw  Fri Jul 12 11:26:16 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 12 Jul 2024 17:26:16 +0800
Subject: [R] grep
In-Reply-To: <b0700c60-74ca-4b02-a813-68202010f634@statistik.tu-dortmund.de>
References: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>
 <b0700c60-74ca-4b02-a813-68202010f634@statistik.tu-dortmund.de>
Message-ID: <a9ad4017-ba88-4364-a4c2-0e68389b333b@ntu.edu.tw>

Thanks. In this case below, what is "x"? I tried rownames(out) which did 
not work.

Sorry. Does this sound like homework to you?

On 7/12/2024 5:09 PM, Uwe Ligges wrote:
>
>
> On 12.07.2024 10:54, Steven Yen wrote:
>> Below is part a regression printout. How can I use "grep" to identify
>> rows headed by variables (first column) with a certain label. In this
>> case, I like to find variables containing "somewhath",
>> "veryh",?"somewhatm", "verym", "somewhatc", "veryc","somewhatl",
>> "veryl". The result should be an index 6:13 or 6,7,8,9,10,11,12,13. Note
>> that they all contain "somewhat" and "very". Thanks.
>
> Sounds like homework?
>
> which(grep("very|somewhat", x))
>
> Best,
> Uwe Ligges
>
>
>> est se t p g sig x.1.age 0.0341 0.0138 2.4766 0.0133 -3.8835e-04 **
>> x.1.sleep -0.1108 0.0059 -18.6277 0.0000 -4.4572e-04 *** x.1.primary
>> -0.0694 0.0289 -2.4002 0.0164 -9.9638e-06 ** x.1.middle -0.2909 0.0356
>> -8.1657 0.0000 -1.4913e-05 *** x.1.high -0.4267 0.0463 -9.2118 0.0000
>> -3.6246e-05 *** x.1.somewhath -0.6188 0.0256 -24.1971 0.0000 -3.1337e-05
>> *** x.1.veryh -0.7580 0.0331 -22.8695 0.0000 -2.9558e-05 ***
>> x.1.somewhatm -0.3413 0.0426 -8.0112 0.0000 -1.8920e-05 *** x.1.verym
>> -0.3813 0.0446 -8.5413 0.0000 -4.4029e-05 *** x.1.somewhatc -0.3101
>> 0.0649 -4.7783 0.0000 -1.4353e-05 *** x.1.veryc -0.2977 0.0648 -4.5910
>> 0.0000 -4.8986e-05 *** x.1.somewhatl -0.6310 0.0424 -14.8846 0.0000
>> -1.9543e-05 *** x.1.veryl -0.9132 0.0462 -19.7525 0.0000 -4.4603e-05 ***
>> ...
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Fri Jul 12 11:34:45 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 12 Jul 2024 17:34:45 +0800
Subject: [R] grep
In-Reply-To: <a9ad4017-ba88-4364-a4c2-0e68389b333b@ntu.edu.tw>
References: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>
 <b0700c60-74ca-4b02-a813-68202010f634@statistik.tu-dortmund.de>
 <a9ad4017-ba88-4364-a4c2-0e68389b333b@ntu.edu.tw>
Message-ID: <81d6d273-a7b6-4665-98e1-56583981ca81@ntu.edu.tw>

Could not get "which" to work, but my grep worked. Thanks.

> which(grep("very|somewhat",names(goprobit.p$est))) Error in 
which(grep("very|somewhat", names(goprobit.p$est))) : argument to 
'which' is not logical > grep("very|somewhat",names(goprobit.p$est)) [1] 
6 7 8 9 10 11 12 13 28 29 30 31 32 33 34 35 50 51 52 53 54 55 56 57

On 7/12/2024 5:26 PM, Steven Yen wrote:
> Thanks. In this case below, what is "x"? I tried rownames(out) which 
> did not work.
>
> Sorry. Does this sound like homework to you?
>
> On 7/12/2024 5:09 PM, Uwe Ligges wrote:
>>
>>
>> On 12.07.2024 10:54, Steven Yen wrote:
>>> Below is part a regression printout. How can I use "grep" to identify
>>> rows headed by variables (first column) with a certain label. In this
>>> case, I like to find variables containing "somewhath",
>>> "veryh",?"somewhatm", "verym", "somewhatc", "veryc","somewhatl",
>>> "veryl". The result should be an index 6:13 or 6,7,8,9,10,11,12,13. 
>>> Note
>>> that they all contain "somewhat" and "very". Thanks.
>>
>> Sounds like homework?
>>
>> which(grep("very|somewhat", x))
>>
>> Best,
>> Uwe Ligges
>>
>>
>>> est se t p g sig x.1.age 0.0341 0.0138 2.4766 0.0133 -3.8835e-04 **
>>> x.1.sleep -0.1108 0.0059 -18.6277 0.0000 -4.4572e-04 *** x.1.primary
>>> -0.0694 0.0289 -2.4002 0.0164 -9.9638e-06 ** x.1.middle -0.2909 0.0356
>>> -8.1657 0.0000 -1.4913e-05 *** x.1.high -0.4267 0.0463 -9.2118 0.0000
>>> -3.6246e-05 *** x.1.somewhath -0.6188 0.0256 -24.1971 0.0000 
>>> -3.1337e-05
>>> *** x.1.veryh -0.7580 0.0331 -22.8695 0.0000 -2.9558e-05 ***
>>> x.1.somewhatm -0.3413 0.0426 -8.0112 0.0000 -1.8920e-05 *** x.1.verym
>>> -0.3813 0.0446 -8.5413 0.0000 -4.4029e-05 *** x.1.somewhatc -0.3101
>>> 0.0649 -4.7783 0.0000 -1.4353e-05 *** x.1.veryc -0.2977 0.0648 -4.5910
>>> 0.0000 -4.8986e-05 *** x.1.somewhatl -0.6310 0.0424 -14.8846 0.0000
>>> -1.9543e-05 *** x.1.veryl -0.9132 0.0462 -19.7525 0.0000 -4.4603e-05 
>>> ***
>>> ...
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Fri Jul 12 11:42:05 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 12 Jul 2024 17:42:05 +0800
Subject: [R] grep
In-Reply-To: <81d6d273-a7b6-4665-98e1-56583981ca81@ntu.edu.tw>
References: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>
 <b0700c60-74ca-4b02-a813-68202010f634@statistik.tu-dortmund.de>
 <a9ad4017-ba88-4364-a4c2-0e68389b333b@ntu.edu.tw>
 <81d6d273-a7b6-4665-98e1-56583981ca81@ntu.edu.tw>
Message-ID: <b73784ce-c018-4587-bcd9-64adbd0dc4a7@ntu.edu.tw>

Sorry. grepl worked:

which(grepl("very|somewhat",names(goprobit.p$est)))

On 7/12/2024 5:34 PM, Steven Yen wrote:
>
> Could not get "which" to work, but my grep worked. Thanks.
>
> > which(grep("very|somewhat",names(goprobit.p$est))) Error in 
> which(grep("very|somewhat", names(goprobit.p$est))) : argument to 
> 'which' is not logical > grep("very|somewhat",names(goprobit.p$est)) 
> [1] 6 7 8 9 10 11 12 13 28 29 30 31 32 33 34 35 50 51 52 53 54 55 56 57
> On 7/12/2024 5:26 PM, Steven Yen wrote:
>> Thanks. In this case below, what is "x"? I tried rownames(out) which 
>> did not work.
>>
>> Sorry. Does this sound like homework to you?
>>
>> On 7/12/2024 5:09 PM, Uwe Ligges wrote:
>>>
>>>
>>> On 12.07.2024 10:54, Steven Yen wrote:
>>>> Below is part a regression printout. How can I use "grep" to identify
>>>> rows headed by variables (first column) with a certain label. In this
>>>> case, I like to find variables containing "somewhath",
>>>> "veryh",?"somewhatm", "verym", "somewhatc", "veryc","somewhatl",
>>>> "veryl". The result should be an index 6:13 or 6,7,8,9,10,11,12,13. 
>>>> Note
>>>> that they all contain "somewhat" and "very". Thanks.
>>>
>>> Sounds like homework?
>>>
>>> which(grep("very|somewhat", x))
>>>
>>> Best,
>>> Uwe Ligges
>>>
>>>
>>>> est se t p g sig x.1.age 0.0341 0.0138 2.4766 0.0133 -3.8835e-04 **
>>>> x.1.sleep -0.1108 0.0059 -18.6277 0.0000 -4.4572e-04 *** x.1.primary
>>>> -0.0694 0.0289 -2.4002 0.0164 -9.9638e-06 ** x.1.middle -0.2909 0.0356
>>>> -8.1657 0.0000 -1.4913e-05 *** x.1.high -0.4267 0.0463 -9.2118 0.0000
>>>> -3.6246e-05 *** x.1.somewhath -0.6188 0.0256 -24.1971 0.0000 
>>>> -3.1337e-05
>>>> *** x.1.veryh -0.7580 0.0331 -22.8695 0.0000 -2.9558e-05 ***
>>>> x.1.somewhatm -0.3413 0.0426 -8.0112 0.0000 -1.8920e-05 *** x.1.verym
>>>> -0.3813 0.0446 -8.5413 0.0000 -4.4029e-05 *** x.1.somewhatc -0.3101
>>>> 0.0649 -4.7783 0.0000 -1.4353e-05 *** x.1.veryc -0.2977 0.0648 -4.5910
>>>> 0.0000 -4.8986e-05 *** x.1.somewhatl -0.6310 0.0424 -14.8846 0.0000
>>>> -1.9543e-05 *** x.1.veryl -0.9132 0.0462 -19.7525 0.0000 
>>>> -4.4603e-05 ***
>>>> ...
>>>>
>>>> ????[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From JH@rm@e @end|ng |rom roku@com  Fri Jul 12 16:46:43 2024
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Fri, 12 Jul 2024 14:46:43 +0000
Subject: [R] grep
Message-ID: <F1037460-C263-4821-91A3-E93A2AABCC7A@roku.com>

which(grepl(....)) looks odd. Doesn't grep by itself return the correct vector of indices?

Regards,
Jorgen Harmse.?


Message: 5
Date: Fri, 12 Jul 2024 17:42:05 +0800
From: Steven Yen <styen at ntu.edu.tw <mailto:styen at ntu.edu.tw>>
To: Uwe Ligges <ligges at statistik.tu-dortmund.de <mailto:ligges at statistik.tu-dortmund.de>>, R-help Mailing List
<r-help at r-project.org <mailto:r-help at r-project.org>>
Cc: Steven Yen <syen04 at gmail.com <mailto:syen04 at gmail.com>>
Subject: Re: [R] grep
Message-ID: <b73784ce-c018-4587-bcd9-64adbd0dc4a7 at ntu.edu.tw <mailto:b73784ce-c018-4587-bcd9-64adbd0dc4a7 at ntu.edu.tw>>
Content-Type: text/plain; charset="utf-8"


Sorry. grepl worked:


which(grepl("very|somewhat",names(goprobit.p$est)))





From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jul 12 17:23:04 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 12 Jul 2024 16:23:04 +0100
Subject: [R] grep
In-Reply-To: <a9ad4017-ba88-4364-a4c2-0e68389b333b@ntu.edu.tw>
References: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>
 <b0700c60-74ca-4b02-a813-68202010f634@statistik.tu-dortmund.de>
 <a9ad4017-ba88-4364-a4c2-0e68389b333b@ntu.edu.tw>
Message-ID: <b96273a5-8499-4445-a12f-d9f90f92e0a2@sapo.pt>


Hello,l

Though the question is already answered, here is another answer to what 
is 'x'.
The output in the OP is not a lm or glm output but if your regression 
model was programmed according to recommended practices, there must be a 
'coefficients' member in the list or object it returns and the following 
should work.


# this is 'x', a named character vector
coef(fit)
#
fit |> coef() |> names() |> grep("somewhat|very", x = _)


Hope this helps,

Rui Barradas

?s 10:26 de 12/07/2024, Steven Yen escreveu:
> Thanks. In this case below, what is "x"? I tried rownames(out) which did 
> not work.
> 
> Sorry. Does this sound like homework to you?
> 
> On 7/12/2024 5:09 PM, Uwe Ligges wrote:
>>
>>
>> On 12.07.2024 10:54, Steven Yen wrote:
>>> Below is part a regression printout. How can I use "grep" to identify
>>> rows headed by variables (first column) with a certain label. In this
>>> case, I like to find variables containing "somewhath",
>>> "veryh",?"somewhatm", "verym", "somewhatc", "veryc","somewhatl",
>>> "veryl". The result should be an index 6:13 or 6,7,8,9,10,11,12,13. Note
>>> that they all contain "somewhat" and "very". Thanks.
>>
>> Sounds like homework?
>>
>> which(grep("very|somewhat", x))
>>
>> Best,
>> Uwe Ligges
>>
>>
>>> est se t p g sig x.1.age 0.0341 0.0138 2.4766 0.0133 -3.8835e-04 **
>>> x.1.sleep -0.1108 0.0059 -18.6277 0.0000 -4.4572e-04 *** x.1.primary
>>> -0.0694 0.0289 -2.4002 0.0164 -9.9638e-06 ** x.1.middle -0.2909 0.0356
>>> -8.1657 0.0000 -1.4913e-05 *** x.1.high -0.4267 0.0463 -9.2118 0.0000
>>> -3.6246e-05 *** x.1.somewhath -0.6188 0.0256 -24.1971 0.0000 -3.1337e-05
>>> *** x.1.veryh -0.7580 0.0331 -22.8695 0.0000 -2.9558e-05 ***
>>> x.1.somewhatm -0.3413 0.0426 -8.0112 0.0000 -1.8920e-05 *** x.1.verym
>>> -0.3813 0.0446 -8.5413 0.0000 -4.4029e-05 *** x.1.somewhatc -0.3101
>>> 0.0649 -4.7783 0.0000 -1.4353e-05 *** x.1.veryc -0.2977 0.0648 -4.5910
>>> 0.0000 -4.8986e-05 *** x.1.somewhatl -0.6310 0.0424 -14.8846 0.0000
>>> -1.9543e-05 *** x.1.veryl -0.9132 0.0462 -19.7525 0.0000 -4.4603e-05 ***
>>> ...
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From @tyen @end|ng |rom ntu@edu@tw  Fri Jul 12 18:13:23 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sat, 13 Jul 2024 00:13:23 +0800
Subject: [R] grep
In-Reply-To: <47360462-553b-4223-99d7-2225ad03a6ed@ntu.edu.tw>
References: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>
 <b0700c60-74ca-4b02-a813-68202010f634@statistik.tu-dortmund.de>
 <a9ad4017-ba88-4364-a4c2-0e68389b333b@ntu.edu.tw>
 <b96273a5-8499-4445-a12f-d9f90f92e0a2@sapo.pt>
 <47360462-553b-4223-99d7-2225ad03a6ed@ntu.edu.tw>
Message-ID: <fd6df188-4eaa-404b-bcb8-9f0fdb2961a8@ntu.edu.tw>

Now I've found another way to make it work. All I need is to pick up the 
names in the column (x.1.age...).

> v<-pr(goprobit.p); v

Maximum-Likelihood Estimates weighted = FALSE iterations = 5 logLik = 
-14160.75 finalHessian = TRUE Covariance matrix is Robust Number of 
parameters = 66 Sample size = 17922 est se t p g sig x.1.age 0.0341 
0.0138 2.4766 0.0133 -3.8835e-04 ** x.1.sleep -0.1108 0.0059 -18.6277 
0.0000 -4.4572e-04 *** x.1.primary -0.0694 0.0289 -2.4002 0.0164 
-9.9638e-06 ** x.1.middle -0.2909 0.0356 -8.1657 0.0000 -1.4913e-05 *** 
... > rownames(v) [1] "x.1.age" "x.1.sleep" "x.1.primary" "x.1.middle" 
[5] "x.1.high" "x.1.somewhath" "x.1.veryh" "x.1.somewhatm" ...Treating 
it as the first column does not work, because the first column contains 
the numbers. > v[,1] [1] 0.0341 -0.1108 -0.0694 -0.2909 -0.4267 -0.6188 
-0.7580 -0.3413 -0.3813 [10] -0.3101 -0.2977 -0.6310 -0.9132 0.1885 
-0.0887 -0.0850 0.0847 -0.1588

On 7/12/2024 11:57 PM, Steven Yen wrote:
> Thanks. First and second of the following worked, but the third (with 
> coef) did not. This may be because I programmed my own estimation 
> program. In short,
>
> names(goprobit.p$est) was recognized, but
> names(coef(goprobit)) was not
>
> > which(grepl("very|somewhat",names(goprobit.p$est)))
> ?[1]? 6? 7? 8? 9 10 11 12 13 28 29 30 31 32 33 34 35 50 51 52 53 54 55 
> 56 57
> > jj<-grep("very|somewhat",names(goprobit.p$est)); length(jj)
> [1] 24
> > jj<-grep("very|somewhat",names(coef(goprobit))); length(jj)
> Error: object 'goprobit' not found
>
> On 7/12/2024 11:23 PM, Rui Barradas wrote:
>>
>> Hello,l
>>
>> Though the question is already answered, here is another answer to 
>> what is 'x'.
>> The output in the OP is not a lm or glm output but if your regression 
>> model was programmed according to recommended practices, there must 
>> be a 'coefficients' member in the list or object it returns and the 
>> following should work.
>>
>>
>> # this is 'x', a named character vector
>> coef(fit)
>> #
>> fit |> coef() |> names() |> grep("somewhat|very", x = _)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 10:26 de 12/07/2024, Steven Yen escreveu:
>>> Thanks. In this case below, what is "x"? I tried rownames(out) which 
>>> did not work.
>>>
>>> Sorry. Does this sound like homework to you?
>>>
>>> On 7/12/2024 5:09 PM, Uwe Ligges wrote:
>>>>
>>>>
>>>> On 12.07.2024 10:54, Steven Yen wrote:
>>>>> Below is part a regression printout. How can I use "grep" to identify
>>>>> rows headed by variables (first column) with a certain label. In this
>>>>> case, I like to find variables containing "somewhath",
>>>>> "veryh",?"somewhatm", "verym", "somewhatc", "veryc","somewhatl",
>>>>> "veryl". The result should be an index 6:13 or 
>>>>> 6,7,8,9,10,11,12,13. Note
>>>>> that they all contain "somewhat" and "very". Thanks.
>>>>
>>>> Sounds like homework?
>>>>
>>>> which(grep("very|somewhat", x))
>>>>
>>>> Best,
>>>> Uwe Ligges
>>>>
>>>>
>>>>> est se t p g sig x.1.age 0.0341 0.0138 2.4766 0.0133 -3.8835e-04 **
>>>>> x.1.sleep -0.1108 0.0059 -18.6277 0.0000 -4.4572e-04 *** x.1.primary
>>>>> -0.0694 0.0289 -2.4002 0.0164 -9.9638e-06 ** x.1.middle -0.2909 
>>>>> 0.0356
>>>>> -8.1657 0.0000 -1.4913e-05 *** x.1.high -0.4267 0.0463 -9.2118 0.0000
>>>>> -3.6246e-05 *** x.1.somewhath -0.6188 0.0256 -24.1971 0.0000 
>>>>> -3.1337e-05
>>>>> *** x.1.veryh -0.7580 0.0331 -22.8695 0.0000 -2.9558e-05 ***
>>>>> x.1.somewhatm -0.3413 0.0426 -8.0112 0.0000 -1.8920e-05 *** x.1.verym
>>>>> -0.3813 0.0446 -8.5413 0.0000 -4.4029e-05 *** x.1.somewhatc -0.3101
>>>>> 0.0649 -4.7783 0.0000 -1.4353e-05 *** x.1.veryc -0.2977 0.0648 
>>>>> -4.5910
>>>>> 0.0000 -4.8986e-05 *** x.1.somewhatl -0.6310 0.0424 -14.8846 0.0000
>>>>> -1.9543e-05 *** x.1.veryl -0.9132 0.0462 -19.7525 0.0000 
>>>>> -4.4603e-05 ***
>>>>> ...
>>>>>
>>>>> ????[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide 
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sat Jul 13 13:13:41 2024
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sat, 13 Jul 2024 16:43:41 +0530
Subject: [R] Obtaining predicted probabilities for Logistic regression
Message-ID: <CA+dpOJ=GGZE6TTwky6pWPGxd+YKBTiK3YqFXAbAwgR_PpvvZLQ@mail.gmail.com>

Hi,

I ran below code

Dat = read.csv('https://raw.githubusercontent.com/sam16tyagi/Machine-Learning-techniques-in-python/master/logistic%20regression%20dataset-Social_Network_Ads.csv')
head(Dat)
Model = glm(Purchased ~ Gender, data = Dat, family = binomial())
head(predict(Model, type="response"))
My_Predict = 1/(1+exp(-1 * (as.vector(coef(Model))[1] *
as.vector(coef(Model))[2] * ifelse(Dat['Gender'] == "Male", 1, 0))))
head(My_Predict)

However, My_Predict and predict(Model, type="response")) are differing
when I tried to manually calculate prediction.

Could you please help to identify what was the mistake I made?


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jul 13 15:16:21 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 13 Jul 2024 14:16:21 +0100
Subject: [R] Obtaining predicted probabilities for Logistic regression
In-Reply-To: <CA+dpOJ=GGZE6TTwky6pWPGxd+YKBTiK3YqFXAbAwgR_PpvvZLQ@mail.gmail.com>
References: <CA+dpOJ=GGZE6TTwky6pWPGxd+YKBTiK3YqFXAbAwgR_PpvvZLQ@mail.gmail.com>
Message-ID: <1cc2695d-6d7e-4fee-abbe-783de6d5e11c@sapo.pt>

?s 12:13 de 13/07/2024, Christofer Bogaso escreveu:
> Hi,
> 
> I ran below code
> 
> Dat = read.csv('https://raw.githubusercontent.com/sam16tyagi/Machine-Learning-techniques-in-python/master/logistic%20regression%20dataset-Social_Network_Ads.csv')
> head(Dat)
> Model = glm(Purchased ~ Gender, data = Dat, family = binomial())
> head(predict(Model, type="response"))
> My_Predict = 1/(1+exp(-1 * (as.vector(coef(Model))[1] *
> as.vector(coef(Model))[2] * ifelse(Dat['Gender'] == "Male", 1, 0))))
> head(My_Predict)
> 
> However, My_Predict and predict(Model, type="response")) are differing
> when I tried to manually calculate prediction.
> 
> Could you please help to identify what was the mistake I made?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Sometimes when there is an error, the best way to correct it is to 
rewrite the offending part of the code.
In your case, after as.vector(coef(Model))[1] you should have a plus sign.



Dat = 
read.csv('https://raw.githubusercontent.com/sam16tyagi/Machine-Learning-techniques-in-python/master/logistic%20regression%20dataset-Social_Network_Ads.csv')
head(Dat)
Model = glm(Purchased ~ Gender, data = Dat, family = binomial())

# use matrix algebra
x <- cbind(1, (Dat$Gender == "Male")) %*% coef(Model)
pred1 <- exp(x)/(1 + exp(x))

# use the fitted line equation
y <- coef(Model)[1L] + coef(Model)[2L] * (Dat$Gender == "Male")
pred2 <- exp(y)/(1 + exp(y))

head(predict(Model, type="response"))
head(pred1) |> c()
head(pred2)


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sat Jul 13 18:53:37 2024
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sat, 13 Jul 2024 22:23:37 +0530
Subject: [R] Obtaining predicted probabilities for Logistic regression
In-Reply-To: <1cc2695d-6d7e-4fee-abbe-783de6d5e11c@sapo.pt>
References: <CA+dpOJ=GGZE6TTwky6pWPGxd+YKBTiK3YqFXAbAwgR_PpvvZLQ@mail.gmail.com>
 <1cc2695d-6d7e-4fee-abbe-783de6d5e11c@sapo.pt>
Message-ID: <CA+dpOJkQfMDby9R990L9R9LKtsGoTsFMzw11fRKD55hLouHMyg@mail.gmail.com>

Many thanks.

May be I need to check my eyes before anything!!!

On Sat, Jul 13, 2024 at 6:46?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> ?s 12:13 de 13/07/2024, Christofer Bogaso escreveu:
> > Hi,
> >
> > I ran below code
> >
> > Dat = read.csv('https://raw.githubusercontent.com/sam16tyagi/Machine-Learning-techniques-in-python/master/logistic%20regression%20dataset-Social_Network_Ads.csv')
> > head(Dat)
> > Model = glm(Purchased ~ Gender, data = Dat, family = binomial())
> > head(predict(Model, type="response"))
> > My_Predict = 1/(1+exp(-1 * (as.vector(coef(Model))[1] *
> > as.vector(coef(Model))[2] * ifelse(Dat['Gender'] == "Male", 1, 0))))
> > head(My_Predict)
> >
> > However, My_Predict and predict(Model, type="response")) are differing
> > when I tried to manually calculate prediction.
> >
> > Could you please help to identify what was the mistake I made?
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> Sometimes when there is an error, the best way to correct it is to
> rewrite the offending part of the code.
> In your case, after as.vector(coef(Model))[1] you should have a plus sign.
>
>
>
> Dat =
> read.csv('https://raw.githubusercontent.com/sam16tyagi/Machine-Learning-techniques-in-python/master/logistic%20regression%20dataset-Social_Network_Ads.csv')
> head(Dat)
> Model = glm(Purchased ~ Gender, data = Dat, family = binomial())
>
> # use matrix algebra
> x <- cbind(1, (Dat$Gender == "Male")) %*% coef(Model)
> pred1 <- exp(x)/(1 + exp(x))
>
> # use the fitted line equation
> y <- coef(Model)[1L] + coef(Model)[2L] * (Dat$Gender == "Male")
> pred2 <- exp(y)/(1 + exp(y))
>
> head(predict(Model, type="response"))
> head(pred1) |> c()
> head(pred2)
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> www.avg.com


From @tyen @end|ng |rom ntu@edu@tw  Sun Jul 14 05:23:44 2024
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sun, 14 Jul 2024 11:23:44 +0800
Subject: [R] grep
In-Reply-To: <0504c3e0-e0b7-44a9-a165-75f1af2e1ebb@sapo.pt>
References: <658bc8e3-c654-4ed7-acf5-3d63eb34967d@ntu.edu.tw>
 <b0700c60-74ca-4b02-a813-68202010f634@statistik.tu-dortmund.de>
 <a9ad4017-ba88-4364-a4c2-0e68389b333b@ntu.edu.tw>
 <b96273a5-8499-4445-a12f-d9f90f92e0a2@sapo.pt>
 <47360462-553b-4223-99d7-2225ad03a6ed@ntu.edu.tw>
 <0504c3e0-e0b7-44a9-a165-75f1af2e1ebb@sapo.pt>
Message-ID: <e61fae42-57d6-44e1-9706-7ce389a92443@ntu.edu.tw>

Yes. Any of the following worked. The pipe greater than (|>) is neat! 
Thanks.

 > v<-goprobit.p$est
 > names(v) |> grep("somewhat|very", x = _)
 ?[1]? 6? 7? 8? 9 10 11 12 13 28 29 30 31 32 33 34 35 50 51 52 53 54 55 
56 57
 > v |> names() |> grep("somewhat|very", x = _)
 ?[1]? 6? 7? 8? 9 10 11 12 13 28 29 30 31 32 33 34 35 50 51 52 53 54 55 
56 57
 > which(grepl("very|somewhat",names(v)))
 ?[1]? 6? 7? 8? 9 10 11 12 13 28 29 30 31 32 33 34 35 50 51 52 53 54 55 
56 57
 > jj<-grep("very|somewhat",names(v)); jj
 ?[1]? 6? 7? 8? 9 10 11 12 13 28 29 30 31 32 33 34 35 50 51 52 53 54 55 
56 57
 >

On 7/13/2024 12:31 AM, Rui Barradas wrote:
> Hello,
>
> So any of
>
>
> names(goprobit.p$est) |> grep("somewhat|very", x = _)
> goprobit.p$est |> names() |> grep("somewhat|very", x = _)
>
>
> should work, right?
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 16:57 de 12/07/2024, Steven Yen escreveu:
>> Thanks. First and second of the following worked, but the third (with 
>> coef) did not. This may be because I programmed my own estimation 
>> program. In short,
>>
>> names(goprobit.p$est) was recognized, but
>> names(coef(goprobit)) was not
>>
>> ?> which(grepl("very|somewhat",names(goprobit.p$est)))
>> ??[1]? 6? 7? 8? 9 10 11 12 13 28 29 30 31 32 33 34 35 50 51 52 53 54 
>> 55 56 57
>> ?> jj<-grep("very|somewhat",names(goprobit.p$est)); length(jj)
>> [1] 24
>> ?> jj<-grep("very|somewhat",names(coef(goprobit))); length(jj)
>> Error: object 'goprobit' not found
>>
>> On 7/12/2024 11:23 PM, Rui Barradas wrote:
>>>
>>> Hello,l
>>>
>>> Though the question is already answered, here is another answer to 
>>> what is 'x'.
>>> The output in the OP is not a lm or glm output but if your 
>>> regression model was programmed according to recommended practices, 
>>> there must be a 'coefficients' member in the list or object it 
>>> returns and the following should work.
>>>
>>>
>>> # this is 'x', a named character vector
>>> coef(fit)
>>> #
>>> fit |> coef() |> names() |> grep("somewhat|very", x = _)
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> ?s 10:26 de 12/07/2024, Steven Yen escreveu:
>>>> Thanks. In this case below, what is "x"? I tried rownames(out) 
>>>> which did not work.
>>>>
>>>> Sorry. Does this sound like homework to you?
>>>>
>>>> On 7/12/2024 5:09 PM, Uwe Ligges wrote:
>>>>>
>>>>>
>>>>> On 12.07.2024 10:54, Steven Yen wrote:
>>>>>> Below is part a regression printout. How can I use "grep" to 
>>>>>> identify
>>>>>> rows headed by variables (first column) with a certain label. In 
>>>>>> this
>>>>>> case, I like to find variables containing "somewhath",
>>>>>> "veryh",?"somewhatm", "verym", "somewhatc", "veryc","somewhatl",
>>>>>> "veryl". The result should be an index 6:13 or 
>>>>>> 6,7,8,9,10,11,12,13. Note
>>>>>> that they all contain "somewhat" and "very". Thanks.
>>>>>
>>>>> Sounds like homework?
>>>>>
>>>>> which(grep("very|somewhat", x))
>>>>>
>>>>> Best,
>>>>> Uwe Ligges
>>>>>
>>>>>
>>>>>> est se t p g sig x.1.age 0.0341 0.0138 2.4766 0.0133 -3.8835e-04 **
>>>>>> x.1.sleep -0.1108 0.0059 -18.6277 0.0000 -4.4572e-04 *** x.1.primary
>>>>>> -0.0694 0.0289 -2.4002 0.0164 -9.9638e-06 ** x.1.middle -0.2909 
>>>>>> 0.0356
>>>>>> -8.1657 0.0000 -1.4913e-05 *** x.1.high -0.4267 0.0463 -9.2118 
>>>>>> 0.0000
>>>>>> -3.6246e-05 *** x.1.somewhath -0.6188 0.0256 -24.1971 0.0000 
>>>>>> -3.1337e-05
>>>>>> *** x.1.veryh -0.7580 0.0331 -22.8695 0.0000 -2.9558e-05 ***
>>>>>> x.1.somewhatm -0.3413 0.0426 -8.0112 0.0000 -1.8920e-05 *** 
>>>>>> x.1.verym
>>>>>> -0.3813 0.0446 -8.5413 0.0000 -4.4029e-05 *** x.1.somewhatc -0.3101
>>>>>> 0.0649 -4.7783 0.0000 -1.4353e-05 *** x.1.veryc -0.2977 0.0648 
>>>>>> -4.5910
>>>>>> 0.0000 -4.8986e-05 *** x.1.somewhatl -0.6310 0.0424 -14.8846 0.0000
>>>>>> -1.9543e-05 *** x.1.veryl -0.9132 0.0462 -19.7525 0.0000 
>>>>>> -4.4603e-05 ***
>>>>>> ...
>>>>>>
>>>>>> ????[[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide 
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>


From dynvec @end|ng |rom gm@||@com  Sun Jul 14 09:16:56 2024
From: dynvec @end|ng |rom gm@||@com (DynV Montrealer)
Date: Sun, 14 Jul 2024 03:16:56 -0400
Subject: [R] Reinterpret data without saving it to a file 1st? Check for
 integer stopping at 1st decimal?
Message-ID: <CAGYhDoOY1shokz7QZ+2bdrXiii+i23wpu+L-6o_msGLCSUYWDg@mail.gmail.com>

A small number of columns in the data I need to work with are strings, the
rest numbers.  I'm using read_excel() from the readxl package to get the
data ; right after it, the string columns are of type chr and the rest num.
I'm tasked with finding out which columns are integers. From an advice, I
tried saving the spreadsheet content into a CSV then loading that, which
works like a charm ; the chr columns are the same but now a large portion
of num is now instead int. Is there a way to skip writing and reading a CSV
and get the same transformation? Perhaps some way to break the spreadsheet
data (eg XLdata <- read_excel(...)), then put it back together without any
writing to a file (eg XLdataReformed <- reform(XLdata)) ?

In addition, from is.integer() documentation I ran

> is.wholenumber <- function(x, tol = .Machine$double.eps^0.5) abs(x - round
> (x)) < tol

and I'm now trying to have it stop at the 1st decimal content of a column.
Someone advised me to use break and I scripted

> is_integer = TRUE for (current_row in seq_along(data$column)) { if (!
> is.wholenumber(data$column[current_row])) { is_integer = FALSE break; } }

but I'm wondering if there's something better to check if a column is
entirely made of integers.

Thank you kindly for your help

	[[alternative HTML version deleted]]


From @d@m@c@h||||er @end|ng |rom gm@||@com  Sat Jul 13 17:04:17 2024
From: @d@m@c@h||||er @end|ng |rom gm@||@com (Adam Hillier)
Date: Sat, 13 Jul 2024 16:04:17 +0100
Subject: [R] =?utf-8?q?Problem_loading_BiodiversityR=2C__Error=3A_package?=
 =?utf-8?q?_=E2=80=98tcltk=E2=80=99_could_not_be_loaded?=
Message-ID: <111CF71B-8D94-4A97-89F4-D97F270FE014@gmail.com>

Hi,

I get the following error when trying to load the BiodiversityR package

> library(> library(BiodiversityR)
Loading required package: tcltk
tcltk DLL is linked to '/opt/X11/lib/libX11.6.dylib'
Error: package or namespace load failed for ?tcltk?:
 .onLoad failed in loadNamespace() for 'tcltk', details:
  call: fun(libname, pkgname)
  error: X11 library is missing: install XQuartz from www.xquartz.org
Error: package ?tcltk? could not be loaded


In my package library I can see ?tcltk2? but not ?tcltk?.

Have see a few others online facing the same issue.

Can you help ?

Thanks.

Adam

From |kry|ov @end|ng |rom d|@root@org  Sun Jul 14 12:16:00 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sun, 14 Jul 2024 13:16:00 +0300
Subject: [R] 
 =?utf-8?q?Problem_loading_BiodiversityR=2C__Error=3A_package?=
 =?utf-8?q?_=E2=80=98tcltk=E2=80=99_could_not_be_loaded?=
In-Reply-To: <111CF71B-8D94-4A97-89F4-D97F270FE014@gmail.com>
References: <111CF71B-8D94-4A97-89F4-D97F270FE014@gmail.com>
Message-ID: <20240714131600.59effff5@trisector>

? Sat, 13 Jul 2024 16:04:17 +0100
Adam Hillier <adam.c.hillier at gmail.com> ?????:

>   error: X11 library is missing: install XQuartz from www.xquartz.org

Does the problem go away if you install XQuartz from www.xquartz.org?

"R installation and administration" section 4 also documents the
requirement to have XQuartz installed in order to use the tcltk package
(which is part of R itself) and the x11() device:
https://cran.r-project.org/doc/manuals/R-admin.html#Installing-R-under-macOS

For macOS-specific problems, r-sig-mac at r-project.org may give you more
precise advice. If installing XQuartz doesn't help, make sure to
provide your sessionInfo() output.

-- 
Best regards,
Ivan


From |kry|ov @end|ng |rom d|@root@org  Sun Jul 14 13:08:11 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sun, 14 Jul 2024 14:08:11 +0300
Subject: [R] Reinterpret data without saving it to a file 1st? Check for
 integer stopping at 1st decimal?
In-Reply-To: <CAGYhDoOY1shokz7QZ+2bdrXiii+i23wpu+L-6o_msGLCSUYWDg@mail.gmail.com>
References: <CAGYhDoOY1shokz7QZ+2bdrXiii+i23wpu+L-6o_msGLCSUYWDg@mail.gmail.com>
Message-ID: <20240714140811.0d4403fa@trisector>

? Sun, 14 Jul 2024 03:16:56 -0400
DynV Montrealer <dynvec at gmail.com> ?????:

> Perhaps some way to break the spreadsheet data (eg XLdata <-
> read_excel(...)), then put it back together without any writing to a
> file (eg XLdataReformed <- reform(XLdata)) ?

read_excel() is documented to return objects of class tibble:
https://cran.r-project.org/package=tibble/vignettes/tibble.html

Long story short, tibbles are named lists of columns, so it should be
possible for you to access and replace the individual parts of them
using the standard list subset syntax XLdata[[columnname]].

Lists are described in R Intro chapter 6 and many other books on R:
https://cran.r-project.org/doc/manuals/R-intro.html#Lists-and-data-frames
http://web.archive.org/web/20230415001551if_/http://ashipunov.info/shipunov/school/biol_240/en/visual_statistics.pdf
(see section 3.8.2 on page 93 and following)

> In addition, from is.integer() documentation I ran
> 
> > is.wholenumber <- function(x, tol = .Machine$double.eps^0.5) abs(x
> > - round (x)) < tol  
> 
> and I'm now trying to have it stop at the 1st decimal content of a
> column.

If you'd like to write idiomatic R code, consider the fact that
is.wholenumber is vectorised:

is.wholenumber(c(1,2,3,pi))
# [1]  TRUE  TRUE  TRUE FALSE

Given a vector of numbers, it will return a vector of the same length
specifying whether each element can be considered a whole number.
Combine it with all() and you can test the whole column in two function
calls.

R also has a type.convert function that may be useful in this case:
https://search.r-project.org/R/refmans/utils/html/type.convert.html

-- 
Best regards,
Ivan


From dynvec @end|ng |rom gm@||@com  Mon Jul 15 07:36:59 2024
From: dynvec @end|ng |rom gm@||@com (DynV Montrealer)
Date: Mon, 15 Jul 2024 01:36:59 -0400
Subject: [R] Ps: Reinterpret data without saving it to a file 1st? Check for
 integer stopping at 1st decimal?
In-Reply-To: <CAGYhDoOY1shokz7QZ+2bdrXiii+i23wpu+L-6o_msGLCSUYWDg@mail.gmail.com>
References: <CAGYhDoOY1shokz7QZ+2bdrXiii+i23wpu+L-6o_msGLCSUYWDg@mail.gmail.com>
Message-ID: <CAGYhDoOwbBAtktR8mfQpnhwSLT8eQj4oSCO1BjH7H5U3b_eeBw@mail.gmail.com>

The answer:
https://statisticsglobe.com/change-classes-data-frame-columns-automatically-r

On Sun, Jul 14, 2024 at 3:16?AM DynV Montrealer <dynvec at gmail.com> wrote:

> A small number of columns in the data I need to work with are strings, the
> rest numbers.  I'm using read_excel() from the readxl package to get the
> data ; right after it, the string columns are of type chr and the rest num.
> I'm tasked with finding out which columns are integers. From an advice, I
> tried saving the spreadsheet content into a CSV then loading that, which
> works like a charm ; the chr columns are the same but now a large portion
> of num is now instead int. Is there a way to skip writing and reading a CSV
> and get the same transformation? Perhaps some way to break the spreadsheet
> data (eg XLdata <- read_excel(...)), then put it back together without any
> writing to a file (eg XLdataReformed <- reform(XLdata)) ?
>
> In addition, from is.integer() documentation I ran
>
> > is.wholenumber <- function(x, tol = .Machine$double.eps^0.5) abs(x -
> round
> > (x)) < tol
>
> and I'm now trying to have it stop at the 1st decimal content of a column.
> Someone advised me to use break and I scripted
>
> > is_integer = TRUE for (current_row in seq_along(data$column)) { if (!
> > is.wholenumber(data$column[current_row])) { is_integer = FALSE break; } }
>
> but I'm wondering if there's something better to check if a column is
> entirely made of integers.
>
> Thank you kindly for your help
>
>

	[[alternative HTML version deleted]]


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Mon Jul 15 07:56:17 2024
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Mon, 15 Jul 2024 07:56:17 +0200
Subject: [R] reticulate + virtual environments
Message-ID: <c2db6d75-e3e3-4abc-ada3-f351be530ecd@wiwi.hu-berlin.de>

Hi,

I am using reticulate and a virtual environment (not conda) to run 
Python scripts from RStudio. However, when I try to use my own 
(existing) virtual environment, reticulate does not use it. If I run my 
scripts, the installed modules (e.g., py_install("pandas", 
"mmstat4.hu.data")) are not found. I believe this happens because 
reticulate is using r-reticulate instead of mmstat4.hu.data. How can I 
force reticulate to use my virtual environment?

Thanks Sigbert

 > library("reticulate")

 > py_config()

python:         /home/sk/.virtualenvs/r-reticulate/bin/python

libpython: 
/usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so

pythonhome: 
/home/sk/.virtualenvs/r-reticulate:/home/sk/.virtualenvs/r-reticulate

version:        3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]

numpy: 
/home/sk/.virtualenvs/r-reticulate/lib/python3.10/site-packages/numpy

numpy_version:  2.0.0

 > use_virtualenv("mmstat4.hu.data", required = TRUE)

 > py_config()

python:         /home/sk/.virtualenvs/r-reticulate/bin/python

libpython: 
/usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so

pythonhome: 
/home/sk/.virtualenvs/r-reticulate:/home/sk/.virtualenvs/r-reticulate

version:        3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]

numpy: 
/home/sk/.virtualenvs/r-reticulate/lib/python3.10/site-packages/numpy

numpy_version:  2.0.0

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jul 15 16:41:32 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 15 Jul 2024 07:41:32 -0700
Subject: [R] reticulate + virtual environments
In-Reply-To: <c2db6d75-e3e3-4abc-ada3-f351be530ecd@wiwi.hu-berlin.de>
References: <c2db6d75-e3e3-4abc-ada3-f351be530ecd@wiwi.hu-berlin.de>
Message-ID: <CAGxFJbQAkzXvTebdwn_w0UFwjGEzmkLDo71U6KNUngdQgwbUJA@mail.gmail.com>

Have you tried https://rstudio.github.io/reticulate/  ?

Generally speaking, complex nonstandard package specific questions
such as yours rarely get a reply here -- there are 20,000+ packages
(and counting) after all! As reticulate was created by and integrated
with RStudio/Posit, I would think their site and help resources might
be a better venue. Of course, if you don't use RStudio, you may have
no joy there either.

Cheers,
Bert




On Sun, Jul 14, 2024 at 10:56?PM Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
>
> Hi,
>
> I am using reticulate and a virtual environment (not conda) to run
> Python scripts from RStudio. However, when I try to use my own
> (existing) virtual environment, reticulate does not use it. If I run my
> scripts, the installed modules (e.g., py_install("pandas",
> "mmstat4.hu.data")) are not found. I believe this happens because
> reticulate is using r-reticulate instead of mmstat4.hu.data. How can I
> force reticulate to use my virtual environment?
>
> Thanks Sigbert
>
>  > library("reticulate")
>
>  > py_config()
>
> python:         /home/sk/.virtualenvs/r-reticulate/bin/python
>
> libpython:
> /usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so
>
> pythonhome:
> /home/sk/.virtualenvs/r-reticulate:/home/sk/.virtualenvs/r-reticulate
>
> version:        3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]
>
> numpy:
> /home/sk/.virtualenvs/r-reticulate/lib/python3.10/site-packages/numpy
>
> numpy_version:  2.0.0
>
>  > use_virtualenv("mmstat4.hu.data", required = TRUE)
>
>  > py_config()
>
> python:         /home/sk/.virtualenvs/r-reticulate/bin/python
>
> libpython:
> /usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so
>
> pythonhome:
> /home/sk/.virtualenvs/r-reticulate:/home/sk/.virtualenvs/r-reticulate
>
> version:        3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]
>
> numpy:
> /home/sk/.virtualenvs/r-reticulate/lib/python3.10/site-packages/numpy
>
> numpy_version:  2.0.0
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Mon Jul 15 17:17:24 2024
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Mon, 15 Jul 2024 17:17:24 +0200
Subject: [R] reticulate + virtual environments
In-Reply-To: <CAGxFJbQAkzXvTebdwn_w0UFwjGEzmkLDo71U6KNUngdQgwbUJA@mail.gmail.com>
References: <c2db6d75-e3e3-4abc-ada3-f351be530ecd@wiwi.hu-berlin.de>
 <CAGxFJbQAkzXvTebdwn_w0UFwjGEzmkLDo71U6KNUngdQgwbUJA@mail.gmail.com>
Message-ID: <6ded88f4-80a5-4050-9723-17351f5a4cc2@wiwi.hu-berlin.de>

Hi,

thanks, I posted in the Posit community.

Sigbert

Am 15.07.24 um 16:41 schrieb Bert Gunter:
> Have you tried https://rstudio.github.io/reticulate/  ?
> 
> Generally speaking, complex nonstandard package specific questions
> such as yours rarely get a reply here -- there are 20,000+ packages
> (and counting) after all! As reticulate was created by and integrated
> with RStudio/Posit, I would think their site and help resources might
> be a better venue. Of course, if you don't use RStudio, you may have
> no joy there either.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> On Sun, Jul 14, 2024 at 10:56?PM Sigbert Klinke
> <sigbert at wiwi.hu-berlin.de> wrote:
>>
>> Hi,
>>
>> I am using reticulate and a virtual environment (not conda) to run
>> Python scripts from RStudio. However, when I try to use my own
>> (existing) virtual environment, reticulate does not use it. If I run my
>> scripts, the installed modules (e.g., py_install("pandas",
>> "mmstat4.hu.data")) are not found. I believe this happens because
>> reticulate is using r-reticulate instead of mmstat4.hu.data. How can I
>> force reticulate to use my virtual environment?
>>
>> Thanks Sigbert
>>
>>   > library("reticulate")
>>
>>   > py_config()
>>
>> python:         /home/sk/.virtualenvs/r-reticulate/bin/python
>>
>> libpython:
>> /usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so
>>
>> pythonhome:
>> /home/sk/.virtualenvs/r-reticulate:/home/sk/.virtualenvs/r-reticulate
>>
>> version:        3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]
>>
>> numpy:
>> /home/sk/.virtualenvs/r-reticulate/lib/python3.10/site-packages/numpy
>>
>> numpy_version:  2.0.0
>>
>>   > use_virtualenv("mmstat4.hu.data", required = TRUE)
>>
>>   > py_config()
>>
>> python:         /home/sk/.virtualenvs/r-reticulate/bin/python
>>
>> libpython:
>> /usr/lib/python3.10/config-3.10-x86_64-linux-gnu/libpython3.10.so
>>
>> pythonhome:
>> /home/sk/.virtualenvs/r-reticulate:/home/sk/.virtualenvs/r-reticulate
>>
>> version:        3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]
>>
>> numpy:
>> /home/sk/.virtualenvs/r-reticulate/lib/python3.10/site-packages/numpy
>>
>> numpy_version:  2.0.0
>>
>> --
>> https://hu.berlin/sk
>> https://hu.berlin/mmstat
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat


From |kry|ov @end|ng |rom d|@root@org  Mon Jul 15 17:26:56 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 15 Jul 2024 18:26:56 +0300
Subject: [R] reticulate + virtual environments
In-Reply-To: <c2db6d75-e3e3-4abc-ada3-f351be530ecd@wiwi.hu-berlin.de>
References: <c2db6d75-e3e3-4abc-ada3-f351be530ecd@wiwi.hu-berlin.de>
Message-ID: <20240715182656.5c669ef2@arachnoid>

? Mon, 15 Jul 2024 07:56:17 +0200
Sigbert Klinke <sigbert at wiwi.hu-berlin.de> ?????:

>  > py_config()  

>  > use_virtualenv("mmstat4.hu.data", required = TRUE)  

Does it help _not_ to call py_config() before use_virtualenv()?

help(py_config) says that it forces the initialization of Python. When
you later try to ask for a different virtual environment, no conflict
is detected because
normalizePath('/home/sk/.virtualenvs/r-reticulate/bin/python') is
identical to
normalizePath('/home/sk/.virtualenvs/mmstat4.hu.data/bin/python'): they
must be both symlinks to /usr/bin/python3, so reticulate is likely
thinking that it's the same Python. Thus Python is not initialised
again, but you also don't see an error.

-- 
Best regards,
Ivan


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Jul 16 11:22:46 2024
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 16 Jul 2024 11:22:46 +0200
Subject: [R] Automatic Knot selection in Piecewise linear splines
In-Reply-To: <CAFL9eukUVQzjkmY2fXiLH5LFbySusU6qZqrCd1dMxRHOFZBgFg@mail.gmail.com>
References: <CAFL9eukUVQzjkmY2fXiLH5LFbySusU6qZqrCd1dMxRHOFZBgFg@mail.gmail.com>
Message-ID: <26262.15334.396036.478147@stat.math.ethz.ch>

>>>>> Anupam Tyagi 
>>>>>     on Tue, 9 Jul 2024 16:16:43 +0530 writes:

    > How can I do automatic knot selection while fitting piecewise linear
    > splines to two variables x and y? Which package to use to do it simply? I
    > also want to visualize the splines (and the scatter plot) with a graph.

    > Anupam

NB: linear splines, i.e. piecewise linear continuous functions.
Given the knots, use  approx() or approxfun() however, the
automatic knots selection does not happen in the base R packages.

I'm sure there are several R packages doing this.
The best such package in my opinion is "earth" which does a
re-implementation (and extensive  *generalization*) of the
famous  MARS algorithm of Friedman.
==> https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines

Note that their strengths and power is that  they do their work
for multivariate x (MARS := Multivariate Adaptive Regression
Splines), but indeed do work for the simple 1D case.

In the following example, we always get 11 final knots,
but I'm sure one can tweak the many tuning paramters of earth()
to get more:

## Can we do  knot-selection  for simple (x,y) splines?  === Yes, via  earth() {using MARS}!

x <- (0:800)/8

f <- function(x) 7 * sin(pi/8*x) * abs((x-50)/20)^1.25 - (x-40)*(12-x)/64
curve(f(x), 0, 100, n = 1000, col=2, lwd=2)

set.seed(11)
y <- f(x) + 10*rnorm(x)

m.sspl <- smooth.spline(x,y) # base line "standard smoother"

require(earth)
fm1 <- earth(x, y) # default settings
summary(fm1, style = "pmax") #-- got  10 knots (x = 44 "used twice") below
## Call: earth(x=x, y=y)

## y =
##   175.9612
##   -   10.6744 * pmax(0,      x -  4.625)
##   +  9.928496 * pmax(0,      x - 10.875)
##   -  5.940857 * pmax(0,      x -  20.25)
##   +  3.438948 * pmax(0,      x - 27.125)
##   -  3.828159 * pmax(0,     44 -      x)
##   +  4.207046 * pmax(0,      x -     44)
##   +  2.573822 * pmax(0,      x -   76.5)
##   -  10.99073 * pmax(0,      x - 87.125)
##   +  10.97592 * pmax(0,      x - 90.875)
##   +  9.331949 * pmax(0,      x -     94)
##   -   8.48575 * pmax(0,      x -   96.5)

## Selected 12 of 12 terms, and 1 of 1 predictors
## Termination condition: Reached nk 21
## Importance: x
## Number of terms at each degree of interaction: 1 11 (additive model)
## GCV 108.6592    RSS 82109.44    GRSq 0.861423    RSq 0.86894


fm2 <- earth(x, y, fast.k = 0) # (more extensive forward pass)
summary(fm2)
all.equal(fm1, fm2)# they are identical (apart from 'call'):
fm3 <- earth(x, y, fast.k = 0, pmethod = "none", trace = 3) # extensive forward pass; *no* pruning
## still no change: fm3 "==" fm1
all.equal(predict(fm1, xx), predict(fm3, xx))

## BTW: The chosen knots and coefficients are
mat <- with(fm1, cbind(dirs, cuts=c(cuts), coef = c(coefficients)))

## Plots : fine grid for visualization: instead of   xx <- seq(x[1], x[length(x)], length.out = 1024)
rnx <- extendrange(x) ## to extrapolate a bit
xx <- do.call(seq.int, c(rnx, list(length.out = 1200)))

cbind(f = f(xx),
      sspl = predict(m.sspl, xx)$y,
      mars = predict(fm1, xx)) -> fits

plot(x,y, xlim=rnx, cex = 1/4, col = adjustcolor(1, 1/2))
cols <- c(adjustcolor(2, 1/3),
          adjustcolor(4, 2/3),
          adjustcolor("orange4", 2/3))
lwds <- c(3, 2, 2)
matlines(xx, fits, col = cols, lwd = lwds, lty=1)
legend("topleft", c("true f(x)", "smooth.spline()", "earth()"),
       col=cols, lwd=lwds, bty = "n")
title(paste("earth() linear spline vs. smooth.spline();  n =", length(x)))
mtext(substitute(f(x) == FDEF, list(FDEF = body(f))))


From @nupty@g| @end|ng |rom gm@||@com  Tue Jul 16 12:43:26 2024
From: @nupty@g| @end|ng |rom gm@||@com (Anupam Tyagi)
Date: Tue, 16 Jul 2024 16:13:26 +0530
Subject: [R] Automatic Knot selection in Piecewise linear splines
In-Reply-To: <26262.15334.396036.478147@stat.math.ethz.ch>
References: <CAFL9eukUVQzjkmY2fXiLH5LFbySusU6qZqrCd1dMxRHOFZBgFg@mail.gmail.com>
 <26262.15334.396036.478147@stat.math.ethz.ch>
Message-ID: <CAFL9eukrEguE_gz_Fa-9Ofvy8Uga2yxyAOLW44hhuPMeoe3_PA@mail.gmail.com>

Thanks, Martin. This is very helpful.



On Tue, 16 Jul 2024 at 14:52, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Anupam Tyagi
> >>>>>     on Tue, 9 Jul 2024 16:16:43 +0530 writes:
>
>     > How can I do automatic knot selection while fitting piecewise linear
>     > splines to two variables x and y? Which package to use to do it
> simply? I
>     > also want to visualize the splines (and the scatter plot) with a
> graph.
>
>     > Anupam
>
> NB: linear splines, i.e. piecewise linear continuous functions.
> Given the knots, use  approx() or approxfun() however, the
> automatic knots selection does not happen in the base R packages.
>
> I'm sure there are several R packages doing this.
> The best such package in my opinion is "earth" which does a
> re-implementation (and extensive  *generalization*) of the
> famous  MARS algorithm of Friedman.
> ==> https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines
>
> Note that their strengths and power is that  they do their work
> for multivariate x (MARS := Multivariate Adaptive Regression
> Splines), but indeed do work for the simple 1D case.
>
> In the following example, we always get 11 final knots,
> but I'm sure one can tweak the many tuning paramters of earth()
> to get more:
>
> ## Can we do  knot-selection  for simple (x,y) splines?  === Yes, via
> earth() {using MARS}!
>
> x <- (0:800)/8
>
> f <- function(x) 7 * sin(pi/8*x) * abs((x-50)/20)^1.25 - (x-40)*(12-x)/64
> curve(f(x), 0, 100, n = 1000, col=2, lwd=2)
>
> set.seed(11)
> y <- f(x) + 10*rnorm(x)
>
> m.sspl <- smooth.spline(x,y) # base line "standard smoother"
>
> require(earth)
> fm1 <- earth(x, y) # default settings
> summary(fm1, style = "pmax") #-- got  10 knots (x = 44 "used twice") below
> ## Call: earth(x=x, y=y)
>
> ## y =
> ##   175.9612
> ##   -   10.6744 * pmax(0,      x -  4.625)
> ##   +  9.928496 * pmax(0,      x - 10.875)
> ##   -  5.940857 * pmax(0,      x -  20.25)
> ##   +  3.438948 * pmax(0,      x - 27.125)
> ##   -  3.828159 * pmax(0,     44 -      x)
> ##   +  4.207046 * pmax(0,      x -     44)
> ##   +  2.573822 * pmax(0,      x -   76.5)
> ##   -  10.99073 * pmax(0,      x - 87.125)
> ##   +  10.97592 * pmax(0,      x - 90.875)
> ##   +  9.331949 * pmax(0,      x -     94)
> ##   -   8.48575 * pmax(0,      x -   96.5)
>
> ## Selected 12 of 12 terms, and 1 of 1 predictors
> ## Termination condition: Reached nk 21
> ## Importance: x
> ## Number of terms at each degree of interaction: 1 11 (additive model)
> ## GCV 108.6592    RSS 82109.44    GRSq 0.861423    RSq 0.86894
>
>
> fm2 <- earth(x, y, fast.k = 0) # (more extensive forward pass)
> summary(fm2)
> all.equal(fm1, fm2)# they are identical (apart from 'call'):
> fm3 <- earth(x, y, fast.k = 0, pmethod = "none", trace = 3) # extensive
> forward pass; *no* pruning
> ## still no change: fm3 "==" fm1
> all.equal(predict(fm1, xx), predict(fm3, xx))
>
> ## BTW: The chosen knots and coefficients are
> mat <- with(fm1, cbind(dirs, cuts=c(cuts), coef = c(coefficients)))
>
> ## Plots : fine grid for visualization: instead of   xx <- seq(x[1],
> x[length(x)], length.out = 1024)
> rnx <- extendrange(x) ## to extrapolate a bit
> xx <- do.call(seq.int, c(rnx, list(length.out = 1200)))
>
> cbind(f = f(xx),
>       sspl = predict(m.sspl, xx)$y,
>       mars = predict(fm1, xx)) -> fits
>
> plot(x,y, xlim=rnx, cex = 1/4, col = adjustcolor(1, 1/2))
> cols <- c(adjustcolor(2, 1/3),
>           adjustcolor(4, 2/3),
>           adjustcolor("orange4", 2/3))
> lwds <- c(3, 2, 2)
> matlines(xx, fits, col = cols, lwd = lwds, lty=1)
> legend("topleft", c("true f(x)", "smooth.spline()", "earth()"),
>        col=cols, lwd=lwds, bty = "n")
> title(paste("earth() linear spline vs. smooth.spline();  n =", length(x)))
> mtext(substitute(f(x) == FDEF, list(FDEF = body(f))))
>


-- 
Anupam.

	[[alternative HTML version deleted]]


From r@@ook|@@ @end|ng |rom gm@||@com  Tue Jul 16 18:07:31 2024
From: r@@ook|@@ @end|ng |rom gm@||@com (Roland Sookias)
Date: Tue, 16 Jul 2024 18:07:31 +0200
Subject: [R] Interpreting p values of gls in nlme
Message-ID: <CA+PBJbnBtDe0uLrgdbyrBQfWVaC-d0P8fCH=Xn9s_rQ_aRqupA@mail.gmail.com>

Dear all

I have undertaken some phylogenetic and non-phylogenetic regressions with
gls() in nlme with single preictor variables. A p value is associated with
the intercept (upper p value) and another with the predictor variable
(lower). Which p value is important? What does it mean if the intercept p
value is insignificant but the predictor is still significant?

Thanks a lot, and sorry for my ignorance,

Roland

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 17 00:41:28 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 16 Jul 2024 15:41:28 -0700
Subject: [R] Interpreting p values of gls in nlme
In-Reply-To: <CA+PBJbnBtDe0uLrgdbyrBQfWVaC-d0P8fCH=Xn9s_rQ_aRqupA@mail.gmail.com>
References: <CA+PBJbnBtDe0uLrgdbyrBQfWVaC-d0P8fCH=Xn9s_rQ_aRqupA@mail.gmail.com>
Message-ID: <CAGxFJbQO-=7=ZW3WHxrp8JaWaXSJycRJKo1sPuQL=BP-quCong@mail.gmail.com>

Yikes!

This list is for help on R *programming*, not statistics per se,
although these do sometimes intersect. However, your query strikes me
as a request for a kind of statistical tutorial, which is OT here.
Just so you are aware...

R has a special interest group (SIG) for phylgenetics at
https://stat.ethz.ch/mailman/listinfo/r-sig-phylo  . I think this
would be a better place for you to post, as relevant expertise should
be found there. However, I do not know how active that list is, so
maybe not. Good luck.

Cheers,
Bert

On Tue, Jul 16, 2024 at 3:10?PM Roland Sookias <r.sookias at gmail.com> wrote:
>
> Dear all
>
> I have undertaken some phylogenetic and non-phylogenetic regressions with
> gls() in nlme with single preictor variables. A p value is associated with
> the intercept (upper p value) and another with the predictor variable
> (lower). Which p value is important? What does it mean if the intercept p
> value is insignificant but the predictor is still significant?
>
> Thanks a lot, and sorry for my ignorance,
>
> Roland
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Wed Jul 17 04:11:57 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 17 Jul 2024 02:11:57 +0000
Subject: [R] Interpreting p values of gls in nlme
In-Reply-To: <CA+PBJbnBtDe0uLrgdbyrBQfWVaC-d0P8fCH=Xn9s_rQ_aRqupA@mail.gmail.com>
References: <CA+PBJbnBtDe0uLrgdbyrBQfWVaC-d0P8fCH=Xn9s_rQ_aRqupA@mail.gmail.com>
Message-ID: <CH3PR22MB451407B0EEAD578CE687200BCFA32@CH3PR22MB4514.namprd22.prod.outlook.com>

In a lm() model a significant intercept means that the line passes above or below the intercept (x=0, y=0). A significant predictor means that the slope is not zero. More  generally the significant predictor means that the predictor has some influence on the predicted. With nlme() the relationship may not be linear. Your result indicates that you cannot tell if the relationship passes through the origin or not, but the predictor has a significant influence on the predicted.

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Roland Sookias
Sent: Tuesday, July 16, 2024 12:08 PM
To: r-help at r-project.org
Subject: [R] Interpreting p values of gls in nlme

[External Email]

Dear all

I have undertaken some phylogenetic and non-phylogenetic regressions with
gls() in nlme with single preictor variables. A p value is associated with the intercept (upper p value) and another with the predictor variable (lower). Which p value is important? What does it mean if the intercept p value is insignificant but the predictor is still significant?

Thanks a lot, and sorry for my ignorance,

Roland

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From e@tev@@m @end|ng |rom weh|@edu@@u  Wed Jul 17 04:35:22 2024
From: e@tev@@m @end|ng |rom weh|@edu@@u (Miguel Esteva)
Date: Wed, 17 Jul 2024 02:35:22 +0000
Subject: [R] grDevices segfault when building R4.4.0 on RHEL 9.1.
In-Reply-To: <20240503144059.58281559@arachnoid>
References: <MEYP282MB23414408289F6E94466AFDCFDA1F2@MEYP282MB2341.AUSP282.PROD.OUTLOOK.COM>
 <20240503144059.58281559@arachnoid>
Message-ID: <MEYP282MB23413FE4C0C83F93D5471C28DAA32@MEYP282MB2341.AUSP282.PROD.OUTLOOK.COM>

Hi Ivan,

An apology, I was away for quite a bit.

To reproduce the setup:

I have been using the default GCC in RHEL 9.1.

gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/11/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-redhat-linux
Configured with: ../configure --enable-bootstrap --enable-host-pie --enable-host-bind-now --enable-languages=c,c++,fortran,lto --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-gcc-major-version-only --enable-plugin --enable-initfini-array --without-isl --enable-multilib --with-linker-hash-style=gnu --enable-offload-targets=nvptx-none --without-cuda-driver --enable-gnu-indirect-function --enable-cet --with-tune=generic --with-arch_64=x86-64-v2 --with-arch_32=x86-64 --build=x86_64-redhat-linux --with-build-config=bootstrap-lto --enable-link-serialization=1
Thread model: posix
Supported LTO compression algorithms: zlib zstd
gcc version 11.4.1 20230605 (Red Hat 11.4.1-2) (GCC)

I have been building R 4.4.0 and 4.4.1 with Flexiblas and with the built in R BLAS/LAPACK.

R BLAS:
./configure --prefix=/tools/R/$RVER  --enable-R-shlib --enable-memory-profiling  --with-pcre2=/tools/pcre2/10.42

Flexiblas:

PKG_CONFIG_PATH=/tools/flexiblas/3.4.2/lib64/pkgconfig ./configure --prefix=/tools/R/flexiblas/4.4.1  --enable-R-shlib --enable-memory-profiling --with-pcre2=/tools/pcre2/10.42 --with-blas="-lflexiblas -L/tools/flexiblas/3.4.2/lib64" --with-lapack

I realised the build fails when "--with-lapack" is left unspecified, even though the configure output shows this:

  Source directory:            .
  Installation directory:      /tools/R/flexiblas

  C compiler:                  gcc  -g -O2
  Fortran fixed-form compiler: gfortran  -g -O2

  Default C++ compiler:        g++ -std=gnu++17  -g -O2
  C++11 compiler:              g++ -std=gnu++11  -g -O2
  C++14 compiler:              g++ -std=gnu++14  -g -O2
  C++17 compiler:              g++ -std=gnu++17  -g -O2
  C++20 compiler:              g++ -std=gnu++20  -g -O2
  C++23 compiler:              g++ -std=gnu++23  -g -O2
  Fortran free-form compiler:  gfortran  -g -O2
  Obj-C compiler:

  Interfaces supported:        X11, tcltk
  External libraries:          pcre2, readline, BLAS(FlexiBlas), LAPACK(in blas), curl, libdeflate
  Additional capabilities:     PNG, JPEG, TIFF, NLS, cairo, ICU
  Options enabled:             shared R library, R profiling, memory profiling, libdeflate for lazyload

  Capabilities skipped:
  Options not enabled:         shared BLAS

  Recommended packages:        yes

I replaced the "--with-lapack" flag with "--with-lapack='-lflexiblas -L/tools/flexiblas/3.4.2/lib64'" and everything built ok.

>From a quick check in my emails, seems the RHEL9 system lapack packages are broken. Will test a bit more.

If you need a singularity container in the future, I can provide one with the R-dependencies installed. We setup dependencies similar to: https://github.com/rstudio/r-builds/blob/main/builder/Dockerfile.rhel-9

or

subscription-manager repos --enable codeready-builder-for-rhel-9-$(arch)-rpms
dnf install -y yum-utils
dnf install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm
yum-builddep -y R

Just bringing this to your attention as the issue is not with R by the looks, as I was unable to reproduce on Rocky Linux 9.1.

Kind regards and thanks!


Miguel Esteva
Senior ITS Research Systems Engineer


The Walter and Eliza Hall Institute of Medical Research
1G Royal Parade
Parkville VIC 3052
Australia

Phone (03) 9345 2909<callto:(03)%209345%202909>

Email esteva.m at wehi.edu.au

Web http://www.wehi.edu.au<http://www.wehi.edu.au/>

________________________________
From: Ivan Krylov <ikrylov at disroot.org>
Sent: Friday, 3 May 2024 9:40 PM
To: Miguel Esteva via R-help <r-help at r-project.org>
Cc: Miguel Esteva <esteva.m at wehi.edu.au>
Subject: Re: [R] grDevices segfault when building R4.4.0 on RHEL 9.1.

Dear Miguel Esteva,

I couldn't get a Red Hat "ubi9" container to install enough
dependencies to build R. Is there a way to reproduce your setup on a
virtual machine somewhere?

On Fri, 3 May 2024 00:42:43 +0000
Miguel Esteva via R-help <r-help at r-project.org> wrote:

>  *** caught segfault ***
>
> address 0x1801fa8f70, cause 'memory not mapped'
>
>
> Traceback:
>
>  1: solve.default(rgb)

This seems to crash inside the BLAS. Which BLAS are you using? Any
custom ./configure arguments? Which compilers are you running?

To find out more information about the crash, try to follow it with a
debugger. Change directory to src/library/grDevices and run:

_R_COMPILE_PKGS_=1 R_COMPILER_SUPPRESS_ALL=1 \
 R_DEFAULT_PACKAGES=NULL LC_ALL=C \
../../../bin/R -d gdb --vanilla --no-echo -e \
 'tools:::makeLazyLoading("grDevices")'

(This assumes building straight from the source directory. Adjust the
paths if you're using a separate build directory.)

Use the "run" command to start the process. One you see a crash, use
"backtrace" to see the state of the call stack at the place of the
crash, or "backtrace full" to include the contents of local variables.
The first few entries are probably the most important ones.

Not sure what to do with this information yet, but it might provide
more clues.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Wed Jul 17 16:11:56 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 17 Jul 2024 17:11:56 +0300
Subject: [R] grDevices segfault when building R4.4.0 on RHEL 9.1.
In-Reply-To: <MEYP282MB23413FE4C0C83F93D5471C28DAA32@MEYP282MB2341.AUSP282.PROD.OUTLOOK.COM>
References: <MEYP282MB23414408289F6E94466AFDCFDA1F2@MEYP282MB2341.AUSP282.PROD.OUTLOOK.COM>
 <20240503144059.58281559@arachnoid>
 <MEYP282MB23413FE4C0C83F93D5471C28DAA32@MEYP282MB2341.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <20240717171156.021d605d@arachnoid>

? Wed, 17 Jul 2024 02:35:22 +0000
Miguel Esteva <esteva.m at wehi.edu.au> ?????:

> I replaced the "--with-lapack" flag with "--with-lapack='-lflexiblas
> -L/tools/flexiblas/3.4.2/lib64'" and everything built ok.

Glad to see you managed to avoid the crash!

> From a quick check in my emails, seems the RHEL9 system lapack
> packages are broken. Will test a bit more.

Simon Andrews has also shown me how to reproduce the crash on
AlmaLinux: https://stat.ethz.ch/pipermail/r-help/2024-May/479321.html

Looks like an ABI incompatibility between gfortran-11 and blas-devel +
lapack-devel.

-- 
Best regards,
Ivan


From sibyiie@stoeckii m@iii@g oii gmx@ch  Thu Jul 18 17:27:05 2024
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Thu, 18 Jul 2024 17:27:05 +0200
Subject: [R] ggplot two-factor legend
Message-ID: <004001dad926$f2612b90$d72382b0$@gmx.ch>

Hi

I am using ggplot to visualise y for a two-factorial group (Bio: 0 and 1) x
= 6 years. I was able to adapt the colour of the lines (green and red) and
the linetype (solid and dashed).
Challenge: my code produces now two legends. One with the colors for the
group and one with the linetype for the group. Does somebody have a hint how
to adapt the code to produce one legend? Group 0 = red and dashed, Group 1 =
green and solid?


MS1<- MS %>% filter(QI_A!="NA") %>% droplevels()
dev.new(width=4, height=2.75)
par(mar = c(0,6,0,0))
p1<-ggplot(data = MS1, aes(x= Jahr, y= QI_A,group=Bio,color=Bio,
linetype=Bio)) + 
    	geom_smooth(aes(fill=Bio) , method = "lm" , formula = y ~ x +
I(x^2),linewidth=1) +
	theme(panel.background = element_blank())+
	theme(axis.line = element_line(colour = "black"))+
  theme(axis.text=element_text(size=18))+
  theme(axis.title=element_text(size=20))+
	ylab("Anteil BFF an LN [%]") +xlab("Jahr")+
	scale_color_manual(values=c("red","dark green"), labels=c("?LN",
"BIO"))+
	scale_fill_manual(values=c("red","dark green"), labels= c("?LN",
"BIO"))+
	theme(legend.title = element_blank())+
  theme(legend.text=element_text(size=20))+
  scale_linetype_manual(values=c("dashed", "solid"))
p1<-p1 + expand_limits(y=c(0, 30))

kind regards
Sibylle


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jul 18 18:12:54 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 18 Jul 2024 09:12:54 -0700
Subject: [R] ggplot two-factor legend
In-Reply-To: <004001dad926$f2612b90$d72382b0$@gmx.ch>
References: <004001dad926$f2612b90$d72382b0$@gmx.ch>
Message-ID: <A1B02F4E-97B3-417F-8439-07DF75D3A69B@dcn.davis.ca.us>

If I follow your question, you want redundant aesthetics. Ggplot normally notices correlated aesthetic mapping variables and merges the legends, so the most likely answer is that your data are not fully correlated in all rows. I have also seen this where data are drawn from different dataframes for different layers since it is hard to merge factors, but I don't see that here.

You are using the group parameter... try removing that? The group parameter overrides the automatic group determination. There might be a syntax for specifying correlated grouping, but I don't know it... I normally just verify that my data meets the requirements to be automatically identified as correlated if that is my goal, since that is a prerequisite anyway.

On July 18, 2024 8:27:05 AM PDT, "SIBYLLE ST?CKLI via R-help" <r-help at r-project.org> wrote:
>Hi
>
>I am using ggplot to visualise y for a two-factorial group (Bio: 0 and 1) x
>= 6 years. I was able to adapt the colour of the lines (green and red) and
>the linetype (solid and dashed).
>Challenge: my code produces now two legends. One with the colors for the
>group and one with the linetype for the group. Does somebody have a hint how
>to adapt the code to produce one legend? Group 0 = red and dashed, Group 1 =
>green and solid?
>
>
>MS1<- MS %>% filter(QI_A!="NA") %>% droplevels()
>dev.new(width=4, height=2.75)
>par(mar = c(0,6,0,0))
>p1<-ggplot(data = MS1, aes(x= Jahr, y= QI_A,group=Bio,color=Bio,
>linetype=Bio)) + 
>    	geom_smooth(aes(fill=Bio) , method = "lm" , formula = y ~ x +
>I(x^2),linewidth=1) +
>	theme(panel.background = element_blank())+
>	theme(axis.line = element_line(colour = "black"))+
>  theme(axis.text=element_text(size=18))+
>  theme(axis.title=element_text(size=20))+
>	ylab("Anteil BFF an LN [%]") +xlab("Jahr")+
>	scale_color_manual(values=c("red","dark green"), labels=c("?LN",
>"BIO"))+
>	scale_fill_manual(values=c("red","dark green"), labels= c("?LN",
>"BIO"))+
>	theme(legend.title = element_blank())+
>  theme(legend.text=element_text(size=20))+
>  scale_linetype_manual(values=c("dashed", "solid"))
>p1<-p1 + expand_limits(y=c(0, 30))
>
>kind regards
>Sibylle
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From sibyiie@stoeckii m@iii@g oii gmx@ch  Thu Jul 18 18:33:34 2024
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Thu, 18 Jul 2024 18:33:34 +0200
Subject: [R] ggplot two-factor legend
In-Reply-To: <A1B02F4E-97B3-417F-8439-07DF75D3A69B@dcn.davis.ca.us>
References: <004001dad926$f2612b90$d72382b0$@gmx.ch>
 <A1B02F4E-97B3-417F-8439-07DF75D3A69B@dcn.davis.ca.us>
Message-ID: <006d01dad930$3c1a5ff0$b44f1fd0$@gmx.ch>

Thanks Jeff

I removed the group parameter in the fp1<-ggplot () line. It doesn't change anything.
I suppose I got two legends as in the ggplot () line I have color=Bio & linetype=Bio. However, when removing linetype = Bio I just geht red and green. For black and white printing I would like the additionally differentiate the two lines (groups) in the linetype.

Sibylle

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Thursday, July 18, 2024 6:13 PM
To: sibylle.stoeckli at gmx.ch; SIBYLLE ST?CKLI via R-help <r-help at r-project.org>; r-help at r-project.org
Subject: Re: [R] ggplot two-factor legend

If I follow your question, you want redundant aesthetics. Ggplot normally notices correlated aesthetic mapping variables and merges the legends, so the most likely answer is that your data are not fully correlated in all rows. I have also seen this where data are drawn from different dataframes for different layers since it is hard to merge factors, but I don't see that here.

You are using the group parameter... try removing that? The group parameter overrides the automatic group determination. There might be a syntax for specifying correlated grouping, but I don't know it... I normally just verify that my data meets the requirements to be automatically identified as correlated if that is my goal, since that is a prerequisite anyway.

On July 18, 2024 8:27:05 AM PDT, "SIBYLLE ST?CKLI via R-help" <r-help at r-project.org> wrote:
>Hi
>
>I am using ggplot to visualise y for a two-factorial group (Bio: 0 and 
>1) x = 6 years. I was able to adapt the colour of the lines (green and 
>red) and the linetype (solid and dashed).
>Challenge: my code produces now two legends. One with the colors for 
>the group and one with the linetype for the group. Does somebody have a 
>hint how to adapt the code to produce one legend? Group 0 = red and 
>dashed, Group 1 = green and solid?
>
>
>MS1<- MS %>% filter(QI_A!="NA") %>% droplevels() dev.new(width=4, 
>height=2.75) par(mar = c(0,6,0,0)) p1<-ggplot(data = MS1, aes(x= Jahr, 
>y= QI_A,group=Bio,color=Bio,
>linetype=Bio)) + 
>    	geom_smooth(aes(fill=Bio) , method = "lm" , formula = y ~ x +
>I(x^2),linewidth=1) +
>	theme(panel.background = element_blank())+
>	theme(axis.line = element_line(colour = "black"))+
>  theme(axis.text=element_text(size=18))+
>  theme(axis.title=element_text(size=20))+
>	ylab("Anteil BFF an LN [%]") +xlab("Jahr")+
>	scale_color_manual(values=c("red","dark green"), labels=c("?LN", 
>"BIO"))+
>	scale_fill_manual(values=c("red","dark green"), labels= c("?LN", 
>"BIO"))+
>	theme(legend.title = element_blank())+
>  theme(legend.text=element_text(size=20))+
>  scale_linetype_manual(values=c("dashed", "solid"))
>p1<-p1 + expand_limits(y=c(0, 30))
>
>kind regards
>Sibylle
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jul 18 18:43:19 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 18 Jul 2024 17:43:19 +0100
Subject: [R] ggplot two-factor legend
In-Reply-To: <004001dad926$f2612b90$d72382b0$@gmx.ch>
References: <004001dad926$f2612b90$d72382b0$@gmx.ch>
Message-ID: <983e90aa-0975-41d0-9103-a48629c013ff@sapo.pt>

?s 16:27 de 18/07/2024, SIBYLLE ST?CKLI via R-help escreveu:
> Hi
> 
> I am using ggplot to visualise y for a two-factorial group (Bio: 0 and 1) x
> = 6 years. I was able to adapt the colour of the lines (green and red) and
> the linetype (solid and dashed).
> Challenge: my code produces now two legends. One with the colors for the
> group and one with the linetype for the group. Does somebody have a hint how
> to adapt the code to produce one legend? Group 0 = red and dashed, Group 1 =
> green and solid?
> 
> 
> MS1<- MS %>% filter(QI_A!="NA") %>% droplevels()
> dev.new(width=4, height=2.75)
> par(mar = c(0,6,0,0))
> p1<-ggplot(data = MS1, aes(x= Jahr, y= QI_A,group=Bio,color=Bio,
> linetype=Bio)) +
>      	geom_smooth(aes(fill=Bio) , method = "lm" , formula = y ~ x +
> I(x^2),linewidth=1) +
> 	theme(panel.background = element_blank())+
> 	theme(axis.line = element_line(colour = "black"))+
>    theme(axis.text=element_text(size=18))+
>    theme(axis.title=element_text(size=20))+
> 	ylab("Anteil BFF an LN [%]") +xlab("Jahr")+
> 	scale_color_manual(values=c("red","dark green"), labels=c("?LN",
> "BIO"))+
> 	scale_fill_manual(values=c("red","dark green"), labels= c("?LN",
> "BIO"))+
> 	theme(legend.title = element_blank())+
>    theme(legend.text=element_text(size=20))+
>    scale_linetype_manual(values=c("dashed", "solid"))
> p1<-p1 + expand_limits(y=c(0, 30))
> 
> kind regards
> Sibylle
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

To have one legend only, the labels must be the same. Try using

labels=c("?LN", "BIO")

in

scale_linetype_manual(values=c("dashed", "solid"), labels=c("?LN", "BIO"))


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jul 18 18:50:12 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 18 Jul 2024 17:50:12 +0100
Subject: [R] ggplot two-factor legend
In-Reply-To: <983e90aa-0975-41d0-9103-a48629c013ff@sapo.pt>
References: <004001dad926$f2612b90$d72382b0$@gmx.ch>
 <983e90aa-0975-41d0-9103-a48629c013ff@sapo.pt>
Message-ID: <60d41d14-7c38-4f03-8aac-2e343439779a@sapo.pt>

?s 17:43 de 18/07/2024, Rui Barradas escreveu:
> ?s 16:27 de 18/07/2024, SIBYLLE ST?CKLI via R-help escreveu:
>> Hi
>>
>> I am using ggplot to visualise y for a two-factorial group (Bio: 0 and 
>> 1) x
>> = 6 years. I was able to adapt the colour of the lines (green and red) 
>> and
>> the linetype (solid and dashed).
>> Challenge: my code produces now two legends. One with the colors for the
>> group and one with the linetype for the group. Does somebody have a 
>> hint how
>> to adapt the code to produce one legend? Group 0 = red and dashed, 
>> Group 1 =
>> green and solid?
>>
>>
>> MS1<- MS %>% filter(QI_A!="NA") %>% droplevels()
>> dev.new(width=4, height=2.75)
>> par(mar = c(0,6,0,0))
>> p1<-ggplot(data = MS1, aes(x= Jahr, y= QI_A,group=Bio,color=Bio,
>> linetype=Bio)) +
>> ???????? geom_smooth(aes(fill=Bio) , method = "lm" , formula = y ~ x +
>> I(x^2),linewidth=1) +
>> ????theme(panel.background = element_blank())+
>> ????theme(axis.line = element_line(colour = "black"))+
>> ?? theme(axis.text=element_text(size=18))+
>> ?? theme(axis.title=element_text(size=20))+
>> ????ylab("Anteil BFF an LN [%]") +xlab("Jahr")+
>> ????scale_color_manual(values=c("red","dark green"), labels=c("?LN",
>> "BIO"))+
>> ????scale_fill_manual(values=c("red","dark green"), labels= c("?LN",
>> "BIO"))+
>> ????theme(legend.title = element_blank())+
>> ?? theme(legend.text=element_text(size=20))+
>> ?? scale_linetype_manual(values=c("dashed", "solid"))
>> p1<-p1 + expand_limits(y=c(0, 30))
>>
>> kind regards
>> Sibylle
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
> 
> To have one legend only, the labels must be the same. Try using
> 
> labels=c("?LN", "BIO")
> 
> in
> 
> scale_linetype_manual(values=c("dashed", "solid"), labels=c("?LN", "BIO"))
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
Hello,

Here is a more complete an answer with the built-in data set mtcars.
Note that the group aesthetic is not used. This is because linetype is 
categorical (after mutate) and there's no need to group again by the 
same variable (am).

Remove labels from scale_linetype_manual and there are two legends but 
with the same labels the legends merge.


library(ggplot2)
library(dplyr)

mtcars %>%
   # linetype must be categorical
   mutate(am = factor(am)) %>%
   ggplot(aes(hp, disp, color = am, linetype = am)) +
   geom_line() +
   scale_color_manual(
     values = c("red","dark green"),
     labels = c("?LN", "BIO")
   ) +
   scale_linetype_manual(
     values = c("dashed", "solid"),
     labels = c("?LN", "BIO")
   ) +
   theme_bw()


Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From sibyiie@stoeckii m@iii@g oii gmx@ch  Thu Jul 18 20:47:39 2024
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Thu, 18 Jul 2024 20:47:39 +0200
Subject: [R] ggplot two-factor legend
In-Reply-To: <60d41d14-7c38-4f03-8aac-2e343439779a@sapo.pt>
References: <004001dad926$f2612b90$d72382b0$@gmx.ch>
 <983e90aa-0975-41d0-9103-a48629c013ff@sapo.pt>
 <60d41d14-7c38-4f03-8aac-2e343439779a@sapo.pt>
Message-ID: <008f01dad942$f70d16b0$e5274410$@gmx.ch>

Thanks a lot Rui and Jeff

Yes including labels=c() in  scale_linetype_manual() was the hint.

Sibylle

-----Original Message-----
From: Rui Barradas <ruipbarradas at sapo.pt> 
Sent: Thursday, July 18, 2024 6:50 PM
To: sibylle.stoeckli at gmx.ch; r-help at r-project.org
Subject: Re: [R] ggplot two-factor legend

?s 17:43 de 18/07/2024, Rui Barradas escreveu:
> ?s 16:27 de 18/07/2024, SIBYLLE ST?CKLI via R-help escreveu:
>> Hi
>>
>> I am using ggplot to visualise y for a two-factorial group (Bio: 0 
>> and
>> 1) x
>> = 6 years. I was able to adapt the colour of the lines (green and 
>> red) and the linetype (solid and dashed).
>> Challenge: my code produces now two legends. One with the colors for 
>> the group and one with the linetype for the group. Does somebody have 
>> a hint how to adapt the code to produce one legend? Group 0 = red and 
>> dashed, Group 1 = green and solid?
>>
>>
>> MS1<- MS %>% filter(QI_A!="NA") %>% droplevels() dev.new(width=4, 
>> height=2.75) par(mar = c(0,6,0,0)) p1<-ggplot(data = MS1, aes(x= 
>> Jahr, y= QI_A,group=Bio,color=Bio,
>> linetype=Bio)) +
>>          geom_smooth(aes(fill=Bio) , method = "lm" , formula = y ~ x 
>> +
>> I(x^2),linewidth=1) +
>>     theme(panel.background = element_blank())+
>>     theme(axis.line = element_line(colour = "black"))+
>>    theme(axis.text=element_text(size=18))+
>>    theme(axis.title=element_text(size=20))+
>>     ylab("Anteil BFF an LN [%]") +xlab("Jahr")+
>>     scale_color_manual(values=c("red","dark green"), labels=c("?LN", 
>> "BIO"))+
>>     scale_fill_manual(values=c("red","dark green"), labels= c("?LN", 
>> "BIO"))+
>>     theme(legend.title = element_blank())+
>>    theme(legend.text=element_text(size=20))+
>>    scale_linetype_manual(values=c("dashed", "solid"))
>> p1<-p1 + expand_limits(y=c(0, 30))
>>
>> kind regards
>> Sibylle
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
> 
> To have one legend only, the labels must be the same. Try using
> 
> labels=c("?LN", "BIO")
> 
> in
> 
> scale_linetype_manual(values=c("dashed", "solid"), labels=c("?LN", 
> "BIO"))
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
Hello,

Here is a more complete an answer with the built-in data set mtcars.
Note that the group aesthetic is not used. This is because linetype is categorical (after mutate) and there's no need to group again by the same variable (am).

Remove labels from scale_linetype_manual and there are two legends but with the same labels the legends merge.


library(ggplot2)
library(dplyr)

mtcars %>%
   # linetype must be categorical
   mutate(am = factor(am)) %>%
   ggplot(aes(hp, disp, color = am, linetype = am)) +
   geom_line() +
   scale_color_manual(
     values = c("red","dark green"),
     labels = c("?LN", "BIO")
   ) +
   scale_linetype_manual(
     values = c("dashed", "solid"),
     labels = c("?LN", "BIO")
   ) +
   theme_bw()


Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From v@|kremk @end|ng |rom gm@||@com  Fri Jul 19 18:52:18 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 19 Jul 2024 11:52:18 -0500
Subject: [R] Extract
Message-ID: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>

Hi All,

I want to extract new variables from a string and add it to the dataframe.
Sample data is csv file.

dat<-read.csv(text="Year, Sex,string
2002,F,15 xc Ab
2003,F,14
2004,M,18 xb 25 35 21
2005,M,13 25
2006,M,14 ac 256 AV 35
2007,F,11",header=TRUE)

The string column has  a maximum of five variables. Some rows have all
and others may not have all the five variables. If missing then  fill
it with NA,
Desired result is shown below,


Year,Sex,string, S1, S2, S3 S4,S5
2002,F,15 xc Ab, 15,xc,Ab, NA, NA
2003,F,14, 14,NA,NA,NA,NA
2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
2005,M,13 25,13, 25,NA,NA,NA
2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
2007,F,11, 11,NA,NA,NA,NA

Any help?
Thank you in advance.


From bobby@kn|ght @end|ng |rom gm@||@com  Fri Jul 19 19:01:11 2024
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Fri, 19 Jul 2024 13:01:11 -0400
Subject: [R] Extract
In-Reply-To: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
Message-ID: <CAKBFG3bfMMRCxkM6ozYQBF2WhT9WHM_C1aVLLNWPenkj5V1kaA@mail.gmail.com>

I would split dat$string into it's own vector, break it apart at the spaces
into an array, and then place dat$year and dat$sex in positions 1 and 2 of
that newly created array.





On Fri, Jul 19, 2024, 12:52?PM Val <valkremk at gmail.com> wrote:

> Hi All,
>
> I want to extract new variables from a string and add it to the dataframe.
> Sample data is csv file.
>
> dat<-read.csv(text="Year, Sex,string
> 2002,F,15 xc Ab
> 2003,F,14
> 2004,M,18 xb 25 35 21
> 2005,M,13 25
> 2006,M,14 ac 256 AV 35
> 2007,F,11",header=TRUE)
>
> The string column has  a maximum of five variables. Some rows have all
> and others may not have all the five variables. If missing then  fill
> it with NA,
> Desired result is shown below,
>
>
> Year,Sex,string, S1, S2, S3 S4,S5
> 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> 2003,F,14, 14,NA,NA,NA,NA
> 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> 2005,M,13 25,13, 25,NA,NA,NA
> 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> 2007,F,11, 11,NA,NA,NA,NA
>
> Any help?
> Thank you in advance.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Fri Jul 19 20:00:13 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Fri, 19 Jul 2024 18:00:13 +0000
Subject: [R] Extract
In-Reply-To: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
Message-ID: <CH3PR22MB45143FA0ACE5F86E979F6388CFAD2@CH3PR22MB4514.namprd22.prod.outlook.com>

The desired result is odd.
1) It looks like the string is duplicated in the desired result. The first line of data has "15, xc, Ab",  and the desired result has "15, xc, Ab, 15, xc, Ab"
2) The example has S1 through S5, but the desired result has data for eight variables in the first line (not five).
3) The desired result has a different number of variables for each line.
4) Are you assuming that all missing data is at the end of the string? If there are 5 variables (S1 .... S5), do you know that "15, xc, Ab" is S1 = 15, S2 = 'xc', and S3 = 'Ab' rather than S2=15, S4='xc' and S5='Ab' ?

This isn't exactly what you asked for, but maybe I was confused somewhere. This approach puts string data into variables in order. In this approach one mixes string and numeric data. The string is not duplicated.

library(tidyr)

dat <- read.csv(text="Year,Sex,string
2002,F,15 xc Ab
2003,F,14
2004,M,18 xb 25 35 21
2005,M,13 25
2006,M,14 ac 256 AV 35
2007,F,11", header=TRUE, stringsAsFactors=FALSE)

# split the 'string' column based on spaces
dat_separated <- dat |>
  separate(string, into = paste0("S", 1:5), sep = " ",
           fill = "right", extra = "merge")

Tim


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Val
Sent: Friday, July 19, 2024 12:52 PM
To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] Extract

[External Email]

Hi All,

I want to extract new variables from a string and add it to the dataframe.
Sample data is csv file.

dat<-read.csv(text="Year, Sex,string
2002,F,15 xc Ab
2003,F,14
2004,M,18 xb 25 35 21
2005,M,13 25
2006,M,14 ac 256 AV 35
2007,F,11",header=TRUE)

The string column has  a maximum of five variables. Some rows have all and others may not have all the five variables. If missing then  fill it with NA, Desired result is shown below,


Year,Sex,string, S1, S2, S3 S4,S5
2002,F,15 xc Ab, 15,xc,Ab, NA, NA
2003,F,14, 14,NA,NA,NA,NA
2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
2005,M,13 25,13, 25,NA,NA,NA
2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
2007,F,11, 11,NA,NA,NA,NA

Any help?
Thank you in advance.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From v@|kremk @end|ng |rom gm@||@com  Fri Jul 19 20:23:48 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 19 Jul 2024 13:23:48 -0500
Subject: [R] Extract
In-Reply-To: <CH3PR22MB45143FA0ACE5F86E979F6388CFAD2@CH3PR22MB4514.namprd22.prod.outlook.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CH3PR22MB45143FA0ACE5F86E979F6388CFAD2@CH3PR22MB4514.namprd22.prod.outlook.com>
Message-ID: <CAJOiR6ZrONC+Lm3a2NtjH0LwZ_apgS_rEawMEYcGuA9sj6Wmsg@mail.gmail.com>

Thank you and sorry for the confusion.
The desired result should have 8 variables as a comma separated in
each line.  The string variable  is  considered as one variable.
The output of your script is wfine for me.  Thank you!

On Fri, Jul 19, 2024 at 1:00?PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>
> The desired result is odd.
> 1) It looks like the string is duplicated in the desired result. The first line of data has "15, xc, Ab",  and the desired result has "15, xc, Ab, 15, xc, Ab"
> 2) The example has S1 through S5, but the desired result has data for eight variables in the first line (not five).
> 3) The desired result has a different number of variables for each line.
> 4) Are you assuming that all missing data is at the end of the string? If there are 5 variables (S1 .... S5), do you know that "15, xc, Ab" is S1 = 15, S2 = 'xc', and S3 = 'Ab' rather than S2=15, S4='xc' and S5='Ab' ?
>
> This isn't exactly what you asked for, but maybe I was confused somewhere. This approach puts string data into variables in order. In this approach one mixes string and numeric data. The string is not duplicated.
>
> library(tidyr)
>
> dat <- read.csv(text="Year,Sex,string
> 2002,F,15 xc Ab
> 2003,F,14
> 2004,M,18 xb 25 35 21
> 2005,M,13 25
> 2006,M,14 ac 256 AV 35
> 2007,F,11", header=TRUE, stringsAsFactors=FALSE)
>
> # split the 'string' column based on spaces
> dat_separated <- dat |>
>   separate(string, into = paste0("S", 1:5), sep = " ",
>            fill = "right", extra = "merge")
>
> Tim
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Val
> Sent: Friday, July 19, 2024 12:52 PM
> To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
> Subject: [R] Extract
>
> [External Email]
>
> Hi All,
>
> I want to extract new variables from a string and add it to the dataframe.
> Sample data is csv file.
>
> dat<-read.csv(text="Year, Sex,string
> 2002,F,15 xc Ab
> 2003,F,14
> 2004,M,18 xb 25 35 21
> 2005,M,13 25
> 2006,M,14 ac 256 AV 35
> 2007,F,11",header=TRUE)
>
> The string column has  a maximum of five variables. Some rows have all and others may not have all the five variables. If missing then  fill it with NA, Desired result is shown below,
>
>
> Year,Sex,string, S1, S2, S3 S4,S5
> 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> 2003,F,14, 14,NA,NA,NA,NA
> 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> 2005,M,13 25,13, 25,NA,NA,NA
> 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> 2007,F,11, 11,NA,NA,NA,NA
>
> Any help?
> Thank you in advance.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jul 19 20:40:48 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 19 Jul 2024 11:40:48 -0700
Subject: [R] Extract
In-Reply-To: <CAJOiR6ZrONC+Lm3a2NtjH0LwZ_apgS_rEawMEYcGuA9sj6Wmsg@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CH3PR22MB45143FA0ACE5F86E979F6388CFAD2@CH3PR22MB4514.namprd22.prod.outlook.com>
 <CAJOiR6ZrONC+Lm3a2NtjH0LwZ_apgS_rEawMEYcGuA9sj6Wmsg@mail.gmail.com>
Message-ID: <A11A334B-10F0-4179-82FF-A25F88789961@dcn.davis.ca.us>

Here is another way... for data analysis, the idiomatic result is usually more useful, though for presentation in a final result the wide result might be desired.

library(dplyr)
library(tidyr)

dat<-read.csv(text=
"Year, Sex,string
2002,F,15 xc Ab
2003,F,14
2004,M,18 xb 25 35 21
2005,M,13 25
2006,M,14 ac 256 AV 35
2007,F,11"
, header=TRUE )

idiomatic <- (
    dat
    %>% mutate( string = strsplit( string, " " ) )
    %>% unnest( cols = string )
    %>% group_by( Year, Sex )
    %>% mutate( s_name = paste0( "S", seq_along( string ) ) )
    %>% ungroup()
)
idiomatic # each row has unique Year, Sex, and s_name

wide <- (
    idiomatic
    %>% spread( s_name, string )
)
wide


On July 19, 2024 11:23:48 AM PDT, Val <valkremk at gmail.com> wrote:
>Thank you and sorry for the confusion.
>The desired result should have 8 variables as a comma separated in
>each line.  The string variable  is  considered as one variable.
>The output of your script is wfine for me.  Thank you!
>
>On Fri, Jul 19, 2024 at 1:00?PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:
>>
>> The desired result is odd.
>> 1) It looks like the string is duplicated in the desired result. The first line of data has "15, xc, Ab",  and the desired result has "15, xc, Ab, 15, xc, Ab"
>> 2) The example has S1 through S5, but the desired result has data for eight variables in the first line (not five).
>> 3) The desired result has a different number of variables for each line.
>> 4) Are you assuming that all missing data is at the end of the string? If there are 5 variables (S1 .... S5), do you know that "15, xc, Ab" is S1 = 15, S2 = 'xc', and S3 = 'Ab' rather than S2=15, S4='xc' and S5='Ab' ?
>>
>> This isn't exactly what you asked for, but maybe I was confused somewhere. This approach puts string data into variables in order. In this approach one mixes string and numeric data. The string is not duplicated.
>>
>> library(tidyr)
>>
>> dat <- read.csv(text="Year,Sex,string
>> 2002,F,15 xc Ab
>> 2003,F,14
>> 2004,M,18 xb 25 35 21
>> 2005,M,13 25
>> 2006,M,14 ac 256 AV 35
>> 2007,F,11", header=TRUE, stringsAsFactors=FALSE)
>>
>> # split the 'string' column based on spaces
>> dat_separated <- dat |>
>>   separate(string, into = paste0("S", 1:5), sep = " ",
>>            fill = "right", extra = "merge")
>>
>> Tim
>>
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Val
>> Sent: Friday, July 19, 2024 12:52 PM
>> To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
>> Subject: [R] Extract
>>
>> [External Email]
>>
>> Hi All,
>>
>> I want to extract new variables from a string and add it to the dataframe.
>> Sample data is csv file.
>>
>> dat<-read.csv(text="Year, Sex,string
>> 2002,F,15 xc Ab
>> 2003,F,14
>> 2004,M,18 xb 25 35 21
>> 2005,M,13 25
>> 2006,M,14 ac 256 AV 35
>> 2007,F,11",header=TRUE)
>>
>> The string column has  a maximum of five variables. Some rows have all and others may not have all the five variables. If missing then  fill it with NA, Desired result is shown below,
>>
>>
>> Year,Sex,string, S1, S2, S3 S4,S5
>> 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
>> 2003,F,14, 14,NA,NA,NA,NA
>> 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
>> 2005,M,13 25,13, 25,NA,NA,NA
>> 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
>> 2007,F,11, 11,NA,NA,NA,NA
>>
>> Any help?
>> Thank you in advance.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul 19 21:10:23 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 19 Jul 2024 12:10:23 -0700
Subject: [R] Extract
In-Reply-To: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
Message-ID: <CAGxFJbSSruMcDyQFwXE1qzyP+7_PpP+4j5cmpCJUHyacnCeHqQ@mail.gmail.com>

I did not look closely at the solutions that you were offered, but
note that you did not specify in your post whether the numbers in your
string were to be character or numeric variables after they are broken
out into their own columns. I believe that they are character in the
solutions, but you should check this. If you want them as numeric,
e.g., for further processing, you will need to convert them. Or
vice-versa.

Bert


On Fri, Jul 19, 2024 at 9:52?AM Val <valkremk at gmail.com> wrote:
>
> Hi All,
>
> I want to extract new variables from a string and add it to the dataframe.
> Sample data is csv file.
>
> dat<-read.csv(text="Year, Sex,string
> 2002,F,15 xc Ab
> 2003,F,14
> 2004,M,18 xb 25 35 21
> 2005,M,13 25
> 2006,M,14 ac 256 AV 35
> 2007,F,11",header=TRUE)
>
> The string column has  a maximum of five variables. Some rows have all
> and others may not have all the five variables. If missing then  fill
> it with NA,
> Desired result is shown below,
>
>
> Year,Sex,string, S1, S2, S3 S4,S5
> 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> 2003,F,14, 14,NA,NA,NA,NA
> 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> 2005,M,13 25,13, 25,NA,NA,NA
> 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> 2007,F,11, 11,NA,NA,NA,NA
>
> Any help?
> Thank you in advance.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@|kremk @end|ng |rom gm@||@com  Fri Jul 19 21:26:08 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 19 Jul 2024 14:26:08 -0500
Subject: [R] Extract
In-Reply-To: <CAGxFJbSSruMcDyQFwXE1qzyP+7_PpP+4j5cmpCJUHyacnCeHqQ@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAGxFJbSSruMcDyQFwXE1qzyP+7_PpP+4j5cmpCJUHyacnCeHqQ@mail.gmail.com>
Message-ID: <CAJOiR6Z=MC=14K-jCEx4W98btKPOnCmVH6CxWkVyO45=JKOrNw@mail.gmail.com>

Thank you Jeff and Bert for your help!
The components of the string  could be nixed (i.e,  numeric, character
or date). Once that is splitted it would be easy for me to format it
accordingly.

On Fri, Jul 19, 2024 at 2:10?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I did not look closely at the solutions that you were offered, but
> note that you did not specify in your post whether the numbers in your
> string were to be character or numeric variables after they are broken
> out into their own columns. I believe that they are character in the
> solutions, but you should check this. If you want them as numeric,
> e.g., for further processing, you will need to convert them. Or
> vice-versa.
>
> Bert
>
>
> On Fri, Jul 19, 2024 at 9:52?AM Val <valkremk at gmail.com> wrote:
> >
> > Hi All,
> >
> > I want to extract new variables from a string and add it to the dataframe.
> > Sample data is csv file.
> >
> > dat<-read.csv(text="Year, Sex,string
> > 2002,F,15 xc Ab
> > 2003,F,14
> > 2004,M,18 xb 25 35 21
> > 2005,M,13 25
> > 2006,M,14 ac 256 AV 35
> > 2007,F,11",header=TRUE)
> >
> > The string column has  a maximum of five variables. Some rows have all
> > and others may not have all the five variables. If missing then  fill
> > it with NA,
> > Desired result is shown below,
> >
> >
> > Year,Sex,string, S1, S2, S3 S4,S5
> > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > 2003,F,14, 14,NA,NA,NA,NA
> > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > 2005,M,13 25,13, 25,NA,NA,NA
> > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > 2007,F,11, 11,NA,NA,NA,NA
> >
> > Any help?
> > Thank you in advance.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jul 20 22:06:52 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jul 2024 13:06:52 -0700
Subject: [R] Using the pipe, |>, syntax with "names<-"
Message-ID: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>

This post is likely pretty useless;  it is motivated by a recent post
from "Val" that was elegantly answered using Tidyverse constructs, but
I wondered how to do it using base R only. Along the way, I ran into
the following question to which I think my answer (below) is pretty
awful. I would be interested in more elegant base R approaches. So...

z <- data.frame(a = 1:3, b = letters[1:3])
> z
  a h
1 1 a
2 2 b
3 3 c

Suppose I want to change the name of the second column of z from 'b'
to 'foo' . This is very easy using nested function syntax by:

names(z)[2] <- "foo"
> z
  a foo
1 1   a
2 2   b
3 3   c

Now suppose I wanted to do this using |> syntax, along the lines of:

z |> names()[2] <- "foo"  ## throws an error

Slightly fancier is:

z |> (\(x)names(x)[2] <- "b")()
## does nothing, but does not throw an error.

However, the following, which resulted from a more careful read of
?names works (after changing the name of the second column back to "b"
of course):

z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
>z
  a foo
1 1   a
2 2   b
3 3   c

This qualifies to me as "pretty awful." I'm sure there are better ways
to do this using pipe syntax, so I would appreciate any better
approaches.

Best,
Bert


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jul 20 22:14:58 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jul 2024 13:14:58 -0700
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
Message-ID: <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>

Nope, I still got it wrong: None of my approaches work.  :(

So my query remains: how to do it via piping with |> ?

Bert


On Sat, Jul 20, 2024 at 1:06?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> This post is likely pretty useless;  it is motivated by a recent post
> from "Val" that was elegantly answered using Tidyverse constructs, but
> I wondered how to do it using base R only. Along the way, I ran into
> the following question to which I think my answer (below) is pretty
> awful. I would be interested in more elegant base R approaches. So...
>
> z <- data.frame(a = 1:3, b = letters[1:3])
> > z
>   a h
> 1 1 a
> 2 2 b
> 3 3 c
>
> Suppose I want to change the name of the second column of z from 'b'
> to 'foo' . This is very easy using nested function syntax by:
>
> names(z)[2] <- "foo"
> > z
>   a foo
> 1 1   a
> 2 2   b
> 3 3   c
>
> Now suppose I wanted to do this using |> syntax, along the lines of:
>
> z |> names()[2] <- "foo"  ## throws an error
>
> Slightly fancier is:
>
> z |> (\(x)names(x)[2] <- "b")()
> ## does nothing, but does not throw an error.
>
> However, the following, which resulted from a more careful read of
> ?names works (after changing the name of the second column back to "b"
> of course):
>
> z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> >z
>   a foo
> 1 1   a
> 2 2   b
> 3 3   c
>
> This qualifies to me as "pretty awful." I'm sure there are better ways
> to do this using pipe syntax, so I would appreciate any better
> approaches.
>
> Best,
> Bert


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jul 20 22:46:42 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jul 2024 13:46:42 -0700
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
Message-ID: <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>

With further fooling around, I realized that explicitly assigning my
last "solution" 'works'; i.e.

names(z)[2] <- "foo"

can be piped as:

 z <- z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> z
  a foo
1 1   a
2 2   b
3 3   c

This is even awfuller than before. So my query still stands.

-- Bert

On Sat, Jul 20, 2024 at 1:14?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Nope, I still got it wrong: None of my approaches work.  :(
>
> So my query remains: how to do it via piping with |> ?
>
> Bert
>
>
> On Sat, Jul 20, 2024 at 1:06?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > This post is likely pretty useless;  it is motivated by a recent post
> > from "Val" that was elegantly answered using Tidyverse constructs, but
> > I wondered how to do it using base R only. Along the way, I ran into
> > the following question to which I think my answer (below) is pretty
> > awful. I would be interested in more elegant base R approaches. So...
> >
> > z <- data.frame(a = 1:3, b = letters[1:3])
> > > z
> >   a h
> > 1 1 a
> > 2 2 b
> > 3 3 c
> >
> > Suppose I want to change the name of the second column of z from 'b'
> > to 'foo' . This is very easy using nested function syntax by:
> >
> > names(z)[2] <- "foo"
> > > z
> >   a foo
> > 1 1   a
> > 2 2   b
> > 3 3   c
> >
> > Now suppose I wanted to do this using |> syntax, along the lines of:
> >
> > z |> names()[2] <- "foo"  ## throws an error
> >
> > Slightly fancier is:
> >
> > z |> (\(x)names(x)[2] <- "b")()
> > ## does nothing, but does not throw an error.
> >
> > However, the following, which resulted from a more careful read of
> > ?names works (after changing the name of the second column back to "b"
> > of course):
> >
> > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > >z
> >   a foo
> > 1 1   a
> > 2 2   b
> > 3 3   c
> >
> > This qualifies to me as "pretty awful." I'm sure there are better ways
> > to do this using pipe syntax, so I would appreciate any better
> > approaches.
> >
> > Best,
> > Bert


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jul 20 23:55:30 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 20 Jul 2024 22:55:30 +0100
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
Message-ID: <4945bfbf-c149-445b-9156-21f848854074@sapo.pt>

?s 21:46 de 20/07/2024, Bert Gunter escreveu:
> With further fooling around, I realized that explicitly assigning my
> last "solution" 'works'; i.e.
> 
> names(z)[2] <- "foo"
> 
> can be piped as:
> 
>   z <- z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
>> z
>    a foo
> 1 1   a
> 2 2   b
> 3 3   c
> 
> This is even awfuller than before. So my query still stands.
> 
> -- Bert
> 
> On Sat, Jul 20, 2024 at 1:14?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Nope, I still got it wrong: None of my approaches work.  :(
>>
>> So my query remains: how to do it via piping with |> ?
>>
>> Bert
>>
>>
>> On Sat, Jul 20, 2024 at 1:06?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> This post is likely pretty useless;  it is motivated by a recent post
>>> from "Val" that was elegantly answered using Tidyverse constructs, but
>>> I wondered how to do it using base R only. Along the way, I ran into
>>> the following question to which I think my answer (below) is pretty
>>> awful. I would be interested in more elegant base R approaches. So...
>>>
>>> z <- data.frame(a = 1:3, b = letters[1:3])
>>>> z
>>>    a h
>>> 1 1 a
>>> 2 2 b
>>> 3 3 c
>>>
>>> Suppose I want to change the name of the second column of z from 'b'
>>> to 'foo' . This is very easy using nested function syntax by:
>>>
>>> names(z)[2] <- "foo"
>>>> z
>>>    a foo
>>> 1 1   a
>>> 2 2   b
>>> 3 3   c
>>>
>>> Now suppose I wanted to do this using |> syntax, along the lines of:
>>>
>>> z |> names()[2] <- "foo"  ## throws an error
>>>
>>> Slightly fancier is:
>>>
>>> z |> (\(x)names(x)[2] <- "b")()
>>> ## does nothing, but does not throw an error.
>>>
>>> However, the following, which resulted from a more careful read of
>>> ?names works (after changing the name of the second column back to "b"
>>> of course):
>>>
>>> z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
>>>> z
>>>    a foo
>>> 1 1   a
>>> 2 2   b
>>> 3 3   c
>>>
>>> This qualifies to me as "pretty awful." I'm sure there are better ways
>>> to do this using pipe syntax, so I would appreciate any better
>>> approaches.
>>>
>>> Best,
>>> Bert
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

This is not exactly the same but in one of your attempts all you have to 
do is to return x.
The following works and does something.


z |> (\(x){names(x)[2] <- "foo";x})()
#   a foo
# 1 1   a
# 2 2   b
# 3 3   c


Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jul 20 23:59:43 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 20 Jul 2024 17:59:43 -0400
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
Message-ID: <2f3df8c7-d1a7-4004-a636-d862d80a93c6@gmail.com>

I suspect that you would want to define a function which was aware of 
the limitations of piping to handle this.  For example:

rename <- function(x, col, newname) {
   names(x)[col] <- newname
   x
}

Then

z |> rename(2, "foo")

would be fine.

Duncan Murdoch

On 2024-07-20 4:46 p.m., Bert Gunter wrote:
> With further fooling around, I realized that explicitly assigning my
> last "solution" 'works'; i.e.
> 
> names(z)[2] <- "foo"
> 
> can be piped as:
> 
>   z <- z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
>> z
>    a foo
> 1 1   a
> 2 2   b
> 3 3   c
> 
> This is even awfuller than before. So my query still stands.
> 
> -- Bert
> 
> On Sat, Jul 20, 2024 at 1:14?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Nope, I still got it wrong: None of my approaches work.  :(
>>
>> So my query remains: how to do it via piping with |> ?
>>
>> Bert
>>
>>
>> On Sat, Jul 20, 2024 at 1:06?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> This post is likely pretty useless;  it is motivated by a recent post
>>> from "Val" that was elegantly answered using Tidyverse constructs, but
>>> I wondered how to do it using base R only. Along the way, I ran into
>>> the following question to which I think my answer (below) is pretty
>>> awful. I would be interested in more elegant base R approaches. So...
>>>
>>> z <- data.frame(a = 1:3, b = letters[1:3])
>>>> z
>>>    a h
>>> 1 1 a
>>> 2 2 b
>>> 3 3 c
>>>
>>> Suppose I want to change the name of the second column of z from 'b'
>>> to 'foo' . This is very easy using nested function syntax by:
>>>
>>> names(z)[2] <- "foo"
>>>> z
>>>    a foo
>>> 1 1   a
>>> 2 2   b
>>> 3 3   c
>>>
>>> Now suppose I wanted to do this using |> syntax, along the lines of:
>>>
>>> z |> names()[2] <- "foo"  ## throws an error
>>>
>>> Slightly fancier is:
>>>
>>> z |> (\(x)names(x)[2] <- "b")()
>>> ## does nothing, but does not throw an error.
>>>
>>> However, the following, which resulted from a more careful read of
>>> ?names works (after changing the name of the second column back to "b"
>>> of course):
>>>
>>> z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
>>>> z
>>>    a foo
>>> 1 1   a
>>> 2 2   b
>>> 3 3   c
>>>
>>> This qualifies to me as "pretty awful." I'm sure there are better ways
>>> to do this using pipe syntax, so I would appreciate any better
>>> approaches.
>>>
>>> Best,
>>> Bert
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Jul 21 00:07:12 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 20 Jul 2024 18:07:12 -0400
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
Message-ID: <005301dadaf1$2c8777e0$859667a0$@gmail.com>

Bert,

You need to consider LHS vs RHS functionality.

Before I start, I would have done your example setup lie this:

trio <- 1:3
z <- data.frame(a = trio, b = letters[trio])

Just kidding!

Syntactic sugar means you are calling this function:

> `names<-`
function (x, value)  .Primitive("names<-")

Not particularly documented is a gimmick I just tried of supplying a second argument to the more routine function version:

> `names<-`(z, c("one","two"))
  one two
1   1   a
2   2   b
3   3   c

The above does not change z, but returns a new DF with new names.

In a pipeline, try this:

z <-
  z |>
  `names<-`( c("one","two"))

> z
  a b
1 1 a
2 2 b
3 3 c
> z <-
+   z |>
+   `names<-`( c("one","two"))
> z
  one two
1   1   a
2   2   b
3   3   c





-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Saturday, July 20, 2024 4:47 PM
To: R-help <R-help at r-project.org>
Subject: Re: [R] Using the pipe, |>, syntax with "names<-"

With further fooling around, I realized that explicitly assigning my
last "solution" 'works'; i.e.

names(z)[2] <- "foo"

can be piped as:

 z <- z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> z
  a foo
1 1   a
2 2   b
3 3   c

This is even awfuller than before. So my query still stands.

-- Bert

On Sat, Jul 20, 2024 at 1:14?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Nope, I still got it wrong: None of my approaches work.  :(
>
> So my query remains: how to do it via piping with |> ?
>
> Bert
>
>
> On Sat, Jul 20, 2024 at 1:06?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > This post is likely pretty useless;  it is motivated by a recent post
> > from "Val" that was elegantly answered using Tidyverse constructs, but
> > I wondered how to do it using base R only. Along the way, I ran into
> > the following question to which I think my answer (below) is pretty
> > awful. I would be interested in more elegant base R approaches. So...
> >
> > z <- data.frame(a = 1:3, b = letters[1:3])
> > > z
> >   a h
> > 1 1 a
> > 2 2 b
> > 3 3 c
> >
> > Suppose I want to change the name of the second column of z from 'b'
> > to 'foo' . This is very easy using nested function syntax by:
> >
> > names(z)[2] <- "foo"
> > > z
> >   a foo
> > 1 1   a
> > 2 2   b
> > 3 3   c
> >
> > Now suppose I wanted to do this using |> syntax, along the lines of:
> >
> > z |> names()[2] <- "foo"  ## throws an error
> >
> > Slightly fancier is:
> >
> > z |> (\(x)names(x)[2] <- "b")()
> > ## does nothing, but does not throw an error.
> >
> > However, the following, which resulted from a more careful read of
> > ?names works (after changing the name of the second column back to "b"
> > of course):
> >
> > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > >z
> >   a foo
> > 1 1   a
> > 2 2   b
> > 3 3   c
> >
> > This qualifies to me as "pretty awful." I'm sure there are better ways
> > to do this using pipe syntax, so I would appreciate any better
> > approaches.
> >
> > Best,
> > Bert

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From |kw@|mmo @end|ng |rom gm@||@com  Sun Jul 21 00:02:45 2024
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Sat, 20 Jul 2024 18:02:45 -0400
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
Message-ID: <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>

It should be written more like this:

```R
z <- data.frame(a = 1:3, b = letters[1:3])
z |> names() |> _[2] <- "foo"
z
```

Regards,
    Iris

On Sat, Jul 20, 2024 at 4:47?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> With further fooling around, I realized that explicitly assigning my
> last "solution" 'works'; i.e.
>
> names(z)[2] <- "foo"
>
> can be piped as:
>
>  z <- z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > z
>   a foo
> 1 1   a
> 2 2   b
> 3 3   c
>
> This is even awfuller than before. So my query still stands.
>
> -- Bert
>
> On Sat, Jul 20, 2024 at 1:14?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Nope, I still got it wrong: None of my approaches work.  :(
> >
> > So my query remains: how to do it via piping with |> ?
> >
> > Bert
> >
> >
> > On Sat, Jul 20, 2024 at 1:06?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > This post is likely pretty useless;  it is motivated by a recent post
> > > from "Val" that was elegantly answered using Tidyverse constructs, but
> > > I wondered how to do it using base R only. Along the way, I ran into
> > > the following question to which I think my answer (below) is pretty
> > > awful. I would be interested in more elegant base R approaches. So...
> > >
> > > z <- data.frame(a = 1:3, b = letters[1:3])
> > > > z
> > >   a h
> > > 1 1 a
> > > 2 2 b
> > > 3 3 c
> > >
> > > Suppose I want to change the name of the second column of z from 'b'
> > > to 'foo' . This is very easy using nested function syntax by:
> > >
> > > names(z)[2] <- "foo"
> > > > z
> > >   a foo
> > > 1 1   a
> > > 2 2   b
> > > 3 3   c
> > >
> > > Now suppose I wanted to do this using |> syntax, along the lines of:
> > >
> > > z |> names()[2] <- "foo"  ## throws an error
> > >
> > > Slightly fancier is:
> > >
> > > z |> (\(x)names(x)[2] <- "b")()
> > > ## does nothing, but does not throw an error.
> > >
> > > However, the following, which resulted from a more careful read of
> > > ?names works (after changing the name of the second column back to "b"
> > > of course):
> > >
> > > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > > >z
> > >   a foo
> > > 1 1   a
> > > 2 2   b
> > > 3 3   c
> > >
> > > This qualifies to me as "pretty awful." I'm sure there are better ways
> > > to do this using pipe syntax, so I would appreciate any better
> > > approaches.
> > >
> > > Best,
> > > Bert
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 00:14:34 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jul 2024 15:14:34 -0700
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
 <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
Message-ID: <CAGxFJbQW26-TnPHTyRPTJwCunZnpg-qfL8B+xFw8pCuF5dBPKw@mail.gmail.com>

Iris's reply is what I was looking for.  Many thanks -- I can now sleep tonight!

Both Rui's and Duncan's responses merely hid what I wanted to avoid. I
hope that I did not occupy much of your times on my useless question
and rather pathetic attempts at an answer.

Cheers,
Bert



On Sat, Jul 20, 2024 at 3:02?PM Iris Simmons <ikwsimmo at gmail.com> wrote:
>
> It should be written more like this:
>
> ```R
> z <- data.frame(a = 1:3, b = letters[1:3])
> z |> names() |> _[2] <- "foo"
> z
> ```
>
> Regards,
>     Iris
>
> On Sat, Jul 20, 2024 at 4:47?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > With further fooling around, I realized that explicitly assigning my
> > last "solution" 'works'; i.e.
> >
> > names(z)[2] <- "foo"
> >
> > can be piped as:
> >
> >  z <- z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > > z
> >   a foo
> > 1 1   a
> > 2 2   b
> > 3 3   c
> >
> > This is even awfuller than before. So my query still stands.
> >
> > -- Bert
> >
> > On Sat, Jul 20, 2024 at 1:14?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > Nope, I still got it wrong: None of my approaches work.  :(
> > >
> > > So my query remains: how to do it via piping with |> ?
> > >
> > > Bert
> > >
> > >
> > > On Sat, Jul 20, 2024 at 1:06?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > > >
> > > > This post is likely pretty useless;  it is motivated by a recent post
> > > > from "Val" that was elegantly answered using Tidyverse constructs, but
> > > > I wondered how to do it using base R only. Along the way, I ran into
> > > > the following question to which I think my answer (below) is pretty
> > > > awful. I would be interested in more elegant base R approaches. So...
> > > >
> > > > z <- data.frame(a = 1:3, b = letters[1:3])
> > > > > z
> > > >   a h
> > > > 1 1 a
> > > > 2 2 b
> > > > 3 3 c
> > > >
> > > > Suppose I want to change the name of the second column of z from 'b'
> > > > to 'foo' . This is very easy using nested function syntax by:
> > > >
> > > > names(z)[2] <- "foo"
> > > > > z
> > > >   a foo
> > > > 1 1   a
> > > > 2 2   b
> > > > 3 3   c
> > > >
> > > > Now suppose I wanted to do this using |> syntax, along the lines of:
> > > >
> > > > z |> names()[2] <- "foo"  ## throws an error
> > > >
> > > > Slightly fancier is:
> > > >
> > > > z |> (\(x)names(x)[2] <- "b")()
> > > > ## does nothing, but does not throw an error.
> > > >
> > > > However, the following, which resulted from a more careful read of
> > > > ?names works (after changing the name of the second column back to "b"
> > > > of course):
> > > >
> > > > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > > > >z
> > > >   a foo
> > > > 1 1   a
> > > > 2 2   b
> > > > 3 3   c
> > > >
> > > > This qualifies to me as "pretty awful." I'm sure there are better ways
> > > > to do this using pipe syntax, so I would appreciate any better
> > > > approaches.
> > > >
> > > > Best,
> > > > Bert
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jul 21 00:21:01 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 20 Jul 2024 18:21:01 -0400
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
 <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
Message-ID: <7be52826-1922-4e11-bcb5-57c9dc721ebd@gmail.com>

On 2024-07-20 6:02 p.m., Iris Simmons wrote:
> z <- data.frame(a = 1:3, b = letters[1:3])
> z |> names() |> _[2] <- "foo"
> z

That's a great suggestion!

Duncan Murdoch


From rmh @end|ng |rom temp|e@edu  Sun Jul 21 00:35:20 2024
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sat, 20 Jul 2024 22:35:20 +0000
Subject: [R] [External]  Using the pipe, |>, syntax with "names<-"
In-Reply-To: <7be52826-1922-4e11-bcb5-57c9dc721ebd@gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
 <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
 <7be52826-1922-4e11-bcb5-57c9dc721ebd@gmail.com>
Message-ID: <64B21EB8-28D4-43A3-96FA-497F8DBBEB76@temple.edu>

I think Iris's solution should be added to the help file: ?|>
there are no examples there now that show assignment or replacement using the "_"

> On Jul 20, 2024, at 18:21, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 2024-07-20 6:02 p.m., Iris Simmons wrote:
>> z <- data.frame(a = 1:3, b = letters[1:3])
>> z |> names() |> _[2] <- "foo"
>> z
>
> That's a great suggestion!
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 01:02:28 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jul 2024 16:02:28 -0700
Subject: [R] [External]  Using the pipe, |>, syntax with "names<-"
In-Reply-To: <64B21EB8-28D4-43A3-96FA-497F8DBBEB76@temple.edu>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
 <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
 <7be52826-1922-4e11-bcb5-57c9dc721ebd@gmail.com>
 <64B21EB8-28D4-43A3-96FA-497F8DBBEB76@temple.edu>
Message-ID: <CAGxFJbR9ZG3n_QL8S51phVD0wAbj4Cko0xc1c0S6EqUtiJ4-KA@mail.gmail.com>

I second Rich's excellent suggestion.

As with all elegant solutions, Iris's clicked on the wee light bulb in
my brain, and I realized that a slightly more verbose, but perhaps
more enlightening, alternative may be:

z |>  attr("names") |> _[2] <- "foo"

However, I would add this as an example *only with* Iris's solution.
Hers should be shown whether or not the above is.

Cheers,
Bert

On Sat, Jul 20, 2024 at 3:35?PM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> I think Iris's solution should be added to the help file: ?|>
> there are no examples there now that show assignment or replacement using the "_"
>
> > On Jul 20, 2024, at 18:21, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >
> > On 2024-07-20 6:02 p.m., Iris Simmons wrote:
> >> z <- data.frame(a = 1:3, b = letters[1:3])
> >> z |> names() |> _[2] <- "foo"
> >> z
> >
> > That's a great suggestion!
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 02:41:06 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jul 2024 17:41:06 -0700
Subject: [R] Extract
In-Reply-To: <CAJOiR6Z=MC=14K-jCEx4W98btKPOnCmVH6CxWkVyO45=JKOrNw@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAGxFJbSSruMcDyQFwXE1qzyP+7_PpP+4j5cmpCJUHyacnCeHqQ@mail.gmail.com>
 <CAJOiR6Z=MC=14K-jCEx4W98btKPOnCmVH6CxWkVyO45=JKOrNw@mail.gmail.com>
Message-ID: <CAGxFJbRfrB4FvAsbssmDWGkZR9duZtW1pmt_qPCUFzurg-yWJg@mail.gmail.com>

Val:
I wanted to add here a base R solution to your problem that I realize
you can happily ignore. However, in the course of puzzling over how to
do it using the R native pipe syntax ("|>") , I learned some new stuff
that I thought others might find useful, and it seemed sensible to
keep the code with this thread for comparison.

 I want to acknowledge that in the course of my labor, I posted a
query to R-Help to which Iris Simmons posted a very clever answer that
I would never have figured out myself and that is used below at the
end to change a subset of the names of the modified data frame via a
pipe.

Here's the whole solution starting from your (excellent!) example dat:

   dat <- dat$string |>
      strsplit(" ") |>
      sapply(FUN = \(x)c(x, rep(NA, 5 - length(x)))) |>
      t() |> cbind(dat, ..2 = _)

   ## And Iris's trick for changing a subset of attributes, i.e. the
"names", in a pipe
   dat |> names() |> _[4:8] <- paste0("s", 1:5)

## and here's the result:
> dat
  Year Sex          string s1   s2   s3   s4   s5
1 2002   F        15 xc Ab 15   xc   Ab <NA> <NA>
2 2003   F              14 14 <NA> <NA> <NA> <NA>
3 2004   M  18 xb 25 35 21 18   xb   25   35   21
4 2005   M           13 25 13   25 <NA> <NA> <NA>
5 2006   M 14 ac 256 AV 35 14   ac  256   AV   35
6 2007   F              11 11 <NA> <NA> <NA> <NA>

As I noted previously, all columns beyond Sex are character

Cheers,
Bert


On Fri, Jul 19, 2024 at 12:26?PM Val <valkremk at gmail.com> wrote:
>
> Thank you Jeff and Bert for your help!
> The components of the string  could be nixed (i.e,  numeric, character
> or date). Once that is splitted it would be easy for me to format it
> accordingly.
>
> On Fri, Jul 19, 2024 at 2:10?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > I did not look closely at the solutions that you were offered, but
> > note that you did not specify in your post whether the numbers in your
> > string were to be character or numeric variables after they are broken
> > out into their own columns. I believe that they are character in the
> > solutions, but you should check this. If you want them as numeric,
> > e.g., for further processing, you will need to convert them. Or
> > vice-versa.
> >
> > Bert
> >
> >
> > On Fri, Jul 19, 2024 at 9:52?AM Val <valkremk at gmail.com> wrote:
> > >
> > > Hi All,
> > >
> > > I want to extract new variables from a string and add it to the dataframe.
> > > Sample data is csv file.
> > >
> > > dat<-read.csv(text="Year, Sex,string
> > > 2002,F,15 xc Ab
> > > 2003,F,14
> > > 2004,M,18 xb 25 35 21
> > > 2005,M,13 25
> > > 2006,M,14 ac 256 AV 35
> > > 2007,F,11",header=TRUE)
> > >
> > > The string column has  a maximum of five variables. Some rows have all
> > > and others may not have all the five variables. If missing then  fill
> > > it with NA,
> > > Desired result is shown below,
> > >
> > >
> > > Year,Sex,string, S1, S2, S3 S4,S5
> > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > 2003,F,14, 14,NA,NA,NA,NA
> > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > 2005,M,13 25,13, 25,NA,NA,NA
> > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > 2007,F,11, 11,NA,NA,NA,NA
> > >
> > > Any help?
> > > Thank you in advance.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sun Jul 21 07:07:57 2024
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sun, 21 Jul 2024 10:37:57 +0530
Subject: [R] [External] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbR9ZG3n_QL8S51phVD0wAbj4Cko0xc1c0S6EqUtiJ4-KA@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
 <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
 <7be52826-1922-4e11-bcb5-57c9dc721ebd@gmail.com>
 <64B21EB8-28D4-43A3-96FA-497F8DBBEB76@temple.edu>
 <CAGxFJbR9ZG3n_QL8S51phVD0wAbj4Cko0xc1c0S6EqUtiJ4-KA@mail.gmail.com>
Message-ID: <CADfFDC7khmCsd=8AcpnKQ=JwwJfEnJxwHJ=F3QQ=CZ=ruJ0Cyw@mail.gmail.com>

The main challenge in Bert's original problem is that `[` and `[<-` cannot
be called in a pipeline. The obvious solution is to define named versions,
e.g.:

elt <- `[`
`elt<-` <- `[<-`

Then,

> z <- data.frame(a = 1:3, b = letters[1:3])
> z |> names() |> elt(2)
[1] "b"
> z |> names() |> elt(2) <- "foo"
> z
  a foo
1 1   a
2 2   b
3 3   c

You could actually also do (using a similar function already defined in
methods)

z |> names() |> el(2) <- "bar"

Iris's _ trick is of course a nice alternative; and this example in ?pipeOp
already covers it:

# using the placeholder as the head of an extraction chain:
mtcars |> subset(cyl == 4) |> lm(formula = mpg ~ disp) |> _$coef[[2]]

While the replacement question is a nice exercise, I am not sure about the
value of emphasizing that you can use pipes to do complex assignments.
Doesn't that defeat the whole purpose of piping? For one thing, it will
necessarily terminate the pipe. Also, it will not work if the starting
value is not a variable. E.g.,

> data.frame(a = 1:3, b = letters[1:3]) |> names() |> _[2] <- "bar"
Error in names(data.frame(a = 1:3, b = letters[1:3]))[2] <- "bar" :
  target of assignment expands to non-language object

Duncan's rename() approach, which will just change the column name and
return the modified object, seems more useful as part of a pipeline.

Best,
-Deepayan

On Sun, 21 Jul 2024 at 04:46, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I second Rich's excellent suggestion.
>
> As with all elegant solutions, Iris's clicked on the wee light bulb in
> my brain, and I realized that a slightly more verbose, but perhaps
> more enlightening, alternative may be:
>
> z |>  attr("names") |> _[2] <- "foo"
>
> However, I would add this as an example *only with* Iris's solution.
> Hers should be shown whether or not the above is.
>
> Cheers,
> Bert
>
> On Sat, Jul 20, 2024 at 3:35?PM Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >
> > I think Iris's solution should be added to the help file: ?|>
> > there are no examples there now that show assignment or replacement
> using the "_"
> >
> > > On Jul 20, 2024, at 18:21, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> > >
> > > On 2024-07-20 6:02 p.m., Iris Simmons wrote:
> > >> z <- data.frame(a = 1:3, b = letters[1:3])
> > >> z |> names() |> _[2] <- "foo"
> > >> z
> > >
> > > That's a great suggestion!
> > >
> > > Duncan Murdoch
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul 21 08:49:55 2024
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 20 Jul 2024 23:49:55 -0700
Subject: [R] [External] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CADfFDC7khmCsd=8AcpnKQ=JwwJfEnJxwHJ=F3QQ=CZ=ruJ0Cyw@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
 <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
 <7be52826-1922-4e11-bcb5-57c9dc721ebd@gmail.com>
 <64B21EB8-28D4-43A3-96FA-497F8DBBEB76@temple.edu>
 <CAGxFJbR9ZG3n_QL8S51phVD0wAbj4Cko0xc1c0S6EqUtiJ4-KA@mail.gmail.com>
 <CADfFDC7khmCsd=8AcpnKQ=JwwJfEnJxwHJ=F3QQ=CZ=ruJ0Cyw@mail.gmail.com>
Message-ID: <A7075229-A89F-40B4-99C2-C5F0CFD3BA8B@dcn.davis.ca.us>

I think that the simplicity of setNames is hard to beat:

z |> setNames( c( "a", "foo" ) )

and if you are determined not to load dplyr then

column_rename <- function( DF, map ) {
  on <- names( DF )
  on[ match( map, on ) ] <- names( map )
  names( DF ) <- on
  DF
}

is more robust to column reorganization than replace():

z |> column_rename( c( foo = "b" ) )


On July 20, 2024 10:07:57 PM PDT, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
>The main challenge in Bert's original problem is that `[` and `[<-` cannot
>be called in a pipeline. The obvious solution is to define named versions,
>e.g.:
>
>elt <- `[`
>`elt<-` <- `[<-`
>
>Then,
>
>> z <- data.frame(a = 1:3, b = letters[1:3])
>> z |> names() |> elt(2)
>[1] "b"
>> z |> names() |> elt(2) <- "foo"
>> z
>  a foo
>1 1   a
>2 2   b
>3 3   c
>
>You could actually also do (using a similar function already defined in
>methods)
>
>z |> names() |> el(2) <- "bar"
>
>Iris's _ trick is of course a nice alternative; and this example in ?pipeOp
>already covers it:
>
># using the placeholder as the head of an extraction chain:
>mtcars |> subset(cyl == 4) |> lm(formula = mpg ~ disp) |> _$coef[[2]]
>
>While the replacement question is a nice exercise, I am not sure about the
>value of emphasizing that you can use pipes to do complex assignments.
>Doesn't that defeat the whole purpose of piping? For one thing, it will
>necessarily terminate the pipe. Also, it will not work if the starting
>value is not a variable. E.g.,
>
>> data.frame(a = 1:3, b = letters[1:3]) |> names() |> _[2] <- "bar"
>Error in names(data.frame(a = 1:3, b = letters[1:3]))[2] <- "bar" :
>  target of assignment expands to non-language object
>
>Duncan's rename() approach, which will just change the column name and
>return the modified object, seems more useful as part of a pipeline.
>
>Best,
>-Deepayan
>
>On Sun, 21 Jul 2024 at 04:46, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> I second Rich's excellent suggestion.
>>
>> As with all elegant solutions, Iris's clicked on the wee light bulb in
>> my brain, and I realized that a slightly more verbose, but perhaps
>> more enlightening, alternative may be:
>>
>> z |>  attr("names") |> _[2] <- "foo"
>>
>> However, I would add this as an example *only with* Iris's solution.
>> Hers should be shown whether or not the above is.
>>
>> Cheers,
>> Bert
>>
>> On Sat, Jul 20, 2024 at 3:35?PM Richard M. Heiberger <rmh at temple.edu>
>> wrote:
>> >
>> > I think Iris's solution should be added to the help file: ?|>
>> > there are no examples there now that show assignment or replacement
>> using the "_"
>> >
>> > > On Jul 20, 2024, at 18:21, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>> > >
>> > > On 2024-07-20 6:02 p.m., Iris Simmons wrote:
>> > >> z <- data.frame(a = 1:3, b = letters[1:3])
>> > >> z |> names() |> _[2] <- "foo"
>> > >> z
>> > >
>> > > That's a great suggestion!
>> > >
>> > > Duncan Murdoch
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> http://www.r-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Jul 21 14:45:44 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 21 Jul 2024 08:45:44 -0400
Subject: [R] [External] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CADfFDC7khmCsd=8AcpnKQ=JwwJfEnJxwHJ=F3QQ=CZ=ruJ0Cyw@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAGxFJbRRZ1cbwWKX71qLSDXAWveOP5ywPtxEXH6CtZ26cYWpZA@mail.gmail.com>
 <CAGxFJbTQ+zzKB2iubbQmiC2yc4jLSodC4D_q1xWi1NeyQT_qaw@mail.gmail.com>
 <CADNULg_dz7c3DeyO036faxw+oypH_T=PTRWR4285gBRktkgW9g@mail.gmail.com>
 <7be52826-1922-4e11-bcb5-57c9dc721ebd@gmail.com>
 <64B21EB8-28D4-43A3-96FA-497F8DBBEB76@temple.edu>
 <CAGxFJbR9ZG3n_QL8S51phVD0wAbj4Cko0xc1c0S6EqUtiJ4-KA@mail.gmail.com>
 <CADfFDC7khmCsd=8AcpnKQ=JwwJfEnJxwHJ=F3QQ=CZ=ruJ0Cyw@mail.gmail.com>
Message-ID: <004501dadb6b$e7579030$b606b090$@gmail.com>

As an intellectual exercise it can be reasonable to discuss these ways to use a pipe even in places where it may not have been seen as something anyone would even try to use it.

In actual code, it is often better to not make overly cute constructions that others (or yourself a month later) will not understand.

Pipes were not part of R originally and the versions created over the years have included many kinds of functionality that is not in the new official pipe and that might allow functionality such as this. In some ways, the tidyverse evolved so that they did not require this game as their normal method of changing the names of columns works inline by using verbs such as rename(). Other things you can often do in-line is to reorder the columns or apply changes selectively to columns whose names or contents match your patterns. 

If you now wanted to use base R to make similar changes in a pipeline, the result may be that you end up reinventing extensions such as functions that do what you want in a pipeline, OR you realize that many things done in just base R should continue being done in more discrete lumps rather than one huge pipeline.

There may well already be one or more packages outside the tidyverse that provide such extensions but I am not so sure that using them will be as easy or convenient or readable until and unless they are as well-known. I note that even in the tidyverse, many things are often better done, especially while testing the code, without really long pipes so that it is easier to modify and rearrange things or see intermediate values. Similar arguments apply to something like using ggplot() with its own sort-of piping where it may make sense to use repeated invocations of "p <- p + function(args)" so each can clearly be documented with comments and sometimes steps can selectively be commented out or moved later in the "pipeline" if it seems the changes by one step are interfering with a later step by re-setting internal variables. Of course, if the code is completely done and not expected to change, you can always switch to piping if that is what you want.

Programming languages can have many purposes including things like efficiency or compact representations or making it harder to make mistakes but a major advantage of some is that the programs be READ easily without having to consult gurus or try to debug. Pipes can both be helpful in this regard or be absolutely mysterious. Using "_" in any way imaginable as a placeholder is convenient and allowing a default of it being a replacement for a first argument without specifying it is nice. But you can imagine an implementation where you constantly put in ".placeHolder." as clearer.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Deepayan Sarkar
Sent: Sunday, July 21, 2024 1:08 AM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: R-help <R-help at r-project.org>
Subject: Re: [R] [External] Using the pipe, |>, syntax with "names<-"

The main challenge in Bert's original problem is that `[` and `[<-` cannot
be called in a pipeline. The obvious solution is to define named versions,
e.g.:

elt <- `[`
`elt<-` <- `[<-`

Then,

> z <- data.frame(a = 1:3, b = letters[1:3])
> z |> names() |> elt(2)
[1] "b"
> z |> names() |> elt(2) <- "foo"
> z
  a foo
1 1   a
2 2   b
3 3   c

You could actually also do (using a similar function already defined in
methods)

z |> names() |> el(2) <- "bar"

Iris's _ trick is of course a nice alternative; and this example in ?pipeOp
already covers it:

# using the placeholder as the head of an extraction chain:
mtcars |> subset(cyl == 4) |> lm(formula = mpg ~ disp) |> _$coef[[2]]

While the replacement question is a nice exercise, I am not sure about the
value of emphasizing that you can use pipes to do complex assignments.
Doesn't that defeat the whole purpose of piping? For one thing, it will
necessarily terminate the pipe. Also, it will not work if the starting
value is not a variable. E.g.,

> data.frame(a = 1:3, b = letters[1:3]) |> names() |> _[2] <- "bar"
Error in names(data.frame(a = 1:3, b = letters[1:3]))[2] <- "bar" :
  target of assignment expands to non-language object

Duncan's rename() approach, which will just change the column name and
return the modified object, seems more useful as part of a pipeline.

Best,
-Deepayan

On Sun, 21 Jul 2024 at 04:46, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I second Rich's excellent suggestion.
>
> As with all elegant solutions, Iris's clicked on the wee light bulb in
> my brain, and I realized that a slightly more verbose, but perhaps
> more enlightening, alternative may be:
>
> z |>  attr("names") |> _[2] <- "foo"
>
> However, I would add this as an example *only with* Iris's solution.
> Hers should be shown whether or not the above is.
>
> Cheers,
> Bert
>
> On Sat, Jul 20, 2024 at 3:35?PM Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >
> > I think Iris's solution should be added to the help file: ?|>
> > there are no examples there now that show assignment or replacement
> using the "_"
> >
> > > On Jul 20, 2024, at 18:21, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> > >
> > > On 2024-07-20 6:02 p.m., Iris Simmons wrote:
> > >> z <- data.frame(a = 1:3, b = letters[1:3])
> > >> z |> names() |> _[2] <- "foo"
> > >> z
> > >
> > > That's a great suggestion!
> > >
> > > Duncan Murdoch
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ggrothend|eck @end|ng |rom gm@||@com  Sun Jul 21 16:47:28 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Sun, 21 Jul 2024 10:47:28 -0400
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
Message-ID: <CAP01uRkNn-VnYn1MSaGk7L3EQ4chx+DBa7=TANUnCvY+mYQcoQ@mail.gmail.com>

This
- is non-destructive (does not change z)
- passes the renamed z onto further pipe legs
- does not use \(x)...

It works by boxing z, operating on the boxed version and then unboxing it.

  z <- data.frame(a = 1:3, b = letters[1:3])
  z |> list(x = _) |> within(names(x)[2] <- "foo") |> _$x
  ##   a foo
  ## 1 1   a
  ## 2 2   b
  ## 3 3   c

On Sat, Jul 20, 2024 at 4:07?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> This post is likely pretty useless;  it is motivated by a recent post
> from "Val" that was elegantly answered using Tidyverse constructs, but
> I wondered how to do it using base R only. Along the way, I ran into
> the following question to which I think my answer (below) is pretty
> awful. I would be interested in more elegant base R approaches. So...
>
> z <- data.frame(a = 1:3, b = letters[1:3])
> > z
>   a h
> 1 1 a
> 2 2 b
> 3 3 c
>
> Suppose I want to change the name of the second column of z from 'b'
> to 'foo' . This is very easy using nested function syntax by:
>
> names(z)[2] <- "foo"
> > z
>   a foo
> 1 1   a
> 2 2   b
> 3 3   c
>
> Now suppose I wanted to do this using |> syntax, along the lines of:
>
> z |> names()[2] <- "foo"  ## throws an error
>
> Slightly fancier is:
>
> z |> (\(x)names(x)[2] <- "b")()
> ## does nothing, but does not throw an error.
>
> However, the following, which resulted from a more careful read of
> ?names works (after changing the name of the second column back to "b"
> of course):
>
> z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> >z
>   a foo
> 1 1   a
> 2 2   b
> 3 3   c
>
> This qualifies to me as "pretty awful." I'm sure there are better ways
> to do this using pipe syntax, so I would appreciate any better
> approaches.
>
> Best,
> Bert
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 17:01:23 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 21 Jul 2024 08:01:23 -0700
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAP01uRkNn-VnYn1MSaGk7L3EQ4chx+DBa7=TANUnCvY+mYQcoQ@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAP01uRkNn-VnYn1MSaGk7L3EQ4chx+DBa7=TANUnCvY+mYQcoQ@mail.gmail.com>
Message-ID: <CAGxFJbQSQh=zECXJkLJaQy7Abxpzmb8x2ARrRgfCwpBTFYf-0A@mail.gmail.com>

Wow!
Yes, this is very clever -- way too clever for me -- and meets my
criteria for a solution.

I think it's also another piece of evidence of why piping in base R is
not suited for complex/nested assignments, as discussed in Deepayan's
response.

Maybe someone could offer a better Tidydata piping solution just for
completeness?

Best,
Bert

On Sun, Jul 21, 2024 at 7:48?AM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> This
> - is non-destructive (does not change z)
> - passes the renamed z onto further pipe legs
> - does not use \(x)...
>
> It works by boxing z, operating on the boxed version and then unboxing it.
>
>   z <- data.frame(a = 1:3, b = letters[1:3])
>   z |> list(x = _) |> within(names(x)[2] <- "foo") |> _$x
>   ##   a foo
>   ## 1 1   a
>   ## 2 2   b
>   ## 3 3   c
>
> On Sat, Jul 20, 2024 at 4:07?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > This post is likely pretty useless;  it is motivated by a recent post
> > from "Val" that was elegantly answered using Tidyverse constructs, but
> > I wondered how to do it using base R only. Along the way, I ran into
> > the following question to which I think my answer (below) is pretty
> > awful. I would be interested in more elegant base R approaches. So...
> >
> > z <- data.frame(a = 1:3, b = letters[1:3])
> > > z
> >   a h
> > 1 1 a
> > 2 2 b
> > 3 3 c
> >
> > Suppose I want to change the name of the second column of z from 'b'
> > to 'foo' . This is very easy using nested function syntax by:
> >
> > names(z)[2] <- "foo"
> > > z
> >   a foo
> > 1 1   a
> > 2 2   b
> > 3 3   c
> >
> > Now suppose I wanted to do this using |> syntax, along the lines of:
> >
> > z |> names()[2] <- "foo"  ## throws an error
> >
> > Slightly fancier is:
> >
> > z |> (\(x)names(x)[2] <- "b")()
> > ## does nothing, but does not throw an error.
> >
> > However, the following, which resulted from a more careful read of
> > ?names works (after changing the name of the second column back to "b"
> > of course):
> >
> > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > >z
> >   a foo
> > 1 1   a
> > 2 2   b
> > 3 3   c
> >
> > This qualifies to me as "pretty awful." I'm sure there are better ways
> > to do this using pipe syntax, so I would appreciate any better
> > approaches.
> >
> > Best,
> > Bert
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 17:10:45 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 21 Jul 2024 08:10:45 -0700
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbQSQh=zECXJkLJaQy7Abxpzmb8x2ARrRgfCwpBTFYf-0A@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAP01uRkNn-VnYn1MSaGk7L3EQ4chx+DBa7=TANUnCvY+mYQcoQ@mail.gmail.com>
 <CAGxFJbQSQh=zECXJkLJaQy7Abxpzmb8x2ARrRgfCwpBTFYf-0A@mail.gmail.com>
Message-ID: <CAGxFJbR7fyaGPCR7YfyK7GZXEuiwkMGf5bB6FmLnyC2_WQWLDg@mail.gmail.com>

hmmm...
But note that you still used the nested assignment, names()[2] <-
"foo", to circumvent R's pipe limitations, which is exactly what
Iris's solution avoids. So I think I was overawed by your cleverness
;-)

Best,
Bert


On Sun, Jul 21, 2024 at 8:01?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Wow!
> Yes, this is very clever -- way too clever for me -- and meets my
> criteria for a solution.
>
> I think it's also another piece of evidence of why piping in base R is
> not suited for complex/nested assignments, as discussed in Deepayan's
> response.
>
> Maybe someone could offer a better Tidydata piping solution just for
> completeness?
>
> Best,
> Bert
>
> On Sun, Jul 21, 2024 at 7:48?AM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > This
> > - is non-destructive (does not change z)
> > - passes the renamed z onto further pipe legs
> > - does not use \(x)...
> >
> > It works by boxing z, operating on the boxed version and then unboxing it.
> >
> >   z <- data.frame(a = 1:3, b = letters[1:3])
> >   z |> list(x = _) |> within(names(x)[2] <- "foo") |> _$x
> >   ##   a foo
> >   ## 1 1   a
> >   ## 2 2   b
> >   ## 3 3   c
> >
> > On Sat, Jul 20, 2024 at 4:07?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > This post is likely pretty useless;  it is motivated by a recent post
> > > from "Val" that was elegantly answered using Tidyverse constructs, but
> > > I wondered how to do it using base R only. Along the way, I ran into
> > > the following question to which I think my answer (below) is pretty
> > > awful. I would be interested in more elegant base R approaches. So...
> > >
> > > z <- data.frame(a = 1:3, b = letters[1:3])
> > > > z
> > >   a h
> > > 1 1 a
> > > 2 2 b
> > > 3 3 c
> > >
> > > Suppose I want to change the name of the second column of z from 'b'
> > > to 'foo' . This is very easy using nested function syntax by:
> > >
> > > names(z)[2] <- "foo"
> > > > z
> > >   a foo
> > > 1 1   a
> > > 2 2   b
> > > 3 3   c
> > >
> > > Now suppose I wanted to do this using |> syntax, along the lines of:
> > >
> > > z |> names()[2] <- "foo"  ## throws an error
> > >
> > > Slightly fancier is:
> > >
> > > z |> (\(x)names(x)[2] <- "b")()
> > > ## does nothing, but does not throw an error.
> > >
> > > However, the following, which resulted from a more careful read of
> > > ?names works (after changing the name of the second column back to "b"
> > > of course):
> > >
> > > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > > >z
> > >   a foo
> > > 1 1   a
> > > 2 2   b
> > > 3 3   c
> > >
> > > This qualifies to me as "pretty awful." I'm sure there are better ways
> > > to do this using pipe syntax, so I would appreciate any better
> > > approaches.
> > >
> > > Best,
> > > Bert
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com


From ggrothend|eck @end|ng |rom gm@||@com  Sun Jul 21 17:17:47 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Sun, 21 Jul 2024 11:17:47 -0400
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbR7fyaGPCR7YfyK7GZXEuiwkMGf5bB6FmLnyC2_WQWLDg@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAP01uRkNn-VnYn1MSaGk7L3EQ4chx+DBa7=TANUnCvY+mYQcoQ@mail.gmail.com>
 <CAGxFJbQSQh=zECXJkLJaQy7Abxpzmb8x2ARrRgfCwpBTFYf-0A@mail.gmail.com>
 <CAGxFJbR7fyaGPCR7YfyK7GZXEuiwkMGf5bB6FmLnyC2_WQWLDg@mail.gmail.com>
Message-ID: <CAP01uRn9_eRhDCOPGBKJA+wqPEuR92GJuU-HkqEXQXvyrOersA@mail.gmail.com>

If you object to names(x)[2]<- ... then use replace:

  z |> list(x = _) |> within(replace(names(x), 2, "foo")) |> _$x

On Sun, Jul 21, 2024 at 11:10?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> hmmm...
> But note that you still used the nested assignment, names()[2] <-
> "foo", to circumvent R's pipe limitations, which is exactly what
> Iris's solution avoids. So I think I was overawed by your cleverness
> ;-)
>
> Best,
> Bert
>
>
> On Sun, Jul 21, 2024 at 8:01?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Wow!
> > Yes, this is very clever -- way too clever for me -- and meets my
> > criteria for a solution.
> >
> > I think it's also another piece of evidence of why piping in base R is
> > not suited for complex/nested assignments, as discussed in Deepayan's
> > response.
> >
> > Maybe someone could offer a better Tidydata piping solution just for
> > completeness?
> >
> > Best,
> > Bert
> >
> > On Sun, Jul 21, 2024 at 7:48?AM Gabor Grothendieck
> > <ggrothendieck at gmail.com> wrote:
> > >
> > > This
> > > - is non-destructive (does not change z)
> > > - passes the renamed z onto further pipe legs
> > > - does not use \(x)...
> > >
> > > It works by boxing z, operating on the boxed version and then unboxing it.
> > >
> > >   z <- data.frame(a = 1:3, b = letters[1:3])
> > >   z |> list(x = _) |> within(names(x)[2] <- "foo") |> _$x
> > >   ##   a foo
> > >   ## 1 1   a
> > >   ## 2 2   b
> > >   ## 3 3   c
> > >
> > > On Sat, Jul 20, 2024 at 4:07?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > > >
> > > > This post is likely pretty useless;  it is motivated by a recent post
> > > > from "Val" that was elegantly answered using Tidyverse constructs, but
> > > > I wondered how to do it using base R only. Along the way, I ran into
> > > > the following question to which I think my answer (below) is pretty
> > > > awful. I would be interested in more elegant base R approaches. So...
> > > >
> > > > z <- data.frame(a = 1:3, b = letters[1:3])
> > > > > z
> > > >   a h
> > > > 1 1 a
> > > > 2 2 b
> > > > 3 3 c
> > > >
> > > > Suppose I want to change the name of the second column of z from 'b'
> > > > to 'foo' . This is very easy using nested function syntax by:
> > > >
> > > > names(z)[2] <- "foo"
> > > > > z
> > > >   a foo
> > > > 1 1   a
> > > > 2 2   b
> > > > 3 3   c
> > > >
> > > > Now suppose I wanted to do this using |> syntax, along the lines of:
> > > >
> > > > z |> names()[2] <- "foo"  ## throws an error
> > > >
> > > > Slightly fancier is:
> > > >
> > > > z |> (\(x)names(x)[2] <- "b")()
> > > > ## does nothing, but does not throw an error.
> > > >
> > > > However, the following, which resulted from a more careful read of
> > > > ?names works (after changing the name of the second column back to "b"
> > > > of course):
> > > >
> > > > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > > > >z
> > > >   a foo
> > > > 1 1   a
> > > > 2 2   b
> > > > 3 3   c
> > > >
> > > > This qualifies to me as "pretty awful." I'm sure there are better ways
> > > > to do this using pipe syntax, so I would appreciate any better
> > > > approaches.
> > > >
> > > > Best,
> > > > Bert
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Statistics & Software Consulting
> > > GKX Group, GKX Associates Inc.
> > > tel: 1-877-GKX-GROUP
> > > email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 17:19:28 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 21 Jul 2024 08:19:28 -0700
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CA+etgPko5n2s7i42t-ZUNhiPfVL+et5dHvSFviZmD+ODBgb4OA@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAP01uRkNn-VnYn1MSaGk7L3EQ4chx+DBa7=TANUnCvY+mYQcoQ@mail.gmail.com>
 <CAGxFJbQSQh=zECXJkLJaQy7Abxpzmb8x2ARrRgfCwpBTFYf-0A@mail.gmail.com>
 <CA+etgPko5n2s7i42t-ZUNhiPfVL+et5dHvSFviZmD+ODBgb4OA@mail.gmail.com>
Message-ID: <CAGxFJbR2dVv4jR8Bc1CtRr987W8ucq0igK-=UC=UzOemnkz0uA@mail.gmail.com>

Thanks, Calum.

That was exactly what Duncan Murdoch proposed earlier in this thread,
except, of course, he had to explicitly write the function first.

-- Bert

On Sun, Jul 21, 2024 at 8:12?AM CALUM POLWART <polc1410 at gmail.com> wrote:
>
> The tidy solution is rename
>
> literally:
>
> z |> rename(foo = 2)
>
> Or you could do it with other functions
>
> z |> select ( 1, foo = 2)
>
> Or
>
> z |> mutate( foo = 2 ) |> # untested (always worry that makes the whole column 2)
> select (-2)
>
> But that's akin to
>
> z$foo <- z[2]
> z[2] <- null
>
>
> On Sun, 21 Jul 2024, 16:01 Bert Gunter, <bgunter.4567 at gmail.com> wrote:
>>
>> Wow!
>> Yes, this is very clever -- way too clever for me -- and meets my
>> criteria for a solution.
>>
>> I think it's also another piece of evidence of why piping in base R is
>> not suited for complex/nested assignments, as discussed in Deepayan's
>> response.
>>
>> Maybe someone could offer a better Tidydata piping solution just for
>> completeness?
>>
>> Best,
>> Bert
>>
>> On Sun, Jul 21, 2024 at 7:48?AM Gabor Grothendieck
>> <ggrothendieck at gmail.com> wrote:
>> >
>> > This
>> > - is non-destructive (does not change z)
>> > - passes the renamed z onto further pipe legs
>> > - does not use \(x)...
>> >
>> > It works by boxing z, operating on the boxed version and then unboxing it.
>> >
>> >   z <- data.frame(a = 1:3, b = letters[1:3])
>> >   z |> list(x = _) |> within(names(x)[2] <- "foo") |> _$x
>> >   ##   a foo
>> >   ## 1 1   a
>> >   ## 2 2   b
>> >   ## 3 3   c
>> >
>> > On Sat, Jul 20, 2024 at 4:07?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> > >
>> > > This post is likely pretty useless;  it is motivated by a recent post
>> > > from "Val" that was elegantly answered using Tidyverse constructs, but
>> > > I wondered how to do it using base R only. Along the way, I ran into
>> > > the following question to which I think my answer (below) is pretty
>> > > awful. I would be interested in more elegant base R approaches. So...
>> > >
>> > > z <- data.frame(a = 1:3, b = letters[1:3])
>> > > > z
>> > >   a h
>> > > 1 1 a
>> > > 2 2 b
>> > > 3 3 c
>> > >
>> > > Suppose I want to change the name of the second column of z from 'b'
>> > > to 'foo' . This is very easy using nested function syntax by:
>> > >
>> > > names(z)[2] <- "foo"
>> > > > z
>> > >   a foo
>> > > 1 1   a
>> > > 2 2   b
>> > > 3 3   c
>> > >
>> > > Now suppose I wanted to do this using |> syntax, along the lines of:
>> > >
>> > > z |> names()[2] <- "foo"  ## throws an error
>> > >
>> > > Slightly fancier is:
>> > >
>> > > z |> (\(x)names(x)[2] <- "b")()
>> > > ## does nothing, but does not throw an error.
>> > >
>> > > However, the following, which resulted from a more careful read of
>> > > ?names works (after changing the name of the second column back to "b"
>> > > of course):
>> > >
>> > > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
>> > > >z
>> > >   a foo
>> > > 1 1   a
>> > > 2 2   b
>> > > 3 3   c
>> > >
>> > > This qualifies to me as "pretty awful." I'm sure there are better ways
>> > > to do this using pipe syntax, so I would appreciate any better
>> > > approaches.
>> > >
>> > > Best,
>> > > Bert
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> > --
>> > Statistics & Software Consulting
>> > GKX Group, GKX Associates Inc.
>> > tel: 1-877-GKX-GROUP
>> > email: ggrothendieck at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From po|c1410 @end|ng |rom gm@||@com  Sun Jul 21 17:12:22 2024
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Sun, 21 Jul 2024 16:12:22 +0100
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAGxFJbQSQh=zECXJkLJaQy7Abxpzmb8x2ARrRgfCwpBTFYf-0A@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAP01uRkNn-VnYn1MSaGk7L3EQ4chx+DBa7=TANUnCvY+mYQcoQ@mail.gmail.com>
 <CAGxFJbQSQh=zECXJkLJaQy7Abxpzmb8x2ARrRgfCwpBTFYf-0A@mail.gmail.com>
Message-ID: <CA+etgPko5n2s7i42t-ZUNhiPfVL+et5dHvSFviZmD+ODBgb4OA@mail.gmail.com>

The tidy solution is rename

literally:

z |> rename(foo = 2)

Or you could do it with other functions

z |> select ( 1, foo = 2)

Or

z |> mutate( foo = 2 ) |> # untested (always worry that makes the whole
column 2)
select (-2)

But that's akin to

z$foo <- z[2]
z[2] <- null

On Sun, 21 Jul 2024, 16:01 Bert Gunter, <bgunter.4567 at gmail.com> wrote:

> Wow!
> Yes, this is very clever -- way too clever for me -- and meets my
> criteria for a solution.
>
> I think it's also another piece of evidence of why piping in base R is
> not suited for complex/nested assignments, as discussed in Deepayan's
> response.
>
> Maybe someone could offer a better Tidydata piping solution just for
> completeness?
>
> Best,
> Bert
>
> On Sun, Jul 21, 2024 at 7:48?AM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > This
> > - is non-destructive (does not change z)
> > - passes the renamed z onto further pipe legs
> > - does not use \(x)...
> >
> > It works by boxing z, operating on the boxed version and then unboxing
> it.
> >
> >   z <- data.frame(a = 1:3, b = letters[1:3])
> >   z |> list(x = _) |> within(names(x)[2] <- "foo") |> _$x
> >   ##   a foo
> >   ## 1 1   a
> >   ## 2 2   b
> >   ## 3 3   c
> >
> > On Sat, Jul 20, 2024 at 4:07?PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > >
> > > This post is likely pretty useless;  it is motivated by a recent post
> > > from "Val" that was elegantly answered using Tidyverse constructs, but
> > > I wondered how to do it using base R only. Along the way, I ran into
> > > the following question to which I think my answer (below) is pretty
> > > awful. I would be interested in more elegant base R approaches. So...
> > >
> > > z <- data.frame(a = 1:3, b = letters[1:3])
> > > > z
> > >   a h
> > > 1 1 a
> > > 2 2 b
> > > 3 3 c
> > >
> > > Suppose I want to change the name of the second column of z from 'b'
> > > to 'foo' . This is very easy using nested function syntax by:
> > >
> > > names(z)[2] <- "foo"
> > > > z
> > >   a foo
> > > 1 1   a
> > > 2 2   b
> > > 3 3   c
> > >
> > > Now suppose I wanted to do this using |> syntax, along the lines of:
> > >
> > > z |> names()[2] <- "foo"  ## throws an error
> > >
> > > Slightly fancier is:
> > >
> > > z |> (\(x)names(x)[2] <- "b")()
> > > ## does nothing, but does not throw an error.
> > >
> > > However, the following, which resulted from a more careful read of
> > > ?names works (after changing the name of the second column back to "b"
> > > of course):
> > >
> > > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > > >z
> > >   a foo
> > > 1 1   a
> > > 2 2   b
> > > 3 3   c
> > >
> > > This qualifies to me as "pretty awful." I'm sure there are better ways
> > > to do this using pipe syntax, so I would appreciate any better
> > > approaches.
> > >
> > > Best,
> > > Bert
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@|kremk @end|ng |rom gm@||@com  Sun Jul 21 18:36:03 2024
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Sun, 21 Jul 2024 11:36:03 -0500
Subject: [R] Extract
In-Reply-To: <CAGxFJbRfrB4FvAsbssmDWGkZR9duZtW1pmt_qPCUFzurg-yWJg@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAGxFJbSSruMcDyQFwXE1qzyP+7_PpP+4j5cmpCJUHyacnCeHqQ@mail.gmail.com>
 <CAJOiR6Z=MC=14K-jCEx4W98btKPOnCmVH6CxWkVyO45=JKOrNw@mail.gmail.com>
 <CAGxFJbRfrB4FvAsbssmDWGkZR9duZtW1pmt_qPCUFzurg-yWJg@mail.gmail.com>
Message-ID: <CAJOiR6YvHHFX1iZ7LBVCi8RcQe=HE8Zo6HGji4ahL86SwL4GYg@mail.gmail.com>

Thank   you Bert!
However, the last line of the script.

dat |> names() |> _[4:8] <- paste0("s", 1:5)

is giving me an error as shown below
Error: pipe placeholder can only be used as a named argument

Thank you!

On Sat, Jul 20, 2024 at 7:41?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Val:
> I wanted to add here a base R solution to your problem that I realize
> you can happily ignore. However, in the course of puzzling over how to
> do it using the R native pipe syntax ("|>") , I learned some new stuff
> that I thought others might find useful, and it seemed sensible to
> keep the code with this thread for comparison.
>
>  I want to acknowledge that in the course of my labor, I posted a
> query to R-Help to which Iris Simmons posted a very clever answer that
> I would never have figured out myself and that is used below at the
> end to change a subset of the names of the modified data frame via a
> pipe.
>
> Here's the whole solution starting from your (excellent!) example dat:
>
>    dat <- dat$string |>
>       strsplit(" ") |>
>       sapply(FUN = \(x)c(x, rep(NA, 5 - length(x)))) |>
>       t() |> cbind(dat, ..2 = _)
>
>    ## And Iris's trick for changing a subset of attributes, i.e. the
> "names", in a pipe
>    dat |> names() |> _[4:8] <- paste0("s", 1:5)
>
> ## and here's the result:
> > dat
>   Year Sex          string s1   s2   s3   s4   s5
> 1 2002   F        15 xc Ab 15   xc   Ab <NA> <NA>
> 2 2003   F              14 14 <NA> <NA> <NA> <NA>
> 3 2004   M  18 xb 25 35 21 18   xb   25   35   21
> 4 2005   M           13 25 13   25 <NA> <NA> <NA>
> 5 2006   M 14 ac 256 AV 35 14   ac  256   AV   35
> 6 2007   F              11 11 <NA> <NA> <NA> <NA>
>
> As I noted previously, all columns beyond Sex are character
>
> Cheers,
> Bert
>
>
> On Fri, Jul 19, 2024 at 12:26?PM Val <valkremk at gmail.com> wrote:
> >
> > Thank you Jeff and Bert for your help!
> > The components of the string  could be nixed (i.e,  numeric, character
> > or date). Once that is splitted it would be easy for me to format it
> > accordingly.
> >
> > On Fri, Jul 19, 2024 at 2:10?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > I did not look closely at the solutions that you were offered, but
> > > note that you did not specify in your post whether the numbers in your
> > > string were to be character or numeric variables after they are broken
> > > out into their own columns. I believe that they are character in the
> > > solutions, but you should check this. If you want them as numeric,
> > > e.g., for further processing, you will need to convert them. Or
> > > vice-versa.
> > >
> > > Bert
> > >
> > >
> > > On Fri, Jul 19, 2024 at 9:52?AM Val <valkremk at gmail.com> wrote:
> > > >
> > > > Hi All,
> > > >
> > > > I want to extract new variables from a string and add it to the dataframe.
> > > > Sample data is csv file.
> > > >
> > > > dat<-read.csv(text="Year, Sex,string
> > > > 2002,F,15 xc Ab
> > > > 2003,F,14
> > > > 2004,M,18 xb 25 35 21
> > > > 2005,M,13 25
> > > > 2006,M,14 ac 256 AV 35
> > > > 2007,F,11",header=TRUE)
> > > >
> > > > The string column has  a maximum of five variables. Some rows have all
> > > > and others may not have all the five variables. If missing then  fill
> > > > it with NA,
> > > > Desired result is shown below,
> > > >
> > > >
> > > > Year,Sex,string, S1, S2, S3 S4,S5
> > > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > > 2003,F,14, 14,NA,NA,NA,NA
> > > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > > 2005,M,13 25,13, 25,NA,NA,NA
> > > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > > 2007,F,11, 11,NA,NA,NA,NA
> > > >
> > > > Any help?
> > > > Thank you in advance.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From ggrothend|eck @end|ng |rom gm@||@com  Sun Jul 21 18:48:06 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Sun, 21 Jul 2024 12:48:06 -0400
Subject: [R] Using the pipe, |>, syntax with "names<-"
In-Reply-To: <CAP01uRn9_eRhDCOPGBKJA+wqPEuR92GJuU-HkqEXQXvyrOersA@mail.gmail.com>
References: <CAGxFJbRLA-k6VJNQVdrj-yChyxc2WjQUtxsiQ0nr_SpS_MJnfA@mail.gmail.com>
 <CAP01uRkNn-VnYn1MSaGk7L3EQ4chx+DBa7=TANUnCvY+mYQcoQ@mail.gmail.com>
 <CAGxFJbQSQh=zECXJkLJaQy7Abxpzmb8x2ARrRgfCwpBTFYf-0A@mail.gmail.com>
 <CAGxFJbR7fyaGPCR7YfyK7GZXEuiwkMGf5bB6FmLnyC2_WQWLDg@mail.gmail.com>
 <CAP01uRn9_eRhDCOPGBKJA+wqPEuR92GJuU-HkqEXQXvyrOersA@mail.gmail.com>
Message-ID: <CAP01uR=9QUwJ6=7cH4=7ZG4eo0kSAtrQcEqUgN=DRBOz4kedMQ@mail.gmail.com>

That was supposed to be

  z |> list(x = _) |> within(names(x) <- replace(names(x), 2, "foo")) |> _$x

but I really see no advantage over

  z |> list(x = _) |> within(names(x)[2] <- "foo") |> _$x

Regarding the z |> names() |> _[2] <- "foo" idiom, while it is clever,
and well illustrates
what is possible with base R pipes that might not be initially expected,
I think it should be discouraged as not in the spirit of pipes which is a more
functional approach to programming.  Such an approach ought to be
non-destructive and should pass on the result to the next
step in the pipeline.  These criteria are not satisfied by it.

On Sun, Jul 21, 2024 at 11:17?AM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> If you object to names(x)[2]<- ... then use replace:
>
>   z |> list(x = _) |> within(replace(names(x), 2, "foo")) |> _$x
>
> On Sun, Jul 21, 2024 at 11:10?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > hmmm...
> > But note that you still used the nested assignment, names()[2] <-
> > "foo", to circumvent R's pipe limitations, which is exactly what
> > Iris's solution avoids. So I think I was overawed by your cleverness
> > ;-)
> >
> > Best,
> > Bert
> >
> >
> > On Sun, Jul 21, 2024 at 8:01?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > Wow!
> > > Yes, this is very clever -- way too clever for me -- and meets my
> > > criteria for a solution.
> > >
> > > I think it's also another piece of evidence of why piping in base R is
> > > not suited for complex/nested assignments, as discussed in Deepayan's
> > > response.
> > >
> > > Maybe someone could offer a better Tidydata piping solution just for
> > > completeness?
> > >
> > > Best,
> > > Bert
> > >
> > > On Sun, Jul 21, 2024 at 7:48?AM Gabor Grothendieck
> > > <ggrothendieck at gmail.com> wrote:
> > > >
> > > > This
> > > > - is non-destructive (does not change z)
> > > > - passes the renamed z onto further pipe legs
> > > > - does not use \(x)...
> > > >
> > > > It works by boxing z, operating on the boxed version and then unboxing it.
> > > >
> > > >   z <- data.frame(a = 1:3, b = letters[1:3])
> > > >   z |> list(x = _) |> within(names(x)[2] <- "foo") |> _$x
> > > >   ##   a foo
> > > >   ## 1 1   a
> > > >   ## 2 2   b
> > > >   ## 3 3   c
> > > >
> > > > On Sat, Jul 20, 2024 at 4:07?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > > > >
> > > > > This post is likely pretty useless;  it is motivated by a recent post
> > > > > from "Val" that was elegantly answered using Tidyverse constructs, but
> > > > > I wondered how to do it using base R only. Along the way, I ran into
> > > > > the following question to which I think my answer (below) is pretty
> > > > > awful. I would be interested in more elegant base R approaches. So...
> > > > >
> > > > > z <- data.frame(a = 1:3, b = letters[1:3])
> > > > > > z
> > > > >   a h
> > > > > 1 1 a
> > > > > 2 2 b
> > > > > 3 3 c
> > > > >
> > > > > Suppose I want to change the name of the second column of z from 'b'
> > > > > to 'foo' . This is very easy using nested function syntax by:
> > > > >
> > > > > names(z)[2] <- "foo"
> > > > > > z
> > > > >   a foo
> > > > > 1 1   a
> > > > > 2 2   b
> > > > > 3 3   c
> > > > >
> > > > > Now suppose I wanted to do this using |> syntax, along the lines of:
> > > > >
> > > > > z |> names()[2] <- "foo"  ## throws an error
> > > > >
> > > > > Slightly fancier is:
> > > > >
> > > > > z |> (\(x)names(x)[2] <- "b")()
> > > > > ## does nothing, but does not throw an error.
> > > > >
> > > > > However, the following, which resulted from a more careful read of
> > > > > ?names works (after changing the name of the second column back to "b"
> > > > > of course):
> > > > >
> > > > > z |>(\(x) "names<-"(x,value = "[<-"(names(x),2,'foo')))()
> > > > > >z
> > > > >   a foo
> > > > > 1 1   a
> > > > > 2 2   b
> > > > > 3 3   c
> > > > >
> > > > > This qualifies to me as "pretty awful." I'm sure there are better ways
> > > > > to do this using pipe syntax, so I would appreciate any better
> > > > > approaches.
> > > > >
> > > > > Best,
> > > > > Bert
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > >
> > > > --
> > > > Statistics & Software Consulting
> > > > GKX Group, GKX Associates Inc.
> > > > tel: 1-877-GKX-GROUP
> > > > email: ggrothendieck at gmail.com
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothend|eck @end|ng |rom gm@||@com  Sun Jul 21 19:15:14 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Sun, 21 Jul 2024 13:15:14 -0400
Subject: [R] Extract
In-Reply-To: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
Message-ID: <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>

We can use read.table for a base R solution

string <- read.table(text = dat$string, fill = TRUE, header = FALSE,
na.strings = "")
names(string) <- paste0("S", seq_along(string))
cbind(dat[-3], string)

On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
>
> Hi All,
>
> I want to extract new variables from a string and add it to the dataframe.
> Sample data is csv file.
>
> dat<-read.csv(text="Year, Sex,string
> 2002,F,15 xc Ab
> 2003,F,14
> 2004,M,18 xb 25 35 21
> 2005,M,13 25
> 2006,M,14 ac 256 AV 35
> 2007,F,11",header=TRUE)
>
> The string column has  a maximum of five variables. Some rows have all
> and others may not have all the five variables. If missing then  fill
> it with NA,
> Desired result is shown below,
>
>
> Year,Sex,string, S1, S2, S3 S4,S5
> 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> 2003,F,14, 14,NA,NA,NA,NA
> 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> 2005,M,13 25,13, 25,NA,NA,NA
> 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> 2007,F,11, 11,NA,NA,NA,NA
>
> Any help?
> Thank you in advance.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 19:59:49 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 21 Jul 2024 10:59:49 -0700
Subject: [R] Extract
In-Reply-To: <CAJOiR6YvHHFX1iZ7LBVCi8RcQe=HE8Zo6HGji4ahL86SwL4GYg@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAGxFJbSSruMcDyQFwXE1qzyP+7_PpP+4j5cmpCJUHyacnCeHqQ@mail.gmail.com>
 <CAJOiR6Z=MC=14K-jCEx4W98btKPOnCmVH6CxWkVyO45=JKOrNw@mail.gmail.com>
 <CAGxFJbRfrB4FvAsbssmDWGkZR9duZtW1pmt_qPCUFzurg-yWJg@mail.gmail.com>
 <CAJOiR6YvHHFX1iZ7LBVCi8RcQe=HE8Zo6HGji4ahL86SwL4GYg@mail.gmail.com>
Message-ID: <CAGxFJbT0hc2TnsApVe49gOXMo=p5E6E8wbjEbujcEGh0FYQg5w@mail.gmail.com>

I get no error. Please show the entirety of the code you used that
produced the error. Also, are you using a current R version? I am, and
if you are not, there might have been changes from your version to
mine that caused the error.

However, as you were already given satisfactory solutions before, and
Gabor has provided you a simple non-piped base R version that is
probably better anyway, feel free to ignore my request as a waste of
your time.

-- Bert

On Sun, Jul 21, 2024 at 9:36?AM Val <valkremk at gmail.com> wrote:
>
> Thank   you Bert!
> However, the last line of the script.
>
> dat |> names() |> _[4:8] <- paste0("s", 1:5)
>
> is giving me an error as shown below
> Error: pipe placeholder can only be used as a named argument
>
> Thank you!
>
> On Sat, Jul 20, 2024 at 7:41?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Val:
> > I wanted to add here a base R solution to your problem that I realize
> > you can happily ignore. However, in the course of puzzling over how to
> > do it using the R native pipe syntax ("|>") , I learned some new stuff
> > that I thought others might find useful, and it seemed sensible to
> > keep the code with this thread for comparison.
> >
> >  I want to acknowledge that in the course of my labor, I posted a
> > query to R-Help to which Iris Simmons posted a very clever answer that
> > I would never have figured out myself and that is used below at the
> > end to change a subset of the names of the modified data frame via a
> > pipe.
> >
> > Here's the whole solution starting from your (excellent!) example dat:
> >
> >    dat <- dat$string |>
> >       strsplit(" ") |>
> >       sapply(FUN = \(x)c(x, rep(NA, 5 - length(x)))) |>
> >       t() |> cbind(dat, ..2 = _)
> >
> >    ## And Iris's trick for changing a subset of attributes, i.e. the
> > "names", in a pipe
> >    dat |> names() |> _[4:8] <- paste0("s", 1:5)
> >
> > ## and here's the result:
> > > dat
> >   Year Sex          string s1   s2   s3   s4   s5
> > 1 2002   F        15 xc Ab 15   xc   Ab <NA> <NA>
> > 2 2003   F              14 14 <NA> <NA> <NA> <NA>
> > 3 2004   M  18 xb 25 35 21 18   xb   25   35   21
> > 4 2005   M           13 25 13   25 <NA> <NA> <NA>
> > 5 2006   M 14 ac 256 AV 35 14   ac  256   AV   35
> > 6 2007   F              11 11 <NA> <NA> <NA> <NA>
> >
> > As I noted previously, all columns beyond Sex are character
> >
> > Cheers,
> > Bert
> >
> >
> > On Fri, Jul 19, 2024 at 12:26?PM Val <valkremk at gmail.com> wrote:
> > >
> > > Thank you Jeff and Bert for your help!
> > > The components of the string  could be nixed (i.e,  numeric, character
> > > or date). Once that is splitted it would be easy for me to format it
> > > accordingly.
> > >
> > > On Fri, Jul 19, 2024 at 2:10?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > > >
> > > > I did not look closely at the solutions that you were offered, but
> > > > note that you did not specify in your post whether the numbers in your
> > > > string were to be character or numeric variables after they are broken
> > > > out into their own columns. I believe that they are character in the
> > > > solutions, but you should check this. If you want them as numeric,
> > > > e.g., for further processing, you will need to convert them. Or
> > > > vice-versa.
> > > >
> > > > Bert
> > > >
> > > >
> > > > On Fri, Jul 19, 2024 at 9:52?AM Val <valkremk at gmail.com> wrote:
> > > > >
> > > > > Hi All,
> > > > >
> > > > > I want to extract new variables from a string and add it to the dataframe.
> > > > > Sample data is csv file.
> > > > >
> > > > > dat<-read.csv(text="Year, Sex,string
> > > > > 2002,F,15 xc Ab
> > > > > 2003,F,14
> > > > > 2004,M,18 xb 25 35 21
> > > > > 2005,M,13 25
> > > > > 2006,M,14 ac 256 AV 35
> > > > > 2007,F,11",header=TRUE)
> > > > >
> > > > > The string column has  a maximum of five variables. Some rows have all
> > > > > and others may not have all the five variables. If missing then  fill
> > > > > it with NA,
> > > > > Desired result is shown below,
> > > > >
> > > > >
> > > > > Year,Sex,string, S1, S2, S3 S4,S5
> > > > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > > > 2003,F,14, 14,NA,NA,NA,NA
> > > > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > > > 2005,M,13 25,13, 25,NA,NA,NA
> > > > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > > > 2007,F,11, 11,NA,NA,NA,NA
> > > > >
> > > > > Any help?
> > > > > Thank you in advance.
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 20:19:48 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 21 Jul 2024 11:19:48 -0700
Subject: [R] Extract
In-Reply-To: <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
Message-ID: <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>

Nice! -- Let read.table do the work of handling the NA's.
However, even simpler is to use the 'colnames' argument of
read.table() for the column names no?

      string <- read.table(text = dat$string, fill = TRUE, header =
FALSE, na.strings = "",
col.names = paste0("s", 1:5))
      dat <- cbind(dat, string)

-- Bert

On Sun, Jul 21, 2024 at 10:16?AM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> We can use read.table for a base R solution
>
> string <- read.table(text = dat$string, fill = TRUE, header = FALSE,
> na.strings = "")
> names(string) <- paste0("S", seq_along(string))
> cbind(dat[-3], string)
>
> On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
> >
> > Hi All,
> >
> > I want to extract new variables from a string and add it to the dataframe.
> > Sample data is csv file.
> >
> > dat<-read.csv(text="Year, Sex,string
> > 2002,F,15 xc Ab
> > 2003,F,14
> > 2004,M,18 xb 25 35 21
> > 2005,M,13 25
> > 2006,M,14 ac 256 AV 35
> > 2007,F,11",header=TRUE)
> >
> > The string column has  a maximum of five variables. Some rows have all
> > and others may not have all the five variables. If missing then  fill
> > it with NA,
> > Desired result is shown below,
> >
> >
> > Year,Sex,string, S1, S2, S3 S4,S5
> > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > 2003,F,14, 14,NA,NA,NA,NA
> > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > 2005,M,13 25,13, 25,NA,NA,NA
> > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > 2007,F,11, 11,NA,NA,NA,NA
> >
> > Any help?
> > Thank you in advance.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothend|eck @end|ng |rom gm@||@com  Sun Jul 21 20:29:55 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Sun, 21 Jul 2024 14:29:55 -0400
Subject: [R] Extract
In-Reply-To: <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
 <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>
Message-ID: <CAP01uRn21n2q5BV=+5pZfnGbJKyu6-Z9noYBP2_=Fz1WzZRB6w@mail.gmail.com>

Fixing col.names=paste0("S", 1:5) assumes that there will be 5 columns and
we may not want to do that.  If there are only 3 fields in string, at the most,
we may wish to generate only 3 columns.

On Sun, Jul 21, 2024 at 2:20?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Nice! -- Let read.table do the work of handling the NA's.
> However, even simpler is to use the 'colnames' argument of
> read.table() for the column names no?
>
>       string <- read.table(text = dat$string, fill = TRUE, header =
> FALSE, na.strings = "",
> col.names = paste0("s", 1:5))
>       dat <- cbind(dat, string)
>
> -- Bert
>
> On Sun, Jul 21, 2024 at 10:16?AM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > We can use read.table for a base R solution
> >
> > string <- read.table(text = dat$string, fill = TRUE, header = FALSE,
> > na.strings = "")
> > names(string) <- paste0("S", seq_along(string))
> > cbind(dat[-3], string)
> >
> > On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
> > >
> > > Hi All,
> > >
> > > I want to extract new variables from a string and add it to the dataframe.
> > > Sample data is csv file.
> > >
> > > dat<-read.csv(text="Year, Sex,string
> > > 2002,F,15 xc Ab
> > > 2003,F,14
> > > 2004,M,18 xb 25 35 21
> > > 2005,M,13 25
> > > 2006,M,14 ac 256 AV 35
> > > 2007,F,11",header=TRUE)
> > >
> > > The string column has  a maximum of five variables. Some rows have all
> > > and others may not have all the five variables. If missing then  fill
> > > it with NA,
> > > Desired result is shown below,
> > >
> > >
> > > Year,Sex,string, S1, S2, S3 S4,S5
> > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > 2003,F,14, 14,NA,NA,NA,NA
> > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > 2005,M,13 25,13, 25,NA,NA,NA
> > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > 2007,F,11, 11,NA,NA,NA,NA
> > >
> > > Any help?
> > > Thank you in advance.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 21 21:08:35 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 21 Jul 2024 12:08:35 -0700
Subject: [R] Extract
In-Reply-To: <CAP01uRn21n2q5BV=+5pZfnGbJKyu6-Z9noYBP2_=Fz1WzZRB6w@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
 <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>
 <CAP01uRn21n2q5BV=+5pZfnGbJKyu6-Z9noYBP2_=Fz1WzZRB6w@mail.gmail.com>
Message-ID: <CAGxFJbRSaUO+X=6u2uDptwAawv_bxTM6-7282s2gyH0Dn980Hg@mail.gmail.com>

As always, good point.
Here's a piped version of your code for those who are pipe
afficianados. As I'm not very skilled with pipes, it might certainly
be improved.
dat <-
      dat$string |>
         read.table( text = _, fill = TRUE, header = FALSE, na.strings = "")  |>
         (\(x)'names<-'(x,paste0("s", seq_along(x))))() |>
         (\(x)cbind(dat, x))()

-- Bert


On Sun, Jul 21, 2024 at 11:30?AM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> Fixing col.names=paste0("S", 1:5) assumes that there will be 5 columns and
> we may not want to do that.  If there are only 3 fields in string, at the most,
> we may wish to generate only 3 columns.
>
> On Sun, Jul 21, 2024 at 2:20?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Nice! -- Let read.table do the work of handling the NA's.
> > However, even simpler is to use the 'colnames' argument of
> > read.table() for the column names no?
> >
> >       string <- read.table(text = dat$string, fill = TRUE, header =
> > FALSE, na.strings = "",
> > col.names = paste0("s", 1:5))
> >       dat <- cbind(dat, string)
> >
> > -- Bert
> >
> > On Sun, Jul 21, 2024 at 10:16?AM Gabor Grothendieck
> > <ggrothendieck at gmail.com> wrote:
> > >
> > > We can use read.table for a base R solution
> > >
> > > string <- read.table(text = dat$string, fill = TRUE, header = FALSE,
> > > na.strings = "")
> > > names(string) <- paste0("S", seq_along(string))
> > > cbind(dat[-3], string)
> > >
> > > On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
> > > >
> > > > Hi All,
> > > >
> > > > I want to extract new variables from a string and add it to the dataframe.
> > > > Sample data is csv file.
> > > >
> > > > dat<-read.csv(text="Year, Sex,string
> > > > 2002,F,15 xc Ab
> > > > 2003,F,14
> > > > 2004,M,18 xb 25 35 21
> > > > 2005,M,13 25
> > > > 2006,M,14 ac 256 AV 35
> > > > 2007,F,11",header=TRUE)
> > > >
> > > > The string column has  a maximum of five variables. Some rows have all
> > > > and others may not have all the five variables. If missing then  fill
> > > > it with NA,
> > > > Desired result is shown below,
> > > >
> > > >
> > > > Year,Sex,string, S1, S2, S3 S4,S5
> > > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > > 2003,F,14, 14,NA,NA,NA,NA
> > > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > > 2005,M,13 25,13, 25,NA,NA,NA
> > > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > > 2007,F,11, 11,NA,NA,NA,NA
> > > >
> > > > Any help?
> > > > Thank you in advance.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Statistics & Software Consulting
> > > GKX Group, GKX Associates Inc.
> > > tel: 1-877-GKX-GROUP
> > > email: ggrothendieck at gmail.com
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com


From ggrothend|eck @end|ng |rom gm@||@com  Mon Jul 22 13:49:23 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Mon, 22 Jul 2024 07:49:23 -0400
Subject: [R] Extract
In-Reply-To: <CAGxFJbRSaUO+X=6u2uDptwAawv_bxTM6-7282s2gyH0Dn980Hg@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
 <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>
 <CAP01uRn21n2q5BV=+5pZfnGbJKyu6-Z9noYBP2_=Fz1WzZRB6w@mail.gmail.com>
 <CAGxFJbRSaUO+X=6u2uDptwAawv_bxTM6-7282s2gyH0Dn980Hg@mail.gmail.com>
Message-ID: <CAP01uRkU4G86Ee_A0oD4cxVst3rZ12k0Zw-qS8gQmS=hNo5T3w@mail.gmail.com>

Base R. Regarding code improvements:

1. Personally I find (\(...) ...)() notation hard to read (although by
placing (\(x), the body and )() on 3 separate lines it can be improved
somewhat). Instead let us use a named function. The name of the
function can also serve to self document the code.

2. The use of dat both at the start of the pipeline and then again
within a later step of the pipeline goes against a strict left to
right flow. In general if this occurs it is either a sign that we need
to break the pipeline into two or that we need to find another
approach which is what we do here.

We can use the base R code below. Note that the column names produced
by transform(S = read.table(...)) are S.V1, S.V2, etc. so to fix the
column names remove .V from all column names as in the fix_colnames
function shown. It does no harm to apply that to all column names
since the remaining column names will not match.

  fix_colnames <- function(x) {
    setNames(x, sub("\\.V", "", names(x)))
  }

  dat |>
     transform(S = read.table(text = string,
       header = FALSE, fill = TRUE, na.strings = "")) |>
       fix_colnames()

Another way to write this which does not use a separate defined
function nor the anonymous function notation is to box the output of
transform:

  dat |>
     transform(S = read.table(text = string,
       header = FALSE, fill = TRUE, na.strings = "")) |>
       list(x = _) |>
       with( setNames(x, sub("\\.V", "", names(x))) )

dplyr. Alternately use dplyr in which case we can make use of
rename_with . In this case read.table(...) creates column names V1,
V2, etc. and mutate does not change them so simply replacing V with S
at the start of each column name in the output of read.table will do.
Also we can pipe the read.table output directly to rename_with using a
nested pipeline, i.e. the second pipe is entirely within mutate rather
than after it) since mutate won't change the column names. The win
here is because, unlike transform, mutate does not require the S= that
is needed with transform (although it allows it had we wanted it).

  library(dplyr)

  dat |>
     mutate(read.table(text = string,
       header = FALSE, fill = TRUE, na.strings = "")  |>
      rename_with(~ sub("^V", "S", .x))
    )


On Sun, Jul 21, 2024 at 3:08?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> As always, good point.
> Here's a piped version of your code for those who are pipe
> afficianados. As I'm not very skilled with pipes, it might certainly
> be improved.
> dat <-
>       dat$string |>
>          read.table( text = _, fill = TRUE, header = FALSE, na.strings = "")  |>
>          (\(x)'names<-'(x,paste0("s", seq_along(x))))() |>
>          (\(x)cbind(dat, x))()
>
> -- Bert
>
>
> On Sun, Jul 21, 2024 at 11:30?AM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > Fixing col.names=paste0("S", 1:5) assumes that there will be 5 columns and
> > we may not want to do that.  If there are only 3 fields in string, at the most,
> > we may wish to generate only 3 columns.
> >
> > On Sun, Jul 21, 2024 at 2:20?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > Nice! -- Let read.table do the work of handling the NA's.
> > > However, even simpler is to use the 'colnames' argument of
> > > read.table() for the column names no?
> > >
> > >       string <- read.table(text = dat$string, fill = TRUE, header =
> > > FALSE, na.strings = "",
> > > col.names = paste0("s", 1:5))
> > >       dat <- cbind(dat, string)
> > >
> > > -- Bert
> > >
> > > On Sun, Jul 21, 2024 at 10:16?AM Gabor Grothendieck
> > > <ggrothendieck at gmail.com> wrote:
> > > >
> > > > We can use read.table for a base R solution
> > > >
> > > > string <- read.table(text = dat$string, fill = TRUE, header = FALSE,
> > > > na.strings = "")
> > > > names(string) <- paste0("S", seq_along(string))
> > > > cbind(dat[-3], string)
> > > >
> > > > On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
> > > > >
> > > > > Hi All,
> > > > >
> > > > > I want to extract new variables from a string and add it to the dataframe.
> > > > > Sample data is csv file.
> > > > >
> > > > > dat<-read.csv(text="Year, Sex,string
> > > > > 2002,F,15 xc Ab
> > > > > 2003,F,14
> > > > > 2004,M,18 xb 25 35 21
> > > > > 2005,M,13 25
> > > > > 2006,M,14 ac 256 AV 35
> > > > > 2007,F,11",header=TRUE)
> > > > >
> > > > > The string column has  a maximum of five variables. Some rows have all
> > > > > and others may not have all the five variables. If missing then  fill
> > > > > it with NA,
> > > > > Desired result is shown below,
> > > > >
> > > > >
> > > > > Year,Sex,string, S1, S2, S3 S4,S5
> > > > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > > > 2003,F,14, 14,NA,NA,NA,NA
> > > > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > > > 2005,M,13 25,13, 25,NA,NA,NA
> > > > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > > > 2007,F,11, 11,NA,NA,NA,NA
> > > > >
> > > > > Any help?
> > > > > Thank you in advance.
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > >
> > > > --
> > > > Statistics & Software Consulting
> > > > GKX Group, GKX Associates Inc.
> > > > tel: 1-877-GKX-GROUP
> > > > email: ggrothendieck at gmail.com
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From @vi@e@gross m@iii@g oii gm@ii@com  Mon Jul 22 15:29:35 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Mon, 22 Jul 2024 09:29:35 -0400
Subject: [R] Extract
In-Reply-To: <CAP01uRkU4G86Ee_A0oD4cxVst3rZ12k0Zw-qS8gQmS=hNo5T3w@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
 <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>
 <CAP01uRn21n2q5BV=+5pZfnGbJKyu6-Z9noYBP2_=Fz1WzZRB6w@mail.gmail.com>
 <CAGxFJbRSaUO+X=6u2uDptwAawv_bxTM6-7282s2gyH0Dn980Hg@mail.gmail.com>
 <CAP01uRkU4G86Ee_A0oD4cxVst3rZ12k0Zw-qS8gQmS=hNo5T3w@mail.gmail.com>
Message-ID: <012801dadc3b$31ca3e90$955ebbb0$@gmail.com>

Excellent message, Gabor.

Many tools we use are quite flexible and I just want to mention dplyr does have ways to use something like mutate to rename a column, albeit rename(0 is more specifically designed to do the job.

Here is an example of how mutate() can rename by making a new column and removing the old by using a sort of pipeline within mutate():

mydata <- data.frame(a=1, b=2)
mutate(mydata, 
       c=a, 
       a=NULL, 
       d=b, 
       b=NULL)

The result:

> mutate(mydata, c=a, a=NULL, d=b, b=NULL)
  c d
1 1 2

It is effectively the same as following up with a select as an alternative:

mydata |>
  mutate(c=a,
         d=b) |>
  select(c,d)

What people may not quite have grasped is that pipes are not a panacea and can be used alongside all kinds of other methods. Much of dplyr, such as shown above, but also in things like the filter() verb, does a sort of internal pipelining and can apply successive transformations before returning a result suitable for another part of a pipeline. Part of the philosophy was to make more functions where the first argument was something like a data.frame object (but it could be other things) that could be passed along in a pipeline. Trying to shoehorn in other functions that want the item in other positions makes for less intuitive code using place markers like period or underscore.

Pipelines are seen by many as a linear construct but as you point out, with careful design, you can make bigger pipelines that are more like graphs with some regions being a sub-pipeline and do fairly complex things, albeit hard for people to read and understand.

Maybe later, we can discuss again why some people insist on some kind of purity of using the base of languages that are not really expected to stay still but to evolve.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Gabor Grothendieck
Sent: Monday, July 22, 2024 7:49 AM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Extract

Base R. Regarding code improvements:

1. Personally I find (\(...) ...)() notation hard to read (although by
placing (\(x), the body and )() on 3 separate lines it can be improved
somewhat). Instead let us use a named function. The name of the
function can also serve to self document the code.

2. The use of dat both at the start of the pipeline and then again
within a later step of the pipeline goes against a strict left to
right flow. In general if this occurs it is either a sign that we need
to break the pipeline into two or that we need to find another
approach which is what we do here.

We can use the base R code below. Note that the column names produced
by transform(S = read.table(...)) are S.V1, S.V2, etc. so to fix the
column names remove .V from all column names as in the fix_colnames
function shown. It does no harm to apply that to all column names
since the remaining column names will not match.

  fix_colnames <- function(x) {
    setNames(x, sub("\\.V", "", names(x)))
  }

  dat |>
     transform(S = read.table(text = string,
       header = FALSE, fill = TRUE, na.strings = "")) |>
       fix_colnames()

Another way to write this which does not use a separate defined
function nor the anonymous function notation is to box the output of
transform:

  dat |>
     transform(S = read.table(text = string,
       header = FALSE, fill = TRUE, na.strings = "")) |>
       list(x = _) |>
       with( setNames(x, sub("\\.V", "", names(x))) )

dplyr. Alternately use dplyr in which case we can make use of
rename_with . In this case read.table(...) creates column names V1,
V2, etc. and mutate does not change them so simply replacing V with S
at the start of each column name in the output of read.table will do.
Also we can pipe the read.table output directly to rename_with using a
nested pipeline, i.e. the second pipe is entirely within mutate rather
than after it) since mutate won't change the column names. The win
here is because, unlike transform, mutate does not require the S= that
is needed with transform (although it allows it had we wanted it).

  library(dplyr)

  dat |>
     mutate(read.table(text = string,
       header = FALSE, fill = TRUE, na.strings = "")  |>
      rename_with(~ sub("^V", "S", .x))
    )


On Sun, Jul 21, 2024 at 3:08?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> As always, good point.
> Here's a piped version of your code for those who are pipe
> afficianados. As I'm not very skilled with pipes, it might certainly
> be improved.
> dat <-
>       dat$string |>
>          read.table( text = _, fill = TRUE, header = FALSE, na.strings = "")  |>
>          (\(x)'names<-'(x,paste0("s", seq_along(x))))() |>
>          (\(x)cbind(dat, x))()
>
> -- Bert
>
>
> On Sun, Jul 21, 2024 at 11:30?AM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > Fixing col.names=paste0("S", 1:5) assumes that there will be 5 columns and
> > we may not want to do that.  If there are only 3 fields in string, at the most,
> > we may wish to generate only 3 columns.
> >
> > On Sun, Jul 21, 2024 at 2:20?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > Nice! -- Let read.table do the work of handling the NA's.
> > > However, even simpler is to use the 'colnames' argument of
> > > read.table() for the column names no?
> > >
> > >       string <- read.table(text = dat$string, fill = TRUE, header =
> > > FALSE, na.strings = "",
> > > col.names = paste0("s", 1:5))
> > >       dat <- cbind(dat, string)
> > >
> > > -- Bert
> > >
> > > On Sun, Jul 21, 2024 at 10:16?AM Gabor Grothendieck
> > > <ggrothendieck at gmail.com> wrote:
> > > >
> > > > We can use read.table for a base R solution
> > > >
> > > > string <- read.table(text = dat$string, fill = TRUE, header = FALSE,
> > > > na.strings = "")
> > > > names(string) <- paste0("S", seq_along(string))
> > > > cbind(dat[-3], string)
> > > >
> > > > On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
> > > > >
> > > > > Hi All,
> > > > >
> > > > > I want to extract new variables from a string and add it to the dataframe.
> > > > > Sample data is csv file.
> > > > >
> > > > > dat<-read.csv(text="Year, Sex,string
> > > > > 2002,F,15 xc Ab
> > > > > 2003,F,14
> > > > > 2004,M,18 xb 25 35 21
> > > > > 2005,M,13 25
> > > > > 2006,M,14 ac 256 AV 35
> > > > > 2007,F,11",header=TRUE)
> > > > >
> > > > > The string column has  a maximum of five variables. Some rows have all
> > > > > and others may not have all the five variables. If missing then  fill
> > > > > it with NA,
> > > > > Desired result is shown below,
> > > > >
> > > > >
> > > > > Year,Sex,string, S1, S2, S3 S4,S5
> > > > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > > > 2003,F,14, 14,NA,NA,NA,NA
> > > > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > > > 2005,M,13 25,13, 25,NA,NA,NA
> > > > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > > > 2007,F,11, 11,NA,NA,NA,NA
> > > > >
> > > > > Any help?
> > > > > Thank you in advance.
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > >
> > > > --
> > > > Statistics & Software Consulting
> > > > GKX Group, GKX Associates Inc.
> > > > tel: 1-877-GKX-GROUP
> > > > email: ggrothendieck at gmail.com
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jul 22 16:22:08 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 22 Jul 2024 07:22:08 -0700
Subject: [R] Extract
In-Reply-To: <CAP01uRkU4G86Ee_A0oD4cxVst3rZ12k0Zw-qS8gQmS=hNo5T3w@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
 <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>
 <CAP01uRn21n2q5BV=+5pZfnGbJKyu6-Z9noYBP2_=Fz1WzZRB6w@mail.gmail.com>
 <CAGxFJbRSaUO+X=6u2uDptwAawv_bxTM6-7282s2gyH0Dn980Hg@mail.gmail.com>
 <CAP01uRkU4G86Ee_A0oD4cxVst3rZ12k0Zw-qS8gQmS=hNo5T3w@mail.gmail.com>
Message-ID: <CAGxFJbRehzFbQVZaWafW_SayqrbTc=BPrnMr_VLM1e3JeLBOLQ@mail.gmail.com>

Thanks.

I found this to be quite informative and a nice example of how useful
R-Help can be as a resource for R users.

Best,
Bert

On Mon, Jul 22, 2024 at 4:50?AM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> Base R. Regarding code improvements:
>
> 1. Personally I find (\(...) ...)() notation hard to read (although by
> placing (\(x), the body and )() on 3 separate lines it can be improved
> somewhat). Instead let us use a named function. The name of the
> function can also serve to self document the code.
>
> 2. The use of dat both at the start of the pipeline and then again
> within a later step of the pipeline goes against a strict left to
> right flow. In general if this occurs it is either a sign that we need
> to break the pipeline into two or that we need to find another
> approach which is what we do here.
>
> We can use the base R code below. Note that the column names produced
> by transform(S = read.table(...)) are S.V1, S.V2, etc. so to fix the
> column names remove .V from all column names as in the fix_colnames
> function shown. It does no harm to apply that to all column names
> since the remaining column names will not match.
>
>   fix_colnames <- function(x) {
>     setNames(x, sub("\\.V", "", names(x)))
>   }
>
>   dat |>
>      transform(S = read.table(text = string,
>        header = FALSE, fill = TRUE, na.strings = "")) |>
>        fix_colnames()
>
> Another way to write this which does not use a separate defined
> function nor the anonymous function notation is to box the output of
> transform:
>
>   dat |>
>      transform(S = read.table(text = string,
>        header = FALSE, fill = TRUE, na.strings = "")) |>
>        list(x = _) |>
>        with( setNames(x, sub("\\.V", "", names(x))) )
>
> dplyr. Alternately use dplyr in which case we can make use of
> rename_with . In this case read.table(...) creates column names V1,
> V2, etc. and mutate does not change them so simply replacing V with S
> at the start of each column name in the output of read.table will do.
> Also we can pipe the read.table output directly to rename_with using a
> nested pipeline, i.e. the second pipe is entirely within mutate rather
> than after it) since mutate won't change the column names. The win
> here is because, unlike transform, mutate does not require the S= that
> is needed with transform (although it allows it had we wanted it).
>
>   library(dplyr)
>
>   dat |>
>      mutate(read.table(text = string,
>        header = FALSE, fill = TRUE, na.strings = "")  |>
>       rename_with(~ sub("^V", "S", .x))
>     )
>
>
> On Sun, Jul 21, 2024 at 3:08?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > As always, good point.
> > Here's a piped version of your code for those who are pipe
> > afficianados. As I'm not very skilled with pipes, it might certainly
> > be improved.
> > dat <-
> >       dat$string |>
> >          read.table( text = _, fill = TRUE, header = FALSE, na.strings = "")  |>
> >          (\(x)'names<-'(x,paste0("s", seq_along(x))))() |>
> >          (\(x)cbind(dat, x))()
> >
> > -- Bert
> >
> >
> > On Sun, Jul 21, 2024 at 11:30?AM Gabor Grothendieck
> > <ggrothendieck at gmail.com> wrote:
> > >
> > > Fixing col.names=paste0("S", 1:5) assumes that there will be 5 columns and
> > > we may not want to do that.  If there are only 3 fields in string, at the most,
> > > we may wish to generate only 3 columns.
> > >
> > > On Sun, Jul 21, 2024 at 2:20?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > > >
> > > > Nice! -- Let read.table do the work of handling the NA's.
> > > > However, even simpler is to use the 'colnames' argument of
> > > > read.table() for the column names no?
> > > >
> > > >       string <- read.table(text = dat$string, fill = TRUE, header =
> > > > FALSE, na.strings = "",
> > > > col.names = paste0("s", 1:5))
> > > >       dat <- cbind(dat, string)
> > > >
> > > > -- Bert
> > > >
> > > > On Sun, Jul 21, 2024 at 10:16?AM Gabor Grothendieck
> > > > <ggrothendieck at gmail.com> wrote:
> > > > >
> > > > > We can use read.table for a base R solution
> > > > >
> > > > > string <- read.table(text = dat$string, fill = TRUE, header = FALSE,
> > > > > na.strings = "")
> > > > > names(string) <- paste0("S", seq_along(string))
> > > > > cbind(dat[-3], string)
> > > > >
> > > > > On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
> > > > > >
> > > > > > Hi All,
> > > > > >
> > > > > > I want to extract new variables from a string and add it to the dataframe.
> > > > > > Sample data is csv file.
> > > > > >
> > > > > > dat<-read.csv(text="Year, Sex,string
> > > > > > 2002,F,15 xc Ab
> > > > > > 2003,F,14
> > > > > > 2004,M,18 xb 25 35 21
> > > > > > 2005,M,13 25
> > > > > > 2006,M,14 ac 256 AV 35
> > > > > > 2007,F,11",header=TRUE)
> > > > > >
> > > > > > The string column has  a maximum of five variables. Some rows have all
> > > > > > and others may not have all the five variables. If missing then  fill
> > > > > > it with NA,
> > > > > > Desired result is shown below,
> > > > > >
> > > > > >
> > > > > > Year,Sex,string, S1, S2, S3 S4,S5
> > > > > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > > > > 2003,F,14, 14,NA,NA,NA,NA
> > > > > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > > > > 2005,M,13 25,13, 25,NA,NA,NA
> > > > > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > > > > 2007,F,11, 11,NA,NA,NA,NA
> > > > > >
> > > > > > Any help?
> > > > > > Thank you in advance.
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Statistics & Software Consulting
> > > > > GKX Group, GKX Associates Inc.
> > > > > tel: 1-877-GKX-GROUP
> > > > > email: ggrothendieck at gmail.com
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Statistics & Software Consulting
> > > GKX Group, GKX Associates Inc.
> > > tel: 1-877-GKX-GROUP
> > > email: ggrothendieck at gmail.com
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com


From ggrothend|eck @end|ng |rom gm@||@com  Mon Jul 22 16:45:23 2024
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Mon, 22 Jul 2024 10:45:23 -0400
Subject: [R] Extract
In-Reply-To: <CAP01uRkU4G86Ee_A0oD4cxVst3rZ12k0Zw-qS8gQmS=hNo5T3w@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
 <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>
 <CAP01uRn21n2q5BV=+5pZfnGbJKyu6-Z9noYBP2_=Fz1WzZRB6w@mail.gmail.com>
 <CAGxFJbRSaUO+X=6u2uDptwAawv_bxTM6-7282s2gyH0Dn980Hg@mail.gmail.com>
 <CAP01uRkU4G86Ee_A0oD4cxVst3rZ12k0Zw-qS8gQmS=hNo5T3w@mail.gmail.com>
Message-ID: <CAP01uRnoO_DzP2DFqQO1xHZcGyhoWRNWqbiUdvE-wDZiaASKpg@mail.gmail.com>

I had missed that one can pass fix.empty.names = TRUE to transform and
if we do that then we can
put an unnamed data.frame in transform like we can with mutate so
making that change we have the following
base R solution where there is an inner nested pipeline within the
outer pipeline as with the dplyr example.

  transform(dat,
    read.table(text = string, header = FALSE, na.strings = "", fill =
TRUE), fix.empty.names = TRUE) |>
      list(x = _) |>
      with( setNames(x, sub("V", "S", names(x)) )
    )


On Mon, Jul 22, 2024 at 7:49?AM Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
>
> Base R. Regarding code improvements:
>
> 1. Personally I find (\(...) ...)() notation hard to read (although by
> placing (\(x), the body and )() on 3 separate lines it can be improved
> somewhat). Instead let us use a named function. The name of the
> function can also serve to self document the code.
>
> 2. The use of dat both at the start of the pipeline and then again
> within a later step of the pipeline goes against a strict left to
> right flow. In general if this occurs it is either a sign that we need
> to break the pipeline into two or that we need to find another
> approach which is what we do here.
>
> We can use the base R code below. Note that the column names produced
> by transform(S = read.table(...)) are S.V1, S.V2, etc. so to fix the
> column names remove .V from all column names as in the fix_colnames
> function shown. It does no harm to apply that to all column names
> since the remaining column names will not match.
>
>   fix_colnames <- function(x) {
>     setNames(x, sub("\\.V", "", names(x)))
>   }
>
>   dat |>
>      transform(S = read.table(text = string,
>        header = FALSE, fill = TRUE, na.strings = "")) |>
>        fix_colnames()
>
> Another way to write this which does not use a separate defined
> function nor the anonymous function notation is to box the output of
> transform:
>
>   dat |>
>      transform(S = read.table(text = string,
>        header = FALSE, fill = TRUE, na.strings = "")) |>
>        list(x = _) |>
>        with( setNames(x, sub("\\.V", "", names(x))) )
>
> dplyr. Alternately use dplyr in which case we can make use of
> rename_with . In this case read.table(...) creates column names V1,
> V2, etc. and mutate does not change them so simply replacing V with S
> at the start of each column name in the output of read.table will do.
> Also we can pipe the read.table output directly to rename_with using a
> nested pipeline, i.e. the second pipe is entirely within mutate rather
> than after it) since mutate won't change the column names. The win
> here is because, unlike transform, mutate does not require the S= that
> is needed with transform (although it allows it had we wanted it).
>
>   library(dplyr)
>
>   dat |>
>      mutate(read.table(text = string,
>        header = FALSE, fill = TRUE, na.strings = "")  |>
>       rename_with(~ sub("^V", "S", .x))
>     )
>
>
> On Sun, Jul 21, 2024 at 3:08?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > As always, good point.
> > Here's a piped version of your code for those who are pipe
> > afficianados. As I'm not very skilled with pipes, it might certainly
> > be improved.
> > dat <-
> >       dat$string |>
> >          read.table( text = _, fill = TRUE, header = FALSE, na.strings = "")  |>
> >          (\(x)'names<-'(x,paste0("s", seq_along(x))))() |>
> >          (\(x)cbind(dat, x))()
> >
> > -- Bert
> >
> >
> > On Sun, Jul 21, 2024 at 11:30?AM Gabor Grothendieck
> > <ggrothendieck at gmail.com> wrote:
> > >
> > > Fixing col.names=paste0("S", 1:5) assumes that there will be 5 columns and
> > > we may not want to do that.  If there are only 3 fields in string, at the most,
> > > we may wish to generate only 3 columns.
> > >
> > > On Sun, Jul 21, 2024 at 2:20?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > > >
> > > > Nice! -- Let read.table do the work of handling the NA's.
> > > > However, even simpler is to use the 'colnames' argument of
> > > > read.table() for the column names no?
> > > >
> > > >       string <- read.table(text = dat$string, fill = TRUE, header =
> > > > FALSE, na.strings = "",
> > > > col.names = paste0("s", 1:5))
> > > >       dat <- cbind(dat, string)
> > > >
> > > > -- Bert
> > > >
> > > > On Sun, Jul 21, 2024 at 10:16?AM Gabor Grothendieck
> > > > <ggrothendieck at gmail.com> wrote:
> > > > >
> > > > > We can use read.table for a base R solution
> > > > >
> > > > > string <- read.table(text = dat$string, fill = TRUE, header = FALSE,
> > > > > na.strings = "")
> > > > > names(string) <- paste0("S", seq_along(string))
> > > > > cbind(dat[-3], string)
> > > > >
> > > > > On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
> > > > > >
> > > > > > Hi All,
> > > > > >
> > > > > > I want to extract new variables from a string and add it to the dataframe.
> > > > > > Sample data is csv file.
> > > > > >
> > > > > > dat<-read.csv(text="Year, Sex,string
> > > > > > 2002,F,15 xc Ab
> > > > > > 2003,F,14
> > > > > > 2004,M,18 xb 25 35 21
> > > > > > 2005,M,13 25
> > > > > > 2006,M,14 ac 256 AV 35
> > > > > > 2007,F,11",header=TRUE)
> > > > > >
> > > > > > The string column has  a maximum of five variables. Some rows have all
> > > > > > and others may not have all the five variables. If missing then  fill
> > > > > > it with NA,
> > > > > > Desired result is shown below,
> > > > > >
> > > > > >
> > > > > > Year,Sex,string, S1, S2, S3 S4,S5
> > > > > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > > > > 2003,F,14, 14,NA,NA,NA,NA
> > > > > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > > > > 2005,M,13 25,13, 25,NA,NA,NA
> > > > > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > > > > 2007,F,11, 11,NA,NA,NA,NA
> > > > > >
> > > > > > Any help?
> > > > > > Thank you in advance.
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > >
> > > > >
> > > > >
> > > > > --
> > > > > Statistics & Software Consulting
> > > > > GKX Group, GKX Associates Inc.
> > > > > tel: 1-877-GKX-GROUP
> > > > > email: ggrothendieck at gmail.com
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Statistics & Software Consulting
> > > GKX Group, GKX Associates Inc.
> > > tel: 1-877-GKX-GROUP
> > > email: ggrothendieck at gmail.com
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From po|c1410 @end|ng |rom gm@||@com  Mon Jul 22 18:04:43 2024
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Mon, 22 Jul 2024 17:04:43 +0100
Subject: [R] Extract
In-Reply-To: <CAGxFJbRehzFbQVZaWafW_SayqrbTc=BPrnMr_VLM1e3JeLBOLQ@mail.gmail.com>
References: <CAJOiR6YNtC41Htw+4gO9poiH_Qn9o96dh7j74Jpuf1jDdFFiyQ@mail.gmail.com>
 <CAP01uR=FZ2m+TbgtQxP9QCE8ufabPZ0Cv2XE=pYuNhaaHA0t5A@mail.gmail.com>
 <CAGxFJbR86GgM0MFicCxA2t7Wr_45zPMyfdbhY8-J9g-UuyJS5w@mail.gmail.com>
 <CAP01uRn21n2q5BV=+5pZfnGbJKyu6-Z9noYBP2_=Fz1WzZRB6w@mail.gmail.com>
 <CAGxFJbRSaUO+X=6u2uDptwAawv_bxTM6-7282s2gyH0Dn980Hg@mail.gmail.com>
 <CAP01uRkU4G86Ee_A0oD4cxVst3rZ12k0Zw-qS8gQmS=hNo5T3w@mail.gmail.com>
 <CAGxFJbRehzFbQVZaWafW_SayqrbTc=BPrnMr_VLM1e3JeLBOLQ@mail.gmail.com>
Message-ID: <CA+etgPnwBVWYc6J1ET3n_BWY26tv6T0j5t3-SnTU1K4esoPR1w@mail.gmail.com>

But have we lured you to the dark side with the tidyverse yet ;-)



On Mon, 22 Jul 2024, 15:22 Bert Gunter, <bgunter.4567 at gmail.com> wrote:

> Thanks.
>
> I found this to be quite informative and a nice example of how useful
> R-Help can be as a resource for R users.
>
> Best,
> Bert
>
> On Mon, Jul 22, 2024 at 4:50?AM Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
> >
> > Base R. Regarding code improvements:
> >
> > 1. Personally I find (\(...) ...)() notation hard to read (although by
> > placing (\(x), the body and )() on 3 separate lines it can be improved
> > somewhat). Instead let us use a named function. The name of the
> > function can also serve to self document the code.
> >
> > 2. The use of dat both at the start of the pipeline and then again
> > within a later step of the pipeline goes against a strict left to
> > right flow. In general if this occurs it is either a sign that we need
> > to break the pipeline into two or that we need to find another
> > approach which is what we do here.
> >
> > We can use the base R code below. Note that the column names produced
> > by transform(S = read.table(...)) are S.V1, S.V2, etc. so to fix the
> > column names remove .V from all column names as in the fix_colnames
> > function shown. It does no harm to apply that to all column names
> > since the remaining column names will not match.
> >
> >   fix_colnames <- function(x) {
> >     setNames(x, sub("\\.V", "", names(x)))
> >   }
> >
> >   dat |>
> >      transform(S = read.table(text = string,
> >        header = FALSE, fill = TRUE, na.strings = "")) |>
> >        fix_colnames()
> >
> > Another way to write this which does not use a separate defined
> > function nor the anonymous function notation is to box the output of
> > transform:
> >
> >   dat |>
> >      transform(S = read.table(text = string,
> >        header = FALSE, fill = TRUE, na.strings = "")) |>
> >        list(x = _) |>
> >        with( setNames(x, sub("\\.V", "", names(x))) )
> >
> > dplyr. Alternately use dplyr in which case we can make use of
> > rename_with . In this case read.table(...) creates column names V1,
> > V2, etc. and mutate does not change them so simply replacing V with S
> > at the start of each column name in the output of read.table will do.
> > Also we can pipe the read.table output directly to rename_with using a
> > nested pipeline, i.e. the second pipe is entirely within mutate rather
> > than after it) since mutate won't change the column names. The win
> > here is because, unlike transform, mutate does not require the S= that
> > is needed with transform (although it allows it had we wanted it).
> >
> >   library(dplyr)
> >
> >   dat |>
> >      mutate(read.table(text = string,
> >        header = FALSE, fill = TRUE, na.strings = "")  |>
> >       rename_with(~ sub("^V", "S", .x))
> >     )
> >
> >
> > On Sun, Jul 21, 2024 at 3:08?PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > >
> > > As always, good point.
> > > Here's a piped version of your code for those who are pipe
> > > afficianados. As I'm not very skilled with pipes, it might certainly
> > > be improved.
> > > dat <-
> > >       dat$string |>
> > >          read.table( text = _, fill = TRUE, header = FALSE, na.strings
> = "")  |>
> > >          (\(x)'names<-'(x,paste0("s", seq_along(x))))() |>
> > >          (\(x)cbind(dat, x))()
> > >
> > > -- Bert
> > >
> > >
> > > On Sun, Jul 21, 2024 at 11:30?AM Gabor Grothendieck
> > > <ggrothendieck at gmail.com> wrote:
> > > >
> > > > Fixing col.names=paste0("S", 1:5) assumes that there will be 5
> columns and
> > > > we may not want to do that.  If there are only 3 fields in string,
> at the most,
> > > > we may wish to generate only 3 columns.
> > > >
> > > > On Sun, Jul 21, 2024 at 2:20?PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > > > >
> > > > > Nice! -- Let read.table do the work of handling the NA's.
> > > > > However, even simpler is to use the 'colnames' argument of
> > > > > read.table() for the column names no?
> > > > >
> > > > >       string <- read.table(text = dat$string, fill = TRUE, header =
> > > > > FALSE, na.strings = "",
> > > > > col.names = paste0("s", 1:5))
> > > > >       dat <- cbind(dat, string)
> > > > >
> > > > > -- Bert
> > > > >
> > > > > On Sun, Jul 21, 2024 at 10:16?AM Gabor Grothendieck
> > > > > <ggrothendieck at gmail.com> wrote:
> > > > > >
> > > > > > We can use read.table for a base R solution
> > > > > >
> > > > > > string <- read.table(text = dat$string, fill = TRUE, header =
> FALSE,
> > > > > > na.strings = "")
> > > > > > names(string) <- paste0("S", seq_along(string))
> > > > > > cbind(dat[-3], string)
> > > > > >
> > > > > > On Fri, Jul 19, 2024 at 12:52?PM Val <valkremk at gmail.com> wrote:
> > > > > > >
> > > > > > > Hi All,
> > > > > > >
> > > > > > > I want to extract new variables from a string and add it to
> the dataframe.
> > > > > > > Sample data is csv file.
> > > > > > >
> > > > > > > dat<-read.csv(text="Year, Sex,string
> > > > > > > 2002,F,15 xc Ab
> > > > > > > 2003,F,14
> > > > > > > 2004,M,18 xb 25 35 21
> > > > > > > 2005,M,13 25
> > > > > > > 2006,M,14 ac 256 AV 35
> > > > > > > 2007,F,11",header=TRUE)
> > > > > > >
> > > > > > > The string column has  a maximum of five variables. Some rows
> have all
> > > > > > > and others may not have all the five variables. If missing
> then  fill
> > > > > > > it with NA,
> > > > > > > Desired result is shown below,
> > > > > > >
> > > > > > >
> > > > > > > Year,Sex,string, S1, S2, S3 S4,S5
> > > > > > > 2002,F,15 xc Ab, 15,xc,Ab, NA, NA
> > > > > > > 2003,F,14, 14,NA,NA,NA,NA
> > > > > > > 2004,M,18 xb 25 35 21,18, xb, 25, 35, 21
> > > > > > > 2005,M,13 25,13, 25,NA,NA,NA
> > > > > > > 2006,M,14 ac 256 AV 35, 14, ac, 256, AV, 35
> > > > > > > 2007,F,11, 11,NA,NA,NA,NA
> > > > > > >
> > > > > > > Any help?
> > > > > > > Thank you in advance.
> > > > > > >
> > > > > > > ______________________________________________
> > > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > > > > > and provide commented, minimal, self-contained, reproducible
> code.
> > > > > >
> > > > > >
> > > > > >
> > > > > > --
> > > > > > Statistics & Software Consulting
> > > > > > GKX Group, GKX Associates Inc.
> > > > > > tel: 1-877-GKX-GROUP
> > > > > > email: ggrothendieck at gmail.com
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible
> code.
> > > >
> > > >
> > > >
> > > > --
> > > > Statistics & Software Consulting
> > > > GKX Group, GKX Associates Inc.
> > > > tel: 1-877-GKX-GROUP
> > > > email: ggrothendieck at gmail.com
> >
> >
> >
> > --
> > Statistics & Software Consulting
> > GKX Group, GKX Associates Inc.
> > tel: 1-877-GKX-GROUP
> > email: ggrothendieck at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 24 16:43:34 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 24 Jul 2024 07:43:34 -0700
Subject: [R] OFF TOPIC: Nature article on File Drawer Problem in Reserach
Message-ID: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>

Again, this is off topic, not about statistics or R, but I think of
interest to many on this list. The title is:

"So you got a null result. Will anyone publish it?"

https://www.nature.com/articles/d41586-024-02383-9

Best to all,
Bert


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jul 24 17:22:06 2024
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 24 Jul 2024 16:22:06 +0100
Subject: [R] 
 OFF TOPIC: Nature article on File Drawer Problem in Reserach
In-Reply-To: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
References: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
Message-ID: <CAC8ss30ZDk-NGo3USSoY+4no96wGu1jLc8x9v0tU2V4fQqTaLA@mail.gmail.com>

Dear Bert,

You have made my day!! Your post is a great help and very useful in my
field.

The paper is not among the off-the-shelf research output. Some of us, who
get into unenviable conflict and disputation with some reverenced
authorities in our field, understand the weight of the article. I had not
even consumed half of it before I decided to thank you. I will quickly go
back to see how it goes. I am sure it is going to be one of my best
collections for the year!!

Thank you very much. I often follow your posts, even if the topic does not
concern me. Your tough comments always make sense to me. Today, I have
gained something vital I should have lost if I overlooked it because of the
subject heading: "
OFF TOPIC"

Please accept my warmest regards
Ogbos

On Wed, Jul 24, 2024 at 3:44?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Again, this is off topic, not about statistics or R, but I think of
> interest to many on this list. The title is:
>
> "So you got a null result. Will anyone publish it?"
>
> https://www.nature.com/articles/d41586-024-02383-9
>
> Best to all,
> Bert
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 24 17:43:28 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 24 Jul 2024 08:43:28 -0700
Subject: [R] 
 OFF TOPIC: Nature article on File Drawer Problem in Reserach
In-Reply-To: <CAC8ss30ZDk-NGo3USSoY+4no96wGu1jLc8x9v0tU2V4fQqTaLA@mail.gmail.com>
References: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
 <CAC8ss30ZDk-NGo3USSoY+4no96wGu1jLc8x9v0tU2V4fQqTaLA@mail.gmail.com>
Message-ID: <CAGxFJbRuh=8aA2r_Ni1vJ7ah5uy+qOha0DGHOWRSyGTnd-nWmw@mail.gmail.com>

Thank you, but I should have said that this post was not meant to
provoke on-list discussion, as it *is* off topic. My Apologies. Please
keep any further discussion private to me only.

-- Bert

On Wed, Jul 24, 2024 at 8:22?AM Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
> Dear Bert,
>
> You have made my day!! Your post is a great help and very useful in my field.
>
> The paper is not among the off-the-shelf research output. Some of us, who get into unenviable conflict and disputation with some reverenced authorities in our field, understand the weight of the article. I had not even consumed half of it before I decided to thank you. I will quickly go back to see how it goes. I am sure it is going to be one of my best collections for the year!!
>
> Thank you very much. I often follow your posts, even if the topic does not concern me. Your tough comments always make sense to me. Today, I have gained something vital I should have lost if I overlooked it because of the subject heading: "
>
> OFF TOPIC"
>
>
> Please accept my warmest regards
> Ogbos
>
> On Wed, Jul 24, 2024 at 3:44?PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Again, this is off topic, not about statistics or R, but I think of
>> interest to many on this list. The title is:
>>
>> "So you got a null result. Will anyone publish it?"
>>
>> https://www.nature.com/articles/d41586-024-02383-9
>>
>> Best to all,
>> Bert
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Wed Jul 24 19:26:24 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Wed, 24 Jul 2024 13:26:24 -0400
Subject: [R] 
 OFF TOPIC: Nature article on File Drawer Problem in Reserach
In-Reply-To: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
References: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
Message-ID: <005e01daddee$9be6f390$d3b4dab0$@gmail.com>

Bert,

Although the ?ticle was interesting, I have to wonder how much publishing there has been in formal journals related to R, especially recently, that is of a research variety.

I am thinking of an example and wonder if we picked something that is often re-implemented by many parties such as ways of doing graphics or making and manipulating things like variants of data.frames. If someone came up with some new design, such as tibbles or data.table and hypothesized they would be better in some ways, then that could be the basis for doing some serious testing and perhaps publishing results. Sometimes it could just be a comparison of all kinds of cases and a discussion of when one or the other might be better, but other times, the hypothesis might be determined in advance to be looking for a specific outcome and if wrong, publishing it fairly would let people know that your guess was wrong!

I once had a chance to get an Erd?s number of two as my adviser later published several times with Paul Erd?s, but I ended up proving the opposite of my hypothesis, which was not really worthy of publishing! LOL!

I am curious where people go to see research papers in various aspects of Computer Science, or in ones dedicated to specific languages or systems. Is there the same publish or perish aspect in academia as for some older sciences or is the field different in many ways and perhaps often seen as a helper in other disciplines so you can publish elsewhere?

Some areas of the field like aspects of AI, might still be considered quite active but perhaps other areas are seen as less worthy of much further analysis and refinement. Unless actively being changed, where do programming languages like R fit in?


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Wednesday, July 24, 2024 10:44 AM
To: R-help <R-help at r-project.org>
Subject: [R] OFF TOPIC: Nature article on File Drawer Problem in Reserach

Again, this is off topic, not about statistics or R, but I think of
interest to many on this list. The title is:

"So you got a null result. Will anyone publish it?"

https://www.nature.com/articles/d41586-024-02383-9

Best to all,
Bert

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Thu Jul 25 02:54:36 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 25 Jul 2024 00:54:36 +0000
Subject: [R] 
 OFF TOPIC: Nature article on File Drawer Problem in Reserach
In-Reply-To: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
References: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
Message-ID: <CH3PR22MB45142C7771EB8C9FE16DE4BBCFAB2@CH3PR22MB4514.namprd22.prod.outlook.com>

Here is one response: https://doi.org/10.1093/jisesa/iew092
Or paraphrased: yes.

Regards,
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Wednesday, July 24, 2024 10:44 AM
To: R-help <R-help at r-project.org>
Subject: [R] OFF TOPIC: Nature article on File Drawer Problem in Reserach

[External Email]

Again, this is off topic, not about statistics or R, but I think of interest to many on this list. The title is:

"So you got a null result. Will anyone publish it?"

https://www.nature.com/articles/d41586-024-02383-9

Best to all,
Bert

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Thu Jul 25 13:40:14 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 25 Jul 2024 23:40:14 +1200
Subject: [R] 
 OFF TOPIC: Nature article on File Drawer Problem in Reserach
In-Reply-To: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
References: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
Message-ID: <CABcYAd+FxJ8Dg4DQVw+CAAQBHCLV5NbenS3+-Jn=46+u5QtDvQ@mail.gmail.com>

I know you didn't want to stimulate discussion, but the problem is not
confined to publication.  "Adverse reaction to medication" monitoring
programs are plagued by a similarly massive under-reporting problem:
adverse reactions are seldom reported unless they are particularly bad
or surprising.  (The Ministry of Health in my country estimates 90% of
cases are never reported.)  Remembering to check for possible bias
from unreported cases is a human problem for analysts.  Which, if any,
R packages have proven useful to detecting the existence of a
systematic under-reporting problem might well be an appropriate topic
for this list.

On Thu, 25 Jul 2024 at 02:44, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Again, this is off topic, not about statistics or R, but I think of
> interest to many on this list. The title is:
>
> "So you got a null result. Will anyone publish it?"
>
> https://www.nature.com/articles/d41586-024-02383-9
>
> Best to all,
> Bert
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ycd|ng @end|ng |rom coh@org  Thu Jul 25 18:39:28 2024
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 25 Jul 2024 16:39:28 +0000
Subject: [R] please help generate a square correlation matrix
Message-ID: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>

Hi R users,

I generated a square correlation matrix for the dat dataframe below;
dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),
                g2=c(0,1,0,1,0,1,1,0,0),
                g3=c(1,1,0,0,0,1,0,0,0),
                g4=c(0,1,0,1,1,1,1,1,0))
library("Hmisc")
dat.rcorr = rcorr(as.matrix(dat))
dat.r <-round(dat.rcorr$r,2)

however, I want to modify this correlation calculation;
my dat has more than 1000 rows and 22 columns;
in each column, less than 10% values are 1, most of them are 0;
so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
I just want to check whether those values of 1 are correlated between two columns.
Please look at my code in the following;

cor.4gene <-matrix(0,nrow=4*4, ncol=4)
for (i in 1:4){
  #i=1
  for (j in 1:4) {
    #j=1
    d <-dat[,c(i,j)]%>%
      filter(eval(as.symbol(colnames(dat)[i]))!=0 |
               eval(as.symbol(colnames(dat)[j]))!=0)
    c <-cor.test(d[,1],d[,2])
    cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],
                        c$estimate,c$p.value)
  }
}
cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)
colnames(cor.4gene)<-c("gene1","gene2","cor","P")

Can you tell me what mistakes I made?
first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.

cor.4gene$cor[is.na(cor.4gene$cor)]<-1
cor.4gene$cor[is.na(cor.4gene$P)]<-0
cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)

Then this line of code above did not generate a square matrix as what the HMisc library did.
How to fix my code?

Thank you,

Ding


----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jul 25 20:15:07 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 25 Jul 2024 19:15:07 +0100
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>

?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:
> Hi R users,
> 
> I generated a square correlation matrix for the dat dataframe below;
> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),
>                  g2=c(0,1,0,1,0,1,1,0,0),
>                  g3=c(1,1,0,0,0,1,0,0,0),
>                  g4=c(0,1,0,1,1,1,1,1,0))
> library("Hmisc")
> dat.rcorr = rcorr(as.matrix(dat))
> dat.r <-round(dat.rcorr$r,2)
> 
> however, I want to modify this correlation calculation;
> my dat has more than 1000 rows and 22 columns;
> in each column, less than 10% values are 1, most of them are 0;
> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
> I just want to check whether those values of 1 are correlated between two columns.
> Please look at my code in the following;
> 
> cor.4gene <-matrix(0,nrow=4*4, ncol=4)
> for (i in 1:4){
>    #i=1
>    for (j in 1:4) {
>      #j=1
>      d <-dat[,c(i,j)]%>%
>        filter(eval(as.symbol(colnames(dat)[i]))!=0 |
>                 eval(as.symbol(colnames(dat)[j]))!=0)
>      c <-cor.test(d[,1],d[,2])
>      cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],
>                          c$estimate,c$p.value)
>    }
> }
> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)
> colnames(cor.4gene)<-c("gene1","gene2","cor","P")
> 
> Can you tell me what mistakes I made?
> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.
> 
> cor.4gene$cor[is.na(cor.4gene$cor)]<-1
> cor.4gene$cor[is.na(cor.4gene$P)]<-0
> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)
> 
> Then this line of code above did not generate a square matrix as what the HMisc library did.
> How to fix my code?
> 
> Thank you,
> 
> Ding
> 
> 
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> 
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
>   eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> ------------------------------------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

You are complicating the code, there's no need for as.symbol/eval, the 
column numbers do exactly the same.

# create the two results matrices beforehand
r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat), 
names(dat)))

for(i in 1:4) {
   x <- dat[[i]]
   for(j in (1:4)) {
     if(i == j) {
       # there's nothing to test, assign correlation 1
       r[i, j] <- 1
     } else {
       tmp <- cor.test(x, dat[[j]])
       r[i, j] <- tmp$estimate
       P[i, j] <- tmp$p.value
     }
   }
}

# these two results are equal up to floating-point precision
dat.rcorr$r
#>           g1        g2        g3        g4
#> g1 1.0000000 0.1000000 0.3162278 0.1581139
#> g2 0.1000000 1.0000000 0.3162278 0.6324555
#> g3 0.3162278 0.3162278 1.0000000 0.0000000
#> g4 0.1581139 0.6324555 0.0000000 1.0000000
r
#>           g1        g2           g3           g4
#> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01
#> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01
#> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20
#> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00

# these two results are equal up to floating-point precision
dat.rcorr$P
#>           g1         g2        g3         g4
#> g1        NA 0.79797170 0.4070838 0.68452834
#> g2 0.7979717         NA 0.4070838 0.06758329
#> g3 0.4070838 0.40708382        NA 1.00000000
#> g4 0.6845283 0.06758329 1.0000000         NA
P
#>           g1         g2        g3         g4
#> g1        NA 0.79797170 0.4070838 0.68452834
#> g2 0.7979717         NA 0.4070838 0.06758329
#> g3 0.4070838 0.40708382        NA 1.00000000
#> g4 0.6845283 0.06758329 1.0000000         NA


You can put these two results in a list, like Hmisc::rcorr does.

lst_rcorr <- list(r = r, P = P)


Hope this helps,

Rui Barradas




-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com

From ycd|ng @end|ng |rom coh@org  Thu Jul 25 20:26:21 2024
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 25 Jul 2024 18:26:21 +0000
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
Message-ID: <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>

HI Rui,

Thank you for the  help!

You did not remove a row if zero values exist in both column pair, right?

Ding

From: Rui Barradas <ruipbarradas at sapo.pt>
Sent: Thursday, July 25, 2024 11:15 AM
To: Yuan Chun Ding <ycding at coh.org>; r-help at r-project.org
Subject: Re: [R] please help generate a square correlation matrix

?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),


?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:

> Hi R users,

>

> I generated a square correlation matrix for the dat dataframe below;

> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),

>                  g2=c(0,1,0,1,0,1,1,0,0),

>                  g3=c(1,1,0,0,0,1,0,0,0),

>                  g4=c(0,1,0,1,1,1,1,1,0))

> library("Hmisc")

> dat.rcorr = rcorr(as.matrix(dat))

> dat.r <-round(dat.rcorr$r,2)

>

> however, I want to modify this correlation calculation;

> my dat has more than 1000 rows and 22 columns;

> in each column, less than 10% values are 1, most of them are 0;

> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.

> I just want to check whether those values of 1 are correlated between two columns.

> Please look at my code in the following;

>

> cor.4gene <-matrix(0,nrow=4*4, ncol=4)

> for (i in 1:4){

>    #i=1

>    for (j in 1:4) {

>      #j=1

>      d <-dat[,c(i,j)]%>%

>        filter(eval(as.symbol(colnames(dat)[i]))!=0 |

>                 eval(as.symbol(colnames(dat)[j]))!=0)

>      c <-cor.test(d[,1],d[,2])

>      cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],

>                          c$estimate,c$p.value)

>    }

> }

> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)

> colnames(cor.4gene)<-c("gene1","gene2","cor","P")

>

> Can you tell me what mistakes I made?

> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.

>

> cor.4gene$cor[is.na(cor.4gene$cor)]<-1

> cor.4gene$cor[is.na(cor.4gene$P)]<-0

> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)

>

> Then this line of code above did not generate a square matrix as what the HMisc library did.

> How to fix my code?

>

> Thank you,

>

> Ding

>

>

> ----------------------------------------------------------------------

> ------------------------------------------------------------

> -SECURITY/CONFIDENTIALITY WARNING-

>

> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec

>   eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)

> ------------------------------------------------------------

>

>             [[alternative HTML version deleted]]

>

> ______________________________________________

> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$>

> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$>

> and provide commented, minimal, self-contained, reproducible code.

Hello,



You are complicating the code, there's no need for as.symbol/eval, the

column numbers do exactly the same.



# create the two results matrices beforehand

r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),

names(dat)))



for(i in 1:4) {

   x <- dat[[i]]

   for(j in (1:4)) {

     if(i == j) {

       # there's nothing to test, assign correlation 1

       r[i, j] <- 1

     } else {

       tmp <- cor.test(x, dat[[j]])

       r[i, j] <- tmp$estimate

       P[i, j] <- tmp$p.value

     }

   }

}



# these two results are equal up to floating-point precision

dat.rcorr$r

#>           g1        g2        g3        g4

#> g1 1.0000000 0.1000000 0.3162278 0.1581139

#> g2 0.1000000 1.0000000 0.3162278 0.6324555

#> g3 0.3162278 0.3162278 1.0000000 0.0000000

#> g4 0.1581139 0.6324555 0.0000000 1.0000000

r

#>           g1        g2           g3           g4

#> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01

#> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01

#> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20

#> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00



# these two results are equal up to floating-point precision

dat.rcorr$P

#>           g1         g2        g3         g4

#> g1        NA 0.79797170 0.4070838 0.68452834

#> g2 0.7979717         NA 0.4070838 0.06758329

#> g3 0.4070838 0.40708382        NA 1.00000000

#> g4 0.6845283 0.06758329 1.0000000         NA

P

#>           g1         g2        g3         g4

#> g1        NA 0.79797170 0.4070838 0.68452834

#> g2 0.7979717         NA 0.4070838 0.06758329

#> g3 0.4070838 0.40708382        NA 1.00000000

#> g4 0.6845283 0.06758329 1.0000000         NA





You can put these two results in a list, like Hmisc::rcorr does.



lst_rcorr <- list(r = r, P = P)





Hope this helps,



Rui Barradas









--

Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.

https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$>

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Thu Jul 25 21:47:13 2024
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 25 Jul 2024 19:47:13 +0000
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>

Hi Rui,

You are always very helpful!! Thank you,

I just modified your R codes to remove a row with zero values in both column pair as below for my real data.

Ding

dat<-gene22mut.coded
r <- P <- matrix(NA, nrow = 22L, ncol = 22L,
                 dimnames = list(names(dat), names(dat)))

for(i in 1:22) {
  #i=1
  x <- dat[[i]]
  for(j in (1:22)) {
    #j=2
    if(i == j) {
      # there's nothing to test, assign correlation 1
      r[i, j] <- 1
    } else {
      tmp <-cbind(x,dat[[j]])
      row0 <-rowSums(tmp)
      tem2 <-tmp[row0!=0,]
      tmp3 <- cor.test(tem2[,1],tem2[,2])
      r[i, j] <- tmp3$estimate
      P[i, j] <- tmp3$p.value
    }
  }
}
r<-as.data.frame(r)
P<-as.data.frame(P)

From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via R-help
Sent: Thursday, July 25, 2024 11:26 AM
To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
Subject: Re: [R] please help generate a square correlation matrix

HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;


HI Rui,



Thank you for the  help!



You did not remove a row if zero values exist in both column pair, right?



Ding



From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>

Sent: Thursday, July 25, 2024 11:15 AM

To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>; r-help at r-project.org<mailto:r-help at r-project.org>

Subject: Re: [R] please help generate a square correlation matrix



?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),





?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:



> Hi R users,



>



> I generated a square correlation matrix for the dat dataframe below;



> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),



>                  g2=c(0,1,0,1,0,1,1,0,0),



>                  g3=c(1,1,0,0,0,1,0,0,0),



>                  g4=c(0,1,0,1,1,1,1,1,0))



> library("Hmisc")



> dat.rcorr = rcorr(as.matrix(dat))



> dat.r <-round(dat.rcorr$r,2)



>



> however, I want to modify this correlation calculation;



> my dat has more than 1000 rows and 22 columns;



> in each column, less than 10% values are 1, most of them are 0;



> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.



> I just want to check whether those values of 1 are correlated between two columns.



> Please look at my code in the following;



>



> cor.4gene <-matrix(0,nrow=4*4, ncol=4)



> for (i in 1:4){



>    #i=1



>    for (j in 1:4) {



>      #j=1



>      d <-dat[,c(i,j)]%>%



>        filter(eval(as.symbol(colnames(dat)[i]))!=0 |



>                 eval(as.symbol(colnames(dat)[j]))!=0)



>      c <-cor.test(d[,1],d[,2])



>      cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],



>                          c$estimate,c$p.value)



>    }



> }



> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)



> colnames(cor.4gene)<-c("gene1","gene2","cor","P")



>



> Can you tell me what mistakes I made?



> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.



>



> cor.4gene$cor[is.na(cor.4gene$cor)]<-1



> cor.4gene$cor[is.na(cor.4gene$P)]<-0



> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)



>



> Then this line of code above did not generate a square matrix as what the HMisc library did.



> How to fix my code?



>



> Thank you,



>



> Ding



>



>



> ----------------------------------------------------------------------



> ------------------------------------------------------------



> -SECURITY/CONFIDENTIALITY WARNING-



>



> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec



>   eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)



> ------------------------------------------------------------



>



>             [[alternative HTML version deleted]]



>



> ______________________________________________



> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see



> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>

 <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>

 <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>and provide commented, minimal, self-contained, reproducible code.



Hello,







You are complicating the code, there's no need for as.symbol/eval, the



column numbers do exactly the same.







# create the two results matrices beforehand



r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),



names(dat)))







for(i in 1:4) {



   x <- dat[[i]]



   for(j in (1:4)) {



     if(i == j) {



       # there's nothing to test, assign correlation 1



       r[i, j] <- 1



     } else {



       tmp <- cor.test(x, dat[[j]])



       r[i, j] <- tmp$estimate



       P[i, j] <- tmp$p.value



     }



   }



}







# these two results are equal up to floating-point precision



dat.rcorr$r



#>           g1        g2        g3        g4



#> g1 1.0000000 0.1000000 0.3162278 0.1581139



#> g2 0.1000000 1.0000000 0.3162278 0.6324555



#> g3 0.3162278 0.3162278 1.0000000 0.0000000



#> g4 0.1581139 0.6324555 0.0000000 1.0000000



r



#>           g1        g2           g3           g4



#> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01



#> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01



#> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20



#> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00







# these two results are equal up to floating-point precision



dat.rcorr$P



#>           g1         g2        g3         g4



#> g1        NA 0.79797170 0.4070838 0.68452834



#> g2 0.7979717         NA 0.4070838 0.06758329



#> g3 0.4070838 0.40708382        NA 1.00000000



#> g4 0.6845283 0.06758329 1.0000000         NA



P



#>           g1         g2        g3         g4



#> g1        NA 0.79797170 0.4070838 0.68452834



#> g2 0.7979717         NA 0.4070838 0.06758329



#> g3 0.4070838 0.40708382        NA 1.00000000



#> g4 0.6845283 0.06758329 1.0000000         NA











You can put these two results in a list, like Hmisc::rcorr does.







lst_rcorr <- list(r = r, P = P)











Hope this helps,







Rui Barradas



















--



Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.



https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>

 <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>

               [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTML version deleted]]



______________________________________________

R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$>

PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$>

and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jul 25 23:00:54 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 25 Jul 2024 22:00:54 +0100
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>

?s 20:47 de 25/07/2024, Yuan Chun Ding escreveu:
> Hi Rui,
> 
> You are always very helpful!! Thank you,
> 
> I just modified your R codes to remove a row with zero values in both column pair as below for my real data.
> 
> Ding
> 
> dat<-gene22mut.coded
> r <- P <- matrix(NA, nrow = 22L, ncol = 22L,
>                   dimnames = list(names(dat), names(dat)))
> 
> for(i in 1:22) {
>    #i=1
>    x <- dat[[i]]
>    for(j in (1:22)) {
>      #j=2
>      if(i == j) {
>        # there's nothing to test, assign correlation 1
>        r[i, j] <- 1
>      } else {
>        tmp <-cbind(x,dat[[j]])
>        row0 <-rowSums(tmp)
>        tem2 <-tmp[row0!=0,]
>        tmp3 <- cor.test(tem2[,1],tem2[,2])
>        r[i, j] <- tmp3$estimate
>        P[i, j] <- tmp3$p.value
>      }
>    }
> }
> r<-as.data.frame(r)
> P<-as.data.frame(P)
> 
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via R-help
> Sent: Thursday, July 25, 2024 11:26 AM
> To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
> Subject: Re: [R] please help generate a square correlation matrix
> 
> HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;
> 
> 
> HI Rui,
> 
> 
> 
> Thank you for the  help!
> 
> 
> 
> You did not remove a row if zero values exist in both column pair, right?
> 
> 
> 
> Ding
> 
> 
> 
> From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>
> 
> Sent: Thursday, July 25, 2024 11:15 AM
> 
> To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>; r-help at r-project.org<mailto:r-help at r-project.org>
> 
> Subject: Re: [R] please help generate a square correlation matrix
> 
> 
> 
> ?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),
> 
> 
> 
> 
> 
> ?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:
> 
> 
> 
>> Hi R users,
> 
> 
> 
>>
> 
> 
> 
>> I generated a square correlation matrix for the dat dataframe below;
> 
> 
> 
>> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),
> 
> 
> 
>>                   g2=c(0,1,0,1,0,1,1,0,0),
> 
> 
> 
>>                   g3=c(1,1,0,0,0,1,0,0,0),
> 
> 
> 
>>                   g4=c(0,1,0,1,1,1,1,1,0))
> 
> 
> 
>> library("Hmisc")
> 
> 
> 
>> dat.rcorr = rcorr(as.matrix(dat))
> 
> 
> 
>> dat.r <-round(dat.rcorr$r,2)
> 
> 
> 
>>
> 
> 
> 
>> however, I want to modify this correlation calculation;
> 
> 
> 
>> my dat has more than 1000 rows and 22 columns;
> 
> 
> 
>> in each column, less than 10% values are 1, most of them are 0;
> 
> 
> 
>> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
> 
> 
> 
>> I just want to check whether those values of 1 are correlated between two columns.
> 
> 
> 
>> Please look at my code in the following;
> 
> 
> 
>>
> 
> 
> 
>> cor.4gene <-matrix(0,nrow=4*4, ncol=4)
> 
> 
> 
>> for (i in 1:4){
> 
> 
> 
>>     #i=1
> 
> 
> 
>>     for (j in 1:4) {
> 
> 
> 
>>       #j=1
> 
> 
> 
>>       d <-dat[,c(i,j)]%>%
> 
> 
> 
>>         filter(eval(as.symbol(colnames(dat)[i]))!=0 |
> 
> 
> 
>>                  eval(as.symbol(colnames(dat)[j]))!=0)
> 
> 
> 
>>       c <-cor.test(d[,1],d[,2])
> 
> 
> 
>>       cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],
> 
> 
> 
>>                           c$estimate,c$p.value)
> 
> 
> 
>>     }
> 
> 
> 
>> }
> 
> 
> 
>> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)
> 
> 
> 
>> colnames(cor.4gene)<-c("gene1","gene2","cor","P")
> 
> 
> 
>>
> 
> 
> 
>> Can you tell me what mistakes I made?
> 
> 
> 
>> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.
> 
> 
> 
>>
> 
> 
> 
>> cor.4gene$cor[is.na(cor.4gene$cor)]<-1
> 
> 
> 
>> cor.4gene$cor[is.na(cor.4gene$P)]<-0
> 
> 
> 
>> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)
> 
> 
> 
>>
> 
> 
> 
>> Then this line of code above did not generate a square matrix as what the HMisc library did.
> 
> 
> 
>> How to fix my code?
> 
> 
> 
>>
> 
> 
> 
>> Thank you,
> 
> 
> 
>>
> 
> 
> 
>> Ding
> 
> 
> 
>>
> 
> 
> 
>>
> 
> 
> 
>> ----------------------------------------------------------------------
> 
> 
> 
>> ------------------------------------------------------------
> 
> 
> 
>> -SECURITY/CONFIDENTIALITY WARNING-
> 
> 
> 
>>
> 
> 
> 
>> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
> 
> 
> 
>>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> 
> 
> 
>> ------------------------------------------------------------
> 
> 
> 
>>
> 
> 
> 
>>              [[alternative HTML version deleted]]
> 
> 
> 
>>
> 
> 
> 
>> ______________________________________________
> 
> 
> 
>> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> 
> 
> 
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
> 
>   <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
> 
>> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
> 
>   <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
> 
>> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> Hello,
> 
> 
> 
> 
> 
> 
> 
> You are complicating the code, there's no need for as.symbol/eval, the
> 
> 
> 
> column numbers do exactly the same.
> 
> 
> 
> 
> 
> 
> 
> # create the two results matrices beforehand
> 
> 
> 
> r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),
> 
> 
> 
> names(dat)))
> 
> 
> 
> 
> 
> 
> 
> for(i in 1:4) {
> 
> 
> 
>     x <- dat[[i]]
> 
> 
> 
>     for(j in (1:4)) {
> 
> 
> 
>       if(i == j) {
> 
> 
> 
>         # there's nothing to test, assign correlation 1
> 
> 
> 
>         r[i, j] <- 1
> 
> 
> 
>       } else {
> 
> 
> 
>         tmp <- cor.test(x, dat[[j]])
> 
> 
> 
>         r[i, j] <- tmp$estimate
> 
> 
> 
>         P[i, j] <- tmp$p.value
> 
> 
> 
>       }
> 
> 
> 
>     }
> 
> 
> 
> }
> 
> 
> 
> 
> 
> 
> 
> # these two results are equal up to floating-point precision
> 
> 
> 
> dat.rcorr$r
> 
> 
> 
> #>           g1        g2        g3        g4
> 
> 
> 
> #> g1 1.0000000 0.1000000 0.3162278 0.1581139
> 
> 
> 
> #> g2 0.1000000 1.0000000 0.3162278 0.6324555
> 
> 
> 
> #> g3 0.3162278 0.3162278 1.0000000 0.0000000
> 
> 
> 
> #> g4 0.1581139 0.6324555 0.0000000 1.0000000
> 
> 
> 
> r
> 
> 
> 
> #>           g1        g2           g3           g4
> 
> 
> 
> #> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01
> 
> 
> 
> #> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01
> 
> 
> 
> #> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20
> 
> 
> 
> #> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00
> 
> 
> 
> 
> 
> 
> 
> # these two results are equal up to floating-point precision
> 
> 
> 
> dat.rcorr$P
> 
> 
> 
> #>           g1         g2        g3         g4
> 
> 
> 
> #> g1        NA 0.79797170 0.4070838 0.68452834
> 
> 
> 
> #> g2 0.7979717         NA 0.4070838 0.06758329
> 
> 
> 
> #> g3 0.4070838 0.40708382        NA 1.00000000
> 
> 
> 
> #> g4 0.6845283 0.06758329 1.0000000         NA
> 
> 
> 
> P
> 
> 
> 
> #>           g1         g2        g3         g4
> 
> 
> 
> #> g1        NA 0.79797170 0.4070838 0.68452834
> 
> 
> 
> #> g2 0.7979717         NA 0.4070838 0.06758329
> 
> 
> 
> #> g3 0.4070838 0.40708382        NA 1.00000000
> 
> 
> 
> #> g4 0.6845283 0.06758329 1.0000000         NA
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> You can put these two results in a list, like Hmisc::rcorr does.
> 
> 
> 
> 
> 
> 
> 
> lst_rcorr <- list(r = r, P = P)
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Hope this helps,
> 
> 
> 
> 
> 
> 
> 
> Rui Barradas
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> --
> 
> 
> 
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> 
> 
> 
> https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
> 
>   <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
> 
>                 [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTML version deleted]]
> 
> 
> 
> ______________________________________________
> 
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> 
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$>
> 
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$>
> 
> and provide commented, minimal, self-contained, reproducible code.
> 
Hello,

Here are two other ways.

The first is equivalent to your long format attempt.


library(tidyverse)

dat %>%
   names() %>%
   expand.grid(., .) %>%
   apply(1L, \(x) {
     tmp <- dat[rowSums(dat[x]) > 0, ]
     tmp2 <- cor.test(tmp[[ x[1L] ]], tmp[[ x[2L] ]])
     c(tmp2$estimate, P = tmp2$p.value)
   }) %>%
   t() %>%
   as.data.frame() %>%
   cbind(tmp_df, .) %>%
   na.omit()


The second is, in my opinion the one that makes more sense. If you see 
the results, cor is symmetric (as it should) so the calculations are 
repeated. If you only run the cor.tests on the combinations of 
names(dat) by groups of 2, it will save a lot of work. But the output is 
a much smaller a data.frame.


cbind(
   combn(names(dat), 2L) %>%
     t() %>%
     as.data.frame(),
   combn(dat, 2L, FUN = \(d) {
     d2 <- d[rowSums(d) > 0, ]
     tmp2 <- cor.test(d2[[1L]], d2[[2L]])
     c(tmp2$estimate, P = tmp2$p.value)
   }) %>% t()
) %>% na.omit()



Hope this helps,

Rui Barradas



From rb@er @end|ng |rom @t@u@edu  Fri Jul 26 00:40:33 2024
From: rb@er @end|ng |rom @t@u@edu (Robert Baer)
Date: Thu, 25 Jul 2024 17:40:33 -0500
Subject: [R] 
 OFF TOPIC: Nature article on File Drawer Problem in Reserach
In-Reply-To: <CABcYAd+FxJ8Dg4DQVw+CAAQBHCLV5NbenS3+-Jn=46+u5QtDvQ@mail.gmail.com>
References: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
 <CABcYAd+FxJ8Dg4DQVw+CAAQBHCLV5NbenS3+-Jn=46+u5QtDvQ@mail.gmail.com>
Message-ID: <86414ae3-d5ac-4a8a-9784-b5d59fe99aa8@atsu.edu>

Chapter 9 might be of interest:

https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/

And specifically, for funnel plots in R:
https://wviechtb.github.io/metafor/reference/funnel.html

Best,
Rob

On 7/25/2024 6:40 AM, Richard O'Keefe wrote:
> I know you didn't want to stimulate discussion, but the problem is not
> confined to publication.  "Adverse reaction to medication" monitoring
> programs are plagued by a similarly massive under-reporting problem:
> adverse reactions are seldom reported unless they are particularly bad
> or surprising.  (The Ministry of Health in my country estimates 90% of
> cases are never reported.)  Remembering to check for possible bias
> from unreported cases is a human problem for analysts.  Which, if any,
> R packages have proven useful to detecting the existence of a
> systematic under-reporting problem might well be an appropriate topic
> for this list.
>
> On Thu, 25 Jul 2024 at 02:44, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Again, this is off topic, not about statistics or R, but I think of
>> interest to many on this list. The title is:
>>
>> "So you got a null result. Will anyone publish it?"
>>
>> https://www.nature.com/articles/d41586-024-02383-9
>>
>> Best to all,
>> Bert
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul 26 02:07:09 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 25 Jul 2024 17:07:09 -0700
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>
Message-ID: <CAGxFJbTGphHj9bNyS2hfCn6tAPvBaQJyq2=VDsqe=mkcbL-_5g@mail.gmail.com>

If I have understood the request, I'm not sure that omitting all 0
pairs for each pair of columns makes much sense, but be that as it
may, here's another way to do it by using the 'FUN' argument of combn
to encapsulate any calculations that you do. I just use cor() as the
calculation -- you can use anything you like that takes two vectors of
0's and 1's and produces fixed length numeric results (or fromm which
you can extract such).

I encapsulated it all in a little function. Note that I first
converted the data frame to a matrix. Because of their generality,
data frames carry a lot of extra baggage that can slow purely numeric
manipulations down.

Anyway, here's the function, 'somecors' (I'm a bad name picker :(  ! )

   somecors <- function(dat, func = cor){
      dat <- as.matrix(dat)
      indx <- seq_len(ncol(dat))
         combn(indx, 2, FUN = \(z) {
            i <- z[1]; j <- z[2]
            k <- dat[, i ] | dat[, j ]
            c(z,func(dat[k,i ], dat[k,j ]))
         })
   }

Results come out as a matrix with combn(ncol(dat),2) columns, the
first 2 rows giving the pair of column numbers for each column,and
then 1 or more rows (possibly extracted) from whatever func you use.
Here's the results for your data formatted to 2 decimal places:

> round(somecors(dat),2)
     [,1]  [,2]  [,3]  [,4] [,5]  [,6]
[1,]  1.0  1.00  1.00  2.00    2  3.00
[2,]  2.0  3.00  4.00  3.00    4  4.00
[3,] -0.5 -0.41 -0.35 -0.41   NA -0.47
Warning message:
In func(dat[k, i], dat[k, j]) : the standard deviation is zero

The NA and warning comes in the 2,4 pair of columns because after
removing all zero rows in the pair, dat[,4] is all 1's, giving a zero
in the denominator of the cor() calculation -- again, assuming I have
correctly understood your request. If so, this might be something you
need to worry about.

Again, feel free to ignore if  I have misinterpreterd or this does not suit.

Cheers,
Bert


On Thu, Jul 25, 2024 at 2:01?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> ?s 20:47 de 25/07/2024, Yuan Chun Ding escreveu:
> > Hi Rui,
> >
> > You are always very helpful!! Thank you,
> >
> > I just modified your R codes to remove a row with zero values in both column pair as below for my real data.
> >
> > Ding
> >
> > dat<-gene22mut.coded
> > r <- P <- matrix(NA, nrow = 22L, ncol = 22L,
> >                   dimnames = list(names(dat), names(dat)))
> >
> > for(i in 1:22) {
> >    #i=1
> >    x <- dat[[i]]
> >    for(j in (1:22)) {
> >      #j=2
> >      if(i == j) {
> >        # there's nothing to test, assign correlation 1
> >        r[i, j] <- 1
> >      } else {
> >        tmp <-cbind(x,dat[[j]])
> >        row0 <-rowSums(tmp)
> >        tem2 <-tmp[row0!=0,]
> >        tmp3 <- cor.test(tem2[,1],tem2[,2])
> >        r[i, j] <- tmp3$estimate
> >        P[i, j] <- tmp3$p.value
> >      }
> >    }
> > }
> > r<-as.data.frame(r)
> > P<-as.data.frame(P)
> >
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via R-help
> > Sent: Thursday, July 25, 2024 11:26 AM
> > To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
> > Subject: Re: [R] please help generate a square correlation matrix
> >
> > HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;
> >
> >
> > HI Rui,
> >
> >
> >
> > Thank you for the  help!
> >
> >
> >
> > You did not remove a row if zero values exist in both column pair, right?
> >
> >
> >
> > Ding
> >
> >
> >
> > From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>
> >
> > Sent: Thursday, July 25, 2024 11:15 AM
> >
> > To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>; r-help at r-project.org<mailto:r-help at r-project.org>
> >
> > Subject: Re: [R] please help generate a square correlation matrix
> >
> >
> >
> > ?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),
> >
> >
> >
> >
> >
> > ?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:
> >
> >
> >
> >> Hi R users,
> >
> >
> >
> >>
> >
> >
> >
> >> I generated a square correlation matrix for the dat dataframe below;
> >
> >
> >
> >> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),
> >
> >
> >
> >>                   g2=c(0,1,0,1,0,1,1,0,0),
> >
> >
> >
> >>                   g3=c(1,1,0,0,0,1,0,0,0),
> >
> >
> >
> >>                   g4=c(0,1,0,1,1,1,1,1,0))
> >
> >
> >
> >> library("Hmisc")
> >
> >
> >
> >> dat.rcorr = rcorr(as.matrix(dat))
> >
> >
> >
> >> dat.r <-round(dat.rcorr$r,2)
> >
> >
> >
> >>
> >
> >
> >
> >> however, I want to modify this correlation calculation;
> >
> >
> >
> >> my dat has more than 1000 rows and 22 columns;
> >
> >
> >
> >> in each column, less than 10% values are 1, most of them are 0;
> >
> >
> >
> >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
> >
> >
> >
> >> I just want to check whether those values of 1 are correlated between two columns.
> >
> >
> >
> >> Please look at my code in the following;
> >
> >
> >
> >>
> >
> >
> >
> >> cor.4gene <-matrix(0,nrow=4*4, ncol=4)
> >
> >
> >
> >> for (i in 1:4){
> >
> >
> >
> >>     #i=1
> >
> >
> >
> >>     for (j in 1:4) {
> >
> >
> >
> >>       #j=1
> >
> >
> >
> >>       d <-dat[,c(i,j)]%>%
> >
> >
> >
> >>         filter(eval(as.symbol(colnames(dat)[i]))!=0 |
> >
> >
> >
> >>                  eval(as.symbol(colnames(dat)[j]))!=0)
> >
> >
> >
> >>       c <-cor.test(d[,1],d[,2])
> >
> >
> >
> >>       cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],
> >
> >
> >
> >>                           c$estimate,c$p.value)
> >
> >
> >
> >>     }
> >
> >
> >
> >> }
> >
> >
> >
> >> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)
> >
> >
> >
> >> colnames(cor.4gene)<-c("gene1","gene2","cor","P")
> >
> >
> >
> >>
> >
> >
> >
> >> Can you tell me what mistakes I made?
> >
> >
> >
> >> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.
> >
> >
> >
> >>
> >
> >
> >
> >> cor.4gene$cor[is.na(cor.4gene$cor)]<-1
> >
> >
> >
> >> cor.4gene$cor[is.na(cor.4gene$P)]<-0
> >
> >
> >
> >> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)
> >
> >
> >
> >>
> >
> >
> >
> >> Then this line of code above did not generate a square matrix as what the HMisc library did.
> >
> >
> >
> >> How to fix my code?
> >
> >
> >
> >>
> >
> >
> >
> >> Thank you,
> >
> >
> >
> >>
> >
> >
> >
> >> Ding
> >
> >
> >
> >>
> >
> >
> >
> >>
> >
> >
> >
> >> ----------------------------------------------------------------------
> >
> >
> >
> >> ------------------------------------------------------------
> >
> >
> >
> >> -SECURITY/CONFIDENTIALITY WARNING-
> >
> >
> >
> >>
> >
> >
> >
> >> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
> >
> >
> >
> >>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> >
> >
> >
> >> ------------------------------------------------------------
> >
> >
> >
> >>
> >
> >
> >
> >>              [[alternative HTML version deleted]]
> >
> >
> >
> >>
> >
> >
> >
> >> ______________________________________________
> >
> >
> >
> >> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> >
> >
> >
> >> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
> >
> >   <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
> >
> >> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
> >
> >   <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
> >
> >> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > Hello,
> >
> >
> >
> >
> >
> >
> >
> > You are complicating the code, there's no need for as.symbol/eval, the
> >
> >
> >
> > column numbers do exactly the same.
> >
> >
> >
> >
> >
> >
> >
> > # create the two results matrices beforehand
> >
> >
> >
> > r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),
> >
> >
> >
> > names(dat)))
> >
> >
> >
> >
> >
> >
> >
> > for(i in 1:4) {
> >
> >
> >
> >     x <- dat[[i]]
> >
> >
> >
> >     for(j in (1:4)) {
> >
> >
> >
> >       if(i == j) {
> >
> >
> >
> >         # there's nothing to test, assign correlation 1
> >
> >
> >
> >         r[i, j] <- 1
> >
> >
> >
> >       } else {
> >
> >
> >
> >         tmp <- cor.test(x, dat[[j]])
> >
> >
> >
> >         r[i, j] <- tmp$estimate
> >
> >
> >
> >         P[i, j] <- tmp$p.value
> >
> >
> >
> >       }
> >
> >
> >
> >     }
> >
> >
> >
> > }
> >
> >
> >
> >
> >
> >
> >
> > # these two results are equal up to floating-point precision
> >
> >
> >
> > dat.rcorr$r
> >
> >
> >
> > #>           g1        g2        g3        g4
> >
> >
> >
> > #> g1 1.0000000 0.1000000 0.3162278 0.1581139
> >
> >
> >
> > #> g2 0.1000000 1.0000000 0.3162278 0.6324555
> >
> >
> >
> > #> g3 0.3162278 0.3162278 1.0000000 0.0000000
> >
> >
> >
> > #> g4 0.1581139 0.6324555 0.0000000 1.0000000
> >
> >
> >
> > r
> >
> >
> >
> > #>           g1        g2           g3           g4
> >
> >
> >
> > #> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01
> >
> >
> >
> > #> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01
> >
> >
> >
> > #> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20
> >
> >
> >
> > #> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00
> >
> >
> >
> >
> >
> >
> >
> > # these two results are equal up to floating-point precision
> >
> >
> >
> > dat.rcorr$P
> >
> >
> >
> > #>           g1         g2        g3         g4
> >
> >
> >
> > #> g1        NA 0.79797170 0.4070838 0.68452834
> >
> >
> >
> > #> g2 0.7979717         NA 0.4070838 0.06758329
> >
> >
> >
> > #> g3 0.4070838 0.40708382        NA 1.00000000
> >
> >
> >
> > #> g4 0.6845283 0.06758329 1.0000000         NA
> >
> >
> >
> > P
> >
> >
> >
> > #>           g1         g2        g3         g4
> >
> >
> >
> > #> g1        NA 0.79797170 0.4070838 0.68452834
> >
> >
> >
> > #> g2 0.7979717         NA 0.4070838 0.06758329
> >
> >
> >
> > #> g3 0.4070838 0.40708382        NA 1.00000000
> >
> >
> >
> > #> g4 0.6845283 0.06758329 1.0000000         NA
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > You can put these two results in a list, like Hmisc::rcorr does.
> >
> >
> >
> >
> >
> >
> >
> > lst_rcorr <- list(r = r, P = P)
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > Hope this helps,
> >
> >
> >
> >
> >
> >
> >
> > Rui Barradas
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > --
> >
> >
> >
> > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> >
> >
> >
> > https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
> >
> >   <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
> >
> >                 [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTML version deleted]]
> >
> >
> >
> > ______________________________________________
> >
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >
> > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$>
> >
> > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$>
> >
> > and provide commented, minimal, self-contained, reproducible code.
> >
> Hello,
>
> Here are two other ways.
>
> The first is equivalent to your long format attempt.
>
>
> library(tidyverse)
>
> dat %>%
>    names() %>%
>    expand.grid(., .) %>%
>    apply(1L, \(x) {
>      tmp <- dat[rowSums(dat[x]) > 0, ]
>      tmp2 <- cor.test(tmp[[ x[1L] ]], tmp[[ x[2L] ]])
>      c(tmp2$estimate, P = tmp2$p.value)
>    }) %>%
>    t() %>%
>    as.data.frame() %>%
>    cbind(tmp_df, .) %>%
>    na.omit()
>
>
> The second is, in my opinion the one that makes more sense. If you see
> the results, cor is symmetric (as it should) so the calculations are
> repeated. If you only run the cor.tests on the combinations of
> names(dat) by groups of 2, it will save a lot of work. But the output is
> a much smaller a data.frame.
>
>
> cbind(
>    combn(names(dat), 2L) %>%
>      t() %>%
>      as.data.frame(),
>    combn(dat, 2L, FUN = \(d) {
>      d2 <- d[rowSums(d) > 0, ]
>      tmp2 <- cor.test(d2[[1L]], d2[[2L]])
>      c(tmp2$estimate, P = tmp2$p.value)
>    }) %>% t()
> ) %>% na.omit()
>
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Fri Jul 26 14:29:15 2024
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 26 Jul 2024 13:29:15 +0100
Subject: [R] 
 OFF TOPIC: Nature article on File Drawer Problem in Reserach
In-Reply-To: <86414ae3-d5ac-4a8a-9784-b5d59fe99aa8@atsu.edu>
References: <CAGxFJbSfFOVvFjqa22oQLb3QB255x1ME_RVC5qxB-VDRyw_MOw@mail.gmail.com>
 <CABcYAd+FxJ8Dg4DQVw+CAAQBHCLV5NbenS3+-Jn=46+u5QtDvQ@mail.gmail.com>
 <86414ae3-d5ac-4a8a-9784-b5d59fe99aa8@atsu.edu>
Message-ID: <8f0fca91-2a7b-0eb0-1e62-c1458ab9cb29@dewey.myzen.co.uk>

Just to remark that the R community hs been active in developing 
software in this area. The CRAN Task View has almost twenty packages 
claiming to address the problem under various names.

https://cran.r-project.org/view=MetaAnalysis

Whether the methods work has also been the topic of discussion on the 
mailing list dedicated to meta-analysis and interested readers may want 
to search its archives

https://stat.ethz.ch/pipermail/r-sig-meta-analysis/

Michael


On 25/07/2024 23:40, Robert Baer wrote:
> Chapter 9 might be of interest:
> 
> https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/
> 
> And specifically, for funnel plots in R:
> https://wviechtb.github.io/metafor/reference/funnel.html
> 
> Best,
> Rob
> 
> On 7/25/2024 6:40 AM, Richard O'Keefe wrote:
>> I know you didn't want to stimulate discussion, but the problem is not
>> confined to publication.? "Adverse reaction to medication" monitoring
>> programs are plagued by a similarly massive under-reporting problem:
>> adverse reactions are seldom reported unless they are particularly bad
>> or surprising.? (The Ministry of Health in my country estimates 90% of
>> cases are never reported.)? Remembering to check for possible bias
>> from unreported cases is a human problem for analysts.? Which, if any,
>> R packages have proven useful to detecting the existence of a
>> systematic under-reporting problem might well be an appropriate topic
>> for this list.
>>
>> On Thu, 25 Jul 2024 at 02:44, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> Again, this is off topic, not about statistics or R, but I think of
>>> interest to many on this list. The title is:
>>>
>>> "So you got a null result. Will anyone publish it?"
>>>
>>> https://www.nature.com/articles/d41586-024-02383-9
>>>
>>> Best to all,
>>> Bert
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael


From v|to@muggeo @end|ng |rom un|p@@|t  Fri Jul 26 16:46:36 2024
From: v|to@muggeo @end|ng |rom un|p@@|t (Vito Muggeo)
Date: Fri, 26 Jul 2024 16:46:36 +0200
Subject: [R] Automatic Knot selection in Piecewise linear splines
In-Reply-To: <26262.15334.396036.478147@stat.math.ethz.ch>
References: <CAFL9eukUVQzjkmY2fXiLH5LFbySusU6qZqrCd1dMxRHOFZBgFg@mail.gmail.com>
 <26262.15334.396036.478147@stat.math.ethz.ch>
Message-ID: <daae2c17-b44f-426c-b10d-be3542a14951@unipa.it>

dear all,
I apologize for my delay in replying you. Here my contribution, maybe 
just for completeness:

Similar to "earth", "segmented" also fits piecewise linear relationships 
with the number of breakpoints being selected by the AIC or BIC 
(recommended).

#code (example and code from Martin Maechler previous email)

library(segmented)
o<-selgmented(y, ~x, Kmax=20, type="bic", msg=TRUE)
plot(o, add=TRUE)
lines(o, col=2) #the approx CI for the breakpoints

confint(o) #the estimated breakpoints (with CI's)
slope(o) #the estimated slopes (with CI's)


However segmented appears to be less efficient than earth (although with 
reasonable running times), it does NOT work with multivariate responses 
neither products between piecewise linear terms.

kind regards,
Vito



Il 16/07/2024 11:22, Martin Maechler ha scritto:
>>>>>> Anupam Tyagi
>>>>>>      on Tue, 9 Jul 2024 16:16:43 +0530 writes:
> 
>      > How can I do automatic knot selection while fitting piecewise linear
>      > splines to two variables x and y? Which package to use to do it simply? I
>      > also want to visualize the splines (and the scatter plot) with a graph.
> 
>      > Anupam
> 
> NB: linear splines, i.e. piecewise linear continuous functions.
> Given the knots, use  approx() or approxfun() however, the
> automatic knots selection does not happen in the base R packages.
> 
> I'm sure there are several R packages doing this.
> The best such package in my opinion is "earth" which does a
> re-implementation (and extensive  *generalization*) of the
> famous  MARS algorithm of Friedman.
> ==> https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines
> 
> Note that their strengths and power is that  they do their work
> for multivariate x (MARS := Multivariate Adaptive Regression
> Splines), but indeed do work for the simple 1D case.
> 
> In the following example, we always get 11 final knots,
> but I'm sure one can tweak the many tuning paramters of earth()
> to get more:
> 
> ## Can we do  knot-selection  for simple (x,y) splines?  === Yes, via  earth() {using MARS}!
> 
> x <- (0:800)/8
> 
> f <- function(x) 7 * sin(pi/8*x) * abs((x-50)/20)^1.25 - (x-40)*(12-x)/64
> curve(f(x), 0, 100, n = 1000, col=2, lwd=2)
> 
> set.seed(11)
> y <- f(x) + 10*rnorm(x)
> 
> m.sspl <- smooth.spline(x,y) # base line "standard smoother"
> 
> require(earth)
> fm1 <- earth(x, y) # default settings
> summary(fm1, style = "pmax") #-- got  10 knots (x = 44 "used twice") below
> ## Call: earth(x=x, y=y)
> 
> ## y =
> ##   175.9612
> ##   -   10.6744 * pmax(0,      x -  4.625)
> ##   +  9.928496 * pmax(0,      x - 10.875)
> ##   -  5.940857 * pmax(0,      x -  20.25)
> ##   +  3.438948 * pmax(0,      x - 27.125)
> ##   -  3.828159 * pmax(0,     44 -      x)
> ##   +  4.207046 * pmax(0,      x -     44)
> ##   +  2.573822 * pmax(0,      x -   76.5)
> ##   -  10.99073 * pmax(0,      x - 87.125)
> ##   +  10.97592 * pmax(0,      x - 90.875)
> ##   +  9.331949 * pmax(0,      x -     94)
> ##   -   8.48575 * pmax(0,      x -   96.5)
> 
> ## Selected 12 of 12 terms, and 1 of 1 predictors
> ## Termination condition: Reached nk 21
> ## Importance: x
> ## Number of terms at each degree of interaction: 1 11 (additive model)
> ## GCV 108.6592    RSS 82109.44    GRSq 0.861423    RSq 0.86894
> 
> 
> fm2 <- earth(x, y, fast.k = 0) # (more extensive forward pass)
> summary(fm2)
> all.equal(fm1, fm2)# they are identical (apart from 'call'):
> fm3 <- earth(x, y, fast.k = 0, pmethod = "none", trace = 3) # extensive forward pass; *no* pruning
> ## still no change: fm3 "==" fm1
> all.equal(predict(fm1, xx), predict(fm3, xx))
> 
> ## BTW: The chosen knots and coefficients are
> mat <- with(fm1, cbind(dirs, cuts=c(cuts), coef = c(coefficients)))
> 
> ## Plots : fine grid for visualization: instead of   xx <- seq(x[1], x[length(x)], length.out = 1024)
> rnx <- extendrange(x) ## to extrapolate a bit
> xx <- do.call(seq.int, c(rnx, list(length.out = 1200)))
> 
> cbind(f = f(xx),
>        sspl = predict(m.sspl, xx)$y,
>        mars = predict(fm1, xx)) -> fits
> 
> plot(x,y, xlim=rnx, cex = 1/4, col = adjustcolor(1, 1/2))
> cols <- c(adjustcolor(2, 1/3),
>            adjustcolor(4, 2/3),
>            adjustcolor("orange4", 2/3))
> lwds <- c(3, 2, 2)
> matlines(xx, fits, col = cols, lwd = lwds, lty=1)
> legend("topleft", c("true f(x)", "smooth.spline()", "earth()"),
>         col=cols, lwd=lwds, bty = "n")
> title(paste("earth() linear spline vs. smooth.spline();  n =", length(x)))
> mtext(substitute(f(x) == FDEF, list(FDEF = body(f))))
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
=================================================
Vito M.R. Muggeo, PhD
Professor of Statistics
Dip.to Sc Econom, Az e Statistiche
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240; fax: 091 485726
http://www.unipa.it/persone/docenti/m/vito.muggeo
Associate Editor: Statistical Modelling
past chair, Statistical Modelling Society
coordinator, PhD Program in Econ, Businss, Statist


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sat Jul 27 13:00:34 2024
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sat, 27 Jul 2024 11:00:34 +0000
Subject: [R] plotting nnet function....
Message-ID: <PU4P216MB156812A876A473E7DA695695C8B52@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

Dear members,
                             I am using caret for modelling my data. It is a regression problem. My question is : how to plot the final model on the actual data points? The output of the model will be a nonlinear form of the activation function; I want to plot it on the data points. I have researched on web but to no effect. Like drawing a line on the original data points, for a linear model.

Thanking you,
Yours sincerely
AKSHAY M KULKARNI

[https://s-install.avcdn.net/ipm/preview/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>  Virus-free.www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sat Jul 27 13:06:28 2024
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sat, 27 Jul 2024 11:06:28 +0000
Subject: [R] correction.....
Message-ID: <PU4P216MB15685A88D579FDDF7E9E1100C8B52@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

dear members,
                              I want to mention that I am using the neural network model in caret. I forgot to mention it in the previous mail to you people....

THanking you,
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sat Jul 27 13:07:46 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 27 Jul 2024 23:07:46 +1200
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <CAGxFJbTGphHj9bNyS2hfCn6tAPvBaQJyq2=VDsqe=mkcbL-_5g@mail.gmail.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>
 <CAGxFJbTGphHj9bNyS2hfCn6tAPvBaQJyq2=VDsqe=mkcbL-_5g@mail.gmail.com>
Message-ID: <CABcYAdJ2tOowkEMFire6nL0s08P6LQ+gapev1VhY_aDE8TkVVg@mail.gmail.com>

Let's go back to the original posting.

> >
> >> in each column, less than 10% values are 1, most of them are 0;
> >
> >
> >
> >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
> >

So we're talking about correlations between binary variables.
Suppose we have two 0-1-valued variables, x and y.
Let A <- sum(x*y)  # number of cases where x and y are both 1.
Let B <- sum(x)-a  # number of cases where x is 1 and y is 0
Let C <- sum(y)-a # number of cases where y is 1 and x is 0
Let D <- sum(!x * !y) # number of cases where x and y are both 0.

N

On Fri, 26 Jul 2024 at 12:07, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> If I have understood the request, I'm not sure that omitting all 0
> pairs for each pair of columns makes much sense, but be that as it
> may, here's another way to do it by using the 'FUN' argument of combn
> to encapsulate any calculations that you do. I just use cor() as the
> calculation -- you can use anything you like that takes two vectors of
> 0's and 1's and produces fixed length numeric results (or fromm which
> you can extract such).
>
> I encapsulated it all in a little function. Note that I first
> converted the data frame to a matrix. Because of their generality,
> data frames carry a lot of extra baggage that can slow purely numeric
> manipulations down.
>
> Anyway, here's the function, 'somecors' (I'm a bad name picker :(  ! )
>
>    somecors <- function(dat, func = cor){
>       dat <- as.matrix(dat)
>       indx <- seq_len(ncol(dat))
>          combn(indx, 2, FUN = \(z) {
>             i <- z[1]; j <- z[2]
>             k <- dat[, i ] | dat[, j ]
>             c(z,func(dat[k,i ], dat[k,j ]))
>          })
>    }
>
> Results come out as a matrix with combn(ncol(dat),2) columns, the
> first 2 rows giving the pair of column numbers for each column,and
> then 1 or more rows (possibly extracted) from whatever func you use.
> Here's the results for your data formatted to 2 decimal places:
>
> > round(somecors(dat),2)
>      [,1]  [,2]  [,3]  [,4] [,5]  [,6]
> [1,]  1.0  1.00  1.00  2.00    2  3.00
> [2,]  2.0  3.00  4.00  3.00    4  4.00
> [3,] -0.5 -0.41 -0.35 -0.41   NA -0.47
> Warning message:
> In func(dat[k, i], dat[k, j]) : the standard deviation is zero
>
> The NA and warning comes in the 2,4 pair of columns because after
> removing all zero rows in the pair, dat[,4] is all 1's, giving a zero
> in the denominator of the cor() calculation -- again, assuming I have
> correctly understood your request. If so, this might be something you
> need to worry about.
>
> Again, feel free to ignore if  I have misinterpreterd or this does not suit.
>
> Cheers,
> Bert
>
>
> On Thu, Jul 25, 2024 at 2:01?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > ?s 20:47 de 25/07/2024, Yuan Chun Ding escreveu:
> > > Hi Rui,
> > >
> > > You are always very helpful!! Thank you,
> > >
> > > I just modified your R codes to remove a row with zero values in both column pair as below for my real data.
> > >
> > > Ding
> > >
> > > dat<-gene22mut.coded
> > > r <- P <- matrix(NA, nrow = 22L, ncol = 22L,
> > >                   dimnames = list(names(dat), names(dat)))
> > >
> > > for(i in 1:22) {
> > >    #i=1
> > >    x <- dat[[i]]
> > >    for(j in (1:22)) {
> > >      #j=2
> > >      if(i == j) {
> > >        # there's nothing to test, assign correlation 1
> > >        r[i, j] <- 1
> > >      } else {
> > >        tmp <-cbind(x,dat[[j]])
> > >        row0 <-rowSums(tmp)
> > >        tem2 <-tmp[row0!=0,]
> > >        tmp3 <- cor.test(tem2[,1],tem2[,2])
> > >        r[i, j] <- tmp3$estimate
> > >        P[i, j] <- tmp3$p.value
> > >      }
> > >    }
> > > }
> > > r<-as.data.frame(r)
> > > P<-as.data.frame(P)
> > >
> > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via R-help
> > > Sent: Thursday, July 25, 2024 11:26 AM
> > > To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
> > > Subject: Re: [R] please help generate a square correlation matrix
> > >
> > > HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;
> > >
> > >
> > > HI Rui,
> > >
> > >
> > >
> > > Thank you for the  help!
> > >
> > >
> > >
> > > You did not remove a row if zero values exist in both column pair, right?
> > >
> > >
> > >
> > > Ding
> > >
> > >
> > >
> > > From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>
> > >
> > > Sent: Thursday, July 25, 2024 11:15 AM
> > >
> > > To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>; r-help at r-project.org<mailto:r-help at r-project.org>
> > >
> > > Subject: Re: [R] please help generate a square correlation matrix
> > >
> > >
> > >
> > > ?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),
> > >
> > >
> > >
> > >
> > >
> > > ?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:
> > >
> > >
> > >
> > >> Hi R users,
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> I generated a square correlation matrix for the dat dataframe below;
> > >
> > >
> > >
> > >> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),
> > >
> > >
> > >
> > >>                   g2=c(0,1,0,1,0,1,1,0,0),
> > >
> > >
> > >
> > >>                   g3=c(1,1,0,0,0,1,0,0,0),
> > >
> > >
> > >
> > >>                   g4=c(0,1,0,1,1,1,1,1,0))
> > >
> > >
> > >
> > >> library("Hmisc")
> > >
> > >
> > >
> > >> dat.rcorr = rcorr(as.matrix(dat))
> > >
> > >
> > >
> > >> dat.r <-round(dat.rcorr$r,2)
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> however, I want to modify this correlation calculation;
> > >
> > >
> > >
> > >> my dat has more than 1000 rows and 22 columns;
> > >
> > >
> > >
> > >> in each column, less than 10% values are 1, most of them are 0;
> > >
> > >
> > >
> > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
> > >
> > >
> > >
> > >> I just want to check whether those values of 1 are correlated between two columns.
> > >
> > >
> > >
> > >> Please look at my code in the following;
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> cor.4gene <-matrix(0,nrow=4*4, ncol=4)
> > >
> > >
> > >
> > >> for (i in 1:4){
> > >
> > >
> > >
> > >>     #i=1
> > >
> > >
> > >
> > >>     for (j in 1:4) {
> > >
> > >
> > >
> > >>       #j=1
> > >
> > >
> > >
> > >>       d <-dat[,c(i,j)]%>%
> > >
> > >
> > >
> > >>         filter(eval(as.symbol(colnames(dat)[i]))!=0 |
> > >
> > >
> > >
> > >>                  eval(as.symbol(colnames(dat)[j]))!=0)
> > >
> > >
> > >
> > >>       c <-cor.test(d[,1],d[,2])
> > >
> > >
> > >
> > >>       cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],
> > >
> > >
> > >
> > >>                           c$estimate,c$p.value)
> > >
> > >
> > >
> > >>     }
> > >
> > >
> > >
> > >> }
> > >
> > >
> > >
> > >> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)
> > >
> > >
> > >
> > >> colnames(cor.4gene)<-c("gene1","gene2","cor","P")
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> Can you tell me what mistakes I made?
> > >
> > >
> > >
> > >> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> cor.4gene$cor[is.na(cor.4gene$cor)]<-1
> > >
> > >
> > >
> > >> cor.4gene$cor[is.na(cor.4gene$P)]<-0
> > >
> > >
> > >
> > >> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> Then this line of code above did not generate a square matrix as what the HMisc library did.
> > >
> > >
> > >
> > >> How to fix my code?
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> Thank you,
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> Ding
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> ----------------------------------------------------------------------
> > >
> > >
> > >
> > >> ------------------------------------------------------------
> > >
> > >
> > >
> > >> -SECURITY/CONFIDENTIALITY WARNING-
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
> > >
> > >
> > >
> > >>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> > >
> > >
> > >
> > >> ------------------------------------------------------------
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >>              [[alternative HTML version deleted]]
> > >
> > >
> > >
> > >>
> > >
> > >
> > >
> > >> ______________________________________________
> > >
> > >
> > >
> > >> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> > >
> > >
> > >
> > >> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
> > >
> > >   <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
> > >
> > >> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
> > >
> > >   <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
> > >
> > >> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > Hello,
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > You are complicating the code, there's no need for as.symbol/eval, the
> > >
> > >
> > >
> > > column numbers do exactly the same.
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > # create the two results matrices beforehand
> > >
> > >
> > >
> > > r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),
> > >
> > >
> > >
> > > names(dat)))
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > for(i in 1:4) {
> > >
> > >
> > >
> > >     x <- dat[[i]]
> > >
> > >
> > >
> > >     for(j in (1:4)) {
> > >
> > >
> > >
> > >       if(i == j) {
> > >
> > >
> > >
> > >         # there's nothing to test, assign correlation 1
> > >
> > >
> > >
> > >         r[i, j] <- 1
> > >
> > >
> > >
> > >       } else {
> > >
> > >
> > >
> > >         tmp <- cor.test(x, dat[[j]])
> > >
> > >
> > >
> > >         r[i, j] <- tmp$estimate
> > >
> > >
> > >
> > >         P[i, j] <- tmp$p.value
> > >
> > >
> > >
> > >       }
> > >
> > >
> > >
> > >     }
> > >
> > >
> > >
> > > }
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > # these two results are equal up to floating-point precision
> > >
> > >
> > >
> > > dat.rcorr$r
> > >
> > >
> > >
> > > #>           g1        g2        g3        g4
> > >
> > >
> > >
> > > #> g1 1.0000000 0.1000000 0.3162278 0.1581139
> > >
> > >
> > >
> > > #> g2 0.1000000 1.0000000 0.3162278 0.6324555
> > >
> > >
> > >
> > > #> g3 0.3162278 0.3162278 1.0000000 0.0000000
> > >
> > >
> > >
> > > #> g4 0.1581139 0.6324555 0.0000000 1.0000000
> > >
> > >
> > >
> > > r
> > >
> > >
> > >
> > > #>           g1        g2           g3           g4
> > >
> > >
> > >
> > > #> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01
> > >
> > >
> > >
> > > #> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01
> > >
> > >
> > >
> > > #> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20
> > >
> > >
> > >
> > > #> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > # these two results are equal up to floating-point precision
> > >
> > >
> > >
> > > dat.rcorr$P
> > >
> > >
> > >
> > > #>           g1         g2        g3         g4
> > >
> > >
> > >
> > > #> g1        NA 0.79797170 0.4070838 0.68452834
> > >
> > >
> > >
> > > #> g2 0.7979717         NA 0.4070838 0.06758329
> > >
> > >
> > >
> > > #> g3 0.4070838 0.40708382        NA 1.00000000
> > >
> > >
> > >
> > > #> g4 0.6845283 0.06758329 1.0000000         NA
> > >
> > >
> > >
> > > P
> > >
> > >
> > >
> > > #>           g1         g2        g3         g4
> > >
> > >
> > >
> > > #> g1        NA 0.79797170 0.4070838 0.68452834
> > >
> > >
> > >
> > > #> g2 0.7979717         NA 0.4070838 0.06758329
> > >
> > >
> > >
> > > #> g3 0.4070838 0.40708382        NA 1.00000000
> > >
> > >
> > >
> > > #> g4 0.6845283 0.06758329 1.0000000         NA
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > You can put these two results in a list, like Hmisc::rcorr does.
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > lst_rcorr <- list(r = r, P = P)
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > Hope this helps,
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > Rui Barradas
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > --
> > >
> > >
> > >
> > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> > >
> > >
> > >
> > > https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
> > >
> > >   <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
> > >
> > >                 [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTML version deleted]]
> > >
> > >
> > >
> > > ______________________________________________
> > >
> > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > >
> > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$>
> > >
> > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$>
> > >
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > Hello,
> >
> > Here are two other ways.
> >
> > The first is equivalent to your long format attempt.
> >
> >
> > library(tidyverse)
> >
> > dat %>%
> >    names() %>%
> >    expand.grid(., .) %>%
> >    apply(1L, \(x) {
> >      tmp <- dat[rowSums(dat[x]) > 0, ]
> >      tmp2 <- cor.test(tmp[[ x[1L] ]], tmp[[ x[2L] ]])
> >      c(tmp2$estimate, P = tmp2$p.value)
> >    }) %>%
> >    t() %>%
> >    as.data.frame() %>%
> >    cbind(tmp_df, .) %>%
> >    na.omit()
> >
> >
> > The second is, in my opinion the one that makes more sense. If you see
> > the results, cor is symmetric (as it should) so the calculations are
> > repeated. If you only run the cor.tests on the combinations of
> > names(dat) by groups of 2, it will save a lot of work. But the output is
> > a much smaller a data.frame.
> >
> >
> > cbind(
> >    combn(names(dat), 2L) %>%
> >      t() %>%
> >      as.data.frame(),
> >    combn(dat, 2L, FUN = \(d) {
> >      d2 <- d[rowSums(d) > 0, ]
> >      tmp2 <- cor.test(d2[[1L]], d2[[2L]])
> >      c(tmp2$estimate, P = tmp2$p.value)
> >    }) %>% t()
> > ) %>% na.omit()
> >
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Sat Jul 27 13:46:51 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 27 Jul 2024 23:46:51 +1200
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <CABcYAdJ2tOowkEMFire6nL0s08P6LQ+gapev1VhY_aDE8TkVVg@mail.gmail.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>
 <CAGxFJbTGphHj9bNyS2hfCn6tAPvBaQJyq2=VDsqe=mkcbL-_5g@mail.gmail.com>
 <CABcYAdJ2tOowkEMFire6nL0s08P6LQ+gapev1VhY_aDE8TkVVg@mail.gmail.com>
Message-ID: <CABcYAdL7H-VByeMjXHx47gAcntYp0UAqM6h+2_T0+C0_ZJ=ppw@mail.gmail.com>

Curses, my laptop is hallucinating again.  Hope I can get through this.
So we're talking about correlations between binary variables.
Suppose we have two 0-1-valued variables, x and y.
Let A <- sum(x*y)  # number of cases where x and y are both 1.
Let B <- sum(x)-A  # number of cases where x is 1 and y is 0
Let C <- sum(y)-A # number of cases where y is 1 and x is 0
Let D <- sum(!x * !y) # number of cases where x and y are both 0.
(also D = length(x)-A-B-C)

All the information is summarised in the 2-by-2 contingency table.
Some years ago, Nathan Rountree and I supervised Yung-Sing Koh's
data-mining PhD.
She surveyed the data mining literature and found some 37 different
"interestingness measures" for two-variable associations  -- if I
remember correctly; there were a lot of them.  They fell into a much
smaller number of qualitatively similar groups.
At any rate, the Pearson correlation between x and y is
(A*D - B*C)/sqrt((A+B)*(C+D)*(A+C)*(B+D))

So what happens when we delete the rows where x = 0 and y = 0?
Right, it forces D to 0, leaving A B C unchanged.
And looking at the numerator,
  If you delete rows with x = 0 y = 0 you MUST get a negative correlation.

Quite a modest "true" correlation (based on all the data) like -0.2
can masquerade as quite a strong "zero-suppressed" correlation like
-0.6.  Even +0.2 can turn into -0.4.   (These figures are from a
particular simulation run and may not apply in your case.)

Now one of the reasons why Yun-Sing Koh, Nathan Rountree, and I were
interested in interestingness measures is perhaps coincidentally
related to the file drawer/underreporting problem: it's quite common
for rows where x = 0 and y = 0 never to have been reported to you, so
we were hoping there were measures immune to that.  I have argued for
years that "till record analysis" for supermarkets &c is badly flawed
by two facts: (a) it is hard to measure how much of a product people
WOULD have bought if only you had offered it for sale (although you
can make educated guesses) and (b) till records provide no evidence on
what the people who walked out without buying anything wanted (was the
price too high?  could they not find it?).  Problem (a) leads to a
commercial variant of the Signor-Lipps effect: "when x and/or y were
available for purchase" is not the same as "the period for which data
were recorded", thus inflating D, perhaps massively.  Methods
developed for handling the Signor-Lipps effect in paleontology can be
used to estimate when x and y were available helping you to recover a
more realistic N=A+B+C+D.  I really should have published that.

All of which is a long-winded way of saying that
- Pearson correlations on binary columns can be computed very efficiently
- the rows with x=0 and y=0 may be very informative, even essential for analysis
- delete them at your peril.
- really, delete them at your peril.

On Sat, 27 Jul 2024 at 23:07, Richard O'Keefe <raoknz at gmail.com> wrote:
>
> Let's go back to the original posting.
>
> > >
> > >> in each column, less than 10% values are 1, most of them are 0;
> > >
> > >
> > >
> > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
> > >
>
> So we're talking about correlations between binary variables.
> Suppose we have two 0-1-valued variables, x and y.
> Let A <- sum(x*y)  # number of cases where x and y are both 1.
> Let B <- sum(x)-a  # number of cases where x is 1 and y is 0
> Let C <- sum(y)-a # number of cases where y is 1 and x is 0
> Let D <- sum(!x * !y) # number of cases where x and y are both 0.
>
> N
>
> On Fri, 26 Jul 2024 at 12:07, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > If I have understood the request, I'm not sure that omitting all 0
> > pairs for each pair of columns makes much sense, but be that as it
> > may, here's another way to do it by using the 'FUN' argument of combn
> > to encapsulate any calculations that you do. I just use cor() as the
> > calculation -- you can use anything you like that takes two vectors of
> > 0's and 1's and produces fixed length numeric results (or fromm which
> > you can extract such).
> >
> > I encapsulated it all in a little function. Note that I first
> > converted the data frame to a matrix. Because of their generality,
> > data frames carry a lot of extra baggage that can slow purely numeric
> > manipulations down.
> >
> > Anyway, here's the function, 'somecors' (I'm a bad name picker :(  ! )
> >
> >    somecors <- function(dat, func = cor){
> >       dat <- as.matrix(dat)
> >       indx <- seq_len(ncol(dat))
> >          combn(indx, 2, FUN = \(z) {
> >             i <- z[1]; j <- z[2]
> >             k <- dat[, i ] | dat[, j ]
> >             c(z,func(dat[k,i ], dat[k,j ]))
> >          })
> >    }
> >
> > Results come out as a matrix with combn(ncol(dat),2) columns, the
> > first 2 rows giving the pair of column numbers for each column,and
> > then 1 or more rows (possibly extracted) from whatever func you use.
> > Here's the results for your data formatted to 2 decimal places:
> >
> > > round(somecors(dat),2)
> >      [,1]  [,2]  [,3]  [,4] [,5]  [,6]
> > [1,]  1.0  1.00  1.00  2.00    2  3.00
> > [2,]  2.0  3.00  4.00  3.00    4  4.00
> > [3,] -0.5 -0.41 -0.35 -0.41   NA -0.47
> > Warning message:
> > In func(dat[k, i], dat[k, j]) : the standard deviation is zero
> >
> > The NA and warning comes in the 2,4 pair of columns because after
> > removing all zero rows in the pair, dat[,4] is all 1's, giving a zero
> > in the denominator of the cor() calculation -- again, assuming I have
> > correctly understood your request. If so, this might be something you
> > need to worry about.
> >
> > Again, feel free to ignore if  I have misinterpreterd or this does not suit.
> >
> > Cheers,
> > Bert
> >
> >
> > On Thu, Jul 25, 2024 at 2:01?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> > >
> > > ?s 20:47 de 25/07/2024, Yuan Chun Ding escreveu:
> > > > Hi Rui,
> > > >
> > > > You are always very helpful!! Thank you,
> > > >
> > > > I just modified your R codes to remove a row with zero values in both column pair as below for my real data.
> > > >
> > > > Ding
> > > >
> > > > dat<-gene22mut.coded
> > > > r <- P <- matrix(NA, nrow = 22L, ncol = 22L,
> > > >                   dimnames = list(names(dat), names(dat)))
> > > >
> > > > for(i in 1:22) {
> > > >    #i=1
> > > >    x <- dat[[i]]
> > > >    for(j in (1:22)) {
> > > >      #j=2
> > > >      if(i == j) {
> > > >        # there's nothing to test, assign correlation 1
> > > >        r[i, j] <- 1
> > > >      } else {
> > > >        tmp <-cbind(x,dat[[j]])
> > > >        row0 <-rowSums(tmp)
> > > >        tem2 <-tmp[row0!=0,]
> > > >        tmp3 <- cor.test(tem2[,1],tem2[,2])
> > > >        r[i, j] <- tmp3$estimate
> > > >        P[i, j] <- tmp3$p.value
> > > >      }
> > > >    }
> > > > }
> > > > r<-as.data.frame(r)
> > > > P<-as.data.frame(P)
> > > >
> > > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via R-help
> > > > Sent: Thursday, July 25, 2024 11:26 AM
> > > > To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
> > > > Subject: Re: [R] please help generate a square correlation matrix
> > > >
> > > > HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;
> > > >
> > > >
> > > > HI Rui,
> > > >
> > > >
> > > >
> > > > Thank you for the  help!
> > > >
> > > >
> > > >
> > > > You did not remove a row if zero values exist in both column pair, right?
> > > >
> > > >
> > > >
> > > > Ding
> > > >
> > > >
> > > >
> > > > From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>
> > > >
> > > > Sent: Thursday, July 25, 2024 11:15 AM
> > > >
> > > > To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>; r-help at r-project.org<mailto:r-help at r-project.org>
> > > >
> > > > Subject: Re: [R] please help generate a square correlation matrix
> > > >
> > > >
> > > >
> > > > ?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > ?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:
> > > >
> > > >
> > > >
> > > >> Hi R users,
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> I generated a square correlation matrix for the dat dataframe below;
> > > >
> > > >
> > > >
> > > >> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),
> > > >
> > > >
> > > >
> > > >>                   g2=c(0,1,0,1,0,1,1,0,0),
> > > >
> > > >
> > > >
> > > >>                   g3=c(1,1,0,0,0,1,0,0,0),
> > > >
> > > >
> > > >
> > > >>                   g4=c(0,1,0,1,1,1,1,1,0))
> > > >
> > > >
> > > >
> > > >> library("Hmisc")
> > > >
> > > >
> > > >
> > > >> dat.rcorr = rcorr(as.matrix(dat))
> > > >
> > > >
> > > >
> > > >> dat.r <-round(dat.rcorr$r,2)
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> however, I want to modify this correlation calculation;
> > > >
> > > >
> > > >
> > > >> my dat has more than 1000 rows and 22 columns;
> > > >
> > > >
> > > >
> > > >> in each column, less than 10% values are 1, most of them are 0;
> > > >
> > > >
> > > >
> > > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
> > > >
> > > >
> > > >
> > > >> I just want to check whether those values of 1 are correlated between two columns.
> > > >
> > > >
> > > >
> > > >> Please look at my code in the following;
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> cor.4gene <-matrix(0,nrow=4*4, ncol=4)
> > > >
> > > >
> > > >
> > > >> for (i in 1:4){
> > > >
> > > >
> > > >
> > > >>     #i=1
> > > >
> > > >
> > > >
> > > >>     for (j in 1:4) {
> > > >
> > > >
> > > >
> > > >>       #j=1
> > > >
> > > >
> > > >
> > > >>       d <-dat[,c(i,j)]%>%
> > > >
> > > >
> > > >
> > > >>         filter(eval(as.symbol(colnames(dat)[i]))!=0 |
> > > >
> > > >
> > > >
> > > >>                  eval(as.symbol(colnames(dat)[j]))!=0)
> > > >
> > > >
> > > >
> > > >>       c <-cor.test(d[,1],d[,2])
> > > >
> > > >
> > > >
> > > >>       cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],
> > > >
> > > >
> > > >
> > > >>                           c$estimate,c$p.value)
> > > >
> > > >
> > > >
> > > >>     }
> > > >
> > > >
> > > >
> > > >> }
> > > >
> > > >
> > > >
> > > >> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)
> > > >
> > > >
> > > >
> > > >> colnames(cor.4gene)<-c("gene1","gene2","cor","P")
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> Can you tell me what mistakes I made?
> > > >
> > > >
> > > >
> > > >> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> cor.4gene$cor[is.na(cor.4gene$cor)]<-1
> > > >
> > > >
> > > >
> > > >> cor.4gene$cor[is.na(cor.4gene$P)]<-0
> > > >
> > > >
> > > >
> > > >> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> Then this line of code above did not generate a square matrix as what the HMisc library did.
> > > >
> > > >
> > > >
> > > >> How to fix my code?
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> Thank you,
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> Ding
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> ----------------------------------------------------------------------
> > > >
> > > >
> > > >
> > > >> ------------------------------------------------------------
> > > >
> > > >
> > > >
> > > >> -SECURITY/CONFIDENTIALITY WARNING-
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
> > > >
> > > >
> > > >
> > > >>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> > > >
> > > >
> > > >
> > > >> ------------------------------------------------------------
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >>              [[alternative HTML version deleted]]
> > > >
> > > >
> > > >
> > > >>
> > > >
> > > >
> > > >
> > > >> ______________________________________________
> > > >
> > > >
> > > >
> > > >> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> > > >
> > > >
> > > >
> > > >> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
> > > >
> > > >   <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
> > > >
> > > >> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
> > > >
> > > >   <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
> > > >
> > > >> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > >
> > > > Hello,
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > You are complicating the code, there's no need for as.symbol/eval, the
> > > >
> > > >
> > > >
> > > > column numbers do exactly the same.
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > # create the two results matrices beforehand
> > > >
> > > >
> > > >
> > > > r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),
> > > >
> > > >
> > > >
> > > > names(dat)))
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > for(i in 1:4) {
> > > >
> > > >
> > > >
> > > >     x <- dat[[i]]
> > > >
> > > >
> > > >
> > > >     for(j in (1:4)) {
> > > >
> > > >
> > > >
> > > >       if(i == j) {
> > > >
> > > >
> > > >
> > > >         # there's nothing to test, assign correlation 1
> > > >
> > > >
> > > >
> > > >         r[i, j] <- 1
> > > >
> > > >
> > > >
> > > >       } else {
> > > >
> > > >
> > > >
> > > >         tmp <- cor.test(x, dat[[j]])
> > > >
> > > >
> > > >
> > > >         r[i, j] <- tmp$estimate
> > > >
> > > >
> > > >
> > > >         P[i, j] <- tmp$p.value
> > > >
> > > >
> > > >
> > > >       }
> > > >
> > > >
> > > >
> > > >     }
> > > >
> > > >
> > > >
> > > > }
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > # these two results are equal up to floating-point precision
> > > >
> > > >
> > > >
> > > > dat.rcorr$r
> > > >
> > > >
> > > >
> > > > #>           g1        g2        g3        g4
> > > >
> > > >
> > > >
> > > > #> g1 1.0000000 0.1000000 0.3162278 0.1581139
> > > >
> > > >
> > > >
> > > > #> g2 0.1000000 1.0000000 0.3162278 0.6324555
> > > >
> > > >
> > > >
> > > > #> g3 0.3162278 0.3162278 1.0000000 0.0000000
> > > >
> > > >
> > > >
> > > > #> g4 0.1581139 0.6324555 0.0000000 1.0000000
> > > >
> > > >
> > > >
> > > > r
> > > >
> > > >
> > > >
> > > > #>           g1        g2           g3           g4
> > > >
> > > >
> > > >
> > > > #> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01
> > > >
> > > >
> > > >
> > > > #> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01
> > > >
> > > >
> > > >
> > > > #> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20
> > > >
> > > >
> > > >
> > > > #> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > # these two results are equal up to floating-point precision
> > > >
> > > >
> > > >
> > > > dat.rcorr$P
> > > >
> > > >
> > > >
> > > > #>           g1         g2        g3         g4
> > > >
> > > >
> > > >
> > > > #> g1        NA 0.79797170 0.4070838 0.68452834
> > > >
> > > >
> > > >
> > > > #> g2 0.7979717         NA 0.4070838 0.06758329
> > > >
> > > >
> > > >
> > > > #> g3 0.4070838 0.40708382        NA 1.00000000
> > > >
> > > >
> > > >
> > > > #> g4 0.6845283 0.06758329 1.0000000         NA
> > > >
> > > >
> > > >
> > > > P
> > > >
> > > >
> > > >
> > > > #>           g1         g2        g3         g4
> > > >
> > > >
> > > >
> > > > #> g1        NA 0.79797170 0.4070838 0.68452834
> > > >
> > > >
> > > >
> > > > #> g2 0.7979717         NA 0.4070838 0.06758329
> > > >
> > > >
> > > >
> > > > #> g3 0.4070838 0.40708382        NA 1.00000000
> > > >
> > > >
> > > >
> > > > #> g4 0.6845283 0.06758329 1.0000000         NA
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > You can put these two results in a list, like Hmisc::rcorr does.
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > lst_rcorr <- list(r = r, P = P)
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > Hope this helps,
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > Rui Barradas
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > --
> > > >
> > > >
> > > >
> > > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
> > > >
> > > >
> > > >
> > > > https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
> > > >
> > > >   <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
> > > >
> > > >                 [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTML version deleted]]
> > > >
> > > >
> > > >
> > > > ______________________________________________
> > > >
> > > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > > >
> > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$>
> > > >
> > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$>
> > > >
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > Hello,
> > >
> > > Here are two other ways.
> > >
> > > The first is equivalent to your long format attempt.
> > >
> > >
> > > library(tidyverse)
> > >
> > > dat %>%
> > >    names() %>%
> > >    expand.grid(., .) %>%
> > >    apply(1L, \(x) {
> > >      tmp <- dat[rowSums(dat[x]) > 0, ]
> > >      tmp2 <- cor.test(tmp[[ x[1L] ]], tmp[[ x[2L] ]])
> > >      c(tmp2$estimate, P = tmp2$p.value)
> > >    }) %>%
> > >    t() %>%
> > >    as.data.frame() %>%
> > >    cbind(tmp_df, .) %>%
> > >    na.omit()
> > >
> > >
> > > The second is, in my opinion the one that makes more sense. If you see
> > > the results, cor is symmetric (as it should) so the calculations are
> > > repeated. If you only run the cor.tests on the combinations of
> > > names(dat) by groups of 2, it will save a lot of work. But the output is
> > > a much smaller a data.frame.
> > >
> > >
> > > cbind(
> > >    combn(names(dat), 2L) %>%
> > >      t() %>%
> > >      as.data.frame(),
> > >    combn(dat, 2L, FUN = \(d) {
> > >      d2 <- d[rowSums(d) > 0, ]
> > >      tmp2 <- cor.test(d2[[1L]], d2[[2L]])
> > >      c(tmp2$estimate, P = tmp2$p.value)
> > >    }) %>% t()
> > > ) %>% na.omit()
> > >
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @nupty@g| @end|ng |rom gm@||@com  Sat Jul 27 15:04:38 2024
From: @nupty@g| @end|ng |rom gm@||@com (Anupam Tyagi)
Date: Sat, 27 Jul 2024 18:34:38 +0530
Subject: [R] Automatic Knot selection in Piecewise linear splines
In-Reply-To: <daae2c17-b44f-426c-b10d-be3542a14951@unipa.it>
References: <CAFL9eukUVQzjkmY2fXiLH5LFbySusU6qZqrCd1dMxRHOFZBgFg@mail.gmail.com>
 <26262.15334.396036.478147@stat.math.ethz.ch>
 <daae2c17-b44f-426c-b10d-be3542a14951@unipa.it>
Message-ID: <CAFL9eu=3H-ueGF+i+UnaWYft5aQK8NgDaUr06vJo12Chq2xVug@mail.gmail.com>

Thanks!

For some reason I am getting an error when I run your code with my
variables. It works fine with Martin's x and y variables.
So far as I know variable lengths are equal.
> o <-selgmented(lnCpc, ~lnGdpc, Kmax=20, type="bic", msg=TRUE)
Error in model.frame.default(formula = y ~ x, drop.unused.levels = TRUE) :
        variable lengths differ (found for 'x')
> length(lnCpc)
[1] 2726
> length(lnGdpc)
[1] 2726

On Fri, 26 Jul 2024 at 20:16, Vito Muggeo <vito.muggeo at unipa.it> wrote:

> dear all,
> I apologize for my delay in replying you. Here my contribution, maybe
> just for completeness:
>
> Similar to "earth", "segmented" also fits piecewise linear relationships
> with the number of breakpoints being selected by the AIC or BIC
> (recommended).
>
> #code (example and code from Martin Maechler previous email)
>
> library(segmented)
> o<-selgmented(y, ~x, Kmax=20, type="bic", msg=TRUE)
> plot(o, add=TRUE)
> lines(o, col=2) #the approx CI for the breakpoints
>
> confint(o) #the estimated breakpoints (with CI's)
> slope(o) #the estimated slopes (with CI's)
>
>
> However segmented appears to be less efficient than earth (although with
> reasonable running times), it does NOT work with multivariate responses
> neither products between piecewise linear terms.
>
> kind regards,
> Vito
>
>
>
> Il 16/07/2024 11:22, Martin Maechler ha scritto:
> >>>>>> Anupam Tyagi
> >>>>>>      on Tue, 9 Jul 2024 16:16:43 +0530 writes:
> >
> >      > How can I do automatic knot selection while fitting piecewise
> linear
> >      > splines to two variables x and y? Which package to use to do it
> simply? I
> >      > also want to visualize the splines (and the scatter plot) with a
> graph.
> >
> >      > Anupam
> >
> > NB: linear splines, i.e. piecewise linear continuous functions.
> > Given the knots, use  approx() or approxfun() however, the
> > automatic knots selection does not happen in the base R packages.
> >
> > I'm sure there are several R packages doing this.
> > The best such package in my opinion is "earth" which does a
> > re-implementation (and extensive  *generalization*) of the
> > famous  MARS algorithm of Friedman.
> > ==>
> https://en.wikipedia.org/wiki/Multivariate_adaptive_regression_splines
> >
> > Note that their strengths and power is that  they do their work
> > for multivariate x (MARS := Multivariate Adaptive Regression
> > Splines), but indeed do work for the simple 1D case.
> >
> > In the following example, we always get 11 final knots,
> > but I'm sure one can tweak the many tuning paramters of earth()
> > to get more:
> >
> > ## Can we do  knot-selection  for simple (x,y) splines?  === Yes, via
> earth() {using MARS}!
> >
> > x <- (0:800)/8
> >
> > f <- function(x) 7 * sin(pi/8*x) * abs((x-50)/20)^1.25 - (x-40)*(12-x)/64
> > curve(f(x), 0, 100, n = 1000, col=2, lwd=2)
> >
> > set.seed(11)
> > y <- f(x) + 10*rnorm(x)
> >
> > m.sspl <- smooth.spline(x,y) # base line "standard smoother"
> >
> > require(earth)
> > fm1 <- earth(x, y) # default settings
> > summary(fm1, style = "pmax") #-- got  10 knots (x = 44 "used twice")
> below
> > ## Call: earth(x=x, y=y)
> >
> > ## y =
> > ##   175.9612
> > ##   -   10.6744 * pmax(0,      x -  4.625)
> > ##   +  9.928496 * pmax(0,      x - 10.875)
> > ##   -  5.940857 * pmax(0,      x -  20.25)
> > ##   +  3.438948 * pmax(0,      x - 27.125)
> > ##   -  3.828159 * pmax(0,     44 -      x)
> > ##   +  4.207046 * pmax(0,      x -     44)
> > ##   +  2.573822 * pmax(0,      x -   76.5)
> > ##   -  10.99073 * pmax(0,      x - 87.125)
> > ##   +  10.97592 * pmax(0,      x - 90.875)
> > ##   +  9.331949 * pmax(0,      x -     94)
> > ##   -   8.48575 * pmax(0,      x -   96.5)
> >
> > ## Selected 12 of 12 terms, and 1 of 1 predictors
> > ## Termination condition: Reached nk 21
> > ## Importance: x
> > ## Number of terms at each degree of interaction: 1 11 (additive model)
> > ## GCV 108.6592    RSS 82109.44    GRSq 0.861423    RSq 0.86894
> >
> >
> > fm2 <- earth(x, y, fast.k = 0) # (more extensive forward pass)
> > summary(fm2)
> > all.equal(fm1, fm2)# they are identical (apart from 'call'):
> > fm3 <- earth(x, y, fast.k = 0, pmethod = "none", trace = 3) # extensive
> forward pass; *no* pruning
> > ## still no change: fm3 "==" fm1
> > all.equal(predict(fm1, xx), predict(fm3, xx))
> >
> > ## BTW: The chosen knots and coefficients are
> > mat <- with(fm1, cbind(dirs, cuts=c(cuts), coef = c(coefficients)))
> >
> > ## Plots : fine grid for visualization: instead of   xx <- seq(x[1],
> x[length(x)], length.out = 1024)
> > rnx <- extendrange(x) ## to extrapolate a bit
> > xx <- do.call(seq.int, c(rnx, list(length.out = 1200)))
> >
> > cbind(f = f(xx),
> >        sspl = predict(m.sspl, xx)$y,
> >        mars = predict(fm1, xx)) -> fits
> >
> > plot(x,y, xlim=rnx, cex = 1/4, col = adjustcolor(1, 1/2))
> > cols <- c(adjustcolor(2, 1/3),
> >            adjustcolor(4, 2/3),
> >            adjustcolor("orange4", 2/3))
> > lwds <- c(3, 2, 2)
> > matlines(xx, fits, col = cols, lwd = lwds, lty=1)
> > legend("topleft", c("true f(x)", "smooth.spline()", "earth()"),
> >         col=cols, lwd=lwds, bty = "n")
> > title(paste("earth() linear spline vs. smooth.spline();  n =",
> length(x)))
> > mtext(substitute(f(x) == FDEF, list(FDEF = body(f))))
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> =================================================
> Vito M.R. Muggeo, PhD
> Professor of Statistics
> Dip.to Sc Econom, Az e Statistiche
> Universit? di Palermo
> viale delle Scienze, edificio 13
> 90128 Palermo - ITALY
> tel: 091 23895240; fax: 091 485726
> http://www.unipa.it/persone/docenti/m/vito.muggeo
> Associate Editor: Statistical Modelling
> past chair, Statistical Modelling Society
> coordinator, PhD Program in Econ, Businss, Statist
> ==================================================
>


-- 
Anupam.

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Sat Jul 27 16:39:44 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sat, 27 Jul 2024 17:39:44 +0300
Subject: [R] plotting nnet function....
In-Reply-To: <PU4P216MB156812A876A473E7DA695695C8B52@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB156812A876A473E7DA695695C8B52@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <20240727173944.197758ad@trisector>

? Sat, 27 Jul 2024 11:00:34 +0000
akshay kulkarni <akshay_e4 at hotmail.com> ?????:

> My question is : how to plot the final model on the actual data
> points?

Have you been able to obtain the predictions? What happens if you call
predict() on the model object returned to you by train()?

Once you have both the data and the prediction, it should be as simple
as plot(traindata$predictor_column, traindata$regressor_column);
lines(traindata$predictor_column, previously_returned_predictions). (Or
an equivalent with your favourite plotting system for R.)

Try following the vignette from the 'caret' package:
https://cran.r-project.org/package=caret/vignettes/caret.html

If you do encounter an error on your way or get stuck not knowing how
exactly to continue, please ask a more specific question.

-- 
Best regards,
Ivan


From ycd|ng @end|ng |rom coh@org  Sat Jul 27 21:54:48 2024
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Sat, 27 Jul 2024 19:54:48 +0000
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <CABcYAdL7H-VByeMjXHx47gAcntYp0UAqM6h+2_T0+C0_ZJ=ppw@mail.gmail.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>
 <CAGxFJbTGphHj9bNyS2hfCn6tAPvBaQJyq2=VDsqe=mkcbL-_5g@mail.gmail.com>
 <CABcYAdJ2tOowkEMFire6nL0s08P6LQ+gapev1VhY_aDE8TkVVg@mail.gmail.com>
 <CABcYAdL7H-VByeMjXHx47gAcntYp0UAqM6h+2_T0+C0_ZJ=ppw@mail.gmail.com>
Message-ID: <MN2PR02MB691195653B0F7349AE172F6CD4B52@MN2PR02MB6911.namprd02.prod.outlook.com>

Hi Richard,

Nice to know you had similar experience.
Yes, your understanding is right.  all correlations are negative after removing double-zero rows.
It is consistent with a heatmap we generated.
1 is for a cancer patient with a specific mutation.  0 is no mutation for the same mutation type in a patient.
a pair of mutation type (two different mutations) are exclusive for most of patients in heatmap or oncoplots.
 If we include all 1000 patients, 900 of patients with no mutations in both mutation types, then the correlation is not significant at all.
But eyeball the heatmap (oncoplots) for mutation (row) by patient (column), mutations are exclusive for most of patients,
so I want to measure how strong the exclusiveness between two specific mutation types across those patients with at least one mutation type.
Then put the pair of mutations with strong negative mutations on the top rows by order of negative mutation values.

Regarding a final application,  maybe there are some usage for my case.
 If one develops two drugs specific to the two negative correlated mutations, the drug treatment for cancer patients is usually only for those patients carrying the specific mutation,
then it is informative to know how strong the negative correlation when considering different combination of treatment strategies.

Ding





From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
Sent: Saturday, July 27, 2024 4:47 AM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] please help generate a square correlation matrix

Curses, my laptop is hallucinating again. Hope I can get through this. So we're talking about correlations between binary variables. Suppose we have two 0-1-valued variables, x and y. Let A <- sum(x*y) # number of cases where x and y are


Curses, my laptop is hallucinating again.  Hope I can get through this.

So we're talking about correlations between binary variables.

Suppose we have two 0-1-valued variables, x and y.

Let A <- sum(x*y)  # number of cases where x and y are both 1.

Let B <- sum(x)-A  # number of cases where x is 1 and y is 0

Let C <- sum(y)-A # number of cases where y is 1 and x is 0

Let D <- sum(!x * !y) # number of cases where x and y are both 0.

(also D = length(x)-A-B-C)



All the information is summarised in the 2-by-2 contingency table.

Some years ago, Nathan Rountree and I supervised Yung-Sing Koh's

data-mining PhD.

She surveyed the data mining literature and found some 37 different

"interestingness measures" for two-variable associations  -- if I

remember correctly; there were a lot of them.  They fell into a much

smaller number of qualitatively similar groups.

At any rate, the Pearson correlation between x and y is

(A*D - B*C)/sqrt((A+B)*(C+D)*(A+C)*(B+D))



So what happens when we delete the rows where x = 0 and y = 0?

Right, it forces D to 0, leaving A B C unchanged.

And looking at the numerator,

  If you delete rows with x = 0 y = 0 you MUST get a negative correlation.



Quite a modest "true" correlation (based on all the data) like -0.2

can masquerade as quite a strong "zero-suppressed" correlation like

-0.6.  Even +0.2 can turn into -0.4.   (These figures are from a

particular simulation run and may not apply in your case.)



Now one of the reasons why Yun-Sing Koh, Nathan Rountree, and I were

interested in interestingness measures is perhaps coincidentally

related to the file drawer/underreporting problem: it's quite common

for rows where x = 0 and y = 0 never to have been reported to you, so

we were hoping there were measures immune to that.  I have argued for

years that "till record analysis" for supermarkets &c is badly flawed

by two facts: (a) it is hard to measure how much of a product people

WOULD have bought if only you had offered it for sale (although you

can make educated guesses) and (b) till records provide no evidence on

what the people who walked out without buying anything wanted (was the

price too high?  could they not find it?).  Problem (a) leads to a

commercial variant of the Signor-Lipps effect: "when x and/or y were

available for purchase" is not the same as "the period for which data

were recorded", thus inflating D, perhaps massively.  Methods

developed for handling the Signor-Lipps effect in paleontology can be

used to estimate when x and y were available helping you to recover a

more realistic N=A+B+C+D.  I really should have published that.



All of which is a long-winded way of saying that

- Pearson correlations on binary columns can be computed very efficiently

- the rows with x=0 and y=0 may be very informative, even essential for analysis

- delete them at your peril.

- really, delete them at your peril.



On Sat, 27 Jul 2024 at 23:07, Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>> wrote:

>

> Let's go back to the original posting.

>

> > >

> > >> in each column, less than 10% values are 1, most of them are 0;

> > >

> > >

> > >

> > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.

> > >

>

> So we're talking about correlations between binary variables.

> Suppose we have two 0-1-valued variables, x and y.

> Let A <- sum(x*y)  # number of cases where x and y are both 1.

> Let B <- sum(x)-a  # number of cases where x is 1 and y is 0

> Let C <- sum(y)-a # number of cases where y is 1 and x is 0

> Let D <- sum(!x * !y) # number of cases where x and y are both 0.

>

> N

>

> On Fri, 26 Jul 2024 at 12:07, Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:

> >

> > If I have understood the request, I'm not sure that omitting all 0

> > pairs for each pair of columns makes much sense, but be that as it

> > may, here's another way to do it by using the 'FUN' argument of combn

> > to encapsulate any calculations that you do. I just use cor() as the

> > calculation -- you can use anything you like that takes two vectors of

> > 0's and 1's and produces fixed length numeric results (or fromm which

> > you can extract such).

> >

> > I encapsulated it all in a little function. Note that I first

> > converted the data frame to a matrix. Because of their generality,

> > data frames carry a lot of extra baggage that can slow purely numeric

> > manipulations down.

> >

> > Anyway, here's the function, 'somecors' (I'm a bad name picker :(  ! )

> >

> >    somecors <- function(dat, func = cor){

> >       dat <- as.matrix(dat)

> >       indx <- seq_len(ncol(dat))

> >          combn(indx, 2, FUN = \(z) {

> >             i <- z[1]; j <- z[2]

> >             k <- dat[, i ] | dat[, j ]

> >             c(z,func(dat[k,i ], dat[k,j ]))

> >          })

> >    }

> >

> > Results come out as a matrix with combn(ncol(dat),2) columns, the

> > first 2 rows giving the pair of column numbers for each column,and

> > then 1 or more rows (possibly extracted) from whatever func you use.

> > Here's the results for your data formatted to 2 decimal places:

> >

> > > round(somecors(dat),2)

> >      [,1]  [,2]  [,3]  [,4] [,5]  [,6]

> > [1,]  1.0  1.00  1.00  2.00    2  3.00

> > [2,]  2.0  3.00  4.00  3.00    4  4.00

> > [3,] -0.5 -0.41 -0.35 -0.41   NA -0.47

> > Warning message:

> > In func(dat[k, i], dat[k, j]) : the standard deviation is zero

> >

> > The NA and warning comes in the 2,4 pair of columns because after

> > removing all zero rows in the pair, dat[,4] is all 1's, giving a zero

> > in the denominator of the cor() calculation -- again, assuming I have

> > correctly understood your request. If so, this might be something you

> > need to worry about.

> >

> > Again, feel free to ignore if  I have misinterpreterd or this does not suit.

> >

> > Cheers,

> > Bert

> >

> >

> > On Thu, Jul 25, 2024 at 2:01?PM Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>> wrote:

> > >

> > > ?s 20:47 de 25/07/2024, Yuan Chun Ding escreveu:

> > > > Hi Rui,

> > > >

> > > > You are always very helpful!! Thank you,

> > > >

> > > > I just modified your R codes to remove a row with zero values in both column pair as below for my real data.

> > > >

> > > > Ding

> > > >

> > > > dat<-gene22mut.coded

> > > > r <- P <- matrix(NA, nrow = 22L, ncol = 22L,

> > > >                   dimnames = list(names(dat), names(dat)))

> > > >

> > > > for(i in 1:22) {

> > > >    #i=1

> > > >    x <- dat[[i]]

> > > >    for(j in (1:22)) {

> > > >      #j=2

> > > >      if(i == j) {

> > > >        # there's nothing to test, assign correlation 1

> > > >        r[i, j] <- 1

> > > >      } else {

> > > >        tmp <-cbind(x,dat[[j]])

> > > >        row0 <-rowSums(tmp)

> > > >        tem2 <-tmp[row0!=0,]

> > > >        tmp3 <- cor.test(tem2[,1],tem2[,2])

> > > >        r[i, j] <- tmp3$estimate

> > > >        P[i, j] <- tmp3$p.value

> > > >      }

> > > >    }

> > > > }

> > > > r<-as.data.frame(r)

> > > > P<-as.data.frame(P)

> > > >

> > > > From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Yuan Chun Ding via R-help

> > > > Sent: Thursday, July 25, 2024 11:26 AM

> > > > To: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>; r-help at r-project.org<mailto:r-help at r-project.org>

> > > > Subject: Re: [R] please help generate a square correlation matrix

> > > >

> > > > HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;

> > > >

> > > >

> > > > HI Rui,

> > > >

> > > >

> > > >

> > > > Thank you for the  help!

> > > >

> > > >

> > > >

> > > > You did not remove a row if zero values exist in both column pair, right?

> > > >

> > > >

> > > >

> > > > Ding

> > > >

> > > >

> > > >

> > > > From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt%3cmailto:ruipbarradas at sapo.pt>>>

> > > >

> > > > Sent: Thursday, July 25, 2024 11:15 AM

> > > >

> > > > To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org<mailto:ycding at coh.org%3cmailto:ycding at coh.org>>>; r-help at r-project.org<mailto:r-help at r-project.org<mailto:r-help at r-project.org%3cmailto:r-help at r-project.org>>

> > > >

> > > > Subject: Re: [R] please help generate a square correlation matrix

> > > >

> > > >

> > > >

> > > > ?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > ?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:

> > > >

> > > >

> > > >

> > > >> Hi R users,

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> I generated a square correlation matrix for the dat dataframe below;

> > > >

> > > >

> > > >

> > > >> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),

> > > >

> > > >

> > > >

> > > >>                   g2=c(0,1,0,1,0,1,1,0,0),

> > > >

> > > >

> > > >

> > > >>                   g3=c(1,1,0,0,0,1,0,0,0),

> > > >

> > > >

> > > >

> > > >>                   g4=c(0,1,0,1,1,1,1,1,0))

> > > >

> > > >

> > > >

> > > >> library("Hmisc")

> > > >

> > > >

> > > >

> > > >> dat.rcorr = rcorr(as.matrix(dat))

> > > >

> > > >

> > > >

> > > >> dat.r <-round(dat.rcorr$r,2)

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> however, I want to modify this correlation calculation;

> > > >

> > > >

> > > >

> > > >> my dat has more than 1000 rows and 22 columns;

> > > >

> > > >

> > > >

> > > >> in each column, less than 10% values are 1, most of them are 0;

> > > >

> > > >

> > > >

> > > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.

> > > >

> > > >

> > > >

> > > >> I just want to check whether those values of 1 are correlated between two columns.

> > > >

> > > >

> > > >

> > > >> Please look at my code in the following;

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> cor.4gene <-matrix(0,nrow=4*4, ncol=4)

> > > >

> > > >

> > > >

> > > >> for (i in 1:4){

> > > >

> > > >

> > > >

> > > >>     #i=1

> > > >

> > > >

> > > >

> > > >>     for (j in 1:4) {

> > > >

> > > >

> > > >

> > > >>       #j=1

> > > >

> > > >

> > > >

> > > >>       d <-dat[,c(i,j)]%>%

> > > >

> > > >

> > > >

> > > >>         filter(eval(as.symbol(colnames(dat)[i]))!=0 |

> > > >

> > > >

> > > >

> > > >>                  eval(as.symbol(colnames(dat)[j]))!=0)

> > > >

> > > >

> > > >

> > > >>       c <-cor.test(d[,1],d[,2])

> > > >

> > > >

> > > >

> > > >>       cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],

> > > >

> > > >

> > > >

> > > >>                           c$estimate,c$p.value)

> > > >

> > > >

> > > >

> > > >>     }

> > > >

> > > >

> > > >

> > > >> }

> > > >

> > > >

> > > >

> > > >> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)

> > > >

> > > >

> > > >

> > > >> colnames(cor.4gene)<-c("gene1","gene2","cor","P")

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> Can you tell me what mistakes I made?

> > > >

> > > >

> > > >

> > > >> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> cor.4gene$cor[is.na(cor.4gene$cor)]<-1

> > > >

> > > >

> > > >

> > > >> cor.4gene$cor[is.na(cor.4gene$P)]<-0

> > > >

> > > >

> > > >

> > > >> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> Then this line of code above did not generate a square matrix as what the HMisc library did.

> > > >

> > > >

> > > >

> > > >> How to fix my code?

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> Thank you,

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> Ding

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> ----------------------------------------------------------------------

> > > >

> > > >

> > > >

> > > >> ------------------------------------------------------------

> > > >

> > > >

> > > >

> > > >> -SECURITY/CONFIDENTIALITY WARNING-

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec

> > > >

> > > >

> > > >

> > > >>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)

> > > >

> > > >

> > > >

> > > >> ------------------------------------------------------------

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >>              [[alternative HTML version deleted]]

> > > >

> > > >

> > > >

> > > >>

> > > >

> > > >

> > > >

> > > >> ______________________________________________

> > > >

> > > >

> > > >

> > > >> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org%3cmailto:R-help at r-project.org%3cmailto:R-help at r-project.org>>> mailing list -- To UNSUBSCRIBE and more, see

> > > >

> > > >

> > > >

> > > >> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e>> > >

> > > >   <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e>> > >

> > > >> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASE<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3ePLEASE>do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e>> > >

> > > >   <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e>> > >

> > > >> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>and<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3eand>provide commented, minimal, self-contained, reproducible code.

> > > >

> > > >

> > > >

> > > > Hello,

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > You are complicating the code, there's no need for as.symbol/eval, the

> > > >

> > > >

> > > >

> > > > column numbers do exactly the same.

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > # create the two results matrices beforehand

> > > >

> > > >

> > > >

> > > > r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),

> > > >

> > > >

> > > >

> > > > names(dat)))

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > for(i in 1:4) {

> > > >

> > > >

> > > >

> > > >     x <- dat[[i]]

> > > >

> > > >

> > > >

> > > >     for(j in (1:4)) {

> > > >

> > > >

> > > >

> > > >       if(i == j) {

> > > >

> > > >

> > > >

> > > >         # there's nothing to test, assign correlation 1

> > > >

> > > >

> > > >

> > > >         r[i, j] <- 1

> > > >

> > > >

> > > >

> > > >       } else {

> > > >

> > > >

> > > >

> > > >         tmp <- cor.test(x, dat[[j]])

> > > >

> > > >

> > > >

> > > >         r[i, j] <- tmp$estimate

> > > >

> > > >

> > > >

> > > >         P[i, j] <- tmp$p.value

> > > >

> > > >

> > > >

> > > >       }

> > > >

> > > >

> > > >

> > > >     }

> > > >

> > > >

> > > >

> > > > }

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > # these two results are equal up to floating-point precision

> > > >

> > > >

> > > >

> > > > dat.rcorr$r

> > > >

> > > >

> > > >

> > > > #>           g1        g2        g3        g4

> > > >

> > > >

> > > >

> > > > #> g1 1.0000000 0.1000000 0.3162278 0.1581139

> > > >

> > > >

> > > >

> > > > #> g2 0.1000000 1.0000000 0.3162278 0.6324555

> > > >

> > > >

> > > >

> > > > #> g3 0.3162278 0.3162278 1.0000000 0.0000000

> > > >

> > > >

> > > >

> > > > #> g4 0.1581139 0.6324555 0.0000000 1.0000000

> > > >

> > > >

> > > >

> > > > r

> > > >

> > > >

> > > >

> > > > #>           g1        g2           g3           g4

> > > >

> > > >

> > > >

> > > > #> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01

> > > >

> > > >

> > > >

> > > > #> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01

> > > >

> > > >

> > > >

> > > > #> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20

> > > >

> > > >

> > > >

> > > > #> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > # these two results are equal up to floating-point precision

> > > >

> > > >

> > > >

> > > > dat.rcorr$P

> > > >

> > > >

> > > >

> > > > #>           g1         g2        g3         g4

> > > >

> > > >

> > > >

> > > > #> g1        NA 0.79797170 0.4070838 0.68452834

> > > >

> > > >

> > > >

> > > > #> g2 0.7979717         NA 0.4070838 0.06758329

> > > >

> > > >

> > > >

> > > > #> g3 0.4070838 0.40708382        NA 1.00000000

> > > >

> > > >

> > > >

> > > > #> g4 0.6845283 0.06758329 1.0000000         NA

> > > >

> > > >

> > > >

> > > > P

> > > >

> > > >

> > > >

> > > > #>           g1         g2        g3         g4

> > > >

> > > >

> > > >

> > > > #> g1        NA 0.79797170 0.4070838 0.68452834

> > > >

> > > >

> > > >

> > > > #> g2 0.7979717         NA 0.4070838 0.06758329

> > > >

> > > >

> > > >

> > > > #> g3 0.4070838 0.40708382        NA 1.00000000

> > > >

> > > >

> > > >

> > > > #> g4 0.6845283 0.06758329 1.0000000         NA

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > You can put these two results in a list, like Hmisc::rcorr does.

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > lst_rcorr <- list(r = r, P = P)

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > Hope this helps,

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > Rui Barradas

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > >

> > > > --

> > > >

> > > >

> > > >

> > > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.

> > > >

> > > >

> > > >

> > > > https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e>

><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e>> > >

> > > >   <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e>

><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e>> > >

> > > >                 [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTML<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3eHTML>version deleted]]

> > > >

> > > >

> > > >

> > > > ______________________________________________

> > > >

> > > > R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see

> > > >

> > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3e%3e>> > >

> > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3e%3e>> > >

> > > > and provide commented, minimal, self-contained, reproducible code.

> > > >

> > > Hello,

> > >

> > > Here are two other ways.

> > >

> > > The first is equivalent to your long format attempt.

> > >

> > >

> > > library(tidyverse)

> > >

> > > dat %>%

> > >    names() %>%

> > >    expand.grid(., .) %>%

> > >    apply(1L, \(x) {

> > >      tmp <- dat[rowSums(dat[x]) > 0, ]

> > >      tmp2 <- cor.test(tmp[[ x[1L] ]], tmp[[ x[2L] ]])

> > >      c(tmp2$estimate, P = tmp2$p.value)

> > >    }) %>%

> > >    t() %>%

> > >    as.data.frame() %>%

> > >    cbind(tmp_df, .) %>%

> > >    na.omit()

> > >

> > >

> > > The second is, in my opinion the one that makes more sense. If you see

> > > the results, cor is symmetric (as it should) so the calculations are

> > > repeated. If you only run the cor.tests on the combinations of

> > > names(dat) by groups of 2, it will save a lot of work. But the output is

> > > a much smaller a data.frame.

> > >

> > >

> > > cbind(

> > >    combn(names(dat), 2L) %>%

> > >      t() %>%

> > >      as.data.frame(),

> > >    combn(dat, 2L, FUN = \(d) {

> > >      d2 <- d[rowSums(d) > 0, ]

> > >      tmp2 <- cor.test(d2[[1L]], d2[[2L]])

> > >      c(tmp2$estimate, P = tmp2$p.value)

> > >    }) %>% t()

> > > ) %>% na.omit()

> > >

> > >

> > >

> > > Hope this helps,

> > >

> > > Rui Barradas

> > >

> > >

> > > ______________________________________________

> > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

> > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$>

> > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$>

> > > and provide commented, minimal, self-contained, reproducible code.

> >

> > ______________________________________________

> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

> > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$>

> > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$>

> > and provide commented, minimal, self-contained, reproducible code.



______________________________________________

R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$>

PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$>

and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 28 01:49:55 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 27 Jul 2024 16:49:55 -0700
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <MN2PR02MB691195653B0F7349AE172F6CD4B52@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>
 <CAGxFJbTGphHj9bNyS2hfCn6tAPvBaQJyq2=VDsqe=mkcbL-_5g@mail.gmail.com>
 <CABcYAdJ2tOowkEMFire6nL0s08P6LQ+gapev1VhY_aDE8TkVVg@mail.gmail.com>
 <CABcYAdL7H-VByeMjXHx47gAcntYp0UAqM6h+2_T0+C0_ZJ=ppw@mail.gmail.com>
 <MN2PR02MB691195653B0F7349AE172F6CD4B52@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbS_MwQgxueuX6JXeMRAa8+zrv=mnEc9r8H9kC26QpEkbg@mail.gmail.com>

Your expanded explanation helps clarify your intent. Herewith some
comments. Of course, feel free to ignore and not respond. And, as
always, my apologies if I have failed to comprehend your intent.

1. I would avoid any notion of "statistical significance" like the
plague. This is a purely exploratory exercise.

2. My understanding is that you want to know the proportion of rows in
a pair of columns/vectors in which only 1 values of the pair is 1 out
of the number of pairs where 1 or 2 values is 1.  In R syntax, this is
simply:

sum(xor(x, y)) / sum(x | y)  ,
where x and y are two columns of 1's and 0's

Better yet might be to report both this *and* sum(x|y) to help you
judge "meaningfulness".
Here is a simple function that does this

## first, define a function that does above calculation:
assoc <- \(z){
   x <- z[,1]; y <- z[,2]
   n <- sum(x|y)
   c(prop = sum(xor(x, y))/n, N = n)
}

## Now a function that uses it for the various combinations:

somecor <- function(dat, func = assoc){
   dat <- as.matrix(dat)
   indx <- seq_len(ncol(dat))
   rbind(w <- combn(indx,2),
         combn(indx, 2, FUN = \(m)func(dat[,m]) )) |>
     t()  |> round(digits =2) |>
  'dimnames<-'(list(rep.int('',ncol(w)), c("","", "prop","N")))
}

# Now apply it to your example data:

somecor(dat)
## which gives
     prop N
 1 2 0.67 6
 1 3 0.60 5
 1 4 0.57 7
 2 3 0.60 5
 2 4 0.33 6
 3 4 0.71 7

This seems more interpretable and directly useful to me. Bigger values
of prop for bigger N are the more interesting, assuming I have
interpreted you correctly.

Cheers,
Bert


On Sat, Jul 27, 2024 at 12:54?PM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi Richard,
>
>
>
> Nice to know you had similar experience.
>
> Yes, your understanding is right.  all correlations are negative after removing double-zero rows.
>
> It is consistent with a heatmap we generated.
>
> 1 is for a cancer patient with a specific mutation.  0 is no mutation for the same mutation type in a patient.
>
> a pair of mutation type (two different mutations) are exclusive for most of patients in heatmap or oncoplots.
>
>  If we include all 1000 patients, 900 of patients with no mutations in both mutation types, then the correlation is not significant at all.
>
> But eyeball the heatmap (oncoplots) for mutation (row) by patient (column), mutations are exclusive for most of patients,
>
> so I want to measure how strong the exclusiveness between two specific mutation types across those patients with at least one mutation type.
>
> Then put the pair of mutations with strong negative mutations on the top rows by order of negative mutation values.
>
>
>
> Regarding a final application,  maybe there are some usage for my case.
>
>  If one develops two drugs specific to the two negative correlated mutations, the drug treatment for cancer patients is usually only for those patients carrying the specific mutation,
>
> then it is informative to know how strong the negative correlation when considering different combination of treatment strategies.
>
>
>
> Ding
>
>
>
>
>
>
>
>
>
>
>
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
> Sent: Saturday, July 27, 2024 4:47 AM
> To: Bert Gunter <bgunter.4567 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] please help generate a square correlation matrix
>
>
>
> Curses, my laptop is hallucinating again. Hope I can get through this. So we're talking about correlations between binary variables. Suppose we have two 0-1-valued variables, x and y. Let A <- sum(x*y) # number of cases where x and y are
>
> Curses, my laptop is hallucinating again.  Hope I can get through this.
>
> So we're talking about correlations between binary variables.
>
> Suppose we have two 0-1-valued variables, x and y.
>
> Let A <- sum(x*y)  # number of cases where x and y are both 1.
>
> Let B <- sum(x)-A  # number of cases where x is 1 and y is 0
>
> Let C <- sum(y)-A # number of cases where y is 1 and x is 0
>
> Let D <- sum(!x * !y) # number of cases where x and y are both 0.
>
> (also D = length(x)-A-B-C)
>
>
>
> All the information is summarised in the 2-by-2 contingency table.
>
> Some years ago, Nathan Rountree and I supervised Yung-Sing Koh's
>
> data-mining PhD.
>
> She surveyed the data mining literature and found some 37 different
>
> "interestingness measures" for two-variable associations  -- if I
>
> remember correctly; there were a lot of them.  They fell into a much
>
> smaller number of qualitatively similar groups.
>
> At any rate, the Pearson correlation between x and y is
>
> (A*D - B*C)/sqrt((A+B)*(C+D)*(A+C)*(B+D))
>
>
>
> So what happens when we delete the rows where x = 0 and y = 0?
>
> Right, it forces D to 0, leaving A B C unchanged.
>
> And looking at the numerator,
>
>   If you delete rows with x = 0 y = 0 you MUST get a negative correlation.
>
>
>
> Quite a modest "true" correlation (based on all the data) like -0.2
>
> can masquerade as quite a strong "zero-suppressed" correlation like
>
> -0.6.  Even +0.2 can turn into -0.4.   (These figures are from a
>
> particular simulation run and may not apply in your case.)
>
>
>
> Now one of the reasons why Yun-Sing Koh, Nathan Rountree, and I were
>
> interested in interestingness measures is perhaps coincidentally
>
> related to the file drawer/underreporting problem: it's quite common
>
> for rows where x = 0 and y = 0 never to have been reported to you, so
>
> we were hoping there were measures immune to that.  I have argued for
>
> years that "till record analysis" for supermarkets &c is badly flawed
>
> by two facts: (a) it is hard to measure how much of a product people
>
> WOULD have bought if only you had offered it for sale (although you
>
> can make educated guesses) and (b) till records provide no evidence on
>
> what the people who walked out without buying anything wanted (was the
>
> price too high?  could they not find it?).  Problem (a) leads to a
>
> commercial variant of the Signor-Lipps effect: "when x and/or y were
>
> available for purchase" is not the same as "the period for which data
>
> were recorded", thus inflating D, perhaps massively.  Methods
>
> developed for handling the Signor-Lipps effect in paleontology can be
>
> used to estimate when x and y were available helping you to recover a
>
> more realistic N=A+B+C+D.  I really should have published that.
>
>
>
> All of which is a long-winded way of saying that
>
> - Pearson correlations on binary columns can be computed very efficiently
>
> - the rows with x=0 and y=0 may be very informative, even essential for analysis
>
> - delete them at your peril.
>
> - really, delete them at your peril.
>
>
>
> On Sat, 27 Jul 2024 at 23:07, Richard O'Keefe <raoknz at gmail.com> wrote:
>
> >
>
> > Let's go back to the original posting.
>
> >
>
> > > >
>
> > > >> in each column, less than 10% values are 1, most of them are 0;
>
> > > >
>
> > > >
>
> > > >
>
> > > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
>
> > > >
>
> >
>
> > So we're talking about correlations between binary variables.
>
> > Suppose we have two 0-1-valued variables, x and y.
>
> > Let A <- sum(x*y)  # number of cases where x and y are both 1.
>
> > Let B <- sum(x)-a  # number of cases where x is 1 and y is 0
>
> > Let C <- sum(y)-a # number of cases where y is 1 and x is 0
>
> > Let D <- sum(!x * !y) # number of cases where x and y are both 0.
>
> >
>
> > N
>
> >
>
> > On Fri, 26 Jul 2024 at 12:07, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> > >
>
> > > If I have understood the request, I'm not sure that omitting all 0
>
> > > pairs for each pair of columns makes much sense, but be that as it
>
> > > may, here's another way to do it by using the 'FUN' argument of combn
>
> > > to encapsulate any calculations that you do. I just use cor() as the
>
> > > calculation -- you can use anything you like that takes two vectors of
>
> > > 0's and 1's and produces fixed length numeric results (or fromm which
>
> > > you can extract such).
>
> > >
>
> > > I encapsulated it all in a little function. Note that I first
>
> > > converted the data frame to a matrix. Because of their generality,
>
> > > data frames carry a lot of extra baggage that can slow purely numeric
>
> > > manipulations down.
>
> > >
>
> > > Anyway, here's the function, 'somecors' (I'm a bad name picker :(  ! )
>
> > >
>
> > >    somecors <- function(dat, func = cor){
>
> > >       dat <- as.matrix(dat)
>
> > >       indx <- seq_len(ncol(dat))
>
> > >          combn(indx, 2, FUN = \(z) {
>
> > >             i <- z[1]; j <- z[2]
>
> > >             k <- dat[, i ] | dat[, j ]
>
> > >             c(z,func(dat[k,i ], dat[k,j ]))
>
> > >          })
>
> > >    }
>
> > >
>
> > > Results come out as a matrix with combn(ncol(dat),2) columns, the
>
> > > first 2 rows giving the pair of column numbers for each column,and
>
> > > then 1 or more rows (possibly extracted) from whatever func you use.
>
> > > Here's the results for your data formatted to 2 decimal places:
>
> > >
>
> > > > round(somecors(dat),2)
>
> > >      [,1]  [,2]  [,3]  [,4] [,5]  [,6]
>
> > > [1,]  1.0  1.00  1.00  2.00    2  3.00
>
> > > [2,]  2.0  3.00  4.00  3.00    4  4.00
>
> > > [3,] -0.5 -0.41 -0.35 -0.41   NA -0.47
>
> > > Warning message:
>
> > > In func(dat[k, i], dat[k, j]) : the standard deviation is zero
>
> > >
>
> > > The NA and warning comes in the 2,4 pair of columns because after
>
> > > removing all zero rows in the pair, dat[,4] is all 1's, giving a zero
>
> > > in the denominator of the cor() calculation -- again, assuming I have
>
> > > correctly understood your request. If so, this might be something you
>
> > > need to worry about.
>
> > >
>
> > > Again, feel free to ignore if  I have misinterpreterd or this does not suit.
>
> > >
>
> > > Cheers,
>
> > > Bert
>
> > >
>
> > >
>
> > > On Thu, Jul 25, 2024 at 2:01?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> > > >
>
> > > > ?s 20:47 de 25/07/2024, Yuan Chun Ding escreveu:
>
> > > > > Hi Rui,
>
> > > > >
>
> > > > > You are always very helpful!! Thank you,
>
> > > > >
>
> > > > > I just modified your R codes to remove a row with zero values in both column pair as below for my real data.
>
> > > > >
>
> > > > > Ding
>
> > > > >
>
> > > > > dat<-gene22mut.coded
>
> > > > > r <- P <- matrix(NA, nrow = 22L, ncol = 22L,
>
> > > > >                   dimnames = list(names(dat), names(dat)))
>
> > > > >
>
> > > > > for(i in 1:22) {
>
> > > > >    #i=1
>
> > > > >    x <- dat[[i]]
>
> > > > >    for(j in (1:22)) {
>
> > > > >      #j=2
>
> > > > >      if(i == j) {
>
> > > > >        # there's nothing to test, assign correlation 1
>
> > > > >        r[i, j] <- 1
>
> > > > >      } else {
>
> > > > >        tmp <-cbind(x,dat[[j]])
>
> > > > >        row0 <-rowSums(tmp)
>
> > > > >        tem2 <-tmp[row0!=0,]
>
> > > > >        tmp3 <- cor.test(tem2[,1],tem2[,2])
>
> > > > >        r[i, j] <- tmp3$estimate
>
> > > > >        P[i, j] <- tmp3$p.value
>
> > > > >      }
>
> > > > >    }
>
> > > > > }
>
> > > > > r<-as.data.frame(r)
>
> > > > > P<-as.data.frame(P)
>
> > > > >
>
> > > > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via R-help
>
> > > > > Sent: Thursday, July 25, 2024 11:26 AM
>
> > > > > To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
>
> > > > > Subject: Re: [R] please help generate a square correlation matrix
>
> > > > >
>
> > > > > HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;
>
> > > > >
>
> > > > >
>
> > > > > HI Rui,
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > Thank you for the  help!
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > You did not remove a row if zero values exist in both column pair, right?
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > Ding
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>
>
> > > > >
>
> > > > > Sent: Thursday, July 25, 2024 11:15 AM
>
> > > > >
>
> > > > > To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>; r-help at r-project.org<mailto:r-help at r-project.org>
>
> > > > >
>
> > > > > Subject: Re: [R] please help generate a square correlation matrix
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > ?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > ?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> Hi R users,
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> I generated a square correlation matrix for the dat dataframe below;
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>                   g2=c(0,1,0,1,0,1,1,0,0),
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>                   g3=c(1,1,0,0,0,1,0,0,0),
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>                   g4=c(0,1,0,1,1,1,1,1,0))
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> library("Hmisc")
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> dat.rcorr = rcorr(as.matrix(dat))
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> dat.r <-round(dat.rcorr$r,2)
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> however, I want to modify this correlation calculation;
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> my dat has more than 1000 rows and 22 columns;
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> in each column, less than 10% values are 1, most of them are 0;
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> I just want to check whether those values of 1 are correlated between two columns.
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> Please look at my code in the following;
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> cor.4gene <-matrix(0,nrow=4*4, ncol=4)
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> for (i in 1:4){
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>     #i=1
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>     for (j in 1:4) {
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>       #j=1
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>       d <-dat[,c(i,j)]%>%
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>         filter(eval(as.symbol(colnames(dat)[i]))!=0 |
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>                  eval(as.symbol(colnames(dat)[j]))!=0)
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>       c <-cor.test(d[,1],d[,2])
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>       cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>                           c$estimate,c$p.value)
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>     }
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> }
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> colnames(cor.4gene)<-c("gene1","gene2","cor","P")
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> Can you tell me what mistakes I made?
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> cor.4gene$cor[is.na(cor.4gene$cor)]<-1
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> cor.4gene$cor[is.na(cor.4gene$P)]<-0
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> Then this line of code above did not generate a square matrix as what the HMisc library did.
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> How to fix my code?
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> Thank you,
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> Ding
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> ----------------------------------------------------------------------
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> ------------------------------------------------------------
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> -SECURITY/CONFIDENTIALITY WARNING-
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> ------------------------------------------------------------
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>              [[alternative HTML version deleted]]
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >>
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> ______________________________________________
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
>
> >> > >
>
> > > > >   <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
>
> >> > >
>
> > > > >> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASEdo read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
>
> >> > >
>
> > > > >   <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
>
> >> > >
>
> > > > >> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>andprovide commented, minimal, self-contained, reproducible code.
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > Hello,
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > You are complicating the code, there's no need for as.symbol/eval, the
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > column numbers do exactly the same.
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > # create the two results matrices beforehand
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > names(dat)))
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > for(i in 1:4) {
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >     x <- dat[[i]]
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >     for(j in (1:4)) {
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >       if(i == j) {
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >         # there's nothing to test, assign correlation 1
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >         r[i, j] <- 1
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >       } else {
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >         tmp <- cor.test(x, dat[[j]])
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >         r[i, j] <- tmp$estimate
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >         P[i, j] <- tmp$p.value
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >       }
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >     }
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > }
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > # these two results are equal up to floating-point precision
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > dat.rcorr$r
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #>           g1        g2        g3        g4
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g1 1.0000000 0.1000000 0.3162278 0.1581139
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g2 0.1000000 1.0000000 0.3162278 0.6324555
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g3 0.3162278 0.3162278 1.0000000 0.0000000
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g4 0.1581139 0.6324555 0.0000000 1.0000000
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > r
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #>           g1        g2           g3           g4
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > # these two results are equal up to floating-point precision
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > dat.rcorr$P
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #>           g1         g2        g3         g4
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g1        NA 0.79797170 0.4070838 0.68452834
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g2 0.7979717         NA 0.4070838 0.06758329
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g3 0.4070838 0.40708382        NA 1.00000000
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g4 0.6845283 0.06758329 1.0000000         NA
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > P
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #>           g1         g2        g3         g4
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g1        NA 0.79797170 0.4070838 0.68452834
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g2 0.7979717         NA 0.4070838 0.06758329
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g3 0.4070838 0.40708382        NA 1.00000000
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > #> g4 0.6845283 0.06758329 1.0000000         NA
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > You can put these two results in a list, like Hmisc::rcorr does.
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > lst_rcorr <- list(r = r, P = P)
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > Hope this helps,
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > Rui Barradas
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > --
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
>
> >> > >
>
> > > > >   <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
>
> >> > >
>
> > > > >                 [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTMLversion deleted]]
>
> > > > >
>
> > > > >
>
> > > > >
>
> > > > > ______________________________________________
>
> > > > >
>
> > > > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>
> > > > >
>
> > > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$>
>
> >> > >
>
> > > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$>
>
> >> > >
>
> > > > > and provide commented, minimal, self-contained, reproducible code.
>
> > > > >
>
> > > > Hello,
>
> > > >
>
> > > > Here are two other ways.
>
> > > >
>
> > > > The first is equivalent to your long format attempt.
>
> > > >
>
> > > >
>
> > > > library(tidyverse)
>
> > > >
>
> > > > dat %>%
>
> > > >    names() %>%
>
> > > >    expand.grid(., .) %>%
>
> > > >    apply(1L, \(x) {
>
> > > >      tmp <- dat[rowSums(dat[x]) > 0, ]
>
> > > >      tmp2 <- cor.test(tmp[[ x[1L] ]], tmp[[ x[2L] ]])
>
> > > >      c(tmp2$estimate, P = tmp2$p.value)
>
> > > >    }) %>%
>
> > > >    t() %>%
>
> > > >    as.data.frame() %>%
>
> > > >    cbind(tmp_df, .) %>%
>
> > > >    na.omit()
>
> > > >
>
> > > >
>
> > > > The second is, in my opinion the one that makes more sense. If you see
>
> > > > the results, cor is symmetric (as it should) so the calculations are
>
> > > > repeated. If you only run the cor.tests on the combinations of
>
> > > > names(dat) by groups of 2, it will save a lot of work. But the output is
>
> > > > a much smaller a data.frame.
>
> > > >
>
> > > >
>
> > > > cbind(
>
> > > >    combn(names(dat), 2L) %>%
>
> > > >      t() %>%
>
> > > >      as.data.frame(),
>
> > > >    combn(dat, 2L, FUN = \(d) {
>
> > > >      d2 <- d[rowSums(d) > 0, ]
>
> > > >      tmp2 <- cor.test(d2[[1L]], d2[[2L]])
>
> > > >      c(tmp2$estimate, P = tmp2$p.value)
>
> > > >    }) %>% t()
>
> > > > ) %>% na.omit()
>
> > > >
>
> > > >
>
> > > >
>
> > > > Hope this helps,
>
> > > >
>
> > > > Rui Barradas
>
> > > >
>
> > > >
>
> > > > ______________________________________________
>
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$
>
> > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$
>
> > > > and provide commented, minimal, self-contained, reproducible code.
>
> > >
>
> > > ______________________________________________
>
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$
>
> > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$
>
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$
>
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$
>
> and provide commented, minimal, self-contained, reproducible code.


From ycd|ng @end|ng |rom coh@org  Sun Jul 28 02:40:32 2024
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Sun, 28 Jul 2024 00:40:32 +0000
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <CAGxFJbS_MwQgxueuX6JXeMRAa8+zrv=mnEc9r8H9kC26QpEkbg@mail.gmail.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>
 <CAGxFJbTGphHj9bNyS2hfCn6tAPvBaQJyq2=VDsqe=mkcbL-_5g@mail.gmail.com>
 <CABcYAdJ2tOowkEMFire6nL0s08P6LQ+gapev1VhY_aDE8TkVVg@mail.gmail.com>
 <CABcYAdL7H-VByeMjXHx47gAcntYp0UAqM6h+2_T0+C0_ZJ=ppw@mail.gmail.com>
 <MN2PR02MB691195653B0F7349AE172F6CD4B52@MN2PR02MB6911.namprd02.prod.outlook.com>
 <CAGxFJbS_MwQgxueuX6JXeMRAa8+zrv=mnEc9r8H9kC26QpEkbg@mail.gmail.com>
Message-ID: <MN2PR02MB69116399477B384CCBB04BFCD4B62@MN2PR02MB6911.namprd02.prod.outlook.com>

HI Bert,

Thank you for extra help!!
Yes, exactly, your interpretation is perfectly correct and your R code is what I should look for.
after generated all those negative values of correlation,
I thought about the extremely small p values associated with those negative correlation, which is not meaningful as I truncated my data.

When examining the exclusiveness of mutation pairs, what I first thought about is correlation, so stepped into a more complicated correlation journey.
However, what Richard share is very helpful to explain why I got negative correlation values for all pairs.
In my case, we measured all mutations for all 1000 samples using an exactly same sequencing method, so no issue of never-reporting.
I am  very grateful for help and comments from Rui, Richard and Bert!!

Ding



From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Saturday, July 27, 2024 4:50 PM
To: Yuan Chun Ding <ycding at coh.org>
Cc: Richard O'Keefe <raoknz at gmail.com>; r-help at r-project.org
Subject: Re: [R] please help generate a square correlation matrix

Your expanded explanation helps clarify your intent. Herewith some comments. Of course, feel free to ignore and not respond. And, as always, my apologies if I have failed to comprehend your intent. 1. I would avoid any notion of "statistical


Your expanded explanation helps clarify your intent. Herewith some

comments. Of course, feel free to ignore and not respond. And, as

always, my apologies if I have failed to comprehend your intent.



1. I would avoid any notion of "statistical significance" like the

plague. This is a purely exploratory exercise.



2. My understanding is that you want to know the proportion of rows in

a pair of columns/vectors in which only 1 values of the pair is 1 out

of the number of pairs where 1 or 2 values is 1.  In R syntax, this is

simply:



sum(xor(x, y)) / sum(x | y)  ,

where x and y are two columns of 1's and 0's



Better yet might be to report both this *and* sum(x|y) to help you

judge "meaningfulness".

Here is a simple function that does this



## first, define a function that does above calculation:

assoc <- \(z){

   x <- z[,1]; y <- z[,2]

   n <- sum(x|y)

   c(prop = sum(xor(x, y))/n, N = n)

}



## Now a function that uses it for the various combinations:



somecor <- function(dat, func = assoc){

   dat <- as.matrix(dat)

   indx <- seq_len(ncol(dat))

   rbind(w <- combn(indx,2),

         combn(indx, 2, FUN = \(m)func(dat[,m]) )) |>

     t()  |> round(digits =2) |>

  'dimnames<-'(list(rep.int('',ncol(w)), c("","", "prop","N")))

}



# Now apply it to your example data:



somecor(dat)

## which gives

     prop N

 1 2 0.67 6

 1 3 0.60 5

 1 4 0.57 7

 2 3 0.60 5

 2 4 0.33 6

 3 4 0.71 7



This seems more interpretable and directly useful to me. Bigger values

of prop for bigger N are the more interesting, assuming I have

interpreted you correctly.



Cheers,

Bert





On Sat, Jul 27, 2024 at 12:54?PM Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>> wrote:

>

> Hi Richard,

>

>

>

> Nice to know you had similar experience.

>

> Yes, your understanding is right.  all correlations are negative after removing double-zero rows.

>

> It is consistent with a heatmap we generated.

>

> 1 is for a cancer patient with a specific mutation.  0 is no mutation for the same mutation type in a patient.

>

> a pair of mutation type (two different mutations) are exclusive for most of patients in heatmap or oncoplots.

>

>  If we include all 1000 patients, 900 of patients with no mutations in both mutation types, then the correlation is not significant at all.

>

> But eyeball the heatmap (oncoplots) for mutation (row) by patient (column), mutations are exclusive for most of patients,

>

> so I want to measure how strong the exclusiveness between two specific mutation types across those patients with at least one mutation type.

>

> Then put the pair of mutations with strong negative mutations on the top rows by order of negative mutation values.

>

>

>

> Regarding a final application,  maybe there are some usage for my case.

>

>  If one develops two drugs specific to the two negative correlated mutations, the drug treatment for cancer patients is usually only for those patients carrying the specific mutation,

>

> then it is informative to know how strong the negative correlation when considering different combination of treatment strategies.

>

>

>

> Ding

>

>

>

>

>

>

>

>

>

>

>

> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Richard O'Keefe

> Sent: Saturday, July 27, 2024 4:47 AM

> To: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>

> Cc: r-help at r-project.org<mailto:r-help at r-project.org>

> Subject: Re: [R] please help generate a square correlation matrix

>

>

>

> Curses, my laptop is hallucinating again. Hope I can get through this. So we're talking about correlations between binary variables. Suppose we have two 0-1-valued variables, x and y. Let A <- sum(x*y) # number of cases where x and y are

>

> Curses, my laptop is hallucinating again.  Hope I can get through this.

>

> So we're talking about correlations between binary variables.

>

> Suppose we have two 0-1-valued variables, x and y.

>

> Let A <- sum(x*y)  # number of cases where x and y are both 1.

>

> Let B <- sum(x)-A  # number of cases where x is 1 and y is 0

>

> Let C <- sum(y)-A # number of cases where y is 1 and x is 0

>

> Let D <- sum(!x * !y) # number of cases where x and y are both 0.

>

> (also D = length(x)-A-B-C)

>

>

>

> All the information is summarised in the 2-by-2 contingency table.

>

> Some years ago, Nathan Rountree and I supervised Yung-Sing Koh's

>

> data-mining PhD.

>

> She surveyed the data mining literature and found some 37 different

>

> "interestingness measures" for two-variable associations  -- if I

>

> remember correctly; there were a lot of them.  They fell into a much

>

> smaller number of qualitatively similar groups.

>

> At any rate, the Pearson correlation between x and y is

>

> (A*D - B*C)/sqrt((A+B)*(C+D)*(A+C)*(B+D))

>

>

>

> So what happens when we delete the rows where x = 0 and y = 0?

>

> Right, it forces D to 0, leaving A B C unchanged.

>

> And looking at the numerator,

>

>   If you delete rows with x = 0 y = 0 you MUST get a negative correlation.

>

>

>

> Quite a modest "true" correlation (based on all the data) like -0.2

>

> can masquerade as quite a strong "zero-suppressed" correlation like

>

> -0.6.  Even +0.2 can turn into -0.4.   (These figures are from a

>

> particular simulation run and may not apply in your case.)

>

>

>

> Now one of the reasons why Yun-Sing Koh, Nathan Rountree, and I were

>

> interested in interestingness measures is perhaps coincidentally

>

> related to the file drawer/underreporting problem: it's quite common

>

> for rows where x = 0 and y = 0 never to have been reported to you, so

>

> we were hoping there were measures immune to that.  I have argued for

>

> years that "till record analysis" for supermarkets &c is badly flawed

>

> by two facts: (a) it is hard to measure how much of a product people

>

> WOULD have bought if only you had offered it for sale (although you

>

> can make educated guesses) and (b) till records provide no evidence on

>

> what the people who walked out without buying anything wanted (was the

>

> price too high?  could they not find it?).  Problem (a) leads to a

>

> commercial variant of the Signor-Lipps effect: "when x and/or y were

>

> available for purchase" is not the same as "the period for which data

>

> were recorded", thus inflating D, perhaps massively.  Methods

>

> developed for handling the Signor-Lipps effect in paleontology can be

>

> used to estimate when x and y were available helping you to recover a

>

> more realistic N=A+B+C+D.  I really should have published that.

>

>

>

> All of which is a long-winded way of saying that

>

> - Pearson correlations on binary columns can be computed very efficiently

>

> - the rows with x=0 and y=0 may be very informative, even essential for analysis

>

> - delete them at your peril.

>

> - really, delete them at your peril.

>

>

>

> On Sat, 27 Jul 2024 at 23:07, Richard O'Keefe <raoknz at gmail.com<mailto:raoknz at gmail.com>> wrote:

>

> >

>

> > Let's go back to the original posting.

>

> >

>

> > > >

>

> > > >> in each column, less than 10% values are 1, most of them are 0;

>

> > > >

>

> > > >

>

> > > >

>

> > > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.

>

> > > >

>

> >

>

> > So we're talking about correlations between binary variables.

>

> > Suppose we have two 0-1-valued variables, x and y.

>

> > Let A <- sum(x*y)  # number of cases where x and y are both 1.

>

> > Let B <- sum(x)-a  # number of cases where x is 1 and y is 0

>

> > Let C <- sum(y)-a # number of cases where y is 1 and x is 0

>

> > Let D <- sum(!x * !y) # number of cases where x and y are both 0.

>

> >

>

> > N

>

> >

>

> > On Fri, 26 Jul 2024 at 12:07, Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:

>

> > >

>

> > > If I have understood the request, I'm not sure that omitting all 0

>

> > > pairs for each pair of columns makes much sense, but be that as it

>

> > > may, here's another way to do it by using the 'FUN' argument of combn

>

> > > to encapsulate any calculations that you do. I just use cor() as the

>

> > > calculation -- you can use anything you like that takes two vectors of

>

> > > 0's and 1's and produces fixed length numeric results (or fromm which

>

> > > you can extract such).

>

> > >

>

> > > I encapsulated it all in a little function. Note that I first

>

> > > converted the data frame to a matrix. Because of their generality,

>

> > > data frames carry a lot of extra baggage that can slow purely numeric

>

> > > manipulations down.

>

> > >

>

> > > Anyway, here's the function, 'somecors' (I'm a bad name picker :(  ! )

>

> > >

>

> > >    somecors <- function(dat, func = cor){

>

> > >       dat <- as.matrix(dat)

>

> > >       indx <- seq_len(ncol(dat))

>

> > >          combn(indx, 2, FUN = \(z) {

>

> > >             i <- z[1]; j <- z[2]

>

> > >             k <- dat[, i ] | dat[, j ]

>

> > >             c(z,func(dat[k,i ], dat[k,j ]))

>

> > >          })

>

> > >    }

>

> > >

>

> > > Results come out as a matrix with combn(ncol(dat),2) columns, the

>

> > > first 2 rows giving the pair of column numbers for each column,and

>

> > > then 1 or more rows (possibly extracted) from whatever func you use.

>

> > > Here's the results for your data formatted to 2 decimal places:

>

> > >

>

> > > > round(somecors(dat),2)

>

> > >      [,1]  [,2]  [,3]  [,4] [,5]  [,6]

>

> > > [1,]  1.0  1.00  1.00  2.00    2  3.00

>

> > > [2,]  2.0  3.00  4.00  3.00    4  4.00

>

> > > [3,] -0.5 -0.41 -0.35 -0.41   NA -0.47

>

> > > Warning message:

>

> > > In func(dat[k, i], dat[k, j]) : the standard deviation is zero

>

> > >

>

> > > The NA and warning comes in the 2,4 pair of columns because after

>

> > > removing all zero rows in the pair, dat[,4] is all 1's, giving a zero

>

> > > in the denominator of the cor() calculation -- again, assuming I have

>

> > > correctly understood your request. If so, this might be something you

>

> > > need to worry about.

>

> > >

>

> > > Again, feel free to ignore if  I have misinterpreterd or this does not suit.

>

> > >

>

> > > Cheers,

>

> > > Bert

>

> > >

>

> > >

>

> > > On Thu, Jul 25, 2024 at 2:01?PM Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>> wrote:

>

> > > >

>

> > > > ?s 20:47 de 25/07/2024, Yuan Chun Ding escreveu:

>

> > > > > Hi Rui,

>

> > > > >

>

> > > > > You are always very helpful!! Thank you,

>

> > > > >

>

> > > > > I just modified your R codes to remove a row with zero values in both column pair as below for my real data.

>

> > > > >

>

> > > > > Ding

>

> > > > >

>

> > > > > dat<-gene22mut.coded

>

> > > > > r <- P <- matrix(NA, nrow = 22L, ncol = 22L,

>

> > > > >                   dimnames = list(names(dat), names(dat)))

>

> > > > >

>

> > > > > for(i in 1:22) {

>

> > > > >    #i=1

>

> > > > >    x <- dat[[i]]

>

> > > > >    for(j in (1:22)) {

>

> > > > >      #j=2

>

> > > > >      if(i == j) {

>

> > > > >        # there's nothing to test, assign correlation 1

>

> > > > >        r[i, j] <- 1

>

> > > > >      } else {

>

> > > > >        tmp <-cbind(x,dat[[j]])

>

> > > > >        row0 <-rowSums(tmp)

>

> > > > >        tem2 <-tmp[row0!=0,]

>

> > > > >        tmp3 <- cor.test(tem2[,1],tem2[,2])

>

> > > > >        r[i, j] <- tmp3$estimate

>

> > > > >        P[i, j] <- tmp3$p.value

>

> > > > >      }

>

> > > > >    }

>

> > > > > }

>

> > > > > r<-as.data.frame(r)

>

> > > > > P<-as.data.frame(P)

>

> > > > >

>

> > > > > From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Yuan Chun Ding via R-help

>

> > > > > Sent: Thursday, July 25, 2024 11:26 AM

>

> > > > > To: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>; r-help at r-project.org<mailto:r-help at r-project.org>

>

> > > > > Subject: Re: [R] please help generate a square correlation matrix

>

> > > > >

>

> > > > > HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;

>

> > > > >

>

> > > > >

>

> > > > > HI Rui,

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > Thank you for the  help!

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > You did not remove a row if zero values exist in both column pair, right?

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > Ding

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt%3cmailto:ruipbarradas at sapo.pt>>>

>

> > > > >

>

> > > > > Sent: Thursday, July 25, 2024 11:15 AM

>

> > > > >

>

> > > > > To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org<mailto:ycding at coh.org%3cmailto:ycding at coh.org>>>; r-help at r-project.org<mailto:r-help at r-project.org<mailto:r-help at r-project.org%3cmailto:r-help at r-project.org>>

>

> > > > >

>

> > > > > Subject: Re: [R] please help generate a square correlation matrix

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > ?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > ?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> Hi R users,

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> I generated a square correlation matrix for the dat dataframe below;

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>                   g2=c(0,1,0,1,0,1,1,0,0),

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>                   g3=c(1,1,0,0,0,1,0,0,0),

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>                   g4=c(0,1,0,1,1,1,1,1,0))

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> library("Hmisc")

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> dat.rcorr = rcorr(as.matrix(dat))

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> dat.r <-round(dat.rcorr$r,2)

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> however, I want to modify this correlation calculation;

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> my dat has more than 1000 rows and 22 columns;

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> in each column, less than 10% values are 1, most of them are 0;

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> I just want to check whether those values of 1 are correlated between two columns.

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> Please look at my code in the following;

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> cor.4gene <-matrix(0,nrow=4*4, ncol=4)

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> for (i in 1:4){

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>     #i=1

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>     for (j in 1:4) {

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>       #j=1

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>       d <-dat[,c(i,j)]%>%

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>         filter(eval(as.symbol(colnames(dat)[i]))!=0 |

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>                  eval(as.symbol(colnames(dat)[j]))!=0)

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>       c <-cor.test(d[,1],d[,2])

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>       cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>                           c$estimate,c$p.value)

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>     }

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> }

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> colnames(cor.4gene)<-c("gene1","gene2","cor","P")

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> Can you tell me what mistakes I made?

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> cor.4gene$cor[is.na(cor.4gene$cor)]<-1

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> cor.4gene$cor[is.na(cor.4gene$P)]<-0

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> Then this line of code above did not generate a square matrix as what the HMisc library did.

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> How to fix my code?

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> Thank you,

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> Ding

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> ----------------------------------------------------------------------

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> ------------------------------------------------------------

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> -SECURITY/CONFIDENTIALITY WARNING-

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> ------------------------------------------------------------

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>              [[alternative HTML version deleted]]

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >>

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> ______________________________________________

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org%3cmailto:R-help at r-project.org%3cmailto:R-help at r-project.org>>> mailing list -- To UNSUBSCRIBE and more, see

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e%3e>

> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e%3e>>> > >

>

> > > > >   <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e%3e>

> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3e%3e%3e>>> > >

>

> > > > >> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASEdo<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e%3ePLEASEdo>read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e%3e>

> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e%3e>>> > >

>

> > > > >   <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e%3e>

> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3e%3e%3e>>> > >

>

> > > > >> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>andprovide<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e%3eandprovide>commented, minimal, self-contained, reproducible code.

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > Hello,

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > You are complicating the code, there's no need for as.symbol/eval, the

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > column numbers do exactly the same.

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > # create the two results matrices beforehand

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > names(dat)))

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > for(i in 1:4) {

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >     x <- dat[[i]]

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >     for(j in (1:4)) {

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >       if(i == j) {

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >         # there's nothing to test, assign correlation 1

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >         r[i, j] <- 1

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >       } else {

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >         tmp <- cor.test(x, dat[[j]])

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >         r[i, j] <- tmp$estimate

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >         P[i, j] <- tmp$p.value

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >       }

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >     }

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > }

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > # these two results are equal up to floating-point precision

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > dat.rcorr$r

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #>           g1        g2        g3        g4

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g1 1.0000000 0.1000000 0.3162278 0.1581139

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g2 0.1000000 1.0000000 0.3162278 0.6324555

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g3 0.3162278 0.3162278 1.0000000 0.0000000

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g4 0.1581139 0.6324555 0.0000000 1.0000000

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > r

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #>           g1        g2           g3           g4

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > # these two results are equal up to floating-point precision

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > dat.rcorr$P

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #>           g1         g2        g3         g4

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g1        NA 0.79797170 0.4070838 0.68452834

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g2 0.7979717         NA 0.4070838 0.06758329

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g3 0.4070838 0.40708382        NA 1.00000000

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g4 0.6845283 0.06758329 1.0000000         NA

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > P

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #>           g1         g2        g3         g4

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g1        NA 0.79797170 0.4070838 0.68452834

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g2 0.7979717         NA 0.4070838 0.06758329

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g3 0.4070838 0.40708382        NA 1.00000000

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > #> g4 0.6845283 0.06758329 1.0000000         NA

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > You can put these two results in a list, like Hmisc::rcorr does.

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > lst_rcorr <- list(r = r, P = P)

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > Hope this helps,

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > Rui Barradas

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > --

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e%3e>

> <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e%3e>

><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e%3e>>> > >

>

> > > > >   <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e%3e>

> <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e%3e>

><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3e%3e%3e>>> > >

>

> > > > >                 [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTMLversion<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative%3eHTMLversion>deleted]]

>

> > > > >

>

> > > > >

>

> > > > >

>

> > > > > ______________________________________________

>

> > > > >

>

> > > > > R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see

>

> > > > >

>

> > > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3e%3e%3e>

> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3e%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$%3e%3e%3e>>> > >

>

> > > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3e%3e%3e>

> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3e%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$%3e%3e%3e>>> > >

>

> > > > > and provide commented, minimal, self-contained, reproducible code.

>

> > > > >

>

> > > > Hello,

>

> > > >

>

> > > > Here are two other ways.

>

> > > >

>

> > > > The first is equivalent to your long format attempt.

>

> > > >

>

> > > >

>

> > > > library(tidyverse)

>

> > > >

>

> > > > dat %>%

>

> > > >    names() %>%

>

> > > >    expand.grid(., .) %>%

>

> > > >    apply(1L, \(x) {

>

> > > >      tmp <- dat[rowSums(dat[x]) > 0, ]

>

> > > >      tmp2 <- cor.test(tmp[[ x[1L] ]], tmp[[ x[2L] ]])

>

> > > >      c(tmp2$estimate, P = tmp2$p.value)

>

> > > >    }) %>%

>

> > > >    t() %>%

>

> > > >    as.data.frame() %>%

>

> > > >    cbind(tmp_df, .) %>%

>

> > > >    na.omit()

>

> > > >

>

> > > >

>

> > > > The second is, in my opinion the one that makes more sense. If you see

>

> > > > the results, cor is symmetric (as it should) so the calculations are

>

> > > > repeated. If you only run the cor.tests on the combinations of

>

> > > > names(dat) by groups of 2, it will save a lot of work. But the output is

>

> > > > a much smaller a data.frame.

>

> > > >

>

> > > >

>

> > > > cbind(

>

> > > >    combn(names(dat), 2L) %>%

>

> > > >      t() %>%

>

> > > >      as.data.frame(),

>

> > > >    combn(dat, 2L, FUN = \(d) {

>

> > > >      d2 <- d[rowSums(d) > 0, ]

>

> > > >      tmp2 <- cor.test(d2[[1L]], d2[[2L]])

>

> > > >      c(tmp2$estimate, P = tmp2$p.value)

>

> > > >    }) %>% t()

>

> > > > ) %>% na.omit()

>

> > > >

>

> > > >

>

> > > >

>

> > > > Hope this helps,

>

> > > >

>

> > > > Rui Barradas

>

> > > >

>

> > > >

>

> > > > ______________________________________________

>

> > > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

>

> > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>

> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>> > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>

> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>> > > and provide commented, minimal, self-contained, reproducible code.

>

> > >

>

> > > ______________________________________________

>

> > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

>

> > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>

> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>> > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>

> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>> > and provide commented, minimal, self-contained, reproducible code.

>

>

>

> ______________________________________________

>

> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

>

> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>

> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>

><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$%3e%3e>PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>

> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>

><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$%3e%3e>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Jul 28 06:23:36 2024
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 28 Jul 2024 04:23:36 +0000
Subject: [R] help on date objects...
Message-ID: <PU4P216MB15684FD087C687AFD9055640C8B62@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

Dear members,
                             WHy is the following code returning NA instead of the date?


> as.Date("2022-01-02", origin = "1900-01-01",  format = "%y%d%m")
[1] NA


Thanking you,
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Jul 28 06:39:47 2024
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 28 Jul 2024 04:39:47 +0000
Subject: [R] ts_regular....in tsbox
Message-ID: <PU4P216MB15680A9AA443D4F8FD32D510C8B62@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I have a data frame which contains, among others, a date object of monthly frequency which is not regular, i.e some months are omitted, and the main variable to be forecast, among others. Its name is vesselB.

I did the following code:

vesselBR <- ts_regular(vesselB)

but the missing months are not filled with NA. What should I do to insert NAs into the missing months? THe date column is of character class; should I make it Date class? Any other trick?

THanking you,
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sun Jul 28 08:34:52 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 28 Jul 2024 09:34:52 +0300
Subject: [R] help on date objects...
In-Reply-To: <PU4P216MB15684FD087C687AFD9055640C8B62@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB15684FD087C687AFD9055640C8B62@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW77ESzazTB0KsZ1rxbskOwndo34FS9WXKw+fu2XnRr9eqw@mail.gmail.com>

as.Date("2022-01-02", origin="1900-01-01", format="%Y-%d-%m")

On Sun, Jul 28, 2024 at 7:24?AM akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> Dear members,
>                              WHy is the following code returning NA
> instead of the date?
>
>
> > as.Date("2022-01-02", origin = "1900-01-01",  format = "%y%d%m")
> [1] NA
>
>
> Thanking you,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sun Jul 28 08:47:25 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 28 Jul 2024 09:47:25 +0300
Subject: [R] ts_regular....in tsbox
In-Reply-To: <PU4P216MB15680A9AA443D4F8FD32D510C8B62@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB15680A9AA443D4F8FD32D510C8B62@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW75VhudREc6x+eQ7s4QeFPJgUeOCh0MuJVX9gTz5PrM=bg@mail.gmail.com>

Did you try converting the date column to class Date? Does that work?


On Sun, Jul 28, 2024 at 7:40?AM akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                             I have a data frame which contains, among
> others, a date object of monthly frequency which is not regular, i.e some
> months are omitted, and the main variable to be forecast, among others. Its
> name is vesselB.
>
> I did the following code:
>
> vesselBR <- ts_regular(vesselB)
>
> but the missing months are not filled with NA. What should I do to insert
> NAs into the missing months? THe date column is of character class; should
> I make it Date class? Any other trick?
>
> THanking you,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jul 28 13:50:39 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 28 Jul 2024 12:50:39 +0100
Subject: [R] help on date objects...
In-Reply-To: <PU4P216MB15684FD087C687AFD9055640C8B62@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
References: <PU4P216MB15684FD087C687AFD9055640C8B62@PU4P216MB1568.KORP216.PROD.OUTLOOK.COM>
Message-ID: <b6de96d4-2eac-46b6-9d92-fcf5a3f5646e@sapo.pt>

?s 05:23 de 28/07/2024, akshay kulkarni escreveu:
> Dear members,
>                               WHy is the following code returning NA instead of the date?
> 
> 
>> as.Date("2022-01-02", origin = "1900-01-01",  format = "%y%d%m")
> [1] NA
> 
> 
> Thanking you,
> Yours sincerely,
> AKSHAY M KULKARNI
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

There are several reasons for your result.

1. You have 4 digits year but format %y (lower case = 2 digits year) It 
should be %Y
2. Your date has '-' as separator but your format doesn't have a separator.

Also, though less important:

1. You don't need argument origin. This is only needed with numeric to 
date coercion.
2. Are you sure the format is YYYY-DD-MM, year-day-month?


as.Date("2022-01-02", format = "%Y-%d-%m")
#> [1] "2022-02-01"

# note the origin is not your posted origin date,
# see the examples on Windows and Excel
# dates in help("as.Date")
as.Date(19024, origin = "1970-01-01")
#> [1] "2022-02-01"


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From r@oknz @end|ng |rom gm@||@com  Sun Jul 28 13:56:46 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 28 Jul 2024 23:56:46 +1200
Subject: [R] please help generate a square correlation matrix
In-Reply-To: <MN2PR02MB69116399477B384CCBB04BFCD4B62@MN2PR02MB6911.namprd02.prod.outlook.com>
References: <MN2PR02MB6911ADCC246E872E385F8B43D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <436887d3-3282-4a45-bb49-26f659b165fc@sapo.pt>
 <MN2PR02MB69114D44E886F65F6254CEA4D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <MN2PR02MB69117C33C32C453380AED677D4AB2@MN2PR02MB6911.namprd02.prod.outlook.com>
 <fb4de5ea-fd24-4d2e-8743-f66d2c71f330@sapo.pt>
 <CAGxFJbTGphHj9bNyS2hfCn6tAPvBaQJyq2=VDsqe=mkcbL-_5g@mail.gmail.com>
 <CABcYAdJ2tOowkEMFire6nL0s08P6LQ+gapev1VhY_aDE8TkVVg@mail.gmail.com>
 <CABcYAdL7H-VByeMjXHx47gAcntYp0UAqM6h+2_T0+C0_ZJ=ppw@mail.gmail.com>
 <MN2PR02MB691195653B0F7349AE172F6CD4B52@MN2PR02MB6911.namprd02.prod.outlook.com>
 <CAGxFJbS_MwQgxueuX6JXeMRAa8+zrv=mnEc9r8H9kC26QpEkbg@mail.gmail.com>
 <MN2PR02MB69116399477B384CCBB04BFCD4B62@MN2PR02MB6911.namprd02.prod.outlook.com>
Message-ID: <CABcYAdK0f9wSfViZxPjtuMTst+AA4wZSfzoRp2XDyYCSRW6_Qg@mail.gmail.com>

It sounds as though you have null hypothesis "x records independent
Bernoulli trials with the same (unknown) success probability p_x, y
records independent Bernoulli trials with the same (unknown) success
probability p_y, x and y are independent" and alternative hypothesis
"x and y succeed less often than they would under the null
hypothesis".  The obvious way to do that is to fit \hat{p_x} =
sum(x)/length(x), \hat{p_y| = sum(y)/length(y), and then compute the
lower tail Pr(number of times x and y succeed <= sum(xy) | p_x =
\hat{p_x} \& p_y = \hat{p_y}, and unless I am completely off my head
with sleepiness, this is just

pbinom(sum(x*y), length(x), mean(x)*mean(y))

So I don't quite see why you wanted correlations.

Since you say that "WE measured ..." the various Signor-Lipps-like
scenarios I was thinking of probably don't apply.  There are other
threats to validity:
- the presence of two (or more) mutations may be hard for your
equipment to detect
- patients with multiple mutations may die faster so may be less
likely to be captured for your study
- cell division rates decrease with age
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6789572/ so mutations
whose likelihood  depends on *rate* might tend to occur earlier in
life while mutations that depend on *accumulated* error might tend to
occur later in life, so "x occurs SOME time in a patient's life" and
"y occurs SOME time in a patient's life" might be independent while "x
and y occur at the SAME time in a patient's life" might be unlikely.
It would be interesting to check whether the frequency of each
mutation is independent of patient age, because you might want to
stratify the pbinom test by age in that case.  Exposure to
environmental mutagens is also likely to vary with age.

Looking at supermarket data in the past primed me to expect rates to
vary with age.  Sunscreen and cough mixture are negatively associated
(:-).

On Sun, 28 Jul 2024 at 12:40, Yuan Chun Ding <ycding at coh.org> wrote:
>
> HI Bert,
>
>
>
> Thank you for extra help!!
>
> Yes, exactly, your interpretation is perfectly correct and your R code is what I should look for.
>
> after generated all those negative values of correlation,
>
> I thought about the extremely small p values associated with those negative correlation, which is not meaningful as I truncated my data.
>
>
>
> When examining the exclusiveness of mutation pairs, what I first thought about is correlation, so stepped into a more complicated correlation journey.
>
> However, what Richard share is very helpful to explain why I got negative correlation values for all pairs.
>
> In my case, we measured all mutations for all 1000 samples using an exactly same sequencing method, so no issue of never-reporting.
>
> I am  very grateful for help and comments from Rui, Richard and Bert!!
>
>
>
> Ding
>
>
>
>
>
>
>
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Saturday, July 27, 2024 4:50 PM
> To: Yuan Chun Ding <ycding at coh.org>
> Cc: Richard O'Keefe <raoknz at gmail.com>; r-help at r-project.org
> Subject: Re: [R] please help generate a square correlation matrix
>
>
>
> Your expanded explanation helps clarify your intent. Herewith some comments. Of course, feel free to ignore and not respond. And, as always, my apologies if I have failed to comprehend your intent. 1. I would avoid any notion of "statistical
>
> Your expanded explanation helps clarify your intent. Herewith some
>
> comments. Of course, feel free to ignore and not respond. And, as
>
> always, my apologies if I have failed to comprehend your intent.
>
>
>
> 1. I would avoid any notion of "statistical significance" like the
>
> plague. This is a purely exploratory exercise.
>
>
>
> 2. My understanding is that you want to know the proportion of rows in
>
> a pair of columns/vectors in which only 1 values of the pair is 1 out
>
> of the number of pairs where 1 or 2 values is 1.  In R syntax, this is
>
> simply:
>
>
>
> sum(xor(x, y)) / sum(x | y)  ,
>
> where x and y are two columns of 1's and 0's
>
>
>
> Better yet might be to report both this *and* sum(x|y) to help you
>
> judge "meaningfulness".
>
> Here is a simple function that does this
>
>
>
> ## first, define a function that does above calculation:
>
> assoc <- \(z){
>
>    x <- z[,1]; y <- z[,2]
>
>    n <- sum(x|y)
>
>    c(prop = sum(xor(x, y))/n, N = n)
>
> }
>
>
>
> ## Now a function that uses it for the various combinations:
>
>
>
> somecor <- function(dat, func = assoc){
>
>    dat <- as.matrix(dat)
>
>    indx <- seq_len(ncol(dat))
>
>    rbind(w <- combn(indx,2),
>
>          combn(indx, 2, FUN = \(m)func(dat[,m]) )) |>
>
>      t()  |> round(digits =2) |>
>
>   'dimnames<-'(list(rep.int('',ncol(w)), c("","", "prop","N")))
>
> }
>
>
>
> # Now apply it to your example data:
>
>
>
> somecor(dat)
>
> ## which gives
>
>      prop N
>
>  1 2 0.67 6
>
>  1 3 0.60 5
>
>  1 4 0.57 7
>
>  2 3 0.60 5
>
>  2 4 0.33 6
>
>  3 4 0.71 7
>
>
>
> This seems more interpretable and directly useful to me. Bigger values
>
> of prop for bigger N are the more interesting, assuming I have
>
> interpreted you correctly.
>
>
>
> Cheers,
>
> Bert
>
>
>
>
>
> On Sat, Jul 27, 2024 at 12:54?PM Yuan Chun Ding <ycding at coh.org> wrote:
>
> >
>
> > Hi Richard,
>
> >
>
> >
>
> >
>
> > Nice to know you had similar experience.
>
> >
>
> > Yes, your understanding is right.  all correlations are negative after removing double-zero rows.
>
> >
>
> > It is consistent with a heatmap we generated.
>
> >
>
> > 1 is for a cancer patient with a specific mutation.  0 is no mutation for the same mutation type in a patient.
>
> >
>
> > a pair of mutation type (two different mutations) are exclusive for most of patients in heatmap or oncoplots.
>
> >
>
> >  If we include all 1000 patients, 900 of patients with no mutations in both mutation types, then the correlation is not significant at all.
>
> >
>
> > But eyeball the heatmap (oncoplots) for mutation (row) by patient (column), mutations are exclusive for most of patients,
>
> >
>
> > so I want to measure how strong the exclusiveness between two specific mutation types across those patients with at least one mutation type.
>
> >
>
> > Then put the pair of mutations with strong negative mutations on the top rows by order of negative mutation values.
>
> >
>
> >
>
> >
>
> > Regarding a final application,  maybe there are some usage for my case.
>
> >
>
> >  If one develops two drugs specific to the two negative correlated mutations, the drug treatment for cancer patients is usually only for those patients carrying the specific mutation,
>
> >
>
> > then it is informative to know how strong the negative correlation when considering different combination of treatment strategies.
>
> >
>
> >
>
> >
>
> > Ding
>
> >
>
> >
>
> >
>
> >
>
> >
>
> >
>
> >
>
> >
>
> >
>
> >
>
> >
>
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
>
> > Sent: Saturday, July 27, 2024 4:47 AM
>
> > To: Bert Gunter <bgunter.4567 at gmail.com>
>
> > Cc: r-help at r-project.org
>
> > Subject: Re: [R] please help generate a square correlation matrix
>
> >
>
> >
>
> >
>
> > Curses, my laptop is hallucinating again. Hope I can get through this. So we're talking about correlations between binary variables. Suppose we have two 0-1-valued variables, x and y. Let A <- sum(x*y) # number of cases where x and y are
>
> >
>
> > Curses, my laptop is hallucinating again.  Hope I can get through this.
>
> >
>
> > So we're talking about correlations between binary variables.
>
> >
>
> > Suppose we have two 0-1-valued variables, x and y.
>
> >
>
> > Let A <- sum(x*y)  # number of cases where x and y are both 1.
>
> >
>
> > Let B <- sum(x)-A  # number of cases where x is 1 and y is 0
>
> >
>
> > Let C <- sum(y)-A # number of cases where y is 1 and x is 0
>
> >
>
> > Let D <- sum(!x * !y) # number of cases where x and y are both 0.
>
> >
>
> > (also D = length(x)-A-B-C)
>
> >
>
> >
>
> >
>
> > All the information is summarised in the 2-by-2 contingency table.
>
> >
>
> > Some years ago, Nathan Rountree and I supervised Yung-Sing Koh's
>
> >
>
> > data-mining PhD.
>
> >
>
> > She surveyed the data mining literature and found some 37 different
>
> >
>
> > "interestingness measures" for two-variable associations  -- if I
>
> >
>
> > remember correctly; there were a lot of them.  They fell into a much
>
> >
>
> > smaller number of qualitatively similar groups.
>
> >
>
> > At any rate, the Pearson correlation between x and y is
>
> >
>
> > (A*D - B*C)/sqrt((A+B)*(C+D)*(A+C)*(B+D))
>
> >
>
> >
>
> >
>
> > So what happens when we delete the rows where x = 0 and y = 0?
>
> >
>
> > Right, it forces D to 0, leaving A B C unchanged.
>
> >
>
> > And looking at the numerator,
>
> >
>
> >   If you delete rows with x = 0 y = 0 you MUST get a negative correlation.
>
> >
>
> >
>
> >
>
> > Quite a modest "true" correlation (based on all the data) like -0.2
>
> >
>
> > can masquerade as quite a strong "zero-suppressed" correlation like
>
> >
>
> > -0.6.  Even +0.2 can turn into -0.4.   (These figures are from a
>
> >
>
> > particular simulation run and may not apply in your case.)
>
> >
>
> >
>
> >
>
> > Now one of the reasons why Yun-Sing Koh, Nathan Rountree, and I were
>
> >
>
> > interested in interestingness measures is perhaps coincidentally
>
> >
>
> > related to the file drawer/underreporting problem: it's quite common
>
> >
>
> > for rows where x = 0 and y = 0 never to have been reported to you, so
>
> >
>
> > we were hoping there were measures immune to that.  I have argued for
>
> >
>
> > years that "till record analysis" for supermarkets &c is badly flawed
>
> >
>
> > by two facts: (a) it is hard to measure how much of a product people
>
> >
>
> > WOULD have bought if only you had offered it for sale (although you
>
> >
>
> > can make educated guesses) and (b) till records provide no evidence on
>
> >
>
> > what the people who walked out without buying anything wanted (was the
>
> >
>
> > price too high?  could they not find it?).  Problem (a) leads to a
>
> >
>
> > commercial variant of the Signor-Lipps effect: "when x and/or y were
>
> >
>
> > available for purchase" is not the same as "the period for which data
>
> >
>
> > were recorded", thus inflating D, perhaps massively.  Methods
>
> >
>
> > developed for handling the Signor-Lipps effect in paleontology can be
>
> >
>
> > used to estimate when x and y were available helping you to recover a
>
> >
>
> > more realistic N=A+B+C+D.  I really should have published that.
>
> >
>
> >
>
> >
>
> > All of which is a long-winded way of saying that
>
> >
>
> > - Pearson correlations on binary columns can be computed very efficiently
>
> >
>
> > - the rows with x=0 and y=0 may be very informative, even essential for analysis
>
> >
>
> > - delete them at your peril.
>
> >
>
> > - really, delete them at your peril.
>
> >
>
> >
>
> >
>
> > On Sat, 27 Jul 2024 at 23:07, Richard O'Keefe <raoknz at gmail.com> wrote:
>
> >
>
> > >
>
> >
>
> > > Let's go back to the original posting.
>
> >
>
> > >
>
> >
>
> > > > >
>
> >
>
> > > > >> in each column, less than 10% values are 1, most of them are 0;
>
> >
>
> > > > >
>
> >
>
> > > > >
>
> >
>
> > > > >
>
> >
>
> > > > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
>
> >
>
> > > > >
>
> >
>
> > >
>
> >
>
> > > So we're talking about correlations between binary variables.
>
> >
>
> > > Suppose we have two 0-1-valued variables, x and y.
>
> >
>
> > > Let A <- sum(x*y)  # number of cases where x and y are both 1.
>
> >
>
> > > Let B <- sum(x)-a  # number of cases where x is 1 and y is 0
>
> >
>
> > > Let C <- sum(y)-a # number of cases where y is 1 and x is 0
>
> >
>
> > > Let D <- sum(!x * !y) # number of cases where x and y are both 0.
>
> >
>
> > >
>
> >
>
> > > N
>
> >
>
> > >
>
> >
>
> > > On Fri, 26 Jul 2024 at 12:07, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> >
>
> > > >
>
> >
>
> > > > If I have understood the request, I'm not sure that omitting all 0
>
> >
>
> > > > pairs for each pair of columns makes much sense, but be that as it
>
> >
>
> > > > may, here's another way to do it by using the 'FUN' argument of combn
>
> >
>
> > > > to encapsulate any calculations that you do. I just use cor() as the
>
> >
>
> > > > calculation -- you can use anything you like that takes two vectors of
>
> >
>
> > > > 0's and 1's and produces fixed length numeric results (or fromm which
>
> >
>
> > > > you can extract such).
>
> >
>
> > > >
>
> >
>
> > > > I encapsulated it all in a little function. Note that I first
>
> >
>
> > > > converted the data frame to a matrix. Because of their generality,
>
> >
>
> > > > data frames carry a lot of extra baggage that can slow purely numeric
>
> >
>
> > > > manipulations down.
>
> >
>
> > > >
>
> >
>
> > > > Anyway, here's the function, 'somecors' (I'm a bad name picker :(  ! )
>
> >
>
> > > >
>
> >
>
> > > >    somecors <- function(dat, func = cor){
>
> >
>
> > > >       dat <- as.matrix(dat)
>
> >
>
> > > >       indx <- seq_len(ncol(dat))
>
> >
>
> > > >          combn(indx, 2, FUN = \(z) {
>
> >
>
> > > >             i <- z[1]; j <- z[2]
>
> >
>
> > > >             k <- dat[, i ] | dat[, j ]
>
> >
>
> > > >             c(z,func(dat[k,i ], dat[k,j ]))
>
> >
>
> > > >          })
>
> >
>
> > > >    }
>
> >
>
> > > >
>
> >
>
> > > > Results come out as a matrix with combn(ncol(dat),2) columns, the
>
> >
>
> > > > first 2 rows giving the pair of column numbers for each column,and
>
> >
>
> > > > then 1 or more rows (possibly extracted) from whatever func you use.
>
> >
>
> > > > Here's the results for your data formatted to 2 decimal places:
>
> >
>
> > > >
>
> >
>
> > > > > round(somecors(dat),2)
>
> >
>
> > > >      [,1]  [,2]  [,3]  [,4] [,5]  [,6]
>
> >
>
> > > > [1,]  1.0  1.00  1.00  2.00    2  3.00
>
> >
>
> > > > [2,]  2.0  3.00  4.00  3.00    4  4.00
>
> >
>
> > > > [3,] -0.5 -0.41 -0.35 -0.41   NA -0.47
>
> >
>
> > > > Warning message:
>
> >
>
> > > > In func(dat[k, i], dat[k, j]) : the standard deviation is zero
>
> >
>
> > > >
>
> >
>
> > > > The NA and warning comes in the 2,4 pair of columns because after
>
> >
>
> > > > removing all zero rows in the pair, dat[,4] is all 1's, giving a zero
>
> >
>
> > > > in the denominator of the cor() calculation -- again, assuming I have
>
> >
>
> > > > correctly understood your request. If so, this might be something you
>
> >
>
> > > > need to worry about.
>
> >
>
> > > >
>
> >
>
> > > > Again, feel free to ignore if  I have misinterpreterd or this does not suit.
>
> >
>
> > > >
>
> >
>
> > > > Cheers,
>
> >
>
> > > > Bert
>
> >
>
> > > >
>
> >
>
> > > >
>
> >
>
> > > > On Thu, Jul 25, 2024 at 2:01?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> >
>
> > > > >
>
> >
>
> > > > > ?s 20:47 de 25/07/2024, Yuan Chun Ding escreveu:
>
> >
>
> > > > > > Hi Rui,
>
> >
>
> > > > > >
>
> >
>
> > > > > > You are always very helpful!! Thank you,
>
> >
>
> > > > > >
>
> >
>
> > > > > > I just modified your R codes to remove a row with zero values in both column pair as below for my real data.
>
> >
>
> > > > > >
>
> >
>
> > > > > > Ding
>
> >
>
> > > > > >
>
> >
>
> > > > > > dat<-gene22mut.coded
>
> >
>
> > > > > > r <- P <- matrix(NA, nrow = 22L, ncol = 22L,
>
> >
>
> > > > > >                   dimnames = list(names(dat), names(dat)))
>
> >
>
> > > > > >
>
> >
>
> > > > > > for(i in 1:22) {
>
> >
>
> > > > > >    #i=1
>
> >
>
> > > > > >    x <- dat[[i]]
>
> >
>
> > > > > >    for(j in (1:22)) {
>
> >
>
> > > > > >      #j=2
>
> >
>
> > > > > >      if(i == j) {
>
> >
>
> > > > > >        # there's nothing to test, assign correlation 1
>
> >
>
> > > > > >        r[i, j] <- 1
>
> >
>
> > > > > >      } else {
>
> >
>
> > > > > >        tmp <-cbind(x,dat[[j]])
>
> >
>
> > > > > >        row0 <-rowSums(tmp)
>
> >
>
> > > > > >        tem2 <-tmp[row0!=0,]
>
> >
>
> > > > > >        tmp3 <- cor.test(tem2[,1],tem2[,2])
>
> >
>
> > > > > >        r[i, j] <- tmp3$estimate
>
> >
>
> > > > > >        P[i, j] <- tmp3$p.value
>
> >
>
> > > > > >      }
>
> >
>
> > > > > >    }
>
> >
>
> > > > > > }
>
> >
>
> > > > > > r<-as.data.frame(r)
>
> >
>
> > > > > > P<-as.data.frame(P)
>
> >
>
> > > > > >
>
> >
>
> > > > > > From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via R-help
>
> >
>
> > > > > > Sent: Thursday, July 25, 2024 11:26 AM
>
> >
>
> > > > > > To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
>
> >
>
> > > > > > Subject: Re: [R] please help generate a square correlation matrix
>
> >
>
> > > > > >
>
> >
>
> > > > > > HI Rui, Thank you for the help! You did not remove a row if zero values exist in both column pair, right? Ding From: Rui Barradas <ruipbarradas@?sapo.?pt> Sent: Thursday, July 25, 2024 11:?15 AM To: Yuan Chun Ding <ycding@?coh.?org>;
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > HI Rui,
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > Thank you for the  help!
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > You did not remove a row if zero values exist in both column pair, right?
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > Ding
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > From: Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>>
>
> >
>
> > > > > >
>
> >
>
> > > > > > Sent: Thursday, July 25, 2024 11:15 AM
>
> >
>
> > > > > >
>
> >
>
> > > > > > To: Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>>; r-help at r-project.org<mailto:r-help at r-project.org>
>
> >
>
> > > > > >
>
> >
>
> > > > > > Subject: Re: [R] please help generate a square correlation matrix
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > ?s 17:?39 de 25/07/2024, Yuan Chun Ding via R-help escreveu: > Hi R users, > > I generated a square correlation matrix for the dat dataframe below; > dat<-data.?frame(g1=c(1,0,0,1,1,1,0,0,0), > g2=c(0,1,0,1,0,1,1,0,0), > g3=c(1,1,0,0,0,1,0,0,0),
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > ?s 17:39 de 25/07/2024, Yuan Chun Ding via R-help escreveu:
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> Hi R users,
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> I generated a square correlation matrix for the dat dataframe below;
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> dat<-data.frame(g1=c(1,0,0,1,1,1,0,0,0),
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>                   g2=c(0,1,0,1,0,1,1,0,0),
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>                   g3=c(1,1,0,0,0,1,0,0,0),
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>                   g4=c(0,1,0,1,1,1,1,1,0))
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> library("Hmisc")
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> dat.rcorr = rcorr(as.matrix(dat))
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> dat.r <-round(dat.rcorr$r,2)
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> however, I want to modify this correlation calculation;
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> my dat has more than 1000 rows and 22 columns;
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> in each column, less than 10% values are 1, most of them are 0;
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> so I want to remove a  row with value of zero in both columns when calculate correlation between two columns.
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> I just want to check whether those values of 1 are correlated between two columns.
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> Please look at my code in the following;
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> cor.4gene <-matrix(0,nrow=4*4, ncol=4)
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> for (i in 1:4){
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>     #i=1
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>     for (j in 1:4) {
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>       #j=1
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>       d <-dat[,c(i,j)]%>%
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>         filter(eval(as.symbol(colnames(dat)[i]))!=0 |
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>                  eval(as.symbol(colnames(dat)[j]))!=0)
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>       c <-cor.test(d[,1],d[,2])
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>       cor.4gene[i*j,]<-c(colnames(dat)[i],colnames(dat)[j],
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>                           c$estimate,c$p.value)
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>     }
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> }
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> cor.4gene<-as.data.frame(cor.4gene)%>%filter(V1 !=0)
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> colnames(cor.4gene)<-c("gene1","gene2","cor","P")
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> Can you tell me what mistakes I made?
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> first, why cor is NA when calculation of correlation for g1 and g1, I though it should be 1.
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> cor.4gene$cor[is.na(cor.4gene$cor)]<-1
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> cor.4gene$cor[is.na(cor.4gene$P)]<-0
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> cor.4gene.sq <-pivot_wider(cor.4gene, names_from = gene1, values_from = cor)
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> Then this line of code above did not generate a square matrix as what the HMisc library did.
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> How to fix my code?
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> Thank you,
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> Ding
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> ----------------------------------------------------------------------
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> ------------------------------------------------------------
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> -SECURITY/CONFIDENTIALITY WARNING-
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to rec
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>    eive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> ------------------------------------------------------------
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>              [[alternative HTML version deleted]]
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >>
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> ______________________________________________
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> R-help at r-project.org<mailto:R-help at r-project.org<mailto:R-help at r-project.org%3cmailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$><https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
>
> >
>
> >>> > >
>
> >
>
> > > > > >   <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>
>
> >
>
> >>> > >
>
> >
>
> > > > > >> <https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3chttps:/urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb8338TBM$%3e%3e>PLEASEdoread the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$><https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
>
> >
>
> >>> > >
>
> >
>
> > > > > >   <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>
>
> >
>
> >>> > >
>
> >
>
> > > > > >> <https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3chttps:/urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6Hb880tLw0$%3e%3e>andprovidecommented, minimal, self-contained, reproducible code.
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > Hello,
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > You are complicating the code, there's no need for as.symbol/eval, the
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > column numbers do exactly the same.
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > # create the two results matrices beforehand
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > r <- P <- matrix(NA, nrow = 4L, ncol = 4L, dimnames = list(names(dat),
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > names(dat)))
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > for(i in 1:4) {
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >     x <- dat[[i]]
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >     for(j in (1:4)) {
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >       if(i == j) {
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >         # there's nothing to test, assign correlation 1
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >         r[i, j] <- 1
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >       } else {
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >         tmp <- cor.test(x, dat[[j]])
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >         r[i, j] <- tmp$estimate
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >         P[i, j] <- tmp$p.value
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >       }
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >     }
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > }
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > # these two results are equal up to floating-point precision
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > dat.rcorr$r
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #>           g1        g2        g3        g4
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g1 1.0000000 0.1000000 0.3162278 0.1581139
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g2 0.1000000 1.0000000 0.3162278 0.6324555
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g3 0.3162278 0.3162278 1.0000000 0.0000000
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g4 0.1581139 0.6324555 0.0000000 1.0000000
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > r
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #>           g1        g2           g3           g4
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g1 1.0000000 0.1000000 3.162278e-01 1.581139e-01
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g2 0.1000000 1.0000000 3.162278e-01 6.324555e-01
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g3 0.3162278 0.3162278 1.000000e+00 1.355253e-20
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g4 0.1581139 0.6324555 1.355253e-20 1.000000e+00
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > # these two results are equal up to floating-point precision
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > dat.rcorr$P
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #>           g1         g2        g3         g4
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g1        NA 0.79797170 0.4070838 0.68452834
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g2 0.7979717         NA 0.4070838 0.06758329
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g3 0.4070838 0.40708382        NA 1.00000000
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g4 0.6845283 0.06758329 1.0000000         NA
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > P
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #>           g1         g2        g3         g4
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g1        NA 0.79797170 0.4070838 0.68452834
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g2 0.7979717         NA 0.4070838 0.06758329
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g3 0.4070838 0.40708382        NA 1.00000000
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > #> g4 0.6845283 0.06758329 1.0000000         NA
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > You can put these two results in a list, like Hmisc::rcorr does.
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > lst_rcorr <- list(r = r, P = P)
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > Hope this helps,
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > Rui Barradas
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > --
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > https://urldefense.com/v3/__http://www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$><https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
>
> >
>
> >>> > >
>
> >
>
> > > > > >   <https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>
>
> >
>
> >>> > >
>
> >
>
> > > > > >                 [[alternative<https://urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3chttps:/urldefense.com/v3/__http:/www.avg.com__;!!Fou38LsQmgU!tyykZkQmOKcwoWXEpV2ohbnr02thhHMabAcYLL_-7dteKHAabK-eo4rGDnwgSFjniAy8SO00L6HbloMCQMI$%3e%09%5b%5balternative>HTMLversiondeleted]]
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > >
>
> >
>
> > > > > > ______________________________________________
>
> >
>
> > > > > >
>
> >
>
> > > > > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>
> >
>
> > > > > >
>
> >
>
> > > > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXz-YrhdUE$>
>
> >
>
> >>> > >
>
> >
>
> > > > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!s54ahZtZNAIyaIGV3C2p8lhXpYlHksC6XvFKZltf6g3ElJHOO3I1MYFecLQ4QeMO3MpP3qXzNRZxc6s$>
>
> >
>
> >>> > >
>
> >
>
> > > > > > and provide commented, minimal, self-contained, reproducible code.
>
> >
>
> > > > > >
>
> >
>
> > > > > Hello,
>
> >
>
> > > > >
>
> >
>
> > > > > Here are two other ways.
>
> >
>
> > > > >
>
> >
>
> > > > > The first is equivalent to your long format attempt.
>
> >
>
> > > > >
>
> >
>
> > > > >
>
> >
>
> > > > > library(tidyverse)
>
> >
>
> > > > >
>
> >
>
> > > > > dat %>%
>
> >
>
> > > > >    names() %>%
>
> >
>
> > > > >    expand.grid(., .) %>%
>
> >
>
> > > > >    apply(1L, \(x) {
>
> >
>
> > > > >      tmp <- dat[rowSums(dat[x]) > 0, ]
>
> >
>
> > > > >      tmp2 <- cor.test(tmp[[ x[1L] ]], tmp[[ x[2L] ]])
>
> >
>
> > > > >      c(tmp2$estimate, P = tmp2$p.value)
>
> >
>
> > > > >    }) %>%
>
> >
>
> > > > >    t() %>%
>
> >
>
> > > > >    as.data.frame() %>%
>
> >
>
> > > > >    cbind(tmp_df, .) %>%
>
> >
>
> > > > >    na.omit()
>
> >
>
> > > > >
>
> >
>
> > > > >
>
> >
>
> > > > > The second is, in my opinion the one that makes more sense. If you see
>
> >
>
> > > > > the results, cor is symmetric (as it should) so the calculations are
>
> >
>
> > > > > repeated. If you only run the cor.tests on the combinations of
>
> >
>
> > > > > names(dat) by groups of 2, it will save a lot of work. But the output is
>
> >
>
> > > > > a much smaller a data.frame.
>
> >
>
> > > > >
>
> >
>
> > > > >
>
> >
>
> > > > > cbind(
>
> >
>
> > > > >    combn(names(dat), 2L) %>%
>
> >
>
> > > > >      t() %>%
>
> >
>
> > > > >      as.data.frame(),
>
> >
>
> > > > >    combn(dat, 2L, FUN = \(d) {
>
> >
>
> > > > >      d2 <- d[rowSums(d) > 0, ]
>
> >
>
> > > > >      tmp2 <- cor.test(d2[[1L]], d2[[2L]])
>
> >
>
> > > > >      c(tmp2$estimate, P = tmp2$p.value)
>
> >
>
> > > > >    }) %>% t()
>
> >
>
> > > > > ) %>% na.omit()
>
> >
>
> > > > >
>
> >
>
> > > > >
>
> >
>
> > > > >
>
> >
>
> > > > > Hope this helps,
>
> >
>
> > > > >
>
> >
>
> > > > > Rui Barradas
>
> >
>
> > > > >
>
> >
>
> > > > >
>
> >
>
> > > > > ______________________________________________
>
> >
>
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> >
>
> > > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$
>
> >
>
> >> > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$
>
> >
>
> >> > > and provide commented, minimal, self-contained, reproducible code.
>
> >
>
> > > >
>
> >
>
> > > > ______________________________________________
>
> >
>
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> >
>
> > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$
>
> >
>
> >> > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$
>
> >
>
> >> > and provide commented, minimal, self-contained, reproducible code.
>
> >
>
> >
>
> >
>
> > ______________________________________________
>
> >
>
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> >
>
> > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmwxIgqJrg$
>
> >
>
> >PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!syHSW7xho1Y4ssijZgjysEtoRhDbKljzLKfIYGOzmXQsT7wsjfUQ3n7CZDn7aQ-aUmxc76WB2w$
>
> >
>
> >and provide commented, minimal, self-contained, reproducible code.


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jul 29 06:22:22 2024
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 29 Jul 2024 09:52:22 +0530
Subject: [R] Using optim() function to find MLE
Message-ID: <CA+dpOJkfyfUkGDYF6=JjsKHDtrTrTRC7XSavLgD3TOy97zX7PA@mail.gmail.com>

Hi,

I am trying to fit a GLM on below data. While R does provide direct
estimation, I wanted to go with manual calculation as below

dat = structure(list(PurchasedProb = c(0.37212389963679, 0.572853363351896,
0.908207789994776, 0.201681931037456, 0.898389684967697, 0.944675268605351,
0.660797792486846, 0.62911404389888, 0.0617862704675645, 0.205974574899301,
0.176556752528995, 0.687022846657783, 0.384103718213737, 0.769841419998556,
0.497699242085218, 0.717618508264422, 0.991906094830483, 0.380035179434344,
0.777445221319795, 0.934705231105909, 0.212142521282658, 0.651673766085878,
0.125555095961317, 0.267220668727532, 0.386114092543721, 0.0133903331588954,
0.382387957070023, 0.86969084572047, 0.34034899668768, 0.482080115471035,
0.599565825425088, 0.493541307048872, 0.186217601411045, 0.827373318606988,
0.668466738192365, 0.79423986072652, 0.107943625887856, 0.723710946040228,
0.411274429643527, 0.820946294115856, 0.647060193819925, 0.78293276228942,
0.553036311641335, 0.529719580197707, 0.789356231689453, 0.023331202333793,
0.477230065036565, 0.7323137386702, 0.692731556482613, 0.477619622135535,
0.8612094768323, 0.438097107224166, 0.244797277031466, 0.0706790471449494,
0.0994661601725966, 0.31627170718275, 0.518634263193235, 0.6620050764177,
0.406830187188461, 0.912875924259424, 0.293603372760117, 0.459065726259723,
0.332394674187526, 0.65087046707049, 0.258016780717298, 0.478545248275623,
0.766310670645908, 0.0842469143681228, 0.875321330036968, 0.339072937844321,
0.839440350187942, 0.34668348915875, 0.333774930797517, 0.476351245073602,
0.892198335845023, 0.864339470630512, 0.389989543473348, 0.777320698834956,
0.960617997217923, 0.434659484773874, 0.712514678714797, 0.399994368897751,
0.325352151878178, 0.757087148027495, 0.202692255144939, 0.711121222469956,
0.121691921027377, 0.245488513959572, 0.14330437942408, 0.239629415096715,
0.0589343772735447, 0.642288258532062, 0.876269212691113, 0.778914677444845,
0.79730882588774, 0.455274453619495, 0.410084082046524, 0.810870242770761,
0.604933290276676, 0.654723928077146, 0.353197271935642, 0.270260145887733,
0.99268406117335, 0.633493264438584, 0.213208135217428, 0.129372348077595,
0.478118034312502, 0.924074469832703, 0.59876096714288, 0.976170694921166,
0.731792511884123, 0.356726912083104, 0.431473690550774, 0.148211560677737,
0.0130775754805654, 0.715566066093743, 0.103184235747904, 0.446284348610789,
0.640101045137271, 0.991838620044291, 0.495593577856198, 0.484349524369463,
0.173442334868014, 0.754820944508538, 0.453895489219576, 0.511169783771038,
0.207545113284141, 0.228658142732456, 0.595711996313184, 0.57487219828181,
0.0770643802825361, 0.0355405795853585, 0.642795492196456, 0.928615199634805,
0.598092422354966, 0.560900748008862, 0.526027723914012, 0.985095223877579,
0.507641822332516, 0.682788078673184, 0.601541217649356, 0.238868677755818,
0.258165926672518, 0.729309623362496, 0.452570831403136, 0.175126768415794,
0.746698269620538, 0.104987640399486, 0.864544949028641, 0.614644971676171,
0.557159538846463, 0.328777319053188, 0.453131445450708, 0.500440972624347,
0.180866361130029, 0.529630602803081, 0.0752757457084954, 0.277755932649598,
0.212699519237503, 0.284790480975062, 0.895094102947041, 0.4462353233248,
0.779984889784828, 0.880619034869596, 0.413124209502712, 0.0638084805104882,
0.335487491684034, 0.723725946620107, 0.337615333497524, 0.630414122482762,
0.840614554006606, 0.856131664710119, 0.39135928102769, 0.380493885604665,
0.895445425994694, 0.644315762910992, 0.741078648716211, 0.605303446529433,
0.903081611497328, 0.293730155099183, 0.19126010988839, 0.886450943304226,
0.503339485730976, 0.877057543024421, 0.189193622441962, 0.758103052387014,
0.724498892668635, 0.943724818294868, 0.547646587016061, 0.711743867723271,
0.388905099825934, 0.100873126182705, 0.927302088588476, 0.283232500310987,
0.59057315881364, 0.110360604943708, 0.840507032116875, 0.317963684443384,
0.782851336989552, 0.267508207354695, 0.218645284883678, 0.516796836396679,
0.268950592027977, 0.181168327340856, 0.518576137488708, 0.562782935798168,
0.129156854469329, 0.256367604015395, 0.717935275984928, 0.961409936426207,
0.100140846567228, 0.763222689507529, 0.947966354666278, 0.818634688388556,
0.308292330708355, 0.649579460499808, 0.953355451114476, 0.953732650028542,
0.339979203417897, 0.262474110117182, 0.165453933179379, 0.322168056620285,
0.510125206550583, 0.923968471353874, 0.510959698352963, 0.257621260825545,
0.0464608869515359, 0.41785625834018, 0.854001502273604, 0.347230677725747,
0.131442320533097, 0.374486864544451, 0.631420228397474, 0.390078933676705,
0.689627848798409, 0.689413412474096, 0.554900623159483, 0.429624407785013,
0.452720062807202, 0.306443258887157, 0.578353944001719, 0.910370304249227,
0.142604082124308, 0.415047625312582, 0.210925750667229, 0.428750370861962,
0.132689975202084, 0.460096445865929, 0.942957059247419, 0.761973861604929,
0.932909828843549, 0.470678497571498, 0.603588067693636, 0.484989680582657,
0.10880631650798, 0.247726832982153, 0.498514530714601, 0.372866708086804,
0.934691370232031, 0.523986077867448, 0.317144671687856, 0.277966029476374,
0.787540507735685, 0.702462512534112, 0.165027638664469, 0.0644575387705117,
0.754705621628091, 0.620410033036023, 0.169576766667888, 0.0622140523046255,
0.109029268613085, 0.381716351723298, 0.169310914585367, 0.298652542056516,
0.192209535045549, 0.257170021301135, 0.181231822818518, 0.477313709678128,
0.770737042883411, 0.0277871224097908, 0.527310776989907, 0.880319068906829,
0.373063371982425, 0.047959131654352, 0.138628246728331, 0.321492120390758,
0.154831611318514, 0.132228172151372, 0.221305927727371, 0.226380796171725,
0.13141653384082, 0.981563460314646, 0.327013726811856, 0.506939497077838,
0.68144251476042, 0.0991691031958908, 0.118902558228001, 0.0504396595060825,
0.929253919748589, 0.673712232848629, 0.0948578554671258, 0.492596120806411,
0.461551840649918, 0.375216530868784, 0.991099219536409, 0.176350713707507,
0.813435208518058, 0.0684466371312737, 0.40044974675402, 0.141144325723872,
0.193309862399474, 0.841351716779172, 0.719913988374174, 0.267212083097547,
0.495001644827425, 0.0831138978246599, 0.353884240612388, 0.969208805356175,
0.624714189674705, 0.664618249749765, 0.312489656498656, 0.405689612729475,
0.996077371528372, 0.855082356370986, 0.953548396006227, 0.812305092345923,
0.782182115828618, 0.267878128914163, 0.762151529546827, 0.986311589134857,
0.293605549028143, 0.399351106956601, 0.812131523853168, 0.0771516691893339,
0.363696809858084, 0.442592467181385, 0.156714132521302, 0.582205270184204,
0.970162178855389, 0.98949983343482, 0.176452036481351, 0.542130424408242,
0.384303892031312, 0.676164050819352, 0.26929377974011, 0.469250942347571,
0.171800082316622, 0.36918946239166, 0.725405272562057, 0.486149104312062,
0.0638024667277932, 0.784546229988337, 0.418321635806933, 0.981018084799871,
0.282883955864236, 0.847882149508223, 0.0822392308618873, 0.886458750581369,
0.471930730855092, 0.109100963454694, 0.333277984522283, 0.837416569236666,
0.276849841699004, 0.587035141419619, 0.836732269730419, 0.0711540239863098,
0.702778743347153, 0.69882453721948, 0.46396238100715, 0.436931110452861,
0.562176787760109, 0.928483226336539, 0.230466414242983, 0.221813754411414,
0.420215893303975, 0.333520805696025, 0.864807550329715, 0.177194535732269,
0.49331872863695, 0.429713366786018, 0.564263842999935, 0.656162315513939,
0.97855406277813, 0.232161148451269, 0.240811596158892, 0.796836083987728,
0.831671715015545, 0.113507706439123, 0.963312016334385, 0.147322899661958,
0.143626942764968, 0.925229935208336, 0.507035602582619, 0.15485101705417,
0.348302052123472, 0.659821025794372, 0.311772374436259, 0.351573409279808,
0.147845706902444, 0.658877609064803), Age = c(19L, 35L, 26L,
27L, 19L, 27L, 27L, 32L, 25L, 35L, 26L, 26L, 20L, 32L, 18L, 29L,
47L, 45L, 46L, 48L, 45L, 47L, 48L, 45L, 46L, 47L, 49L, 47L, 29L,
31L, 31L, 27L, 21L, 28L, 27L, 35L, 33L, 30L, 26L, 27L, 27L, 33L,
35L, 30L, 28L, 23L, 25L, 27L, 30L, 31L, 24L, 18L, 29L, 35L, 27L,
24L, 23L, 28L, 22L, 32L, 27L, 25L, 23L, 32L, 59L, 24L, 24L, 23L,
22L, 31L, 25L, 24L, 20L, 33L, 32L, 34L, 18L, 22L, 28L, 26L, 30L,
39L, 20L, 35L, 30L, 31L, 24L, 28L, 26L, 35L, 22L, 30L, 26L, 29L,
29L, 35L, 35L, 28L, 35L, 28L, 27L, 28L, 32L, 33L, 19L, 21L, 26L,
27L, 26L, 38L, 39L, 37L, 38L, 37L, 42L, 40L, 35L, 36L, 40L, 41L,
36L, 37L, 40L, 35L, 41L, 39L, 42L, 26L, 30L, 26L, 31L, 33L, 30L,
21L, 28L, 23L, 20L, 30L, 28L, 19L, 19L, 18L, 35L, 30L, 34L, 24L,
27L, 41L, 29L, 20L, 26L, 41L, 31L, 36L, 40L, 31L, 46L, 29L, 26L,
32L, 32L, 25L, 37L, 35L, 33L, 18L, 22L, 35L, 29L, 29L, 21L, 34L,
26L, 34L, 34L, 23L, 35L, 25L, 24L, 31L, 26L, 31L, 32L, 33L, 33L,
31L, 20L, 33L, 35L, 28L, 24L, 19L, 29L, 19L, 28L, 34L, 30L, 20L,
26L, 35L, 35L, 49L, 39L, 41L, 58L, 47L, 55L, 52L, 40L, 46L, 48L,
52L, 59L, 35L, 47L, 60L, 49L, 40L, 46L, 59L, 41L, 35L, 37L, 60L,
35L, 37L, 36L, 56L, 40L, 42L, 35L, 39L, 40L, 49L, 38L, 46L, 40L,
37L, 46L, 53L, 42L, 38L, 50L, 56L, 41L, 51L, 35L, 57L, 41L, 35L,
44L, 37L, 48L, 37L, 50L, 52L, 41L, 40L, 58L, 45L, 35L, 36L, 55L,
35L, 48L, 42L, 40L, 37L, 47L, 40L, 43L, 59L, 60L, 39L, 57L, 57L,
38L, 49L, 52L, 50L, 59L, 35L, 37L, 52L, 48L, 37L, 37L, 48L, 41L,
37L, 39L, 49L, 55L, 37L, 35L, 36L, 42L, 43L, 45L, 46L, 58L, 48L,
37L, 37L, 40L, 42L, 51L, 47L, 36L, 38L, 42L, 39L, 38L, 49L, 39L,
39L, 54L, 35L, 45L, 36L, 52L, 53L, 41L, 48L, 48L, 41L, 41L, 42L,
36L, 47L, 38L, 48L, 42L, 40L, 57L, 36L, 58L, 35L, 38L, 39L, 53L,
35L, 38L, 47L, 47L, 41L, 53L, 54L, 39L, 38L, 38L, 37L, 42L, 37L,
36L, 60L, 54L, 41L, 40L, 42L, 43L, 53L, 47L, 42L, 42L, 59L, 58L,
46L, 38L, 54L, 60L, 60L, 39L, 59L, 37L, 46L, 46L, 42L, 41L, 58L,
42L, 48L, 44L, 49L, 57L, 56L, 49L, 39L, 47L, 48L, 48L, 47L, 45L,
60L, 39L, 46L, 51L, 50L, 36L, 49L)), class = "data.frame", row.names = c(NA,
-400L))
dat[, 'b0'] = 1
LL = function(b0, b1)
sum(apply(as.matrix(dat[, c('PurchasedProb', 'Age')]), 1, function(iROw)
iROw['PurchasedProb'] * log( 1 / (1 + exp(-1 * (b0 + b1 * iROw['Age'])))) +
(1 - iROw['PurchasedProb']) * log(1 - 1 / (1 + exp(-1 * (b0 + b1 *
iROw['Age']))))))


result1 = optim(par = c(0,1), fn = LL, method = "L-BFGS-B")
coef(result1)

Unfortunately my calculation fails. Could you please help me to
understand what went wrong in my calculation?

Additionally, I want to use Newton-CG algorithm in my optimisation as
to follow certain norm which I am bound to. Is there any way to force
optim() function to use Newton-CG algorithm?

I am expecting to get similar result as
coef(glm("PurchasedProb ~ Age", data = dat, family = binomial())) ###
0.268640013 -0.007738782


From |kry|ov @end|ng |rom d|@root@org  Mon Jul 29 08:50:10 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 29 Jul 2024 09:50:10 +0300
Subject: [R] Using optim() function to find MLE
In-Reply-To: <CA+dpOJkfyfUkGDYF6=JjsKHDtrTrTRC7XSavLgD3TOy97zX7PA@mail.gmail.com>
References: <CA+dpOJkfyfUkGDYF6=JjsKHDtrTrTRC7XSavLgD3TOy97zX7PA@mail.gmail.com>
Message-ID: <20240729095010.13778c99@Tarkus>

? Mon, 29 Jul 2024 09:52:22 +0530
Christofer Bogaso <bogaso.christofer at gmail.com> ?????:

> LL = function(b0, b1)

help(optim) documents that the function to be optimised takes a single
argument, a vector containing the parameters. Here's how your LL
function can be adapted to this interface:

LL <- function(par) {
 b0 <- par[1]
 b1 <- par[2]
 sum(apply(as.matrix(dat[, c('PurchasedProb', 'Age')]), 1,
 function(iROw) iROw['PurchasedProb'] * log( 1 / (1 + exp(-1 * (b0 + b1
 * iROw['Age'])))) + (1 - iROw['PurchasedProb']) * log(1 - 1 / (1 +
 exp(-1 * (b0 + b1 * iROw['Age']))))))
}

Furethermore, LL(c(0, 1)) results in -Inf. All the methods supported by
optim() require at least the initial parameters to result in finite
values, and L-BFGS-B requires all evaluations to be finite. You're also
maximising the function, and optim() defaults to minimisation, so you
need an additional parameter to adjust that (or rewrite the LL function
further):

result1 <- optim(
 par = c(0, 0), fn = LL, method = "L-BFGS-B",
 control = list(fnscale = -1)
)

> coef(result1)

help(optim) documents the return value of optim() as not having a
class or a $coefficients field. You can use result1$par to access the
parameters.

> Is there any way to force optim() function to use Newton-CG algorithm?

I'm assuming you mean the method documented in
<https://docs.scipy.org/doc/scipy/reference/optimize.minimize-newtoncg.html>.
optim() doesn't support the truncated (line search) Newton-CG method.
See the 'optimx' and 'nloptr' packages for an implementation of a
truncated Newton method (not necessarily exactly the same one).

-- 
Best regards,
Ivan


From r-m@||@ @end|ng |rom erez@h@org  Sat Jul 27 13:36:20 2024
From: r-m@||@ @end|ng |rom erez@h@org (Erez Shomron)
Date: Sat, 27 Jul 2024 14:36:20 +0300
Subject: [R] C API - no NULL pointer guarantee?
Message-ID: <8bd9238a-1d2a-4c63-8594-5516f569003e@app.fastmail.com>

Hello,

I'm working on bindings for the API (for zig), and was wondering if the R's C API guarantees it won't return null pointers?
The only reference I found in the "Writing R Extensions" manual where this not the case is `R_tryEval` and `R_tryEvalSilent`.
Otherwise it's unclear.

The reason I care about this is syntax. Because I don't know whether SEXPs are NULL or not, then I wrap the SEXP in an optional type, and the burden is on the user to either check or assert every time you want to handle an optional SEXP.
It's not too bad and provides null safety, but can get excessive.

See an example from one of my test functions (question mark unwraps the optional. asserting it is not null):
```
export fn testAsScalarVector() Robject {
    const results = rzig.vec.allocVector(.List, 23).?.protect();
    defer rzig.gc.protect_stack.unprotectAll();

    results.?.setListObj(0, rzig.vec.asScalarVector(@as(f32, 1.32456e+32)));
    results.?.setListObj(1, rzig.vec.asScalarVector(@as(f32, -9.87123e-32)));
    results.?.setListObj(2, rzig.vec.asScalarVector(math.inf(f32)));
    results.?.setListObj(3, rzig.vec.asScalarVector(-math.inf(f32)));
    results.?.setListObj(4, rzig.vec.asScalarVector(math.nan(f32)));

    results.?.setListObj(5, rzig.vec.asScalarVector(@as(f64, -9.1e+300)));
    results.?.setListObj(6, rzig.vec.asScalarVector(@as(f64, 1.2e-300)));
    results.?.setListObj(7, rzig.vec.asScalarVector(math.inf(f64)));
    results.?.setListObj(8, rzig.vec.asScalarVector(-math.inf(f64)));
    results.?.setListObj(9, rzig.vec.asScalarVector(math.nan(f64)));

    results.?.setListObj(10, rzig.vec.asScalarVector(-9.1e+307));
    results.?.setListObj(11, rzig.vec.asScalarVector(1.2e-307));
    results.?.setListObj(12, rzig.vec.asScalarVector(1.0e+500)); // Inf
    results.?.setListObj(13, rzig.vec.asScalarVector(-1.0e+500)); // -Inf

    results.?.setListObj(14, rzig.vec.asScalarVector(5));
    results.?.setListObj(15, rzig.vec.asScalarVector(-5));
    results.?.setListObj(16, rzig.vec.asScalarVector(@as(u32, 4)));
    results.?.setListObj(17, rzig.vec.asScalarVector(@as(i32, -4)));
    results.?.setListObj(18, rzig.vec.asScalarVector(@as(u0, 0)));
    results.?.setListObj(19, rzig.vec.asScalarVector(@as(u150, 2_000_000_000)));
    results.?.setListObj(20, rzig.vec.asScalarVector(@as(i150, -2_000_000_000)));
    results.?.setListObj(21, rzig.vec.asScalarVector(true));
    results.?.setListObj(22, rzig.vec.asScalarVector(false));

    return results;
}
```

It would be nice to be able to drop the question mark, but only if R guarantees null safety at the API level. Then I would declare optional return types only for documented cases like `R_tryEval`

Appreciate your time an help!
Thanks,
- Erez


From |kry|ov @end|ng |rom d|@root@org  Mon Jul 29 12:23:59 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 29 Jul 2024 13:23:59 +0300
Subject: [R] C API - no NULL pointer guarantee?
In-Reply-To: <8bd9238a-1d2a-4c63-8594-5516f569003e@app.fastmail.com>
References: <8bd9238a-1d2a-4c63-8594-5516f569003e@app.fastmail.com>
Message-ID: <20240729132359.555ddf03@arachnoid>

? Sat, 27 Jul 2024 14:36:20 +0300
"Erez Shomron" <r-mails at erezsh.org> ?????:

> I'm working on bindings for the API (for zig), and was wondering if
> the R's C API guarantees it won't return null pointers? The only
> reference I found in the "Writing R Extensions" manual where this not
> the case is `R_tryEval` and `R_tryEvalSilent`.

Based on what I've been reading while working on (still very much
incomplete) <https://aitap.codeberg.page/R-api>, I think that these are
the only two cases where a SEXP can be null, precisely because a null
pointer is distinguished from every possible value that could be
returned by eval().

Some APIs may accept a null SEXP (with comments in the source code that
this is to support some legacy code, not the intended use), but when R
wants to return a value, it is always allocated through the memory
manager. A failing allocation will longjmp() away from the frame, not
return a null pointer.

It's hard to prove a negative, though.

-- 
Best regards,
Ivan


From gb @end|ng |rom eh@r@@e  Mon Jul 29 16:06:18 2024
From: gb @end|ng |rom eh@r@@e (=?UTF-8?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Mon, 29 Jul 2024 16:06:18 +0200
Subject: [R] round and trailing zero
Message-ID: <7cefda81-7d81-4981-bffc-825fdcd7a361@ehar.se>

I have a "result":

 > hazards
         (60, 70]    (70, 80]    (80, 90]   (90, 100]
[1,] 0.046612937 0.115643783 0.273613266 0.450127975

Two issues: (i) Too many decimals, and (ii) it seems to be an 1x4 
matrix, I only need the first row. (i):

 > haz <- round(hazards, 3)
 > haz
      (60, 70] (70, 80] (80, 90] (90, 100]
[1,]    0.047    0.116    0.274      0.45

As expected, the fourth element lost a trailing zero. I'll deal with 
that, but first (ii):

 > haz[1, ]
  (60, 70]  (70, 80]  (80, 90] (90, 100]
     0.047     0.116     0.274     0.450

And the trailing zero is mysteriously recovered!

Is there some general rule governing this behaviour?

Thanks, G?ran


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jul 29 16:22:58 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 29 Jul 2024 10:22:58 -0400
Subject: [R] round and trailing zero
In-Reply-To: <7cefda81-7d81-4981-bffc-825fdcd7a361@ehar.se>
References: <7cefda81-7d81-4981-bffc-825fdcd7a361@ehar.se>
Message-ID: <363bf79a-2614-48bb-ae79-4a0757df1f62@gmail.com>

On 2024-07-29 10:06 a.m., G?ran Brostr?m wrote:
> I have a "result":
> 
>   > hazards
>           (60, 70]    (70, 80]    (80, 90]   (90, 100]
> [1,] 0.046612937 0.115643783 0.273613266 0.450127975
> 
> Two issues: (i) Too many decimals, and (ii) it seems to be an 1x4
> matrix, I only need the first row. (i):
> 
>   > haz <- round(hazards, 3)
>   > haz
>        (60, 70] (70, 80] (80, 90] (90, 100]
> [1,]    0.047    0.116    0.274      0.45
> 
> As expected, the fourth element lost a trailing zero. I'll deal with
> that, but first (ii):
> 
>   > haz[1, ]
>    (60, 70]  (70, 80]  (80, 90] (90, 100]
>       0.047     0.116     0.274     0.450
> 
> And the trailing zero is mysteriously recovered!
> 
> Is there some general rule governing this behaviour?

R uses the same format for every element in each column when printing a 
matrix or dataframe, and for every element in a vector.

Your first example had only one element per column.  If you had printed 
t(haz) you'd get numbers displayed like the second version, where 
haz[1,] converts that row to a vector.

Duncan Murdoch


From gb @end|ng |rom eh@r@@e  Mon Jul 29 17:21:06 2024
From: gb @end|ng |rom eh@r@@e (=?utf-8?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Mon, 29 Jul 2024 17:21:06 +0200
Subject: [R] round and trailing zero
In-Reply-To: <363bf79a-2614-48bb-ae79-4a0757df1f62@gmail.com>
References: <363bf79a-2614-48bb-ae79-4a0757df1f62@gmail.com>
Message-ID: <2C4B38AB-EA29-4BF1-BD06-DADB3A06536C@ehar.se>

Ah, thanks,

G?ran

> 29 juli 2024 kl. 16:23 skrev Duncan Murdoch <murdoch.duncan at gmail.com>:
> 
> ?On 2024-07-29 10:06 a.m., G?ran Brostr?m wrote:
>> I have a "result":
>>  > hazards
>>          (60, 70]    (70, 80]    (80, 90]   (90, 100]
>> [1,] 0.046612937 0.115643783 0.273613266 0.450127975
>> Two issues: (i) Too many decimals, and (ii) it seems to be an 1x4
>> matrix, I only need the first row. (i):
>>  > haz <- round(hazards, 3)
>>  > haz
>>       (60, 70] (70, 80] (80, 90] (90, 100]
>> [1,]    0.047    0.116    0.274      0.45
>> As expected, the fourth element lost a trailing zero. I'll deal with
>> that, but first (ii):
>>  > haz[1, ]
>>   (60, 70]  (70, 80]  (80, 90] (90, 100]
>>      0.047     0.116     0.274     0.450
>> And the trailing zero is mysteriously recovered!
>> Is there some general rule governing this behaviour?
> 
> R uses the same format for every element in each column when printing a matrix or dataframe, and for every element in a vector.
> 
> Your first example had only one element per column.  If you had printed t(haz) you'd get numbers displayed like the second version, where haz[1,] converts that row to a vector.
> 
> Duncan Murdoch
> 


From r-m@||@ @end|ng |rom erez@h@org  Tue Jul 30 04:54:11 2024
From: r-m@||@ @end|ng |rom erez@h@org (Erez Shomron)
Date: Tue, 30 Jul 2024 05:54:11 +0300
Subject: [R] C API - no NULL pointer guarantee?
In-Reply-To: <20240729132359.555ddf03@arachnoid>
References: <8bd9238a-1d2a-4c63-8594-5516f569003e@app.fastmail.com>
 <20240729132359.555ddf03@arachnoid>
Message-ID: <71bcd586-a7b9-466d-b10e-de55dcfa147a@app.fastmail.com>

Thank you Ivan,

At this point, without it being documented explicitly, I tend to lean on the safe side.

If the non-null assumption is ever incorrect, on debug and safe builds unwrapping is an assert that will guarantee to crash R.

While the source code has plenty of NULL checks, also for some SEXP, it's hard to tell just from grepping if any are related to the public API or not.

Secondly as zig's documentation indicates: "Edge cases matter". If I'm making bindings in this language, I should care about edge cases as well.

Last but not least, thanks for sharing your WIP documentation. If you agree, I definitely can use that as a reference as I progress.

Best regards,
- Erez



On Mon, Jul 29, 2024, at 1:23 PM, Ivan Krylov wrote:
> ? Sat, 27 Jul 2024 14:36:20 +0300
> "Erez Shomron" <r-mails at erezsh.org> ?????:
> 
> > I'm working on bindings for the API (for zig), and was wondering if
> > the R's C API guarantees it won't return null pointers? The only
> > reference I found in the "Writing R Extensions" manual where this not
> > the case is `R_tryEval` and `R_tryEvalSilent`.
> 
> Based on what I've been reading while working on (still very much
> incomplete) <https://aitap.codeberg.page/R-api>, I think that these are
> the only two cases where a SEXP can be null, precisely because a null
> pointer is distinguished from every possible value that could be
> returned by eval().
> 
> Some APIs may accept a null SEXP (with comments in the source code that
> this is to support some legacy code, not the intended use), but when R
> wants to return a value, it is always allocated through the memory
> manager. A failing allocation will longjmp() away from the frame, not
> return a null pointer.
> 
> It's hard to prove a negative, though.
> 
> -- 
> Best regards,
> Ivan
> 


From @|mon@urb@nek @end|ng |rom R-project@org  Tue Jul 30 07:32:55 2024
From: @|mon@urb@nek @end|ng |rom R-project@org (Simon Urbanek)
Date: Tue, 30 Jul 2024 17:32:55 +1200
Subject: [R] C API - no NULL pointer guarantee?
In-Reply-To: <71bcd586-a7b9-466d-b10e-de55dcfa147a@app.fastmail.com>
References: <8bd9238a-1d2a-4c63-8594-5516f569003e@app.fastmail.com>
 <20240729132359.555ddf03@arachnoid>
 <71bcd586-a7b9-466d-b10e-de55dcfa147a@app.fastmail.com>
Message-ID: <80E5B2A4-799D-44EF-B5EC-54C074655D31@R-project.org>

Erez,

I think the API is very explicit about this, NULL is not an accepted input for any function taking SEXP by design. The special case of try*Eval() return values can be taken as a case where the resulting object is not actually SEXP but rather a special type which can be NULL (=failure) or SEXP. It may be even perhaps useful to declare it as a separate type to make this clearer, but I don't think it was really necessary so far. Any other cases where a SEXP value somehow escapes as NULL should be considered a bug.

Cheers,
Simon


> On 30/07/2024, at 2:54 PM, Erez Shomron <r-mails at erezsh.org> wrote:
> 
> Thank you Ivan,
> 
> At this point, without it being documented explicitly, I tend to lean on the safe side.
> 
> If the non-null assumption is ever incorrect, on debug and safe builds unwrapping is an assert that will guarantee to crash R.
> 
> While the source code has plenty of NULL checks, also for some SEXP, it's hard to tell just from grepping if any are related to the public API or not.
> 
> Secondly as zig's documentation indicates: "Edge cases matter". If I'm making bindings in this language, I should care about edge cases as well.
> 
> Last but not least, thanks for sharing your WIP documentation. If you agree, I definitely can use that as a reference as I progress.
> 
> Best regards,
> - Erez
> 
> 
> 
> On Mon, Jul 29, 2024, at 1:23 PM, Ivan Krylov wrote:
>> ? Sat, 27 Jul 2024 14:36:20 +0300
>> "Erez Shomron" <r-mails at erezsh.org> ?????:
>> 
>>> I'm working on bindings for the API (for zig), and was wondering if
>>> the R's C API guarantees it won't return null pointers? The only
>>> reference I found in the "Writing R Extensions" manual where this not
>>> the case is `R_tryEval` and `R_tryEvalSilent`.
>> 
>> Based on what I've been reading while working on (still very much
>> incomplete) <https://aitap.codeberg.page/R-api>, I think that these are
>> the only two cases where a SEXP can be null, precisely because a null
>> pointer is distinguished from every possible value that could be
>> returned by eval().
>> 
>> Some APIs may accept a null SEXP (with comments in the source code that
>> this is to support some legacy code, not the intended use), but when R
>> wants to return a value, it is always allocated through the memory
>> manager. A failing allocation will longjmp() away from the frame, not
>> return a null pointer.
>> 
>> It's hard to prove a negative, though.
>> 
>> -- 
>> Best regards,
>> Ivan
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From JH@rm@e @end|ng |rom roku@com  Tue Jul 30 17:09:21 2024
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Tue, 30 Jul 2024 15:09:21 +0000
Subject: [R] round and trailing zero
In-Reply-To: <mailman.371715.1.1722333601.38826.r-help@r-project.org>
References: <mailman.371715.1.1722333601.38826.r-help@r-project.org>
Message-ID: <BL0PR01MB4434C3CE7ABB97B459F242C5DCB02@BL0PR01MB4434.prod.exchangelabs.com>

Duncan Murdoch answered your question, but I have another. Are you going to do some computation with the rounded numbers, or are they just for display? (One thing I like about Excel is that I can change the display format of a cell without changing answers that depend on that cell.) In the latter case, why stash them in a variable? For more control of the display, consider sprintf (or a wrapper that combines sprintf with cat).

Regards,
Jorgen Harmse.


	[[alternative HTML version deleted]]


From r-m@||@ @end|ng |rom erez@h@org  Tue Jul 30 18:03:40 2024
From: r-m@||@ @end|ng |rom erez@h@org (Erez Shomron)
Date: Tue, 30 Jul 2024 19:03:40 +0300
Subject: [R] C API - no NULL pointer guarantee?
In-Reply-To: <80E5B2A4-799D-44EF-B5EC-54C074655D31@R-project.org>
References: <8bd9238a-1d2a-4c63-8594-5516f569003e@app.fastmail.com>
 <20240729132359.555ddf03@arachnoid>
 <71bcd586-a7b9-466d-b10e-de55dcfa147a@app.fastmail.com>
 <80E5B2A4-799D-44EF-B5EC-54C074655D31@R-project.org>
Message-ID: <d46c13b6-a223-4883-b0ec-3452bff52c6f@app.fastmail.com>

Thank you and I appreciate the explanation.

I will drop the optional from all but the tryEval() cases.

Thanks,
- Erez



On Tue, Jul 30, 2024, at 8:32 AM, Simon Urbanek wrote:
> Erez,
> 
> I think the API is very explicit about this, NULL is not an accepted input for any function taking SEXP by design. The special case of try*Eval() return values can be taken as a case where the resulting object is not actually SEXP but rather a special type which can be NULL (=failure) or SEXP. It may be even perhaps useful to declare it as a separate type to make this clearer, but I don't think it was really necessary so far. Any other cases where a SEXP value somehow escapes as NULL should be considered a bug.
> 
> Cheers,
> Simon
> 
> 
> > On 30/07/2024, at 2:54 PM, Erez Shomron <r-mails at erezsh.org> wrote:
> > 
> > Thank you Ivan,
> > 
> > At this point, without it being documented explicitly, I tend to lean on the safe side.
> > 
> > If the non-null assumption is ever incorrect, on debug and safe builds unwrapping is an assert that will guarantee to crash R.
> > 
> > While the source code has plenty of NULL checks, also for some SEXP, it's hard to tell just from grepping if any are related to the public API or not.
> > 
> > Secondly as zig's documentation indicates: "Edge cases matter". If I'm making bindings in this language, I should care about edge cases as well.
> > 
> > Last but not least, thanks for sharing your WIP documentation. If you agree, I definitely can use that as a reference as I progress.
> > 
> > Best regards,
> > - Erez
> > 
> > 
> > 
> > On Mon, Jul 29, 2024, at 1:23 PM, Ivan Krylov wrote:
> >> ? Sat, 27 Jul 2024 14:36:20 +0300
> >> "Erez Shomron" <r-mails at erezsh.org> ?????:
> >> 
> >>> I'm working on bindings for the API (for zig), and was wondering if
> >>> the R's C API guarantees it won't return null pointers? The only
> >>> reference I found in the "Writing R Extensions" manual where this not
> >>> the case is `R_tryEval` and `R_tryEvalSilent`.
> >> 
> >> Based on what I've been reading while working on (still very much
> >> incomplete) <https://aitap.codeberg.page/R-api>, I think that these are
> >> the only two cases where a SEXP can be null, precisely because a null
> >> pointer is distinguished from every possible value that could be
> >> returned by eval().
> >> 
> >> Some APIs may accept a null SEXP (with comments in the source code that
> >> this is to support some legacy code, not the intended use), but when R
> >> wants to return a value, it is always allocated through the memory
> >> manager. A failing allocation will longjmp() away from the frame, not
> >> return a null pointer.
> >> 
> >> It's hard to prove a negative, though.
> >> 
> >> -- 
> >> Best regards,
> >> Ivan
> >> 
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> 


From gb @end|ng |rom eh@r@@e  Tue Jul 30 20:55:11 2024
From: gb @end|ng |rom eh@r@@e (=?UTF-8?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Tue, 30 Jul 2024 20:55:11 +0200
Subject: [R] round and trailing zero
In-Reply-To: <BL0PR01MB4434C3CE7ABB97B459F242C5DCB02@BL0PR01MB4434.prod.exchangelabs.com>
References: <mailman.371715.1.1722333601.38826.r-help@r-project.org>
 <BL0PR01MB4434C3CE7ABB97B459F242C5DCB02@BL0PR01MB4434.prod.exchangelabs.com>
Message-ID: <72831bba-9da6-45bd-bfc9-cb91c9c3dec2@ehar.se>



Den 2024-07-30 kl. 17:09, skrev Jorgen Harmse:
> Duncan Murdoch answered your question, but I have another. Are you
> going to do some computation with the rounded numbers, 

Wouldn't dream of it.

> or are they just for display? 

Yes.

G,

> (One thing I like about Excel is that I can change
> the display format of a cell without changing answers that depend on
> that cell.) In the latter case, why stash them in a variable? For
> more control of the display, consider sprintf (or a wrapper that
> combines sprintf with cat).
> 
> Regards,
> 
> Jorgen Harmse.
>


From ken@knob|@uch @end|ng |rom |n@erm@|r  Wed Jul 31 14:45:06 2024
From: ken@knob|@uch @end|ng |rom |n@erm@|r (Kenneth Knoblauch)
Date: Wed, 31 Jul 2024 12:45:06 +0000
Subject: [R] cloning a graphics window
Message-ID: <31ec0bb9dadf4208bd649e6b8b2e2c81@inserm.fr>

I often want to get a graphics window that is the same size as one that I resized by hand
(because it was quicker than setting the width and height directly in dev.new)
and have sometimes resorted to using a ruler on my screen or just resize matching.

I came up with the following function that does what I want

dev.clone <- function(){
	if(is.null(dev.list())) stop("No active graphics window!")
	dev.size() |> 
		as.list() |> 
			setNames(c("width", 'height')) |> 
				do.call(dev.new, args = _ ) 
	invisible(dev.size())
}

I thought that I might be able to leverage the new %||% operator but
wasn't able to get the logic to work out as I wanted.  

I haven't found another function to do this.  dev.copy doesn't keep
the dimensions of the previous plot, but maybe there is a more
concise and direct way to achieve this that has escaped me.  
If anyone knows?

Thanks.

best,

Ken
     
  
 R version 4.4.1 Patched (2024-06-15 r86749)
Platform: x86_64-apple-darwin20
Running under: macOS Monterey 12.7.6

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.4-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: Europe/Paris
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_4.4.1 tools_4.4.1   

  ___
  Kenneth Knoblauch
 Inserm U1208
 Stem-cell and Brain Research Institute
 18 avenue du Doyen L?pine
 69500 Bron
 France
 tel: +33 (0)4 72 91 34 77
 fax: +33 (0)4 72 91 34 61
 portable: +33 (0)6 84 10 64 10
 https://sbri.fr/public-profile/63/single-member/
    

From c@buhtz m@iii@g oii posteo@jp  Wed Jul 31 13:56:55 2024
From: c@buhtz m@iii@g oii posteo@jp (c@buhtz m@iii@g oii posteo@jp)
Date: Wed, 31 Jul 2024 11:56:55 +0000
Subject: [R] Difference between stats.steps() and MuMIn.dredge() to select
 best fit model
Message-ID: <ff2e607efd2c1093cfa0f6c42a37df3e@posteo.de>

Hello,

I try to understand the different approaches how to select the best fit 
regression model.
This is not about AIC, BIC, etc. It is about the difference between the 
steps() function
(in stats package) and the dredge() function (in MuMIn) package.
I see several examples on the internet.

step() explore the model space with a step wise approach.
And dredge() try out all possible combinations of the variables.

But isn't that the same? I might have a mental block on this.

Which model (formula) would dredge() "test" that step() wouldn't?`

Thanks in advance,
Christian


