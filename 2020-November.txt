From nev||@@mo@ @end|ng |rom gm@||@com  Sun Nov  1 00:01:57 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Sun, 1 Nov 2020 10:01:57 +1100
Subject: [R] 
 [R-sig-Geo] raster::levels() not working in packaged function.
In-Reply-To: <312c6bc4-9d77-9521-71a2-1aad75b9ed6d@urjc.es>
References: <CAN9eD7=C3jeZu9yiv4u_=FpQiaihmp3puH8n86RMKyBgXZDWtA@mail.gmail.com>
 <312c6bc4-9d77-9521-71a2-1aad75b9ed6d@urjc.es>
Message-ID: <CAN9eD7=2AuQmaM5MO5EMrxJUJJBRU1+En7GYHTWOYCBg1wYT5w@mail.gmail.com>

Many thanks,

That worked, since the NAMESPACE file incudes a warning about editing it
directly I ysed the reoygen tag in the fucntion script
#' @import raster.

On Sun, 1 Nov 2020 at 00:18, Marcelino de la Cruz Rot <
marcelino.delacruz at urjc.es> wrote:

> Maybe including
>
> import(raster)
>
> or
>
> importFrom("raster", "levels")
>
> in the package NAMESPACE would help.
>
> Cheers,
>
> Marcelino
>
> El 31/10/2020 a las 13:24, nevil amos escribi?:
> > Apologies, I cannot see how to make a rero for this issue.
> >
> > I have a function that uses levels(r) tor return the RAT of a raster "r"
> > when the function is sourced from a script
> > source(".\R\function.r")
> > it works fine.
> > when the function is built into a package and sourced from there
> > library(mypackage) using the same script file to make the package
> > levels(r)[[1]]
> > the same line throws an error, as levels(myraster returns NULL
> >
> > If I modify the script to include the raster namespace:
> > raster::levels(r)[[1]]
> > Then I get the error
> >   Error: 'levels<-' is not an exported object from 'namespace:raster'
> >
> >
> > I have also tried just using levels(r) and putting raster as a depends
> > rather than an import in the DESCRIPTION file for the package, this does
> > not solve the error.
> >
> >
> > Any suggestions on how to overcome the problem?
> >
> > many thanks
> >
> > Nevil Amos
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > .
>
>
> --
> Marcelino de la Cruz Rot
> Depto. de Biolog?a y Geolog?a
> F?sica y Qu?mica Inorg?nica
> Universidad Rey Juan Carlos
> M?stoles Espa?a
>
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sun Nov  1 00:10:59 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 1 Nov 2020 12:10:59 +1300
Subject: [R] FREDR and R 3.6
In-Reply-To: <5BD4D1DB-0ADB-400D-8E77-7BBAF7117D53@me.com>
References: <f14e8dbf-9c3e-9971-8ef3-3ccdfce2bd32@meddatainc.com>
 <3069209C-ED94-4400-9ADE-289D38B8A509@me.com>
 <cbb3ade1-196c-14e9-0b60-e7c2ba04c5cd@meddatainc.com>
 <5BD4D1DB-0ADB-400D-8E77-7BBAF7117D53@me.com>
Message-ID: <CABcYAd+PAQ5VwW6e8FnUovxkwGRFzX+D-POPk-5POPgmiyBecA@mail.gmail.com>

I'm running Ubuntu 18.04 LTS and
r-base/bionic-cran35,now 3.6.3-1bionic all [installed]
3.6.3 is also the latest version in the repository.


On Fri, 30 Oct 2020 at 12:21, Marc Schwartz via R-help <r-help at r-project.org>
wrote:

>
> > On Oct 29, 2020, at 6:35 PM, H <agents at meddatainc.com> wrote:
> >
> > On 10/29/2020 01:49 PM, Marc Schwartz wrote:
> >>> On Oct 29, 2020, at 1:29 PM, H <agents at meddatainc.com> wrote:
> >>>
> >>> I tried to install the fredr package yesterday to access the data
> series hosted by the St. Louis Fed but my installation of R, version 3.6,
> tells me it is not available from a cran repository.
> >>>
> >>> I could not find any information on this on the fredr information
> package and was wondering if anyone here might know?
> >>
> >> Hi,
> >>
> >> When that happens, check the CRAN page for the package:
> >>
> >>  https://cran.r-project.org/web/packages/fredr/index.html
> >>
> >> where you will see that the package has been archived as a result of a
> lack of response by the maintainer to problems with the package.
> >>
> >> The archive link on the above page allows you to download the last
> version of the source package tarball, however, the check results for the
> package show numerous issues.
> >>
> >> You may want to contact the package maintainer (sboysel at gmail.com) to
> see what the current status of the package is, and if they plan to resolve
> the issues. If not, consider alternative approaches.
> >>
> >> You should also consider updating your R installation, as 3.6.0 is well
> over a year old at this point. 4.0.3 is the current stable release.
> >>
> >> Regards,
> >>
> >> Marc Schwartz
> >
> > Thank you. That is very surprising! I would have thought there would be
> sufficient number of users and interest enough for this important package
> that it would be maintained!
> >
> > As for R 3.6, it is the latest version in the repository for my
> operating system, CentOS/RHEL...
>
>
> Hi,
>
> On your first point, the number of users is largely irrelevant, if the
> package maintainer no longer has the interest or the time to continue to
> support it. It is possible, in that scenario, that an interested user, who
> has the time and interest, might engage in a process to take over such
> maintenance.
>
> Keep in mind that package maintainers are, in the vast majority of cases,
> volunteers. Their motivations for creating and maintaining CRAN packages
> will vary.
>
> I did a quick check and found that there are discussions in the Issues
> section of the package's Github repo:
>
>   https://github.com/sboysel/fredr
>
> that suggest that such discussions are indeed taking place. So perhaps the
> situation with CRAN will be resolved in time. Again, you should contact the
> maintainer to get a better sense of their plans and possible timeline.
>
> With respect to CentOS/RHEL, you might post to r-sig-fedora, which focuses
> on R issues on RH derived Linux distros, to see if there are any plans to
> update R for your version of the distribution:
>
>   https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>
> The R RPM maintainers, like Tom Callaway, follow that list.
>
> Regards,
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sun Nov  1 07:02:42 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 1 Nov 2020 19:02:42 +1300
Subject: [R] R: sim1000G
In-Reply-To: <CAEVpY9LOdLrCeKYQ=Y8zHK3gbwJyV-9KfOWAaHvPYHAiO5_Xtg@mail.gmail.com>
References: <CAEVpY9LOdLrCeKYQ=Y8zHK3gbwJyV-9KfOWAaHvPYHAiO5_Xtg@mail.gmail.com>
Message-ID: <CAB8pepy-zK-xG-rO2ZhvB+eboCM6LBf-Zo+nESn_F-4BEaVMBg@mail.gmail.com>

Hi Berina,

I'm not an expert on genetics.
I haven't looked at the package.
And I've only glanced at your question.
So, this is probably not the best response.

But as no one else has responded, here's some comments:

(1)

Have you checked if there's a function in the package to do what you want?
The remainder of these questions assume that you have, and the answer is no.

(2)

I'm having some difficulty following the sample size.
The initial code sets an explicit value to 3000.
But if I'm following it correctly, the object that's returned has 2000
rows, containing two 1000 row groups.
But then your question implies you want 48?

Given that the sample already contains two groups, are they relevant
to the sample you're trying to produce?
And are you wanting to take a small sample of 48 from a larger sample
of 2000, or something else?

(3)

Are the observations (not sure if that's the correct term here) in
each 1000 row group, statistically independent?
If they are, then taking a smaller sample should be relatively simple.
If they're not, then this is a much more complex question, that's
probably off-topic.

(4)

What exactly is in the data?
i.e. Could you call the str() or head() functions on the data, and
show us the results?

(5)

Is there a boolean-style variable in the data, indicating whether each
row is casual or non-casual?


B.


On Fri, Oct 30, 2020 at 10:37 PM Berina Zametica UNI
<s0bezame at uni-bonn.de> wrote:
>
> Hi,
>
> I am using the sim1000G R package to simulate data for case/control study.
> I can not figure out how to manipulate this code to be able to generate 10%
> or 50% causal SNPs in R.
>
> This is whole code provided as example on GitHub:
>
> library(sim1000G)
> vcf_file = "region-chr4-357-ANK2.vcf.gz" #nvariants = 442, ss=1000
>
> vcf = readVCF( vcf_file, maxNumberOfVariants = 442  ,min_maf =
> 0.0005,max_maf = 0.01) #lowest MAF
> dim( vcf$gt1 ) #rows represent number of variants, columns represent
> number of individuals
>
> ## Download and use full chromosome genetic map
> downloadGeneticMap(4)
> readGeneticMap(4)
>
> sample.size=3000
>
> startSimulation(vcf, totalNumberOfIndividuals = sample.size)
>
> data_sim = function(seed.num){
>
>   SIM$reset()
>
>   id = generateUnrelatedIndividuals(sample.size)
>
>   gt = retrieveGenotypes(id)
>
>
>   freq = apply(gt,2,sum)/(2*nrow(gt))
>   causal = sample(setdiff(1:ncol(gt),which(freq==0)),45)
>
>   beta.sign = rep(1,45)
>   c.value = 0.402
>   beta.abs = c.value*abs(log10(freq[causal]))
>   beta.val = beta.sign*beta.abs
>   x.bar = apply(gt[,causal],2,mean)
>   x.bar = as.matrix(x.bar)
>   beta.val = t(as.matrix(beta.val))
>   #disease prvalance = 1%
>   #beta0 = -log(99)-beta.val %*% x.bar
>   #disease prvalance = 1.5%
>   beta0 = 0-beta.val %*% x.bar
>
>   eta = beta.val %*% t(gt[,causal])
>   eta = as.vector(eta) + rep(beta0,nrow(gt))
>   prob = exp(eta)/(1+exp(eta))
>
>   genocase = rep(NA, sample.size)
>
>   set.seed(seed.num)
>   for(i in 1:sample.size){
>     genocase[i] = rbinom(1, 1, prob[i])
>   }
>   case.idx = sample(which(genocase==1),1000)
>   control.idx = sample(which(genocase==0),1000)
>
>   return(rbind(gt[case.idx,],gt[control.idx,]))
> }
>
> How I can modify code in a way that it will simulate:
> 50 % of causal SNPs** ( exmp. 24 causal variants and 24 non causal SNPs)
> 10 % of causal SNP (exmpl. 5 causal and 43 non causal SNPs)
>
> Thanks a lot for any suggestion.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From d@v|d@kepp||nger @end|ng |rom gm@||@com  Sun Nov  1 00:55:42 2020
From: d@v|d@kepp||nger @end|ng |rom gm@||@com (David Kepplinger)
Date: Sat, 31 Oct 2020 16:55:42 -0700
Subject: [R] strptime() keeps emitting warnings after establishing a handler
 with tryCatch()
Message-ID: <CAGmyFCGSHiLYBvu8ZW6u6MerJXGSBUFbfxrXra8FHX8yz_htww@mail.gmail.com>

Dear list members,

I have come about a peculiar behavior in R (4.0.2) which I would
describe as a bug.
On macOS, where `strptime()` raises a warning for invalid timezone
identifiers, the following code will continue to raise the original
warning with every subsequent call to `strptime()`:

```
# attach a handler for warnings for this call only:
tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz =
'Wrong Timezone!'),
                  warning = function (w) { stop("Error") })
# but every subsequent call will emit the original warning ("unknown
timezone 'Wrong Timezone!'")
strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
```

The output of the code above in R 4.0.2 on macOS is:

> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!'),
+                   warning = function (w) { stop("Error") })
Error in value[[3L]](cond) : Error
>
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
[1] "2020-10-31 18:30:00 CET"
Warning message:
In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz =
"Europe/Vienna") :
  unknown timezone 'Wrong Timezone!'
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
[1] "2020-10-31 18:30:00 GMT"
Warning messages:
1: In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz = "GMT") :
  unknown timezone 'Wrong Timezone!'

The corresponding R session info is:

> sessionInfo()
R version 4.0.2 Patched (2020-07-13 r78838)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.7

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.2


I get the same odd behavior when attaching calling handlers with
`withCallingHandlers()`.
On RHEL 7 and Cent OS 6, which both don't issue warnings for invalid
timezones, the above code works.

I don't see anything wrong with the code itself, but maybe I am
missing something. Any input would be appreciated.

Best wishes,
David


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Nov  1 18:51:02 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 1 Nov 2020 17:51:02 +0000
Subject: [R] 
 strptime() keeps emitting warnings after establishing a handler
 with tryCatch()
In-Reply-To: <CAGmyFCGSHiLYBvu8ZW6u6MerJXGSBUFbfxrXra8FHX8yz_htww@mail.gmail.com>
References: <CAGmyFCGSHiLYBvu8ZW6u6MerJXGSBUFbfxrXra8FHX8yz_htww@mail.gmail.com>
Message-ID: <65f5fea0-97bc-47a6-a7b7-dbc23c544e6b@sapo.pt>

Hello,

I cannot reproduce this behavior and, as documented, the posted code 
doesn't issue warnings due to a wrong timezone but I'm running


sessionInfo()
R version 4.0.3 (2020-10-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.1 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
  [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
  [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.3


Hope this helps,

Rui Barradas

?s 23:55 de 31/10/20, David Kepplinger escreveu:
> Dear list members,
> 
> I have come about a peculiar behavior in R (4.0.2) which I would
> describe as a bug.
> On macOS, where `strptime()` raises a warning for invalid timezone
> identifiers, the following code will continue to raise the original
> warning with every subsequent call to `strptime()`:
> 
> ```
> # attach a handler for warnings for this call only:
> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz =
> 'Wrong Timezone!'),
>                    warning = function (w) { stop("Error") })
> # but every subsequent call will emit the original warning ("unknown
> timezone 'Wrong Timezone!'")
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
> ```
> 
> The output of the code above in R 4.0.2 on macOS is:
> 
>> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!'),
> +                   warning = function (w) { stop("Error") })
> Error in value[[3L]](cond) : Error
>>
>> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
> [1] "2020-10-31 18:30:00 CET"
> Warning message:
> In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz =
> "Europe/Vienna") :
>    unknown timezone 'Wrong Timezone!'
>> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
> [1] "2020-10-31 18:30:00 GMT"
> Warning messages:
> 1: In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz = "GMT") :
>    unknown timezone 'Wrong Timezone!'
> 
> The corresponding R session info is:
> 
>> sessionInfo()
> R version 4.0.2 Patched (2020-07-13 r78838)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Catalina 10.15.7
> 
> Matrix products: default
> BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
> LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.0.2
> 
> 
> I get the same odd behavior when attaching calling handlers with
> `withCallingHandlers()`.
> On RHEL 7 and Cent OS 6, which both don't issue warnings for invalid
> timezones, the above code works.
> 
> I don't see anything wrong with the code itself, but maybe I am
> missing something. Any input would be appreciated.
> 
> Best wishes,
> David
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sun Nov  1 21:16:41 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sun, 1 Nov 2020 14:16:41 -0600
Subject: [R] analyzing results from Tuesday's US elections
Message-ID: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>

Hello:


       What can you tell me about plans to analyze data from this year's 
general election, especially to detect possible fraud?


       I might be able to help with such an effort.  I have NOT done 
much with election data, but I have developed tools for data analysis, 
including web scraping, and included them in R packages available on the 
Comprehensive R Archive Network (CRAN) and GitHub.[1]


       Penny Abernathy, who holds the Knight Chair in Journalism and 
Digital Media Economics at UNC-Chapel Hill, told me that the electoral 
fraud that disqualified the official winner from NC-09 to the US House 
in 2018 was detected by a college prof, who accessed the data two weeks 
after the election.[2]


       Spencer Graves


[1]
https://github.com/sbgraves237


[2]
https://en.wikiversity.org/wiki/Local_Journalism_Sustainability_Act


From d@v|d@kepp||nger @end|ng |rom gm@||@com  Sun Nov  1 19:34:42 2020
From: d@v|d@kepp||nger @end|ng |rom gm@||@com (David Kepplinger)
Date: Sun, 1 Nov 2020 10:34:42 -0800
Subject: [R] 
 strptime() keeps emitting warnings after establishing a handler
 with tryCatch()
In-Reply-To: <65f5fea0-97bc-47a6-a7b7-dbc23c544e6b@sapo.pt>
References: <CAGmyFCGSHiLYBvu8ZW6u6MerJXGSBUFbfxrXra8FHX8yz_htww@mail.gmail.com>
 <65f5fea0-97bc-47a6-a7b7-dbc23c544e6b@sapo.pt>
Message-ID: <CAGmyFCG3Z0aT=45_aoS2Kh-8tPhJEFheCy7jdisoVOWTbsem6g@mail.gmail.com>

Thanks, Rui, for checking on your end. I don't think any Linux-based
system is affected, as they silently ignore invalid timezone
identifiers (at least the versions I know of).

I now also had a chance to test on Windows 10 and get the same errors
as under macOS. The session info for this test is

> sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19041)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.2

I also tested a bit more and it seems that attaching handlers really
messes up `strptime()`. For example, `strptime()` stops to emit any
warning for invalid timezone identifiers:

> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!'),
+                   warning = function (w) { stop("Error") })
Error in value[[3L]](cond) : Error
> # The following calls with a wrong timezone identifier don't emit any warnings anymore?!
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!')
[1] "2020-10-31 18:30:00"

But a subsequent call to `strptime()` with a valid timezone identifier
does emit the original warning (continuing the R session from above):

> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
[1] "2020-10-31 18:30:00 GMT"
Warning messages:
1: In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz = "GMT") :
  unknown timezone 'Wrong Timezone!'

And the next call with an incorrect tz identifier, doesn't emit a
warning, but uses the timezone from the previous call (continuing the
R session as above):

> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!')
[1] "2020-10-31 18:30:00 GMT"

Best wishes,
David


On Sun, Nov 1, 2020 at 9:51 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> I cannot reproduce this behavior and, as documented, the posted code
> doesn't issue warnings due to a wrong timezone but I'm running
>
>
> sessionInfo()
> R version 4.0.3 (2020-10-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.1 LTS
>
> Matrix products: default
> BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0
>
> locale:
>   [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
>   [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
>   [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.3
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 23:55 de 31/10/20, David Kepplinger escreveu:
> > Dear list members,
> >
> > I have come about a peculiar behavior in R (4.0.2) which I would
> > describe as a bug.
> > On macOS, where `strptime()` raises a warning for invalid timezone
> > identifiers, the following code will continue to raise the original
> > warning with every subsequent call to `strptime()`:
> >
> > ```
> > # attach a handler for warnings for this call only:
> > tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz =
> > 'Wrong Timezone!'),
> >                    warning = function (w) { stop("Error") })
> > # but every subsequent call will emit the original warning ("unknown
> > timezone 'Wrong Timezone!'")
> > strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
> > strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
> > ```
> >
> > The output of the code above in R 4.0.2 on macOS is:
> >
> >> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!'),
> > +                   warning = function (w) { stop("Error") })
> > Error in value[[3L]](cond) : Error
> >>
> >> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
> > [1] "2020-10-31 18:30:00 CET"
> > Warning message:
> > In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz =
> > "Europe/Vienna") :
> >    unknown timezone 'Wrong Timezone!'
> >> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
> > [1] "2020-10-31 18:30:00 GMT"
> > Warning messages:
> > 1: In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz = "GMT") :
> >    unknown timezone 'Wrong Timezone!'
> >
> > The corresponding R session info is:
> >
> >> sessionInfo()
> > R version 4.0.2 Patched (2020-07-13 r78838)
> > Platform: x86_64-apple-darwin17.0 (64-bit)
> > Running under: macOS Catalina 10.15.7
> >
> > Matrix products: default
> > BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
> > LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] compiler_4.0.2
> >
> >
> > I get the same odd behavior when attaching calling handlers with
> > `withCallingHandlers()`.
> > On RHEL 7 and Cent OS 6, which both don't issue warnings for invalid
> > timezones, the above code works.
> >
> > I don't see anything wrong with the code itself, but maybe I am
> > missing something. Any input would be appreciated.
> >
> > Best wishes,
> > David
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From h@nn@hv@n|mpe @end|ng |rom out|ook@com  Mon Nov  2 14:56:20 2020
From: h@nn@hv@n|mpe @end|ng |rom out|ook@com (Hannah Van Impe)
Date: Mon, 2 Nov 2020 13:56:20 +0000
Subject: [R] Error: vector memory exhausted (limit reached?)
Message-ID: <C4E152D0-1EAA-4616-B045-E4E76BB329D9@outlook.com>

Hello

I have a question about the error: vector memory exhausted (limit reached?). I have the R-studio version 4.0.3 (2020-10-10). 
I have a MacBook Air (13-inch, 2017). I am trying to open a dataset file ?data_dta? through the import dataset ?file from stata? button. 
I already did this with other datasets, and this works fine. Now, I want to work with a bigger dataset of 4.08 GB. When I try to open the dataset, I get this error: vector memory exhausted (limit reached?). 
What can I do about this? I still have 25 GB available on my laptop. 

Thank you very much
Hannah Van Impe

From gob@@|||ngrud @end|ng |rom gm@||@com  Mon Nov  2 18:28:59 2020
From: gob@@|||ngrud @end|ng |rom gm@||@com (Gordon Ballingrud)
Date: Mon, 2 Nov 2020 12:28:59 -0500
Subject: [R] help loading files into R for koRpus analysis
Message-ID: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>

Hello all,



I need some help with loading text-file data into R for analysis with
packages like koRpus.



The problem I am facing is getting R to recognize a folder full of Word
files (about 4,000) as data which I can then make koRpus perform analyses
like Coleman-Liau indexing. If at all possible, I prefer to make this work
with Word files. The key problem is the struggle to cause R to recognize
the text (Word) files in bulk (that is, all at the same time) so that
koRpus can do its thing with those files.



My attempts to make this work have all been in vain, but I know that
packages like koRpus would be limited in usefulness if there were no way to
get the package to do its work on a large collection of files all at once.



I hope this problem will make sense to someone, and that there is a tenable
solution to it.



Thanks,

Gordon

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov  2 21:15:28 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 2 Nov 2020 15:15:28 -0500
Subject: [R] help loading files into R for koRpus analysis
In-Reply-To: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>
References: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>
Message-ID: <8957a8f6-c550-5c4e-8964-9318ed6aa71d@gmail.com>

You may get a helpful response, but if not, I'd suggest posting code you 
have to read one file.  Then lots of people could likely show you how to 
modify it to read all 4000 files.

Duncan Murdoch

On 02/11/2020 12:28 p.m., Gordon Ballingrud wrote:
> Hello all,
> 
> 
> 
> I need some help with loading text-file data into R for analysis with
> packages like koRpus.
> 
> 
> 
> The problem I am facing is getting R to recognize a folder full of Word
> files (about 4,000) as data which I can then make koRpus perform analyses
> like Coleman-Liau indexing. If at all possible, I prefer to make this work
> with Word files. The key problem is the struggle to cause R to recognize
> the text (Word) files in bulk (that is, all at the same time) so that
> koRpus can do its thing with those files.
> 
> 
> 
> My attempts to make this work have all been in vain, but I know that
> packages like koRpus would be limited in usefulness if there were no way to
> get the package to do its work on a large collection of files all at once.
> 
> 
> 
> I hope this problem will make sense to someone, and that there is a tenable
> solution to it.
> 
> 
> 
> Thanks,
> 
> Gordon
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Mon Nov  2 21:16:41 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Mon, 2 Nov 2020 15:16:41 -0500
Subject: [R] Error: vector memory exhausted (limit reached?)
In-Reply-To: <C4E152D0-1EAA-4616-B045-E4E76BB329D9@outlook.com>
References: <C4E152D0-1EAA-4616-B045-E4E76BB329D9@outlook.com>
Message-ID: <CAJc=yOEpvYq-P0z=mzpMK-oZeXQdvg2ZbJ-PDEi4kiMLsCmqDw@mail.gmail.com>

The error probably means what it says. I'm guessing "25 GB available"
is on the hard drive. But the issue is the data must be held in RAM,
and a file >4GB (before de-compression) is quite a lot of RAM on
laptop scales.

Try taking a subset of the data in Stata before importing?

Pat


On Mon, Nov 2, 2020 at 3:09 PM Hannah Van Impe
<hannahvanimpe at outlook.com> wrote:
>
> Hello
>
> I have a question about the error: vector memory exhausted (limit reached?). I have the R-studio version 4.0.3 (2020-10-10).
> I have a MacBook Air (13-inch, 2017). I am trying to open a dataset file ?data_dta? through the import dataset ?file from stata? button.
> I already did this with other datasets, and this works fine. Now, I want to work with a bigger dataset of 4.08 GB. When I try to open the dataset, I get this error: vector memory exhausted (limit reached?).
> What can I do about this? I still have 25 GB available on my laptop.
>
> Thank you very much
> Hannah Van Impe
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Mon Nov  2 21:27:49 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Mon, 2 Nov 2020 15:27:49 -0500
Subject: [R] Error: vector memory exhausted (limit reached?)
In-Reply-To: <293F477F-2475-4AB7-943B-63048D21D54A@outlook.com>
References: <C4E152D0-1EAA-4616-B045-E4E76BB329D9@outlook.com>
 <CAJc=yOEpvYq-P0z=mzpMK-oZeXQdvg2ZbJ-PDEi4kiMLsCmqDw@mail.gmail.com>
 <293F477F-2475-4AB7-943B-63048D21D54A@outlook.com>
Message-ID: <CAJc=yOEM=0sqx8zErs0Hghae=LSrprAbS_X79o_Md3gp=Mwujw@mail.gmail.com>

Re-looping R-help. My error.

Hannah, I can't tell you how much RAM your computer has, certainly not how
much is free for R's use.  Just that you are  probably not going to be able
to load a dataset that Large into a 2017 MacBook.

On Mon, Nov 2, 2020, 3:20 PM Hannah Van Impe <hannahvanimpe at outlook.com>
wrote:

> Thank you very much,
> would it be possible to merge multiple smaller datasets into this one
> dataset?
> How much RAM would be possible for one dataset on laptop scales?
> I need to work with this data for the university, so it would be best if I
> could work with the whole dataset.
> Thank you!
>
> > Op 2 nov. 2020, om 21:16 heeft Patrick (Malone Quantitative) <
> malone at malonequantitative.com> het volgende geschreven:
> >
> > The error probably means what it says. I'm guessing "25 GB available"
> > is on the hard drive. But the issue is the data must be held in RAM,
> > and a file >4GB (before de-compression) is quite a lot of RAM on
> > laptop scales.
> >
> > Try taking a subset of the data in Stata before importing?
> >
> > Pat
> >
> >
> > On Mon, Nov 2, 2020 at 3:09 PM Hannah Van Impe
> > <hannahvanimpe at outlook.com> wrote:
> >>
> >> Hello
> >>
> >> I have a question about the error: vector memory exhausted (limit
> reached?). I have the R-studio version 4.0.3 (2020-10-10).
> >> I have a MacBook Air (13-inch, 2017). I am trying to open a dataset
> file ?data_dta? through the import dataset ?file from stata? button.
> >> I already did this with other datasets, and this works fine. Now, I
> want to work with a bigger dataset of 4.08 GB. When I try to open the
> dataset, I get this error: vector memory exhausted (limit reached?).
> >> What can I do about this? I still have 25 GB available on my laptop.
> >>
> >> Thank you very much
> >> Hannah Van Impe
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Patrick S. Malone, Ph.D., Malone Quantitative
> > NEW Service Models: http://malonequantitative.com
> >
> > He/Him/His
>
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Nov  3 01:43:10 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 2 Nov 2020 19:43:10 -0500
Subject: [R] help loading files into R for koRpus analysis
In-Reply-To: <CAJ6CFDshmrSd7NEvOxz+L_ASbnyXLX08pGdd4YS3EtmEkf9tHg@mail.gmail.com>
References: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>
 <8957a8f6-c550-5c4e-8964-9318ed6aa71d@gmail.com>
 <CAJ6CFDshmrSd7NEvOxz+L_ASbnyXLX08pGdd4YS3EtmEkf9tHg@mail.gmail.com>
Message-ID: <5e5fdad1-f80b-5275-35e6-a80c83c2e0ee@gmail.com>

On 02/11/2020 4:46 p.m., Gordon Ballingrud wrote:
> Thanks; that's a good point. Here is what I have been working with:
> 
> library(quanteda)
> library(readtext)
> 
> texts <- readtext(paste0("/Users/Gordon/Desktop/WPSCASES/", "/word/*.docx"))

On Windows, you can't have an empty entry in a pathname, so you should 
leave off one of the slashes:

   texts <- readtext(paste0("/Users/Gordon/Desktop/WPSCASES/", 
"word/*.docx"))

You could skip the paste0 entirely, and use

   texts <- readtext("/Users/Gordon/Desktop/WPSCASES/word/*.docx")

but I'm assuming this is just an example of a more complex situation.

Duncan Murdoch

> 
> And the error message:
> Error in list_files(file, ignore_missing, TRUE, verbosity) :
>  ? File '' does not exist.
> 
> 
> On Mon, Nov 2, 2020 at 3:15 PM Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     You may get a helpful response, but if not, I'd suggest posting code
>     you
>     have to read one file.? Then lots of people could likely show you
>     how to
>     modify it to read all 4000 files.
> 
>     Duncan Murdoch
> 
>     On 02/11/2020 12:28 p.m., Gordon Ballingrud wrote:
>      > Hello all,
>      >
>      >
>      >
>      > I need some help with loading text-file data into R for analysis with
>      > packages like koRpus.
>      >
>      >
>      >
>      > The problem I am facing is getting R to recognize a folder full
>     of Word
>      > files (about 4,000) as data which I can then make koRpus perform
>     analyses
>      > like Coleman-Liau indexing. If at all possible, I prefer to make
>     this work
>      > with Word files. The key problem is the struggle to cause R to
>     recognize
>      > the text (Word) files in bulk (that is, all at the same time) so that
>      > koRpus can do its thing with those files.
>      >
>      >
>      >
>      > My attempts to make this work have all been in vain, but I know that
>      > packages like koRpus would be limited in usefulness if there were
>     no way to
>      > get the package to do its work on a large collection of files all
>     at once.
>      >
>      >
>      >
>      > I hope this problem will make sense to someone, and that there is
>     a tenable
>      > solution to it.
>      >
>      >
>      >
>      > Thanks,
>      >
>      > Gordon
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From c||ve||@t@ @end|ng |rom goog|em@||@com  Tue Nov  3 02:14:46 2020
From: c||ve||@t@ @end|ng |rom goog|em@||@com (Clive Nicholas)
Date: Tue, 3 Nov 2020 01:14:46 +0000
Subject: [R] Query on constrained regressions using -mgcv- and -pcls-
Message-ID: <CAHs5aTis_z1NPHtzkUr6rTK0m1NeEvMbMkkg10rTz1vLVYQqOA@mail.gmail.com>

Hello all,

I'll level with you: I'm puzzled!

How is it that this constrained regression routine using -pcls- runs
satisfactorily (courtesy of Tian Zheng):

library(mgcv)
options(digits=3)
x.1=rnorm(100, 0, 1)
x.2=rnorm(100, 0, 1)
x.3=rnorm(100, 0, 1)
x.4=rnorm(100, 0, 1)
y=1+0.5*x.1-0.2*x.2+0.3*x.3+0.1*x.4+rnorm(100, 0, 0.01)
x.mat=cbind(rep(1, length(y)), x.1, x.2, x.3, x.4)
ls.print(lsfit(x.mat, y, intercept=FALSE))
M=list(y=y,
w=rep(1, length(y)),
X=x.mat,
C=matrix(0,0,0),
p=rep(1, ncol(x.mat)),
off=array(0,0),
S=list(),
sp=array(0,0),
Ain=diag(ncol(x.mat)),
bin=rep(0, ncol(x.mat)) )
pcls(M)
Residual Standard Error=0.0095
R-Square=1
F-statistic (df=5, 95)=314735
p-value=0

    Estimate Std.Err t-value Pr(>|t|)
       1.000  0.0010  1043.9        0
x.1    0.501  0.0010   512.6        0
x.2   -0.202  0.0009  -231.6        0
x.3    0.298  0.0010   297.8        0
x.4    0.103  0.0011    94.8        0

but this one does not for a panel dataset:

set.seed(02102020)
N=500
M=10
rater=rep(1:M, each = N)
lead_n=as.factor(rep(1:N,M))
a=rep(rnorm(N),M)
z=rep(round(25+2*rnorm(N)+.2*a))
x=a+rnorm(N*M)
y=.5*x+5*a-.5*z+2*rnorm(N*M)
x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
model=lm(y~x+x_cl+z)
summary(model)
y=1+1.5*x+4.6*x_cl-0.5*z
x.mat=cbind(rep(1,length(y)),x,x_cl,z)
ls.print(lsfit(x.mat,y,intercept=FALSE))

Residual Standard Error=0
R-Square=1
F-statistic (df=4, 4996)=5.06e+30
p-value=0

     Estimate Std.Err   t-value Pr(>|t|)
          1.0       0  2.89e+13        0
x         0.8       0  2.71e+14        0
x_cl      4.6       0  1.18e+15        0
z        -0.5       0 -3.63e+14        0

?

There shouldn't be anything wrong with the second set of data, unless I've
missed something obvious (that constraints don't work for panel data? Seems
unlikely to me)!

Also:

(1) I'm ultimately looking just to constrain ONE coefficient whilst
allowing the other coefficients to be unconstrained (I tried this with the
first dataset by setting

y=1+0.5*x.1-x.2+x.3+x.4

in the call, but got similar-looking output to what I got in the second
dataset); and

(2) it would be really useful to have the call to -pcls(M)- produce more
informative output (SEs, t-values, fit stats, etc).

Many thanks in anticipation of your expert help and being told what a
clueless berk I am,
Clive

-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

	[[alternative HTML version deleted]]


From gob@@|||ngrud @end|ng |rom gm@||@com  Mon Nov  2 22:46:59 2020
From: gob@@|||ngrud @end|ng |rom gm@||@com (Gordon Ballingrud)
Date: Mon, 2 Nov 2020 16:46:59 -0500
Subject: [R] help loading files into R for koRpus analysis
In-Reply-To: <8957a8f6-c550-5c4e-8964-9318ed6aa71d@gmail.com>
References: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>
 <8957a8f6-c550-5c4e-8964-9318ed6aa71d@gmail.com>
Message-ID: <CAJ6CFDshmrSd7NEvOxz+L_ASbnyXLX08pGdd4YS3EtmEkf9tHg@mail.gmail.com>

Thanks; that's a good point. Here is what I have been working with:

library(quanteda)
library(readtext)

texts <- readtext(paste0("/Users/Gordon/Desktop/WPSCASES/", "/word/*.docx"))

And the error message:
Error in list_files(file, ignore_missing, TRUE, verbosity) :
  File '' does not exist.


On Mon, Nov 2, 2020 at 3:15 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> You may get a helpful response, but if not, I'd suggest posting code you
> have to read one file.  Then lots of people could likely show you how to
> modify it to read all 4000 files.
>
> Duncan Murdoch
>
> On 02/11/2020 12:28 p.m., Gordon Ballingrud wrote:
> > Hello all,
> >
> >
> >
> > I need some help with loading text-file data into R for analysis with
> > packages like koRpus.
> >
> >
> >
> > The problem I am facing is getting R to recognize a folder full of Word
> > files (about 4,000) as data which I can then make koRpus perform analyses
> > like Coleman-Liau indexing. If at all possible, I prefer to make this
> work
> > with Word files. The key problem is the struggle to cause R to recognize
> > the text (Word) files in bulk (that is, all at the same time) so that
> > koRpus can do its thing with those files.
> >
> >
> >
> > My attempts to make this work have all been in vain, but I know that
> > packages like koRpus would be limited in usefulness if there were no way
> to
> > get the package to do its work on a large collection of files all at
> once.
> >
> >
> >
> > I hope this problem will make sense to someone, and that there is a
> tenable
> > solution to it.
> >
> >
> >
> > Thanks,
> >
> > Gordon
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From c||ve||@t@ @end|ng |rom goog|em@||@com  Tue Nov  3 06:28:09 2020
From: c||ve||@t@ @end|ng |rom goog|em@||@com (Clive Nicholas)
Date: Tue, 3 Nov 2020 05:28:09 +0000
Subject: [R] Query on constrained regressions using -mgcv- and -pcls-
In-Reply-To: <CAHs5aTis_z1NPHtzkUr6rTK0m1NeEvMbMkkg10rTz1vLVYQqOA@mail.gmail.com>
References: <CAHs5aTis_z1NPHtzkUr6rTK0m1NeEvMbMkkg10rTz1vLVYQqOA@mail.gmail.com>
Message-ID: <CAHs5aTi-D+JVf3vtbhn=hEDGgKdSA3wK72nd-_7hotSuBa9ztQ@mail.gmail.com>

As an addendum / erratum to my original post, the second block of code
should read for completeness:

set.seed(02102020)
N=500
M=10
rater=rep(1:M, each = N)
lead_n=as.factor(rep(1:N,M))
a=rep(rnorm(N),M)
z=rep(round(25+2*rnorm(N)+.2*a))
x=a+rnorm(N*M)
y=.5*x+5*a-.5*z+2*rnorm(N*M)
x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
model=lm(y~x+x_cl+z)
summary(model)
y=1+1.5*x+4.6*x_cl-0.5*z
x.mat=cbind(rep(1,length(y)),x,x_cl,z)
ls.print(lsfit(x.mat,y,intercept=FALSE))
M=list(y=y,
w=rep(1, length(y)),
X=x.mat,
C=matrix(0,0,0),
p=rep(1, ncol(x.mat)),
off=array(0,0),
S=list(),
sp=array(0,0),
Ain=diag(ncol(x.mat)),
bin=rep(0, ncol(x.mat)) )
pcls(M)

However, all my questions stand.

Ta, Clive

On Tue, 3 Nov 2020 at 01:14, Clive Nicholas <clivelists at googlemail.com>
wrote:

> Hello all,
>
> I'll level with you: I'm puzzled!
>
> How is it that this constrained regression routine using -pcls- runs
> satisfactorily (courtesy of Tian Zheng):
>
> library(mgcv)
> options(digits=3)
> x.1=rnorm(100, 0, 1)
> x.2=rnorm(100, 0, 1)
> x.3=rnorm(100, 0, 1)
> x.4=rnorm(100, 0, 1)
> y=1+0.5*x.1-0.2*x.2+0.3*x.3+0.1*x.4+rnorm(100, 0, 0.01)
> x.mat=cbind(rep(1, length(y)), x.1, x.2, x.3, x.4)
> ls.print(lsfit(x.mat, y, intercept=FALSE))
> M=list(y=y,
> w=rep(1, length(y)),
> X=x.mat,
> C=matrix(0,0,0),
> p=rep(1, ncol(x.mat)),
> off=array(0,0),
> S=list(),
> sp=array(0,0),
> Ain=diag(ncol(x.mat)),
> bin=rep(0, ncol(x.mat)) )
> pcls(M)
> Residual Standard Error=0.0095
> R-Square=1
> F-statistic (df=5, 95)=314735
> p-value=0
>
>     Estimate Std.Err t-value Pr(>|t|)
>        1.000  0.0010  1043.9        0
> x.1    0.501  0.0010   512.6        0
> x.2   -0.202  0.0009  -231.6        0
> x.3    0.298  0.0010   297.8        0
> x.4    0.103  0.0011    94.8        0
>
> but this one does not for a panel dataset:
>
> set.seed(02102020)
> N=500
> M=10
> rater=rep(1:M, each = N)
> lead_n=as.factor(rep(1:N,M))
> a=rep(rnorm(N),M)
> z=rep(round(25+2*rnorm(N)+.2*a))
> x=a+rnorm(N*M)
> y=.5*x+5*a-.5*z+2*rnorm(N*M)
> x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
> model=lm(y~x+x_cl+z)
> summary(model)
> y=1+1.5*x+4.6*x_cl-0.5*z
> x.mat=cbind(rep(1,length(y)),x,x_cl,z)
> ls.print(lsfit(x.mat,y,intercept=FALSE))
>
> Residual Standard Error=0
> R-Square=1
> F-statistic (df=4, 4996)=5.06e+30
> p-value=0
>
>      Estimate Std.Err   t-value Pr(>|t|)
>           1.0       0  2.89e+13        0
> x         0.8       0  2.71e+14        0
> x_cl      4.6       0  1.18e+15        0
> z        -0.5       0 -3.63e+14        0
>
> ?
>
> There shouldn't be anything wrong with the second set of data, unless I've
> missed something obvious (that constraints don't work for panel data? Seems
> unlikely to me)!
>
> Also:
>
> (1) I'm ultimately looking just to constrain ONE coefficient whilst
> allowing the other coefficients to be unconstrained (I tried this with the
> first dataset by setting
>
> y=1+0.5*x.1-x.2+x.3+x.4
>
> in the call, but got similar-looking output to what I got in the second
> dataset); and
>
> (2) it would be really useful to have the call to -pcls(M)- produce more
> informative output (SEs, t-values, fit stats, etc).
>
> Many thanks in anticipation of your expert help and being told what a
> clueless berk I am,
> Clive
>
> --
> Clive Nicholas
>
> "My colleagues in the social sciences talk a great deal about methodology.
> I prefer to call it style." -- Freeman J. Dyson
>


-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Nov  3 07:18:40 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 2 Nov 2020 22:18:40 -0800
Subject: [R] Query on constrained regressions using -mgcv- and -pcls-
In-Reply-To: <CAHs5aTi-D+JVf3vtbhn=hEDGgKdSA3wK72nd-_7hotSuBa9ztQ@mail.gmail.com>
References: <CAHs5aTis_z1NPHtzkUr6rTK0m1NeEvMbMkkg10rTz1vLVYQqOA@mail.gmail.com>
 <CAHs5aTi-D+JVf3vtbhn=hEDGgKdSA3wK72nd-_7hotSuBa9ztQ@mail.gmail.com>
Message-ID: <CAGxFJbS669NLsjFCBOLLup3z+-s5u45RvspU92aY=-9kEEDzdg@mail.gmail.com>

Warning: I did *not* attempt to follow your query(original or addendum) in
detail. But as you have not yet received a reply, it may be because your
post seems mostly about statistical issues, which are generally off topic
here. This list is primarily about R programming issues. If statistical
issues are your primary focus, SO may be a better place to post:
https://stats.stackexchange.com/

Otherwise, I guess you'll just have to continue waiting.

Incidentally, suggestions for improvements in nonstandard packages should
generally be sent to the package maintainer (?maintainer) rather than
posted here. Maintainers may not even check this list.

Finally, this is a plain text list. HTML posts often get mangled by the
server.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 2, 2020 at 9:28 PM Clive Nicholas via R-help <
r-help at r-project.org> wrote:

> As an addendum / erratum to my original post, the second block of code
> should read for completeness:
>
> set.seed(02102020)
> N=500
> M=10
> rater=rep(1:M, each = N)
> lead_n=as.factor(rep(1:N,M))
> a=rep(rnorm(N),M)
> z=rep(round(25+2*rnorm(N)+.2*a))
> x=a+rnorm(N*M)
> y=.5*x+5*a-.5*z+2*rnorm(N*M)
> x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
> model=lm(y~x+x_cl+z)
> summary(model)
> y=1+1.5*x+4.6*x_cl-0.5*z
> x.mat=cbind(rep(1,length(y)),x,x_cl,z)
> ls.print(lsfit(x.mat,y,intercept=FALSE))
> M=list(y=y,
> w=rep(1, length(y)),
> X=x.mat,
> C=matrix(0,0,0),
> p=rep(1, ncol(x.mat)),
> off=array(0,0),
> S=list(),
> sp=array(0,0),
> Ain=diag(ncol(x.mat)),
> bin=rep(0, ncol(x.mat)) )
> pcls(M)
>
> However, all my questions stand.
>
> Ta, Clive
>
> On Tue, 3 Nov 2020 at 01:14, Clive Nicholas <clivelists at googlemail.com>
> wrote:
>
> > Hello all,
> >
> > I'll level with you: I'm puzzled!
> >
> > How is it that this constrained regression routine using -pcls- runs
> > satisfactorily (courtesy of Tian Zheng):
> >
> > library(mgcv)
> > options(digits=3)
> > x.1=rnorm(100, 0, 1)
> > x.2=rnorm(100, 0, 1)
> > x.3=rnorm(100, 0, 1)
> > x.4=rnorm(100, 0, 1)
> > y=1+0.5*x.1-0.2*x.2+0.3*x.3+0.1*x.4+rnorm(100, 0, 0.01)
> > x.mat=cbind(rep(1, length(y)), x.1, x.2, x.3, x.4)
> > ls.print(lsfit(x.mat, y, intercept=FALSE))
> > M=list(y=y,
> > w=rep(1, length(y)),
> > X=x.mat,
> > C=matrix(0,0,0),
> > p=rep(1, ncol(x.mat)),
> > off=array(0,0),
> > S=list(),
> > sp=array(0,0),
> > Ain=diag(ncol(x.mat)),
> > bin=rep(0, ncol(x.mat)) )
> > pcls(M)
> > Residual Standard Error=0.0095
> > R-Square=1
> > F-statistic (df=5, 95)=314735
> > p-value=0
> >
> >     Estimate Std.Err t-value Pr(>|t|)
> >        1.000  0.0010  1043.9        0
> > x.1    0.501  0.0010   512.6        0
> > x.2   -0.202  0.0009  -231.6        0
> > x.3    0.298  0.0010   297.8        0
> > x.4    0.103  0.0011    94.8        0
> >
> > but this one does not for a panel dataset:
> >
> > set.seed(02102020)
> > N=500
> > M=10
> > rater=rep(1:M, each = N)
> > lead_n=as.factor(rep(1:N,M))
> > a=rep(rnorm(N),M)
> > z=rep(round(25+2*rnorm(N)+.2*a))
> > x=a+rnorm(N*M)
> > y=.5*x+5*a-.5*z+2*rnorm(N*M)
> > x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
> > model=lm(y~x+x_cl+z)
> > summary(model)
> > y=1+1.5*x+4.6*x_cl-0.5*z
> > x.mat=cbind(rep(1,length(y)),x,x_cl,z)
> > ls.print(lsfit(x.mat,y,intercept=FALSE))
> >
> > Residual Standard Error=0
> > R-Square=1
> > F-statistic (df=4, 4996)=5.06e+30
> > p-value=0
> >
> >      Estimate Std.Err   t-value Pr(>|t|)
> >           1.0       0  2.89e+13        0
> > x         0.8       0  2.71e+14        0
> > x_cl      4.6       0  1.18e+15        0
> > z        -0.5       0 -3.63e+14        0
> >
> > ?
> >
> > There shouldn't be anything wrong with the second set of data, unless
> I've
> > missed something obvious (that constraints don't work for panel data?
> Seems
> > unlikely to me)!
> >
> > Also:
> >
> > (1) I'm ultimately looking just to constrain ONE coefficient whilst
> > allowing the other coefficients to be unconstrained (I tried this with
> the
> > first dataset by setting
> >
> > y=1+0.5*x.1-x.2+x.3+x.4
> >
> > in the call, but got similar-looking output to what I got in the second
> > dataset); and
> >
> > (2) it would be really useful to have the call to -pcls(M)- produce more
> > informative output (SEs, t-values, fit stats, etc).
> >
> > Many thanks in anticipation of your expert help and being told what a
> > clueless berk I am,
> > Clive
> >
> > --
> > Clive Nicholas
> >
> > "My colleagues in the social sciences talk a great deal about
> methodology.
> > I prefer to call it style." -- Freeman J. Dyson
> >
>
>
> --
> Clive Nicholas
>
> "My colleagues in the social sciences talk a great deal about methodology.
> I prefer to call it style." -- Freeman J. Dyson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@her @end|ng |rom p|e@@th@n@com  Tue Nov  3 21:43:52 2020
From: ||@her @end|ng |rom p|e@@th@n@com (Dennis Fisher)
Date: Tue, 3 Nov 2020 12:43:52 -0800
Subject: [R] segfault from systemfonts::system_fonts
Message-ID: <305BEAD0-7904-46D9-AB83-38194B0827D3@plessthan.com>

R 4.0.3
OS X 10.15.7

Colleagues

When I run flextable, it generates a segfault.  I traced the problem to systemfonts::system_fonts()

> > require("systemfonts")
> Loading required package: systemfonts
> >  system_fonts()
> 
>  *** caught segfault ***
> address 0x0, cause 'memory not mapped'
> 
> Traceback:
>  1: system_fonts_c()
>  2: system_fonts()
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> 
I updated my OS and R, deleted and reinstalled the systemfonts package -- problem persists.  

I also opened Apple's font application and "validated" all font files (I have never installed any special fonts nor is there anything non-standard (e.g., Homebrew) on my system.

Of note, I can run other functions in systemfonts without problems -- only system_fonts triggers the segfault.

Another similar setup on OS X does not trigger the same problem, so the problem is more likely something in my system rather than a problem in R.

Does anyone have any ideas on how one might address this?

Dennis
 
Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Nov  3 22:00:16 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 3 Nov 2020 16:00:16 -0500
Subject: [R] segfault from systemfonts::system_fonts
In-Reply-To: <305BEAD0-7904-46D9-AB83-38194B0827D3@plessthan.com>
References: <305BEAD0-7904-46D9-AB83-38194B0827D3@plessthan.com>
Message-ID: <95284257-712d-4031-ffbc-f222452ba1d9@gmail.com>

On 03/11/2020 3:43 p.m., Dennis Fisher wrote:
> R 4.0.3
> OS X 10.15.7
> 
> Colleagues
> 
> When I run flextable, it generates a segfault.  I traced the problem to systemfonts::system_fonts()
> 
>>> require("systemfonts")
>> Loading required package: systemfonts
>>>   system_fonts()
>>
>>   *** caught segfault ***
>> address 0x0, cause 'memory not mapped'
>>
>> Traceback:
>>   1: system_fonts_c()
>>   2: system_fonts()
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>>
> I updated my OS and R, deleted and reinstalled the systemfonts package -- problem persists.
> 
> I also opened Apple's font application and "validated" all font files (I have never installed any special fonts nor is there anything non-standard (e.g., Homebrew) on my system.
> 
> Of note, I can run other functions in systemfonts without problems -- only system_fonts triggers the segfault.
> 
> Another similar setup on OS X does not trigger the same problem, so the problem is more likely something in my system rather than a problem in R.
> 
> Does anyone have any ideas on how one might address this?
> 

For what it's worth, I have the same R version and macOS version, and it 
works fine.  Debugging it will be hard:  all the work happens in a 
function called using

     .Call("_systemfonts_system_fonts_c")

If I could reproduce the bug and wanted to track it down, I think I'd do 
it by adding a bunch of Rprintf() commands into the source of 
_systemfonts_system_fonts_c and rebuilding the package.  It would be 
really tedious; I'm glad I'm not doing this!

Duncan Murdoch


From ||@her @end|ng |rom p|e@@th@n@com  Tue Nov  3 22:05:48 2020
From: ||@her @end|ng |rom p|e@@th@n@com (Dennis Fisher)
Date: Tue, 3 Nov 2020 13:05:48 -0800
Subject: [R] segfault from systemfonts::system_fonts
In-Reply-To: <95284257-712d-4031-ffbc-f222452ba1d9@gmail.com>
References: <305BEAD0-7904-46D9-AB83-38194B0827D3@plessthan.com>
 <95284257-712d-4031-ffbc-f222452ba1d9@gmail.com>
Message-ID: <015760A9-EE58-44D0-A2EE-E8C664B20D13@plessthan.com>

Duncan

Thanks for responding -- but your response did not help my mood.
Executing:
	.Call("_systemfonts_system_fonts_c")
triggered the segfault (as you proposed).

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com




> On Nov 3, 2020, at 1:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 03/11/2020 3:43 p.m., Dennis Fisher wrote:
>> R 4.0.3
>> OS X 10.15.7
>> Colleagues
>> When I run flextable, it generates a segfault.  I traced the problem to systemfonts::system_fonts()
>>>> require("systemfonts")
>>> Loading required package: systemfonts
>>>>  system_fonts()
>>> 
>>>  *** caught segfault ***
>>> address 0x0, cause 'memory not mapped'
>>> 
>>> Traceback:
>>>  1: system_fonts_c()
>>>  2: system_fonts()
>>> 
>>> Possible actions:
>>> 1: abort (with core dump, if enabled)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>> 
>> I updated my OS and R, deleted and reinstalled the systemfonts package -- problem persists.
>> I also opened Apple's font application and "validated" all font files (I have never installed any special fonts nor is there anything non-standard (e.g., Homebrew) on my system.
>> Of note, I can run other functions in systemfonts without problems -- only system_fonts triggers the segfault.
>> Another similar setup on OS X does not trigger the same problem, so the problem is more likely something in my system rather than a problem in R.
>> Does anyone have any ideas on how one might address this?
> 
> For what it's worth, I have the same R version and macOS version, and it works fine.  Debugging it will be hard:  all the work happens in a function called using
> 
>    .Call("_systemfonts_system_fonts_c")
> 
> If I could reproduce the bug and wanted to track it down, I think I'd do it by adding a bunch of Rprintf() commands into the source of _systemfonts_system_fonts_c and rebuilding the package.  It would be really tedious; I'm glad I'm not doing this!
> 
> Duncan Murdoch


	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Nov  3 22:17:58 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 3 Nov 2020 21:17:58 +0000 (UTC)
Subject: [R] How to correct my error message
In-Reply-To: <CAO29qn7uQkniPBMgYW3iRV7Jnt7-+YFi_6ZC0aZ+FxHsgG+JFA@mail.gmail.com>
References: <497841733.6368680.1603825619018.ref@mail.yahoo.com>
 <497841733.6368680.1603825619018@mail.yahoo.com>
 <CAM_vjunPUTAk+MREgNsueMUmL-BHB41--vdEaofdTrDruomSSg@mail.gmail.com>
 <CAO29qn7uQkniPBMgYW3iRV7Jnt7-+YFi_6ZC0aZ+FxHsgG+JFA@mail.gmail.com>
Message-ID: <437763544.3319706.1604438278312@mail.yahoo.com>

Dear All,

Many thanks for your responses. I got it !

Best,









Le mardi 27 octobre 2020 ? 21:16:50 UTC+1, Md. Moyazzem Hossain <hossainmm at juniv.edu> a ?crit : 





Dear Varin,

I think the following code will solve your problem.

n <- 60
b <- runif(n, 0, 5)
a <- runif(n, 0, 5)
z1 <- data.frame(x0=1:57,
? ? ? ? ? ? ? ? ? ? x1=rnorm(n*0.95,2,3))
z2 <- data.frame(x0=58:60,
? ? ? ? ? ? ? ? ? ? x1=rnorm(n*0.05,2,9))

combined=rbind(z1,z2)
z=combined[,2]
y_model <- 0.1 * b - 0.5 * z - a + 10
y_obs <- y_model +c( rnorm(n*0.95, 0, 0.1), rnorm(n*0.05, 0, 0.5) )
df<-data.frame(b,a,z,y_obs)

Thanks.

Md

On Tue, Oct 27, 2020 at 7:21 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Hi,
> 
> a is of length 60.
> b is of length 60.
> z is of length 57.
> 
> What do you expect to have happen when you create y_model ? What
> happens to those other 3 observations?
> 
> Sarah
> 
> On Tue, Oct 27, 2020 at 3:07 PM varin sacha via R-help
> <r-help at r-project.org> wrote:
>>
>> Dear R-experts,
>>
>> Here below my R code. The warning message is not a problem to me but there is an error message more problematic. I understand the error message but I don't know if it is possible to correct the error and if yes, how to correct it.
>>
>> Many thanks.
>>
>>
>> n <- 60
>> b <- runif(n, 0, 5)
>> a <- runif(n, 0, 5)
>> z <- rnorm(n*0.95,2,3) + rnorm(n*0.05,2,9)
>> y_model <- 0.1 * b - 0.5 * z - a + 10
>> y_obs <- y_model +c( rnorm(n*0.95, 0, 0.1), rnorm(n*0.05, 0, 0.5) )
>> df<-data.frame(b,a,z,y_obs)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Sarah Goslee (she/her)
> http://www.numberwright.com
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh

Website:?http://www.juniv.edu/teachers/hossainmm?
Research:?Google Scholar;?ResearchGate;?ORCID iD


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Nov  3 22:18:30 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 3 Nov 2020 21:18:30 +0000 (UTC)
Subject: [R] How to correct my error message
In-Reply-To: <b692e57d-7da6-9676-7ebe-f30a8fe35b13@gmail.com>
References: <497841733.6368680.1603825619018.ref@mail.yahoo.com>
 <497841733.6368680.1603825619018@mail.yahoo.com>
 <b692e57d-7da6-9676-7ebe-f30a8fe35b13@gmail.com>
Message-ID: <740399640.3324496.1604438310337@mail.yahoo.com>

Many thanks Duncan,

It works !

Best.









Le mardi 27 octobre 2020 ? 20:49:25 UTC+1, Duncan Murdoch <murdoch.duncan at gmail.com> a ?crit : 





On 27/10/2020 3:06 p.m., varin sacha via R-help wrote:

> Dear R-experts,
> 
> Here below my R code. The warning message is not a problem to me but there is an error message more problematic. I understand the error message but I don't know if it is possible to correct the error and if yes, how to correct it.
> 
> Many thanks.
> 
> 
> n <- 60
> b <- runif(n, 0, 5)
> a <- runif(n, 0, 5)
> z <- rnorm(n*0.95,2,3) + rnorm(n*0.05,2,9)
> y_model <- 0.1 * b - 0.5 * z - a + 10
> y_obs <- y_model +c( rnorm(n*0.95, 0, 0.1), rnorm(n*0.05, 0, 0.5) )
> df<-data.frame(b,a,z,y_obs)

> 

I suspect you intended to concatenate the two parts of z, i.e.

? z <- c(rnorm(n*0.95,2,3), rnorm(n*0.05,2,9))

You shouldn't ignore the warning.

By the way, it's not true for every n that my expression for z will 
always give something of length n.? It would be safer to do the 
calculation as

? m <- round(n*0.95)
? z <- c(rnorm(m,2,3), rnorm(n-m,2,9)

Duncan Murdoch


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Nov  3 22:23:50 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 3 Nov 2020 21:23:50 +0000 (UTC)
Subject: [R] nlcor package
References: <388658574.3320737.1604438630344.ref@mail.yahoo.com>
Message-ID: <388658574.3320737.1604438630344@mail.yahoo.com>

Dear R-helpers,

Here below my R code showing warnings and error messages I don't understand. 
What is going wrong ?

########################
install.packages("devtools")
library(devtools)
install_github("ProcessMiner/nlcor")
library(nlcor) 

A=c(505, 530, 419, 486, 608, 468, 519, 486, 532, 289, 529, 474, 571, 546, 458, 476, 376, 474, 598, 419, 479, 615, 507, 473, 532, 392, 496, 426, 480, 583, 490, 499, 513, 444, 542)
B=c(508, 516, 390, 520, 375, 499, 478, 534, 553, 485, 405, 478, 542, 523, 491, 363, 456, 498, 506, 529, 574, 478, 411, 571, 512, 487, 518, 515, 467, 513, 536, 555, 508, 507, 535)

c<-nlcor(A,B,refine=0.5,plt=T)
c$cor.estimate
c$adjusted.p.value
print(c$cor.plot)
########################


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Nov  4 02:48:29 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 03 Nov 2020 17:48:29 -0800
Subject: [R] nlcor package
In-Reply-To: <388658574.3320737.1604438630344@mail.yahoo.com>
References: <388658574.3320737.1604438630344.ref@mail.yahoo.com>
 <388658574.3320737.1604438630344@mail.yahoo.com>
Message-ID: <E1FC4FC7-2DE3-4C08-9A5C-2A39FEC68BF2@dcn.davis.ca.us>

Someone may investigate this for you anyway, but technically this request is outside of the scope of this mailing list (which is the R programming language, not the theory of use nor possible bugs in the current version of random packages not even registered in CRAN). Do read the Posting Guide and consider corresponding with the package author as directed by the package DESCRIPTION file.

On November 3, 2020 1:23:50 PM PST, varin sacha via R-help <r-help at r-project.org> wrote:
>Dear R-helpers,
>
>Here below my R code showing warnings and error messages I don't
>understand. 
>What is going wrong ?
>
>########################
>install.packages("devtools")
>library(devtools)
>install_github("ProcessMiner/nlcor")
>library(nlcor) 
>
>A=c(505, 530, 419, 486, 608, 468, 519, 486, 532, 289, 529, 474, 571,
>546, 458, 476, 376, 474, 598, 419, 479, 615, 507, 473, 532, 392, 496,
>426, 480, 583, 490, 499, 513, 444, 542)
>B=c(508, 516, 390, 520, 375, 499, 478, 534, 553, 485, 405, 478, 542,
>523, 491, 363, 456, 498, 506, 529, 574, 478, 411, 571, 512, 487, 518,
>515, 467, 513, 536, 555, 508, 507, 535)
>
>c<-nlcor(A,B,refine=0.5,plt=T)
>c$cor.estimate
>c$adjusted.p.value
>print(c$cor.plot)
>########################
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m|@ojpm @end|ng |rom gm@||@com  Wed Nov  4 10:22:26 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Wed, 4 Nov 2020 17:22:26 +0800
Subject: [R] build a literature database
Message-ID: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>

Hi,

   I 'd like to create a table for literature review. Is there any good
data structure (database) I may use? Now I just use a simple dataframe as
follows, but in the second item I swap the order of year and author, and it
records 2013 as author and "XH" as year.  Is there any better structure ?
If not, how may I fix the current condition?Thanks!


df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
df[1, ]<-c(
           author = "Moore",
           year = 2020,
           title = "Statistics and data analysis",
           country = "Colombia",
           sample = NA,
           data = "firm level",
           result = NA,
           note = NA)

df[nrow(df)+1,]<- c(year = 2013,
                    author = "XH",
                    title = NA,
                    country = NA,
                    sample = NA,
                    data = NA,
                    result = NA,
                    note = NA)

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov  4 10:28:13 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Nov 2020 04:28:13 -0500
Subject: [R] build a literature database
In-Reply-To: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
References: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
Message-ID: <ac555c04-c994-161c-ea8f-4dd2a1fbb46e@gmail.com>

On 04/11/2020 4:22 a.m., John wrote:
> Hi,
> 
>     I 'd like to create a table for literature review. Is there any good
> data structure (database) I may use? Now I just use a simple dataframe as
> follows, but in the second item I swap the order of year and author, and it
> records 2013 as author and "XH" as year.  Is there any better structure ?
> If not, how may I fix the current condition?Thanks!
> 
> 
> df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
> NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
> df[1, ]<-c(
>             author = "Moore",
>             year = 2020,
>             title = "Statistics and data analysis",
>             country = "Colombia",
>             sample = NA,
>             data = "firm level",
>             result = NA,
>             note = NA)
> 
> df[nrow(df)+1,]<- c(year = 2013,
>                      author = "XH",
>                      title = NA,
>                      country = NA,
>                      sample = NA,
>                      data = NA,
>                      result = NA,
>                      note = NA)

If you changed the last statement to

df <- rbind(df, data.frame(year = 2013,
                       author = "XH",
                       title = NA,
                       country = NA,
                       sample = NA,
                       data = NA,
                       result = NA,
                       note = NA))

it would correctly sort out the reordered columns.

As to a better data structure:  bibliographic data is hard, because 
different forms of publication should have different fields.  I'd 
suggest storing the data in some existing format rather than rolling 
your own.  For example, the utils::bibentry function is quite a bit like 
BibTeX.

Duncan Murdoch


From bor|@@@te|pe @end|ng |rom utoronto@c@  Wed Nov  4 10:50:38 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Wed, 4 Nov 2020 09:50:38 +0000
Subject: [R] newdata for predict.lm() ??
Message-ID: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>

Can't get data from a data frame into predict() without a detour that seems quite unnecessary ...

Reprex:

# Data frame with simulated data in columns "h" (independent) and "w" (dependent)
DAT <- structure(list(h = c(2.174, 2.092, 2.059, 1.952, 2.216, 2.118, 
                            1.755, 2.060, 2.136, 2.126, 1.792, 1.574,
                            2.117, 1.741, 2.295, 1.526, 1.666, 1.581,
                            1.522, 1.995), 
                      w = c(90.552, 89.518, 84.124, 94.685, 94.710, 82.429,
                            87.176, 90.318, 76.873, 84.183, 57.890, 62.005,
                            84.258, 78.317,101.304, 64.982, 71.237, 77.124,
                            65.010, 81.413)),
                 row.names = c( "1",  "2",  "3",  "4",  "5",  "6",  "7", 
                                "8",  "9", "10", "11", "12", "13", "14",
                               "15", "16", "17", "18", "19", "20"),
                 class = "data.frame")


myFit <- lm(DAT$w ~ DAT$h)
coef(myFit)

# (Intercept)       DAT$h 
#   11.76475    35.92002 


# Create 50 x-values with seq() to plot confidence intervals
myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))

pc <- predict(myFit, newdata = myNew, interval = "confidence")

# Warning message:
# 'newdata' had 50 rows but variables found have 20 rows 

# Problem: predict() was not able to take the single column in myNew
# as the independent variable.

# Ugly workaround: but with that everything works as expected.
xx <- DAT$h
yy <- DAT$w
myFit <- lm(yy ~ xx)
coef(myFit)

myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
colnames(myNew) <- "xx"  # This fixes it!

pc <- predict(myFit, newdata = myNew, interval = "confidence")
str(pc)

# So: specifying the column in newdata to have same name as the coefficient
# name should work, right?
# Back to the original ...

myFit <- lm(DAT$w ~ DAT$h)
colnames(myNew) <- "`DAT$h`"
# ... same error

colnames(myNew) <- "h"
# ... same error again.

Bottom line: how can I properly specify newdata? The documentation is opaque. It seems the algorithm is trying to EXACTLY match the text of the RHS of the formula, which is unlikely to result in a useful column name, unless I assign to an intermediate variable. There must be a better way ...



Thanks!
Boris


From pd@|gd @end|ng |rom gm@||@com  Wed Nov  4 10:56:00 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 4 Nov 2020 10:56:00 +0100
Subject: [R] newdata for predict.lm() ??
In-Reply-To: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>
References: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>
Message-ID: <B368F474-62D6-496B-A0CB-8E097AA2957B@gmail.com>

Don't use $ notation in lm() formulas. Use lm(w ~ h, data=DAT).

-pd

> On 4 Nov 2020, at 10:50 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> Can't get data from a data frame into predict() without a detour that seems quite unnecessary ...
> 
> Reprex:
> 
> # Data frame with simulated data in columns "h" (independent) and "w" (dependent)
> DAT <- structure(list(h = c(2.174, 2.092, 2.059, 1.952, 2.216, 2.118, 
>                            1.755, 2.060, 2.136, 2.126, 1.792, 1.574,
>                            2.117, 1.741, 2.295, 1.526, 1.666, 1.581,
>                            1.522, 1.995), 
>                      w = c(90.552, 89.518, 84.124, 94.685, 94.710, 82.429,
>                            87.176, 90.318, 76.873, 84.183, 57.890, 62.005,
>                            84.258, 78.317,101.304, 64.982, 71.237, 77.124,
>                            65.010, 81.413)),
>                 row.names = c( "1",  "2",  "3",  "4",  "5",  "6",  "7", 
>                                "8",  "9", "10", "11", "12", "13", "14",
>                               "15", "16", "17", "18", "19", "20"),
>                 class = "data.frame")
> 
> 
> myFit <- lm(DAT$w ~ DAT$h)
> coef(myFit)
> 
> # (Intercept)       DAT$h 
> #   11.76475    35.92002 
> 
> 
> # Create 50 x-values with seq() to plot confidence intervals
> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
> 
> pc <- predict(myFit, newdata = myNew, interval = "confidence")
> 
> # Warning message:
> # 'newdata' had 50 rows but variables found have 20 rows 
> 
> # Problem: predict() was not able to take the single column in myNew
> # as the independent variable.
> 
> # Ugly workaround: but with that everything works as expected.
> xx <- DAT$h
> yy <- DAT$w
> myFit <- lm(yy ~ xx)
> coef(myFit)
> 
> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
> colnames(myNew) <- "xx"  # This fixes it!
> 
> pc <- predict(myFit, newdata = myNew, interval = "confidence")
> str(pc)
> 
> # So: specifying the column in newdata to have same name as the coefficient
> # name should work, right?
> # Back to the original ...
> 
> myFit <- lm(DAT$w ~ DAT$h)
> colnames(myNew) <- "`DAT$h`"
> # ... same error
> 
> colnames(myNew) <- "h"
> # ... same error again.
> 
> Bottom line: how can I properly specify newdata? The documentation is opaque. It seems the algorithm is trying to EXACTLY match the text of the RHS of the formula, which is unlikely to result in a useful column name, unless I assign to an intermediate variable. There must be a better way ...
> 
> 
> 
> Thanks!
> Boris
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Wed Nov  4 11:05:31 2020
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Wed, 4 Nov 2020 11:05:31 +0100 (CET)
Subject: [R] newdata for predict.lm() ??
In-Reply-To: <B368F474-62D6-496B-A0CB-8E097AA2957B@gmail.com>
References: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>
 <B368F474-62D6-496B-A0CB-8E097AA2957B@gmail.com>
Message-ID: <9fb129cf-9ad-cfa5-6f13-377c473131d@uibk.ac.at>

On Wed, 4 Nov 2020, peter dalgaard wrote:

> Don't use $ notation in lm() formulas. Use lm(w ~ h, data=DAT).

...or in any other formula for that matter!

Let me expand a bit on Peter's comment because this is really a pet peeve 
of mine:

The idea is that the formula "w ~ h" described the relationships between 
the variables involved, independent of the data set this should be applied 
to. In contrast "DAT$w ~ DAT$h" hard-wires the data into the formula and 
prevents it from applying the formula to another data set.

Hope that helps,
Achim


>> On 4 Nov 2020, at 10:50 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>
>> Can't get data from a data frame into predict() without a detour that seems quite unnecessary ...
>>
>> Reprex:
>>
>> # Data frame with simulated data in columns "h" (independent) and "w" (dependent)
>> DAT <- structure(list(h = c(2.174, 2.092, 2.059, 1.952, 2.216, 2.118,
>>                            1.755, 2.060, 2.136, 2.126, 1.792, 1.574,
>>                            2.117, 1.741, 2.295, 1.526, 1.666, 1.581,
>>                            1.522, 1.995),
>>                      w = c(90.552, 89.518, 84.124, 94.685, 94.710, 82.429,
>>                            87.176, 90.318, 76.873, 84.183, 57.890, 62.005,
>>                            84.258, 78.317,101.304, 64.982, 71.237, 77.124,
>>                            65.010, 81.413)),
>>                 row.names = c( "1",  "2",  "3",  "4",  "5",  "6",  "7",
>>                                "8",  "9", "10", "11", "12", "13", "14",
>>                               "15", "16", "17", "18", "19", "20"),
>>                 class = "data.frame")
>>
>>
>> myFit <- lm(DAT$w ~ DAT$h)
>> coef(myFit)
>>
>> # (Intercept)       DAT$h
>> #   11.76475    35.92002
>>
>>
>> # Create 50 x-values with seq() to plot confidence intervals
>> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
>>
>> pc <- predict(myFit, newdata = myNew, interval = "confidence")
>>
>> # Warning message:
>> # 'newdata' had 50 rows but variables found have 20 rows
>>
>> # Problem: predict() was not able to take the single column in myNew
>> # as the independent variable.
>>
>> # Ugly workaround: but with that everything works as expected.
>> xx <- DAT$h
>> yy <- DAT$w
>> myFit <- lm(yy ~ xx)
>> coef(myFit)
>>
>> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
>> colnames(myNew) <- "xx"  # This fixes it!
>>
>> pc <- predict(myFit, newdata = myNew, interval = "confidence")
>> str(pc)
>>
>> # So: specifying the column in newdata to have same name as the coefficient
>> # name should work, right?
>> # Back to the original ...
>>
>> myFit <- lm(DAT$w ~ DAT$h)
>> colnames(myNew) <- "`DAT$h`"
>> # ... same error
>>
>> colnames(myNew) <- "h"
>> # ... same error again.
>>
>> Bottom line: how can I properly specify newdata? The documentation is opaque. It seems the algorithm is trying to EXACTLY match the text of the RHS of the formula, which is unlikely to result in a useful column name, unless I assign to an intermediate variable. There must be a better way ...
>>
>>
>>
>> Thanks!
>> Boris
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bor|@@@te|pe @end|ng |rom utoronto@c@  Wed Nov  4 11:11:06 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Wed, 4 Nov 2020 10:11:06 +0000
Subject: [R] newdata for predict.lm() ??
In-Reply-To: <9fb129cf-9ad-cfa5-6f13-377c473131d@uibk.ac.at>
References: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>
 <B368F474-62D6-496B-A0CB-8E097AA2957B@gmail.com>
 <9fb129cf-9ad-cfa5-6f13-377c473131d@uibk.ac.at>
Message-ID: <2C4C3657-4A87-471A-A7D1-AFF7649D1738@utoronto.ca>

Solved. Thanks Achim and Peter ...

though following that approach we now are relying implicitly on column names. But at least I've got this silly example working now. Thanks for the explanation Achim.

:-)



> On 2020-11-04, at 20:05, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
> 
> EXTERNAL EMAIL:  Treat content with extra caution.
> 
> On Wed, 4 Nov 2020, peter dalgaard wrote:
> 
>> Don't use $ notation in lm() formulas. Use lm(w ~ h, data=DAT).
> 
> ...or in any other formula for that matter!
> 
> Let me expand a bit on Peter's comment because this is really a pet peeve
> of mine:
> 
> The idea is that the formula "w ~ h" described the relationships between
> the variables involved, independent of the data set this should be applied
> to. In contrast "DAT$w ~ DAT$h" hard-wires the data into the formula and
> prevents it from applying the formula to another data set.
> 
> Hope that helps,
> Achim
> 
> 
>>> On 4 Nov 2020, at 10:50 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> 
>>> Can't get data from a data frame into predict() without a detour that seems quite unnecessary ...
>>> 
>>> Reprex:
>>> 
>>> # Data frame with simulated data in columns "h" (independent) and "w" (dependent)
>>> DAT <- structure(list(h = c(2.174, 2.092, 2.059, 1.952, 2.216, 2.118,
>>>                           1.755, 2.060, 2.136, 2.126, 1.792, 1.574,
>>>                           2.117, 1.741, 2.295, 1.526, 1.666, 1.581,
>>>                           1.522, 1.995),
>>>                     w = c(90.552, 89.518, 84.124, 94.685, 94.710, 82.429,
>>>                           87.176, 90.318, 76.873, 84.183, 57.890, 62.005,
>>>                           84.258, 78.317,101.304, 64.982, 71.237, 77.124,
>>>                           65.010, 81.413)),
>>>                row.names = c( "1",  "2",  "3",  "4",  "5",  "6",  "7",
>>>                               "8",  "9", "10", "11", "12", "13", "14",
>>>                              "15", "16", "17", "18", "19", "20"),
>>>                class = "data.frame")
>>> 
>>> 
>>> myFit <- lm(DAT$w ~ DAT$h)
>>> coef(myFit)
>>> 
>>> # (Intercept)       DAT$h
>>> #   11.76475    35.92002
>>> 
>>> 
>>> # Create 50 x-values with seq() to plot confidence intervals
>>> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
>>> 
>>> pc <- predict(myFit, newdata = myNew, interval = "confidence")
>>> 
>>> # Warning message:
>>> # 'newdata' had 50 rows but variables found have 20 rows
>>> 
>>> # Problem: predict() was not able to take the single column in myNew
>>> # as the independent variable.
>>> 
>>> # Ugly workaround: but with that everything works as expected.
>>> xx <- DAT$h
>>> yy <- DAT$w
>>> myFit <- lm(yy ~ xx)
>>> coef(myFit)
>>> 
>>> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
>>> colnames(myNew) <- "xx"  # This fixes it!
>>> 
>>> pc <- predict(myFit, newdata = myNew, interval = "confidence")
>>> str(pc)
>>> 
>>> # So: specifying the column in newdata to have same name as the coefficient
>>> # name should work, right?
>>> # Back to the original ...
>>> 
>>> myFit <- lm(DAT$w ~ DAT$h)
>>> colnames(myNew) <- "`DAT$h`"
>>> # ... same error
>>> 
>>> colnames(myNew) <- "h"
>>> # ... same error again.
>>> 
>>> Bottom line: how can I properly specify newdata? The documentation is opaque. It seems the algorithm is trying to EXACTLY match the text of the RHS of the formula, which is unlikely to result in a useful column name, unless I assign to an intermediate variable. There must be a better way ...
>>> 
>>> 
>>> 
>>> Thanks!
>>> Boris
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Wed Nov  4 13:12:50 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Wed, 4 Nov 2020 12:12:50 +0000
Subject: [R] build a literature database
In-Reply-To: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
References: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
Message-ID: <5aad18cb-f404-7b6b-104b-82b3ee6dcbcc@dewey.myzen.co.uk>

Dear John

If you are doing a systematic review have you thought of investigating 
some of the packages in the CRAN Task View on MetaAnalysis like metagear 
or revtools? I have not used any of them but they claim to support that 
part of the process.

Michael

On 04/11/2020 09:22, John wrote:
> Hi,
> 
>     I 'd like to create a table for literature review. Is there any good
> data structure (database) I may use? Now I just use a simple dataframe as
> follows, but in the second item I swap the order of year and author, and it
> records 2013 as author and "XH" as year.  Is there any better structure ?
> If not, how may I fix the current condition?Thanks!
> 
> 
> df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
> NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
> df[1, ]<-c(
>             author = "Moore",
>             year = 2020,
>             title = "Statistics and data analysis",
>             country = "Colombia",
>             sample = NA,
>             data = "firm level",
>             result = NA,
>             note = NA)
> 
> df[nrow(df)+1,]<- c(year = 2013,
>                      author = "XH",
>                      title = NA,
>                      country = NA,
>                      sample = NA,
>                      data = NA,
>                      result = NA,
>                      note = NA)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From rkoenker @end|ng |rom ||||no|@@edu  Wed Nov  4 14:01:25 2020
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Wed, 4 Nov 2020 13:01:25 +0000
Subject: [R] build a literature database
In-Reply-To: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
References: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
Message-ID: <C713FE87-D9D8-4B1A-88F8-EA22BDA8B840@illinois.edu>

You might also want to take a look at this survey:  https://ropensci.org/technotes/2020/05/07/rmd-citations/

> On Nov 4, 2020, at 9:22 AM, John <miaojpm at gmail.com> wrote:
> 
> Hi,
> 
>   I 'd like to create a table for literature review. Is there any good
> data structure (database) I may use? Now I just use a simple dataframe as
> follows, but in the second item I swap the order of year and author, and it
> records 2013 as author and "XH" as year.  Is there any better structure ?
> If not, how may I fix the current condition?Thanks!
> 
> 
> df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
> NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
> df[1, ]<-c(
>           author = "Moore",
>           year = 2020,
>           title = "Statistics and data analysis",
>           country = "Colombia",
>           sample = NA,
>           data = "firm level",
>           result = NA,
>           note = NA)
> 
> df[nrow(df)+1,]<- c(year = 2013,
>                    author = "XH",
>                    title = NA,
>                    country = NA,
>                    sample = NA,
>                    data = NA,
>                    result = NA,
>                    note = NA)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |@p@nyo|com @end|ng |rom gm@||@com  Wed Nov  4 14:26:58 2020
From: |@p@nyo|com @end|ng |rom gm@||@com (=?UTF-8?Q?Engin_Y=C4=B1lmaz?=)
Date: Wed, 4 Nov 2020 16:26:58 +0300
Subject: [R] colMeans function
Message-ID: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>

Dear
I use *flights* database library(nycflights13)

The following code is working as

colMeans(flights[2])

* 6.54851*

but other code is  not working as

colMeans(flights$month)

*Error in colMeans(flights$month) : *
*  'x' must be an array of at least two dimensions*

*flights[2]* is equal to the *month *column in database

*Sincerely*
Engin YILMAZ

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov  4 14:37:00 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Nov 2020 08:37:00 -0500
Subject: [R] colMeans function
In-Reply-To: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
References: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
Message-ID: <8c07f001-6fdd-84b2-9183-3dccff3f028c@gmail.com>

On 04/11/2020 8:26 a.m., Engin Y?lmaz wrote:
> Dear
> I use *flights* database library(nycflights13)
> 
> The following code is working as
> 
> colMeans(flights[2])
> 
> * 6.54851*
> 
> but other code is  not working as
> 
> colMeans(flights$month)
> 
> *Error in colMeans(flights$month) : *
> *  'x' must be an array of at least two dimensions*
> 
> *flights[2]* is equal to the *month *column in database

No, flights[2] is a dataframe with one column.  flights[[2]] would be 
the month column.

Duncan Murdoch


From m@rc_@chw@rtz @end|ng |rom me@com  Wed Nov  4 14:46:12 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 4 Nov 2020 08:46:12 -0500
Subject: [R] colMeans function
In-Reply-To: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
References: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
Message-ID: <B74F660C-4230-4391-B7B1-9C18ABF2B459@me.com>

Hi,

You might want to become familiar with the ?str and ?dim functions, which can help you identify the structure of the objects that you are passing to colMeans().

In the first case, flights[2] is a data frame with a single column, so will have two dimensions with a row and column structure.

In the second case, flights$month is a single numeric vector within the data frame and does not have a row and column dimension structure.

If you used flights[[2]], that would be equivalent to flights$month, in referencing a single numeric vector.

So, if you used:

str(flights[2])
dim(flights[2])

str(flights$month)
dim(flights$month)

you would see the difference.

Regards,

Marc Schwartz


> On Nov 4, 2020, at 8:26 AM, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
> 
> Dear
> I use *flights* database library(nycflights13)
> 
> The following code is working as
> 
> colMeans(flights[2])
> 
> * 6.54851*
> 
> but other code is  not working as
> 
> colMeans(flights$month)
> 
> *Error in colMeans(flights$month) : *
> *  'x' must be an array of at least two dimensions*
> 
> *flights[2]* is equal to the *month *column in database
> 
> *Sincerely*
> Engin YILMAZ


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Nov  4 18:19:48 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 4 Nov 2020 17:19:48 +0000
Subject: [R] colMeans function
In-Reply-To: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
References: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
Message-ID: <61acfed6-cae1-283b-6401-5f6f11c5b8be@sapo.pt>

Hello,

No, flights[2] is *not* equal to flights$months. The former is a 
data.frame with only one column, therefore it has a dimension attribute. 
The latter is a column, a vector of the data.frame flights, it does not 
have the attribute dim set.

The difference is very important, see what class(), str() or dim() 
return when applied to both.

See also this StackOverflow post:

https://stackoverflow.com/questions/1169456/the-difference-between-bracket-and-double-bracket-for-accessing-the-el


Hope this helps,

Rui Barradas

?s 13:26 de 04/11/20, Engin Y?lmaz escreveu:
> Dear
> I use *flights* database library(nycflights13)
> 
> The following code is working as
> 
> colMeans(flights[2])
> 
> * 6.54851*
> 
> but other code is  not working as
> 
> colMeans(flights$month)
> 
> *Error in colMeans(flights$month) : *
> *  'x' must be an array of at least two dimensions*
> 
> *flights[2]* is equal to the *month *column in database
> 
> *Sincerely*
> Engin YILMAZ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@|ner_krug @end|ng |rom |c|oud@com  Wed Nov  4 10:32:30 2020
From: r@|ner_krug @end|ng |rom |c|oud@com (Rainer Krug)
Date: Wed, 4 Nov 2020 10:32:30 +0100
Subject: [R] build a literature database
In-Reply-To: <ac555c04-c994-161c-ea8f-4dd2a1fbb46e@gmail.com>
References: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
 <ac555c04-c994-161c-ea8f-4dd2a1fbb46e@gmail.com>
Message-ID: <DD9969F3-FC00-40C0-965B-373A7992BAE1@icloud.com>

I agree with Duncan.

I co-ordinated a large literature review with initially more than 5000 papers and about 30 reviewers, and all the bibliometrics information was in bibtex format, as it is easy to interchange between programs.

Cheers,

Rainer

> On 4 Nov 2020, at 10:28, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 04/11/2020 4:22 a.m., John wrote:
>> Hi,
>>    I 'd like to create a table for literature review. Is there any good
>> data structure (database) I may use? Now I just use a simple dataframe as
>> follows, but in the second item I swap the order of year and author, and it
>> records 2013 as author and "XH" as year.  Is there any better structure ?
>> If not, how may I fix the current condition?Thanks!
>> df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
>> NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
>> df[1, ]<-c(
>>            author = "Moore",
>>            year = 2020,
>>            title = "Statistics and data analysis",
>>            country = "Colombia",
>>            sample = NA,
>>            data = "firm level",
>>            result = NA,
>>            note = NA)
>> df[nrow(df)+1,]<- c(year = 2013,
>>                     author = "XH",
>>                     title = NA,
>>                     country = NA,
>>                     sample = NA,
>>                     data = NA,
>>                     result = NA,
>>                     note = NA)
> 
> If you changed the last statement to
> 
> df <- rbind(df, data.frame(year = 2013,
>                      author = "XH",
>                      title = NA,
>                      country = NA,
>                      sample = NA,
>                      data = NA,
>                      result = NA,
>                      note = NA))
> 
> it would correctly sort out the reordered columns.
> 
> As to a better data structure:  bibliographic data is hard, because different forms of publication should have different fields.  I'd suggest storing the data in some existing format rather than rolling your own.  For example, the utils::bibentry function is quite a bit like BibTeX.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From ph|||p@ch@r|e@ @end|ng |rom ndm@ox@@c@uk  Wed Nov  4 12:48:58 2020
From: ph|||p@ch@r|e@ @end|ng |rom ndm@ox@@c@uk (Philip Charles)
Date: Wed, 4 Nov 2020 11:48:58 +0000
Subject: [R] Intended use-case for data.matrix
Message-ID: <A3EE86FA-C000-4D2B-9A86-0390AFBD0900@ndm.ox.ac.uk>

Hi R gurus,

We do a lot of work with biological -omics datasets (genomics, proteomics etc).  The text file inputs to R typically contain a mixture of (mostly) character data and numeric data.  The number of columns (both character and numeric data) in the file vary with the number of samples measured (which makes use of colClasses , so a typical approach might be

1) read in the whole file as character matrix

#simulated result of read.table (with stringsAsFactors=FALSE)
raw <- data.frame(Accession=c('P04637','P01375','P00761'),Description=c('Cellular tumor antigen p53','Tumor necrosis factor','Trypsin'),Species=c('Homo sapiens','Homo sapiens','Sus scrofa'),Intensity.SampleA=c('919948','1346170','15870'),Intensity.SampleB=c('1625540','710272','83624'),Intensity.SampleC=c('1232780','1481040','62548'))

2) use grep to identify numeric columns based on column names and split the raw matrix

QUANT_COLS <- grepl('^Intensity\\.',colnames(raw))
META_COLS <- !QUANT_COLS
quant.df.char <- raw[,QUANT_COLS]
meta.df <- raw[, META_COLS]

3) convert the quantitation data frame to a numeric matrix

Prior to R version 4, my standard method for step 3 was to use data.matrix() for this last step.  After recently updating from v3.6.3, I've found that all my workflows using this function were giving wildly incorrect results. I figured out that data.matrix now yields a matrix of factor levels rather than the actual numeric values

> quant.df.char
  Intensity.SampleA Intensity.SampleB Intensity.SampleC
1            919948           1625540           1232780
2           1346170            710272           1481040
3             15870             83624             62548

> data.matrix(quant.df.char)
     Intensity.SampleA Intensity.SampleB Intensity.SampleC
[1,]                 3                 1                 1
[2,]                 1                 2                 2
[3,]                 2                 3                 3

The change in behaviour of this function is documented in the R v4.0.0 changelog, so it is clearly intentional:

"data.matrix() now converts character columns to factors and from this to integers."

Now, I know there are other ways to achieve the same conversion, e.g. sapply(quant.df.char, as.numeric). They aren't quite as straightforward to read in the code as data.matrix (sapply/lapply in particular I have to think though whether there will a need to transpose the result!), but the fact that this base function has been changed (without a way to replicate the previous behaviour) leads me to suspect that I have probably not previously been using data.matrix in the intended manner - and I may therefore be making similar mistakes elsewhere! I've certainly distributed/handed out R scripting examples in the past that will now give incorrect results when run on v4+ R.

What even more confusing to me (but possibly related as regards an answer) is that R v4 broke with long-standing convention to change default.stringsAsFactors() to FALSE. So on one hand the update took away what was (at least, from our perspective, with our data - I am sure some here may disagree!) a perennial source of confusion/bugs for R learners, by not introducing string factorisation during data import, and then on the other hand changed a base function to explicitly introduce string factorisation..  I can't see when converting a character dataset, not to factors but, straight to numeric factor levels might be that useful (but of course that doesn't mean it isn't!).

I've had a look through r-help and r-devel archives and couldn't spot any discussion of this, so apologies if this has been asked before. I'm also pretty sure my misunderstanding is with the intended use-case of data.matrix and R ethos around strings/factors rather than the rationale for the change, which is why I'm asking here.

Best wishes,

Phil

Philip Charles
Target Discovery Institute, Nuffield Department Of Medicine
University of Oxford




	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov  4 21:37:40 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Nov 2020 15:37:40 -0500
Subject: [R] Intended use-case for data.matrix
Message-ID: <CA+COuteWqLGoj_QyxCZFAEMYN2qr01pQxTHfb3NS60AQPwygFw@mail.gmail.com>

You can see the change to the help page here:

https://github.com/wch/r-source/commit/d1d3863d72613660727379dd5dffacad32ac9c35#diff-9143902e81e6ad39faace2d926725c4c72b078dd13fbb1223c4a35f833b58ee6

Before the change, it said the input should be

a data frame whose components are logical vectors, factors or numeric
vectors

which suggests your input was invalid. But later it says

Logical and factor columns are converted to integers. Any other
column which is not numeric (according to \code{\link{is.numeric}}) is
converted by \code{\link{as.numeric}} or, for S4 objects,
\code{\link{as}(, "numeric")}.

which suggests what you were doing was supported.

It's unfortunate that you didn't know about this change, but it was made in
August 2019, and appeared on the news feed here:

https://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2019/08/08#n2019-08-08

so some of the blame for this goes to you for not paying attention and
testing unreleased R versions.

To protect yourself against this kind of unpleasant surprise in the future,
I'd suggest this:

- Follow the news feed.

- Put your code in a package, and test it against R-devel now and then. (If
your package is on CRAN the testing will happen automatically; if it's not
on CRAN and not in a package, you could still test against R-devel, but why
make your life more difficult by *not* putting it in a package?)

Duncan Murdoch

On 04/11/2020 6:48 a.m., Philip Charles wrote:
> Hi R gurus,
>
> We do a lot of work with biological -omics datasets (genomics, proteomics
etc). The text file inputs to R typically contain a mixture of (mostly)
character data and numeric data. The number of columns (both character and
numeric data) in the file vary with the number of samples measured (which
makes use of colClasses , so a typical approach might be
>
> 1) read in the whole file as character matrix
>
> #simulated result of read.table (with stringsAsFactors=FALSE)
> raw <-
data.frame(Accession=c('P04637','P01375','P00761'),Description=c('Cellular
tumor antigen p53','Tumor necrosis factor','Trypsin'),Species=c('Homo
sapiens','Homo sapiens','Sus
scrofa'),Intensity.SampleA=c('919948','1346170','15870'),Intensity.SampleB=c('1625540','710272','83624'),Intensity.SampleC=c('1232780','1481040','62548'))
>
> 2) use grep to identify numeric columns based on column names and split
the raw matrix
>
> QUANT_COLS <- grepl('^Intensity\\.',colnames(raw))
> META_COLS <- !QUANT_COLS
> quant.df.char <- raw[,QUANT_COLS]
> meta.df <- raw[, META_COLS]
>
> 3) convert the quantitation data frame to a numeric matrix
>
> Prior to R version 4, my standard method for step 3 was to use
data.matrix() for this last step. After recently updating from v3.6.3, I've
found that all my workflows using this function were giving wildly
incorrect results. I figured out that data.matrix now yields a matrix of
factor levels rather than the actual numeric values
>
>> quant.df.char
> Intensity.SampleA Intensity.SampleB Intensity.SampleC
> 1 919948 1625540 1232780
> 2 1346170 710272 1481040
> 3 15870 83624 62548
>
>> data.matrix(quant.df.char)
> Intensity.SampleA Intensity.SampleB Intensity.SampleC
> [1,] 3 1 1
> [2,] 1 2 2
> [3,] 2 3 3
>
> The change in behaviour of this function is documented in the R v4.0.0
changelog, so it is clearly intentional:
>
> "data.matrix() now converts character columns to factors and from this to
integers."
>
> Now, I know there are other ways to achieve the same conversion, e.g.
sapply(quant.df.char, as.numeric). They aren't quite as straightforward to
read in the code as data.matrix (sapply/lapply in particular I have to
think though whether there will a need to transpose the result!), but the
fact that this base function has been changed (without a way to replicate
the previous behaviour) leads me to suspect that I have probably not
previously been using data.matrix in the intended manner - and I may
therefore be making similar mistakes elsewhere! I've certainly
distributed/handed out R scripting examples in the past that will now give
incorrect results when run on v4+ R.
>
> What even more confusing to me (but possibly related as regards an
answer) is that R v4 broke with long-standing convention to change
default.stringsAsFactors() to FALSE. So on one hand the update took away
what was (at least, from our perspective, with our data - I am sure some
here may disagree!) a perennial source of confusion/bugs for R learners, by
not introducing string factorisation during data import, and then on the
other hand changed a base function to explicitly introduce string
factorisation.. I can't see when converting a character dataset, not to
factors but, straight to numeric factor levels might be that useful (but of
course that doesn't mean it isn't!).
>
> I've had a look through r-help and r-devel archives and couldn't spot any
discussion of this, so apologies if this has been asked before. I'm also
pretty sure my misunderstanding is with the intended use-case of
data.matrix and R ethos around strings/factors rather than the rationale
for the change, which is why I'm asking here.
>
> Best wishes,
>
> Phil
>
> Philip Charles
> Target Discovery Institute, Nuffield Department Of Medicine
> University of Oxford
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ph|||p@ch@r|e@ @end|ng |rom ndm@ox@@c@uk  Wed Nov  4 22:43:53 2020
From: ph|||p@ch@r|e@ @end|ng |rom ndm@ox@@c@uk (Philip Charles)
Date: Wed, 4 Nov 2020 21:43:53 +0000
Subject: [R] Intended use-case for data.matrix
In-Reply-To: <CA+COuteWqLGoj_QyxCZFAEMYN2qr01pQxTHfb3NS60AQPwygFw@mail.gmail.com>
References: <CA+COuteWqLGoj_QyxCZFAEMYN2qr01pQxTHfb3NS60AQPwygFw@mail.gmail.com>
Message-ID: <249C3461-4F26-42DD-9778-A26EC07E25EF@ndm.ox.ac.uk>

Hi Duncan,

Thanks; that's really useful info, and now that you point it out I completely agree that the frame arguments description does make my original use invalid - I will pay closer attention to such details in future.  Would you suggest sapply(...,as.numeric)  is the most 'R'-y way of converting a character dataframe to numeric matrix, or is there a cleaner pattern?

Best wishes,

Phil

On 4 Nov 2020, at 20:37, Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>> wrote:

You can see the change to the help page here:

https://github.com/wch/r-source/commit/d1d3863d72613660727379dd5dffacad32ac9c35#diff-9143902e81e6ad39faace2d926725c4c72b078dd13fbb1223c4a35f833b58ee6

Before the change, it said the input should be

a data frame whose components are logical vectors, factors or numeric vectors

which suggests your input was invalid. But later it says

Logical and factor columns are converted to integers. Any other
column which is not numeric (according to \code{\link{is.numeric}}) is
converted by \code{\link{as.numeric}} or, for S4 objects,
\code{\link{as}(, "numeric")}.

which suggests what you were doing was supported.

It's unfortunate that you didn't know about this change, but it was made in August 2019, and appeared on the news feed here:

https://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2019/08/08#n2019-08-08

so some of the blame for this goes to you for not paying attention and testing unreleased R versions.

To protect yourself against this kind of unpleasant surprise in the future, I'd suggest this:

- Follow the news feed.

- Put your code in a package, and test it against R-devel now and then. (If your package is on CRAN the testing will happen automatically; if it's not on CRAN and not in a package, you could still test against R-devel, but why make your life more difficult by *not* putting it in a package?)

Duncan Murdoch

On 04/11/2020 6:48 a.m., Philip Charles wrote:
> Hi R gurus,
>
> We do a lot of work with biological -omics datasets (genomics, proteomics etc). The text file inputs to R typically contain a mixture of (mostly) character data and numeric data. The number of columns (both character and numeric data) in the file vary with the number of samples measured (which makes use of colClasses , so a typical approach might be
>
> 1) read in the whole file as character matrix
>
> #simulated result of read.table (with stringsAsFactors=FALSE)
> raw <- data.frame(Accession=c('P04637','P01375','P00761'),Description=c('Cellular tumor antigen p53','Tumor necrosis factor','Trypsin'),Species=c('Homo sapiens','Homo sapiens','Sus scrofa'),Intensity.SampleA=c('919948','1346170','15870'),Intensity.SampleB=c('1625540','710272','83624'),Intensity.SampleC=c('1232780','1481040','62548'))
>
> 2) use grep to identify numeric columns based on column names and split the raw matrix
>
> QUANT_COLS <- grepl('^Intensity\\.',colnames(raw))
> META_COLS <- !QUANT_COLS
> quant.df.char <- raw[,QUANT_COLS]
> meta.df <- raw[, META_COLS]
>
> 3) convert the quantitation data frame to a numeric matrix
>
> Prior to R version 4, my standard method for step 3 was to use data.matrix() for this last step. After recently updating from v3.6.3, I've found that all my workflows using this function were giving wildly incorrect results. I figured out that data.matrix now yields a matrix of factor levels rather than the actual numeric values
>
>> quant.df.char
> Intensity.SampleA Intensity.SampleB Intensity.SampleC
> 1 919948 1625540 1232780
> 2 1346170 710272 1481040
> 3 15870 83624 62548
>
>> data.matrix(quant.df.char)
> Intensity.SampleA Intensity.SampleB Intensity.SampleC
> [1,] 3 1 1
> [2,] 1 2 2
> [3,] 2 3 3
>
> The change in behaviour of this function is documented in the R v4.0.0 changelog, so it is clearly intentional:
>
> "data.matrix() now converts character columns to factors and from this to integers."
>
> Now, I know there are other ways to achieve the same conversion, e.g. sapply(quant.df.char, as.numeric). They aren't quite as straightforward to read in the code as data.matrix (sapply/lapply in particular I have to think though whether there will a need to transpose the result!), but the fact that this base function has been changed (without a way to replicate the previous behaviour) leads me to suspect that I have probably not previously been using data.matrix in the intended manner - and I may therefore be making similar mistakes elsewhere! I've certainly distributed/handed out R scripting examples in the past that will now give incorrect results when run on v4+ R.
>
> What even more confusing to me (but possibly related as regards an answer) is that R v4 broke with long-standing convention to change default.stringsAsFactors() to FALSE. So on one hand the update took away what was (at least, from our perspective, with our data - I am sure some here may disagree!) a perennial source of confusion/bugs for R learners, by not introducing string factorisation during data import, and then on the other hand changed a base function to explicitly introduce string factorisation.. I can't see when converting a character dataset, not to factors but, straight to numeric factor levels might be that useful (but of course that doesn't mean it isn't!).
>
> I've had a look through r-help and r-devel archives and couldn't spot any discussion of this, so apologies if this has been asked before. I'm also pretty sure my misunderstanding is with the intended use-case of data.matrix and R ethos around strings/factors rather than the rationale for the change, which is why I'm asking here.
>
> Best wishes,
>
> Phil
>
> Philip Charles
> Target Discovery Institute, Nuffield Department Of Medicine
> University of Oxford
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>





	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov  4 22:50:50 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Nov 2020 16:50:50 -0500
Subject: [R] Intended use-case for data.matrix
In-Reply-To: <249C3461-4F26-42DD-9778-A26EC07E25EF@ndm.ox.ac.uk>
References: <CA+COuteWqLGoj_QyxCZFAEMYN2qr01pQxTHfb3NS60AQPwygFw@mail.gmail.com>
 <249C3461-4F26-42DD-9778-A26EC07E25EF@ndm.ox.ac.uk>
Message-ID: <d17d96ac-e129-cc12-14dd-82ec81d37e1f@gmail.com>

On 04/11/2020 4:43 p.m., Philip Charles wrote:
> Hi Duncan,
> 
> Thanks; that's really useful info, and now that you point it out I 
> completely agree that the frame arguments description does make my 
> original use invalid - I will pay closer attention to such details in 
> future. ?Would you suggest sapply(...,as.numeric) ?is the most 'R'-y way 
> of converting a character dataframe to numeric matrix, or is there a 
> cleaner pattern?

I'd definitely use `as.numeric`. There are some reasons to prefer 
vapply() to sapply() (they are mentioned in the help page).  I tend to 
use for loops more than some people (because I find them more obvious, 
having learned to program a long time ago).

Duncan Murdoch

> 
> Best wishes,
> 
> Phil
> 
>> On 4 Nov 2020, at 20:37, Duncan Murdoch <murdoch.duncan at gmail.com 
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>> You can see the change to the help page here:
>>
>> https://github.com/wch/r-source/commit/d1d3863d72613660727379dd5dffacad32ac9c35#diff-9143902e81e6ad39faace2d926725c4c72b078dd13fbb1223c4a35f833b58ee6
>>
>> Before the change, it said the input should be
>>
>> a data frame whose components are logical vectors, factors or numeric 
>> vectors
>>
>> which suggests your input was invalid. But later it says
>>
>> Logical and factor columns are converted to integers. Any other
>> column which is not numeric (according to \code{\link{is.numeric}}) is
>> converted by \code{\link{as.numeric}} or, for S4 objects,
>> \code{\link{as}(, "numeric")}.
>>
>> which suggests what you were doing was supported.
>>
>> It's unfortunate that you didn't know about this change, but it was 
>> made in August 2019, and appeared on the news feed here:
>>
>> https://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2019/08/08#n2019-08-08
>>
>> so some of the blame for this goes to you for not paying attention and 
>> testing unreleased R versions.
>>
>> To protect yourself against this kind of unpleasant surprise in the 
>> future, I'd suggest this:
>>
>> - Follow the news feed.
>>
>> - Put your code in a package, and test it against R-devel now and 
>> then. (If your package is on CRAN the testing will happen 
>> automatically; if it's not on CRAN and not in a package, you could 
>> still test against R-devel, but why make your life more difficult by 
>> *not* putting it in a package?)
>>
>> Duncan Murdoch
>>
>> On 04/11/2020 6:48 a.m., Philip Charles wrote:
>> > Hi R gurus,
>> > 
>> > We do a lot of work with biological -omics datasets (genomics, proteomics etc). The text file inputs to R typically contain a mixture of (mostly) character data and numeric data. The number of columns (both character and numeric data) in the file vary with the number of samples measured (which makes use of colClasses , so a 
>> typical approach might be
>> > 
>> > 1) read in the whole file as character matrix
>> > 
>> > #simulated result of read.table (with stringsAsFactors=FALSE)
>> > raw <- data.frame(Accession=c('P04637','P01375','P00761'),Description=c('Cellular tumor antigen p53','Tumor necrosis factor','Trypsin'),Species=c('Homo sapiens','Homo sapiens','Sus scrofa'),Intensity.SampleA=c('919948','1346170','15870'),Intensity.SampleB=c('1625540','710272','83624'),Intensity.SampleC=c('1232780','1481040','62548'))
>> > 
>> > 2) use grep to identify numeric columns based on column names and split the raw matrix
>> > 
>> > QUANT_COLS <- grepl('^Intensity\\.',colnames(raw))
>> > META_COLS <- !QUANT_COLS
>> > quant.df.char <- raw[,QUANT_COLS]
>> > meta.df <- raw[, META_COLS]
>> > 
>> > 3) convert the quantitation data frame to a numeric matrix
>> > 
>> > Prior to R version 4, my standard method for step 3 was to use data.matrix() for this last step. After recently updating from v3.6.3, I've found that all my workflows using this function were giving wildly incorrect results. I figured out that data.matrix now yields a matrix of factor levels rather than the actual numeric 
>> values
>> > 
>> >> quant.df.char
>> > Intensity.SampleA Intensity.SampleB Intensity.SampleC
>> > 1 919948 1625540 1232780
>> > 2 1346170 710272 1481040
>> > 3 15870 83624 62548
>> > 
>> >> data.matrix(quant.df.char)
>> > Intensity.SampleA Intensity.SampleB Intensity.SampleC
>> > [1,] 3 1 1
>> > [2,] 1 2 2
>> > [3,] 2 3 3
>> > 
>> > The change in behaviour of this function is documented in the R v4.0.0 changelog, so it is clearly intentional:
>> > 
>> > "data.matrix() now converts character columns to factors and from this to integers."
>> > 
>> > Now, I know there are other ways to achieve the same conversion, e.g. sapply(quant.df.char, as.numeric). They aren't quite as straightforward to read in the code as data.matrix (sapply/lapply in particular I have to think though whether there will a need to transpose the result!), but the fact that this base function has 
>> been changed (without a way to replicate the previous behaviour) leads 
>> me to suspect that I have probably not previously been using 
>> data.matrix in the intended manner - and I may therefore be making 
>> similar mistakes elsewhere! I've certainly distributed/handed out R 
>> scripting examples in the past that will now give incorrect results 
>> when run on v4+ R.
>> > 
>> > What even more confusing to me (but possibly related as regards an answer) is that R v4 broke with long-standing convention to change default.stringsAsFactors() to FALSE. So on one hand the update took away what was (at least, from our perspective, with our data - I am sure some here may disagree!) a perennial source of 
>> confusion/bugs for R learners, by not introducing string factorisation 
>> during data import, and then on the other hand changed a base function 
>> to explicitly introduce string factorisation.. I can't see when 
>> converting a character dataset, not to factors but, straight to 
>> numeric factor levels might be that useful (but of course that doesn't 
>> mean it isn't!).
>> > 
>> > I've had a look through r-help and r-devel archives and couldn't spot any discussion of this, so apologies if this has been asked before. I'm also pretty sure my misunderstanding is with the intended use-case of data.matrix and R ethos around strings/factors rather than the rationale for the change, which is why I'm asking here.
>> > 
>> > Best wishes,
>> > 
>> > Phil
>> > 
>> > Philip Charles
>> > Target Discovery Institute, Nuffield Department Of Medicine
>> > University of Oxford
>> > 
>> > 
>> > 
>> > 
>> > [[alternative HTML version deleted]]
>> > 
>> > ______________________________________________
>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
>> <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>> > 
>>
>>
>>
>


From m|@ojpm @end|ng |rom gm@||@com  Thu Nov  5 03:38:51 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 5 Nov 2020 10:38:51 +0800
Subject: [R] Error message when using "revtools" package
Message-ID: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>

Hi,

    I tried to read a bib file by  "read_bibliography" function in
"revtools" package, but I got an error message but don't know how to fix
it. Anyone can help? Thank you so much!!

###
   library(revtools)
   data2 <- read_bibliography("mlf_ref201105_2.bib", return_df = FALSE)
###

Error message:
####
Error in if (any(names(entry_list) == "author")) { :
  missing value where TRUE/FALSE needed
####

   My "mlf_ref201105_2.bib" file is attached.

   I have no problem reading the built-in ris file:

####
file_location <- system.file(
  "extdata",
  "avian_ecology_bibliography.ris",
  package = "revtools")
x <- read_bibliography(file_location)
####

From bgunter@4567 @end|ng |rom gm@||@com  Thu Nov  5 03:40:15 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 4 Nov 2020 18:40:15 -0800
Subject: [R] Error message when using "revtools" package
In-Reply-To: <CAGxFJbTC-Dh6j=m7+0rJMdAN2iz4vNr8w=n8cDaM_MVcdPEy+w@mail.gmail.com>
References: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>
 <CAGxFJbTC-Dh6j=m7+0rJMdAN2iz4vNr8w=n8cDaM_MVcdPEy+w@mail.gmail.com>
Message-ID: <CAGxFJbQJCg=X3vvXR7_Gh0met0TBEZ2q0Rx2AsdRPcNui_KhEQ@mail.gmail.com>

Perhaps better suggestion: r-sig-meta-analysis  ?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Nov  5 03:41:24 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 4 Nov 2020 18:41:24 -0800
Subject: [R] Fwd:  Error message when using "revtools" package
In-Reply-To: <CAGxFJbQJCg=X3vvXR7_Gh0met0TBEZ2q0Rx2AsdRPcNui_KhEQ@mail.gmail.com>
References: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>
 <CAGxFJbTC-Dh6j=m7+0rJMdAN2iz4vNr8w=n8cDaM_MVcdPEy+w@mail.gmail.com>
 <CAGxFJbQJCg=X3vvXR7_Gh0met0TBEZ2q0Rx2AsdRPcNui_KhEQ@mail.gmail.com>
Message-ID: <CAGxFJbQCyVbDhFgNgCeeF-d2ngxZK69yznZkJRxURBKdF5Gu1Q@mail.gmail.com>

Neglected to cc the list!

Bert

---------- Forwarded message ---------
From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Wed, Nov 4, 2020 at 6:40 PM
Subject: Re: [R] Error message when using "revtools" package
To: John <miaojpm at gmail.com>, R-help <r-help at r-project.org>


Perhaps better suggestion: r-sig-meta-analysis  ?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From m|@ojpm @end|ng |rom gm@||@com  Thu Nov  5 06:25:29 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 5 Nov 2020 13:25:29 +0800
Subject: [R] string concatenation
Message-ID: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>

Hi,

I have a sequence of characters:

x <- c("Alice", "Bob", "Charles")

How can I produce the following results:

"Alice, Bob, Charles"

?

paste? merge?

Thank you very much!

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Thu Nov  5 06:18:02 2020
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 5 Nov 2020 05:18:02 +0000
Subject: [R] [EXT]  string concatenation
In-Reply-To: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
Message-ID: <2905ce7e-24ce-4807-9a24-117ecdfba79e@Spark>

Try

paste(x, collapse = ", ")

Cheers,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On Nov 5, 2020, 4:17 PM +1100, John <miaojpm at gmail.com>, wrote:

x <- c("Alice", "Bob", "Charles")

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Thu Nov  5 06:24:17 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Thu, 5 Nov 2020 13:24:17 +0800
Subject: [R] string concatenation
In-Reply-To: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
Message-ID: <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>

Hi John,

Try paste0(x,collapse = ", ")

Best,
Jiefei

On Thu, Nov 5, 2020 at 1:16 PM John <miaojpm at gmail.com> wrote:

> Hi,
>
> I have a sequence of characters:
>
> x <- c("Alice", "Bob", "Charles")
>
> How can I produce the following results:
>
> "Alice, Bob, Charles"
>
> ?
>
> paste? merge?
>
> Thank you very much!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@k|@we @end|ng |rom gm@||@com  Thu Nov  5 09:20:26 2020
From: m@k|@we @end|ng |rom gm@||@com (Edjabou Vincent)
Date: Thu, 5 Nov 2020 09:20:26 +0100
Subject: [R] string concatenation
In-Reply-To: <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
 <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>
Message-ID: <CALFkoEp3vjKmkJo1-++ZWE8_UuXwpXcq4HKy04OpujGcizH7vg@mail.gmail.com>

Following John request, I am wondering if it is possible to get this result:

Alice, Bob, Charles (without bracket )

Thank you for your help



Med venlig hilsen/ Best regards

Vincent Edjabou
Mobile: +45 31 95 99 33
linkedin.com/vincent
<http://linkedin.com/in/vincent-maklawe-edjabou-9742a41b>

Orcid: 0000-0003-2849-6151



On Thu, Nov 5, 2020 at 6:27 AM Jiefei Wang <szwjf08 at gmail.com> wrote:

> Hi John,
>
> Try paste0(x,collapse = ", ")
>
> Best,
> Jiefei
>
> On Thu, Nov 5, 2020 at 1:16 PM John <miaojpm at gmail.com> wrote:
>
> > Hi,
> >
> > I have a sequence of characters:
> >
> > x <- c("Alice", "Bob", "Charles")
> >
> > How can I produce the following results:
> >
> > "Alice, Bob, Charles"
> >
> > ?
> >
> > paste? merge?
> >
> > Thank you very much!
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Nov  5 11:51:17 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 5 Nov 2020 05:51:17 -0500
Subject: [R] string concatenation
In-Reply-To: <CALFkoEp3vjKmkJo1-++ZWE8_UuXwpXcq4HKy04OpujGcizH7vg@mail.gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
 <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>
 <CALFkoEp3vjKmkJo1-++ZWE8_UuXwpXcq4HKy04OpujGcizH7vg@mail.gmail.com>
Message-ID: <8b4a119b-cf03-abd0-554f-c586af5957f2@gmail.com>

On 05/11/2020 3:20 a.m., Edjabou Vincent wrote:
> Following John request, I am wondering if it is possible to get this result:
> 
> Alice, Bob, Charles (without bracket )

I think you mean "without the quotes".  Use noquote():

   noquote(paste0(x,collapse = ", "))

will print without quotes.  (Internally the data is the same, but a 
class attribute is added that tells print() not to add quotes.)

Duncan Murdoch
> 
> Thank you for your help
> 
> 
> 
> Med venlig hilsen/ Best regards
> 
> Vincent Edjabou
> Mobile: +45 31 95 99 33
> linkedin.com/vincent
> <http://linkedin.com/in/vincent-maklawe-edjabou-9742a41b>
> 
> Orcid: 0000-0003-2849-6151
> 
> 
> 
> On Thu, Nov 5, 2020 at 6:27 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> 
>> Hi John,
>>
>> Try paste0(x,collapse = ", ")
>>
>> Best,
>> Jiefei
>>
>> On Thu, Nov 5, 2020 at 1:16 PM John <miaojpm at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I have a sequence of characters:
>>>
>>> x <- c("Alice", "Bob", "Charles")
>>>
>>> How can I produce the following results:
>>>
>>> "Alice, Bob, Charles"
>>>
>>> ?
>>>
>>> paste? merge?
>>>
>>> Thank you very much!
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Nov  5 12:50:46 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 5 Nov 2020 11:50:46 +0000
Subject: [R] Error message when using "revtools" package
In-Reply-To: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>
References: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>
Message-ID: <1973ba7e-479a-7502-f7cd-e26da2cbd246@dewey.myzen.co.uk>

Dear John

Your .bib file did not make it through the system as only a very limited 
set of attachments is supported. Try to make a minimal .bib file which 
triggers the problem by splitting your file in half, testing each half, 
repeat until you get the smallest file which triggers the error. 
Hopefully that will be a single entry which you can then include in your 
post. It also increases the chances of someone looking at it as a large 
.bib file is going to deter people.

Michael

On 05/11/2020 02:38, John wrote:
> Hi,
> 
>      I tried to read a bib file by  "read_bibliography" function in
> "revtools" package, but I got an error message but don't know how to fix
> it. Anyone can help? Thank you so much!!
> 
> ###
>     library(revtools)
>     data2 <- read_bibliography("mlf_ref201105_2.bib", return_df = FALSE)
> ###
> 
> Error message:
> ####
> Error in if (any(names(entry_list) == "author")) { :
>    missing value where TRUE/FALSE needed
> ####
> 
>     My "mlf_ref201105_2.bib" file is attached.
> 
>     I have no problem reading the built-in ris file:
> 
> ####
> file_location <- system.file(
>    "extdata",
>    "avian_ecology_bibliography.ris",
>    package = "revtools")
> x <- read_bibliography(file_location)
> ####
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From @zwj|08 @end|ng |rom gm@||@com  Thu Nov  5 12:53:00 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Thu, 5 Nov 2020 19:53:00 +0800
Subject: [R] string concatenation
In-Reply-To: <8b4a119b-cf03-abd0-554f-c586af5957f2@gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
 <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>
 <CALFkoEp3vjKmkJo1-++ZWE8_UuXwpXcq4HKy04OpujGcizH7vg@mail.gmail.com>
 <8b4a119b-cf03-abd0-554f-c586af5957f2@gmail.com>
Message-ID: <CAGiFhPMA=0YF88QkjEb4ige8uCmgGJovpgqevHPD3QDM1q84FQ@mail.gmail.com>

Hi,

Thanks for clarifying, there is no quote in the result. The quote in the
output is just R's way to tell you that the variable got printed is a
string. If you add quotes around a string, it will get printed like

"\"Alice, Bob, Charles\""

I hope this helps.

Best,
Jiefei

On Thu, Nov 5, 2020 at 6:51 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 05/11/2020 3:20 a.m., Edjabou Vincent wrote:
> > Following John request, I am wondering if it is possible to get this
> result:
> >
> > Alice, Bob, Charles (without bracket )
>
> I think you mean "without the quotes".  Use noquote():
>
>    noquote(paste0(x,collapse = ", "))
>
> will print without quotes.  (Internally the data is the same, but a
> class attribute is added that tells print() not to add quotes.)
>
> Duncan Murdoch
> >
> > Thank you for your help
> >
> >
> >
> > Med venlig hilsen/ Best regards
> >
> > Vincent Edjabou
> > Mobile: +45 31 95 99 33
> > linkedin.com/vincent
> > <http://linkedin.com/in/vincent-maklawe-edjabou-9742a41b>
> >
> > Orcid: 0000-0003-2849-6151
> >
> >
> >
> > On Thu, Nov 5, 2020 at 6:27 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >
> >> Hi John,
> >>
> >> Try paste0(x,collapse = ", ")
> >>
> >> Best,
> >> Jiefei
> >>
> >> On Thu, Nov 5, 2020 at 1:16 PM John <miaojpm at gmail.com> wrote:
> >>
> >>> Hi,
> >>>
> >>> I have a sequence of characters:
> >>>
> >>> x <- c("Alice", "Bob", "Charles")
> >>>
> >>> How can I produce the following results:
> >>>
> >>> "Alice, Bob, Charles"
> >>>
> >>> ?
> >>>
> >>> paste? merge?
> >>>
> >>> Thank you very much!
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From @nthonytrev|@@n @end|ng |rom gm@||@com  Wed Nov  4 13:04:05 2020
From: @nthonytrev|@@n @end|ng |rom gm@||@com (Anthony Trevisan)
Date: Wed, 4 Nov 2020 07:04:05 -0500
Subject: [R] [R-pkgs] fmpcloudr package
Message-ID: <5D40F6F7-71CB-4A7F-BE1A-4CB398F6BB80@gmail.com>

Hello,

As recommended in https://r-pkgs.org/release.html <https://r-pkgs.org/release.html>, I wanted to notify the R community about a new package for accessing financial data metrics. The package fmpcloudr (https://CRAN.R-project.org/package=fmpcloudr <https://cran.r-project.org/package=fmpcloudr>) interacts with the FMP API. 

FMP offers historical pricing data for indexes, stocks, ETFs, mutual finds, currencies, and crypto. Other financial metrics are available such as technical indicators (EMA, RSI, etc), company financials, and 13F. It?s a great data source and could be beneficial to many R users. You can find more details about the package here: https://tonytrevisan.github.io/fmpcloudr/ <https://tonytrevisan.github.io/fmpcloudr/>

Thank you for supporting such an incredible open source community. Learning R has dramatically reshaped my career path which would have been impossible without the R community.  

Best regards,
Tony



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jo@chim m@iii@g oii zuck@reiii@de  Thu Nov  5 10:55:08 2020
From: jo@chim m@iii@g oii zuck@reiii@de (jo@chim m@iii@g oii zuck@reiii@de)
Date: Thu, 5 Nov 2020 10:55:08 +0100
Subject: [R] [R-pkgs] xmlconvert: A package for converting XML data to R
 data frames and vice versa
Message-ID: <015e01d6b359$bf0c8ba0$3d25a2e0$@zuckarelli.de>

Hello everyone,



Driven by the need to work with XML data from medical systems that use
object-oriented databases I have developed the 'xmlconvert' package. With
its easy-to-use functions xml_to_df() and df_to_xml() it allows to convert
data from XML to R data frames and vice versa. A variety of arguments gives
you control over the specifics of the conversion process.



The package is available on CRAN (visit
https://CRAN.R-project.org/package=xmlconvert for more details). Install it
by executing

> install.packages("xmlconvert", dependencies = TRUE)

in the R console.



You will find more information on GitHub
(https://github.com/jsugarelli/xmlconvert). The GitHub README provides an
intro how to use the package and how to adjust for different ways in which
the data can be represented in the XML documents.



Best,



Joachim



----

Joachim L. Zuckarelli

E-mail: joachim at zuckarelli.de <mailto:joachim at zuckarelli.de>

Website: http://www.zuckarelli.de

Twitter: https://twitter.com/jsugarelli






	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m|@ojpm @end|ng |rom gm@||@com  Fri Nov  6 13:39:31 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Fri, 6 Nov 2020 20:39:31 +0800
Subject: [R] backslash in xtable (generate latex code from R)
Message-ID: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>

I'd like to have $\alpha_1$ in my table, and the column name is $\beta_0$
####
library(xtable)
mytable <- data.frame(beta_0 = c("aa","bb","cc$\\alpha_1$"))
colnames(mytable) <- "$\\beta_0$"
print(xtable(mytable), include.rownames = F, sanitize.colnames.function =
identity)
####

No problem with \beta_0, but a problem with \alpha_1:

\begin{table}[ht]
\centering
\begin{tabular}{l}
  \hline
$\beta_0$ \\
  \hline
aa \\
  bb \\
  cc\$$\backslash$alpha\_1\$ \\
   \hline
\end{tabular}
\end{table}

How may I fix the $\alpha_1$? Thanks!

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Nov  6 13:42:32 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 6 Nov 2020 13:42:32 +0100
Subject: [R] backslash in xtable (generate latex code from R)
In-Reply-To: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>
References: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>
Message-ID: <CAJuCY5ytmD2diXZeoSqx9Y=W7FiuHKVULN1R_E73gryrLnP_yA@mail.gmail.com>

You could use kable() from the knitr package.

kable(mytable, format = "latex", escape = FALSE)

\begin{tabular}{l}
\hline
$\beta_0$\\
\hline
aa\\
\hline
bb\\
\hline
cc$\alpha_1$\\
\hline
\end{tabular}


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


<https://www.inbo.be>


Op vr 6 nov. 2020 om 13:30 schreef John <miaojpm at gmail.com>:

> I'd like to have $\alpha_1$ in my table, and the column name is $\beta_0$
> ####
> library(xtable)
> mytable <- data.frame(beta_0 = c("aa","bb","cc$\\alpha_1$"))
> colnames(mytable) <- "$\\beta_0$"
> print(xtable(mytable), include.rownames = F, sanitize.colnames.function =
> identity)
> ####
>
> No problem with \beta_0, but a problem with \alpha_1:
>
> \begin{table}[ht]
> \centering
> \begin{tabular}{l}
>   \hline
> $\beta_0$ \\
>   \hline
> aa \\
>   bb \\
>   cc\$$\backslash$alpha\_1\$ \\
>    \hline
> \end{tabular}
> \end{table}
>
> How may I fix the $\alpha_1$? Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Nov  6 14:04:28 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 6 Nov 2020 08:04:28 -0500
Subject: [R] backslash in xtable (generate latex code from R)
In-Reply-To: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>
References: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>
Message-ID: <7CDBEC55-DFD0-494A-99B0-B95B445193DF@me.com>

Hi,

It looks like xtable is "sanitizing" special characters in the LaTeX output by default, by adding a double backslash, so that LaTeX will process the characters as literals, rather than specials. It is not parsing the boundary '$' characters to define insertion of math symbols inside text mode.

You have 'sanitize.colnames.function = identity', which is why the column name is output 'as is'.

You would seem to need to do the same thing for the text content within the table content:

> print(xtable(mytable), include.rownames = F, 
        sanitize.colnames.function = identity, 
        sanitize.text.function = identity)
% latex table generated in R 4.0.3 by xtable 1.8-4 package
% Fri Nov  6 07:54:51 2020
\begin{table}[ht]
\centering
\begin{tabular}{l}
  \hline
$\beta_0$ \\ 
  \hline
aa \\ 
  bb \\ 
  cc$\alpha_1$ \\ 
   \hline
\end{tabular}
\end{table}


Regards,

Marc Schwartz


> On Nov 6, 2020, at 7:39 AM, John <miaojpm at gmail.com> wrote:
> 
> I'd like to have $\alpha_1$ in my table, and the column name is $\beta_0$
> ####
> library(xtable)
> mytable <- data.frame(beta_0 = c("aa","bb","cc$\\alpha_1$"))
> colnames(mytable) <- "$\\beta_0$"
> print(xtable(mytable), include.rownames = F, sanitize.colnames.function =
> identity)
> ####
> 
> No problem with \beta_0, but a problem with \alpha_1:
> 
> \begin{table}[ht]
> \centering
> \begin{tabular}{l}
>  \hline
> $\beta_0$ \\
>  \hline
> aa \\
>  bb \\
>  cc\$$\backslash$alpha\_1\$ \\
>   \hline
> \end{tabular}
> \end{table}
> 
> How may I fix the $\alpha_1$? Thanks!


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Nov  6 15:07:50 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 6 Nov 2020 08:07:50 -0600
Subject: [R] how to order variables on correlation plot
Message-ID: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>

Hello

I have data like this:

> head(my_data)
      subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
            C3          C4          C5           C6           C7          C8
1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
           C9         C10
1  0.00328111 -0.00113515
2 -0.00495790  0.00320201
3  0.00208591 -0.00874752
4 -0.00967934  0.00607760
5  0.00611030  0.00876190
6 -0.00990661  0.00635349

I am plotting it with:

library(dplyr)
library(magrittr)
library(corrplot)
d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
res <- cor(d, use = "complete.obs")
pdf("correlation.pdf")
corrplot(res, type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45)
dev.off()

and I am getting the plot in attach. How to make it so that my
variables are shown on the plot in the order they are in my_data data
frame?

Thanks
Ana


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Nov  6 15:08:21 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 6 Nov 2020 08:08:21 -0600
Subject: [R] how to order variables on correlation plot
In-Reply-To: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
References: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
Message-ID: <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>

sorry forgot to attach the plot.

On Fri, Nov 6, 2020 at 8:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello
>
> I have data like this:
>
> > head(my_data)
>       subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
> 1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
> 2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
> 3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
> 4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
> 5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
> 6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
>             C3          C4          C5           C6           C7          C8
> 1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
> 2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
> 3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
> 4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
> 5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
> 6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
>            C9         C10
> 1  0.00328111 -0.00113515
> 2 -0.00495790  0.00320201
> 3  0.00208591 -0.00874752
> 4 -0.00967934  0.00607760
> 5  0.00611030  0.00876190
> 6 -0.00990661  0.00635349
>
> I am plotting it with:
>
> library(dplyr)
> library(magrittr)
> library(corrplot)
> d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
> res <- cor(d, use = "complete.obs")
> pdf("correlation.pdf")
> corrplot(res, type = "upper", order = "hclust",
>          tl.col = "black", tl.srt = 45)
> dev.off()
>
> and I am getting the plot in attach. How to make it so that my
> variables are shown on the plot in the order they are in my_data data
> frame?
>
> Thanks
> Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: correlation.pdf
Type: application/pdf
Size: 11160 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201106/529c5f8b/attachment.pdf>

From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Nov  6 17:43:03 2020
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 6 Nov 2020 11:43:03 -0500
Subject: [R] Bootstrap P-Value
Message-ID: <CAE9stmeLzw7S4+4e+zjvSVCWG7306F8Eov9=cTm-QUKbYYQOAA@mail.gmail.com>

*Dear All:*

*I am trying to compute the p-value of the bootstrap test; please see
below.*

*In example 1 the p-value agrees with the confidence interval.*
*BUT, in example 2  the p-value DOES NOT agree with the confidence
interval. In Example 2, the p-value should be zero or close to zero.*

*I am not sure what went wrong, or not sure if I missed something.*

*any help would be appreciated.*


*with many thanks*
*abou*



#####  Two - Sample Bootstrap

#####  Source:
http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Chernick2011.pdf

#####  Example 1:
#####  ----------



set.seed(1)

n1 <- 29
n1
x1 <- rnorm(n1, 1.143, 0.164) #some random normal variates: mean1 = 1.143
x1

n2 <- 33
n2
x2 <- rnorm(n2, 1.175, 0.169) #2nd random sample: mean2 = 1.175
x2

obs.diff.theta <- mean(x1) - mean(x2)
obs.diff.theta

theta <- as.vector(NULL) #### vector to hold difference estimates

iterations <- 1000

for (i in 1:1000) {                        #bootstrap resamples
 xx1 <- sample(x1, n1, replace = TRUE)
 xx2 <- sample(x2, n2, replace = TRUE)
 theta[i] <- mean(xx1) - mean(xx2)
 }



##### Confidence Interval:
##### --------------------


quantile(theta, probs = c(.025,0.975)) #Efron percentile CI on difference
in means

##### 2.5% 97.5%
##### - 0.1248539 0.0137601


##### P-Value
##### -------

p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)

#####  p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)

p.value



#### R OUTPUT

#### > quantile(theta, probs = c(.025,0.975))
####        2.5%       97.5%
#### -0.12647744  0.02099391

#### > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
#### > p.value
#### [1] 1

#####  Example 2:
#####  ----------


set.seed(5)

n1 <- 29
### n1
x1 <- rnorm(n1, 10.5, 0.15) ######   sample 1 with mean1 = 10.5
### x1

n2 <- 33
### n2
x2 <- rnorm(n2, 1.5, 0.155) #####  Sample 2 with mean2 = 1.5
### x2

obs.diff.theta <- mean(x1) - mean(x2)
obs.diff.theta

theta <- as.vector(NULL) #### vector to hold difference estimates

iterations <- 1000

#####   bootstrap resamples

for (i in 1:1000) {
 xx1 <- sample(x1, n1, replace = TRUE)
 xx2 <- sample(x2, n2, replace = TRUE)
 theta[i] <- mean(xx1) - mean(xx2)
 }



##### Confidence Interval:
##### --------------------


######  CI on difference in means

quantile(theta, probs = c(.025,0.975))



##### P-Value
##### -------

p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)

##### p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)

p.value

##### R OUTPUT

####   > ######  CI on difference in means
####   >
####   > quantile(theta, probs = c(.025,0.975))
####       2.5%    97.5%
####   8.908398 9.060601

####   > ##### P-Value
####   > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)

####   > p.value
####   [1] 0.4835165

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Nov  6 18:24:07 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 6 Nov 2020 12:24:07 -0500
Subject: [R] [External] Re:  how to order variables on correlation plot
In-Reply-To: <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
References: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
 <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
Message-ID: <CAGx1TMCAkY+3xWoWDWE9SsyVYhXFqfAWj8D19YT0E_UfGhOazg@mail.gmail.com>

My guess is that the "%>% data.frame %>%" step turned something into a
character that you thought would be a factor.
See this example.  Remember that the stringsAFactors argument to
data.frame was recently changed.



> tmp <- data.frame(A=c("A","F","B","G","C"), B=1:5, CC=6:10)
> tmp
  A B CC
1 A 1  6
2 F 2  7
3 B 3  8
4 G 4  9
5 C 5 10
> sapply(tmp,class)
          A           B          CC
"character"   "integer"   "integer"
> tmp[order(tmp$A),]
  A B CC
1 A 1  6
3 B 3  8
5 C 5 10
2 F 2  7
4 G 4  9
> tmp$A <- factor(tmp$A, levels=unique(tmp$A))
> sapply(tmp,class)
        A         B        CC
 "factor" "integer" "integer"
> tmp[order(tmp$A),]
  A B CC
1 A 1  6
2 F 2  7
3 B 3  8
4 G 4  9
5 C 5 10
>

On Fri, Nov 6, 2020 at 9:18 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> sorry forgot to attach the plot.
>
> On Fri, Nov 6, 2020 at 8:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello
> >
> > I have data like this:
> >
> > > head(my_data)
> >       subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
> > 1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
> > 2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
> > 3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
> > 4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
> > 5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
> > 6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
> >             C3          C4          C5           C6           C7          C8
> > 1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
> > 2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
> > 3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
> > 4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
> > 5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
> > 6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
> >            C9         C10
> > 1  0.00328111 -0.00113515
> > 2 -0.00495790  0.00320201
> > 3  0.00208591 -0.00874752
> > 4 -0.00967934  0.00607760
> > 5  0.00611030  0.00876190
> > 6 -0.00990661  0.00635349
> >
> > I am plotting it with:
> >
> > library(dplyr)
> > library(magrittr)
> > library(corrplot)
> > d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
> > res <- cor(d, use = "complete.obs")
> > pdf("correlation.pdf")
> > corrplot(res, type = "upper", order = "hclust",
> >          tl.col = "black", tl.srt = 45)
> > dev.off()
> >
> > and I am getting the plot in attach. How to make it so that my
> > variables are shown on the plot in the order they are in my_data data
> > frame?
> >
> > Thanks
> > Ana
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 @end|ng |rom gm@||@com  Fri Nov  6 18:34:48 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Fri, 6 Nov 2020 10:34:48 -0700
Subject: [R] Bootstrap P-Value
In-Reply-To: <CAE9stmeLzw7S4+4e+zjvSVCWG7306F8Eov9=cTm-QUKbYYQOAA@mail.gmail.com>
References: <CAE9stmeLzw7S4+4e+zjvSVCWG7306F8Eov9=cTm-QUKbYYQOAA@mail.gmail.com>
Message-ID: <CAFEqCdy7=XzjQhjOG80qXku4A-p8DFJzVsQ_p9MP5oCGs+5T7g@mail.gmail.com>

A p-value is for testing a specific null hypothesis, but you do not
state your null hypothesis anywhere.

It is the null value that needs to be subtracted from the bootstrap
differences, not the observed difference.  By subtracting the observed
difference you are setting a situation where the p-value will always
be about 0.5 or about 1 (depending on 1 tailed or 2 tailed).  If
instead you subtract a null value (such as 0), then the p-values will
be closer to what you are expecting.

On Fri, Nov 6, 2020 at 9:44 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> *Dear All:*
>
> *I am trying to compute the p-value of the bootstrap test; please see
> below.*
>
> *In example 1 the p-value agrees with the confidence interval.*
> *BUT, in example 2  the p-value DOES NOT agree with the confidence
> interval. In Example 2, the p-value should be zero or close to zero.*
>
> *I am not sure what went wrong, or not sure if I missed something.*
>
> *any help would be appreciated.*
>
>
> *with many thanks*
> *abou*
>
>
>
> #####  Two - Sample Bootstrap
>
> #####  Source:
> http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Chernick2011.pdf
>
> #####  Example 1:
> #####  ----------
>
>
>
> set.seed(1)
>
> n1 <- 29
> n1
> x1 <- rnorm(n1, 1.143, 0.164) #some random normal variates: mean1 = 1.143
> x1
>
> n2 <- 33
> n2
> x2 <- rnorm(n2, 1.175, 0.169) #2nd random sample: mean2 = 1.175
> x2
>
> obs.diff.theta <- mean(x1) - mean(x2)
> obs.diff.theta
>
> theta <- as.vector(NULL) #### vector to hold difference estimates
>
> iterations <- 1000
>
> for (i in 1:1000) {                        #bootstrap resamples
>  xx1 <- sample(x1, n1, replace = TRUE)
>  xx2 <- sample(x2, n2, replace = TRUE)
>  theta[i] <- mean(xx1) - mean(xx2)
>  }
>
>
>
> ##### Confidence Interval:
> ##### --------------------
>
>
> quantile(theta, probs = c(.025,0.975)) #Efron percentile CI on difference
> in means
>
> ##### 2.5% 97.5%
> ##### - 0.1248539 0.0137601
>
>
> ##### P-Value
> ##### -------
>
> p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
>
> #####  p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)
>
> p.value
>
>
>
> #### R OUTPUT
>
> #### > quantile(theta, probs = c(.025,0.975))
> ####        2.5%       97.5%
> #### -0.12647744  0.02099391
>
> #### > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
> #### > p.value
> #### [1] 1
>
> #####  Example 2:
> #####  ----------
>
>
> set.seed(5)
>
> n1 <- 29
> ### n1
> x1 <- rnorm(n1, 10.5, 0.15) ######   sample 1 with mean1 = 10.5
> ### x1
>
> n2 <- 33
> ### n2
> x2 <- rnorm(n2, 1.5, 0.155) #####  Sample 2 with mean2 = 1.5
> ### x2
>
> obs.diff.theta <- mean(x1) - mean(x2)
> obs.diff.theta
>
> theta <- as.vector(NULL) #### vector to hold difference estimates
>
> iterations <- 1000
>
> #####   bootstrap resamples
>
> for (i in 1:1000) {
>  xx1 <- sample(x1, n1, replace = TRUE)
>  xx2 <- sample(x2, n2, replace = TRUE)
>  theta[i] <- mean(xx1) - mean(xx2)
>  }
>
>
>
> ##### Confidence Interval:
> ##### --------------------
>
>
> ######  CI on difference in means
>
> quantile(theta, probs = c(.025,0.975))
>
>
>
> ##### P-Value
> ##### -------
>
> p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
>
> ##### p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)
>
> p.value
>
> ##### R OUTPUT
>
> ####   > ######  CI on difference in means
> ####   >
> ####   > quantile(theta, probs = c(.025,0.975))
> ####       2.5%    97.5%
> ####   8.908398 9.060601
>
> ####   > ##### P-Value
> ####   > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
>
> ####   > p.value
> ####   [1] 0.4835165
>
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Nov  6 19:01:24 2020
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 6 Nov 2020 13:01:24 -0500
Subject: [R] Bootstrap P-Value
In-Reply-To: <CAFEqCdy7=XzjQhjOG80qXku4A-p8DFJzVsQ_p9MP5oCGs+5T7g@mail.gmail.com>
References: <CAE9stmeLzw7S4+4e+zjvSVCWG7306F8Eov9=cTm-QUKbYYQOAA@mail.gmail.com>
 <CAFEqCdy7=XzjQhjOG80qXku4A-p8DFJzVsQ_p9MP5oCGs+5T7g@mail.gmail.com>
Message-ID: <CAE9stmdeOVzuRZfq5Lcsvs-E0AcV=21kJJ1atavzPYkO8sPRUg@mail.gmail.com>

Dear Greg:

H0: Mean 1- Mean 2 = 0
Ha: Mean 1 - Mean 2 ! = 0

with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Fri, Nov 6, 2020 at 12:35 PM Greg Snow <538280 at gmail.com> wrote:

> A p-value is for testing a specific null hypothesis, but you do not
> state your null hypothesis anywhere.
>
> It is the null value that needs to be subtracted from the bootstrap
> differences, not the observed difference.  By subtracting the observed
> difference you are setting a situation where the p-value will always
> be about 0.5 or about 1 (depending on 1 tailed or 2 tailed).  If
> instead you subtract a null value (such as 0), then the p-values will
> be closer to what you are expecting.
>
> On Fri, Nov 6, 2020 at 9:44 AM AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> >
> > *Dear All:*
> >
> > *I am trying to compute the p-value of the bootstrap test; please see
> > below.*
> >
> > *In example 1 the p-value agrees with the confidence interval.*
> > *BUT, in example 2  the p-value DOES NOT agree with the confidence
> > interval. In Example 2, the p-value should be zero or close to zero.*
> >
> > *I am not sure what went wrong, or not sure if I missed something.*
> >
> > *any help would be appreciated.*
> >
> >
> > *with many thanks*
> > *abou*
> >
> >
> >
> > #####  Two - Sample Bootstrap
> >
> > #####  Source:
> > http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Chernick2011.pdf
> >
> > #####  Example 1:
> > #####  ----------
> >
> >
> >
> > set.seed(1)
> >
> > n1 <- 29
> > n1
> > x1 <- rnorm(n1, 1.143, 0.164) #some random normal variates: mean1 = 1.143
> > x1
> >
> > n2 <- 33
> > n2
> > x2 <- rnorm(n2, 1.175, 0.169) #2nd random sample: mean2 = 1.175
> > x2
> >
> > obs.diff.theta <- mean(x1) - mean(x2)
> > obs.diff.theta
> >
> > theta <- as.vector(NULL) #### vector to hold difference estimates
> >
> > iterations <- 1000
> >
> > for (i in 1:1000) {                        #bootstrap resamples
> >  xx1 <- sample(x1, n1, replace = TRUE)
> >  xx2 <- sample(x2, n2, replace = TRUE)
> >  theta[i] <- mean(xx1) - mean(xx2)
> >  }
> >
> >
> >
> > ##### Confidence Interval:
> > ##### --------------------
> >
> >
> > quantile(theta, probs = c(.025,0.975)) #Efron percentile CI on difference
> > in means
> >
> > ##### 2.5% 97.5%
> > ##### - 0.1248539 0.0137601
> >
> >
> > ##### P-Value
> > ##### -------
> >
> > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
> >
> > #####  p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)
> >
> > p.value
> >
> >
> >
> > #### R OUTPUT
> >
> > #### > quantile(theta, probs = c(.025,0.975))
> > ####        2.5%       97.5%
> > #### -0.12647744  0.02099391
> >
> > #### > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/
> (iterations+1)
> > #### > p.value
> > #### [1] 1
> >
> > #####  Example 2:
> > #####  ----------
> >
> >
> > set.seed(5)
> >
> > n1 <- 29
> > ### n1
> > x1 <- rnorm(n1, 10.5, 0.15) ######   sample 1 with mean1 = 10.5
> > ### x1
> >
> > n2 <- 33
> > ### n2
> > x2 <- rnorm(n2, 1.5, 0.155) #####  Sample 2 with mean2 = 1.5
> > ### x2
> >
> > obs.diff.theta <- mean(x1) - mean(x2)
> > obs.diff.theta
> >
> > theta <- as.vector(NULL) #### vector to hold difference estimates
> >
> > iterations <- 1000
> >
> > #####   bootstrap resamples
> >
> > for (i in 1:1000) {
> >  xx1 <- sample(x1, n1, replace = TRUE)
> >  xx2 <- sample(x2, n2, replace = TRUE)
> >  theta[i] <- mean(xx1) - mean(xx2)
> >  }
> >
> >
> >
> > ##### Confidence Interval:
> > ##### --------------------
> >
> >
> > ######  CI on difference in means
> >
> > quantile(theta, probs = c(.025,0.975))
> >
> >
> >
> > ##### P-Value
> > ##### -------
> >
> > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
> >
> > ##### p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)
> >
> > p.value
> >
> > ##### R OUTPUT
> >
> > ####   > ######  CI on difference in means
> > ####   >
> > ####   > quantile(theta, probs = c(.025,0.975))
> > ####       2.5%    97.5%
> > ####   8.908398 9.060601
> >
> > ####   > ##### P-Value
> > ####   > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/
> (iterations+1)
> >
> > ####   > p.value
> > ####   [1] 0.4835165
> >
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>

	[[alternative HTML version deleted]]


From @@kth|pr|y@m@th@v@r@j @end|ng |rom gm@||@com  Fri Nov  6 15:12:27 2020
From: @@kth|pr|y@m@th@v@r@j @end|ng |rom gm@||@com (Sakthipriya M)
Date: Fri, 6 Nov 2020 19:42:27 +0530
Subject: [R] Error in is biallelic
Message-ID: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>

Hi,
am trying to run the following using my SNP data vcf file
maizelight <- vcfR2genlight(maizevcf,n.cores=1)
Why am getting error
Error in is.biallelic(x) :
  trying to get slot "fix" from an object (class "spec_tbl_df") that is not
an S4 object

anybody help to solve this, am just trying comments of R newly.

From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Nov  6 20:45:19 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 6 Nov 2020 11:45:19 -0800
Subject: [R] how to order variables on correlation plot
In-Reply-To: <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
References: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
 <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
Message-ID: <50e643ab-c594-56f8-7d56-0a0a9fda6a4f@comcast.net>

Why did you specify a different order parameter if that is not what you 
wanted?

Suggest you look more carefully at the parameters of the code you are 
copying and pasting and also at the help page, ?corrplot .

-- 

David.

On 11/6/20 6:08 AM, Ana Marija wrote:
> sorry forgot to attach the plot.
>
> On Fri, Nov 6, 2020 at 8:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> Hello
>>
>> I have data like this:
>>
>>> head(my_data)
>>        subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
>> 1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
>> 2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
>> 3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
>> 4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
>> 5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
>> 6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
>>              C3          C4          C5           C6           C7          C8
>> 1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
>> 2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
>> 3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
>> 4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
>> 5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
>> 6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
>>             C9         C10
>> 1  0.00328111 -0.00113515
>> 2 -0.00495790  0.00320201
>> 3  0.00208591 -0.00874752
>> 4 -0.00967934  0.00607760
>> 5  0.00611030  0.00876190
>> 6 -0.00990661  0.00635349
>>
>> I am plotting it with:
>>
>> library(dplyr)
>> library(magrittr)
>> library(corrplot)
>> d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
>> res <- cor(d, use = "complete.obs")
>> pdf("correlation.pdf")
>> corrplot(res, type = "upper", order = "hclust",
>>           tl.col = "black", tl.srt = 45)
>> dev.off()
>>
>> and I am getting the plot in attach. How to make it so that my
>> variables are shown on the plot in the order they are in my_data data
>> frame?
>>
>> Thanks
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Nov  6 21:14:35 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 6 Nov 2020 14:14:35 -0600
Subject: [R] how to order variables on correlation plot
In-Reply-To: <50e643ab-c594-56f8-7d56-0a0a9fda6a4f@comcast.net>
References: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
 <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
 <50e643ab-c594-56f8-7d56-0a0a9fda6a4f@comcast.net>
Message-ID: <CAF9-5jOphsHM0MkX7S2DtnWVG=v1AH7GkUUboPLUkcAA5f55yQ@mail.gmail.com>

Thank you!

On Fri, Nov 6, 2020 at 1:45 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
> Why did you specify a different order parameter if that is not what you wanted?
>
> Suggest you look more carefully at the parameters of the code you are copying and pasting and also at the help page, ?corrplot .
>
> --
>
> David.
>
> On 11/6/20 6:08 AM, Ana Marija wrote:
>
> sorry forgot to attach the plot.
>
> On Fri, Nov 6, 2020 at 8:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello
>
> I have data like this:
>
> head(my_data)
>
>       subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
> 1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
> 2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
> 3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
> 4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
> 5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
> 6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
>             C3          C4          C5           C6           C7          C8
> 1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
> 2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
> 3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
> 4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
> 5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
> 6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
>            C9         C10
> 1  0.00328111 -0.00113515
> 2 -0.00495790  0.00320201
> 3  0.00208591 -0.00874752
> 4 -0.00967934  0.00607760
> 5  0.00611030  0.00876190
> 6 -0.00990661  0.00635349
>
> I am plotting it with:
>
> library(dplyr)
> library(magrittr)
> library(corrplot)
> d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
> res <- cor(d, use = "complete.obs")
> pdf("correlation.pdf")
> corrplot(res, type = "upper", order = "hclust",
>          tl.col = "black", tl.srt = 45)
> dev.off()
>
> and I am getting the plot in attach. How to make it so that my
> variables are shown on the plot in the order they are in my_data data
> frame?
>
> Thanks
> Ana
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkr|de@u @end|ng |rom gm@||@com  Sat Nov  7 01:11:37 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 6 Nov 2020 19:11:37 -0500
Subject: [R] Error in is biallelic
In-Reply-To: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>
References: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>
Message-ID: <CAKZQJMB_TZnpbdhYQXKYxZxHNiWH5j7cNMhR_s-aOO1xPdZ1NA@mail.gmail.com>

I think we need a lot mole information.

see these links for suggestions on how to ask a question.

 http://adv-r.had.co.nz/Reproducibility.html

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


On Fri, 6 Nov 2020 at 14:37, Sakthipriya M <sakthipriyamathavaraj at gmail.com>
wrote:

> Hi,
> am trying to run the following using my SNP data vcf file
> maizelight <- vcfR2genlight(maizevcf,n.cores=1)
> Why am getting error
> Error in is.biallelic(x) :
>   trying to get slot "fix" from an object (class "spec_tbl_df") that is not
> an S4 object
>
> anybody help to solve this, am just trying comments of R newly.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Nov  7 02:24:24 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 6 Nov 2020 17:24:24 -0800
Subject: [R] Error in is biallelic
In-Reply-To: <CAKZQJMB_TZnpbdhYQXKYxZxHNiWH5j7cNMhR_s-aOO1xPdZ1NA@mail.gmail.com>
References: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>
 <CAKZQJMB_TZnpbdhYQXKYxZxHNiWH5j7cNMhR_s-aOO1xPdZ1NA@mail.gmail.com>
Message-ID: <d9ecc859-1170-2304-24c4-1a25ced4e6d3@comcast.net>


On 11/6/20 4:11 PM, John Kane wrote:
> I think we need a lot mole information.
>
> see these links for suggestions on how to ask a question.
>
>   http://adv-r.had.co.nz/Reproducibility.html
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

I agree that more information would be needed for a considered answer 
but I also suspect that placement of the question in a venue that had a 
larger population of persons knowledgeable about the domain of genomics 
might be helpful as well. Two possibilities: The BioConductor mailing 
list and the BioInformatics StackExchange forum.

-- 

David

>
>
> On Fri, 6 Nov 2020 at 14:37, Sakthipriya M <sakthipriyamathavaraj at gmail.com>
> wrote:
>
>> Hi,
>> am trying to run the following using my SNP data vcf file
>> maizelight <- vcfR2genlight(maizevcf,n.cores=1)
>> Why am getting error
>> Error in is.biallelic(x) :
>>    trying to get slot "fix" from an object (class "spec_tbl_df") that is not
>> an S4 object
>>
>> anybody help to solve this, am just trying comments of R newly.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From jrkr|de@u @end|ng |rom gm@||@com  Sat Nov  7 03:36:48 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 6 Nov 2020 21:36:48 -0500
Subject: [R] Error in is biallelic
In-Reply-To: <d9ecc859-1170-2304-24c4-1a25ced4e6d3@comcast.net>
References: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>
 <CAKZQJMB_TZnpbdhYQXKYxZxHNiWH5j7cNMhR_s-aOO1xPdZ1NA@mail.gmail.com>
 <d9ecc859-1170-2304-24c4-1a25ced4e6d3@comcast.net>
Message-ID: <CAKZQJMBscxAG3oYXO9bMLcJw-SMpdBpe5daw_T8hNQhLYzv24A@mail.gmail.com>

Ah, good point.

On Fri, 6 Nov 2020 at 20:24, David Winsemius <dwinsemius at comcast.net> wrote:

>
> On 11/6/20 4:11 PM, John Kane wrote:
> > I think we need a lot mole information.
> >
> > see these links for suggestions on how to ask a question.
> >
> >   http://adv-r.had.co.nz/Reproducibility.html
> >
> >
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> I agree that more information would be needed for a considered answer
> but I also suspect that placement of the question in a venue that had a
> larger population of persons knowledgeable about the domain of genomics
> might be helpful as well. Two possibilities: The BioConductor mailing
> list and the BioInformatics StackExchange forum.
>
> --
>
> David
>
> >
> >
> > On Fri, 6 Nov 2020 at 14:37, Sakthipriya M <
> sakthipriyamathavaraj at gmail.com>
> > wrote:
> >
> >> Hi,
> >> am trying to run the following using my SNP data vcf file
> >> maizelight <- vcfR2genlight(maizevcf,n.cores=1)
> >> Why am getting error
> >> Error in is.biallelic(x) :
> >>    trying to get slot "fix" from an object (class "spec_tbl_df") that
> is not
> >> an S4 object
> >>
> >> anybody help to solve this, am just trying comments of R newly.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From r|tm84 @end|ng |rom gm@||@com  Sat Nov  7 11:42:58 2020
From: r|tm84 @end|ng |rom gm@||@com (Ritwik Mohapatra)
Date: Sat, 7 Nov 2020 16:12:58 +0530
Subject: [R] Data Table not rendering properly using R shiny
Message-ID: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>

Hi All,

I have a data output as below.I want to display them in an interactive html
report using shiny but the data table is not rendering properly and instead
giving NA values.

max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))

Region Sum_as_Hours
1 Africa 1156.0833
2 Americas 740.1667
3 APAC 740.2833
4 Europe 1895.2000
5 PDO 1053.3500
6 UK 0.0000


Rshiny code:

library(shiny)

ui <- fluidPage(
selectInput("Region","Select
Region",max_usage_hours_per_region$Region,selected = TRUE),
tableOutput("table")
)
server <- function(input, output) {
output$table <- renderTable(
max_usage_hours_per_region[input$Region,])
}
shinyApp(ui = ui, server = server)

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Nov  7 16:22:26 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 7 Nov 2020 07:22:26 -0800
Subject: [R] Data Table not rendering properly using R shiny
In-Reply-To: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
References: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
Message-ID: <CAGxFJbQEVtpTMOAQVuGjHbxPJXs7-8CXjLockHJVb0x+tRANpA@mail.gmail.com>

Better to post on  RStudio support, I think. Shiny is an RStudio package
and product and this list if for R language/programming help. The two are
separate.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Nov 7, 2020 at 2:43 AM Ritwik Mohapatra <ritm84 at gmail.com> wrote:

> Hi All,
>
> I have a data output as below.I want to display them in an interactive html
> report using shiny but the data table is not rendering properly and instead
> giving NA values.
>
>
> max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))
>
> Region Sum_as_Hours
> 1 Africa 1156.0833
> 2 Americas 740.1667
> 3 APAC 740.2833
> 4 Europe 1895.2000
> 5 PDO 1053.3500
> 6 UK 0.0000
>
>
> Rshiny code:
>
> library(shiny)
>
> ui <- fluidPage(
> selectInput("Region","Select
> Region",max_usage_hours_per_region$Region,selected = TRUE),
> tableOutput("table")
> )
> server <- function(input, output) {
> output$table <- renderTable(
> max_usage_hours_per_region[input$Region,])
> }
> shinyApp(ui = ui, server = server)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Sat Nov  7 16:37:09 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Sat, 7 Nov 2020 10:37:09 -0500
Subject: [R] Data Table not rendering properly using R shiny
In-Reply-To: <CAGxFJbQEVtpTMOAQVuGjHbxPJXs7-8CXjLockHJVb0x+tRANpA@mail.gmail.com>
References: <CAGxFJbQEVtpTMOAQVuGjHbxPJXs7-8CXjLockHJVb0x+tRANpA@mail.gmail.com>
Message-ID: <795248E9-E917-481E-B5EF-025FB5705ADA@me.com>

Hi,

Please drop R-Devel as a cc: from this thread for further replies.

This topic is definitely not relevant there and cross-posting is not needed, but does require manual moderation.

Thanks,

Marc Schwartz

> On Nov 7, 2020, at 10:23 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ?Better to post on  RStudio support, I think. Shiny is an RStudio package
> and product and this list if for R language/programming help. The two are
> separate.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
>> On Sat, Nov 7, 2020 at 2:43 AM Ritwik Mohapatra <ritm84 at gmail.com> wrote:
>> 
>> Hi All,
>> 
>> I have a data output as below.I want to display them in an interactive html
>> report using shiny but the data table is not rendering properly and instead
>> giving NA values.
>> 
>> 
>> max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))
>> 
>> Region Sum_as_Hours
>> 1 Africa 1156.0833
>> 2 Americas 740.1667
>> 3 APAC 740.2833
>> 4 Europe 1895.2000
>> 5 PDO 1053.3500
>> 6 UK 0.0000
>> 
>> 
>> Rshiny code:
>> 
>> library(shiny)
>> 
>> ui <- fluidPage(
>> selectInput("Region","Select
>> Region",max_usage_hours_per_region$Region,selected = TRUE),
>> tableOutput("table")
>> )
>> server <- function(input, output) {
>> output$table <- renderTable(
>> max_usage_hours_per_region[input$Region,])
>> }
>> shinyApp(ui = ui, server = server)
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov  7 16:41:32 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Nov 2020 07:41:32 -0800
Subject: [R] Data Table not rendering properly using R shiny
In-Reply-To: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
References: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
Message-ID: <CCD71CB9-FF37-4621-AB4F-74C8720350B3@dcn.davis.ca.us>

This looks odd...

max_usage_hours_per_region[input$Region,]

This would only work if you had rownames on that data frame corresponding to the names of the Regions. This is a common R mistake... you probably need

logical_idx <- max_usage_hours_per_region$Region == input$Region
max_usage_hours_per_region[  logical_idx,]

That said, it is very difficult to separate out R questions when mixed into shiny code, so you would help yourself and this list to work on minimal reproducible examples that focus on the R syntax if possible for posts here. Read the Posting Guide.

On November 7, 2020 2:42:58 AM PST, Ritwik Mohapatra <ritm84 at gmail.com> wrote:
>Hi All,
>
>I have a data output as below.I want to display them in an interactive
>html
>report using shiny but the data table is not rendering properly and
>instead
>giving NA values.
>
>max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))
>
>Region Sum_as_Hours
>1 Africa 1156.0833
>2 Americas 740.1667
>3 APAC 740.2833
>4 Europe 1895.2000
>5 PDO 1053.3500
>6 UK 0.0000
>
>
>Rshiny code:
>
>library(shiny)
>
>ui <- fluidPage(
>selectInput("Region","Select
>Region",max_usage_hours_per_region$Region,selected = TRUE),
>tableOutput("table")
>)
>server <- function(input, output) {
>output$table <- renderTable(
>max_usage_hours_per_region[input$Region,])
>}
>shinyApp(ui = ui, server = server)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Nov  7 16:57:44 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 7 Nov 2020 15:57:44 +0000
Subject: [R] Data Table not rendering properly using R shiny
In-Reply-To: <CCD71CB9-FF37-4621-AB4F-74C8720350B3@dcn.davis.ca.us>
References: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
 <CCD71CB9-FF37-4621-AB4F-74C8720350B3@dcn.davis.ca.us>
Message-ID: <b5a292d0-b467-05ab-f00f-4273448e1dc7@sapo.pt>

Hello,

Or maybe


logical_idx <- max_usage_hours_per_region$Region %in% input$Region


Another option is ?match


Hope this helps,

Rui Barradas


?s 15:41 de 07/11/20, Jeff Newmiller escreveu:
> This looks odd...
> 
> max_usage_hours_per_region[input$Region,]
> 
> This would only work if you had rownames on that data frame corresponding to the names of the Regions. This is a common R mistake... you probably need
> 
> logical_idx <- max_usage_hours_per_region$Region == input$Region
> max_usage_hours_per_region[  logical_idx,]
> 
> That said, it is very difficult to separate out R questions when mixed into shiny code, so you would help yourself and this list to work on minimal reproducible examples that focus on the R syntax if possible for posts here. Read the Posting Guide.
> 
> On November 7, 2020 2:42:58 AM PST, Ritwik Mohapatra <ritm84 at gmail.com> wrote:
>> Hi All,
>>
>> I have a data output as below.I want to display them in an interactive
>> html
>> report using shiny but the data table is not rendering properly and
>> instead
>> giving NA values.
>>
>> max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))
>>
>> Region Sum_as_Hours
>> 1 Africa 1156.0833
>> 2 Americas 740.1667
>> 3 APAC 740.2833
>> 4 Europe 1895.2000
>> 5 PDO 1053.3500
>> 6 UK 0.0000
>>
>>
>> Rshiny code:
>>
>> library(shiny)
>>
>> ui <- fluidPage(
>> selectInput("Region","Select
>> Region",max_usage_hours_per_region$Region,selected = TRUE),
>> tableOutput("table")
>> )
>> server <- function(input, output) {
>> output$table <- renderTable(
>> max_usage_hours_per_region[input$Region,])
>> }
>> shinyApp(ui = ui, server = server)
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From @purd|e@@ @end|ng |rom gm@||@com  Sun Nov  8 06:39:14 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 8 Nov 2020 18:39:14 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
Message-ID: <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>

> What can you tell me about plans to analyze data from this year's
> general election, especially to detect possible fraud?

I was wondering if there's any R packages with out-of-the-box
functions for this sort of thing.
Can you please let us know, if you find any.

> I might be able to help with such an effort.  I have NOT done
> much with election data, but I have developed tools for data analysis,
> including web scraping, and included them in R packages available on the
> Comprehensive R Archive Network (CRAN) and GitHub.[1]

Do you have a URL for detailed election results?
Or even better, a nice R-friendly CSV file...

I recognize that the results aren't complete.
And that such a file may need to be updated later.
But that doesn't necessarily prevent modelling now.


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sun Nov  8 09:24:52 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sun, 8 Nov 2020 02:24:52 -0600
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
Message-ID: <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>



On 2020-11-07 23:39, Abby Spurdle wrote:
>> What can you tell me about plans to analyze data from this year's
>> general election, especially to detect possible fraud?
> 
> I was wondering if there's any R packages with out-of-the-box
> functions for this sort of thing.
> Can you please let us know, if you find any.
> 
>> I might be able to help with such an effort.  I have NOT done
>> much with election data, but I have developed tools for data analysis,
>> including web scraping, and included them in R packages available on the
>> Comprehensive R Archive Network (CRAN) and GitHub.[1]
> 
> Do you have a URL for detailed election results?
> Or even better, a nice R-friendly CSV file...
> 
> I recognize that the results aren't complete.
> And that such a file may need to be updated later.
> But that doesn't necessarily prevent modelling now.


	  I asked, because I don't know of any such.  With the increasingly 
vicious, widespread and systematic attacks on the integrity of elections 
in the US, I think it would be good to have a central database of 
election results with tools regularly scraping websites of local and 
state election authorities.  Whenever new data were posted, the software 
would update the central repository and send emails to anyone 
interested.  That could simplify data acquisition, because historical 
data could already be available there.  And it would be one standard 
format for the entire US and maybe the world.


	  This could be extremely valuable in exposing electoral fraud, thereby 
reducing its magnitude and effectiveness.  This is a global problem, but 
it seems to have gotten dramatically worse in the US in recent years.[2]


	  I'd like to join -- or organize -- a team of people working on this. 
If we can create the database and data analysis tools in a package like 
Ecfun on CRAN, I think we can interest college profs, especially those 
teaching statistics to political science students, who would love to 
involve their students in something like this.  They could access data 
real time in classes, analyze it using standard tools that we could 
develop, and involve their students in discussing what it means and what 
it doesn't.  They could discuss Bayesian sequential updating and quality 
control concepts using data that are real and relevant to the lives of 
their students.  It could help get students excited about both 
statistics and elections.


	  Such a project may already exist.  I know there are projects at some 
major universities that sound like they might support this.  However 
with the limited time I've invested in this so far, I didn't find any 
that seemed to provide easy access to such data and an easy way to join 
such a project.  Ballotpedia has such data but don't want help in 
analyzing it and asked for a few hundred dollars for data for one 
election cycle in Missouri, which is what I requested.  I can get that 
for free from the web site of the Missouri Secretary of State.


	  I thought I might next ask the Carter Center about this.  However, 
but I'm totally consumed with other priorities right now.  I don't plan 
to do anything on this in the short term -- unless I can find 
collaborators.


	  If such a central database doesn't exist -- and maybe even if it does 
-- I thought it might be good to make all the data available in a 
standard format in Wikidata, which is a project of the Wikimedia 
Foundation, which is also the parent organization of Wikipedia.  Then I 
could help create software and documentation on how to scrape data from 
the web sites of different election organizations that have it and 
automatically update Wikidata while also sending emails to people who 
express interest in those election results.  Then we could create 
software for analyzing such data and make that available, e.g., on 
Wikiversity, which is another project of the Wikimedia Foundation -- 
with the R code in Ecfun or some other CRAN package.


	  If we start now, I think we could have something mediocre in time for 
various local elections that occur next year with improvements for the 
2022 US Congressional elections and something even better for the 2024 
US presidential elections.


	  Thanks for asking.
	  Spencer Graves


[1]
https://github.com/sbgraves237


[2]
https://en.wikiversity.org/wiki/Electoral_integrity_in_the_United_States


From bgunter@4567 @end|ng |rom gm@||@com  Sun Nov  8 16:32:50 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 8 Nov 2020 07:32:50 -0800
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
Message-ID: <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>

Unless I misunderstand, clearly such a repository already exists -- the NY
Times, AP, CNN, etc. etc. already have interactive web pages that did
this!. It doesn't seem to make any difference to Trump conspiracy theorists
and partisans, though.

Also, as usual, a web search (on "central repository of US election
results") brought up what seemed like many relevant hits of historical
data. You may wish to contact one of these sources for further ino.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Nov 8, 2020 at 12:25 AM Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

>
>
> On 2020-11-07 23:39, Abby Spurdle wrote:
> >> What can you tell me about plans to analyze data from this year's
> >> general election, especially to detect possible fraud?
> >
> > I was wondering if there's any R packages with out-of-the-box
> > functions for this sort of thing.
> > Can you please let us know, if you find any.
> >
> >> I might be able to help with such an effort.  I have NOT done
> >> much with election data, but I have developed tools for data analysis,
> >> including web scraping, and included them in R packages available on the
> >> Comprehensive R Archive Network (CRAN) and GitHub.[1]
> >
> > Do you have a URL for detailed election results?
> > Or even better, a nice R-friendly CSV file...
> >
> > I recognize that the results aren't complete.
> > And that such a file may need to be updated later.
> > But that doesn't necessarily prevent modelling now.
>
>
>           I asked, because I don't know of any such.  With the
> increasingly
> vicious, widespread and systematic attacks on the integrity of elections
> in the US, I think it would be good to have a central database of
> election results with tools regularly scraping websites of local and
> state election authorities.  Whenever new data were posted, the software
> would update the central repository and send emails to anyone
> interested.  That could simplify data acquisition, because historical
> data could already be available there.  And it would be one standard
> format for the entire US and maybe the world.
>
>
>           This could be extremely valuable in exposing electoral fraud,
> thereby
> reducing its magnitude and effectiveness.  This is a global problem, but
> it seems to have gotten dramatically worse in the US in recent years.[2]
>
>
>           I'd like to join -- or organize -- a team of people working on
> this.
> If we can create the database and data analysis tools in a package like
> Ecfun on CRAN, I think we can interest college profs, especially those
> teaching statistics to political science students, who would love to
> involve their students in something like this.  They could access data
> real time in classes, analyze it using standard tools that we could
> develop, and involve their students in discussing what it means and what
> it doesn't.  They could discuss Bayesian sequential updating and quality
> control concepts using data that are real and relevant to the lives of
> their students.  It could help get students excited about both
> statistics and elections.
>
>
>           Such a project may already exist.  I know there are projects at
> some
> major universities that sound like they might support this.  However
> with the limited time I've invested in this so far, I didn't find any
> that seemed to provide easy access to such data and an easy way to join
> such a project.  Ballotpedia has such data but don't want help in
> analyzing it and asked for a few hundred dollars for data for one
> election cycle in Missouri, which is what I requested.  I can get that
> for free from the web site of the Missouri Secretary of State.
>
>
>           I thought I might next ask the Carter Center about this.
> However,
> but I'm totally consumed with other priorities right now.  I don't plan
> to do anything on this in the short term -- unless I can find
> collaborators.
>
>
>           If such a central database doesn't exist -- and maybe even if it
> does
> -- I thought it might be good to make all the data available in a
> standard format in Wikidata, which is a project of the Wikimedia
> Foundation, which is also the parent organization of Wikipedia.  Then I
> could help create software and documentation on how to scrape data from
> the web sites of different election organizations that have it and
> automatically update Wikidata while also sending emails to people who
> express interest in those election results.  Then we could create
> software for analyzing such data and make that available, e.g., on
> Wikiversity, which is another project of the Wikimedia Foundation --
> with the R code in Ecfun or some other CRAN package.
>
>
>           If we start now, I think we could have something mediocre in
> time for
> various local elections that occur next year with improvements for the
> 2022 US Congressional elections and something even better for the 2024
> US presidential elections.
>
>
>           Thanks for asking.
>           Spencer Graves
>
>
> [1]
> https://github.com/sbgraves237
>
>
> [2]
> https://en.wikiversity.org/wiki/Electoral_integrity_in_the_United_States
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Nov  9 05:09:05 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 9 Nov 2020 17:09:05 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
Message-ID: <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>

> such a repository already exists -- the NY Times, AP, CNN, etc. etc. already have interactive web pages that did this

I've been looking for presidential election results, by ***county***.
I've found historic results, including results for 2016.

However, I can't find such a dataset, for 2020.
(Even though this seems like an obvious thing to publish).

I suspect that the NY Times has the data, but I haven't been able to
work where the data is on their website, or how to access it.

More ***specific*** suggestions would be appreciated...?


From bgunter@4567 @end|ng |rom gm@||@com  Mon Nov  9 05:25:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 8 Nov 2020 20:25:33 -0800
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
 <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
Message-ID: <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>

NYT  had interactive maps that reported  votes by county. So try contacting
them.


Bert

On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> > such a repository already exists -- the NY Times, AP, CNN, etc. etc.
> already have interactive web pages that did this
>
> I've been looking for presidential election results, by ***county***.
> I've found historic results, including results for 2016.
>
> However, I can't find such a dataset, for 2020.
> (Even though this seems like an obvious thing to publish).
>
> I suspect that the NY Times has the data, but I haven't been able to
> work where the data is on their website, or how to access it.
>
> More ***specific*** suggestions would be appreciated...?
>

	[[alternative HTML version deleted]]


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Mon Nov  9 06:53:46 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Mon, 9 Nov 2020 00:53:46 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
 <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
 <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>
Message-ID: <ae88e502-8011-95b4-31eb-a5db33371aed@molbio.mgh.harvard.edu>

You can try here: https://decisiondeskhq.com/

I think they have what you are looking for. From their website:

"Create a FREE account to access up to the minute election results and 
insights on all U.S. Federal elections. Decision Desk HQ & ?ptimus 
provide live election night coverage, race-specific results including 
county-level returns, and exclusive race probabilities for key 
battleground races."

 ?? Also, this article provides a little, emphasis on little, of 
statistical analysis of election results, but it may be a place to start.

https://www.theepochtimes.com/statistical-anomalies-in-biden-votes-analyses-indicate_3570518.html?utm_source=newsnoe&utm_medium=email&utm_campaign=breaking-2020-11-08-5

Matthew

On 11/8/20 11:25 PM, Bert Gunter wrote:
>          External Email - Use Caution
>
> NYT  had interactive maps that reported  votes by county. So try contacting
> them.
>
>
> Bert
>
> On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
>>> such a repository already exists -- the NY Times, AP, CNN, etc. etc.
>> already have interactive web pages that did this
>>
>> I've been looking for presidential election results, by ***county***.
>> I've found historic results, including results for 2016.
>>
>> However, I can't find such a dataset, for 2020.
>> (Even though this seems like an obvious thing to publish).
>>
>> I suspect that the NY Times has the data, but I haven't been able to
>> work where the data is on their website, or how to access it.
>>
>> More ***specific*** suggestions would be appreciated...?
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://secure-web.cisco.com/1C8m4dUQtDXEQdbAFTH153ehiJcvHuL_FkvDGeJBHhMRYZauAp6gdevfmLIh2MLpRjBx7LXAG9QpagRV63oMY5AyQF6uOkNa7JGw-0zGZKIFHoSuZtjpcIokATDMxqoJlVfCiktqIYXEiJcrovbnxo-DAgLEiREocQrn0yMbLc2A-gwR3CN9XurWkU21TUD1CLJ-3gpiCLKKe9BdHWdaeEA/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> PLEASE do read the posting guide http://secure-web.cisco.com/1ppZyk8SO6U25PKNDKtGQ-VIADLxXgKvnHc8QlV3cUMNPzLQvS8E0i9cg05EyzUyHnFjj2QWDjvAjyuduvE1P8Nr0TogQweiuBysM9a1rXjQn1EOaypHdqwa2_inODK1icu0Ff33AZDB00N4x-nYxZ2e16nArVuaMEddaLXBhtBYMn2LAcPYJ8s2wGN10heiFWywn-r8--Hw77GJx1hkTgg/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Nov  9 12:38:12 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 9 Nov 2020 11:38:12 +0000
Subject: [R] paste() turns list element character vector into deparsed
 expression. Why?
Message-ID: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>

I was just surprised by very un-intuitive behaviour of paste(), which appears to collapse a one-column data frame or one-element list into a deparsed expression, rather than producing the expected string. Can someone kindly explain what's going on here?


reprex:
=======

list(s = c("xyz", "uvw"))
#     s
# 1 xyz
# 2 uvw

paste(list(s = c("xyz", "uvw")), collapse = "")
# [1] "c(\"xyz\", \"uvw\")"   # This is unexpected!

I would have expected:
# [1] "xyzuvw"
 
... which I do get with e.g.
paste(list(s = c("xyz", "uvw"))$s, collapse = "")

But what logic is there in returning a deparsed expression?



Thanks!
Boris

From rub@k @end|ng |rom m@th@@@u@dk  Mon Nov  9 13:24:51 2020
From: rub@k @end|ng |rom m@th@@@u@dk (Ege Rubak)
Date: Mon, 9 Nov 2020 12:24:51 +0000
Subject: [R] paste() turns list element character vector into deparsed
 expression. Why?
In-Reply-To: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>
References: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>
Message-ID: <fa74a036c97f340f484049186eb0a1fecb689df1.camel@math.aau.dk>

I think `paste()` just calls `as.character()` on each input argument
and then collapses things afterwards. Calling `as.character()` on the
first input argument generates exactly the output you show (and didn't
expect) and there is nothing to collapse. So changing `collapse = ""`
to anything else doesn't change behaviour.

The question is reduced to how `as.character()` should handle a list as
input. It seems to me that this input is so generic that it is hard to
handle graciously without all kinds of special cases. So you expect the
length one list

as.character(list(s = c("xyz", "uvw"))

to return the length 2 character vector `c("xyz", "uvw")`? What should

as.character(list(s = c("xyz", "uvw"), t = c("a", "b", "c"))

return?

Kind regards,
Ege

On Mon, 2020-11-09 at 11:38 +0000, Boris Steipe wrote:
> I was just surprised by very un-intuitive behaviour of paste(), which
> appears to collapse a one-column data frame or one-element list into
> a deparsed expression, rather than producing the expected string. Can
> someone kindly explain what's going on here?
> 
> 
> reprex:
> =======
> 
> list(s = c("xyz", "uvw"))
> #     s
> # 1 xyz
> # 2 uvw
> 
> paste(list(s = c("xyz", "uvw")), collapse = "")
> # [1] "c(\"xyz\", \"uvw\")"   # This is unexpected!
> 
> I would have expected:
> # [1] "xyzuvw"
>  
> ... which I do get with e.g.
> paste(list(s = c("xyz", "uvw"))$s, collapse = "")
> 
> But what logic is there in returning a deparsed expression?
> 
> 
> 
> Thanks!
> Boris
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Nov  9 13:58:22 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 9 Nov 2020 12:58:22 +0000
Subject: [R] paste() turns list element character vector into deparsed
 expression. Why?
In-Reply-To: <fa74a036c97f340f484049186eb0a1fecb689df1.camel@math.aau.dk>
References: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>
 <fa74a036c97f340f484049186eb0a1fecb689df1.camel@math.aau.dk>
Message-ID: <D76CB58F-F845-4FDE-9FBF-C42C88E1A114@utoronto.ca>

Thanks Ege -

That narrows it down, ... but it's still weird.

My issue is that I don't consider "c(\"xyz\", \"uvw\")" to be a valid character representation of a list. c() is a function, so "c(\"xyz\", \"uvw\")" is a string representation of a function call that could be  eval(parse(...))'ed into a two-element vector ... but considering this a coercion seems really weird.

What do I think your example should return? An object of the same general structure as the input, with non-character components coerced to character. And if that's not possible because there is no good character representation (e.g. if its a closure) than it should return an error. 


Cheers,
Boris

 


> On 2020-11-09, at 22:24, Ege Rubak <rubak at math.aau.dk> wrote:
> 
> EXTERNAL EMAIL:  Treat content with extra caution.
> 
> I think `paste()` just calls `as.character()` on each input argument
> and then collapses things afterwards. Calling `as.character()` on the
> first input argument generates exactly the output you show (and didn't
> expect) and there is nothing to collapse. So changing `collapse = ""`
> to anything else doesn't change behaviour.
> 
> The question is reduced to how `as.character()` should handle a list as
> input. It seems to me that this input is so generic that it is hard to
> handle graciously without all kinds of special cases. So you expect the
> length one list
> 
> as.character(list(s = c("xyz", "uvw"))
> 
> to return the length 2 character vector `c("xyz", "uvw")`? What should
> 
> as.character(list(s = c("xyz", "uvw"), t = c("a", "b", "c"))
> 
> return?
> 
> Kind regards,
> Ege
> 
> On Mon, 2020-11-09 at 11:38 +0000, Boris Steipe wrote:
>> I was just surprised by very un-intuitive behaviour of paste(), which
>> appears to collapse a one-column data frame or one-element list into
>> a deparsed expression, rather than producing the expected string. Can
>> someone kindly explain what's going on here?
>> 
>> 
>> reprex:
>> =======
>> 
>> list(s = c("xyz", "uvw"))
>> #     s
>> # 1 xyz
>> # 2 uvw
>> 
>> paste(list(s = c("xyz", "uvw")), collapse = "")
>> # [1] "c(\"xyz\", \"uvw\")"   # This is unexpected!
>> 
>> I would have expected:
>> # [1] "xyzuvw"
>> 
>> ... which I do get with e.g.
>> paste(list(s = c("xyz", "uvw"))$s, collapse = "")
>> 
>> But what logic is there in returning a deparsed expression?
>> 
>> 
>> 
>> Thanks!
>> Boris
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Mon Nov  9 14:06:08 2020
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Mon, 9 Nov 2020 14:06:08 +0100
Subject: [R] [effects] Wrong xlevels in effects plot for mixed effects model
 when multiline = TRUE
In-Reply-To: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
References: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
Message-ID: <5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>

Dear list members,

I observe a strange/wrong graphical output when I set the xlevels
in (e. g.) allEffects for an lmer model and plot the effects with
multiline = TRUE. I have compiled a reprex for which you need the
lmer model and the environment in which the model was fitted. They
are contained in the zip file at
https://jlubox.uni-giessen.de/dl/fiSzTCc3bW8z2npZvPpqG1xr/m-and-G1.zip
After unpacking the following should work:

m <- readRDS("m.rds")   # The lmer-model.
G1 <- readRDS("G1.rds") # Environment in which the model
                          # was fitted; needed by alaEffects.
summary(m) # Just to see the model.

library(effects)
aE <- allEffects(m, xlevels = list(gProt = 1:6 * 30))
                      # Non-default values for xlevels.

plot(aE)                      # Fine.
plot(aE, x.var = "Age")       # Fine.
plot(aE, lines = list(multiline = TRUE))  # Fine.

plot(aE, lines = list(multiline = TRUE),
       x.var = "Age")        # Nonsense.


Anybody any idea about the reason, my mistake, or a
workaround? Thx for any hint!

   Regards  --  Gerrit


PS:
  > sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] effects_4.2-0 carData_3.0-4

loaded via a namespace (and not attached):
   [1] Rcpp_1.0.5       lattice_0.20-41  MASS_7.3-53      grid_4.0.2 
DBI_1.1.0
   [6] nlme_3.1-149     survey_4.0       estimability_1.3 minqa_1.2.4 
nloptr_1.2.2.2
[11] Matrix_1.2-18    boot_1.3-25      splines_4.0.2    statmod_1.4.34 
lme4_1.1-23
[16] tools_4.0.2      survival_3.2-3   yaml_2.2.1       compiler_4.0.2 
colorspace_1.4-1
[21] mitools_2.4      insight_0.9.5    nnet_7.3-14

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner


From vgher@rd @end|ng |rom @|@@@@|t  Fri Nov  6 16:13:11 2020
From: vgher@rd @end|ng |rom @|@@@@|t (Valerio Gherardi)
Date: Fri, 6 Nov 2020 16:13:11 +0100
Subject: [R] [R-pkgs] sbo: N-gram Stupid Back-Off models in R
Message-ID: <40ef1bf6-d199-287f-4905-b3d532c7049f@sissa.it>

Dear all,

I would like to introduce
sbo: Utilities for building and evaluating text prediction functions 
based on Stupid Back-off N-gram models.

v0.3.0 is now on CRAN: 
https://cran.r-project.org/web/packages/sbo/index.html
website: https://vgherard.github.io/sbo/
For bugs/issues: https://github.com/vgherard/sbo

Feedback of any kind is welcome.

Sincerely,
Valerio Gherardi.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@|| @end|ng |rom @|ex@ndr@thorn@com  Mon Nov  9 15:23:17 2020
From: m@|| @end|ng |rom @|ex@ndr@thorn@com (Alexandra Thorn)
Date: Mon, 9 Nov 2020 09:23:17 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <ae88e502-8011-95b4-31eb-a5db33371aed@molbio.mgh.harvard.edu>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
 <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
 <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>
 <ae88e502-8011-95b4-31eb-a5db33371aed@molbio.mgh.harvard.edu>
Message-ID: <20201109092317.1858ddd0@athorn-Lemur-Ultra>

This thread strikes me as pretty far off-topic for a forum dedicated to
software support on R.

https://www.r-project.org/mail.html#instructions
"The ?main? R mailing list, for discussion about problems and solutions
using R, announcements (not covered by ?R-announce? or ?R-packages?,
see above), about the availability of new functionality for R and
documentation of R, comparison and compatibility with S-plus, and for
the posting of nice examples and benchmarks. Do read the posting guide
before sending anything!"

https://www.r-project.org/posting-guide.html
"The R mailing lists are primarily intended for questions and
discussion about the R software. However, questions about statistical
methodology are sometimes posted. If the question is well-asked and of
interest to someone on the list, it may elicit an informative
up-to-date answer. See also the Usenet groups sci.stat.consult (applied
statistics and consulting) and sci.stat.math (mathematical stat and
probability)."

On Mon, 9 Nov 2020 00:53:46 -0500
Matthew McCormack <mccormack at molbio.mgh.harvard.edu> wrote:

> You can try here: https://decisiondeskhq.com/
> 
> I think they have what you are looking for. From their website:
> 
> "Create a FREE account to access up to the minute election results
> and insights on all U.S. Federal elections. Decision Desk HQ &
> ?ptimus provide live election night coverage, race-specific results
> including county-level returns, and exclusive race probabilities for
> key battleground races."
> 
>  ?? Also, this article provides a little, emphasis on little, of 
> statistical analysis of election results, but it may be a place to
> start.
> 
> https://www.theepochtimes.com/statistical-anomalies-in-biden-votes-analyses-indicate_3570518.html?utm_source=newsnoe&utm_medium=email&utm_campaign=breaking-2020-11-08-5
> 
> Matthew
> 
> On 11/8/20 11:25 PM, Bert Gunter wrote:
> >          External Email - Use Caution
> >
> > NYT  had interactive maps that reported  votes by county. So try
> > contacting them.
> >
> >
> > Bert
> >
> > On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com>
> > wrote: 
> >>> such a repository already exists -- the NY Times, AP, CNN, etc.
> >>> etc.  
> >> already have interactive web pages that did this
> >>
> >> I've been looking for presidential election results, by
> >> ***county***. I've found historic results, including results for
> >> 2016.
> >>
> >> However, I can't find such a dataset, for 2020.
> >> (Even though this seems like an obvious thing to publish).
> >>
> >> I suspect that the NY Times has the data, but I haven't been able
> >> to work where the data is on their website, or how to access it.
> >>
> >> More ***specific*** suggestions would be appreciated...?
> >>  
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://secure-web.cisco.com/1C8m4dUQtDXEQdbAFTH153ehiJcvHuL_FkvDGeJBHhMRYZauAp6gdevfmLIh2MLpRjBx7LXAG9QpagRV63oMY5AyQF6uOkNa7JGw-0zGZKIFHoSuZtjpcIokATDMxqoJlVfCiktqIYXEiJcrovbnxo-DAgLEiREocQrn0yMbLc2A-gwR3CN9XurWkU21TUD1CLJ-3gpiCLKKe9BdHWdaeEA/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> > PLEASE do read the posting guide
> > http://secure-web.cisco.com/1ppZyk8SO6U25PKNDKtGQ-VIADLxXgKvnHc8QlV3cUMNPzLQvS8E0i9cg05EyzUyHnFjj2QWDjvAjyuduvE1P8Nr0TogQweiuBysM9a1rXjQn1EOaypHdqwa2_inODK1icu0Ff33AZDB00N4x-nYxZ2e16nArVuaMEddaLXBhtBYMn2LAcPYJ8s2wGN10heiFWywn-r8--Hw77GJx1hkTgg/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> > and provide commented, minimal, self-contained, reproducible code. 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Mon Nov  9 18:13:43 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Mon, 9 Nov 2020 12:13:43 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <20201109092317.1858ddd0@athorn-Lemur-Ultra>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
 <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
 <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>
 <ae88e502-8011-95b4-31eb-a5db33371aed@molbio.mgh.harvard.edu>
 <20201109092317.1858ddd0@athorn-Lemur-Ultra>
Message-ID: <1c02cba3-e295-fdd0-21e4-c530c0cdfcb3@molbio.mgh.harvard.edu>


    Benford Analysis for Data Validation and Forensic Analytics

Provides tools that make it easier to validate data using Benford's Law.

https://www.rdocumentation.org/packages/benford.analysis/versions/0.1.5


Matthew

On 11/9/20 9:23 AM, Alexandra Thorn wrote:
>          External Email - Use Caution
>
> This thread strikes me as pretty far off-topic for a forum dedicated to
> software support on R.
>
> https://secure-web.cisco.com/15MzwKoUQfDzeGBDx9gweXKgiYtAPv1UlnW2dg9CuDtSNWgxy3ffTf_uuPizbjoJnovoOD6lrPDluOgGvIUTEF1d_rOTfaF3nUKLvNiZa3fHZ_IHD-SjKotr4lurHjmNPlSrljLipPsrDk2aoo63-GLwvaw64By_MnLST7lt4FgA2pYXgE3x15Xn-kRZ85m29f0BxhHJMVfilvVUoUEBPrw/https%3A%2F%2Fwww.r-project.org%2Fmail.html%23instructions
> "The ?main? R mailing list, for discussion about problems and solutions
> using R, announcements (not covered by ?R-announce? or ?R-packages?,
> see above), about the availability of new functionality for R and
> documentation of R, comparison and compatibility with S-plus, and for
> the posting of nice examples and benchmarks. Do read the posting guide
> before sending anything!"
>
> https://secure-web.cisco.com/1V05G8mWSPHU-YvLbL-UQMy49XX7n7-EivE-gTOlh2nZ3P0oxp6DGUUZQ_Q5VIkE3J0qmhrrSXxJaqZjv-Tllghba8lQrbkazuAHTcltsfo3I-C-SMqhb-CDdFbeEgIsr7py_gKW9BqumTZacywhHVnzhGGR2s1A-2akqQLYSYpYeX5EcVJAYvX1KPCs9kJbOEveOr5yYjetokaZpLTzdMA/https%3A%2F%2Fwww.r-project.org%2Fposting-guide.html
> "The R mailing lists are primarily intended for questions and
> discussion about the R software. However, questions about statistical
> methodology are sometimes posted. If the question is well-asked and of
> interest to someone on the list, it may elicit an informative
> up-to-date answer. See also the Usenet groups sci.stat.consult (applied
> statistics and consulting) and sci.stat.math (mathematical stat and
> probability)."
>
> On Mon, 9 Nov 2020 00:53:46 -0500
> Matthew McCormack <mccormack at molbio.mgh.harvard.edu> wrote:
>
>> You can try here: https://secure-web.cisco.com/17WRivozTB0Frts23cTlTBd3SYWzVXQsLa_jDRN8SldAl35F0SYXRMZczzIXrQFTzbfRV4YfPOVhMSwopcdTU9Sva396s3bX3-KM7-51KjSnY0aXxlADYaHdvs4y4YXrUfk1GT2801rVL26MCEEn2E1azdQ8ECllu1roS_Z8MIj8d6kyCtUYVdOYN1i9DuWBSXPlEi-iOtrQsBp6ELRXNFw/https%3A%2F%2Fdecisiondeskhq.com%2F
>>
>> I think they have what you are looking for. From their website:
>>
>> "Create a FREE account to access up to the minute election results
>> and insights on all U.S. Federal elections. Decision Desk HQ &
>> ?ptimus provide live election night coverage, race-specific results
>> including county-level returns, and exclusive race probabilities for
>> key battleground races."
>>
>>   ?? Also, this article provides a little, emphasis on little, of
>> statistical analysis of election results, but it may be a place to
>> start.
>>
>> https://secure-web.cisco.com/1JA34S9tw27K78g7scwo2aGe4lPpV7HThBE81hhJjb4Ban7fxqbnOZqx7HxfcyqKrcB5BX7oJFHhMPumrxjm6aQJ0trW1Jgk0h9s2mNhZg4T_gTUls8y4l0KZ-AstUtw0eC0TtR9mHblU7KWid-7OO4mg0TfsxWyNpcqkA8MBuGftOEgUF7WtakShYgmCNYJkEfQJHK5_vjwK0taJeUheVw/https%3A%2F%2Fwww.theepochtimes.com%2Fstatistical-anomalies-in-biden-votes-analyses-indicate_3570518.html%3Futm_source%3Dnewsnoe%26utm_medium%3Demail%26utm_campaign%3Dbreaking-2020-11-08-5
>>
>> Matthew
>>
>> On 11/8/20 11:25 PM, Bert Gunter wrote:
>>>           External Email - Use Caution
>>>
>>> NYT  had interactive maps that reported  votes by county. So try
>>> contacting them.
>>>
>>>
>>> Bert
>>>
>>> On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com>
>>> wrote:
>>>>> such a repository already exists -- the NY Times, AP, CNN, etc.
>>>>> etc.
>>>> already have interactive web pages that did this
>>>>
>>>> I've been looking for presidential election results, by
>>>> ***county***. I've found historic results, including results for
>>>> 2016.
>>>>
>>>> However, I can't find such a dataset, for 2020.
>>>> (Even though this seems like an obvious thing to publish).
>>>>
>>>> I suspect that the NY Times has the data, but I haven't been able
>>>> to work where the data is on their website, or how to access it.
>>>>
>>>> More ***specific*** suggestions would be appreciated...?
>>>>   
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://secure-web.cisco.com/1C8m4dUQtDXEQdbAFTH153ehiJcvHuL_FkvDGeJBHhMRYZauAp6gdevfmLIh2MLpRjBx7LXAG9QpagRV63oMY5AyQF6uOkNa7JGw-0zGZKIFHoSuZtjpcIokATDMxqoJlVfCiktqIYXEiJcrovbnxo-DAgLEiREocQrn0yMbLc2A-gwR3CN9XurWkU21TUD1CLJ-3gpiCLKKe9BdHWdaeEA/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
>>> PLEASE do read the posting guide
>>> http://secure-web.cisco.com/1ppZyk8SO6U25PKNDKtGQ-VIADLxXgKvnHc8QlV3cUMNPzLQvS8E0i9cg05EyzUyHnFjj2QWDjvAjyuduvE1P8Nr0TogQweiuBysM9a1rXjQn1EOaypHdqwa2_inODK1icu0Ff33AZDB00N4x-nYxZ2e16nArVuaMEddaLXBhtBYMn2LAcPYJ8s2wGN10heiFWywn-r8--Hw77GJx1hkTgg/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://secure-web.cisco.com/1xog0sXCo0fVwdc0ujt6MkmrNnAl7Ju1I7ftl3WOIqBrFkywFcF7bqkees3YG_OptzqCKk8FboOkp9RKcW2qVhrPKdAW33mim6BrfyidbZIfevwdqsk8o1tOfjXL9HfvQmcD1ZZSORiQo3qDhjQjvbnETfjbVUwoJuHjqBzq9mL_Th23FeltHgtF8jDUDwHbfMDA_jvO84ut6QoHpwYxUjg/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
>> PLEASE do read the posting guide
>> http://secure-web.cisco.com/1jDnxG8gXefH0FYFkpHN4ytfq9oFGTOV2wSrstygDoyYeDl5wcBOTRwYoSBBVqYBzzgdU6ya5v-iShroKo9PEfRnJ6_mwzPKinWeTh-OLAWbiz9A8qqZrVFd1SrWIMiCrlpLXzKEYXYDspvy7N50KWJLR7ZEuZDysXng2zp2ZrCMdq2cJ_ilGKkUK5XeaShoIBifwm39A7Zy4wmUNNWeLaA/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://secure-web.cisco.com/1xog0sXCo0fVwdc0ujt6MkmrNnAl7Ju1I7ftl3WOIqBrFkywFcF7bqkees3YG_OptzqCKk8FboOkp9RKcW2qVhrPKdAW33mim6BrfyidbZIfevwdqsk8o1tOfjXL9HfvQmcD1ZZSORiQo3qDhjQjvbnETfjbVUwoJuHjqBzq9mL_Th23FeltHgtF8jDUDwHbfMDA_jvO84ut6QoHpwYxUjg/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> PLEASE do read the posting guide http://secure-web.cisco.com/1jDnxG8gXefH0FYFkpHN4ytfq9oFGTOV2wSrstygDoyYeDl5wcBOTRwYoSBBVqYBzzgdU6ya5v-iShroKo9PEfRnJ6_mwzPKinWeTh-OLAWbiz9A8qqZrVFd1SrWIMiCrlpLXzKEYXYDspvy7N50KWJLR7ZEuZDysXng2zp2ZrCMdq2cJ_ilGKkUK5XeaShoIBifwm39A7Zy4wmUNNWeLaA/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From M@Roo@ @end|ng |rom |1-out@ourc|ng@eu  Mon Nov  9 18:55:53 2020
From: M@Roo@ @end|ng |rom |1-out@ourc|ng@eu (Marc Roos)
Date: Mon, 9 Nov 2020 18:55:53 +0100
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <1c02cba3-e295-fdd0-21e4-c530c0cdfcb3@molbio.mgh.harvard.edu>
Message-ID: <"H0000071001844e9.1604944553.sx.f1-outsourcing.eu*"@MHS>

 
Publish the results/graphs please, like to see what your are doing.



-----Original Message-----
From: Matthew McCormack [mailto:mccormack at molbio.mgh.harvard.edu] 
Sent: Monday, November 09, 2020 6:14 PM
To: r-help at r-project.org
Subject: Re: [R] analyzing results from Tuesday's US elections


    Benford Analysis for Data Validation and Forensic Analytics

Provides tools that make it easier to validate data using Benford's Law.

https://www.rdocumentation.org/packages/benford.analysis/versions/0.1.5


Matthew

On 11/9/20 9:23 AM, Alexandra Thorn wrote:
>          External Email - Use Caution
>
> This thread strikes me as pretty far off-topic for a forum dedicated 
> to software support on R.
>
> https://secure-web.cisco.com/15MzwKoUQfDzeGBDx9gweXKgiYtAPv1UlnW2dg9Cu
> DtSNWgxy3ffTf_uuPizbjoJnovoOD6lrPDluOgGvIUTEF1d_rOTfaF3nUKLvNiZa3fHZ_I
> HD-SjKotr4lurHjmNPlSrljLipPsrDk2aoo63-GLwvaw64By_MnLST7lt4FgA2pYXgE3x1
> 5Xn-kRZ85m29f0BxhHJMVfilvVUoUEBPrw/https%3A%2F%2Fwww.r-project.org%2Fm
> ail.html%23instructions "The main R mailing list, for discussion 
> about problems and solutions using R, announcements (not covered by 
> R-announce or R-packages, see above), about the availability 
of 
> new functionality for R and documentation of R, comparison and 
> compatibility with S-plus, and for the posting of nice examples and 
> benchmarks. Do read the posting guide before sending anything!"
>
> https://secure-web.cisco.com/1V05G8mWSPHU-YvLbL-UQMy49XX7n7-EivE-gTOlh
> 2nZ3P0oxp6DGUUZQ_Q5VIkE3J0qmhrrSXxJaqZjv-Tllghba8lQrbkazuAHTcltsfo3I-C
> -SMqhb-CDdFbeEgIsr7py_gKW9BqumTZacywhHVnzhGGR2s1A-2akqQLYSYpYeX5EcVJAY
> vX1KPCs9kJbOEveOr5yYjetokaZpLTzdMA/https%3A%2F%2Fwww.r-project.org%2Fp
> osting-guide.html "The R mailing lists are primarily intended for 
> questions and discussion about the R software. However, questions 
> about statistical methodology are sometimes posted. If the question is 

> well-asked and of interest to someone on the list, it may elicit an 
> informative up-to-date answer. See also the Usenet groups 
> sci.stat.consult (applied statistics and consulting) and sci.stat.math 

> (mathematical stat and probability)."
>
> On Mon, 9 Nov 2020 00:53:46 -0500
> Matthew McCormack <mccormack at molbio.mgh.harvard.edu> wrote:
>
>> You can try here: 
>> https://secure-web.cisco.com/17WRivozTB0Frts23cTlTBd3SYWzVXQsLa_jDRN8
>> SldAl35F0SYXRMZczzIXrQFTzbfRV4YfPOVhMSwopcdTU9Sva396s3bX3-KM7-51KjSnY
>> 0aXxlADYaHdvs4y4YXrUfk1GT2801rVL26MCEEn2E1azdQ8ECllu1roS_Z8MIj8d6kyCt
>> UYVdOYN1i9DuWBSXPlEi-iOtrQsBp6ELRXNFw/https%3A%2F%2Fdecisiondeskhq.co
>> m%2F
>>
>> I think they have what you are looking for. From their website:
>>
>> "Create a FREE account to access up to the minute election results 
>> and insights on all U.S. Federal elections. Decision Desk HQ & 
>> ?ptimus provide live election night coverage, race-specific results 
>> including county-level returns, and exclusive race probabilities for 
>> key battleground races."
>>
>>   ?? Also, this article provides a little, emphasis on little, of 
>> statistical analysis of election results, but it may be a place to 
>> start.
>>
>> https://secure-web.cisco.com/1JA34S9tw27K78g7scwo2aGe4lPpV7HThBE81hhJ
>> jb4Ban7fxqbnOZqx7HxfcyqKrcB5BX7oJFHhMPumrxjm6aQJ0trW1Jgk0h9s2mNhZg4T_
>> gTUls8y4l0KZ-AstUtw0eC0TtR9mHblU7KWid-7OO4mg0TfsxWyNpcqkA8MBuGftOEgUF
>> 7WtakShYgmCNYJkEfQJHK5_vjwK0taJeUheVw/https%3A%2F%2Fwww.theepochtimes
>> .com%2Fstatistical-anomalies-in-biden-votes-analyses-indicate_3570518
>> .html%3Futm_source%3Dnewsnoe%26utm_medium%3Demail%26utm_campaign%3Dbr
>> eaking-2020-11-08-5
>>
>> Matthew
>>
>> On 11/8/20 11:25 PM, Bert Gunter wrote:
>>>           External Email - Use Caution
>>>
>>> NYT  had interactive maps that reported  votes by county. So try 
>>> contacting them.
>>>
>>>
>>> Bert
>>>
>>> On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com>
>>> wrote:
>>>>> such a repository already exists -- the NY Times, AP, CNN, etc.
>>>>> etc.
>>>> already have interactive web pages that did this
>>>>
>>>> I've been looking for presidential election results, by 
>>>> ***county***. I've found historic results, including results for 
>>>> 2016.
>>>>
>>>> However, I can't find such a dataset, for 2020.
>>>> (Even though this seems like an obvious thing to publish).
>>>>
>>>> I suspect that the NY Times has the data, but I haven't been able 
>>>> to work where the data is on their website, or how to access it.
>>>>
>>>> More ***specific*** suggestions would be appreciated...?
>>>>   
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://secure-web.cisco.com/1C8m4dUQtDXEQdbAFTH153ehiJcvHuL_FkvDGeJ
>>> BHhMRYZauAp6gdevfmLIh2MLpRjBx7LXAG9QpagRV63oMY5AyQF6uOkNa7JGw-0zGZKI
>>> FHoSuZtjpcIokATDMxqoJlVfCiktqIYXEiJcrovbnxo-DAgLEiREocQrn0yMbLc2A-gw
>>> R3CN9XurWkU21TUD1CLJ-3gpiCLKKe9BdHWdaeEA/https%3A%2F%2Fstat.ethz.ch%
>>> 2Fmailman%2Flistinfo%2Fr-help
>>> PLEASE do read the posting guide
>>> http://secure-web.cisco.com/1ppZyk8SO6U25PKNDKtGQ-VIADLxXgKvnHc8QlV3
>>> cUMNPzLQvS8E0i9cg05EyzUyHnFjj2QWDjvAjyuduvE1P8Nr0TogQweiuBysM9a1rXjQ
>>> n1EOaypHdqwa2_inODK1icu0Ff33AZDB00N4x-nYxZ2e16nArVuaMEddaLXBhtBYMn2L
>>> AcPYJ8s2wGN10heiFWywn-r8--Hw77GJx1hkTgg/http%3A%2F%2Fwww.R-project.o
>>> rg%2Fposting-guide.html and provide commented, minimal, 
>>> self-contained, reproducible code.
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://secure-web.cisco.com/1xog0sXCo0fVwdc0ujt6MkmrNnAl7Ju1I7ftl3WO
>> IqBrFkywFcF7bqkees3YG_OptzqCKk8FboOkp9RKcW2qVhrPKdAW33mim6BrfyidbZIfe
>> vwdqsk8o1tOfjXL9HfvQmcD1ZZSORiQo3qDhjQjvbnETfjbVUwoJuHjqBzq9mL_Th23Fe
>> ltHgtF8jDUDwHbfMDA_jvO84ut6QoHpwYxUjg/https%3A%2F%2Fstat.ethz.ch%2Fma
>> ilman%2Flistinfo%2Fr-help
>> PLEASE do read the posting guide
>> http://secure-web.cisco.com/1jDnxG8gXefH0FYFkpHN4ytfq9oFGTOV2wSrstygD
>> 
oyYeDl5wcBOTRwYoSBBVqYBzzgdU6ya5v-iShroKo9PEfRnJ6_mwzPKinWeTh-OLAWbiz9A8
qqZrVFd1SrWIMiCrlpLXzKEYXYDspvy7N50KWJLR7ZEuZDysXng2zp2ZrCMdq2cJ_ilGKkUK
5XeaShoIBifwm39A7Zy4wmUNNWeLaA/http%3A%2F%2Fwww.R-project.org%2Fposting-
guide.html and provide commented, minimal, self-contained, reproducible 
code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://secure-web.cisco.com/1xog0sXCo0fVwdc0ujt6MkmrNnAl7Ju1I7ftl3WOI
> qBrFkywFcF7bqkees3YG_OptzqCKk8FboOkp9RKcW2qVhrPKdAW33mim6BrfyidbZIfevw
> dqsk8o1tOfjXL9HfvQmcD1ZZSORiQo3qDhjQjvbnETfjbVUwoJuHjqBzq9mL_Th23FeltH
> gtF8jDUDwHbfMDA_jvO84ut6QoHpwYxUjg/https%3A%2F%2Fstat.ethz.ch%2Fmailma
> n%2Flistinfo%2Fr-help PLEASE do read the posting guide 
> http://secure-web.cisco.com/1jDnxG8gXefH0FYFkpHN4ytfq9oFGTOV2wSrstygDo
> yYeDl5wcBOTRwYoSBBVqYBzzgdU6ya5v-iShroKo9PEfRnJ6_mwzPKinWeTh-OLAWbiz9A
> 8qqZrVFd1SrWIMiCrlpLXzKEYXYDspvy7N50KWJLR7ZEuZDysXng2zp2ZrCMdq2cJ_ilGK
> kUK5XeaShoIBifwm39A7Zy4wmUNNWeLaA/http%3A%2F%2Fwww.R-project.org%2Fpos
> ting-guide.html and provide commented, minimal, self-contained, 
> reproducible code.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Mon Nov  9 19:51:33 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 9 Nov 2020 13:51:33 -0500
Subject: [R] 
 [effects] Wrong xlevels in effects plot for mixed effects model
 when multiline = TRUE
In-Reply-To: <27049_1604927072_0A9D4V3L027674_5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>
References: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
 <27049_1604927072_0A9D4V3L027674_5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>
Message-ID: <b4df868d-77ea-3524-02ef-ca2661225dbf@mcmaster.ca>

Dear Gerrit,

This looks like a bug in plot.eff(), which I haven't yet tracked down, 
but the following should give you what you want:

eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30, 
Age=60:100))
plot(eff, lines=list(multiline=TRUE))

or

eff <- predictorEffect("Age", m, xlevels = list(gProt = 1:6 * 30))
plot(eff, lines=list(multiline=TRUE))

A couple of comments on your code, unrelated to the bug in plot.eff():

You don't need allEffects() because there's only one high-order fixed 
effect in the model, I(gProt/10 - 6.2):I(Age/10 - 7.2) (i.e., the 
interaction of gProt with Age).

x.var isn't intended as an argument for plot() with allEffects() because 
there generally isn't a common horizontal axis for all of the high-order 
effect plots.

Finally, thank you for the bug report. Barring unforeseen difficulties, 
we'll fix the bug in due course.

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-11-09 8:06 a.m., Gerrit Eichner wrote:
> Dear list members,
> 
> I observe a strange/wrong graphical output when I set the xlevels
> in (e. g.) allEffects for an lmer model and plot the effects with
> multiline = TRUE. I have compiled a reprex for which you need the
> lmer model and the environment in which the model was fitted. They
> are contained in the zip file at
> https://jlubox.uni-giessen.de/dl/fiSzTCc3bW8z2npZvPpqG1xr/m-and-G1.zip
> After unpacking the following should work:
> 
> m <- readRDS("m.rds")?? # The lmer-model.
> G1 <- readRDS("G1.rds") # Environment in which the model
>  ???????????????????????? # was fitted; needed by alaEffects.
> summary(m) # Just to see the model.
> 
> library(effects)
> aE <- allEffects(m, xlevels = list(gProt = 1:6 * 30))
>  ???????????????????? # Non-default values for xlevels.
> 
> plot(aE)????????????????????? # Fine.
> plot(aE, x.var = "Age")?????? # Fine.
> plot(aE, lines = list(multiline = TRUE))? # Fine.
> 
> plot(aE, lines = list(multiline = TRUE),
>  ????? x.var = "Age")??????? # Nonsense.
> 
> 
> Anybody any idea about the reason, my mistake, or a
> workaround? Thx for any hint!
> 
>  ? Regards? --? Gerrit
> 
> 
> PS:
>  ?> sessionInfo()
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18363)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
> 
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
> 
> other attached packages:
> [1] effects_4.2-0 carData_3.0-4
> 
> loaded via a namespace (and not attached):
>  ? [1] Rcpp_1.0.5?????? lattice_0.20-41? MASS_7.3-53????? grid_4.0.2 
> DBI_1.1.0
>  ? [6] nlme_3.1-149???? survey_4.0?????? estimability_1.3 minqa_1.2.4 
> nloptr_1.2.2.2
> [11] Matrix_1.2-18??? boot_1.3-25????? splines_4.0.2??? statmod_1.4.34 
> lme4_1.1-23
> [16] tools_4.0.2????? survival_3.2-3?? yaml_2.2.1?????? compiler_4.0.2 
> colorspace_1.4-1
> [21] mitools_2.4????? insight_0.9.5??? nnet_7.3-14
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Mon Nov  9 22:51:42 2020
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Mon, 9 Nov 2020 22:51:42 +0100
Subject: [R] 
 [effects] Wrong xlevels in effects plot for mixed effects model
 when multiline = TRUE
In-Reply-To: <b4df868d-77ea-3524-02ef-ca2661225dbf@mcmaster.ca>
References: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
 <27049_1604927072_0A9D4V3L027674_5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>
 <b4df868d-77ea-3524-02ef-ca2661225dbf@mcmaster.ca>
Message-ID: <a1928d36-93d3-db2e-7f5d-cecd7536a759@math.uni-giessen.de>

Dear John,

thank you for prompt reply and your hints. The problem is that our
lmer model is much more complicated and has several interaction
terms:

Mass ~ Sex + I(YoE - 1996) + I(PAI/0.1 - 16) + I(gProt/10 - 6.2) +
     I(Age/10 - 7.2) + I((Age/10 - 7.2)^2) + Diuretics +
     Sex:I(PAI/0.1 - 16) + Sex:I(gProt/10 - 6.2) +
     Sex:I(Age/10 - 7.2) + Sex:I((Age/10 - 7.2)^2) +
     I(YoE - 1996):I(Age/10 - 7.2) + I(PAI/0.1 - 16):I(Age/10 - 7.2) +
     I(gProt/10 - 6.2):I(Age/10 - 7.2) +
     (I(Age/10 - 7.2) + I((Age/10 - 7.2)^2) | ID)

so that allEffects is quite efficient, and since I want to place
several interaction terms with Age in one figure with Age on the
horizontal axis the argument x.var = "Age" in plot would be very
helpful. :-)

Further hints using the above complex model: The following works well:
eff <- Effect(c("gProt", "Age"), m,
               xlevels = list(gProt = 1:6 * 30, Age = 60:100))
plot(eff, lines=list(multiline=TRUE), x.var = "Age")

But this fails (note that Age is missing in xlevels):
eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30))
plot(eff, lines=list(multiline=TRUE), x.var = "Age")


And that just led me to a solutution also for allEffects: Specifying
Age in xlevels for allEffects (although it seems unnecessary when
x.var = "Age" is used in plot) produces the correct graphical
output! :-)

Thank you very much for your support and the brilliant effects
package in general! :-)

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 09.11.2020 um 19:51 schrieb John Fox:
> Dear Gerrit,
> 
> This looks like a bug in plot.eff(), which I haven't yet tracked down, 
> but the following should give you what you want:
> 
> eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30, 
> Age=60:100))
> plot(eff, lines=list(multiline=TRUE))
> 
> or
> 
> eff <- predictorEffect("Age", m, xlevels = list(gProt = 1:6 * 30))
> plot(eff, lines=list(multiline=TRUE))
> 
> A couple of comments on your code, unrelated to the bug in plot.eff():
> 
> You don't need allEffects() because there's only one high-order fixed 
> effect in the model, I(gProt/10 - 6.2):I(Age/10 - 7.2) (i.e., the 
> interaction of gProt with Age).
> 
> x.var isn't intended as an argument for plot() with allEffects() because 
> there generally isn't a common horizontal axis for all of the high-order 
> effect plots.
> 
> Finally, thank you for the bug report. Barring unforeseen difficulties, 
> we'll fix the bug in due course.
> 
> I hope this helps,
>  ?John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
> 
> On 2020-11-09 8:06 a.m., Gerrit Eichner wrote:
>> Dear list members,
>>
>> I observe a strange/wrong graphical output when I set the xlevels
>> in (e. g.) allEffects for an lmer model and plot the effects with
>> multiline = TRUE. I have compiled a reprex for which you need the
>> lmer model and the environment in which the model was fitted. They
>> are contained in the zip file at
>> https://jlubox.uni-giessen.de/dl/fiSzTCc3bW8z2npZvPpqG1xr/m-and-G1.zip
>> After unpacking the following should work:
>>
>> m <- readRDS("m.rds")?? # The lmer-model.
>> G1 <- readRDS("G1.rds") # Environment in which the model
>> ????????????????????????? # was fitted; needed by alaEffects.
>> summary(m) # Just to see the model.
>>
>> library(effects)
>> aE <- allEffects(m, xlevels = list(gProt = 1:6 * 30))
>> ????????????????????? # Non-default values for xlevels.
>>
>> plot(aE)????????????????????? # Fine.
>> plot(aE, x.var = "Age")?????? # Fine.
>> plot(aE, lines = list(multiline = TRUE))? # Fine.
>>
>> plot(aE, lines = list(multiline = TRUE),
>> ?????? x.var = "Age")??????? # Nonsense.
>>
>>
>> Anybody any idea about the reason, my mistake, or a
>> workaround? Thx for any hint!
>>
>> ?? Regards? --? Gerrit
>>
>>
>> PS:
>> ??> sessionInfo()
>> R version 4.0.2 (2020-06-22)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 18363)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>>
>> other attached packages:
>> [1] effects_4.2-0 carData_3.0-4
>>
>> loaded via a namespace (and not attached):
>> ?? [1] Rcpp_1.0.5?????? lattice_0.20-41? MASS_7.3-53????? grid_4.0.2 
>> DBI_1.1.0
>> ?? [6] nlme_3.1-149???? survey_4.0?????? estimability_1.3 minqa_1.2.4 
>> nloptr_1.2.2.2
>> [11] Matrix_1.2-18??? boot_1.3-25????? splines_4.0.2??? statmod_1.4.34 
>> lme4_1.1-23
>> [16] tools_4.0.2????? survival_3.2-3?? yaml_2.2.1?????? compiler_4.0.2 
>> colorspace_1.4-1
>> [21] mitools_2.4????? insight_0.9.5??? nnet_7.3-14
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>> http://www.uni-giessen.de/eichner
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Tue Nov 10 01:45:36 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 10 Nov 2020 13:45:36 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
Message-ID: <CAB8pepzwig92ZkNHgLcfmZcSsBb+qVhC17rqaOqBVHRYKsHcaQ@mail.gmail.com>

RESENT
INITIAL EMAIL, TOO BIG
ATTACHMENTS REPLACED WITH LINKS

I created a dataset, linked.
Had to manually copy and paste from the NY Times website.

> head (data, 3)
    STATE   EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020 SUB_STATEVAL_2016
1 Alabama     Mobile         13.3           12       181783                 0
2 Alabama     Dallas        -37.5          -38        17861                 0
3 Alabama Tuscaloosa         19.3           15        89760                 0

> tail (data, 3)
       STATE EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020 SUB_STATEVAL_2016
4248 Wyoming    Uinta         58.5           63         9400                 0
4249 Wyoming Sublette         63.0           62         4970                 0
4250 Wyoming  Johnson         64.3           61         4914                 0

> head (data [data [,1] == "Alaska",], 3)
    STATE EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020 SUB_STATEVAL_2016
68 Alaska    ED 40         14.7        -24.0           82                 1
69 Alaska    ED 37         14.7         -1.7          173                 1
70 Alaska    ED 38         14.7         -0.4          249                 1

EQCounty, is the County or Equivalent.
Several states, D.C., Alaska, Connecticut, Maine, Massachusetts, Rhode
Island and Vermont are different.
RMargin(s) are the republican percentages minus the democrate
percentages, as 2 or 3 digit numbers between 0 and 100.
The last column is 0s or 1s, with 1s for Alaska, Connecticut, Maine,
Massachusetts, Rhode Island and Vermont, where I didn't have the 2016
margins, so the 2016 margins have been replaced with state-levels
values.

Then I scaled the margins, based on the number of voters.
i.e.
wx2016 <- 1000 * x2016 * nv / max.nv
(Where x2016 is equal to RMARGIN_2020, and nv is equal to NVOTERS_2020).

There may be a much better way.

And came up the following plots (linked) and output (follows):

---INPUT---
PATH = "<PATH TO FILE>"
data = read.csv (PATH, header=TRUE)

#raw data
x2016 <- as.numeric (data$RMARGIN_2016)
x2020 <- as.numeric (data$RMARGIN_2020)
nv <- as.numeric (data$NVOTERS_2020)
subs <- as.logical (data$SUB_STATEVAL)

#computed data
max.nv <- max (nv)
wx2016 <- 1000 * x2016 * nv / max.nv
wx2020 <- 1000 * x2020 * nv / max.nv
diffs <- wx2020 - wx2016

OFFSET <- 500
p0 <- par (mfrow = c (2, 2) )

#plot 1
plot (wx2016, wx2020,
main="All Votes\n(By County, or Equivalent)",
xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin, 2020")
abline (h=0, v=0, lty=2)

#plot 2
OFFSET <- 200
plot (wx2016, wx2020,
xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
main="All Votes\n(Zoomed In)",
xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin, 2020")
abline (h=0, v=0, lty=2)

OFFSET <- 1000

#plot 3
J1 <- order (diffs, decreasing=TRUE)[1:400]
plot (wx2016 [J1], wx2020 [J1],
xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
main="400 Biggest Shifts Towards Republican",
xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin, 2020")
abline (h=0, v=0, lty=2)
abline (a=0, b=1, lty=2)

#plot 4
J2 <- order (diffs)[1:400]
plot (wx2016 [J2], wx2020 [J2],
xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
main="400 Biggest Shifts Towards Democrat",
xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin, 2020")
abline (h=0, v=0, lty=2)
abline (a=0, b=1, lty=2)

par (p0)

#most democrat
I = order (wx2020)[1:30]
cbind (data [I,], scaled.dem.vote = -1 * wx2020 [I])

#biggest move toward democrat
head (cbind (data [J2,], diffs = diffs [J2]), 30)

---OUTPUT---
#most democrat
> cbind (data [I,], scaled.dem.vote = -1 * wx2020 [I])
              STATE        EQCOUNTY RMARGIN_2016 RMARGIN_2020
NVOTERS_2020 SUB_STATEVAL_2016 scaled.dem.vote
229      California     Los Angeles        -49.3          -44
3674850                 0       44000.000
769        Illinois            Cook        -53.1          -47
1897721                 0       24271.164
4073     Washington            King        -48.8          -53
1188152                 0       17135.953
3092   Pennsylvania    Philadelphia        -67.0          -63
701647                 0       12028.725
215      California         Alameda        -63.5          -64
625710                 0       10897.163
227      California     Santa Clara        -52.1          -49
726186                 0        9682.875
238      California       San Diego        -19.7          -23
1546144                 0        9676.942
2683       New York        Brooklyn        -62.0          -49
693937                 0        9252.871
2162      Minnesota        Hennepin        -34.9          -43
753716                 0        8819.350
2074       Michigan           Wayne        -37.1          -37
863382                 0        8692.908
2673       New York       Manhattan        -76.9          -70
446861                 0        8511.986
221      California   San Francisco        -75.2          -73
413642                 0        8216.898
3495          Texas          Dallas        -26.1          -32
920772                 0        8017.934
1741       Maryland Prince George's        -79.7          -80
365857                 0        7964.559
510         Florida         Broward        -34.9          -30
959418                 0        7832.303
3057         Oregon       Multnomah        -56.3          -61
458395                 0        7609.044
3563          Texas          Travis        -38.6          -45
605034                 0        7408.882
565         Georgia          DeKalb        -62.9          -67
369341                 0        6733.839
3942       Virginia         Fairfax        -35.8          -42
578931                 0        6616.624
492            D.C.            D.C.        -86.4          -87
279152                 0        6608.766
562         Georgia          Fulton        -40.9          -46
522050                 0        6534.770
230      California    Contra Costa        -43.0          -48
498340                 0        6509.196
2674       New York          Queens        -53.6          -39
597928                 0        6345.617
257        Colorado          Denver        -54.8          -64
350606                 0        6106.041
2677       New York           Bronx        -79.1          -66
329638                 0        5920.271
3530          Texas          Harris        -12.3          -13
1633671                 0        5779.208
1718       Maryland      Montgomery        -55.4          -57
369405                 0        5729.781
2888           Ohio        Cuyahoga        -35.2          -34
605268                 0        5599.987
2745 North Carolina     Mecklenburg        -29.4          -35
565980                 0        5390.506
2894           Ohio        Franklin        -25.8          -31
606022                 0        5112.231

#biggest move toward democrat
> head (cbind (data [J2,], diffs = diffs [J2]), 30)
              STATE         EQCOUNTY RMARGIN_2016 RMARGIN_2020
NVOTERS_2020 SUB_STATEVAL_2016      diffs
1751  Massachusetts           Boston        -26.8       -67.00
273133                 1 -2987.8625
113         Arizona         Maricopa          2.8        -2.00
2046295                 0 -2672.8209
3531          Texas          Tarrant          8.6        -0.16
830104                 0 -1978.7776
2162      Minnesota         Hennepin        -34.9       -43.00
753716                 0 -1661.3194
3564          Texas           Collin         16.7         5.00
486917                 0 -1550.2480
3495          Texas           Dallas        -26.1       -32.00
920772                 0 -1478.3065
238      California        San Diego        -19.7       -23.00
1546144                 0 -1388.4309
563         Georgia         Gwinnett         -5.8       -18.00
413166                 0 -1371.6547
3565          Texas           Denton         20.0         8.00
416610                 0 -1360.4147
4073     Washington             King        -48.8       -53.00
1188152                 0 -1357.9434
564         Georgia             Cobb         -2.2       -14.00
393340                 0 -1263.0208
2075       Michigan          Oakland         -8.1       -14.00
778418                 0 -1249.7561
291        Colorado        Jefferson         -6.9       -19.00
376430                 0 -1239.4528
292        Colorado          El Paso         22.3        11.00
375058                 0 -1153.2866
2321       Missouri St. Louis County        -16.2       -24.00
528107                 0 -1120.9259
3563          Texas           Travis        -38.6       -45.00
605034                 0 -1053.7077
277        Colorado         Arapahoe        -14.1       -25.00
346740                 0 -1028.4681
2744 North Carolina             Wake        -20.2       -26.00
624049                 0  -984.9339
3942       Virginia          Fairfax        -35.8       -42.00
578931                 0  -976.7398
1116         Kansas          Johnson          2.6        -8.00
338343                 0  -975.9407
3562          Texas            Bexar        -13.4       -18.00
757667                 0  -948.4110
2077       Michigan             Kent          3.1        -6.00
359915                 0  -891.2545
257        Colorado           Denver        -54.8       -64.00
350606                 0  -877.7434
110         Arizona             Pima        -13.6       -20.00
501058                 0  -872.6264
2625     New Jersey         Monmouth          9.3        -1.60
292654                 0  -868.0432
2745 North Carolina      Mecklenburg        -29.4       -35.00
565980                 0  -862.4809
3567          Texas       Williamson          9.7        -1.30
287696                 0  -861.1660
2894           Ohio         Franklin        -25.8       -31.00
606022                 0  -857.5355
203      California        Riverside         -5.4       -11.00
558759                 0  -851.4770
3966       Virginia   Virginia Beach          3.5        -8.00
253477                 0  -793.2257

DISCLAIMER:\ I can not guarantee the accuracy of this da...{{dropped:15}}


From bgunter@4567 @end|ng |rom gm@||@com  Tue Nov 10 04:02:01 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Nov 2020 19:02:01 -0800
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAB8pepzwig92ZkNHgLcfmZcSsBb+qVhC17rqaOqBVHRYKsHcaQ@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepzwig92ZkNHgLcfmZcSsBb+qVhC17rqaOqBVHRYKsHcaQ@mail.gmail.com>
Message-ID: <CAGxFJbRgVENEH_162fyWoRwAbbDvacHsK1hZ9ytNHS+EMbR35Q@mail.gmail.com>

For those who are interested:

Very nice examples of (static) statistical graphics on election results can
be found here:
https://www.nytimes.com/interactive/2020/11/09/us/arizona-election-battleground-state-counties.html?action=click&module=Spotlight&pgtype=Homepage

Takes multidisciplinary teams and lots of hard work to produce, I would
guess.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 9, 2020 at 4:46 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> RESENT
> INITIAL EMAIL, TOO BIG
> ATTACHMENTS REPLACED WITH LINKS
>
> I created a dataset, linked.
> Had to manually copy and paste from the NY Times website.
>
> > head (data, 3)
>     STATE   EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020
> SUB_STATEVAL_2016
> 1 Alabama     Mobile         13.3           12       181783
>  0
> 2 Alabama     Dallas        -37.5          -38        17861
>  0
> 3 Alabama Tuscaloosa         19.3           15        89760
>  0
>
> > tail (data, 3)
>        STATE EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020
> SUB_STATEVAL_2016
> 4248 Wyoming    Uinta         58.5           63         9400
>    0
> 4249 Wyoming Sublette         63.0           62         4970
>    0
> 4250 Wyoming  Johnson         64.3           61         4914
>    0
>
> > head (data [data [,1] == "Alaska",], 3)
>     STATE EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020 SUB_STATEVAL_2016
> 68 Alaska    ED 40         14.7        -24.0           82                 1
> 69 Alaska    ED 37         14.7         -1.7          173                 1
> 70 Alaska    ED 38         14.7         -0.4          249                 1
>
> EQCounty, is the County or Equivalent.
> Several states, D.C., Alaska, Connecticut, Maine, Massachusetts, Rhode
> Island and Vermont are different.
> RMargin(s) are the republican percentages minus the democrate
> percentages, as 2 or 3 digit numbers between 0 and 100.
> The last column is 0s or 1s, with 1s for Alaska, Connecticut, Maine,
> Massachusetts, Rhode Island and Vermont, where I didn't have the 2016
> margins, so the 2016 margins have been replaced with state-levels
> values.
>
> Then I scaled the margins, based on the number of voters.
> i.e.
> wx2016 <- 1000 * x2016 * nv / max.nv
> (Where x2016 is equal to RMARGIN_2020, and nv is equal to NVOTERS_2020).
>
> There may be a much better way.
>
> And came up the following plots (linked) and output (follows):
>
> ---INPUT---
> PATH = "<PATH TO FILE>"
> data = read.csv (PATH, header=TRUE)
>
> #raw data
> x2016 <- as.numeric (data$RMARGIN_2016)
> x2020 <- as.numeric (data$RMARGIN_2020)
> nv <- as.numeric (data$NVOTERS_2020)
> subs <- as.logical (data$SUB_STATEVAL)
>
> #computed data
> max.nv <- max (nv)
> wx2016 <- 1000 * x2016 * nv / max.nv
> wx2020 <- 1000 * x2020 * nv / max.nv
> diffs <- wx2020 - wx2016
>
> OFFSET <- 500
> p0 <- par (mfrow = c (2, 2) )
>
> #plot 1
> plot (wx2016, wx2020,
> main="All Votes\n(By County, or Equivalent)",
> xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin,
> 2020")
> abline (h=0, v=0, lty=2)
>
> #plot 2
> OFFSET <- 200
> plot (wx2016, wx2020,
> xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
> main="All Votes\n(Zoomed In)",
> xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin,
> 2020")
> abline (h=0, v=0, lty=2)
>
> OFFSET <- 1000
>
> #plot 3
> J1 <- order (diffs, decreasing=TRUE)[1:400]
> plot (wx2016 [J1], wx2020 [J1],
> xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
> main="400 Biggest Shifts Towards Republican",
> xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin,
> 2020")
> abline (h=0, v=0, lty=2)
> abline (a=0, b=1, lty=2)
>
> #plot 4
> J2 <- order (diffs)[1:400]
> plot (wx2016 [J2], wx2020 [J2],
> xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
> main="400 Biggest Shifts Towards Democrat",
> xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin,
> 2020")
> abline (h=0, v=0, lty=2)
> abline (a=0, b=1, lty=2)
>
> par (p0)
>
> #most democrat
> I = order (wx2020)[1:30]
> cbind (data [I,], scaled.dem.vote = -1 * wx2020 [I])
>
> #biggest move toward democrat
> head (cbind (data [J2,], diffs = diffs [J2]), 30)
>
> ---OUTPUT---
> #most democrat
> > cbind (data [I,], scaled.dem.vote = -1 * wx2020 [I])
>               STATE        EQCOUNTY RMARGIN_2016 RMARGIN_2020
> NVOTERS_2020 SUB_STATEVAL_2016 scaled.dem.vote
> 229      California     Los Angeles        -49.3          -44
> 3674850                 0       44000.000
> 769        Illinois            Cook        -53.1          -47
> 1897721                 0       24271.164
> 4073     Washington            King        -48.8          -53
> 1188152                 0       17135.953
> 3092   Pennsylvania    Philadelphia        -67.0          -63
> 701647                 0       12028.725
> 215      California         Alameda        -63.5          -64
> 625710                 0       10897.163
> 227      California     Santa Clara        -52.1          -49
> 726186                 0        9682.875
> 238      California       San Diego        -19.7          -23
> 1546144                 0        9676.942
> 2683       New York        Brooklyn        -62.0          -49
> 693937                 0        9252.871
> 2162      Minnesota        Hennepin        -34.9          -43
> 753716                 0        8819.350
> 2074       Michigan           Wayne        -37.1          -37
> 863382                 0        8692.908
> 2673       New York       Manhattan        -76.9          -70
> 446861                 0        8511.986
> 221      California   San Francisco        -75.2          -73
> 413642                 0        8216.898
> 3495          Texas          Dallas        -26.1          -32
> 920772                 0        8017.934
> 1741       Maryland Prince George's        -79.7          -80
> 365857                 0        7964.559
> 510         Florida         Broward        -34.9          -30
> 959418                 0        7832.303
> 3057         Oregon       Multnomah        -56.3          -61
> 458395                 0        7609.044
> 3563          Texas          Travis        -38.6          -45
> 605034                 0        7408.882
> 565         Georgia          DeKalb        -62.9          -67
> 369341                 0        6733.839
> 3942       Virginia         Fairfax        -35.8          -42
> 578931                 0        6616.624
> 492            D.C.            D.C.        -86.4          -87
> 279152                 0        6608.766
> 562         Georgia          Fulton        -40.9          -46
> 522050                 0        6534.770
> 230      California    Contra Costa        -43.0          -48
> 498340                 0        6509.196
> 2674       New York          Queens        -53.6          -39
> 597928                 0        6345.617
> 257        Colorado          Denver        -54.8          -64
> 350606                 0        6106.041
> 2677       New York           Bronx        -79.1          -66
> 329638                 0        5920.271
> 3530          Texas          Harris        -12.3          -13
> 1633671                 0        5779.208
> 1718       Maryland      Montgomery        -55.4          -57
> 369405                 0        5729.781
> 2888           Ohio        Cuyahoga        -35.2          -34
> 605268                 0        5599.987
> 2745 North Carolina     Mecklenburg        -29.4          -35
> 565980                 0        5390.506
> 2894           Ohio        Franklin        -25.8          -31
> 606022                 0        5112.231
>
> #biggest move toward democrat
> > head (cbind (data [J2,], diffs = diffs [J2]), 30)
>               STATE         EQCOUNTY RMARGIN_2016 RMARGIN_2020
> NVOTERS_2020 SUB_STATEVAL_2016      diffs
> 1751  Massachusetts           Boston        -26.8       -67.00
> 273133                 1 -2987.8625
> 113         Arizona         Maricopa          2.8        -2.00
> 2046295                 0 -2672.8209
> 3531          Texas          Tarrant          8.6        -0.16
> 830104                 0 -1978.7776
> 2162      Minnesota         Hennepin        -34.9       -43.00
> 753716                 0 -1661.3194
> 3564          Texas           Collin         16.7         5.00
> 486917                 0 -1550.2480
> 3495          Texas           Dallas        -26.1       -32.00
> 920772                 0 -1478.3065
> 238      California        San Diego        -19.7       -23.00
> 1546144                 0 -1388.4309
> 563         Georgia         Gwinnett         -5.8       -18.00
> 413166                 0 -1371.6547
> 3565          Texas           Denton         20.0         8.00
> 416610                 0 -1360.4147
> 4073     Washington             King        -48.8       -53.00
> 1188152                 0 -1357.9434
> 564         Georgia             Cobb         -2.2       -14.00
> 393340                 0 -1263.0208
> 2075       Michigan          Oakland         -8.1       -14.00
> 778418                 0 -1249.7561
> 291        Colorado        Jefferson         -6.9       -19.00
> 376430                 0 -1239.4528
> 292        Colorado          El Paso         22.3        11.00
> 375058                 0 -1153.2866
> 2321       Missouri St. Louis County        -16.2       -24.00
> 528107                 0 -1120.9259
> 3563          Texas           Travis        -38.6       -45.00
> 605034                 0 -1053.7077
> 277        Colorado         Arapahoe        -14.1       -25.00
> 346740                 0 -1028.4681
> 2744 North Carolina             Wake        -20.2       -26.00
> 624049                 0  -984.9339
> 3942       Virginia          Fairfax        -35.8       -42.00
> 578931                 0  -976.7398
> 1116         Kansas          Johnson          2.6        -8.00
> 338343                 0  -975.9407
> 3562          Texas            Bexar        -13.4       -18.00
> 757667                 0  -948.4110
> 2077       Michigan             Kent          3.1        -6.00
> 359915                 0  -891.2545
> 257        Colorado           Denver        -54.8       -64.00
> 350606                 0  -877.7434
> 110         Arizona             Pima        -13.6       -20.00
> 501058                 0  -872.6264
> 2625     New Jersey         Monmouth          9.3        -1.60
> 292654                 0  -868.0432
> 2745 North Carolina      Mecklenburg        -29.4       -35.00
> 565980                 0  -862.4809
> 3567          Texas       Williamson          9.7        -1.30
> 287696                 0  -861.1660
> 2894           Ohio         Franklin        -25.8       -31.00
> 606022                 0  -857.5355
> 203      California        Riverside         -5.4       -11.00
> 558759                 0  -851.4770
> 3966       Virginia   Virginia Beach          3.5        -8.00
> 253477                 0  -793.2257
>
> DISCLAIMER:
> I can not guarantee the accuracy of this data, or any conclusions.
>
> NOTE:
> Reiterating, several states used state-level values for 2016.
> (So, the Boston value above, may be off).
>
> Monospaced fonts are required for reading the contents of this email.
>
> LINKS:
>
> https://sites.google.com/site/spurdlea/temp_election
>
> https://sites.google.com/site/spurdlea/exts/election_data.txt
>

	[[alternative HTML version deleted]]


From rub@k @end|ng |rom m@th@@@u@dk  Tue Nov 10 08:30:38 2020
From: rub@k @end|ng |rom m@th@@@u@dk (Ege Rubak)
Date: Tue, 10 Nov 2020 07:30:38 +0000
Subject: [R] paste() turns list element character vector into deparsed
 expression. Why?
In-Reply-To: <D76CB58F-F845-4FDE-9FBF-C42C88E1A114@utoronto.ca>
References: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>
 <fa74a036c97f340f484049186eb0a1fecb689df1.camel@math.aau.dk>
 <D76CB58F-F845-4FDE-9FBF-C42C88E1A114@utoronto.ca>
Message-ID: <ba0acac3d86bd8b2789b36bc6569fc1e181d1e82.camel@math.aau.dk>

I agree that it is weird, but I don't see that it is easy to coerce a
list to character of the same structure. In my example (missing the
trailing parenthesis, sorry...) the input is a length two list and the
output is a length two character vector, so in the general case the
rationale seems to be that the output should have the same length as
the input, which makes sense. What specific length two character vector
would you suggest for this example? Would you paste the elements
together with an arbitrary separator of your choice?

In the more general case these elements could be anything: numbers,
characters, functions or even new lists, and I agree that it most often
probably just would make most sense to return an error. Actually I
think it is a bad idea to call `as.character()` on a list in the first
place. Logically this doesn't make much sense. If you want to use
`as.charater()` on each element in the list you should use `lapply()`.

If you really insist on representing a complicated structure as a list
as character I don't see any better general way to represent the list
as character than what R currently does.

Kind regards,
Ege


On Mon, 2020-11-09 at 12:58 +0000, Boris Steipe wrote:
> Thanks Ege -
> 
> That narrows it down, ... but it's still weird.
> 
> My issue is that I don't consider "c(\"xyz\", \"uvw\")" to be a valid
> character representation of a list. c() is a function, so "c(\"xyz\",
> \"uvw\")" is a string representation of a function call that could
> be  eval(parse(...))'ed into a two-element vector ... but considering
> this a coercion seems really weird.
> 
> What do I think your example should return? An object of the same
> general structure as the input, with non-character components coerced
> to character. And if that's not possible because there is no good
> character representation (e.g. if its a closure) than it should
> return an error. 
> 
> 
> Cheers,
> Boris
> 
>  
> 
> 
> > On 2020-11-09, at 22:24, Ege Rubak <rubak at math.aau.dk> wrote:
> > 
> > EXTERNAL EMAIL:  Treat content with extra caution.
> > 
> > I think `paste()` just calls `as.character()` on each input
> > argument
> > and then collapses things afterwards. Calling `as.character()` on
> > the
> > first input argument generates exactly the output you show (and
> > didn't
> > expect) and there is nothing to collapse. So changing `collapse =
> > ""`
> > to anything else doesn't change behaviour.
> > 
> > The question is reduced to how `as.character()` should handle a
> > list as
> > input. It seems to me that this input is so generic that it is hard
> > to
> > handle graciously without all kinds of special cases. So you expect
> > the
> > length one list
> > 
> > as.character(list(s = c("xyz", "uvw"))
> > 
> > to return the length 2 character vector `c("xyz", "uvw")`? What
> > should
> > 
> > as.character(list(s = c("xyz", "uvw"), t = c("a", "b", "c"))
> > 
> > return?
> > 
> > Kind regards,
> > Ege
> > 
> > On Mon, 2020-11-09 at 11:38 +0000, Boris Steipe wrote:
> > > I was just surprised by very un-intuitive behaviour of paste(),
> > > which
> > > appears to collapse a one-column data frame or one-element list
> > > into
> > > a deparsed expression, rather than producing the expected string.
> > > Can
> > > someone kindly explain what's going on here?
> > > 
> > > 
> > > reprex:
> > > =======
> > > 
> > > list(s = c("xyz", "uvw"))
> > > #     s
> > > # 1 xyz
> > > # 2 uvw
> > > 
> > > paste(list(s = c("xyz", "uvw")), collapse = "")
> > > # [1] "c(\"xyz\", \"uvw\")"   # This is unexpected!
> > > 
> > > I would have expected:
> > > # [1] "xyzuvw"
> > > 
> > > ... which I do get with e.g.
> > > paste(list(s = c("xyz", "uvw"))$s, collapse = "")
> > > 
> > > But what logic is there in returning a deparsed expression?
> > > 
> > > 
> > > 
> > > Thanks!
> > > Boris
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible
> > > code.

From m|@ojpm @end|ng |rom gm@||@com  Tue Nov 10 09:06:22 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Tue, 10 Nov 2020 16:06:22 +0800
Subject: [R] Remove all factor levels from an R dataframe
Message-ID: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>

Hi,

   I would like to sort the following simple dataframe by "year"
(characters), but the factor structure prevents me from doing so. How can I
remove the factor structure? Thanks!

> df1
  year                  country
4 2007             Asia; survey
5 2010 8 countries in E/SE Asia
6 2015                    Ghana
7
8 2000                      US?
> str(df1)
'data.frame': 5 obs. of  2 variables:
 $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
 $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
performance of the Euro Area",..: 4 5 6 7 8
> df1[order(-year), ]
Error in order(-year) : object 'year' not found

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Nov 10 09:56:04 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 10 Nov 2020 19:56:04 +1100
Subject: [R] Remove all factor levels from an R dataframe
In-Reply-To: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
References: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
Message-ID: <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>

Hi John,

df1<-sapply(df1,as.character)

Should do what you ask. The error message probably means that you should do
this:

df1<-df1[order(as.character(df1$year)),]

as "year" is the name of the first column in df1, not a separate object.

Jim

On Tue, Nov 10, 2020 at 6:57 PM John <miaojpm at gmail.com> wrote:

> Hi,
>
>    I would like to sort the following simple dataframe by "year"
> (characters), but the factor structure prevents me from doing so. How can I
> remove the factor structure? Thanks!
>
> > df1
>   year                  country
> 4 2007             Asia; survey
> 5 2010 8 countries in E/SE Asia
> 6 2015                    Ghana
> 7
> 8 2000                      US?
> > str(df1)
> 'data.frame': 5 obs. of  2 variables:
>  $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
>  $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
> performance of the Euro Area",..: 4 5 6 7 8
> > df1[order(-year), ]
> Error in order(-year) : object 'year' not found
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|@ojpm @end|ng |rom gm@||@com  Tue Nov 10 10:14:35 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Tue, 10 Nov 2020 17:14:35 +0800
Subject: [R] Remove all factor levels from an R dataframe
In-Reply-To: <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>
References: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
 <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>
Message-ID: <CABcx46Chm9MuM6e6JHeKOAd=_CZqf6sOvczqRu0pf43dHZ01ow@mail.gmail.com>

Thanks Jim. Can we do descending order?

Jim Lemon <drjimlemon at gmail.com> ? 2020?11?10? ?? ??4:56???

> Hi John,
>
> df1<-sapply(df1,as.character)
>
> Should do what you ask. The error message probably means that you should
> do this:
>
> df1<-df1[order(as.character(df1$year)),]
>
> as "year" is the name of the first column in df1, not a separate object.
>
> Jim
>
> On Tue, Nov 10, 2020 at 6:57 PM John <miaojpm at gmail.com> wrote:
>
>> Hi,
>>
>>    I would like to sort the following simple dataframe by "year"
>> (characters), but the factor structure prevents me from doing so. How can
>> I
>> remove the factor structure? Thanks!
>>
>> > df1
>>   year                  country
>> 4 2007             Asia; survey
>> 5 2010 8 countries in E/SE Asia
>> 6 2015                    Ghana
>> 7
>> 8 2000                      US?
>> > str(df1)
>> 'data.frame': 5 obs. of  2 variables:
>>  $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
>>  $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
>> performance of the Euro Area",..: 4 5 6 7 8
>> > df1[order(-year), ]
>> Error in order(-year) : object 'year' not found
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Nov 10 10:15:15 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 10 Nov 2020 20:15:15 +1100
Subject: [R] Remove all factor levels from an R dataframe
In-Reply-To: <CABcx46Chm9MuM6e6JHeKOAd=_CZqf6sOvczqRu0pf43dHZ01ow@mail.gmail.com>
References: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
 <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>
 <CABcx46Chm9MuM6e6JHeKOAd=_CZqf6sOvczqRu0pf43dHZ01ow@mail.gmail.com>
Message-ID: <CA+8X3fXLhh4K+-+gbrvpkpd=+mmEhBvDMkJ5XR95xM0sFfLfdQ@mail.gmail.com>

Sure John,

df1<-df1[order(as.character(df1$year),decreasing=TRUE),]

Jim

On Tue, Nov 10, 2020 at 8:05 PM John <miaojpm at gmail.com> wrote:

> Thanks Jim. Can we do descending order?
>
> Jim Lemon <drjimlemon at gmail.com> ? 2020?11?10? ?? ??4:56???
>
>> Hi John,
>>
>> df1<-sapply(df1,as.character)
>>
>> Should do what you ask. The error message probably means that you should
>> do this:
>>
>> df1<-df1[order(as.character(df1$year)),]
>>
>> as "year" is the name of the first column in df1, not a separate object.
>>
>> Jim
>>
>> On Tue, Nov 10, 2020 at 6:57 PM John <miaojpm at gmail.com> wrote:
>>
>>> Hi,
>>>
>>>    I would like to sort the following simple dataframe by "year"
>>> (characters), but the factor structure prevents me from doing so. How
>>> can I
>>> remove the factor structure? Thanks!
>>>
>>> > df1
>>>   year                  country
>>> 4 2007             Asia; survey
>>> 5 2010 8 countries in E/SE Asia
>>> 6 2015                    Ghana
>>> 7
>>> 8 2000                      US?
>>> > str(df1)
>>> 'data.frame': 5 obs. of  2 variables:
>>>  $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
>>>  $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
>>> performance of the Euro Area",..: 4 5 6 7 8
>>> > df1[order(-year), ]
>>> Error in order(-year) : object 'year' not found
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Nov 10 10:19:05 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 10 Nov 2020 11:19:05 +0200
Subject: [R] Remove all factor levels from an R dataframe
In-Reply-To: <CA+8X3fXLhh4K+-+gbrvpkpd=+mmEhBvDMkJ5XR95xM0sFfLfdQ@mail.gmail.com>
References: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
 <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>
 <CABcx46Chm9MuM6e6JHeKOAd=_CZqf6sOvczqRu0pf43dHZ01ow@mail.gmail.com>
 <CA+8X3fXLhh4K+-+gbrvpkpd=+mmEhBvDMkJ5XR95xM0sFfLfdQ@mail.gmail.com>
Message-ID: <CAGgJW7773YshuYWNHRj+Lea8xBzUi0JNsAUrPOQ1wHwfS7tzuA@mail.gmail.com>

Hi John,
I was thinking that you created df1 in a way that set the 'year'
column as a factor when this is not what you wanted to do.
The data.frame() function takes an argument stringsAsFactors which
controls this behavior.
For R versions 3.6.3 or earlier, the default setting is
stringsAsFactors=TRUE, which means that string columns automatically
become factors.
You have to specify stringsAsFactors=FALSE to avoid this. (In R 4.0.x
the default was changed to FALSE.)

Example:
df1 <- data.frame( a=letters[1:10], stringsAsFactors=FALSE )

HTH,
Eric

On Tue, Nov 10, 2020 at 11:16 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Sure John,
>
> df1<-df1[order(as.character(df1$year),decreasing=TRUE),]
>
> Jim
>
> On Tue, Nov 10, 2020 at 8:05 PM John <miaojpm at gmail.com> wrote:
>
> > Thanks Jim. Can we do descending order?
> >
> > Jim Lemon <drjimlemon at gmail.com> ? 2020?11?10? ?? ??4:56???
> >
> >> Hi John,
> >>
> >> df1<-sapply(df1,as.character)
> >>
> >> Should do what you ask. The error message probably means that you should
> >> do this:
> >>
> >> df1<-df1[order(as.character(df1$year)),]
> >>
> >> as "year" is the name of the first column in df1, not a separate object.
> >>
> >> Jim
> >>
> >> On Tue, Nov 10, 2020 at 6:57 PM John <miaojpm at gmail.com> wrote:
> >>
> >>> Hi,
> >>>
> >>>    I would like to sort the following simple dataframe by "year"
> >>> (characters), but the factor structure prevents me from doing so. How
> >>> can I
> >>> remove the factor structure? Thanks!
> >>>
> >>> > df1
> >>>   year                  country
> >>> 4 2007             Asia; survey
> >>> 5 2010 8 countries in E/SE Asia
> >>> 6 2015                    Ghana
> >>> 7
> >>> 8 2000                      US?
> >>> > str(df1)
> >>> 'data.frame': 5 obs. of  2 variables:
> >>>  $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
> >>>  $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
> >>> performance of the Euro Area",..: 4 5 6 7 8
> >>> > df1[order(-year), ]
> >>> Error in order(-year) : object 'year' not found
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nurog@|eo @end|ng |rom gm@||@com  Wed Nov 11 01:54:29 2020
From: nurog@|eo @end|ng |rom gm@||@com (=?UTF-8?B?R2FzcGFyIE7DusOxZXo=?=)
Date: Tue, 10 Nov 2020 18:54:29 -0600
Subject: [R] R ioanalysis pkg
Message-ID: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>

Hi,

Hope you are doing well, I?m trying to start working
with ioanalysis package, however its being difficult for me
to prepare data from my own input-output table,
import it into R in order to apply the ioanalysis functions
Any help on this will be highly appreciated.
Please note that I do not need links to the ioanalysis manual
nor to pages describing the package and its functions,
but something like a tutorial or worked example on
how to prepare data from the input-output table
import data into R, so that after that i can work with ioanalysis

Thank you very much in advance

Gaspar N??ez

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 11 02:08:36 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 10 Nov 2020 17:08:36 -0800
Subject: [R] R ioanalysis pkg
In-Reply-To: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
References: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
Message-ID: <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>

There are around 20,000 specialized packages for R. This list is set up to
help on standard R features and packages, but cannot possibly be expected
to support 20,000 packages. As the posting guide says (did you read it??!):

"If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."
(Note also: ?maintainer)

So did you you do this?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Nov 10, 2020 at 4:55 PM Gaspar N??ez <nurogaleo at gmail.com> wrote:

> Hi,
>
> Hope you are doing well, I?m trying to start working
> with ioanalysis package, however its being difficult for me
> to prepare data from my own input-output table,
> import it into R in order to apply the ioanalysis functions
> Any help on this will be highly appreciated.
> Please note that I do not need links to the ioanalysis manual
> nor to pages describing the package and its functions,
> but something like a tutorial or worked example on
> how to prepare data from the input-output table
> import data into R, so that after that i can work with ioanalysis
>
> Thank you very much in advance
>
> Gaspar N??ez
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Nov 11 03:06:42 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 10 Nov 2020 18:06:42 -0800
Subject: [R] R ioanalysis pkg
In-Reply-To: <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>
References: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
 <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>
Message-ID: <bfef77fc-e07a-9cc7-71e3-f6ecf3dea12e@comcast.net>


On 11/10/20 5:08 PM, Bert Gunter wrote:
> There are around 20,000 specialized packages for R. This list is set up to
> help on standard R features and packages, but cannot possibly be expected
> to support 20,000 packages. As the posting guide says (did you read it??!):
>
> "If the question relates to a *contributed package* , e.g., one downloaded
> from CRAN, try contacting the package maintainer first. You can also use
> find("functionname") and packageDescription("packagename") to find this
> information. *Only* send such questions to R-help or R-devel if you get no
> reply or need further assistance. This applies to both requests for help
> and to bug reports."
> (Note also: ?maintainer)
>
> So did you you do this?
>
> Bert Gunter

To follow up on this ... the StackOverflow forum also handles coding
questions but it specifically advises against posting overly broad
questions or requests for package recommendations or other requests for
external sources of programming advice or tutoring.

Like Rhelp, SO advises questioners is to prepare a test dataset and to show what efforts have been made using R code. The code should preferably install the package and then load it. It should then make whatever preliminary transformations you have attempted along with the compete error messages or descriptions of what results failed to meet your expectations.

Neither Rhelp or SO should be considered as sources for one-off tutorials or as places to ask for one-off projects builds.

-- 
David.

 ?On Tue, Nov 10, 2020 at 4:55 PM Gaspar N??ez <nurogaleo at gmail.com> wrote:

>> Hi,
>>
>> Hope you are doing well, I?m trying to start working
>> with ioanalysis package, however its being difficult for me
>> to prepare data from my own input-output table,
>> import it into R in order to apply the ioanalysis functions
>> Any help on this will be highly appreciated.
>> Please note that I do not need links to the ioanalysis manual
>> nor to pages describing the package and its functions,
>> but something like a tutorial or worked example on
>> how to prepare data from the input-output table
>> import data into R, so that after that i can work with ioanalysis
>>
>> Thank you very much in advance
>>
>> Gaspar N??ez
>>
>>          [[alternative HTML version deleted]
And .... Rhelp does not accept HTML code. If you had included code, it 
would probably have been mangles. Use plain text.


From drj|m|emon @end|ng |rom gm@||@com  Wed Nov 11 03:20:45 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 11 Nov 2020 13:20:45 +1100
Subject: [R] R ioanalysis pkg
In-Reply-To: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
References: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
Message-ID: <CA+8X3fX0p+1BSLZPXQ85cUWQs0qnCUsXhFUvCMqdm9=CcHji5w@mail.gmail.com>

Hi Gaspar,
I can see why you are having trouble with this. The "as.inputoutput"
function seems to be the core. While the manual claims you can just input
the "Z", "RS_label" and and "X" matrices to "as.inputoutput" and get the
"InputOutput" object that you need for all the other functions, it looks to
me as though the required input matrices are not trivial to create. The
manual is confusing as the argument name "Z" is overprinted by "RS_label"
My guess is that you will have to know a bit about what you are doing to
use the package.

Jim

On Wed, Nov 11, 2020 at 11:55 AM Gaspar N??ez <nurogaleo at gmail.com> wrote:

> Hi,
>
> Hope you are doing well, I?m trying to start working
> with ioanalysis package, however its being difficult for me
> to prepare data from my own input-output table,
> import it into R in order to apply the ioanalysis functions
> Any help on this will be highly appreciated.
> Please note that I do not need links to the ioanalysis manual
> nor to pages describing the package and its functions,
> but something like a tutorial or worked example on
> how to prepare data from the input-output table
> import data into R, so that after that i can work with ioanalysis
>
> Thank you very much in advance
>
> Gaspar N??ez
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nurog@|eo @end|ng |rom gm@||@com  Wed Nov 11 21:51:46 2020
From: nurog@|eo @end|ng |rom gm@||@com (=?UTF-8?B?R2FzcGFyIE7DusOxZXo=?=)
Date: Wed, 11 Nov 2020 14:51:46 -0600
Subject: [R] R ioanalysis pkg
In-Reply-To: <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>
References: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
 <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>
Message-ID: <CAHCwdFHH=uGPdHhxecC=5x2jA1tvxpw0Bjs2ah_3CSZvDMw+eA@mail.gmail.com>

Thank you very much Bert and David,
I appreciate your kind answers
which will be of great help to me no doubt.

G


On Tue, Nov 10, 2020 at 7:08 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> There are around 20,000 specialized packages for R. This list is set up to
> help on standard R features and packages, but cannot possibly be expected
> to support 20,000 packages. As the posting guide says (did you read it??!):
>
> "If the question relates to a *contributed package* , e.g., one
> downloaded from CRAN, try contacting the package maintainer first. You can
> also use find("functionname") and packageDescription("packagename") to
> find this information. *Only* send such questions to R-help or R-devel if
> you get no reply or need further assistance. This applies to both requests
> for help and to bug reports."
> (Note also: ?maintainer)
>
> So did you you do this?
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Nov 10, 2020 at 4:55 PM Gaspar N??ez <nurogaleo at gmail.com> wrote:
>
>> Hi,
>>
>> Hope you are doing well, I?m trying to start working
>> with ioanalysis package, however its being difficult for me
>> to prepare data from my own input-output table,
>> import it into R in order to apply the ioanalysis functions
>> Any help on this will be highly appreciated.
>> Please note that I do not need links to the ioanalysis manual
>> nor to pages describing the package and its functions,
>> but something like a tutorial or worked example on
>> how to prepare data from the input-output table
>> import data into R, so that after that i can work with ioanalysis
>>
>> Thank you very much in advance
>>
>> Gaspar N??ez
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @pr||ett|ngton @end|ng |rom gm@||@com  Wed Nov 11 22:59:44 2020
From: @pr||ett|ngton @end|ng |rom gm@||@com (April Ettington)
Date: Thu, 12 Nov 2020 10:59:44 +1300
Subject: [R] ggtree: color-code multiple paraphyletic clades
Message-ID: <CAE9tUWd7-uhZH+pCgDteJGDV8zRCk6TnrmVjZyGR8cGXGKaGbw@mail.gmail.com>

I've been using groupOTU to color paraphyletic clades in my tree based on
lists of tips, but I have multiple clades I want to highlight.  Is there
some way to use ggplot to indicate multiple paraphyletic clades?

Thank you

	[[alternative HTML version deleted]]


From m@rce|o|@|@ @end|ng |rom gm@||@com  Wed Nov 11 23:11:20 2020
From: m@rce|o|@|@ @end|ng |rom gm@||@com (Marcelo Laia)
Date: Wed, 11 Nov 2020 19:11:20 -0300
Subject: [R] ggplot2 stat_smooth formula different units
Message-ID: <20201111221120.GB33352@localhost>

Hi,

I am running these approaches:

Model 1

ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) + 
    geom_point(size=0.5) +
    stat_smooth(method = "lm",
                formula = y ~ x + I(x^2), size = 1) +
    facet_grid(Espacamento ~ Clone) +
    theme(legend.position="none")

Model 2

ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) + 
    geom_point(size=0.5) +
    stat_smooth(method = "lm",
                formula = I(log(y)) ~ I(1/x), size = 1) +
    facet_grid(Espacamento ~ Clone) +
    theme(legend.position="none")

In model 1, both, original variables and fitted variables are plotted
in the same units.

However, in the second one, points is plotted in the original variable,
instead of fitted variables. I know that

exp(fitted(model2)) 

do the trick and return the variables to the original units.

But, I don't know how I do this in the stat_smooth function.

Please, have you a tip for help me?

Thank you!

-- 
Marcelo


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Nov 12 00:10:51 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 11 Nov 2020 23:10:51 +0000
Subject: [R] ggplot2 stat_smooth formula different units
In-Reply-To: <20201111221120.GB33352@localhost>
References: <20201111221120.GB33352@localhost>
Message-ID: <7ec7f3ce-2a5a-bb4d-245c-69c5c56cfafe@sapo.pt>

Hello,

Try removing I() from I(log(y)). But it's hard to say without a 
reproducible example, please post the output of

dput(dat)

or, if dat is big, the output of

dput(head(dat, 20))


Hope this helps,

Rui Barradas

?s 22:11 de 11/11/20, Marcelo Laia escreveu:
> Hi,
> 
> I am running these approaches:
> 
> Model 1
> 
> ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
>      geom_point(size=0.5) +
>      stat_smooth(method = "lm",
>                  formula = y ~ x + I(x^2), size = 1) +
>      facet_grid(Espacamento ~ Clone) +
>      theme(legend.position="none")
> 
> Model 2
> 
> ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
>      geom_point(size=0.5) +
>      stat_smooth(method = "lm",
>                  formula = I(log(y)) ~ I(1/x), size = 1) +
>      facet_grid(Espacamento ~ Clone) +
>      theme(legend.position="none")
> 
> In model 1, both, original variables and fitted variables are plotted
> in the same units.
> 
> However, in the second one, points is plotted in the original variable,
> instead of fitted variables. I know that
> 
> exp(fitted(model2))
> 
> do the trick and return the variables to the original units.
> 
> But, I don't know how I do this in the stat_smooth function.
> 
> Please, have you a tip for help me?
> 
> Thank you!
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Nov 12 00:15:56 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 11 Nov 2020 23:15:56 +0000
Subject: [R] ggtree: color-code multiple paraphyletic clades
In-Reply-To: <CAE9tUWd7-uhZH+pCgDteJGDV8zRCk6TnrmVjZyGR8cGXGKaGbw@mail.gmail.com>
References: <CAE9tUWd7-uhZH+pCgDteJGDV8zRCk6TnrmVjZyGR8cGXGKaGbw@mail.gmail.com>
Message-ID: <f19c1ff9-1762-a994-3bb2-9d5fb06781f5@sapo.pt>

Hello,

You should post a reproducible example like the posting guide asks you to.
In the mean time, are you looking for [1], section Group Clades, by 
package ggtree author? It even seems to be the package vignette.

[1] 
https://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html


Hope this helps,

Rui Barradas

?s 21:59 de 11/11/20, April Ettington escreveu:
> I've been using groupOTU to color paraphyletic clades in my tree based on
> lists of tips, but I have multiple clades I want to highlight.  Is there
> some way to use ggplot to indicate multiple paraphyletic clades?
> 
> Thank you
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @pr||ett|ngton @end|ng |rom gm@||@com  Thu Nov 12 00:19:05 2020
From: @pr||ett|ngton @end|ng |rom gm@||@com (April Ettington)
Date: Thu, 12 Nov 2020 12:19:05 +1300
Subject: [R] ggtree: color-code multiple paraphyletic clades
In-Reply-To: <f19c1ff9-1762-a994-3bb2-9d5fb06781f5@sapo.pt>
References: <CAE9tUWd7-uhZH+pCgDteJGDV8zRCk6TnrmVjZyGR8cGXGKaGbw@mail.gmail.com>
 <f19c1ff9-1762-a994-3bb2-9d5fb06781f5@sapo.pt>
Message-ID: <CAE9tUWc4Xj9Kz9D78kP_BYi5OWyAHhoMJkT+-DHAckc=k-2hRg@mail.gmail.com>

Thank you, it seems the solution is to define the nodes in groupOTU using a
list of vectors.

On Thu, Nov 12, 2020 at 12:15 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> You should post a reproducible example like the posting guide asks you to.
> In the mean time, are you looking for [1], section Group Clades, by
> package ggtree author? It even seems to be the package vignette.
>
> [1]
>
> https://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 21:59 de 11/11/20, April Ettington escreveu:
> > I've been using groupOTU to color paraphyletic clades in my tree based on
> > lists of tips, but I have multiple clades I want to highlight.  Is there
> > some way to use ggplot to indicate multiple paraphyletic clades?
> >
> > Thank you
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From m@rce|o|@|@ @end|ng |rom gm@||@com  Thu Nov 12 00:36:31 2020
From: m@rce|o|@|@ @end|ng |rom gm@||@com (Marcelo Laia)
Date: Wed, 11 Nov 2020 20:36:31 -0300
Subject: [R] ggplot2 stat_smooth formula different units
In-Reply-To: <7ec7f3ce-2a5a-bb4d-245c-69c5c56cfafe@sapo.pt>
References: <20201111221120.GB33352@localhost>
 <7ec7f3ce-2a5a-bb4d-245c-69c5c56cfafe@sapo.pt>
Message-ID: <20201111233631.GA4908@localhost>

Hi Rui,

You are very welcome!

On 11/11/20 at 11:10, Rui Barradas wrote:
> 
> dput(head(dat, 20))
> 

structure(list(Bloco = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), Espacamento = c("3 x 1", 
"3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", 
"3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", 
"3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1"), Clone = c("AEC 0020", 
"AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", 
"AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", 
"AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", 
"AEC 0020"), Sulco = c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L), Arvore = c(1L, 3L, 5L, 
6L, 7L, 8L, 9L, 10L, 11L, 1L, 2L, 4L, 5L, 6L, 8L, 9L, 10L, 11L, 
1L, 2L), DAP = c(7, 7.73, 7.64, 9.61, 11.94, 11.46, 11.68, 11.84, 
13.37, 11.14, 10.5, 12.19, 7.23, 8.94, 9.99, 12.67, 5.09, 6.37, 
10.28, 8.12), Altura = c(14.8, 17.2, 14.8, 17.2, 18.5, 19.2, 
19.2, 18, 19.3, 18.2, 18.1, 18.1, 15.7, 17.1, 19.3, 19.2, 10.9, 
13.2, 17.1, 16.5), Observacao = c("", "", "", "", "", "", "", 
"", "", "", "", "", "", "", "", "", "", "", "", "")), row.names = c(1L, 
3L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 18L, 
19L, 20L, 21L, 22L, 23L), class = "data.frame")

-- 
Marcelo


From tr@xp|@yer @end|ng |rom gm@||@com  Thu Nov 12 01:23:06 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 12 Nov 2020 01:23:06 +0100
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
Message-ID: <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>

Please watch this video if you wrongly believe that Benford's law easily
can be applied to elections results.

https://youtu.be/etx0k1nLn78



On Sun, Nov 1, 2020, 21:17 Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

> Hello:
>
>
>        What can you tell me about plans to analyze data from this year's
> general election, especially to detect possible fraud?
>
>
>        I might be able to help with such an effort.  I have NOT done
> much with election data, but I have developed tools for data analysis,
> including web scraping, and included them in R packages available on the
> Comprehensive R Archive Network (CRAN) and GitHub.[1]
>
>
>        Penny Abernathy, who holds the Knight Chair in Journalism and
> Digital Media Economics at UNC-Chapel Hill, told me that the electoral
> fraud that disqualified the official winner from NC-09 to the US House
> in 2018 was detected by a college prof, who accessed the data two weeks
> after the election.[2]
>
>
>        Spencer Graves
>
>
> [1]
> https://github.com/sbgraves237
>
>
> [2]
> https://en.wikiversity.org/wiki/Local_Journalism_Sustainability_Act
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Thu Nov 12 01:39:28 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 12 Nov 2020 00:39:28 +0000
Subject: [R] please help with "could not find function "ComBat.mc" "
Message-ID: <CH2PR02MB6069C5F94AAF00DBA88F62D9D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>


Hi All,

I am very sorry to bother you.

This week, I updated my R from 3.5.3? to 4.0.3, reinstalled all required R packages  and reran the following R code;  then got the following error: could not find function "ComBat.mc".

> #' firstly Removing chip-well batch effects using ComBat from the sva package
> # First we convert from beta-values to M-values
> Mvals1 <- log2(betas.rcp)-log2(1-betas.rcp)
> #' ComBat eBayes adjustment using a known variable of interest (here we use row)
> Mvals.ComBat1 <- ComBat.mc(Mvals1, batch = pData(WB.noob)$Array,nCores = detectCores()-1)
Error in ComBat.mc(Mvals1, batch = pData(WB.noob)$Array, nCores = detectCores() -? : 
??could not find function "ComBat.mc"

I have successfully run the same R code with same data sets several times since 2017.? Google searching tells me that this ComBat.mc function is from an R package "Enmix".  When typing library(Enmix), no error message, so the Enmix library is installed.? Can you tell me why I got this error after updating to new R version? 

Thank you,

Yuan Chun Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From j|ox @end|ng |rom mcm@@ter@c@  Thu Nov 12 01:52:07 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Wed, 11 Nov 2020 19:52:07 -0500
Subject: [R] 
 [effects] Wrong xlevels in effects plot for mixed effects model
 when multiline = TRUE
In-Reply-To: <a1928d36-93d3-db2e-7f5d-cecd7536a759@math.uni-giessen.de>
References: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
 <27049_1604927072_0A9D4V3L027674_5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>
 <b4df868d-77ea-3524-02ef-ca2661225dbf@mcmaster.ca>
 <a1928d36-93d3-db2e-7f5d-cecd7536a759@math.uni-giessen.de>
Message-ID: <80397afa-d93b-ddaf-c3b4-837fc10be8bf@mcmaster.ca>

Dear Gerrit,

The bug you reported should now be fixed in the development version 
4.2-1 of the effects package, which you can currently install from 
R-Forge via  install.packages("effects", 
repos="http://R-Forge.R-project.org") . Eventually, the updated version 
of the effects package will be submitted to CRAN.

Thank you again for the bug report,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-11-09 4:51 p.m., Gerrit Eichner wrote:
> Dear John,
> 
> thank you for prompt reply and your hints. The problem is that our
> lmer model is much more complicated and has several interaction
> terms:
> 
> Mass ~ Sex + I(YoE - 1996) + I(PAI/0.1 - 16) + I(gProt/10 - 6.2) +
>  ??? I(Age/10 - 7.2) + I((Age/10 - 7.2)^2) + Diuretics +
>  ??? Sex:I(PAI/0.1 - 16) + Sex:I(gProt/10 - 6.2) +
>  ??? Sex:I(Age/10 - 7.2) + Sex:I((Age/10 - 7.2)^2) +
>  ??? I(YoE - 1996):I(Age/10 - 7.2) + I(PAI/0.1 - 16):I(Age/10 - 7.2) +
>  ??? I(gProt/10 - 6.2):I(Age/10 - 7.2) +
>  ??? (I(Age/10 - 7.2) + I((Age/10 - 7.2)^2) | ID)
> 
> so that allEffects is quite efficient, and since I want to place
> several interaction terms with Age in one figure with Age on the
> horizontal axis the argument x.var = "Age" in plot would be very
> helpful. :-)
> 
> Further hints using the above complex model: The following works well:
> eff <- Effect(c("gProt", "Age"), m,
>  ????????????? xlevels = list(gProt = 1:6 * 30, Age = 60:100))
> plot(eff, lines=list(multiline=TRUE), x.var = "Age")
> 
> But this fails (note that Age is missing in xlevels):
> eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30))
> plot(eff, lines=list(multiline=TRUE), x.var = "Age")
> 
> 
> And that just led me to a solutution also for allEffects: Specifying
> Age in xlevels for allEffects (although it seems unnecessary when
> x.var = "Age" is used in plot) produces the correct graphical
> output! :-)
> 
> Thank you very much for your support and the brilliant effects
> package in general! :-)
> 
>  ?Best regards? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 09.11.2020 um 19:51 schrieb John Fox:
>> Dear Gerrit,
>>
>> This looks like a bug in plot.eff(), which I haven't yet tracked down, 
>> but the following should give you what you want:
>>
>> eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30, 
>> Age=60:100))
>> plot(eff, lines=list(multiline=TRUE))
>>
>> or
>>
>> eff <- predictorEffect("Age", m, xlevels = list(gProt = 1:6 * 30))
>> plot(eff, lines=list(multiline=TRUE))
>>
>> A couple of comments on your code, unrelated to the bug in plot.eff():
>>
>> You don't need allEffects() because there's only one high-order fixed 
>> effect in the model, I(gProt/10 - 6.2):I(Age/10 - 7.2) (i.e., the 
>> interaction of gProt with Age).
>>
>> x.var isn't intended as an argument for plot() with allEffects() 
>> because there generally isn't a common horizontal axis for all of the 
>> high-order effect plots.
>>
>> Finally, thank you for the bug report. Barring unforeseen 
>> difficulties, we'll fix the bug in due course.
>>
>> I hope this helps,
>> ??John
>>
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> web: https://socialsciences.mcmaster.ca/jfox/
>>
>> On 2020-11-09 8:06 a.m., Gerrit Eichner wrote:
>>> Dear list members,
>>>
>>> I observe a strange/wrong graphical output when I set the xlevels
>>> in (e. g.) allEffects for an lmer model and plot the effects with
>>> multiline = TRUE. I have compiled a reprex for which you need the
>>> lmer model and the environment in which the model was fitted. They
>>> are contained in the zip file at
>>> https://jlubox.uni-giessen.de/dl/fiSzTCc3bW8z2npZvPpqG1xr/m-and-G1.zip
>>> After unpacking the following should work:
>>>
>>> m <- readRDS("m.rds")?? # The lmer-model.
>>> G1 <- readRDS("G1.rds") # Environment in which the model
>>> ????????????????????????? # was fitted; needed by alaEffects.
>>> summary(m) # Just to see the model.
>>>
>>> library(effects)
>>> aE <- allEffects(m, xlevels = list(gProt = 1:6 * 30))
>>> ????????????????????? # Non-default values for xlevels.
>>>
>>> plot(aE)????????????????????? # Fine.
>>> plot(aE, x.var = "Age")?????? # Fine.
>>> plot(aE, lines = list(multiline = TRUE))? # Fine.
>>>
>>> plot(aE, lines = list(multiline = TRUE),
>>> ?????? x.var = "Age")??????? # Nonsense.
>>>
>>>
>>> Anybody any idea about the reason, my mistake, or a
>>> workaround? Thx for any hint!
>>>
>>> ?? Regards? --? Gerrit
>>>
>>>
>>> PS:
>>> ??> sessionInfo()
>>> R version 4.0.2 (2020-06-22)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 18363)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252
>>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>>> [5] LC_TIME=German_Germany.1252
>>>
>>> attached base packages:
>>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>>>
>>> other attached packages:
>>> [1] effects_4.2-0 carData_3.0-4
>>>
>>> loaded via a namespace (and not attached):
>>> ?? [1] Rcpp_1.0.5?????? lattice_0.20-41? MASS_7.3-53????? grid_4.0.2 
>>> DBI_1.1.0
>>> ?? [6] nlme_3.1-149???? survey_4.0?????? estimability_1.3 minqa_1.2.4 
>>> nloptr_1.2.2.2
>>> [11] Matrix_1.2-18??? boot_1.3-25????? splines_4.0.2    
>>> statmod_1.4.34 lme4_1.1-23
>>> [16] tools_4.0.2????? survival_3.2-3?? yaml_2.2.1       
>>> compiler_4.0.2 colorspace_1.4-1
>>> [21] mitools_2.4????? insight_0.9.5??? nnet_7.3-14
>>>
>>> ---------------------------------------------------------------------
>>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>>> http://www.uni-giessen.de/eichner
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From z|@d@e|mou@|y @end|ng |rom u@@metr|x|@b@com  Wed Nov 11 23:06:03 2020
From: z|@d@e|mou@|y @end|ng |rom u@@metr|x|@b@com (Ziad Elmously)
Date: Wed, 11 Nov 2020 22:06:03 +0000
Subject: [R] Error Message With the "MCMCmixfactanal" Function
Message-ID: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>

To Whom It May Concern,

In am using the script below to test the function "MAMCmixfactanal" in the package "MCMCpack".

library(MCMCpack)
data(PErisk)
post <- MCMCmixfactanal(~courts+barb2+prsexp2+prscorr2+gdpw2, factors=1, data=PErisk, lambda.constraints=
  list(courts=list(2,"-")),burnin=5000,mcmc=1000000,thin=50,verbose=500,L0=.25,store.lambda=TRUE,store.scores=TRUE,tune=1.2)
plot(post)
summary(post)

However, I get the error message below.

Acceptance rates:
Error in print.default(t(accepts)/(posterior$burnin + posterior$mcmc),  :
  invalid printing width

Your help would be greatly appreciated.

Kind regards,

Ziad Elmously
Director, Advanced Analytics & Data Science

MetrixLab, a Macromill Group company
Chalfont, PA, USA
T (+1) 267 298 1159 ? M (+1) 267 218 4724
ziad.elmously at us.metrixlab.com<mailto:ziad.elmously at us.metrixlab.com> ? www.metrixlab.com<http://www.metrixlab.com/>

How do you create a powerful packaging design?
Discover our 9 best practices. Read our whitepaper ><http://bit.ly/2sGPKEo>


	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Nov 12 02:35:32 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 12 Nov 2020 12:35:32 +1100
Subject: [R] please help with "could not find function "ComBat.mc" "
In-Reply-To: <CH2PR02MB6069C5F94AAF00DBA88F62D9D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>
References: <CH2PR02MB6069C5F94AAF00DBA88F62D9D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>
Message-ID: <CA+8X3fVKk0jKX9ZSCr5jc7s4Gugydr+A_T4oipBz2wJUSpLGhQ@mail.gmail.com>

Hi Yuan,
The package named "Enmix" is maintained on Bioconductor. It seems to be
specific to particular lab equipment and so all I can advise is:

1) Try your question on the Bioconductor help list
2) If no help there contact Zongli Xu (the maintainer)

Jim

On Thu, Nov 12, 2020 at 11:40 AM Yuan Chun Ding <ycding at coh.org> wrote:

>
> Hi All,
>
> I am very sorry to bother you.
>
> This week, I updated my R from 3.5.3  to 4.0.3, reinstalled all required R
> packages  and reran the following R code;  then got the following error:
> could not find function "ComBat.mc".
>
> > #' firstly Removing chip-well batch effects using ComBat from the sva
> package
> > # First we convert from beta-values to M-values
> > Mvals1 <- log2(betas.rcp)-log2(1-betas.rcp)
> > #' ComBat eBayes adjustment using a known variable of interest (here we
> use row)
> > Mvals.ComBat1 <- ComBat.mc(Mvals1, batch = pData(WB.noob)$Array,nCores =
> detectCores()-1)
> Error in ComBat.mc(Mvals1, batch = pData(WB.noob)$Array, nCores =
> detectCores() -  :
>   could not find function "ComBat.mc"
>
> I have successfully run the same R code with same data sets several times
> since 2017.  Google searching tells me that this ComBat.mc function is from
> an R package "Enmix".  When typing library(Enmix), no error message, so the
> Enmix library is installed.  Can you tell me why I got this error after
> updating to new R version?
>
> Thank you,
>
> Yuan Chun Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to receive further
> communications via e-mail, please reply to this message and inform the
> sender that you do not wish to receive further e-mail from the sender.
> (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Nov 12 03:03:54 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 11 Nov 2020 18:03:54 -0800
Subject: [R] Error Message With the "MCMCmixfactanal" Function
In-Reply-To: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>
References: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>
Message-ID: <CAGxFJbSTcaX0AMioHOoThA0r=U8CP7UWJ0Ekh8-5CPWkfiX4AQ@mail.gmail.com>

Please read and follow the posting guide linked below, especially this:

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<http://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports. "

Note: also ?maintainer for finding emails of maintainers.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Nov 11, 2020 at 5:30 PM Ziad Elmously <
ziad.elmously at us.metrixlab.com> wrote:

> To Whom It May Concern,
>
> In am using the script below to test the function "MAMCmixfactanal" in the
> package "MCMCpack".
>
> library(MCMCpack)
> data(PErisk)
> post <- MCMCmixfactanal(~courts+barb2+prsexp2+prscorr2+gdpw2, factors=1,
> data=PErisk, lambda.constraints=
>
> list(courts=list(2,"-")),burnin=5000,mcmc=1000000,thin=50,verbose=500,L0=.25,store.lambda=TRUE,store.scores=TRUE,tune=1.2)
> plot(post)
> summary(post)
>
> However, I get the error message below.
>
> Acceptance rates:
> Error in print.default(t(accepts)/(posterior$burnin + posterior$mcmc),  :
>   invalid printing width
>
> Your help would be greatly appreciated.
>
> Kind regards,
>
> Ziad Elmously
> Director, Advanced Analytics & Data Science
>
> MetrixLab, a Macromill Group company
> Chalfont, PA, USA
> T (+1) 267 298 1159   M (+1) 267 218 4724
> ziad.elmously at us.metrixlab.com<mailto:ziad.elmously at us.metrixlab.com>
> www.metrixlab.com<http://www.metrixlab.com/>
>
> How do you create a powerful packaging design?
> Discover our 9 best practices. Read our whitepaper ><http://bit.ly/2sGPKEo
> >
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Nov 12 03:14:15 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 11 Nov 2020 18:14:15 -0800
Subject: [R] ggplot2 stat_smooth formula different units
In-Reply-To: <20201111221120.GB33352@localhost>
References: <20201111221120.GB33352@localhost>
Message-ID: <21450fcf-7386-670f-7d3c-b0aafd1fd771@comcast.net>


On 11/11/20 2:11 PM, Marcelo Laia wrote:
> Hi,
>
> I am running these approaches:
>
> Model 1
>
> ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
>      geom_point(size=0.5) +
>      stat_smooth(method = "lm",
>                  formula = y ~ x + I(x^2), size = 1) +
>      facet_grid(Espacamento ~ Clone) +
>      theme(legend.position="none")
>
> Model 2
>
> ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
>      geom_point(size=0.5) +
>      stat_smooth(method = "lm",
>                  formula = I(log(y)) ~ I(1/x), size = 1) +
>      facet_grid(Espacamento ~ Clone) +
>      theme(legend.position="none")

Removing the I(.) calls has no effect.

I think you should reshape that formula to the equivalent form with no 
transformation on the LHS:


ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
 ??? geom_point(size=0.5) +
 ??? stat_smooth(method = "lm",
 ??????????????? formula = y ~ exp(1/x), size = 1) +
 ??? facet_grid(Espacamento ~ Clone) +
 ??? theme(legend.position="none")


-- 

David.

>
> In model 1, both, original variables and fitted variables are plotted
> in the same units.
>
> However, in the second one, points is plotted in the original variable,
> instead of fitted variables. I know that
>
> exp(fitted(model2))
>
> do the trick and return the variables to the original units.
>
> But, I don't know how I do this in the stat_smooth function.
>
> Please, have you a tip for help me?
>
> Thank you!
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Nov 12 03:18:56 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 11 Nov 2020 18:18:56 -0800
Subject: [R] Error Message With the "MCMCmixfactanal" Function
In-Reply-To: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>
References: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>
Message-ID: <4F1A4DD6-C62E-4069-8777-07309BACA075@dcn.davis.ca.us>

Someone may feel like tackling this anyway, but technically it is off-topic here, as this forum is about the R language rather than specific contributed packages. (http://www.r-project.org/posting-guide.html). Lookup the package DESCRIPTION file on CRAN and if it does not mention a recommended support forum then correspond with the package maintainer.

On November 11, 2020 2:06:03 PM PST, Ziad Elmously <ziad.elmously at us.metrixlab.com> wrote:
>To Whom It May Concern,
>
>In am using the script below to test the function "MAMCmixfactanal" in
>the package "MCMCpack".
>
>library(MCMCpack)
>data(PErisk)
>post <- MCMCmixfactanal(~courts+barb2+prsexp2+prscorr2+gdpw2,
>factors=1, data=PErisk, lambda.constraints=
>list(courts=list(2,"-")),burnin=5000,mcmc=1000000,thin=50,verbose=500,L0=.25,store.lambda=TRUE,store.scores=TRUE,tune=1.2)
>plot(post)
>summary(post)
>
>However, I get the error message below.
>
>Acceptance rates:
>Error in print.default(t(accepts)/(posterior$burnin + posterior$mcmc), 
>:
>  invalid printing width
>
>Your help would be greatly appreciated.
>
>Kind regards,
>
>Ziad Elmously
>Director, Advanced Analytics & Data Science
>
>MetrixLab, a Macromill Group company
>Chalfont, PA, USA
>T (+1) 267 298 1159 ? M (+1) 267 218 4724
>ziad.elmously at us.metrixlab.com<mailto:ziad.elmously at us.metrixlab.com> ?
>www.metrixlab.com<http://www.metrixlab.com/>
>
>How do you create a powerful packaging design?
>Discover our 9 best practices. Read our whitepaper
>><http://bit.ly/2sGPKEo>
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From phii m@iii@g oii phiiipsmith@c@  Thu Nov 12 04:25:27 2020
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Wed, 11 Nov 2020 22:25:27 -0500
Subject: [R] Data transformation problem
Message-ID: <1cea8da18f039c65f3d8b5640d621a31@philipsmith.ca>

I am stuck on a data transformation problem. I have a data frame, df1 in 
my example, with some original "levels" data. The data pertain to some 
variable, such as GDP, in various reference periods, REF, as estimated 
and released in various release periods, REL. The release periods follow 
after the reference periods by two months or more, sometimes by several 
years. I want to build a second data frame, called df2 in my example, 
with the month-to-month growth rates that existed in each reference 
period, revealing the revisions to those growth rates in subsequent 
periods.

REF1 <- 
c("2017-01-01","2017-01-01","2017-01-01","2017-01-01","2017-01-01",
   "2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
   "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
REL1 <- 
c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
   "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
   "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
VAL1 <- 
c(17974,14567,13425,NA,12900,17974,14000,14000,12999,13245,17197,11500,
   19900,18765,13467)
df1 <- data.frame(REF1,REL1,VAL1)
REF2 <- 
c("2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
   "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
REL2 <- 
c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
   "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
VAL2 <- c(0.0,-3.9,4.3,NA,2.3,-4.3,-17.9,42.1,44.4,1.7)
df2 <- data.frame(REF2,REL2,VAL2)

In my example I have provided some sample data pertaining to three 
reference months, 2017-01-01 through 2017-03-01, and five release 
periods, "2020-09-01","2020-08-01","2020-07-01","2020-06-01" and 
"2019-05-01". In my actual problem I have millions of REF-REL 
combinations, so my data frame is quite large. I am using data.table for 
faster processing, though I am more familiar with the tidyverse. I am 
providing df2 as the target data frame for my example, so you can see 
what I am trying to achieve.

I have not been able to find an efficient way to do these calculations. 
I have tried "for" loops with "if" statements, without success so far, 
and anyway this approach would be too slow, I fear. Suggestions as to 
how I might proceed would be much appreciated.

Philip


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Nov 12 08:20:32 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 11 Nov 2020 23:20:32 -0800 (PST)
Subject: [R] Data transformation problem
In-Reply-To: <1cea8da18f039c65f3d8b5640d621a31@philipsmith.ca>
References: <1cea8da18f039c65f3d8b5640d621a31@philipsmith.ca>
Message-ID: <alpine.BSF.2.00.2011112314400.36172@pedal.dcn.davis.ca.us>

I am not a data.table afficiando, but here is how I would do it with 
dplyr/tidyr:

library(dplyr)
library(tidyr)

do_per_REL <- function( DF ) {
   rng <- range( DF$REF1 ) # watch out for missing months?
   DF <- (   data.frame( REF1 = seq( rng[ 1 ], rng[ 2 ], by = "month" ) )
         %>% left_join( DF, by = "REF1" )
         %>% arrange( REF1 )
         )
   with( DF
       , data.frame( REF2 = REF1[ -1 ]
                   , VAL2 = 100 * diff( VAL1 ) / VAL1[ -length( VAL1 ) ]
                   )
       )
}

df2a <- (   df1
         %>% mutate( REF1 = as.Date( REF1 )
                   , REL1 = as.Date( REL1 )
                   )
         %>% nest( data = -REL1 )
         %>% rename( REL2 = REL1 )
         %>% rowwise()
         %>% mutate( data = list( do_per_REL( data ) ) )
         %>% ungroup()
         %>% unnest( cols = "data" )
         %>% select( REF2, REL2, VAL2 )
         %>% arrange( REF2, desc( REL2 ), VAL2 )
         )
df2a

On Wed, 11 Nov 2020, phil at philipsmith.ca wrote:

> I am stuck on a data transformation problem. I have a data frame, df1 in my 
> example, with some original "levels" data. The data pertain to some variable, 
> such as GDP, in various reference periods, REF, as estimated and released in 
> various release periods, REL. The release periods follow after the reference 
> periods by two months or more, sometimes by several years. I want to build a 
> second data frame, called df2 in my example, with the month-to-month growth 
> rates that existed in each reference period, revealing the revisions to those 
> growth rates in subsequent periods.
>
> REF1 <- c("2017-01-01","2017-01-01","2017-01-01","2017-01-01","2017-01-01",
>  "2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
>  "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
> REL1 <- c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
> VAL1 <- 
> c(17974,14567,13425,NA,12900,17974,14000,14000,12999,13245,17197,11500,
>  19900,18765,13467)
> df1 <- data.frame(REF1,REL1,VAL1)
> REF2 <- c("2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
>  "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
> REL2 <- c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
> VAL2 <- c(0.0,-3.9,4.3,NA,2.3,-4.3,-17.9,42.1,44.4,1.7)
> df2 <- data.frame(REF2,REL2,VAL2)
>
> In my example I have provided some sample data pertaining to three reference 
> months, 2017-01-01 through 2017-03-01, and five release periods, 
> "2020-09-01","2020-08-01","2020-07-01","2020-06-01" and "2019-05-01". In my 
> actual problem I have millions of REF-REL combinations, so my data frame is 
> quite large. I am using data.table for faster processing, though I am more 
> familiar with the tidyverse. I am providing df2 as the target data frame for 
> my example, so you can see what I am trying to achieve.
>
> I have not been able to find an efficient way to do these calculations. I 
> have tried "for" loops with "if" statements, without success so far, and 
> anyway this approach would be too slow, I fear. Suggestions as to how I might 
> proceed would be much appreciated.
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From phii m@iii@g oii phiiipsmith@c@  Thu Nov 12 13:23:34 2020
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Thu, 12 Nov 2020 07:23:34 -0500
Subject: [R] Data transformation problem
In-Reply-To: <alpine.BSF.2.00.2011112314400.36172@pedal.dcn.davis.ca.us>
References: <1cea8da18f039c65f3d8b5640d621a31@philipsmith.ca>
 <alpine.BSF.2.00.2011112314400.36172@pedal.dcn.davis.ca.us>
Message-ID: <73f34267eb874bcdc99c5fbd0273d2e1@philipsmith.ca>

Thank you so much for this elegant solution, Jeff.

Philip

On 2020-11-12 02:20, Jeff Newmiller wrote:
> I am not a data.table afficiando, but here is how I would do it with
> dplyr/tidyr:
> 
> library(dplyr)
> library(tidyr)
> 
> do_per_REL <- function( DF ) {
>   rng <- range( DF$REF1 ) # watch out for missing months?
>   DF <- (   data.frame( REF1 = seq( rng[ 1 ], rng[ 2 ], by = "month" ) 
> )
>         %>% left_join( DF, by = "REF1" )
>         %>% arrange( REF1 )
>         )
>   with( DF
>       , data.frame( REF2 = REF1[ -1 ]
>                   , VAL2 = 100 * diff( VAL1 ) / VAL1[ -length( VAL1 ) ]
>                   )
>       )
> }
> 
> df2a <- (   df1
>         %>% mutate( REF1 = as.Date( REF1 )
>                   , REL1 = as.Date( REL1 )
>                   )
>         %>% nest( data = -REL1 )
>         %>% rename( REL2 = REL1 )
>         %>% rowwise()
>         %>% mutate( data = list( do_per_REL( data ) ) )
>         %>% ungroup()
>         %>% unnest( cols = "data" )
>         %>% select( REF2, REL2, VAL2 )
>         %>% arrange( REF2, desc( REL2 ), VAL2 )
>         )
> df2a
> 
> On Wed, 11 Nov 2020, phil at philipsmith.ca wrote:
> 
>> I am stuck on a data transformation problem. I have a data frame, df1 
>> in my example, with some original "levels" data. The data pertain to 
>> some variable, such as GDP, in various reference periods, REF, as 
>> estimated and released in various release periods, REL. The release 
>> periods follow after the reference periods by two months or more, 
>> sometimes by several years. I want to build a second data frame, 
>> called df2 in my example, with the month-to-month growth rates that 
>> existed in each reference period, revealing the revisions to those 
>> growth rates in subsequent periods.
>> 
>> REF1 <- 
>> c("2017-01-01","2017-01-01","2017-01-01","2017-01-01","2017-01-01",
>>  "2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
>>  "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
>> REL1 <- 
>> c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
>> VAL1 <- 
>> c(17974,14567,13425,NA,12900,17974,14000,14000,12999,13245,17197,11500,
>>  19900,18765,13467)
>> df1 <- data.frame(REF1,REL1,VAL1)
>> REF2 <- 
>> c("2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
>>  "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
>> REL2 <- 
>> c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
>> VAL2 <- c(0.0,-3.9,4.3,NA,2.3,-4.3,-17.9,42.1,44.4,1.7)
>> df2 <- data.frame(REF2,REL2,VAL2)
>> 
>> In my example I have provided some sample data pertaining to three 
>> reference months, 2017-01-01 through 2017-03-01, and five release 
>> periods, "2020-09-01","2020-08-01","2020-07-01","2020-06-01" and 
>> "2019-05-01". In my actual problem I have millions of REF-REL 
>> combinations, so my data frame is quite large. I am using data.table 
>> for faster processing, though I am more familiar with the tidyverse. I 
>> am providing df2 as the target data frame for my example, so you can 
>> see what I am trying to achieve.
>> 
>> I have not been able to find an efficient way to do these 
>> calculations. I have tried "for" loops with "if" statements, without 
>> success so far, and anyway this approach would be too slow, I fear. 
>> Suggestions as to how I might proceed would be much appreciated.
>> 
>> Philip
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go 
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live 
> Go...
>                                       Live:   OO#.. Dead: OO#..  
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  
> rocks...1k
> ---------------------------------------------------------------------------


From ycd|ng @end|ng |rom coh@org  Thu Nov 12 18:41:49 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 12 Nov 2020 17:41:49 +0000
Subject: [R] please help with "could not find function "ComBat.mc" "
In-Reply-To: <CA+8X3fVKk0jKX9ZSCr5jc7s4Gugydr+A_T4oipBz2wJUSpLGhQ@mail.gmail.com>
References: <CH2PR02MB6069C5F94AAF00DBA88F62D9D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>
 <CA+8X3fVKk0jKX9ZSCr5jc7s4Gugydr+A_T4oipBz2wJUSpLGhQ@mail.gmail.com>
Message-ID: <CH2PR02MB60696B8D66862F09BD3C0DC1D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>

Hi Jim,

Thank you for the message!  Yes, you are right, I contacted Dr. Xu Zongli,  he said he removed the ComBat.mc function from the new version.

Ding

From: Jim Lemon [mailto:drjimlemon at gmail.com]
Sent: Wednesday, November 11, 2020 5:36 PM
To: Yuan Chun Ding <ycding at coh.org>
Cc: r-help at r-project.org
Subject: Re: [R] please help with "could not find function "ComBat.mc" "

Hi Yuan,
The package named "Enmix" is maintained on Bioconductor. It seems to be specific to particular lab equipment and so all I can advise is:

1) Try your question on the Bioconductor help list
2) If no help there contact Zongli Xu (the maintainer)

Jim

On Thu, Nov 12, 2020 at 11:40 AM Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>> wrote:

Hi All,

I am very sorry to bother you.

This week, I updated my R from 3.5.3  to 4.0.3, reinstalled all required R packages  and reran the following R code;  then got the following error: could not find function "ComBat.mc".

> #' firstly Removing chip-well batch effects using ComBat from the sva package
> # First we convert from beta-values to M-values
> Mvals1 <- log2(betas.rcp)-log2(1-betas.rcp)
> #' ComBat eBayes adjustment using a known variable of interest (here we use row)
> Mvals.ComBat1 <- ComBat.mc(Mvals1, batch = pData(WB.noob)$Array,nCores = detectCores()-1)
Error in ComBat.mc(Mvals1, batch = pData(WB.noob)$Array, nCores = detectCores() -  :
  could not find function "ComBat.mc"

I have successfully run the same R code with same data sets several times since 2017.  Google searching tells me that this ComBat.mc function is from an R package "Enmix".  When typing library(Enmix), no error message, so the Enmix library is installed.  Can you tell me why I got this error after updating to new R version?

Thank you,

Yuan Chun Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!7LIBMZ-Dl-TUctBxHgefJtTy8Nam0_pdDxu6OlxC4fddmXLyFrFFNr_sX0eD$>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!7LIBMZ-Dl-TUctBxHgefJtTy8Nam0_pdDxu6OlxC4fddmXLyFrFFNuvLUbzY$>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From g@@@uu| @end|ng |rom gm@||@com  Fri Nov 13 10:59:48 2020
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Fri, 13 Nov 2020 18:59:48 +0900
Subject: [R] find local max in moving window
Message-ID: <CAHXS41yGAVSowy5dMSJ68doPZ5Ha-jnCkd-PB8D1ty1ZBgeGcA@mail.gmail.com>

Dear r list,

I try to locate any local max value and location of data that follow 7
moving window condition, meaning that this data is largest and
centered in 7 values to the left and 7 values to the right. I can
solve it by using for and if function, like below:

dput(nordn)
c(`1` = 36.3167318892351, `2` = 13.6970407938013, `3` = 24.8984180253768,
`4` = -17.6647224450612, `5` = -7.57647505851449, `6` = -25.2496137259847,
`7` = -2.01332893598408, `8` = -7.69519958042397, `9` = -8.26353826728723,
`10` = -0.711578256473814, `11` = -9.49356104351281, `12` = -2.85486263863268,
`13` = 3.34926923529002, `14` = -31.4961884481779, `15` = -26.1167714774709,
`16` = -42.6411928687283, `17` = -38.0270384442816, `18` = -11.131459061204,
`19` = -23.622369248939, `20` = -3.64517202744244, `21` = 29.9049425605881,
`22` = 32.8660637407913, `23` = 37.5996245139886, `24` = 40.0028071315676,
`25` = 42.1488678067843, `26` = 29.898734204143, `27` = 31.5737226769497,
`28` = 17.1072348768252, `29` = 18.3678580553113, `30` = 2.99488592118706,
`31` = 17.5268614959386, `32` = 4.63931611503325, `33` = 0.780891049248694,
`34` = 1.2451803667649, `35` = -17.4138837461862, `36` = -17.1764836997295,
`37` = -18.9385526336078, `38` = -18.8785134814426, `39` = -18.8892579027502,
`40` = -17.05939841442, `41` = -17.1773872762212, `42` = -13.9956678436841,
`43` = -25.1754328292478, `44` = -14.3751251170127, `45` = -5.72211699349243,
`46` = -5.92331095941663, `47` = 5.70799013331376, `48` = 5.53987608486618,
`49` = 9.93527336363547, `50` = 9.83337030810877, `51` = 9.77591432958593,
`52` = 20.4486541160032, `53` = 20.5004918014168, `54` = 17.2771628653508,
`55` = 14.4829910263769, `56` = 17.7218103830368, `57` = 11.5422494691249,
`58` = 11.9634243026261, `59` = 6.45278534199771, `60` = 7.04912282719943,
`61` = -9.36267510164784, `62` = -8.58224224917278, `63` = -7.70790082260233,
`64` = -23.4156448928377, `65` = -22.3528607985815, `66` = -20.6638955663105,
`67` = -22.8623707541409, `68` = -18.0788043293803, `69` = -21.1362290377644,
`70` = -19.6291679260569, `71` = -18.4864526754101, `72` = -16.8268389833748,
`73` = -1.86517468137026e-13, `74` = -1.86517468137026e-13, `75` =
-1.86517468137026e-13,
`76` = -1.86517468137026e-13, `77` = -1.86517468137026e-13, `78` =
-1.86517468137026e-13,
`79` = -1.86517468137026e-13, `80` = -1.86517468137026e-13, `81` =
-1.86517468137026e-13,
`82` = -1.86517468137026e-13, `83` = -1.86517468137026e-13, `84` =
-1.86517468137026e-13,
`85` = -1.86517468137026e-13, `86` = -1.86517468137026e-13, `87` =
-1.86517468137026e-13,
`88` = 119.769379215677, `89` = 121.143950270482, `90` = -3.3158245341025,
`91` = -2.27565861892447, `92` = -4.73724890799339, `93` = -1.99736436960567,
`94` = -3.75331767972433, `95` = -5.95256351982827, `96` = -6.15867775456779,
`97` = -10.6570276388287, `98` = -11.5475819732368, `99` = -12.8244899190047,
`100` = -7.67798939908287, `101` = -9.82140578284223, `102` = -9.59888007628085,
`103` = -12.7414099822392, `104` = -22.3056908542011, `105` = -12.0279597037476,
`106` = -31.499265969641, `107` = -1.86517468137026e-13, `108` =
-1.86517468137026e-13,
`109` = -1.86517468137026e-13, `110` = -1.86517468137026e-13,
`111` = -1.86517468137026e-13, `112` = -1.86517468137026e-13,
`113` = -1.86517468137026e-13, `114` = -1.86517468137026e-13,
`115` = -1.86517468137026e-13, `116` = -1.86517468137026e-13,
`117` = 32.862745948818, `118` = -1.86517468137026e-13)


position<-matrix(NA,118,2)
for (i in 7:(length(nordn)-7)){
  if (nordn[i]>nordn[i+1]&&
      nordn[i]>nordn[i+2]&&
      nordn[i]>nordn[i+3]&&
      nordn[i]>nordn[i+4]&&
      nordn[i]>nordn[i+5]&&
      nordn[i]>nordn[i+6]&&
      nordn[i]>nordn[i+7]&&
      nordn[i]>nordn[i-7]&&
      nordn[i]>nordn[i-6]&&
      nordn[i]>nordn[i-5]&&
      nordn[i]>nordn[i-4]&&
      nordn[i]>nordn[i-3]&&
      nordn[i]>nordn[i-2]&&
      nordn[i]>nordn[i-1]){
  position[i,1]<-nordn[i]
  position[i,2]<-i
    }
  }

Is there any straight way or lead or function should I check? And can
I just get the value and the position without storing NA value? Thank
you.

Ani


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Nov 13 11:28:55 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 13 Nov 2020 10:28:55 +0000
Subject: [R] find local max in moving window
In-Reply-To: <CAHXS41yGAVSowy5dMSJ68doPZ5Ha-jnCkd-PB8D1ty1ZBgeGcA@mail.gmail.com>
References: <CAHXS41yGAVSowy5dMSJ68doPZ5Ha-jnCkd-PB8D1ty1ZBgeGcA@mail.gmail.com>
Message-ID: <a3f245d1-219f-c405-ac4a-64502dd4e869@sapo.pt>

Hello,

The best option is package zoo, function(s) rollapply.


p <- zoo::rollapply(nordn, width = 15, FUN = max, fill = c(NA, 0, NA))


These are meant as checks, see the differences between the one-liner 
above and your result.

dim(position)
length(p)

w <- which(position[, 1] == p)
position[w, ]



Hope this helps,

Rui Barradas


?s 09:59 de 13/11/20, ani jaya escreveu:
> Dear r list,
> 
> I try to locate any local max value and location of data that follow 7
> moving window condition, meaning that this data is largest and
> centered in 7 values to the left and 7 values to the right. I can
> solve it by using for and if function, like below:
> 
> dput(nordn)
> c(`1` = 36.3167318892351, `2` = 13.6970407938013, `3` = 24.8984180253768,
> `4` = -17.6647224450612, `5` = -7.57647505851449, `6` = -25.2496137259847,
> `7` = -2.01332893598408, `8` = -7.69519958042397, `9` = -8.26353826728723,
> `10` = -0.711578256473814, `11` = -9.49356104351281, `12` = -2.85486263863268,
> `13` = 3.34926923529002, `14` = -31.4961884481779, `15` = -26.1167714774709,
> `16` = -42.6411928687283, `17` = -38.0270384442816, `18` = -11.131459061204,
> `19` = -23.622369248939, `20` = -3.64517202744244, `21` = 29.9049425605881,
> `22` = 32.8660637407913, `23` = 37.5996245139886, `24` = 40.0028071315676,
> `25` = 42.1488678067843, `26` = 29.898734204143, `27` = 31.5737226769497,
> `28` = 17.1072348768252, `29` = 18.3678580553113, `30` = 2.99488592118706,
> `31` = 17.5268614959386, `32` = 4.63931611503325, `33` = 0.780891049248694,
> `34` = 1.2451803667649, `35` = -17.4138837461862, `36` = -17.1764836997295,
> `37` = -18.9385526336078, `38` = -18.8785134814426, `39` = -18.8892579027502,
> `40` = -17.05939841442, `41` = -17.1773872762212, `42` = -13.9956678436841,
> `43` = -25.1754328292478, `44` = -14.3751251170127, `45` = -5.72211699349243,
> `46` = -5.92331095941663, `47` = 5.70799013331376, `48` = 5.53987608486618,
> `49` = 9.93527336363547, `50` = 9.83337030810877, `51` = 9.77591432958593,
> `52` = 20.4486541160032, `53` = 20.5004918014168, `54` = 17.2771628653508,
> `55` = 14.4829910263769, `56` = 17.7218103830368, `57` = 11.5422494691249,
> `58` = 11.9634243026261, `59` = 6.45278534199771, `60` = 7.04912282719943,
> `61` = -9.36267510164784, `62` = -8.58224224917278, `63` = -7.70790082260233,
> `64` = -23.4156448928377, `65` = -22.3528607985815, `66` = -20.6638955663105,
> `67` = -22.8623707541409, `68` = -18.0788043293803, `69` = -21.1362290377644,
> `70` = -19.6291679260569, `71` = -18.4864526754101, `72` = -16.8268389833748,
> `73` = -1.86517468137026e-13, `74` = -1.86517468137026e-13, `75` =
> -1.86517468137026e-13,
> `76` = -1.86517468137026e-13, `77` = -1.86517468137026e-13, `78` =
> -1.86517468137026e-13,
> `79` = -1.86517468137026e-13, `80` = -1.86517468137026e-13, `81` =
> -1.86517468137026e-13,
> `82` = -1.86517468137026e-13, `83` = -1.86517468137026e-13, `84` =
> -1.86517468137026e-13,
> `85` = -1.86517468137026e-13, `86` = -1.86517468137026e-13, `87` =
> -1.86517468137026e-13,
> `88` = 119.769379215677, `89` = 121.143950270482, `90` = -3.3158245341025,
> `91` = -2.27565861892447, `92` = -4.73724890799339, `93` = -1.99736436960567,
> `94` = -3.75331767972433, `95` = -5.95256351982827, `96` = -6.15867775456779,
> `97` = -10.6570276388287, `98` = -11.5475819732368, `99` = -12.8244899190047,
> `100` = -7.67798939908287, `101` = -9.82140578284223, `102` = -9.59888007628085,
> `103` = -12.7414099822392, `104` = -22.3056908542011, `105` = -12.0279597037476,
> `106` = -31.499265969641, `107` = -1.86517468137026e-13, `108` =
> -1.86517468137026e-13,
> `109` = -1.86517468137026e-13, `110` = -1.86517468137026e-13,
> `111` = -1.86517468137026e-13, `112` = -1.86517468137026e-13,
> `113` = -1.86517468137026e-13, `114` = -1.86517468137026e-13,
> `115` = -1.86517468137026e-13, `116` = -1.86517468137026e-13,
> `117` = 32.862745948818, `118` = -1.86517468137026e-13)
> 
> 
> position<-matrix(NA,118,2)
> for (i in 7:(length(nordn)-7)){
>    if (nordn[i]>nordn[i+1]&&
>        nordn[i]>nordn[i+2]&&
>        nordn[i]>nordn[i+3]&&
>        nordn[i]>nordn[i+4]&&
>        nordn[i]>nordn[i+5]&&
>        nordn[i]>nordn[i+6]&&
>        nordn[i]>nordn[i+7]&&
>        nordn[i]>nordn[i-7]&&
>        nordn[i]>nordn[i-6]&&
>        nordn[i]>nordn[i-5]&&
>        nordn[i]>nordn[i-4]&&
>        nordn[i]>nordn[i-3]&&
>        nordn[i]>nordn[i-2]&&
>        nordn[i]>nordn[i-1]){
>    position[i,1]<-nordn[i]
>    position[i,2]<-i
>      }
>    }
> 
> Is there any straight way or lead or function should I check? And can
> I just get the value and the position without storing NA value? Thank
> you.
> 
> Ani
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Fri Nov 13 23:04:20 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Fri, 13 Nov 2020 22:04:20 +0000 (UTC)
Subject: [R] "NaN" answer don't understand why
References: <1304056825.9448168.1605305060839.ref@mail.yahoo.com>
Message-ID: <1304056825.9448168.1605305060839@mail.yahoo.com>

Dear R-experts,

Here below my reproducible example. No error message but I can not get a result. I get "NaN" as a result. I don't understand what is going on. Many thanks for your precious help, as usual.


?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#
x<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
y<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)

library(robustgam)
true.family <- poisson()

#Robust GAM
fit=robustgam(x,y,sp=0,family=true.family,smooth.basis='ps',K=3)

#OLS
fit1 <- lm(y~x)

#Huber-M
library(robustbase)
library(MASS)
fit2=rlm(y~x)

#GAM
library(mgcv)
fit3=gam(y~s(x))

# MSE of OLS linear model
mean(residuals(fit1)^2)

# MSE of Huber-M linear model
mean(residuals(fit2)^2)

# MSE of GAM
mean(residuals(fit3)^2)

# MSE of robust GAM
mean(residuals(fit)^2)
?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#
?


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sat Nov 14 00:16:58 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 13 Nov 2020 15:16:58 -0800
Subject: [R] "NaN" answer don't understand why
In-Reply-To: <1304056825.9448168.1605305060839@mail.yahoo.com>
References: <1304056825.9448168.1605305060839.ref@mail.yahoo.com>
 <1304056825.9448168.1605305060839@mail.yahoo.com>
Message-ID: <CAHqSRuSquu2gy582AxVArTAsn+onH6tSgKocY98zRBKTr0DRUQ@mail.gmail.com>

fit <- robustgam::robustgam(...) produces a list, with no class attached,
so residuals(fit) invokes the default method for residuals(), which
essentially returns the 'residuals' component of 'fit'.  There is no such
component so it returns NULL, an object of length zero.  The mean of a
length-zero object is NaN.

It would make sense for mean(NULL) or sum(NULL) to give an error since they
are only meant to work on numbers.  However this would probably break some
existing code, since there are various functions that return NULL instead
of numeric(0).

-Bill

On Fri, Nov 13, 2020 at 2:05 PM varin sacha via R-help <r-help at r-project.org>
wrote:

> Dear R-experts,
>
> Here below my reproducible example. No error message but I can not get a
> result. I get "NaN" as a result. I don't understand what is going on. Many
> thanks for your precious help, as usual.
>
>
>  # # # # # # # # # # # # # # # # # # # # # # # # #
>
> x<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
>
> y<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)
>
> library(robustgam)
> true.family <- poisson()
>
> #Robust GAM
> fit=robustgam(x,y,sp=0,family=true.family,smooth.basis='ps',K=3)
>
> #OLS
> fit1 <- lm(y~x)
>
> #Huber-M
> library(robustbase)
> library(MASS)
> fit2=rlm(y~x)
>
> #GAM
> library(mgcv)
> fit3=gam(y~s(x))
>
> # MSE of OLS linear model
> mean(residuals(fit1)^2)
>
> # MSE of Huber-M linear model
> mean(residuals(fit2)^2)
>
> # MSE of GAM
> mean(residuals(fit3)^2)
>
> # MSE of robust GAM
> mean(residuals(fit)^2)
>  # # # # # # # # # # # # # # # # # # # # # # # # #
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From you@r|@|@nou@ @end|ng |rom gm@||@com  Sat Nov 14 02:44:46 2020
From: you@r|@|@nou@ @end|ng |rom gm@||@com (Yousri Fanous)
Date: Fri, 13 Nov 2020 20:44:46 -0500
Subject: [R] long integer handling
Message-ID: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>

I want to calculate 2^64-1 which is
18446744073709551615

I set the following options to prevent scientific notation
options("scipen"=100, "digits"=4)
> x<-2^64 -1
> x
[1] 18446744073709551616

This is not correct. There seem to be still some approximation happening.
How can I get the correct result?

Yousri
IBM Canada ltd
Software developer

	[[alternative HTML version deleted]]


From jrg @end|ng |rom |oe@|@u@  Sat Nov 14 02:54:33 2020
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Fri, 13 Nov 2020 20:54:33 -0500
Subject: [R] long integer handling
In-Reply-To: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
References: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
Message-ID: <5704f5f8-13ba-21da-ccf5-f28c5e313115@loesl.us>

The largest consecutive integer that can be represented in double
precision is 2^53.

You'll have to move past double precision.

---JRG



On 2020-11-13 20:44, Yousri Fanous wrote:
> I want to calculate 2^64-1 which is
> 18446744073709551615
> 
> I set the following options to prevent scientific notation
> options("scipen"=100, "digits"=4)
>> x<-2^64 -1
>> x
> [1] 18446744073709551616
> 
> This is not correct. There seem to be still some approximation happening.
> How can I get the correct result?
> 
> Yousri
> IBM Canada ltd
> Software developer
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh @end|ng |rom temp|e@edu  Sat Nov 14 03:01:56 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 13 Nov 2020 21:01:56 -0500
Subject: [R] [External]  long integer handling
In-Reply-To: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
References: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
Message-ID: <CAGx1TMDLLprQ-JeZzcZKcYiqHBRWF33HhqKh5jm+syRSL05PpA@mail.gmail.com>

You need the Rmpfr package.  Your calculation of 2^64 is an ordinary
double precision number with 53 bits of precision.

> library(Rmpfr)
Loading required package: gmp

Attaching package: ?gmp?

The following objects are masked from ?package:base?:

    %*%, apply, crossprod, matrix, tcrossprod

C code of R package 'Rmpfr': GMP using 64 bits per limb


Attaching package: ?Rmpfr?

The following object is masked from ?package:gmp?:

    outer

The following objects are masked from ?package:stats?:

    dbinom, dgamma, dnorm, dpois, pnorm

The following objects are masked from ?package:base?:

    cbind, pmax, pmin, rbind

> class(2)
[1] "numeric"
> class(2^32)
[1] "numeric"
> class(2^64)
[1] "numeric"
> Two <- mpfr(2, precBits=64)
> Two^64
1 'mpfr' number of precision  64   bits
[1] 18446744073709551616
> class(Two^64)
[1] "mpfr"
attr(,"package")
[1] "Rmpfr"
> Two^64 - 1
1 'mpfr' number of precision  64   bits
[1] 18446744073709551615
> getPrec(Two)
[1] 64
> getPrec(2.)
[1] 53
>

On Fri, Nov 13, 2020 at 8:45 PM Yousri Fanous <yousri.fanous at gmail.com> wrote:
>
> I want to calculate 2^64-1 which is
> 18446744073709551615
>
> I set the following options to prevent scientific notation
> options("scipen"=100, "digits"=4)
> > x<-2^64 -1
> > x
> [1] 18446744073709551616
>
> This is not correct. There seem to be still some approximation happening.
> How can I get the correct result?
>
> Yousri
> IBM Canada ltd
> Software developer
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Nov 14 03:59:49 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 14 Nov 2020 15:59:49 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
Message-ID: <20201114155949.70239ebc@rolf-Latitude-E7470>


On Thu, 12 Nov 2020 01:23:06 +0100
Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:

> Please watch this video if you wrongly believe that Benford's law
> easily can be applied to elections results.
> 
> https://youtu.be/etx0k1nLn78

Just watched this video and found it to be delightfully enlightening
and entertaining.  (Thank you Martin for posting the link.)

However a question springs to mind:  why is it the case that Trump's
vote counts in Chicago *do* seem to follow Benford's law (at least
roughly) when, as is apparently to be expected, Biden's don't?

Has anyone any explanation for this?  Any ideas?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov 14 04:02:19 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 13 Nov 2020 19:02:19 -0800
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <20201114155949.70239ebc@rolf-Latitude-E7470>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
 <20201114155949.70239ebc@rolf-Latitude-E7470>
Message-ID: <41AF906C-E297-4C78-90C6-72A624322AB9@dcn.davis.ca.us>

It was explained in the video... his counts were so small that they spanned the 1-9 and 10-99 ranges.

On November 13, 2020 6:59:49 PM PST, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>On Thu, 12 Nov 2020 01:23:06 +0100
>Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:
>
>> Please watch this video if you wrongly believe that Benford's law
>> easily can be applied to elections results.
>> 
>> https://youtu.be/etx0k1nLn78
>
>Just watched this video and found it to be delightfully enlightening
>and entertaining.  (Thank you Martin for posting the link.)
>
>However a question springs to mind:  why is it the case that Trump's
>vote counts in Chicago *do* seem to follow Benford's law (at least
>roughly) when, as is apparently to be expected, Biden's don't?
>
>Has anyone any explanation for this?  Any ideas?
>
>cheers,
>
>Rolf Turner

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Nov 14 06:50:30 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 14 Nov 2020 05:50:30 +0000
Subject: [R] long integer handling
In-Reply-To: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
References: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
Message-ID: <99ecf2e4-93f1-b498-b1a4-ab10d9093f45@sapo.pt>

Hello,

You can compute the exact result with package Rmpfr.
See ?mpfr and [1].


library(Rmpfr)

two <- mpfr(2, precBits = 64)
two^64 - 1
#1 'mpfr' number of precision  64   bits
#[1] 18446744073709551615



[1] https://www.mpfr.org/

Hope this helps,

Rui Barradas

?s 01:44 de 14/11/20, Yousri Fanous escreveu:
> I want to calculate 2^64-1 which is
> 18446744073709551615
> 
> I set the following options to prevent scientific notation
> options("scipen"=100, "digits"=4)
>> x<-2^64 -1
>> x
> [1] 18446744073709551616
> 
> This is not correct. There seem to be still some approximation happening.
> How can I get the correct result?
> 
> Yousri
> IBM Canada ltd
> Software developer
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Nov 14 06:54:57 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 14 Nov 2020 05:54:57 +0000
Subject: [R] long integer handling
In-Reply-To: <99ecf2e4-93f1-b498-b1a4-ab10d9093f45@sapo.pt>
References: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
 <99ecf2e4-93f1-b498-b1a4-ab10d9093f45@sapo.pt>
Message-ID: <92fb0088-1e84-bfd8-c321-1a65b6280270@sapo.pt>

Hello,

I forgot to suggest package gmp. See the second example in

?gmp::bigz

Hope this helps,

Rui Barradas

?s 05:50 de 14/11/20, Rui Barradas escreveu:
> Hello,
> 
> You can compute the exact result with package Rmpfr.
> See ?mpfr and [1].
> 
> 
> library(Rmpfr)
> 
> two <- mpfr(2, precBits = 64)
> two^64 - 1
> #1 'mpfr' number of precision? 64?? bits
> #[1] 18446744073709551615
> 
> 
> 
> [1] https://www.mpfr.org/
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 01:44 de 14/11/20, Yousri Fanous escreveu:
>> I want to calculate 2^64-1 which is
>> 18446744073709551615
>>
>> I set the following options to prevent scientific notation
>> options("scipen"=100, "digits"=4)
>>> x<-2^64 -1
>>> x
>> [1] 18446744073709551616
>>
>> This is not correct. There seem to be still some approximation happening.
>> How can I get the correct result?
>>
>> Yousri
>> IBM Canada ltd
>> Software developer
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From you@r|@|@nou@ @end|ng |rom gm@||@com  Sat Nov 14 18:41:48 2020
From: you@r|@|@nou@ @end|ng |rom gm@||@com (Yousri Fanous)
Date: Sat, 14 Nov 2020 12:41:48 -0500
Subject: [R] long integer handling
In-Reply-To: <92fb0088-1e84-bfd8-c321-1a65b6280270@sapo.pt>
References: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
 <99ecf2e4-93f1-b498-b1a4-ab10d9093f45@sapo.pt>
 <92fb0088-1e84-bfd8-c321-1a65b6280270@sapo.pt>
Message-ID: <CADsEwSc08sHKdfvxaCtQXXd1LzP+iSZ3P+N5mtLSBn3oraiP-w@mail.gmail.com>

Thank you!

On Sat, Nov 14, 2020 at 12:54 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I forgot to suggest package gmp. See the second example in
>
> ?gmp::bigz
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 05:50 de 14/11/20, Rui Barradas escreveu:
> > Hello,
> >
> > You can compute the exact result with package Rmpfr.
> > See ?mpfr and [1].
> >
> >
> > library(Rmpfr)
> >
> > two <- mpfr(2, precBits = 64)
> > two^64 - 1
> > #1 'mpfr' number of precision  64   bits
> > #[1] 18446744073709551615
> >
> >
> >
> > [1] https://www.mpfr.org/
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 01:44 de 14/11/20, Yousri Fanous escreveu:
> >> I want to calculate 2^64-1 which is
> >> 18446744073709551615
> >>
> >> I set the following options to prevent scientific notation
> >> options("scipen"=100, "digits"=4)
> >>> x<-2^64 -1
> >>> x
> >> [1] 18446744073709551616
> >>
> >> This is not correct. There seem to be still some approximation
> happening.
> >> How can I get the correct result?
> >>
> >> Yousri
> >> IBM Canada ltd
> >> Software developer
> >>
> >>     [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Nov 14 20:50:29 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 15 Nov 2020 08:50:29 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <41AF906C-E297-4C78-90C6-72A624322AB9@dcn.davis.ca.us>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
 <20201114155949.70239ebc@rolf-Latitude-E7470>
 <41AF906C-E297-4C78-90C6-72A624322AB9@dcn.davis.ca.us>
Message-ID: <20201115085029.0e98021a@rolf-Latitude-E7470>


On Fri, 13 Nov 2020 19:02:19 -0800
Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> It was explained in the video... his counts were so small that they
> spanned the 1-9 and 10-99 ranges.

Sorry, missed that.  I'll have to watch the video again.

Thanks.

cheers,

Rolf

> 
> On November 13, 2020 6:59:49 PM PST, Rolf Turner
> <r.turner at auckland.ac.nz> wrote:
> >
> >On Thu, 12 Nov 2020 01:23:06 +0100
> >Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:
> >
> >> Please watch this video if you wrongly believe that Benford's law
> >> easily can be applied to elections results.
> >> 
> >> https://youtu.be/etx0k1nLn78
> >
> >Just watched this video and found it to be delightfully enlightening
> >and entertaining.  (Thank you Martin for posting the link.)
> >
> >However a question springs to mind:  why is it the case that Trump's
> >vote counts in Chicago *do* seem to follow Benford's law (at least
> >roughly) when, as is apparently to be expected, Biden's don't?
> >
> >Has anyone any explanation for this?  Any ideas?


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sat Nov 14 21:44:38 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sat, 14 Nov 2020 20:44:38 +0000 (UTC)
Subject: [R] "NaN" answer don't understand why
In-Reply-To: <CAHqSRuSquu2gy582AxVArTAsn+onH6tSgKocY98zRBKTr0DRUQ@mail.gmail.com>
References: <1304056825.9448168.1605305060839.ref@mail.yahoo.com>
 <1304056825.9448168.1605305060839@mail.yahoo.com>
 <CAHqSRuSquu2gy582AxVArTAsn+onH6tSgKocY98zRBKTr0DRUQ@mail.gmail.com>
Message-ID: <1016395739.9790926.1605386678736@mail.yahoo.com>

Dear Bill,

Many thanks for your response. I got it.

Best,







Le samedi 14 novembre 2020 ? 00:17:10 UTC+1, Bill Dunlap <williamwdunlap at gmail.com> a ?crit : 





fit <- robustgam::robustgam(...) produces a list, with no class attached, so residuals(fit) invokes the default method for residuals(), which essentially returns the 'residuals' component of 'fit'.? There is no such component so it returns NULL, an object of length zero.? The mean of a length-zero object is NaN.

It would make sense for mean(NULL) or sum(NULL) to give an error since they are only meant to work on numbers.? However this would probably break some existing code, since there are various functions that return NULL instead of numeric(0).

-Bill

On Fri, Nov 13, 2020 at 2:05 PM varin sacha via R-help <r-help at r-project.org> wrote:
> Dear R-experts,
> 
> Here below my reproducible example. No error message but I can not get a result. I get "NaN" as a result. I don't understand what is going on. Many thanks for your precious help, as usual.
> 
> 
> ?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#
> x<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
> y<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)
> 
> library(robustgam)
> true.family <- poisson()
> 
> #Robust GAM
> fit=robustgam(x,y,sp=0,family=true.family,smooth.basis='ps',K=3)
> 
> #OLS
> fit1 <- lm(y~x)
> 
> #Huber-M
> library(robustbase)
> library(MASS)
> fit2=rlm(y~x)
> 
> #GAM
> library(mgcv)
> fit3=gam(y~s(x))
> 
> # MSE of OLS linear model
> mean(residuals(fit1)^2)
> 
> # MSE of Huber-M linear model
> mean(residuals(fit2)^2)
> 
> # MSE of GAM
> mean(residuals(fit3)^2)
> 
> # MSE of robust GAM
> mean(residuals(fit)^2)
> ?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#
> ?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From @purd|e@@ @end|ng |rom gm@||@com  Sun Nov 15 09:53:51 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 15 Nov 2020 21:53:51 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <20201115085029.0e98021a@rolf-Latitude-E7470>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
 <20201114155949.70239ebc@rolf-Latitude-E7470>
 <41AF906C-E297-4C78-90C6-72A624322AB9@dcn.davis.ca.us>
 <20201115085029.0e98021a@rolf-Latitude-E7470>
Message-ID: <CAB8pepyftyi+z95+sC09LNGFb5xek1V_ewR30w4pWYBEr8mVfw@mail.gmail.com>

I've updated the dataset.
(Which now includes turnout and population estimates).

Also, I've found some anomalous features in the data.
(Namely, more "straight lines" than what I would intuitively expect).

The dataset/description are on my website.
(Links at bottom).

    ####################################
    #set PATH as required
    ####################################
    data <- read.csv (PATH, header=TRUE)
    head (data, 3)

I took a subset, where the Dem/Rep margins have reversed between the
2016 and 2020 elections.

    rev.results <- (sign (data$RMARGIN_2016) + sign (data$RMARGIN_2020) == 0)
    data2 <- data [data$SUBSV1 != 1 & rev.results,]
    sc <- paste (data2$STATE, data2$EQCOUNTY, sep=": ")
    head (data2, 3)

Then created two plots, attached.
(1) Republican margin vs voter turnout.
(2) Republican margin vs log (number of votes).

In both cases, there are near-straight lines.
Re-iterating, more than what I would intuitively expect.

    library (probhat)

    plot1 <- function ()
    {   x <- with (data2, cbind (x1=RMARGIN_2020, x2=TURNOUT_2020) )
        plot (pdfmv.cks (x, smoothness = c (1, 1) ), contours=FALSE,
hcv=TRUE, n=80,
            xlim = c (-2.5, 10), ylim = c (40, 52.5),
            main="US Counties\n(with reversed results, over 2016/2020
elections)",
            xlab="Republican Margin, 2020", ylab="Voter Turnout, 2020")
        points (x, pch=16, col="#000000")
        abline (v=0, h=50, lty=2)

        I1 <- (sc == "Colorado: Alamosa" | sc == "Georgia: Burke" | sc
== "Ohio: Lorain")
        I2 <- (sc == "South Carolina: Clarendon" | sc == "Ohio: Mahoning")
        sc [! (I1 | I2)] <- ""

        k <- lm (TURNOUT_2020 ~ RMARGIN_2020, data = data2 [I1,])$coef
        abline (a = k [1], b = k [2])

        points (x [I1 | I2,], col="white")
        text (x [,1] + 0.2, x [,2], sc, adj = c (0, 0.5) )
    }

    plot2 <- function ()
    {   x <- with (data2, cbind (x1=RMARGIN_2020, x2 = log (NVOTES_2020) ) )
        plot (pdfmv.cks (x, smoothness = c (1, 1) ), contours=FALSE,
hcv=TRUE, n=80,
            xlim = c (-2.5, 35),
            main="US Counties\n(with reversed results, over 2016/2020
elections)",
            xlab="Republican Margin, 2020", ylab="log (Number of Votes), 2020")
        points (x, pch=16, col="#000000")
        abline (v=0, lty=2)

        sc <- paste (data2$STATE, data2$EQCOUNTY, sep=": ")
        I1 <- (sc == "Texas: Kenedy")
        I2 <- (sc == "Texas: Reeves" | sc == "New York: Rockland")

        k <- lm (log (NVOTES_2020) ~ RMARGIN_2020, data = data2 [I1 | I2,])$coef
        abline (a = k [1], b = k [2])

        points (x [I1 | I2,], col="white")
        text (x [I1, 1] - 0.5, x [I1, 2], sc [I1], adj = c (1, 0.5) )
        text (x [I2, 1] + 0.5, x [I2, 2], sc [I2], adj = c (0, 0.5) )
    }

    plot1 ()
    plot2 ()

https://sites.google.com/site/spurdlea/us_election_2020
https://sites.google.com/site/spurdlea/exts/election_results_2.txt


On Sun, Nov 15, 2020 at 8:51 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> On Fri, 13 Nov 2020 19:02:19 -0800
> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> > It was explained in the video... his counts were so small that they
> > spanned the 1-9 and 10-99 ranges.
>
> Sorry, missed that.  I'll have to watch the video again.
>
> Thanks.
>
> cheers,
>
> Rolf

-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot1.png
Type: image/png
Size: 24878 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201115/55684c86/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot2.png
Type: image/png
Size: 22769 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201115/55684c86/attachment-0001.png>

From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Mon Nov 16 07:14:41 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Mon, 16 Nov 2020 01:14:41 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <20201114155949.70239ebc@rolf-Latitude-E7470>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
 <20201114155949.70239ebc@rolf-Latitude-E7470>
Message-ID: <be0f1a5a-0ec5-e4b5-cf75-7b3fa7729ac5@molbio.mgh.harvard.edu>

 ? I really like this guy's video as well. (He also has another nice 
video critiquing a statistical analysis of vote results from Kent 
county, Michigan that was presented by a Massachusetts Senate candidate, 
who has some impressive academic credentials. )

 ? And continuing in this same vein of the complexities of statistical 
analysis by intelligent people here is a video by Mark Nigrini using 
Benfords analysis on Maricopa County vote results.

https://www.youtube.com/watch?v=FrJui5d7BrI&ab_channel=MarkNigrini

 ??? If you search for Mark Nigrini on Amazon you will see that he has 
written a major text on Forensic Analysis, specifically forensic 
accounting investigations, that is now in its second edition as well as 
an additional two books on analysis with Benford's Law for accounting, 
auditing, and fraud detection (He plugs the text in the last part of the 
video). All four books have 4-5 star reviews with 2-48 reviewers. From 
the tiny amount of reading I have done on Benford's Law, it seems that 
Nigirini is a leading figure in the use of Benford's Law. In the video 
he shows that voting results for both Trump and Biden from Maricopa 
county AZ both agree with Benfords Law. However, he uses the last digit 
and not the first. A word of caution before you click on that link: he 
uses Excel !

Matthew

On 11/13/20 9:59 PM, Rolf Turner wrote:
>          External Email - Use Caution
>
> On Thu, 12 Nov 2020 01:23:06 +0100
> Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:
>
>> Please watch this video if you wrongly believe that Benford's law
>> easily can be applied to elections results.
>>
>> https://secure-web.cisco.com/1nXQfJ050onRLM1UOwgj-z0o0L3Hj6hd0rCZ7zMpqnBfCDuZcCkxAJZnj7o7Z8ZAUVxYBTf5FBjL2Y-Ca8T_ecO-N54S0KhgRtLoVDgxiEKX9N7eqzuxO0k0HloVcc2lXrXFNAiansI8zHgyUS4gTdKtRsJCHttTn5bwmV8J7d0_6iqrjee_toWiGnTsDSFaKVkev7tKKV3ERLFwzTPtNf2Rm99EBbdA75FvsXfBk3WXuVop4GZbN3ZGkd2SssFJaw9AgTHmM1k3C2bnB_STO_w/https%3A%2F%2Fyoutu.be%2Fetx0k1nLn78
> Just watched this video and found it to be delightfully enlightening
> and entertaining.  (Thank you Martin for posting the link.)
>
> However a question springs to mind:  why is it the case that Trump's
> vote counts in Chicago *do* seem to follow Benford's law (at least
> roughly) when, as is apparently to be expected, Biden's don't?
>
> Has anyone any explanation for this?  Any ideas?
>
> cheers,
>
> Rolf Turner
>


From @b|@yeng@|@b@ @end|ng |rom gm@||@com  Mon Nov 16 13:45:19 2020
From: @b|@yeng@|@b@ @end|ng |rom gm@||@com (Ablaye Ngalaba)
Date: Mon, 16 Nov 2020 13:45:19 +0100
Subject: [R] assistance programming R
Message-ID: <CAOkWQv1Kgt5Lnjt4Teg4Ra4xvo338x8oaD-zfHq=QCA0=wD2pw@mail.gmail.com>

Hello,
please, I need help in programming R.
Here is my file

-------------- next part --------------
A non-text attachment was scrubbed...
Name: help code.pdf
Type: application/pdf
Size: 79689 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201116/9a808e24/attachment.pdf>

From @zwj|08 @end|ng |rom gm@||@com  Mon Nov 16 14:03:02 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Mon, 16 Nov 2020 21:03:02 +0800
Subject: [R] assistance programming R
In-Reply-To: <CAOkWQv1Kgt5Lnjt4Teg4Ra4xvo338x8oaD-zfHq=QCA0=wD2pw@mail.gmail.com>
References: <CAOkWQv1Kgt5Lnjt4Teg4Ra4xvo338x8oaD-zfHq=QCA0=wD2pw@mail.gmail.com>
Message-ID: <CAGiFhPOWAeTxiEC_+WLKJU7AUwzgNwupTGbBKYZxVMX5m9q3MA@mail.gmail.com>

HI Ablaye,

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
<http://www.r-project.org/posting-guide.html> before you post your question.

This is not the place for posting your homework. Even if it is, your
homework question is really hard to read.

Cheers,
Jiefei

On Mon, Nov 16, 2020 at 8:46 PM Ablaye Ngalaba <ablayengalaba at gmail.com>
wrote:

> Hello,
> please, I need help in programming R.
> Here is my file
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Nov 16 18:30:13 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Nov 2020 17:30:13 +0000
Subject: [R] assistance programming R
In-Reply-To: <CAOkWQv1Kgt5Lnjt4Teg4Ra4xvo338x8oaD-zfHq=QCA0=wD2pw@mail.gmail.com>
References: <CAOkWQv1Kgt5Lnjt4Teg4Ra4xvo338x8oaD-zfHq=QCA0=wD2pw@mail.gmail.com>
Message-ID: <20e620d1-1dc0-81a3-8284-f13c865e71a3@sapo.pt>

Hello,

You should read an introductory text on R before posting questions. 
Start with file R-intro.pdf that comes your installation of R. There are 
also several books on CRAN and other on-line sites. Cost free.

As for the problem,


n_l <- function(y, q, na.rm = FALSE){
   sum(y %in% seq_len(q), na.rm = na.rm)
}

# Tests
set.seed(2020)
x1 <- rpois(10, lambda = 4)
x2 <- rpois(100, lambda = 10)

n_l(x1, q = 4)
n_l(x2, q = 21)


Hope this helps,

Rui Barradas


?s 12:45 de 16/11/20, Ablaye Ngalaba escreveu:
> Hello,
> please, I need help in programming R.
> Here is my file
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From |@|neyg@||enberg @end|ng |rom gm@||@com  Mon Nov 16 03:35:41 2020
From: |@|neyg@||enberg @end|ng |rom gm@||@com (Lainey Gallenberg)
Date: Sun, 15 Nov 2020 17:35:41 -0900
Subject: [R] Inappropriate color name
Message-ID: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>

Hello,

I'm hoping someone on here knows the appropriate place/contact for me to
lodge a complaint about a color name in the "colors" function. I was
shocked to see there are four named color options that include the term
"indianred." Surely these colors can be changed to something less
offensive- my suggestion is "blush." How can I find out who to contact
about making this happen?

Thank you in advance for any suggestions.

Sincerely,
Elaine Gallenberg

	[[alternative HTML version deleted]]


From b@@|||e @end|ng |rom u||@edu  Mon Nov 16 03:09:02 2020
From: b@@|||e @end|ng |rom u||@edu (Mathieu Basille)
Date: Sun, 15 Nov 2020 21:09:02 -0500
Subject: [R] [R-pkgs] Package 'sftrack': Modern classes for tracking and
 movement data
Message-ID: <892cc4c8-fa44-2d8d-db3a-a9f6818b2d9f@ufl.edu>

Dear R users and developers,

The 'sftrack' package is finally on CRAN!

https://cran.r-project.org/package=sftrack

'sftrack' provides modern classes for tracking and movement data, relying
on 'sf' spatial infrastructure. Tracking data are made of tracks, i.e.
series of locations with at least 2-dimensional spatial coordinates (x,y),
a time index (t), and individual identification (id) of the object being
monitored; movement data are made of trajectories, i.e. the line
representation of the path, composed by steps (the straight-line segments
connecting successive locations). 'sftrack' is designed to handle movement
of both living organisms and inanimate objects. A dedicated website with
extensive vignettes and documentation can be found at:

https://mablab.org/sftrack/

The development and design of the 'sftrack' package follow three simple
principles:

* Minimal and focused: this is basically the Unix philosophy. Do a simple
thing, and do it well. The scope of the package is limited (see above),
with as few dependencies as possible;
* User-friendly: 'sftrack' is designed to be as easy to use as familiar R
structures like data.frames and 'sf' objects. 'sftrack' objects are tidy,
and follow the idea that rows are records (locations) and columns are
variable (following the semantics of tracking and movement data);
* Flexible and extensible: 'sftrack' is meant first for users to use on
their data, but also directly designed to address other developers? needs
for their own tracking packages. If you are a developer of a tracking
package, and you are interested in the classes provided by 'sftrack',
please do not hesitate to contact us (for instance at
https://github.com/mablab/sftrack/issues).

You can directly install the version available on CRAN
('install.packages("sftrack")'), but note that the development version
currently goes a step (!) forward by implementing a true representation of
time steps (t1?t2), which makes each step completely defined by itself
(x,y,t1?x,y,t2) and independent from other steps (each step can be handled
on its own). See the details of the implementation in the documentation of
the dev branch:

https://mablab.org/sftrack/dev/articles/sftrack6_time.html

Best,
Mathieu Basille, for the 'sftrack' team.


-- 

Mathieu Basille

basille at ufl.edu | https://mablab.org/
+1 954-577-6314 | University of Florida FLREC

  ? Le tout est de tout dire, et je manque de mots
  Et je manque de temps, et je manque d'audace. ?
  ? Paul ?luard

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m|h@e|@@e||enberger @end|ng |rom un||r@ch  Mon Nov 16 11:02:05 2020
From: m|h@e|@@e||enberger @end|ng |rom un||r@ch (ELLENBERGER Mihaela)
Date: Mon, 16 Nov 2020 10:02:05 +0000
Subject: [R] WG: Packegs for mathematics
In-Reply-To: <34d86951e8e743f3851059c81bd6087a@unifr.ch>
References: <34d86951e8e743f3851059c81bd6087a@unifr.ch>
Message-ID: <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>




________________________________
Von: ELLENBERGER Mihaela
Gesendet: Montag, 16. November 2020 10:24
An: CRAN-submissions at R-project.org
Betreff: Packegs for mathematics


Hello


I'm undergraduated student of Biomedical Sciences in Switzerland and learning how to work with R.

Currently I'm using R-Studio.


I would like to now, which packeges sholud I install please for mathematics ( analysis)?

My collegeues don't use all the same maths software ( some of them are using Excel, SPSS, Mathematica, etc.)


-Funktionen,Serien, Folgen,Grenzwerte, Stetigkeiten

-Integralrechnungen

-Differentialrechnungen

-Analysis multivariant


Could you sent me an advice please, because there are so many packeges in R.


Kind regards


Mihaela Ellenberger




	[[alternative HTML version deleted]]


From mm@|ten @end|ng |rom gm@||@com  Mon Nov 16 19:45:52 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Mon, 16 Nov 2020 13:45:52 -0500
Subject: [R] Inappropriate color name
In-Reply-To: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
Message-ID: <CANOgrHaZ6_sPFktZQQod0Rzcq-WMibBAEsmxUbZoh2_FHMNzPQ@mail.gmail.com>

According to Wikipedia -- https://en.wikipedia.org/wiki/Indian_red_(color)
-- "Indian red" refers to a pigment from India.

The Wikipedia page reports that Crayola were concerned about the mistaken
etymology so used the name "Chestnut"

On Mon, Nov 16, 2020 at 1:39 PM Lainey Gallenberg <
laineygallenberg at gmail.com> wrote:

> Hello,
>
> I'm hoping someone on here knows the appropriate place/contact for me to
> lodge a complaint about a color name in the "colors" function. I was
> shocked to see there are four named color options that include the term
> "indianred." Surely these colors can be changed to something less
> offensive- my suggestion is "blush." How can I find out who to contact
> about making this happen?
>
> Thank you in advance for any suggestions.
>
> Sincerely,
> Elaine Gallenberg
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From R@|ner @end|ng |rom krug@@de  Mon Nov 16 19:52:40 2020
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Mon, 16 Nov 2020 19:52:40 +0100
Subject: [R] Inappropriate color name
In-Reply-To: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
Message-ID: <72B7708C-420D-4F64-B271-BA38976E14E1@krugs.de>

Please see https://en.wikipedia.org/wiki/Indian_red_(color) <https://en.wikipedia.org/wiki/Indian_red_(color)> for where the name comes from. To cite:

"The name Indian red derives from the red laterite <https://en.wikipedia.org/wiki/Laterite> soil found in India <https://en.wikipedia.org/wiki/India>, which is composed of naturally occurring iron oxides <https://en.wikipedia.org/wiki/Iron_oxide>.[citation needed <https://en.wikipedia.org/wiki/Wikipedia:Citation_needed>] The first recorded use of Indian red as a color term in English <https://en.wikipedia.org/wiki/English_language> was in 1672.[3] <https://en.wikipedia.org/wiki/Indian_red_(color)#cite_note-3>?

So I do not see any offence in the name.

Cheers,

Rainer



> On 16 Nov 2020, at 03:35, Lainey Gallenberg <laineygallenberg at gmail.com> wrote:
> 
> Hello,
> 
> I'm hoping someone on here knows the appropriate place/contact for me to
> lodge a complaint about a color name in the "colors" function. I was
> shocked to see there are four named color options that include the term
> "indianred." Surely these colors can be changed to something less
> offensive- my suggestion is "blush." How can I find out who to contact
> about making this happen?
> 
> Thank you in advance for any suggestions.
> 
> Sincerely,
> Elaine Gallenberg
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Mon Nov 16 20:11:54 2020
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Mon, 16 Nov 2020 19:11:54 +0000
Subject: [R] Inappropriate color name
In-Reply-To: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
Message-ID: <06625B10-B278-4957-8B09-B908E3B7FBE7@utoronto.ca>

This is a standard colour palette name that has been in use for years. R did not invent it. It simply uses the standard names. Look up indianred on google. You will find Wikipedia entries, hex codes for the colour, etc.

This has nothing to do with R, in my opinion.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
 

?On 2020-11-16, 1:39 PM, "R-help on behalf of Lainey Gallenberg" <r-help-bounces at r-project.org on behalf of laineygallenberg at gmail.com> wrote:

    EXTERNAL EMAIL:  Treat content with extra caution.

    Hello,

    I'm hoping someone on here knows the appropriate place/contact for me to
    lodge a complaint about a color name in the "colors" function. I was
    shocked to see there are four named color options that include the term
    "indianred." Surely these colors can be changed to something less
    offensive- my suggestion is "blush." How can I find out who to contact
    about making this happen?

    Thank you in advance for any suggestions.

    Sincerely,
    Elaine Gallenberg

            [[alternative HTML version deleted]]

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Nov 16 20:17:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 16 Nov 2020 11:17:13 -0800
Subject: [R] WG: Packegs for mathematics
In-Reply-To: <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>
References: <34d86951e8e743f3851059c81bd6087a@unifr.ch>
 <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>
Message-ID: <CAGxFJbQfrVtcfej7LTHPT560pwC+zOHisSyP2C3dP5hgSXp_yA@mail.gmail.com>

Good advice on R packages cannot be provided unless **you** first inform
for what purpose the packages are intended.

You should look here before posting further:
https://cran.r-project.org/web/views/

You may also wish to post search queries like "R package to do ..." here:
https://rseek.org/

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 16, 2020 at 10:39 AM ELLENBERGER Mihaela via R-help <
r-help at r-project.org> wrote:

>
>
>
> ________________________________
> Von: ELLENBERGER Mihaela
> Gesendet: Montag, 16. November 2020 10:24
> An: CRAN-submissions at R-project.org
> Betreff: Packegs for mathematics
>
>
> Hello
>
>
> I'm undergraduated student of Biomedical Sciences in Switzerland and
> learning how to work with R.
>
> Currently I'm using R-Studio.
>
>
> I would like to now, which packeges sholud I install please for
> mathematics ( analysis)?
>
> My collegeues don't use all the same maths software ( some of them are
> using Excel, SPSS, Mathematica, etc.)
>
>
> -Funktionen,Serien, Folgen,Grenzwerte, Stetigkeiten
>
> -Integralrechnungen
>
> -Differentialrechnungen
>
> -Analysis multivariant
>
>
> Could you sent me an advice please, because there are so many packeges in
> R.
>
>
> Kind regards
>
>
> Mihaela Ellenberger
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Mon Nov 16 20:17:48 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Mon, 16 Nov 2020 13:17:48 -0600
Subject: [R] WG: Packages for mathematics
In-Reply-To: <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>
References: <34d86951e8e743f3851059c81bd6087a@unifr.ch>
 <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>
Message-ID: <2574caeb-9564-b95c-dfc9-d9840e5b5ccb@effectivedefense.org>

	  Several resources for "Searching R Packages" are discussed in a 
Wikiversity article by that title:


https://en.wikiversity.org/wiki/Searching_R_Packages


	  I've found the "sos" package on CRAN (which has a vignette describing 
use) and "https://www.rdocumentation.org" to be most useful.


	  Many functions are included in base R.  Many more are provided in 
contributed packages.


	  Spencer Graves


On 2020-11-16 04:02, ELLENBERGER Mihaela via R-help wrote:
> 
> 
> 
> ________________________________
> Von: ELLENBERGER Mihaela
> Gesendet: Montag, 16. November 2020 10:24
> An: CRAN-submissions at R-project.org
> Betreff: Packegs for mathematics
> 
> 
> Hello
> 
> 
> I'm undergraduated student of Biomedical Sciences in Switzerland and learning how to work with R.
> 
> Currently I'm using R-Studio.
> 
> 
> I would like to now, which packeges sholud I install please for mathematics ( analysis)?
> 
> My collegeues don't use all the same maths software ( some of them are using Excel, SPSS, Mathematica, etc.)
> 
> 
> -Funktionen,Serien, Folgen,Grenzwerte, Stetigkeiten
> 
> -Integralrechnungen
> 
> -Differentialrechnungen
> 
> -Analysis multivariant
> 
> 
> Could you sent me an advice please, because there are so many packeges in R.
> 
> 
> Kind regards
> 
> 
> Mihaela Ellenberger
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From |@|neyg@||enberg @end|ng |rom gm@||@com  Mon Nov 16 20:31:14 2020
From: |@|neyg@||enberg @end|ng |rom gm@||@com (Lainey Gallenberg)
Date: Mon, 16 Nov 2020 10:31:14 -0900
Subject: [R] Inappropriate color name
In-Reply-To: <CANOgrHaZ6_sPFktZQQod0Rzcq-WMibBAEsmxUbZoh2_FHMNzPQ@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CANOgrHaZ6_sPFktZQQod0Rzcq-WMibBAEsmxUbZoh2_FHMNzPQ@mail.gmail.com>
Message-ID: <CAOvsXQZy46MDig0WCsciLyhedK3HwysJHxRwhRz3HCq0LLFeQw@mail.gmail.com>

Hello,

Thanks for the information. I am glad to learn the etymology of the word is
not related to the offensive terms used in the US and Canada. Personally, I
would prefer if R took Crayola's route and changed the name to avoid this
mistake in the future, but perhaps this sentiment is not shared by others.

Best,
Elaine

On Mon, Nov 16, 2020 at 9:46 AM Mitchell Maltenfort <mmalten at gmail.com>
wrote:

> According to Wikipedia -- https://en.wikipedia.org/wiki/Indian_red_(color)
> -- "Indian red" refers to a pigment from India.
>
> The Wikipedia page reports that Crayola were concerned about the mistaken
> etymology so used the name "Chestnut"
>
> On Mon, Nov 16, 2020 at 1:39 PM Lainey Gallenberg <
> laineygallenberg at gmail.com> wrote:
>
>> Hello,
>>
>> I'm hoping someone on here knows the appropriate place/contact for me to
>> lodge a complaint about a color name in the "colors" function. I was
>> shocked to see there are four named color options that include the term
>> "indianred." Surely these colors can be changed to something less
>> offensive- my suggestion is "blush." How can I find out who to contact
>> about making this happen?
>>
>> Thank you in advance for any suggestions.
>>
>> Sincerely,
>> Elaine Gallenberg
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Nov 16 21:54:01 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 17 Nov 2020 07:54:01 +1100
Subject: [R] Inappropriate color name
In-Reply-To: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
Message-ID: <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>

Hi Elaine,
There seems to be a popular contest to discover offence everywhere. I don't
think that it does anything against racism, sexism or
antidisestablishmentarianism. Words are plucked from our vast lexicon to
comfort or insult our fellows depending upon the intent of the user. It is
the intent that matters, not the poor word. Chasing the words wastes your
time, blames those who use the words harmlessly, and gives the real
offender time to find another epithet.

Jim

On Tue, Nov 17, 2020 at 5:39 AM Lainey Gallenberg <
laineygallenberg at gmail.com> wrote:

> Hello,
>
> I'm hoping someone on here knows the appropriate place/contact for me to
> lodge a complaint about a color name in the "colors" function. I was
> shocked to see there are four named color options that include the term
> "indianred." Surely these colors can be changed to something less
> offensive- my suggestion is "blush." How can I find out who to contact
> about making this happen?
>
> Thank you in advance for any suggestions.
>
> Sincerely,
> Elaine Gallenberg
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g@@@powe|| @end|ng |rom protonm@||@com  Mon Nov 16 21:56:18 2020
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg)
Date: Mon, 16 Nov 2020 20:56:18 +0000
Subject: [R] - Trying to replicate VLOOKUP in R - help needed
Message-ID: <IkbJMS_4gaUyHHbjriqfAZaaprHTwr2mbKOuwuQQ2NwsgOo8RwZowms0bl4SxKgAQG2qGMtfucx6uIDERjiolsb5Ii-ij_4bjVh_GYEVTDQ=@protonmail.com>

PROBLEM: I am trying to replicate something like a VLOOKUP in R but am having no success - need a bit of help.

GIVEN DATA SET (data.table): (looks something like this, but much bigger)

NAME                	 TOTALAUTH	ASSIGNED_COMPANY
ABERDEEN PROVING GROUND	     1	               NA
ADELPHI LABORATORY CENTER    1	               NA
CARLISLE BARRACKS	     1	               NA
DETROIT ARSENAL      	     1	               NA
DUGWAY PROVING GROUND	     1	               NA
FORT A P HILL	             1	               NA
FORT BELVOIR	             1	               NA
FORT BENNING	             1	               NA
FORT BLISS	             1	               NA
FORT BRAGG	             1	               NA
FORT BUCHANAN	             1	               NA


I am trying to update the values in the ASSIGNED_COMPANY column from NAs to a value that matches based on the "key" word like below.

NAME                	 TOTALAUTH	ASSIGNED_COMPANY
ABERDEEN PROVING GROUND	     1	               NEC Aberdeen
ADELPHI LABORATORY CENTER    1	               NEC Adelphi
CARLISLE BARRACKS	     1	               NEC Carlise
DETROIT ARSENAL      	     1	               NEC Detroit
DUGWAY PROVING GROUND	     1	               NEC Dugway
FORT A P HILL	             1	               NEC AP Hill
FORT BELVOIR	             1	               NEC Belvoir
FORT BENNING	             1	               NEC Benning
FORT BLISS	             1	               NEC Bliss
FORT BRAGG	             1	               NEC Bragg
FORT BUCHANAN	             1	               NEC Buchanon


In a nutshell, for instance.......

I want to search for the keyword "ABERDEEN" in the NAME column, and for every row where it exists, I want to update the NA in the ASSIGNED_COMPANY column to "NEC Aberdeen"

I want to search for the keyword "ADELPHI" in the NAME column, and for every row where it exists, I want to update the NA in the ASSIGNED_COMPANY column to "NEC ADELPHI"

....... and so on for every value in the NAME column - so in the end a I have matching names in the ASSIGNED_COMPANY column.

I can use an if statement because it is not vectorized.

If I use an ifelse statement, the "else" rewrites any changes with ""

Something so simple should not be difficult.

Some of the methods I attempted to use are below along with the errors I get...






###################CODE#######################################

library(data.table)
library(dplyr)
library(stringr)


VLOOKUP_inR <- data.table::fread("DATASET_TESTINGONLY.csv")

#METHOD 1 FAILS
VLOOKUP_inR %>% dplyr::rename_if(grepl("ADELPHI", VLOOKUP_inR$NAME, useBytes = TRUE), "NEC Adelphi")

Error in get(.x, .env, mode = "function") : 

  object 'NEC Adelphi' of mode 'function' was not found

#METHOD 2 FAILS
if(stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) {
        VLOOKUP_inR$ASSIGNED_COMPANY == "NEC Adelphi"
}

Warning message:
In if (stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) { :
  the condition has length > 1 and only the first element will be used


#METHOD 3 FAILS
ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, "ADELPHI"), ASIP_combined_location_tally$ASSIGNED_COMPANY == ASIP_combined_location_tally$ASSIGNED_COMPANY)

Error in ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME,  : 

  argument "no" is missing, with no default

#METHOD4 FAILS
VLOOKUP_inR_matching <- VLOOKUP_inR %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'ABERDEEN', x = NAME), 'NEC Aberdeen', ''))
VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'ADELPHI', x = NAME), 'NEC Adelphi', '')) 

VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'CARLISLE', x = NAME), 'NEC Carlisle Barracks', ''))
VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'DETROIT', x = NAME), 'NEC Detroit Arsenal', ''))
VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'BELVOIR', x = NAME), 'NEC Fort Belvoir', ''))

-----------the 4th method just over writes all previous changers back to ""





######################################################################

Any help offered would be so very greatly appreciated.

Thanks you.

r/
gregg powell
AZ









-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201116/acdd4bad/attachment.sig>

From bgunter@4567 @end|ng |rom gm@||@com  Mon Nov 16 22:03:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 16 Nov 2020 13:03:13 -0800
Subject: [R] Inappropriate color name
In-Reply-To: <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
Message-ID: <CAGxFJbR3M-z+EDGAq1_o9w2gdX0WFstvYq+iov3Ascd1=jgfNw@mail.gmail.com>

WIth all due respect, can we end this thread NOW. This is not a forum to
discuss social or political viewpoints. I consider it a disservice to make
it one.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 16, 2020 at 12:54 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Elaine,
> There seems to be a popular contest to discover offence everywhere. I don't
> think that it does anything against racism, sexism or
> antidisestablishmentarianism. Words are plucked from our vast lexicon to
> comfort or insult our fellows depending upon the intent of the user. It is
> the intent that matters, not the poor word. Chasing the words wastes your
> time, blames those who use the words harmlessly, and gives the real
> offender time to find another epithet.
>
> Jim
>
> On Tue, Nov 17, 2020 at 5:39 AM Lainey Gallenberg <
> laineygallenberg at gmail.com> wrote:
>
> > Hello,
> >
> > I'm hoping someone on here knows the appropriate place/contact for me to
> > lodge a complaint about a color name in the "colors" function. I was
> > shocked to see there are four named color options that include the term
> > "indianred." Surely these colors can be changed to something less
> > offensive- my suggestion is "blush." How can I find out who to contact
> > about making this happen?
> >
> > Thank you in advance for any suggestions.
> >
> > Sincerely,
> > Elaine Gallenberg
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Mon Nov 16 22:27:04 2020
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Mon, 16 Nov 2020 21:27:04 +0000
Subject: [R] - Trying to replicate VLOOKUP in R - help needed
In-Reply-To: <IkbJMS_4gaUyHHbjriqfAZaaprHTwr2mbKOuwuQQ2NwsgOo8RwZowms0bl4SxKgAQG2qGMtfucx6uIDERjiolsb5Ii-ij_4bjVh_GYEVTDQ=@protonmail.com>
References: <IkbJMS_4gaUyHHbjriqfAZaaprHTwr2mbKOuwuQQ2NwsgOo8RwZowms0bl4SxKgAQG2qGMtfucx6uIDERjiolsb5Ii-ij_4bjVh_GYEVTDQ=@protonmail.com>
Message-ID: <4fb0a8e9-4003-402a-b6f0-9b0e914cdf82@Spark>

Hi Gregg,

it's not clear from your context if all of ASSIGNED _COMPANY is NA or what the classes of the objects are.  Try the following ideas, none of which are tested.  I assume that the data set is called location.

location$ASSIGNED_COMPANY <- as.character(location$NAME)

is.a.FORT <- substr(location$ASSIGNED_COMPANY, 1, 4) == "FORT"

location$ASSIGNED_COMPANY[!is.a.FORT] <-
  sapply(location$ASSIGNED_COMPANY[!is.a.FORT],
  function(x) strsplit(x)[[1]][[1]]) # retains first name if not a fort

location$ASSIGNED_COMPANY[is.a.FORT] <-
  substr(location$ASSIGNED_COMPANY[is.a.FORT], 6,
  nchar(location$ASSIGNED _COMPANY[is.a.FORT])) # Strips FORT from Forts

substr(location$ASSIGNED_COMPANY, 2, nchar(location$ASSIGNED_COMPANY)) <-
  tolower(substr(location$ASSIGNED _COMPANY, 2,
  nchar(location$ASSIGNED _COMPANY))) # lower case word

location$ASSIGNED_COMPANY <- paste("NEC", location$ASSIGNED_COMPANY)

or you can just do

location$ASSIGNED_COMPANY[location$NAME == "ABERDEEN PROVING GROUND"] <- "NEC Aberdeen"

for each option ....

Cheers,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On Nov 17, 2020, 8:05 AM +1100, Gregg via R-help <R-help at r-project.org>, wrote:
PROBLEM: I am trying to replicate something like a VLOOKUP in R but am having no success - need a bit of help.

GIVEN DATA SET (data.table): (looks something like this, but much bigger)

NAME TOTALAUTH ASSIGNED_COMPANY
ABERDEEN PROVING GROUND 1 NA
ADELPHI LABORATORY CENTER 1 NA
CARLISLE BARRACKS 1 NA
DETROIT ARSENAL 1 NA
DUGWAY PROVING GROUND 1 NA
FORT A P HILL 1 NA
FORT BELVOIR 1 NA
FORT BENNING 1 NA
FORT BLISS 1 NA
FORT BRAGG 1 NA
FORT BUCHANAN 1 NA


I am trying to update the values in the ASSIGNED_COMPANY column from NAs to a value that matches based on the "key" word like below.

NAME TOTALAUTH ASSIGNED_COMPANY
ABERDEEN PROVING GROUND 1 NEC Aberdeen
ADELPHI LABORATORY CENTER 1 NEC Adelphi
CARLISLE BARRACKS 1 NEC Carlise
DETROIT ARSENAL 1 NEC Detroit
DUGWAY PROVING GROUND 1 NEC Dugway
FORT A P HILL 1 NEC AP Hill
FORT BELVOIR 1 NEC Belvoir
FORT BENNING 1 NEC Benning
FORT BLISS 1 NEC Bliss
FORT BRAGG 1 NEC Bragg
FORT BUCHANAN 1 NEC Buchanon


In a nutshell, for instance.......

I want to search for the keyword "ABERDEEN" in the NAME column, and for every row where it exists, I want to update the NA in the ASSIGNED_COMPANY column to "NEC Aberdeen"

I want to search for the keyword "ADELPHI" in the NAME column, and for every row where it exists, I want to update the NA in the ASSIGNED_COMPANY column to "NEC ADELPHI"

....... and so on for every value in the NAME column - so in the end a I have matching names in the ASSIGNED_COMPANY column.

I can use an if statement because it is not vectorized.

If I use an ifelse statement, the "else" rewrites any changes with ""

Something so simple should not be difficult.

Some of the methods I attempted to use are below along with the errors I get...






###################CODE#######################################

library(data.table)
library(dplyr)
library(stringr)


VLOOKUP_inR <- data.table::fread("DATASET_TESTINGONLY.csv")

#METHOD 1 FAILS
VLOOKUP_inR %>% dplyr::rename_if(grepl("ADELPHI", VLOOKUP_inR$NAME, useBytes = TRUE), "NEC Adelphi")

Error in get(.x, .env, mode = "function") :

object 'NEC Adelphi' of mode 'function' was not found

#METHOD 2 FAILS
if(stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) {
VLOOKUP_inR$ASSIGNED_COMPANY == "NEC Adelphi"
}

Warning message:
In if (stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) { :
the condition has length > 1 and only the first element will be used


#METHOD 3 FAILS
ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, "ADELPHI"), ASIP_combined_location_tally$ASSIGNED_COMPANY == ASIP_combined_location_tally$ASSIGNED_COMPANY)

Error in ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, :

argument "no" is missing, with no default

#METHOD4 FAILS
VLOOKUP_inR_matching <- VLOOKUP_inR %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'ABERDEEN', x = NAME), 'NEC Aberdeen', ''))
VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'ADELPHI', x = NAME), 'NEC Adelphi', ''))

VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'CARLISLE', x = NAME), 'NEC Carlisle Barracks', ''))
VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'DETROIT', x = NAME), 'NEC Detroit Arsenal', ''))
VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'BELVOIR', x = NAME), 'NEC Fort Belvoir', ''))

-----------the 4th method just over writes all previous changers back to ""





######################################################################

Any help offered would be so very greatly appreciated.

Thanks you.

r/
gregg powell
AZ









	[[alternative HTML version deleted]]


From |@|neyg@||enberg @end|ng |rom gm@||@com  Mon Nov 16 22:30:03 2020
From: |@|neyg@||enberg @end|ng |rom gm@||@com (Lainey Gallenberg)
Date: Mon, 16 Nov 2020 12:30:03 -0900
Subject: [R] Inappropriate color name
In-Reply-To: <CAGxFJbR3M-z+EDGAq1_o9w2gdX0WFstvYq+iov3Ascd1=jgfNw@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
 <CAGxFJbR3M-z+EDGAq1_o9w2gdX0WFstvYq+iov3Ascd1=jgfNw@mail.gmail.com>
Message-ID: <CAOvsXQYd+dUx=4YzmQTk-Bsg-+AVouHXj45x0n5Pzd=yj-x7Zw@mail.gmail.com>

 Whether or not you agree with my reason for doing so, my question was how
to contact the creator of the "colors" function. If you do not have advice
on this, please refrain from weighing in.

On Mon, Nov 16, 2020 at 12:03 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> WIth all due respect, can we end this thread NOW. This is not a forum to
> discuss social or political viewpoints. I consider it a disservice to make
> it one.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Nov 16, 2020 at 12:54 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Elaine,
>> There seems to be a popular contest to discover offence everywhere. I
>> don't
>> think that it does anything against racism, sexism or
>> antidisestablishmentarianism. Words are plucked from our vast lexicon to
>> comfort or insult our fellows depending upon the intent of the user. It is
>> the intent that matters, not the poor word. Chasing the words wastes your
>> time, blames those who use the words harmlessly, and gives the real
>> offender time to find another epithet.
>>
>> Jim
>>
>> On Tue, Nov 17, 2020 at 5:39 AM Lainey Gallenberg <
>> laineygallenberg at gmail.com> wrote:
>>
>> > Hello,
>> >
>> > I'm hoping someone on here knows the appropriate place/contact for me to
>> > lodge a complaint about a color name in the "colors" function. I was
>> > shocked to see there are four named color options that include the term
>> > "indianred." Surely these colors can be changed to something less
>> > offensive- my suggestion is "blush." How can I find out who to contact
>> > about making this happen?
>> >
>> > Thank you in advance for any suggestions.
>> >
>> > Sincerely,
>> > Elaine Gallenberg
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From mm@|ten @end|ng |rom gm@||@com  Mon Nov 16 22:41:22 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Mon, 16 Nov 2020 16:41:22 -0500
Subject: [R] - Trying to replicate VLOOKUP in R - help needed
In-Reply-To: <4fb0a8e9-4003-402a-b6f0-9b0e914cdf82@Spark>
References: <IkbJMS_4gaUyHHbjriqfAZaaprHTwr2mbKOuwuQQ2NwsgOo8RwZowms0bl4SxKgAQG2qGMtfucx6uIDERjiolsb5Ii-ij_4bjVh_GYEVTDQ=@protonmail.com>
 <4fb0a8e9-4003-402a-b6f0-9b0e914cdf82@Spark>
Message-ID: <CANOgrHZ65yuMtN8LCa3Qnsquv2YG9vXkVnP5mQXcGXiFTxzW0w@mail.gmail.com>

ASSIGNED_COMPANY[grep("ADELPHI",NAME)] <-"NEC ADELPHI" is what I'd try

On Mon, Nov 16, 2020 at 4:27 PM Andrew Robinson <apro at unimelb.edu.au> wrote:

> Hi Gregg,
>
> it's not clear from your context if all of ASSIGNED _COMPANY is NA or what
> the classes of the objects are.  Try the following ideas, none of which are
> tested.  I assume that the data set is called location.
>
> location$ASSIGNED_COMPANY <- as.character(location$NAME)
>
> is.a.FORT <- substr(location$ASSIGNED_COMPANY, 1, 4) == "FORT"
>
> location$ASSIGNED_COMPANY[!is.a.FORT] <-
>   sapply(location$ASSIGNED_COMPANY[!is.a.FORT],
>   function(x) strsplit(x)[[1]][[1]]) # retains first name if not a fort
>
> location$ASSIGNED_COMPANY[is.a.FORT] <-
>   substr(location$ASSIGNED_COMPANY[is.a.FORT], 6,
>   nchar(location$ASSIGNED _COMPANY[is.a.FORT])) # Strips FORT from Forts
>
> substr(location$ASSIGNED_COMPANY, 2, nchar(location$ASSIGNED_COMPANY)) <-
>   tolower(substr(location$ASSIGNED _COMPANY, 2,
>   nchar(location$ASSIGNED _COMPANY))) # lower case word
>
> location$ASSIGNED_COMPANY <- paste("NEC", location$ASSIGNED_COMPANY)
>
> or you can just do
>
> location$ASSIGNED_COMPANY[location$NAME == "ABERDEEN PROVING GROUND"] <-
> "NEC Aberdeen"
>
> for each option ....
>
> Cheers,
>
> Andrew
>
> --
> Andrew Robinson
> Director, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my
> respects to their Elders.
> On Nov 17, 2020, 8:05 AM +1100, Gregg via R-help <R-help at r-project.org>,
> wrote:
> PROBLEM: I am trying to replicate something like a VLOOKUP in R but am
> having no success - need a bit of help.
>
> GIVEN DATA SET (data.table): (looks something like this, but much bigger)
>
> NAME TOTALAUTH ASSIGNED_COMPANY
> ABERDEEN PROVING GROUND 1 NA
> ADELPHI LABORATORY CENTER 1 NA
> CARLISLE BARRACKS 1 NA
> DETROIT ARSENAL 1 NA
> DUGWAY PROVING GROUND 1 NA
> FORT A P HILL 1 NA
> FORT BELVOIR 1 NA
> FORT BENNING 1 NA
> FORT BLISS 1 NA
> FORT BRAGG 1 NA
> FORT BUCHANAN 1 NA
>
>
> I am trying to update the values in the ASSIGNED_COMPANY column from NAs
> to a value that matches based on the "key" word like below.
>
> NAME TOTALAUTH ASSIGNED_COMPANY
> ABERDEEN PROVING GROUND 1 NEC Aberdeen
> ADELPHI LABORATORY CENTER 1 NEC Adelphi
> CARLISLE BARRACKS 1 NEC Carlise
> DETROIT ARSENAL 1 NEC Detroit
> DUGWAY PROVING GROUND 1 NEC Dugway
> FORT A P HILL 1 NEC AP Hill
> FORT BELVOIR 1 NEC Belvoir
> FORT BENNING 1 NEC Benning
> FORT BLISS 1 NEC Bliss
> FORT BRAGG 1 NEC Bragg
> FORT BUCHANAN 1 NEC Buchanon
>
>
> In a nutshell, for instance.......
>
> I want to search for the keyword "ABERDEEN" in the NAME column, and for
> every row where it exists, I want to update the NA in the ASSIGNED_COMPANY
> column to "NEC Aberdeen"
>
> I want to search for the keyword "ADELPHI" in the NAME column, and for
> every row where it exists, I want to update the NA in the ASSIGNED_COMPANY
> column to "NEC ADELPHI"
>
> ....... and so on for every value in the NAME column - so in the end a I
> have matching names in the ASSIGNED_COMPANY column.
>
> I can use an if statement because it is not vectorized.
>
> If I use an ifelse statement, the "else" rewrites any changes with ""
>
> Something so simple should not be difficult.
>
> Some of the methods I attempted to use are below along with the errors I
> get...
>
>
>
>
>
>
> ###################CODE#######################################
>
> library(data.table)
> library(dplyr)
> library(stringr)
>
>
> VLOOKUP_inR <- data.table::fread("DATASET_TESTINGONLY.csv")
>
> #METHOD 1 FAILS
> VLOOKUP_inR %>% dplyr::rename_if(grepl("ADELPHI", VLOOKUP_inR$NAME,
> useBytes = TRUE), "NEC Adelphi")
>
> Error in get(.x, .env, mode = "function") :
>
> object 'NEC Adelphi' of mode 'function' was not found
>
> #METHOD 2 FAILS
> if(stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) {
> VLOOKUP_inR$ASSIGNED_COMPANY == "NEC Adelphi"
> }
>
> Warning message:
> In if (stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) { :
> the condition has length > 1 and only the first element will be used
>
>
> #METHOD 3 FAILS
> ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, "ADELPHI"),
> ASIP_combined_location_tally$ASSIGNED_COMPANY ==
> ASIP_combined_location_tally$ASSIGNED_COMPANY)
>
> Error in ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, :
>
> argument "no" is missing, with no default
>
> #METHOD4 FAILS
> VLOOKUP_inR_matching <- VLOOKUP_inR %>% mutate(ASSIGNED_COMPANY =
> ifelse(grepl(pattern = 'ABERDEEN', x = NAME), 'NEC Aberdeen', ''))
> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY =
> ifelse(grepl(pattern = 'ADELPHI', x = NAME), 'NEC Adelphi', ''))
>
> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY =
> ifelse(grepl(pattern = 'CARLISLE', x = NAME), 'NEC Carlisle Barracks', ''))
> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY =
> ifelse(grepl(pattern = 'DETROIT', x = NAME), 'NEC Detroit Arsenal', ''))
> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY =
> ifelse(grepl(pattern = 'BELVOIR', x = NAME), 'NEC Fort Belvoir', ''))
>
> -----------the 4th method just over writes all previous changers back to ""
>
>
>
>
>
> ######################################################################
>
> Any help offered would be so very greatly appreciated.
>
> Thanks you.
>
> r/
> gregg powell
> AZ
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mm@|ten @end|ng |rom gm@||@com  Mon Nov 16 22:44:13 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Mon, 16 Nov 2020 16:44:13 -0500
Subject: [R] Inappropriate color name
In-Reply-To: <CAOvsXQYd+dUx=4YzmQTk-Bsg-+AVouHXj45x0n5Pzd=yj-x7Zw@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
 <CAGxFJbR3M-z+EDGAq1_o9w2gdX0WFstvYq+iov3Ascd1=jgfNw@mail.gmail.com>
 <CAOvsXQYd+dUx=4YzmQTk-Bsg-+AVouHXj45x0n5Pzd=yj-x7Zw@mail.gmail.com>
Message-ID: <CANOgrHZCwAtRxBgwcL3itf87kMfkEJik_fR4O0fM3pmUiFyUhQ@mail.gmail.com>

R-core at r-project.org. would be the first stop.



On Mon, Nov 16, 2020 at 4:37 PM Lainey Gallenberg <
laineygallenberg at gmail.com> wrote:

>  Whether or not you agree with my reason for doing so, my question was how
> to contact the creator of the "colors" function. If you do not have advice
> on this, please refrain from weighing in.
>
> On Mon, Nov 16, 2020 at 12:03 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
> > WIth all due respect, can we end this thread NOW. This is not a forum to
> > discuss social or political viewpoints. I consider it a disservice to
> make
> > it one.
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Nov 16, 2020 at 12:54 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Elaine,
> >> There seems to be a popular contest to discover offence everywhere. I
> >> don't
> >> think that it does anything against racism, sexism or
> >> antidisestablishmentarianism. Words are plucked from our vast lexicon to
> >> comfort or insult our fellows depending upon the intent of the user. It
> is
> >> the intent that matters, not the poor word. Chasing the words wastes
> your
> >> time, blames those who use the words harmlessly, and gives the real
> >> offender time to find another epithet.
> >>
> >> Jim
> >>
> >> On Tue, Nov 17, 2020 at 5:39 AM Lainey Gallenberg <
> >> laineygallenberg at gmail.com> wrote:
> >>
> >> > Hello,
> >> >
> >> > I'm hoping someone on here knows the appropriate place/contact for me
> to
> >> > lodge a complaint about a color name in the "colors" function. I was
> >> > shocked to see there are four named color options that include the
> term
> >> > "indianred." Surely these colors can be changed to something less
> >> > offensive- my suggestion is "blush." How can I find out who to contact
> >> > about making this happen?
> >> >
> >> > Thank you in advance for any suggestions.
> >> >
> >> > Sincerely,
> >> > Elaine Gallenberg
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Mon Nov 16 23:22:42 2020
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Mon, 16 Nov 2020 22:22:42 +0000
Subject: [R] Inappropriate color name
In-Reply-To: <CANOgrHZCwAtRxBgwcL3itf87kMfkEJik_fR4O0fM3pmUiFyUhQ@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
 <CAGxFJbR3M-z+EDGAq1_o9w2gdX0WFstvYq+iov3Ascd1=jgfNw@mail.gmail.com>
 <CAOvsXQYd+dUx=4YzmQTk-Bsg-+AVouHXj45x0n5Pzd=yj-x7Zw@mail.gmail.com>
 <CANOgrHZCwAtRxBgwcL3itf87kMfkEJik_fR4O0fM3pmUiFyUhQ@mail.gmail.com>
Message-ID: <BL0PR04MB6609A1D717CBE113DA7BDFADF9E30@BL0PR04MB6609.namprd04.prod.outlook.com>

Lainey wishes to report a bug, so should see ?bug.report. Mail sent to R-core will be held for moderator approval, and relevant input or ultimate resolution would not be visible to the wider community; it is not a good place to report bugs.

Martin Morgan

?On 11/16/20, 4:48 PM, "R-help on behalf of Mitchell Maltenfort" <r-help-bounces at r-project.org on behalf of mmalten at gmail.com> wrote:

    R-core at r-project.org. would be the first stop.



    On Mon, Nov 16, 2020 at 4:37 PM Lainey Gallenberg <
    laineygallenberg at gmail.com> wrote:

    >  Whether or not you agree with my reason for doing so, my question was how
    > to contact the creator of the "colors" function. If you do not have advice
    > on this, please refrain from weighing in.
    >
    > On Mon, Nov 16, 2020 at 12:03 PM Bert Gunter <bgunter.4567 at gmail.com>
    > wrote:
    >
    > > WIth all due respect, can we end this thread NOW. This is not a forum to
    > > discuss social or political viewpoints. I consider it a disservice to
    > make
    > > it one.
    > >
    > > Bert Gunter
    > >
    > > "The trouble with having an open mind is that people keep coming along
    > and
    > > sticking things into it."
    > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    > >
    > >
    > > On Mon, Nov 16, 2020 at 12:54 PM Jim Lemon <drjimlemon at gmail.com> wrote:
    > >
    > >> Hi Elaine,
    > >> There seems to be a popular contest to discover offence everywhere. I
    > >> don't
    > >> think that it does anything against racism, sexism or
    > >> antidisestablishmentarianism. Words are plucked from our vast lexicon to
    > >> comfort or insult our fellows depending upon the intent of the user. It
    > is
    > >> the intent that matters, not the poor word. Chasing the words wastes
    > your
    > >> time, blames those who use the words harmlessly, and gives the real
    > >> offender time to find another epithet.
    > >>
    > >> Jim
    > >>
    > >> On Tue, Nov 17, 2020 at 5:39 AM Lainey Gallenberg <
    > >> laineygallenberg at gmail.com> wrote:
    > >>
    > >> > Hello,
    > >> >
    > >> > I'm hoping someone on here knows the appropriate place/contact for me
    > to
    > >> > lodge a complaint about a color name in the "colors" function. I was
    > >> > shocked to see there are four named color options that include the
    > term
    > >> > "indianred." Surely these colors can be changed to something less
    > >> > offensive- my suggestion is "blush." How can I find out who to contact
    > >> > about making this happen?
    > >> >
    > >> > Thank you in advance for any suggestions.
    > >> >
    > >> > Sincerely,
    > >> > Elaine Gallenberg
    > >> >
    > >> >         [[alternative HTML version deleted]]
    > >> >
    > >> > ______________________________________________
    > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > >> > https://stat.ethz.ch/mailman/listinfo/r-help
    > >> > PLEASE do read the posting guide
    > >> > http://www.R-project.org/posting-guide.html
    > >> > and provide commented, minimal, self-contained, reproducible code.
    > >> >
    > >>
    > >>         [[alternative HTML version deleted]]
    > >>
    > >> ______________________________________________
    > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > >> https://stat.ethz.ch/mailman/listinfo/r-help
    > >> PLEASE do read the posting guide
    > >> http://www.R-project.org/posting-guide.html
    > >> and provide commented, minimal, self-contained, reproducible code.
    > >>
    > >
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    >

    	[[alternative HTML version deleted]]

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.

From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Nov 16 23:46:03 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 17 Nov 2020 11:46:03 +1300
Subject: [R] Inappropriate color name
In-Reply-To: <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
Message-ID: <20201117114603.00ade888@rolf-Latitude-E7470>


On Tue, 17 Nov 2020 07:54:01 +1100
Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Elaine,
> There seems to be a popular contest to discover offence everywhere. I
> don't think that it does anything against racism, sexism or
> antidisestablishmentarianism. Words are plucked from our vast lexicon
> to comfort or insult our fellows depending upon the intent of the
> user. It is the intent that matters, not the poor word. Chasing the
> words wastes your time, blames those who use the words harmlessly,
> and gives the real offender time to find another epithet.

Jim:  This is superbly expressed.  I wish that I could have said
that! Your posting should go down in the annals of brilliant rhetoric,
alongside Dr. Johnson's "Letter to Lord Chesterfield".

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @purd|e@@ @end|ng |rom gm@||@com  Tue Nov 17 03:01:10 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 17 Nov 2020 15:01:10 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAB8pepyftyi+z95+sC09LNGFb5xek1V_ewR30w4pWYBEr8mVfw@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
 <20201114155949.70239ebc@rolf-Latitude-E7470>
 <41AF906C-E297-4C78-90C6-72A624322AB9@dcn.davis.ca.us>
 <20201115085029.0e98021a@rolf-Latitude-E7470>
 <CAB8pepyftyi+z95+sC09LNGFb5xek1V_ewR30w4pWYBEr8mVfw@mail.gmail.com>
Message-ID: <CAB8pepyWMjU90=YHTxd0oUZnmSpqA5QDnjvJDJKU44v3osHeZg@mail.gmail.com>

I've come to the conclusion this whole thing was a waste of time.
This is after evaluating much of the relevant information.

The main problem is a large number of red herrings (some in the data,
some in the context), leading pointless data analysis and pointless
data collection.
It's unlikely that sophisticated software, or sophisticated
statistical modelling tools will make any difference.
Although pretty plots, and pretty web-graphics are achievable.

Sorry list, for encouraging this discussion...


From S@E|||@on @end|ng |rom LGCGroup@com  Tue Nov 17 03:44:35 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Tue, 17 Nov 2020 02:44:35 +0000
Subject: [R] Inappropriate color name
In-Reply-To: <CAOvsXQYd+dUx=4YzmQTk-Bsg-+AVouHXj45x0n5Pzd=yj-x7Zw@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
 <CAGxFJbR3M-z+EDGAq1_o9w2gdX0WFstvYq+iov3Ascd1=jgfNw@mail.gmail.com>
 <CAOvsXQYd+dUx=4YzmQTk-Bsg-+AVouHXj45x0n5Pzd=yj-x7Zw@mail.gmail.com>
Message-ID: <69cf7da707de4297a51057d87c743583@GBDCVPEXC08.corp.lgc-group.com>



>  Whether or not you agree with my reason for doing so, my question was
> how to contact the creator of the "colors" function. If you do not have advice
> on this, please refrain from weighing in.

... which is precisely what Prof Gunter said.

However, it is worth consulting the documentation when you are seeking an author or maintainer. In this instance, you will find that 'colours' (and yes, 'color' grates) is part of the grDevices package, and the package maintainers and the relevant email is on the ?grDevices manual page.





*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Tue Nov 17 07:54:46 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Tue, 17 Nov 2020 01:54:46 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAB8pepyWMjU90=YHTxd0oUZnmSpqA5QDnjvJDJKU44v3osHeZg@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
 <20201114155949.70239ebc@rolf-Latitude-E7470>
 <41AF906C-E297-4C78-90C6-72A624322AB9@dcn.davis.ca.us>
 <20201115085029.0e98021a@rolf-Latitude-E7470>
 <CAB8pepyftyi+z95+sC09LNGFb5xek1V_ewR30w4pWYBEr8mVfw@mail.gmail.com>
 <CAB8pepyWMjU90=YHTxd0oUZnmSpqA5QDnjvJDJKU44v3osHeZg@mail.gmail.com>
Message-ID: <6371d11e-7d02-d394-04f7-b86934331628@molbio.mgh.harvard.edu>

 ???? No reason to apologize. It's a timely and very interesting topic 
that provides a glimpse into the application of statistics in forensics. 
I had never heard of Benford's Law before and I think it is really 
fascinating. One of those very counter intuitive rules that show up in 
statistics and probability; like the Monty Hall problem. Why in the 
world does Benford's Law work ?? I have been wondering if it could in 
any way be applied to biological data analysis. (Also, I discovered 
Stand-up-maths !).

 ?? Often things are not as easy to figure out as we may first estimate. 
I think you would have to start with how you would envision a fraud to 
be committed and then figure out if there is a statistical analysis that 
could detect it, or develop an anlalysis. For example, if a voting 
machine were weighting votes and giving 8/10ths of a vote to 'yes' and 
10/10ths vote to a 'no'. Is there some statistical analysis that could 
detect this ?? I, Or if someone dumped a couple of thousand fraudulent 
ballots in a vote counting center, is there some statistical analysis 
that could detect this ?? Who knows, maybe a whole new field waiting to 
be explored. A oncee-in-a-while dive into a practical application of 
statistics that has current interest can be fun and enlightening for 
those interested.

Matthew

On 11/16/20 9:01 PM, Abby Spurdle wrote:
>          External Email - Use Caution
>
> I've come to the conclusion this whole thing was a waste of time.
> This is after evaluating much of the relevant information.
>
> The main problem is a large number of red herrings (some in the data,
> some in the context), leading pointless data analysis and pointless
> data collection.
> It's unlikely that sophisticated software, or sophisticated
> statistical modelling tools will make any difference.
> Although pretty plots, and pretty web-graphics are achievable.
>
> Sorry list, for encouraging this discussion...


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Tue Nov 17 07:59:37 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Tue, 17 Nov 2020 01:59:37 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <6371d11e-7d02-d394-04f7-b86934331628@molbio.mgh.harvard.edu>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>
 <20201114155949.70239ebc@rolf-Latitude-E7470>
 <41AF906C-E297-4C78-90C6-72A624322AB9@dcn.davis.ca.us>
 <20201115085029.0e98021a@rolf-Latitude-E7470>
 <CAB8pepyftyi+z95+sC09LNGFb5xek1V_ewR30w4pWYBEr8mVfw@mail.gmail.com>
 <CAB8pepyWMjU90=YHTxd0oUZnmSpqA5QDnjvJDJKU44v3osHeZg@mail.gmail.com>
 <6371d11e-7d02-d394-04f7-b86934331628@molbio.mgh.harvard.edu>
Message-ID: <a320aa95-54db-337c-3d7a-e436fe0c7309@molbio.mgh.harvard.edu>

Bye the way, I thought I had checked my e-mail before sending it, but my 
last e-mail had an unfortunate typo with an 'I' that originally belonged 
to the beginning of a deleted sentence.

Matthew

On 11/17/20 1:54 AM, Matthew McCormack wrote:
> External Email - Use Caution
> ???? No reason to apologize. It's a timely and very interesting topic 
> that provides a glimpse into the application of statistics in 
> forensics. I had never heard of Benford's Law before and I think it is 
> really fascinating. One of those very counter intuitive rules that 
> show up in statistics and probability; like the Monty Hall problem. 
> Why in the world does Benford's Law work ?? I have been wondering if 
> it could in any way be applied to biological data analysis. (Also, I 
> discovered Stand-up-maths !).
>
> ?? Often things are not as easy to figure out as we may first 
> estimate. I think you would have to start with how you would envision 
> a fraud to be committed and then figure out if there is a statistical 
> analysis that could detect it, or develop an anlalysis. For example, 
> if a voting machine were weighting votes and giving 8/10ths of a vote 
> to 'yes' and 10/10ths vote to a 'no'. Is there some statistical 
> analysis that could detect this ?? I, Or if someone dumped a couple of 
> thousand fraudulent ballots in a vote counting center, is there some 
> statistical analysis that could detect this ?? Who knows, maybe a 
> whole new field waiting to be explored. A oncee-in-a-while dive into a 
> practical application of statistics that has current interest can be 
> fun and enlightening for those interested.
>
> Matthew
>
> On 11/16/20 9:01 PM, Abby Spurdle wrote:
>> ???????? External Email - Use Caution
>>
>> I've come to the conclusion this whole thing was a waste of time.
>> This is after evaluating much of the relevant information.
>>
>> The main problem is a large number of red herrings (some in the data,
>> some in the context), leading pointless data analysis and pointless
>> data collection.
>> It's unlikely that sophisticated software, or sophisticated
>> statistical modelling tools will make any difference.
>> Although pretty plots, and pretty web-graphics are achievable.
>>
>> Sorry list, for encouraging this discussion...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://secure-web.cisco.com/1icMQVewwCL4P0r0nMcvTG7cQoLGA8vrClXS_7PuCMhfAP5EDlSYNlGppDKYtdY57R0Pqq_TLC4uyH7CSQjzrxbWonQqTR0d7Owzt1oJUshxqjBaYybtXPytcEKTyGL0Wj0aNw-lMCtbQG1wHYe2Gw8r8h0LpQfFihvpv8gyl3L3VpdCfL2GdiuVFUHGynOFY8Lu5fZwQDVdp1bN_ZAAbRHhoQEipiM-vRiK0kf20oD1N3CXQfqyS4O2r9kRmArVLk8RiqyHI0rj_I1iVq5m-bQ/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help 
>
> PLEASE do read the posting guide 
> http://secure-web.cisco.com/1K7htkVeCfn5qRcheVmtA1IibcAUehTMiQa-HWmOXY4aZKKdTMqGoB7oWO4dEEBc1qJDtaTeaodidutGZhJexhH2C4c_FpLR_XA-z7GOvfq77dIwhWfnGcvj_31a6y-SXgu5nPP4AdpguRqwR433dZOUMo5MtP5xwtOUGO-EcWd4AvW_7NUFljEFGuAMs06pzQoK4BPfSavqq_QAj-R_mHJ4-AgaKn2Fmh2BOhustujXNyeeWi6KXg3oXtQzqi6BL4HMEK7iWvT21SPXOEJZlMg/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bor|@@@te|pe @end|ng |rom utoronto@c@  Tue Nov 17 11:52:41 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Tue, 17 Nov 2020 10:52:41 +0000
Subject: [R] Packegs for mathematics
In-Reply-To: <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>
References: <34d86951e8e743f3851059c81bd6087a@unifr.ch>
 <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>
Message-ID: <227B7330-40DA-4362-A392-925A1B440790@utoronto.ca>

You really don't need to worry about all those packages in the beginning. Base R has all of the functionality you need to get you started. Then, when you actually need additional functions, you can search for this functionality on the Web, on CRAN, by asking on this helpful list, or on your favourite community forum. Actually downloading and installing packages is very quick, there's no benefit to pre-loading things you don't actually need.

Bottom line: don't view this from the perspective of resources, see it from the perspective of what you want to do.

Cheers,
Boris




> On 2020-11-16, at 20:02, ELLENBERGER Mihaela via R-help <r-help at r-project.org> wrote:
> 
> EXTERNAL EMAIL:  Treat content with extra caution.
> 
> ________________________________
> Von: ELLENBERGER Mihaela
> Gesendet: Montag, 16. November 2020 10:24
> An: CRAN-submissions at R-project.org
> Betreff: Packegs for mathematics
> 
> 
> Hello
> 
> 
> I'm undergraduated student of Biomedical Sciences in Switzerland and learning how to work with R.
> 
> Currently I'm using R-Studio.
> 
> 
> I would like to now, which packeges sholud I install please for mathematics ( analysis)?
> 
> My collegeues don't use all the same maths software ( some of them are using Excel, SPSS, Mathematica, etc.)
> 
> 
> -Funktionen,Serien, Folgen,Grenzwerte, Stetigkeiten
> 
> -Integralrechnungen
> 
> -Differentialrechnungen
> 
> -Analysis multivariant
> 
> 
> Could you sent me an advice please, because there are so many packeges in R.
> 
> 
> Kind regards
> 
> 
> Mihaela Ellenberger
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Nov 17 12:20:39 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 17 Nov 2020 11:20:39 +0000
Subject: [R] WG: Packegs for mathematics
In-Reply-To: <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>
References: <34d86951e8e743f3851059c81bd6087a@unifr.ch>
 <c273d83b1c9f4bdd96fc54332127ba51@unifr.ch>
Message-ID: <c7fd704b-e949-fbd1-9f52-2cae0b226cde@dewey.myzen.co.uk>

Dear Mihaela

As well as the search tips you have been given you may want to look at 
the CRAN Task Views. There is one for Multivariate
https://cran.r-project.org/view=Multivariate
and one for NumericalMathematics
https://cran.r-project.org/view=NumericalMathematics
and several others which may be relevant.

Note that the task views tell you what exists but they do not offer best 
buy information. For that you may need to come back here and ask about a 
specific subset of packages.

Michael

On 16/11/2020 10:02, ELLENBERGER Mihaela via R-help wrote:
> 
> 
> 
> ________________________________
> Von: ELLENBERGER Mihaela
> Gesendet: Montag, 16. November 2020 10:24
> An: CRAN-submissions at R-project.org
> Betreff: Packegs for mathematics
> 
> 
> Hello
> 
> 
> I'm undergraduated student of Biomedical Sciences in Switzerland and learning how to work with R.
> 
> Currently I'm using R-Studio.
> 
> 
> I would like to now, which packeges sholud I install please for mathematics ( analysis)?
> 
> My collegeues don't use all the same maths software ( some of them are using Excel, SPSS, Mathematica, etc.)
> 
> 
> -Funktionen,Serien, Folgen,Grenzwerte, Stetigkeiten
> 
> -Integralrechnungen
> 
> -Differentialrechnungen
> 
> -Analysis multivariant
> 
> 
> Could you sent me an advice please, because there are so many packeges in R.
> 
> 
> Kind regards
> 
> 
> Mihaela Ellenberger
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From @tyen @end|ng |rom ntu@edu@tw  Tue Nov 17 14:00:06 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Tue, 17 Nov 2020 21:00:06 +0800
Subject: [R] Language environment
Message-ID: <63274208-6836-ccd2-54e6-67d19d2ab6a3@ntu.edu.tw>

In R, I was able to set the language environment by fixing the line

in file "C:\Program Files\R\R-4.0.3\etc\Rconsole", line 70 below, set 
language to EN:

language = EN

In RStudio, I am not able to do that, except to include the line

Sys.setenv(LANG="en");

in every one of my program file. That's too much work. Any idea? Thank you!




	[[alternative HTML version deleted]]


From @@e||ck @end|ng |rom gm@||@com  Tue Nov 17 14:39:12 2020
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Tue, 17 Nov 2020 08:39:12 -0500
Subject: [R] Language environment
In-Reply-To: <63274208-6836-ccd2-54e6-67d19d2ab6a3@ntu.edu.tw>
References: <63274208-6836-ccd2-54e6-67d19d2ab6a3@ntu.edu.tw>
Message-ID: <CADKEMqjgD8SANWnbdG2++8BP1ecz+97Qag4BCfhKVnnMsCpNqw@mail.gmail.com>

Maybe in .Rprofile? Maybe in .first in .Rprofile?

Stephen Sefick, PhD

On Tue, Nov 17, 2020, 08:01 Steven Yen <styen at ntu.edu.tw> wrote:

> In R, I was able to set the language environment by fixing the line
>
> in file "C:\Program Files\R\R-4.0.3\etc\Rconsole", line 70 below, set
> language to EN:
>
> language = EN
>
> In RStudio, I am not able to do that, except to include the line
>
> Sys.setenv(LANG="en");
>
> in every one of my program file. That's too much work. Any idea? Thank you!
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Nov 17 14:57:16 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 17 Nov 2020 08:57:16 -0500
Subject: [R] Language environment
In-Reply-To: <63274208-6836-ccd2-54e6-67d19d2ab6a3@ntu.edu.tw>
References: <63274208-6836-ccd2-54e6-67d19d2ab6a3@ntu.edu.tw>
Message-ID: <E31DAB81-5F72-4459-B3E5-1BC78127CAE6@me.com>


> On Nov 17, 2020, at 8:00 AM, Steven Yen <styen at ntu.edu.tw> wrote:
> 
> In R, I was able to set the language environment by fixing the line
> 
> in file "C:\Program Files\R\R-4.0.3\etc\Rconsole", line 70 below, set 
> language to EN:
> 
> language = EN
> 
> In RStudio, I am not able to do that, except to include the line
> 
> Sys.setenv(LANG="en");
> 
> in every one of my program file. That's too much work. Any idea? Thank you!
> 


Hi,

You may be better served using and/or posting to RStudio's own support site:

  https://support.rstudio.com/

as they are a separate product from R itself.

It sounds like there may be somewhat different session startup processes for RStudio, and they would be the best resource to assist you.

Regards,

Marc Schwartz


From mm@|ten @end|ng |rom gm@||@com  Tue Nov 17 15:05:34 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Tue, 17 Nov 2020 09:05:34 -0500
Subject: [R] Inappropriate color name
In-Reply-To: <20201117114603.00ade888@rolf-Latitude-E7470>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
 <20201117114603.00ade888@rolf-Latitude-E7470>
Message-ID: <CANOgrHZR-M_AEbnik1Rvszwd1jDmDr5mGrMkkC9Swe+6M1nUQA@mail.gmail.com>

Thanks, Rolf, I never saw the Letter to Chesterfield myself.

Though I admit I run more to Swift's "A Modest Proposal" but then if you
really want to get into being impolitic that's a stellar example!

Mitch

On Mon, Nov 16, 2020 at 5:46 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On Tue, 17 Nov 2020 07:54:01 +1100
> Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Elaine,
> > There seems to be a popular contest to discover offence everywhere. I
> > don't think that it does anything against racism, sexism or
> > antidisestablishmentarianism. Words are plucked from our vast lexicon
> > to comfort or insult our fellows depending upon the intent of the
> > user. It is the intent that matters, not the poor word. Chasing the
> > words wastes your time, blames those who use the words harmlessly,
> > and gives the real offender time to find another epithet.
>
> Jim:  This is superbly expressed.  I wish that I could have said
> that! Your posting should go down in the annals of brilliant rhetoric,
> alongside Dr. Johnson's "Letter to Lord Chesterfield".
>
> cheers,
>
> Rolf
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ck|uth @end|ng |rom gwdg@de  Mon Nov 16 21:07:31 2020
From: ck|uth @end|ng |rom gwdg@de (Kluth, Christian)
Date: Mon, 16 Nov 2020 20:07:31 +0000
Subject: [R] WG: grouped anova from lm as data frame, tidyr broom
Message-ID: <042bcec07f834cdba4639e717135346d@gwdg.de>

Dear R-project team,
I got a message that the e-mail from this morning was filtered away completely. So hopefully this is working.
I am trying to solve a probably easy problem with R using the tidyr package. Probably I did not get the concept very clearly.
I would like to get a nice tidy data frame of ANOVAs of several identical models (lm or lme (anovas then generated with the car::Anova() function) from grouped data.? As an example, you will find my beginnings of what I did in the attached R-file ("grouped anova from lm as data frame". The example data frame (auto.noise) I use for the example comes from the emmeans-package. 
As an output, I just want something like this (Anova table grouped by size):
size	Dependent	HypothesisType	Source	DF	SS	MS	FValue	ProbF
L	noise	1	side	1	833.3333333	833.3333333	50	0.000104954
L	noise	1	type	1	75	75	4.5	0.066688
L	noise	1	side*type	1	133.3333333	133.3333333	8	0.022203904
M	noise	1	side	1	52.08333333	52.08333333	2.777777778	0.134140641
M	noise	1	type	1	1752.083333	1752.083333	93.44444444	1.09266E-05
M	noise	1	side*type	1	52.08333333	52.08333333	2.777777778	0.134140641
S	noise	1	side	1	408.3333333	408.3333333	49	0.000112639
S	noise	1	type	1	33.33333333	33.33333333	4	0.080516238
S	noise	1	side*type	1	133.3333333	133.3333333	16	0.003949773

The output is generated with SAS (code below) using the 'by' statement within the glm procedure. (The model is probably not appropriate since there are repeated measures (factor side, however no subject is given in the data), but it works as a working example.? The example code comes from two sources:
1 https://dplyr.tidyverse.org/reference/do.html
2 https://cran.r-project.org/web/packages/broom/vignettes/broom_and_dplyr.html. 
I tried to edit the code in order to get a data frame like the one above but without any success. At the end, it seems that I am too stupid to get the concept in my head. I hope that with your help I will better understand the concept and that I then can extract further information as a data frame like post hoc tukey tests and corresponding clds (compact letter display) and apply it to more complex models of lme-type.

I would be very happy if there is somebody who could help.
Thank you very much in advance
Regards
Christian
PS: here are the few lines that generates the above shown data set
proc glm data=auto_noise;
by size;
class side type;
model noise=side|type;
ods output ModelANOVA=ModelANOVA;
run;

And here comes the r-code as plain text:
# working example for grouped anova from lm as data frame
rm(list=ls())
library(emmeans)
library(broom)
library(dplyr)

str(auto.noise)
View(auto.noise)

# 1. I tried this corresponding to https://dplyr.tidyverse.org/reference/do.html

by_size <- auto.noise %>% group_by(size)
# do() with named arguments becomes nest_by() + mutate() & list()
models <- by_size %>% do(mod = lm(noise ~ type*side, data = .))
# ->
models %>% summarise(rsq = summary(mod)$r.squared)
# this works nicely but than I can't extract the anovatables =>

models %>% summary.aov(mod)
models %>% summarise(summary.aov(mod))



# 2. corresponding to  https://cran.r-project.org/web/packages/broom/vignettes/broom_and_dplyr.html
R.lmbysize<-auto.noise %>%
  nest(-size) %>% 
  mutate(
    fit = map(data, ~ lm(noise ~ type*side, data = .x)),
    tidied = map(fit, tidy),
    glanced = map(fit, glance),
    augmented = map(fit, augment))

fit.bysize.df<-R.lmbysize%>% 
  unnest(tidied)
View(fit.bysize.df)


stats.bysize.df<-R.lmbysize%>% 
  unnest(glanced)
View(stats.bysize.df)


resid.pred.bysize.df<-R.lmbysize%>% 
  unnest(augmented)
View(resid.pred.bysize.df)
View(R.lmbysize)

## how to get an extracted anova table by size? the following does not work
Anova.bysize.df<-R.lmbysize%>% 
  unnest(summary.aov(fit))
View(fit.bysize.df)

summary.aov(fit.bysize.df)


# I tried to implement some thing like this: but it doesent work as well
Anova.tab=map(Anova.tab(fit),tidy)


******************************************
Dr. Christian Kluth
Georg-August-Universit?t G?ttingen
Lehrkraft f?r besondere Aufgaben
Statistikberatung f?r Studierende
Department f?r Nutzpflanzenwissenschaften Carl-Sprengel-Weg 1
37075 G?ttingen
Raum: 1.206
https://www.geodata.uni-goettingen.de/lageplan/?ident=4400_2_1.OG_1.206

Tel.: 0551/39-25582
E-Mail: mailto:ckluth at uni-goettingen.de


Termine nach Vereinbarung
*****************************************


From bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com  Tue Nov 17 03:18:11 2020
From: bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com (Bhaskar Mitra)
Date: Mon, 16 Nov 2020 19:18:11 -0700
Subject: [R] Request for help to modify sliderInput in RShiny app
 (conditional statement)
Message-ID: <CAEGXkYX3zJtad-s-09LLHBRnb-49uJzAv6kNvJ_4xqL_RfVJrg@mail.gmail.com>

Hello Everyone,

I have written certain codes in RShiny app which works fine.
There are 3 tabs, "Z1", "Z2" and "Z3".  Currently the sliderinput shows up
when I click all the 3 tabs.

I need  to adjust this code so that sliderInput is only visible when i
click  tab "Z1" and not for tabs "Z2" and "Z3".
 Can anyone please suggest how to modify the codes in that regard?

the codes for ui.r and server.r are given below.

thanks for your help,
regards,
bhaskar



####################################################################################
#Codes for ui.r

library(shiny)
library(shinydashboard)
library(shinyjs)

fluidPage(

  sidebarLayout(position = "left",
                sidebarPanel(
                  sliderInput(inputId = "year",
                              label = "Years included",
                              min = 1990,
                              max = 2000,
                              value = c(1990, 2000),
                              sep = "",
                              step = 1),

                  column(width = 10, plotOutput("distPlot"))

                ),

                mainPanel(
                  tabsetPanel(type = "pills",
                              position = "below",
                              tabPanel("Z1", plotOutput("trend")),
                              tabPanel("Z2", plotOutput("trend1")),
                              tabPanel("Z3", plotOutput("trend2"))
                  ),
                )
  )
)
############################################################################################
#Codes for server.r

#library(ggthemes)
library(gapminder)
library(leaflet)
library(ggmap)
library(tidyverse)
library(lubridate)
library(fpp2)
library(zoo)
library(shinydashboard)
library(shinyjs)
library(ggpubr)

df7 =  read_csv("data.csv")
df8 = read_csv("data1.csv")

function(input, output) {

    theData = reactive({
    df7 %>%
      filter(year >= input$year[1], year <= input$year[2])
     })

  theData1 = reactive({df8})

    output$trend = renderPlot
  ({
    lp1 <- theData() %>%
      gather(metric, value, x1) %>%
      ggplot(aes(date, value, color = metric)) +
      geom_line()
    print(lp1)
      })

  output$trend1 = renderPlot
  ({
    lp2 <- theData1() %>%
      gather(metric, value, x2) %>%
      ggplot(aes(date, value, color = metric)) +
      geom_line()
    print(lp2)
      })

  output$trend2 = renderPlot
  ({
    lp3 <- theData1() %>%
      gather(metric, value, x3) %>%
      ggplot(aes(date, value, color = metric)) +
      geom_line()
    print(lp3)
  })

}

	[[alternative HTML version deleted]]


From q@@m0000 @end|ng |rom gm@||@com  Tue Nov 17 09:19:41 2020
From: q@@m0000 @end|ng |rom gm@||@com (quinter sam)
Date: Tue, 17 Nov 2020 11:19:41 +0300
Subject: [R] Using multiroot for root solution for a matrix based function
Message-ID: <CA+Dt5-wXsSne+9wZG2VFi2pRvUT0_ULu=TAwE=PrhhckYQrRLg@mail.gmail.com>

 I have a function which is actually an output of another function and I
therefore cannot change it. I am trying to use *multiroot * from
package *rootSolve
* to compute the roots of the function but its not working at all. Is there
something I am not seeing or is there another alternative that is based on
Newton-Raphson technique?

library(rootSolve)
f <- function(q,m){
c(F1 = 12 * ((exp(q[, 1]) * m[1])/(exp(q[, 1]) * m[1] + exp(q[, 2]) * m[2]
+ m[3])) - c(1,2),
F2 = 12 * ((exp(q[, 2]) * m[2])/(exp(q[, 1]) * m[1] + exp(q[, 2]) * m[2] +
m[3])) - c(3,3))
}
m = c(0.1,0.2,0.7)

I am trying to solve for *q* and from based on the given m, I expect
something like this;
q <- matrix(c(-0.1335314,0.6931472,0.2719337,0.4054651), nrow=2)

How would I call the multiroot for the function f to hopefully get the
above results. I thought of using newtonRaphson from package pracma but
that possibly only handles univariate inputs.

	[[alternative HTML version deleted]]


From m||net@ @end|ng |rom tut@@|o  Tue Nov 17 15:18:29 2020
From: m||net@ @end|ng |rom tut@@|o (T. A. Milne)
Date: Tue, 17 Nov 2020 15:18:29 +0100 (CET)
Subject: [R] Inappropriate color name
Message-ID: <MMLZYTo--3-2@tuta.io>


On Tue, 17 Nov 2020 07:54:01 +1100Jim Lemon <drjimlemon at gmail.com> <mailto:drjimlemon at gmail.com> wrote:

> Hi Elaine,There seems to be a popular contest to discover offence everywhere. Idon't think that it does anything against racism, sexism orantidisestablishmentarianism. Words are plucked from our vast lexiconto comfort or insult our fellows depending upon the intent of theuser. It is the intent that matters, not the poor word. Chasing thewords wastes your time, blames those who use the words harmlessly,and gives the real offender time to find another epithet.
>
Jim:  This is superbly expressed.  I wish that I could have saidthat! Your posting should go down in the annals of brilliant rhetoric,alongside Dr. Johnson's "Letter to Lord Chesterfield".cheers,Rolf
-- Honorary Research FellowDepartment of StatisticsUniversity of AucklandPhone: +64-9-373-7599 ext. 88276

To Rolf's excellent example, I would add Mandy Rice-Davies' immortal words from the witness box.



- T. Arthur Milne


	[[alternative HTML version deleted]]


From novo@|rj @end|ng |rom rutger@@edu  Tue Nov 17 16:39:38 2020
From: novo@|rj @end|ng |rom rutger@@edu (Ryan Novosielski)
Date: Tue, 17 Nov 2020 15:39:38 +0000
Subject: [R] Inappropriate color name
In-Reply-To: <20201117114603.00ade888@rolf-Latitude-E7470>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
 <20201117114603.00ade888@rolf-Latitude-E7470>
Message-ID: <D2B0582C-E2C8-426F-AA21-9680AEBBBA42@rutgers.edu>

> On Nov 16, 2020, at 5:46 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On Tue, 17 Nov 2020 07:54:01 +1100
> Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi Elaine,
>> There seems to be a popular contest to discover offence everywhere. I
>> don't think that it does anything against racism, sexism or
>> antidisestablishmentarianism. Words are plucked from our vast lexicon
>> to comfort or insult our fellows depending upon the intent of the
>> user. It is the intent that matters, not the poor word. Chasing the
>> words wastes your time, blames those who use the words harmlessly,
>> and gives the real offender time to find another epithet.
> 
> Jim:  This is superbly expressed.  I wish that I could have said
> that! Your posting should go down in the annals of brilliant rhetoric,
> alongside Dr. Johnson's "Letter to Lord Chesterfield".
> 
> cheers,
> 
> Rolf

You know, I wouldn?t have continued this thread (which has now wandered off topic from the original somewhat-more-technical question), but I feel now like it?s necessary to do so (and only fair, if anyone is considering moderating me after letting these posts by):

That is a view commonly held by white people, and even more overwhelmingly by white men. Our field is already not as diverse as it should be for a variety of reasons, and this ?pretending no one else on earth exists? kind of stuff is at least some part of the reason. The question at issue here aside, white men complaining about people finding racism or sexism everywhere they look doesn?t pass the sniff test. Most or all of these things that people are reporting as offensive are being reported by people you?re clearly not listening to.

Further, impact is what matters. If I step on your foot, I apologize, regardless of whether or not it was intentional, because it?s the right thing to do. If someone tells you ?that thing you?re saying is offensive or is hurting me? and you say ?I didn?t mean it,? and then keep right on doing it, what does it say to the person on the receiving end of it? All anyone that is being ?blamed,? as you put it, is being asked to do is to try to do better next time. 

--
#BlackLivesMatter
____
|| \\UTGERS,  	 |---------------------------*O*---------------------------
||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
|| \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
     `'


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Nov 17 17:43:34 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Nov 2020 08:43:34 -0800
Subject: [R] Language environment
In-Reply-To: <63274208-6836-ccd2-54e6-67d19d2ab6a3@ntu.edu.tw>
References: <63274208-6836-ccd2-54e6-67d19d2ab6a3@ntu.edu.tw>
Message-ID: <8C6CD0A9-5B1F-438A-8027-C0589EB37DB5@dcn.davis.ca.us>

put it in your .Rprofile file. Read the R Installation and Administration Manusl for more info.

On November 17, 2020 5:00:06 AM PST, Steven Yen <styen at ntu.edu.tw> wrote:
>In R, I was able to set the language environment by fixing the line
>
>in file "C:\Program Files\R\R-4.0.3\etc\Rconsole", line 70 below, set 
>language to EN:
>
>language = EN
>
>In RStudio, I am not able to do that, except to include the line
>
>Sys.setenv(LANG="en");
>
>in every one of my program file. That's too much work. Any idea? Thank
>you!
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From chr|@ho|d @end|ng |rom p@yctc@org  Tue Nov 17 18:27:25 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Tue, 17 Nov 2020 17:27:25 +0000 (GMT)
Subject: [R] Inappropriate color name
In-Reply-To: <D2B0582C-E2C8-426F-AA21-9680AEBBBA42@rutgers.edu>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
 <20201117114603.00ade888@rolf-Latitude-E7470>
 <D2B0582C-E2C8-426F-AA21-9680AEBBBA42@rutgers.edu>
Message-ID: <306476811.19560713.1605634045722.JavaMail.zimbra@psyctc.org>

... and we are off topic and I'm not sure I would vote for changing the name of the colour but at the same time I have to endorse that as a brilliant, brilliant summary of the issues which ought to be a fortune candidate.  

I have cc'd in the noble Achim, maintainer of the cookies package as I seem to remember that's the correct way to make a formal nomination.

Very best all, 

Chris

----- Original Message -----
> From: "Ryan Novosielski" <novosirj at rutgers.edu>
> To: "r-help mailing list" <r-help at r-project.org>
> Cc: "Lainey Gallenberg" <laineygallenberg at gmail.com>
> Sent: Tuesday, 17 November, 2020 16:39:38
> Subject: Re: [R] Inappropriate color name

>> On Nov 16, 2020, at 5:46 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> 
>> On Tue, 17 Nov 2020 07:54:01 +1100
>> Jim Lemon <drjimlemon at gmail.com> wrote:
>> 
>>> Hi Elaine,
>>> There seems to be a popular contest to discover offence everywhere. I
>>> don't think that it does anything against racism, sexism or
>>> antidisestablishmentarianism. Words are plucked from our vast lexicon
>>> to comfort or insult our fellows depending upon the intent of the
>>> user. It is the intent that matters, not the poor word. Chasing the
>>> words wastes your time, blames those who use the words harmlessly,
>>> and gives the real offender time to find another epithet.
>> 
>> Jim:  This is superbly expressed.  I wish that I could have said
>> that! Your posting should go down in the annals of brilliant rhetoric,
>> alongside Dr. Johnson's "Letter to Lord Chesterfield".
>> 
>> cheers,
>> 
>> Rolf
> 
> You know, I wouldn?t have continued this thread (which has now wandered off
> topic from the original somewhat-more-technical question), but I feel now like
> it?s necessary to do so (and only fair, if anyone is considering moderating me
> after letting these posts by):
> 
> That is a view commonly held by white people, and even more overwhelmingly by
> white men. Our field is already not as diverse as it should be for a variety of
> reasons, and this ?pretending no one else on earth exists? kind of stuff is at
> least some part of the reason. The question at issue here aside, white men
> complaining about people finding racism or sexism everywhere they look doesn?t
> pass the sniff test. Most or all of these things that people are reporting as
> offensive are being reported by people you?re clearly not listening to.
> 
> Further, impact is what matters. If I step on your foot, I apologize, regardless
> of whether or not it was intentional, because it?s the right thing to do. If
> someone tells you ?that thing you?re saying is offensive or is hurting me? and
> you say ?I didn?t mean it,? and then keep right on doing it, what does it say
> to the person on the receiving end of it? All anyone that is being ?blamed,? as
> you put it, is being asked to do is to try to do better next time.
> 
> --
> #BlackLivesMatter
> ____
>|| \\UTGERS,  	 |---------------------------*O*---------------------------
>||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
>|| \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
>||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
>     `'
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From DOg|e @end|ng |rom north|@nd@edu  Tue Nov 17 19:56:30 2020
From: DOg|e @end|ng |rom north|@nd@edu (Derek Ogle)
Date: Tue, 17 Nov 2020 18:56:30 +0000
Subject: [R] Inappropriate color name
In-Reply-To: <D2B0582C-E2C8-426F-AA21-9680AEBBBA42@rutgers.edu>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
 <CA+8X3fUJNMORgCmDM4Nx6uj35rnGW0WdxxJWatOp+im+pPuZ4w@mail.gmail.com>
 <20201117114603.00ade888@rolf-Latitude-E7470>
 <D2B0582C-E2C8-426F-AA21-9680AEBBBA42@rutgers.edu>
Message-ID: <4db6f3ed92aa4cfd94acc97343706918@northland.edu>

I agree with, support, and appreciate this message. Thank you Ryan for the courage to write this, and Lainey for your courage to persist with your question.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Ryan Novosielski
Sent: Tuesday, November 17, 2020 9:40 AM
To: r-help mailing list <r-help at r-project.org>
Cc: Lainey Gallenberg <laineygallenberg at gmail.com>
Subject: Re: [R] Inappropriate color name

*** [EXTERNAL EMAIL] <a href="https://www.northland.edu/about/external-email">What does this mean?</a> ***

> On Nov 16, 2020, at 5:46 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On Tue, 17 Nov 2020 07:54:01 +1100
> Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi Elaine,
>> There seems to be a popular contest to discover offence everywhere. I 
>> don't think that it does anything against racism, sexism or 
>> antidisestablishmentarianism. Words are plucked from our vast lexicon 
>> to comfort or insult our fellows depending upon the intent of the 
>> user. It is the intent that matters, not the poor word. Chasing the 
>> words wastes your time, blames those who use the words harmlessly, 
>> and gives the real offender time to find another epithet.
> 
> Jim:  This is superbly expressed.  I wish that I could have said that! 
> Your posting should go down in the annals of brilliant rhetoric, 
> alongside Dr. Johnson's "Letter to Lord Chesterfield".
> 
> cheers,
> 
> Rolf

You know, I wouldn?t have continued this thread (which has now wandered off topic from the original somewhat-more-technical question), but I feel now like it?s necessary to do so (and only fair, if anyone is considering moderating me after letting these posts by):

That is a view commonly held by white people, and even more overwhelmingly by white men. Our field is already not as diverse as it should be for a variety of reasons, and this ?pretending no one else on earth exists? kind of stuff is at least some part of the reason. The question at issue here aside, white men complaining about people finding racism or sexism everywhere they look doesn?t pass the sniff test. Most or all of these things that people are reporting as offensive are being reported by people you?re clearly not listening to.

Further, impact is what matters. If I step on your foot, I apologize, regardless of whether or not it was intentional, because it?s the right thing to do. If someone tells you ?that thing you?re saying is offensive or is hurting me? and you say ?I didn?t mean it,? and then keep right on doing it, what does it say to the person on the receiving end of it? All anyone that is being ?blamed,? as you put it, is being asked to do is to try to do better next time. 

--
#BlackLivesMatter
____
|| \\UTGERS,  	 |---------------------------*O*---------------------------
||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
|| \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
     `'

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bhh @end|ng |rom x@4@||@n|  Tue Nov 17 20:34:12 2020
From: bhh @end|ng |rom x@4@||@n| (Berend Hasselman)
Date: Tue, 17 Nov 2020 20:34:12 +0100
Subject: [R] 
 Using multiroot for root solution for a matrix based function
In-Reply-To: <CA+Dt5-wXsSne+9wZG2VFi2pRvUT0_ULu=TAwE=PrhhckYQrRLg@mail.gmail.com>
References: <CA+Dt5-wXsSne+9wZG2VFi2pRvUT0_ULu=TAwE=PrhhckYQrRLg@mail.gmail.com>
Message-ID: <76F943E8-9DAF-4785-B807-CB5F1EA39645@xs4all.nl>


Forgot to send this to R-help.


You have already asked this question  on stackoverflow (https://stackoverflow.com/questions/64835251/how-can-i-use-multiroot-with-matrix-based-functions-in-r/64835725#64835725).

In a comment  G. Grothendieck provided an answer. Have you tried it?

Define a function f.mod that converts a vector to a matrix like this

f.mod <-  function(q,m) f(matrix(q,2),m)

Then try multiroot with an appropriate starting value

q.start <- rep(0,4)
multiroot(f.mod, q.start, parms=m)

Finally convert the answer provided by multiroot to a matrix.

You can also use other solvers. Such as nleqslv like this

library(nleqslv)
nleqslv(q.start,f.mod,m=m) # uses Broyden
nleqslv(q.start,f.mod,m=m,method="Newton") # uses Newton

The second call of nleqslv uses less iterations that multiroot.
You can check the answers.


Berend Hasselman

> On 17 Nov 2020, at 09:19, quinter sam <qsam0000 at gmail.com> wrote:
> 
> I have a function which is actually an output of another function and I
> therefore cannot change it. I am trying to use *multiroot * from
> package *rootSolve
> * to compute the roots of the function but its not working at all. Is there
> something I am not seeing or is there another alternative that is based on
> Newton-Raphson technique?
> 
> library(rootSolve)
> f <- function(q,m){
> c(F1 = 12 * ((exp(q[, 1]) * m[1])/(exp(q[, 1]) * m[1] + exp(q[, 2]) * m[2]
> + m[3])) - c(1,2),
> F2 = 12 * ((exp(q[, 2]) * m[2])/(exp(q[, 1]) * m[1] + exp(q[, 2]) * m[2] +
> m[3])) - c(3,3))
> }
> m = c(0.1,0.2,0.7)
> 
> I am trying to solve for *q* and from based on the given m, I expect
> something like this;
> q <- matrix(c(-0.1335314,0.6931472,0.2719337,0.4054651), nrow=2)
> 
> How would I call the multiroot for the function f to hopefully get the
> above results. I thought of using newtonRaphson from package pracma but
> that possibly only handles univariate inputs.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Tue Nov 17 21:43:08 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Tue, 17 Nov 2020 14:43:08 -0600
Subject: [R] How to pass a character string with a hyphen
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
Message-ID: <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>

R-Help

 

How does one pass a character string containing a hyphen? I have a function
that accesses an api if I hard code the object, for example

 

key_key <- "xxxx-yyyy" 

 

it works but when I pass the key  code to the function (say something like
key_code <- code_input)  it returns only xxxx. So R is seeing a string with
a negative operator I'm assuming

 

Jeff


	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Tue Nov 17 22:00:07 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Tue, 17 Nov 2020 21:00:07 +0000
Subject: [R] How to pass a character string with a hyphen
In-Reply-To: <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
Message-ID: <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>

tmp <- function(s) {
  return(str(s))
}
key <- "xxxx-yyyy"
tmp(key)

#  chr "xxxx-yyyy"

... works for me.

Reprex?

Cheers,
Boris


From m||net@ @end|ng |rom tut@@|o  Tue Nov 17 22:00:54 2020
From: m||net@ @end|ng |rom tut@@|o (T. A. Milne)
Date: Tue, 17 Nov 2020 22:00:54 +0100 (CET)
Subject: [R] Inappropriate color name
Message-ID: <MMMyP2m--3-2@tuta.io>


Apologies to the list for continuing a thread which is clearly off-topic.? However, contacting the maintainer of an R package to complain about this specific color name seems ill-considered.

1)? The name "indian red" is a part of widely-used color schemes everywhere, not just in R.? It's the color defined as:

"The color indianred / Indian red with hexadecimal color code #cd5c5c is a shade of red. In the RGB color model #cd5c5c is comprised of 80.39% red, 36.08% green and 36.08% blue. In the HSL color space #cd5c5c has a hue of 0? (degrees), 53% saturation and 58% lightness. This color has an approximate wavelength of 611.37 nm."

https://encycolorpedia.com/cd5c5c


2)? The "indian" in the color name refers to ferric oxide, historically sourced from India.? Per Wikipedia:

"The name Indian red derives from the red laterite soil found in India, which is composed of naturally occurring iron oxides.[citation needed] The first recorded use of Indian red as a color term in English was in 1672.[3"

https://en.wikipedia.org/wiki/Indian_red_(color)


Given the name refers to the locus of the ferric oxide source, It isn't obvious that any particular group should be offended by the name.


--? T. Arthur Milne


> On Nov 16, 2020, at 5:46 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On Tue, 17 Nov 2020 07:54:01 +1100
> Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
>> Hi Elaine,
>> There seems to be a popular contest to discover offence everywhere. I
>> don't think that it does anything against racism, sexism or
>> antidisestablishmentarianism. Words are plucked from our vast lexicon
>> to comfort or insult our fellows depending upon the intent of the
>> user. It is the intent that matters, not the poor word. Chasing the
>> words wastes your time, blames those who use the words harmlessly,
>> and gives the real offender time to find another epithet.
>>
> Jim:? This is superbly expressed.? I wish that I could have said
> that! Your posting should go down in the annals of brilliant rhetoric,
> alongside Dr. Johnson's "Letter to Lord Chesterfield".
>
> cheers,
>
> Rolf
>
You know, I wouldn?t have continued this thread (which has now wandered off topic from the original somewhat-more-technical question), but I feel now like it?s necessary to do so (and only fair, if anyone is considering moderating me after letting these posts by):

That is a view commonly held by white people, and even more overwhelmingly by white men. Our field is already not as diverse as it should be for a variety of reasons, and this ?pretending no one else on earth exists? kind of stuff is at least some part of the reason. The question at issue here aside, white men complaining about people finding racism or sexism everywhere they look doesn?t pass the sniff test. Most or all of these things that people are reporting as offensive are being reported by people you?re clearly not listening to.

Further, impact is what matters. If I step on your foot, I apologize, regardless of whether or not it was intentional, because it?s the right thing to do. If someone tells you ?that thing you?re saying is offensive or is hurting me? and you say ?I didn?t mean it,? and then keep right on doing it, what does it say to the person on the receiving end of it? All anyone that is being ?blamed,? as you put it, is being asked to do is to try to do better next time.

--
#BlackLivesMatter
____
|| \\UTGERS,? 	 |---------------------------*O*---------------------------
||_// the State	 |???????? Ryan Novosielski - novosirj at rutgers.edu
|| \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
||? \\??? of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
???? `'

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From twoo|m@n @end|ng |rom ont@rgettek@com  Tue Nov 17 22:10:26 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Tue, 17 Nov 2020 16:10:26 -0500
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
Message-ID: <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>

Hi everyone.  I have a dataframe that is a collection of Vendor IDs  
plus a bank account number for each vendor. I'm trying to find a way  
to count the number of duplicate bank accounts that occur in more than  
one unique Vendor_ID, and then assign the count value for each row in  
the dataframe in a new variable.

I can do a count of bank accounts that occur within the same vendor  
using dplyr and group_by and count, but I can't figure out a way to  
count duplicates among multiple Vendor_IDs.


Dataframe example code:


#Create a sample data frame:

set.seed(1)

Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =  
sample(1:10000))




Thanks in advance for any help.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Tue Nov 17 22:13:44 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Tue, 17 Nov 2020 15:13:44 -0600
Subject: [R] How to pass a character string with a hyphen
In-Reply-To: <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
Message-ID: <000901d6bd26$88c7ca10$9a575e30$@sbcglobal.net>

Boris

Yes in that case it works as you have assigned a character string to key. My
problem is I'm taking a string input from a shiny app and when I run the
function it only sees xxxx.  How to assign xxxx-yyyy to a character string.

Jeff
-----Original Message-----
From: Boris Steipe <boris.steipe at utoronto.ca> 
Sent: Tuesday, November 17, 2020 3:00 PM
To: reichmanj at sbcglobal.net
Cc: r-help at r-project.org
Subject: Re: [R] How to pass a character string with a hyphen

tmp <- function(s) {
  return(str(s))
}
key <- "xxxx-yyyy"
tmp(key)

#  chr "xxxx-yyyy"

.. works for me.

Reprex?

Cheers,
Boris


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Nov 17 22:16:45 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 17 Nov 2020 16:16:45 -0500
Subject: [R] How to pass a character string with a hyphen
In-Reply-To: <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
Message-ID: <39354FEF-64C9-455F-A299-6FD43F365233@me.com>

Hi,

You might want to look at ?shQuote, which wraps text in single quotes, if the source text does not include them, or double quotes otherwise, as might be used in a shell setting, where you are passing arguments that may have spaces or other characters that may be evaluated.

My guess is that the API that you are passing the character vector to may be parsing/evaluating the '-' and only seeing the first part of the passed value.

So, for example:

> shQuote("xxxx-yyyy")
[1] "'xxxx-yyyy'"


See if that works.

Regards,

Marc Schwartz


> On Nov 17, 2020, at 3:43 PM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> 
> R-Help
> 
> How does one pass a character string containing a hyphen? I have a function
> that accesses an api if I hard code the object, for example
> 
> key_key <- "xxxx-yyyy" 
> 
> it works but when I pass the key  code to the function (say something like
> key_code <- code_input)  it returns only xxxx. So R is seeing a string with
> a negative operator I'm assuming
> 
> Jeff
> 


From mm@|ten @end|ng |rom gm@||@com  Tue Nov 17 22:25:04 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Tue, 17 Nov 2020 16:25:04 -0500
Subject: [R] Inappropriate color name
In-Reply-To: <MMMyP2m--3-2@tuta.io>
References: <MMMyP2m--3-2@tuta.io>
Message-ID: <CANOgrHZe=nWmbxpxsLvhAnVahMFFfBkqfKEZkFStgqOJPrxccQ@mail.gmail.com>

What about just amputating the final "n?"

"Indian" might mean one of two things, but "India" is pretty distinct.



On Tue, Nov 17, 2020 at 4:10 PM T. A. Milne via R-help <r-help at r-project.org>
wrote:

>
> Apologies to the list for continuing a thread which is clearly off-topic.
> However, contacting the maintainer of an R package to complain about this
> specific color name seems ill-considered.
>
> 1)  The name "indian red" is a part of widely-used color schemes
> everywhere, not just in R.  It's the color defined as:
>
> "The color indianred / Indian red with hexadecimal color code #cd5c5c is a
> shade of red. In the RGB color model #cd5c5c is comprised of 80.39% red,
> 36.08% green and 36.08% blue. In the HSL color space #cd5c5c has a hue of
> 0? (degrees), 53% saturation and 58% lightness. This color has an
> approximate wavelength of 611.37 nm."
>
> https://encycolorpedia.com/cd5c5c
>
>
> 2)  The "indian" in the color name refers to ferric oxide, historically
> sourced from India.  Per Wikipedia:
>
> "The name Indian red derives from the red laterite soil found in India,
> which is composed of naturally occurring iron oxides.[citation needed] The
> first recorded use of Indian red as a color term in English was in 1672.[3"
>
> https://en.wikipedia.org/wiki/Indian_red_(color)
>
>
> Given the name refers to the locus of the ferric oxide source, It isn't
> obvious that any particular group should be offended by the name.
>
>
> --  T. Arthur Milne
>
>
> > On Nov 16, 2020, at 5:46 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> >
> > On Tue, 17 Nov 2020 07:54:01 +1100
> > Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >
> >> Hi Elaine,
> >> There seems to be a popular contest to discover offence everywhere. I
> >> don't think that it does anything against racism, sexism or
> >> antidisestablishmentarianism. Words are plucked from our vast lexicon
> >> to comfort or insult our fellows depending upon the intent of the
> >> user. It is the intent that matters, not the poor word. Chasing the
> >> words wastes your time, blames those who use the words harmlessly,
> >> and gives the real offender time to find another epithet.
> >>
> > Jim:  This is superbly expressed.  I wish that I could have said
> > that! Your posting should go down in the annals of brilliant rhetoric,
> > alongside Dr. Johnson's "Letter to Lord Chesterfield".
> >
> > cheers,
> >
> > Rolf
> >
> You know, I wouldn?t have continued this thread (which has now wandered
> off topic from the original somewhat-more-technical question), but I feel
> now like it?s necessary to do so (and only fair, if anyone is considering
> moderating me after letting these posts by):
>
> That is a view commonly held by white people, and even more overwhelmingly
> by white men. Our field is already not as diverse as it should be for a
> variety of reasons, and this ?pretending no one else on earth exists? kind
> of stuff is at least some part of the reason. The question at issue here
> aside, white men complaining about people finding racism or sexism
> everywhere they look doesn?t pass the sniff test. Most or all of these
> things that people are reporting as offensive are being reported by people
> you?re clearly not listening to.
>
> Further, impact is what matters. If I step on your foot, I apologize,
> regardless of whether or not it was intentional, because it?s the right
> thing to do. If someone tells you ?that thing you?re saying is offensive or
> is hurting me? and you say ?I didn?t mean it,? and then keep right on doing
> it, what does it say to the person on the receiving end of it? All anyone
> that is being ?blamed,? as you put it, is being asked to do is to try to do
> better next time.
>
> --
> #BlackLivesMatter
> ____
> || \\UTGERS,     |---------------------------*O*---------------------------
> ||_// the State  |         Ryan Novosielski - novosirj at rutgers.edu
> || \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
> ||  \\    of NJ  | Office of Advanced Research Computing - MSB C630, Newark
>      `'
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bobby@kn|ght @end|ng |rom gm@||@com  Tue Nov 17 22:56:23 2020
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Tue, 17 Nov 2020 15:56:23 -0600
Subject: [R] How to pass a character string with a hyphen
In-Reply-To: <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
Message-ID: <CAKBFG3aTxfHO3QEDV0uuJRwSuMZjitq-6zGyRVowrc6kYG0Snw@mail.gmail.com>

Strip the left characters and strip the right characters into their own
variables using one of the methods that can do that.  Then pass it using
something like paste(left, "-", right).

On Tue, Nov 17, 2020, 2:43 PM Jeff Reichman <reichmanj at sbcglobal.net> wrote:

> R-Help
>
>
>
> How does one pass a character string containing a hyphen? I have a function
> that accesses an api if I hard code the object, for example
>
>
>
> key_key <- "xxxx-yyyy"
>
>
>
> it works but when I pass the key  code to the function (say something like
> key_code <- code_input)  it returns only xxxx. So R is seeing a string with
> a negative operator I'm assuming
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Tue Nov 17 22:57:55 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Tue, 17 Nov 2020 15:57:55 -0600
Subject: [R] Inappropriate color name
In-Reply-To: <CANOgrHZe=nWmbxpxsLvhAnVahMFFfBkqfKEZkFStgqOJPrxccQ@mail.gmail.com>
References: <MMMyP2m--3-2@tuta.io>
 <CANOgrHZe=nWmbxpxsLvhAnVahMFFfBkqfKEZkFStgqOJPrxccQ@mail.gmail.com>
Message-ID: <345a2514-21b8-6128-6e1f-2701f9e45525@effectivedefense.org>

	  Might it be appropriate to raise that question on the Talk page 
associated with the Wikipedia article on "Indian red (color)":


https://en.wikipedia.org/wiki/Indian_red_(color)


	  Many Wikimedian are generally sympathetic to discussions of
political correctness and similar topics.  If the name of that article 
were changed, then it should be a lot easier to pursue a similar name 
change elsewhere.


	  Spencer Graves


On 2020-11-17 15:25, Mitchell Maltenfort wrote:
> What about just amputating the final "n?"
> 
> "Indian" might mean one of two things, but "India" is pretty distinct.
> 
> 
> 
> On Tue, Nov 17, 2020 at 4:10 PM T. A. Milne via R-help <r-help at r-project.org>
> wrote:
> 
>>
>> Apologies to the list for continuing a thread which is clearly off-topic.
>> However, contacting the maintainer of an R package to complain about this
>> specific color name seems ill-considered.
>>
>> 1)  The name "indian red" is a part of widely-used color schemes
>> everywhere, not just in R.  It's the color defined as:
>>
>> "The color indianred / Indian red with hexadecimal color code #cd5c5c is a
>> shade of red. In the RGB color model #cd5c5c is comprised of 80.39% red,
>> 36.08% green and 36.08% blue. In the HSL color space #cd5c5c has a hue of
>> 0? (degrees), 53% saturation and 58% lightness. This color has an
>> approximate wavelength of 611.37 nm."
>>
>> https://encycolorpedia.com/cd5c5c
>>
>>
>> 2)  The "indian" in the color name refers to ferric oxide, historically
>> sourced from India.  Per Wikipedia:
>>
>> "The name Indian red derives from the red laterite soil found in India,
>> which is composed of naturally occurring iron oxides.[citation needed] The
>> first recorded use of Indian red as a color term in English was in 1672.[3"
>>
>> https://en.wikipedia.org/wiki/Indian_red_(color)
>>
>>
>> Given the name refers to the locus of the ferric oxide source, It isn't
>> obvious that any particular group should be offended by the name.
>>
>>
>> --  T. Arthur Milne
>>
>>
>>> On Nov 16, 2020, at 5:46 PM, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>>
>>> On Tue, 17 Nov 2020 07:54:01 +1100
>>> Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>>
>>>> Hi Elaine,
>>>> There seems to be a popular contest to discover offence everywhere. I
>>>> don't think that it does anything against racism, sexism or
>>>> antidisestablishmentarianism. Words are plucked from our vast lexicon
>>>> to comfort or insult our fellows depending upon the intent of the
>>>> user. It is the intent that matters, not the poor word. Chasing the
>>>> words wastes your time, blames those who use the words harmlessly,
>>>> and gives the real offender time to find another epithet.
>>>>
>>> Jim:  This is superbly expressed.  I wish that I could have said
>>> that! Your posting should go down in the annals of brilliant rhetoric,
>>> alongside Dr. Johnson's "Letter to Lord Chesterfield".
>>>
>>> cheers,
>>>
>>> Rolf
>>>
>> You know, I wouldn?t have continued this thread (which has now wandered
>> off topic from the original somewhat-more-technical question), but I feel
>> now like it?s necessary to do so (and only fair, if anyone is considering
>> moderating me after letting these posts by):
>>
>> That is a view commonly held by white people, and even more overwhelmingly
>> by white men. Our field is already not as diverse as it should be for a
>> variety of reasons, and this ?pretending no one else on earth exists? kind
>> of stuff is at least some part of the reason. The question at issue here
>> aside, white men complaining about people finding racism or sexism
>> everywhere they look doesn?t pass the sniff test. Most or all of these
>> things that people are reporting as offensive are being reported by people
>> you?re clearly not listening to.
>>
>> Further, impact is what matters. If I step on your foot, I apologize,
>> regardless of whether or not it was intentional, because it?s the right
>> thing to do. If someone tells you ?that thing you?re saying is offensive or
>> is hurting me? and you say ?I didn?t mean it,? and then keep right on doing
>> it, what does it say to the person on the receiving end of it? All anyone
>> that is being ?blamed,? as you put it, is being asked to do is to try to do
>> better next time.
>>
>> --
>> #BlackLivesMatter
>> ____
>> || \\UTGERS,     |---------------------------*O*---------------------------
>> ||_// the State  |         Ryan Novosielski - novosirj at rutgers.edu
>> || \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
>> ||  \\    of NJ  | Office of Advanced Research Computing - MSB C630, Newark
>>       `'
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bor|@@@te|pe @end|ng |rom utoronto@c@  Tue Nov 17 23:11:07 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Tue, 17 Nov 2020 22:11:07 +0000
Subject: [R] Inappropriate color name
In-Reply-To: <345a2514-21b8-6128-6e1f-2701f9e45525@effectivedefense.org>
References: <MMMyP2m--3-2@tuta.io>
 <CANOgrHZe=nWmbxpxsLvhAnVahMFFfBkqfKEZkFStgqOJPrxccQ@mail.gmail.com>
 <345a2514-21b8-6128-6e1f-2701f9e45525@effectivedefense.org>
Message-ID: <C2AEFFF8-96B6-4A10-B298-1B87CBDAF103@utoronto.ca>

I would not be optimistic about a change - the naming scheme is a community standard, and the community is VERY large; this scheme is employed in thousands of software assets. Ultimately it goes back to X11 color naming in the eighties. See: https://en.wikipedia.org/wiki/X11_color_names for details on how it was created and to get a sense where else the scheme and its derivatives are being used. 

AFAIAC R is simply following standard usage, which is generally a Good Thing - except for the inertia this creates to maintain outdated standards - at times.


B.


> On 2020-11-18, at 07:57, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
> 
> EXTERNAL EMAIL:  Treat content with extra caution.
> 
>         Might it be appropriate to raise that question on the Talk page
> associated with the Wikipedia article on "Indian red (color)":
> 
> 
> https://en.wikipedia.org/wiki/Indian_red_(color)
> 
> 
>         Many Wikimedian are generally sympathetic to discussions of
> political correctness and similar topics.  If the name of that article
> were changed, then it should be a lot easier to pursue a similar name
> change elsewhere.
> 
> 
>         Spencer Graves
> 
> 
> On 2020-11-17 15:25, Mitchell Maltenfort wrote:
>> What about just amputating the final "n?"
>> 
>> "Indian" might mean one of two things, but "India" is pretty distinct.
>> 
>> 
>> 
>> On Tue, Nov 17, 2020 at 4:10 PM T. A. Milne via R-help <r-help at r-project.org>
>> wrote:
>> 
>>> 
>>> Apologies to the list for continuing a thread which is clearly off-topic.
>>> However, contacting the maintainer of an R package to complain about this
>>> specific color name seems ill-considered.
>>> 
>>> 1)  The name "indian red" is a part of widely-used color schemes
>>> everywhere, not just in R.  It's the color defined as:
>>> 
>>> "The color indianred / Indian red with hexadecimal color code #cd5c5c is a
>>> shade of red. In the RGB color model #cd5c5c is comprised of 80.39% red,
>>> 36.08% green and 36.08% blue. In the HSL color space #cd5c5c has a hue of
>>> 0? (degrees), 53% saturation and 58% lightness. This color has an
>>> approximate wavelength of 611.37 nm."
>>> 
>>> https://encycolorpedia.com/cd5c5c
>>> 
>>> 
>>> 2)  The "indian" in the color name refers to ferric oxide, historically
>>> sourced from India.  Per Wikipedia:
>>> 
>>> "The name Indian red derives from the red laterite soil found in India,
>>> which is composed of naturally occurring iron oxides.[citation needed] The
>>> first recorded use of Indian red as a color term in English was in 1672.[3"
>>> 
>>> https://en.wikipedia.org/wiki/Indian_red_(color)
>>> 
>>> 
>>> Given the name refers to the locus of the ferric oxide source, It isn't
>>> obvious that any particular group should be offended by the name.
>>> 
>>> 
>>> --  T. Arthur Milne
>>> 
>>> 
>>>> On Nov 16, 2020, at 5:46 PM, Rolf Turner <r.turner at auckland.ac.nz>
>>> wrote:
>>>> 
>>>> On Tue, 17 Nov 2020 07:54:01 +1100
>>>> Jim Lemon <drjimlemon at gmail.com> wrote:
>>>> 
>>>> 
>>>>> Hi Elaine,
>>>>> There seems to be a popular contest to discover offence everywhere. I
>>>>> don't think that it does anything against racism, sexism or
>>>>> antidisestablishmentarianism. Words are plucked from our vast lexicon
>>>>> to comfort or insult our fellows depending upon the intent of the
>>>>> user. It is the intent that matters, not the poor word. Chasing the
>>>>> words wastes your time, blames those who use the words harmlessly,
>>>>> and gives the real offender time to find another epithet.
>>>>> 
>>>> Jim:  This is superbly expressed.  I wish that I could have said
>>>> that! Your posting should go down in the annals of brilliant rhetoric,
>>>> alongside Dr. Johnson's "Letter to Lord Chesterfield".
>>>> 
>>>> cheers,
>>>> 
>>>> Rolf
>>>> 
>>> You know, I wouldn?t have continued this thread (which has now wandered
>>> off topic from the original somewhat-more-technical question), but I feel
>>> now like it?s necessary to do so (and only fair, if anyone is considering
>>> moderating me after letting these posts by):
>>> 
>>> That is a view commonly held by white people, and even more overwhelmingly
>>> by white men. Our field is already not as diverse as it should be for a
>>> variety of reasons, and this ?pretending no one else on earth exists? kind
>>> of stuff is at least some part of the reason. The question at issue here
>>> aside, white men complaining about people finding racism or sexism
>>> everywhere they look doesn?t pass the sniff test. Most or all of these
>>> things that people are reporting as offensive are being reported by people
>>> you?re clearly not listening to.
>>> 
>>> Further, impact is what matters. If I step on your foot, I apologize,
>>> regardless of whether or not it was intentional, because it?s the right
>>> thing to do. If someone tells you ?that thing you?re saying is offensive or
>>> is hurting me? and you say ?I didn?t mean it,? and then keep right on doing
>>> it, what does it say to the person on the receiving end of it? All anyone
>>> that is being ?blamed,? as you put it, is being asked to do is to try to do
>>> better next time.
>>> 
>>> --
>>> #BlackLivesMatter
>>> ____
>>> || \\UTGERS,     |---------------------------*O*---------------------------
>>> ||_// the State  |         Ryan Novosielski - novosirj at rutgers.edu
>>> || \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
>>> ||  \\    of NJ  | Office of Advanced Research Computing - MSB C630, Newark
>>>      `'
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Tue Nov 17 23:17:40 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Tue, 17 Nov 2020 17:17:40 -0500
Subject: [R] Inappropriate color name
In-Reply-To: <345a2514-21b8-6128-6e1f-2701f9e45525@effectivedefense.org>
References: <345a2514-21b8-6128-6e1f-2701f9e45525@effectivedefense.org>
Message-ID: <3B216B35-6770-4C07-A9CB-DF8AE316FA9A@comcast.net>

If the word Indian refers to India, the place of origin for the color, then referring to it by this name gives an acknowledgement to this fact and I would have assumed such acknowledgement  is a positive thing.

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Nov 17, 2020, at 4:58 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
> 
> ?      Might it be appropriate to raise that question on the Talk page associated with the Wikipedia article on "Indian red (color)":
> 
> 
> https://en.wikipedia.org/wiki/Indian_red_(color)
> 
> 
>      Many Wikimedian are generally sympathetic to discussions of
> political correctness and similar topics.  If the name of that article were changed, then it should be a lot easier to pursue a similar name change elsewhere.
> 
> 
>      Spencer Graves
> 
> 
>> On 2020-11-17 15:25, Mitchell Maltenfort wrote:
>> What about just amputating the final "n?"
>> "Indian" might mean one of two things, but "India" is pretty distinct.
>>> On Tue, Nov 17, 2020 at 4:10 PM T. A. Milne via R-help <r-help at r-project.org>
>>> wrote:
>>> 
>>> Apologies to the list for continuing a thread which is clearly off-topic.
>>> However, contacting the maintainer of an R package to complain about this
>>> specific color name seems ill-considered.
>>> 
>>> 1)  The name "indian red" is a part of widely-used color schemes
>>> everywhere, not just in R.  It's the color defined as:
>>> 
>>> "The color indianred / Indian red with hexadecimal color code #cd5c5c is a
>>> shade of red. In the RGB color model #cd5c5c is comprised of 80.39% red,
>>> 36.08% green and 36.08% blue. In the HSL color space #cd5c5c has a hue of
>>> 0? (degrees), 53% saturation and 58% lightness. This color has an
>>> approximate wavelength of 611.37 nm."
>>> 
>>> https://encycolorpedia.com/cd5c5c
>>> 
>>> 
>>> 2)  The "indian" in the color name refers to ferric oxide, historically
>>> sourced from India.  Per Wikipedia:
>>> 
>>> "The name Indian red derives from the red laterite soil found in India,
>>> which is composed of naturally occurring iron oxides.[citation needed] The
>>> first recorded use of Indian red as a color term in English was in 1672.[3"
>>> 
>>> https://en.wikipedia.org/wiki/Indian_red_(color)
>>> 
>>> 
>>> Given the name refers to the locus of the ferric oxide source, It isn't
>>> obvious that any particular group should be offended by the name.
>>> 
>>> 
>>> --  T. Arthur Milne
>>> 
>>> 
>>>> On Nov 16, 2020, at 5:46 PM, Rolf Turner <r.turner at auckland.ac.nz>
>>> wrote:
>>>> 
>>>> On Tue, 17 Nov 2020 07:54:01 +1100
>>>> Jim Lemon <drjimlemon at gmail.com> wrote:
>>>> 
>>>> 
>>>>> Hi Elaine,
>>>>> There seems to be a popular contest to discover offence everywhere. I
>>>>> don't think that it does anything against racism, sexism or
>>>>> antidisestablishmentarianism. Words are plucked from our vast lexicon
>>>>> to comfort or insult our fellows depending upon the intent of the
>>>>> user. It is the intent that matters, not the poor word. Chasing the
>>>>> words wastes your time, blames those who use the words harmlessly,
>>>>> and gives the real offender time to find another epithet.
>>>>> 
>>>> Jim:  This is superbly expressed.  I wish that I could have said
>>>> that! Your posting should go down in the annals of brilliant rhetoric,
>>>> alongside Dr. Johnson's "Letter to Lord Chesterfield".
>>>> 
>>>> cheers,
>>>> 
>>>> Rolf
>>>> 
>>> You know, I wouldn?t have continued this thread (which has now wandered
>>> off topic from the original somewhat-more-technical question), but I feel
>>> now like it?s necessary to do so (and only fair, if anyone is considering
>>> moderating me after letting these posts by):
>>> 
>>> That is a view commonly held by white people, and even more overwhelmingly
>>> by white men. Our field is already not as diverse as it should be for a
>>> variety of reasons, and this ?pretending no one else on earth exists? kind
>>> of stuff is at least some part of the reason. The question at issue here
>>> aside, white men complaining about people finding racism or sexism
>>> everywhere they look doesn?t pass the sniff test. Most or all of these
>>> things that people are reporting as offensive are being reported by people
>>> you?re clearly not listening to.
>>> 
>>> Further, impact is what matters. If I step on your foot, I apologize,
>>> regardless of whether or not it was intentional, because it?s the right
>>> thing to do. If someone tells you ?that thing you?re saying is offensive or
>>> is hurting me? and you say ?I didn?t mean it,? and then keep right on doing
>>> it, what does it say to the person on the receiving end of it? All anyone
>>> that is being ?blamed,? as you put it, is being asked to do is to try to do
>>> better next time.
>>> 
>>> --
>>> #BlackLivesMatter
>>> ____
>>> || \\UTGERS,     |---------------------------*O*---------------------------
>>> ||_// the State  |         Ryan Novosielski - novosirj at rutgers.edu
>>> || \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
>>> ||  \\    of NJ  | Office of Advanced Research Computing - MSB C630, Newark
>>>      `'
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>    [[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Nov 17 23:22:48 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Nov 2020 14:22:48 -0800
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
Message-ID: <CAGxFJbQ0ieC3wpYtSe6-wqgNQF=o39ciMdxc+YpU8pZoyuc97w@mail.gmail.com>

Inline.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Nov 17, 2020 at 1:20 PM Tom Woolman <twoolman at ontargettek.com>
wrote:

> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
> plus a bank account number for each vendor.


I interpret this as: "all vendors are unique and each vendor has a single
bank account." Is that correct?


> I'm trying to find a way
> to count the number of duplicate bank accounts that occur in more than
> one unique Vendor_ID,


The following makes no sense to me, as each row is a unique vendor and has
only one bank account.

> and then assign the count value for each row in
> the dataframe in a new variable.
>
> I can do a count of bank accounts that occur within the same vendor
>
using dplyr and group_by and count, but I can't figure out a way to
> count duplicates among multiple Vendor_IDs.
>
I interpret this to mean that you want to count vendor ID's by account .
With only one account per vendor
this is trivial; e.g.

set.seed(22)
d1 <- data.frame(id = sample(1:30),
      account = sample(1:20,30, replace = TRUE))

table(d1$account)

## gives
 1  2  3  6  7  8  9 10 11 13 15 16 17 18 19 20
 3  1  2  1  1  1  1  1  4  3  1  2  1  3  2  3

Note that AFAICS your example is useless, as it gives the same number of
different account numbers as ID's, so no duplication can occur.

As my interpretations are likely incorrect and this is not what you mean
nor want, either clarify your meaning and provide a useful **minimal**
example; or wait for a reply from someone with a better understanding than
I.

Cheers,
Bert





>
> Dataframe example code:
>
>
> #Create a sample data frame:
>
> set.seed(1)
>
> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
> sample(1:10000))
>
>
>
>
> Thanks in advance for any help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Nov 18 00:01:03 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 17 Nov 2020 15:01:03 -0800
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
Message-ID: <CAHqSRuT0=-b6W+WXZc49eqq_OPrgemwf72UR=WMvsO88JN=Z4Q@mail.gmail.com>

What should the result be for
  Data1 <- data.frame(Vendor=c("V1","V2","V3","V4"),
Account=c("A1","A2","A2","A2"))
?

Must each vendor have only one account?  If not, what should the result be
for
   Data2 <- data.frame(Vendor=c("V1","V2","V3","V1","V4","V2"),
Account=c("A1","A2","A2","A2","A3","A4"))
?

-Bill

On Tue, Nov 17, 2020 at 1:20 PM Tom Woolman <twoolman at ontargettek.com>
wrote:

> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
> plus a bank account number for each vendor. I'm trying to find a way
> to count the number of duplicate bank accounts that occur in more than
> one unique Vendor_ID, and then assign the count value for each row in
> the dataframe in a new variable.
>
> I can do a count of bank accounts that occur within the same vendor
> using dplyr and group_by and count, but I can't figure out a way to
> count duplicates among multiple Vendor_IDs.
>
>
> Dataframe example code:
>
>
> #Create a sample data frame:
>
> set.seed(1)
>
> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
> sample(1:10000))
>
>
>
>
> Thanks in advance for any help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Nov 18 00:29:39 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Tue, 17 Nov 2020 18:29:39 -0500
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <CAHqSRuT0=-b6W+WXZc49eqq_OPrgemwf72UR=WMvsO88JN=Z4Q@mail.gmail.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
 <CAHqSRuT0=-b6W+WXZc49eqq_OPrgemwf72UR=WMvsO88JN=Z4Q@mail.gmail.com>
Message-ID: <20201117182939.Horde.hu9HkerrHUlPPJkEAhAu3OX@www.ontargettek.com>

Hi Bill. Sorry to be so obtuse with the example data, I was trying  
(too hard) not to share any actual values so I just created randomized  
values for my example; of course I should have specified that the  
random values would not provide the expected problem pattern. I should  
have just used simple dummy codes as Bill Dunlap did.

So per Bill's example data for Data1, the expected (hoped for) output  
should be:

  Vendor Account Num_Vendors_Sharing_Bank_Acct
1     V1      A1      0
2     V2      A2      3
3     V3      A2      3
4     V4      A2      3


Where the new calculated variable is Num_Vendors_Sharing_Bank_Acct.  
The value is 3 for V2, V3 and V4 because they each share bank account  
A2.


Likewise, in the Data2 frame, the same logic applies:

  Vendor Account Num_Vendors_Sharing_Bank_Acct
1     V1      A1     0
2     V2      A2     3
3     V3      A2     3
4     V1      A2     3
5     V4      A3     0
6     V2      A4     0






Thanks!


Quoting Bill Dunlap <williamwdunlap at gmail.com>:

> What should the result be for
>   Data1 <- data.frame(Vendor=c("V1","V2","V3","V4"),
> Account=c("A1","A2","A2","A2"))
> ?
>
> Must each vendor have only one account?  If not, what should the result be
> for
>    Data2 <- data.frame(Vendor=c("V1","V2","V3","V1","V4","V2"),
> Account=c("A1","A2","A2","A2","A3","A4"))
> ?
>
> -Bill
>
> On Tue, Nov 17, 2020 at 1:20 PM Tom Woolman <twoolman at ontargettek.com>
> wrote:
>
>> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
>> plus a bank account number for each vendor. I'm trying to find a way
>> to count the number of duplicate bank accounts that occur in more than
>> one unique Vendor_ID, and then assign the count value for each row in
>> the dataframe in a new variable.
>>
>> I can do a count of bank accounts that occur within the same vendor
>> using dplyr and group_by and count, but I can't figure out a way to
>> count duplicates among multiple Vendor_IDs.
>>
>>
>> Dataframe example code:
>>
>>
>> #Create a sample data frame:
>>
>> set.seed(1)
>>
>> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
>> sample(1:10000))
>>
>>
>>
>>
>> Thanks in advance for any help.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 18 00:33:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Nov 2020 15:33:04 -0800
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <20201117182939.Horde.hu9HkerrHUlPPJkEAhAu3OX@www.ontargettek.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
 <CAHqSRuT0=-b6W+WXZc49eqq_OPrgemwf72UR=WMvsO88JN=Z4Q@mail.gmail.com>
 <20201117182939.Horde.hu9HkerrHUlPPJkEAhAu3OX@www.ontargettek.com>
Message-ID: <CAGxFJbRAFG3jWqx=AM+iKA9A_44rGXhnwj9NQ_dJaVOdy+H-8A@mail.gmail.com>

Why 0's in the data frame? Shouldn't that be 1 (vendor with that account)?

Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Nov 17, 2020 at 3:29 PM Tom Woolman <twoolman at ontargettek.com>
wrote:

> Hi Bill. Sorry to be so obtuse with the example data, I was trying
> (too hard) not to share any actual values so I just created randomized
> values for my example; of course I should have specified that the
> random values would not provide the expected problem pattern. I should
> have just used simple dummy codes as Bill Dunlap did.
>
> So per Bill's example data for Data1, the expected (hoped for) output
> should be:
>
>   Vendor Account Num_Vendors_Sharing_Bank_Acct
> 1     V1      A1      0
> 2     V2      A2      3
> 3     V3      A2      3
> 4     V4      A2      3
>
>
> Where the new calculated variable is Num_Vendors_Sharing_Bank_Acct.
> The value is 3 for V2, V3 and V4 because they each share bank account
> A2.
>
>
> Likewise, in the Data2 frame, the same logic applies:
>
>   Vendor Account Num_Vendors_Sharing_Bank_Acct
> 1     V1      A1     0
> 2     V2      A2     3
> 3     V3      A2     3
> 4     V1      A2     3
> 5     V4      A3     0
> 6     V2      A4     0
>
>
>
>
>
>
> Thanks!
>
>
> Quoting Bill Dunlap <williamwdunlap at gmail.com>:
>
> > What should the result be for
> >   Data1 <- data.frame(Vendor=c("V1","V2","V3","V4"),
> > Account=c("A1","A2","A2","A2"))
> > ?
> >
> > Must each vendor have only one account?  If not, what should the result
> be
> > for
> >    Data2 <- data.frame(Vendor=c("V1","V2","V3","V1","V4","V2"),
> > Account=c("A1","A2","A2","A2","A3","A4"))
> > ?
> >
> > -Bill
> >
> > On Tue, Nov 17, 2020 at 1:20 PM Tom Woolman <twoolman at ontargettek.com>
> > wrote:
> >
> >> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
> >> plus a bank account number for each vendor. I'm trying to find a way
> >> to count the number of duplicate bank accounts that occur in more than
> >> one unique Vendor_ID, and then assign the count value for each row in
> >> the dataframe in a new variable.
> >>
> >> I can do a count of bank accounts that occur within the same vendor
> >> using dplyr and group_by and count, but I can't figure out a way to
> >> count duplicates among multiple Vendor_IDs.
> >>
> >>
> >> Dataframe example code:
> >>
> >>
> >> #Create a sample data frame:
> >>
> >> set.seed(1)
> >>
> >> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
> >> sample(1:10000))
> >>
> >>
> >>
> >>
> >> Thanks in advance for any help.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Nov 18 00:34:47 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Tue, 17 Nov 2020 18:34:47 -0500
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <CAGxFJbRAFG3jWqx=AM+iKA9A_44rGXhnwj9NQ_dJaVOdy+H-8A@mail.gmail.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
 <CAHqSRuT0=-b6W+WXZc49eqq_OPrgemwf72UR=WMvsO88JN=Z4Q@mail.gmail.com>
 <20201117182939.Horde.hu9HkerrHUlPPJkEAhAu3OX@www.ontargettek.com>
 <CAGxFJbRAFG3jWqx=AM+iKA9A_44rGXhnwj9NQ_dJaVOdy+H-8A@mail.gmail.com>
Message-ID: <20201117183447.Horde.hTGQlGmxCEAo9V-fh_GmUuM@www.ontargettek.com>

Yes, good catch. Thanks


Quoting Bert Gunter <bgunter.4567 at gmail.com>:

> Why 0's in the data frame? Shouldn't that be 1 (vendor with that account)?
>
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Nov 17, 2020 at 3:29 PM Tom Woolman <twoolman at ontargettek.com>
> wrote:
>
>> Hi Bill. Sorry to be so obtuse with the example data, I was trying
>> (too hard) not to share any actual values so I just created randomized
>> values for my example; of course I should have specified that the
>> random values would not provide the expected problem pattern. I should
>> have just used simple dummy codes as Bill Dunlap did.
>>
>> So per Bill's example data for Data1, the expected (hoped for) output
>> should be:
>>
>>   Vendor Account Num_Vendors_Sharing_Bank_Acct
>> 1     V1      A1      0
>> 2     V2      A2      3
>> 3     V3      A2      3
>> 4     V4      A2      3
>>
>>
>> Where the new calculated variable is Num_Vendors_Sharing_Bank_Acct.
>> The value is 3 for V2, V3 and V4 because they each share bank account
>> A2.
>>
>>
>> Likewise, in the Data2 frame, the same logic applies:
>>
>>   Vendor Account Num_Vendors_Sharing_Bank_Acct
>> 1     V1      A1     0
>> 2     V2      A2     3
>> 3     V3      A2     3
>> 4     V1      A2     3
>> 5     V4      A3     0
>> 6     V2      A4     0
>>
>>
>>
>>
>>
>>
>> Thanks!
>>
>>
>> Quoting Bill Dunlap <williamwdunlap at gmail.com>:
>>
>> > What should the result be for
>> >   Data1 <- data.frame(Vendor=c("V1","V2","V3","V4"),
>> > Account=c("A1","A2","A2","A2"))
>> > ?
>> >
>> > Must each vendor have only one account?  If not, what should the result
>> be
>> > for
>> >    Data2 <- data.frame(Vendor=c("V1","V2","V3","V1","V4","V2"),
>> > Account=c("A1","A2","A2","A2","A3","A4"))
>> > ?
>> >
>> > -Bill
>> >
>> > On Tue, Nov 17, 2020 at 1:20 PM Tom Woolman <twoolman at ontargettek.com>
>> > wrote:
>> >
>> >> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
>> >> plus a bank account number for each vendor. I'm trying to find a way
>> >> to count the number of duplicate bank accounts that occur in more than
>> >> one unique Vendor_ID, and then assign the count value for each row in
>> >> the dataframe in a new variable.
>> >>
>> >> I can do a count of bank accounts that occur within the same vendor
>> >> using dplyr and group_by and count, but I can't figure out a way to
>> >> count duplicates among multiple Vendor_IDs.
>> >>
>> >>
>> >> Dataframe example code:
>> >>
>> >>
>> >> #Create a sample data frame:
>> >>
>> >> set.seed(1)
>> >>
>> >> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
>> >> sample(1:10000))
>> >>
>> >>
>> >>
>> >>
>> >> Thanks in advance for any help.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Nov 18 00:56:24 2020
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 17 Nov 2020 18:56:24 -0500
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <20201117182939.Horde.hu9HkerrHUlPPJkEAhAu3OX@www.ontargettek.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
 <CAHqSRuT0=-b6W+WXZc49eqq_OPrgemwf72UR=WMvsO88JN=Z4Q@mail.gmail.com>
 <20201117182939.Horde.hu9HkerrHUlPPJkEAhAu3OX@www.ontargettek.com>
Message-ID: <043b01d6bd3d$4190c630$c4b25290$@verizon.net>

Many problems can often be solved with some thought by using the right tools, such as the ones from the tidyverse.

Without giving a specific answer, you might want to think about using the group_by() functionality in a pipeline that would lump together all rows matching say having the same value in several columns. Then in something like a mutate() or summarize() you can use special functions like n() that return how many rows exist within each grouping. There are many more such verbs and features that let you build up something, often by removing the grouping along the way and perhaps adding some other form of grouping including the new rowwise() that then lets you do things across columns on a row at a time and so on.

I think the point is to think of steps that lead to a result that can be used in the next step and so on. 

And, for some problems, you can  think outside the pipelines and create multiple intermediate data.frames with parts of what you will need and then combine them with joins or whatever it takes to efficiently get a result, or by brute force. Sometimes (as when making graphs) you might want to convert data between forms that are often called long versus wide. 

Yes, plenty can be done in base R or using other packages. But a good set of tools might be part of what you need to investigate.

Of course, others can chime in suggesting that there are negatives to dplyr and other aspects of the tidyverse and they would be right too. 


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Tom Woolman
Sent: Tuesday, November 17, 2020 6:30 PM
To: Bill Dunlap <williamwdunlap at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] counting duplicate items that occur in multiple groups

Hi Bill. Sorry to be so obtuse with the example data, I was trying (too hard) not to share any actual values so I just created randomized values for my example; of course I should have specified that the random values would not provide the expected problem pattern. I should have just used simple dummy codes as Bill Dunlap did.

So per Bill's example data for Data1, the expected (hoped for) output should be:

  Vendor Account Num_Vendors_Sharing_Bank_Acct
1     V1      A1      0
2     V2      A2      3
3     V3      A2      3
4     V4      A2      3


Where the new calculated variable is Num_Vendors_Sharing_Bank_Acct.  
The value is 3 for V2, V3 and V4 because they each share bank account A2.


Likewise, in the Data2 frame, the same logic applies:

  Vendor Account Num_Vendors_Sharing_Bank_Acct
1     V1      A1     0
2     V2      A2     3
3     V3      A2     3
4     V1      A2     3
5     V4      A3     0
6     V2      A4     0






Thanks!


Quoting Bill Dunlap <williamwdunlap at gmail.com>:

> What should the result be for
>   Data1 <- data.frame(Vendor=c("V1","V2","V3","V4"),
> Account=c("A1","A2","A2","A2"))
> ?
>
> Must each vendor have only one account?  If not, what should the 
> result be for
>    Data2 <- data.frame(Vendor=c("V1","V2","V3","V1","V4","V2"),
> Account=c("A1","A2","A2","A2","A3","A4"))
> ?
>
> -Bill
>
> On Tue, Nov 17, 2020 at 1:20 PM Tom Woolman <twoolman at ontargettek.com>
> wrote:
>
>> Hi everyone.  I have a dataframe that is a collection of Vendor IDs 
>> plus a bank account number for each vendor. I'm trying to find a way 
>> to count the number of duplicate bank accounts that occur in more 
>> than one unique Vendor_ID, and then assign the count value for each 
>> row in the dataframe in a new variable.
>>
>> I can do a count of bank accounts that occur within the same vendor 
>> using dplyr and group_by and count, but I can't figure out a way to 
>> count duplicates among multiple Vendor_IDs.
>>
>>
>> Dataframe example code:
>>
>>
>> #Create a sample data frame:
>>
>> set.seed(1)
>>
>> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
>> sample(1:10000))
>>
>>
>>
>>
>> Thanks in advance for any help.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 18 01:06:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Nov 2020 16:06:10 -0800
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <20201117183447.Horde.hTGQlGmxCEAo9V-fh_GmUuM@www.ontargettek.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
 <CAHqSRuT0=-b6W+WXZc49eqq_OPrgemwf72UR=WMvsO88JN=Z4Q@mail.gmail.com>
 <20201117182939.Horde.hu9HkerrHUlPPJkEAhAu3OX@www.ontargettek.com>
 <CAGxFJbRAFG3jWqx=AM+iKA9A_44rGXhnwj9NQ_dJaVOdy+H-8A@mail.gmail.com>
 <20201117183447.Horde.hTGQlGmxCEAo9V-fh_GmUuM@www.ontargettek.com>
Message-ID: <CAGxFJbQY9RaPcEsvj_f1MTBSxqVYT7MGj4Z2j22njcYAoaXuTg@mail.gmail.com>

z <- with(Data2, tapply(Vendor,Account, I))
n <- vapply(z,length,1)
data.frame (Vendor = unlist(z),
   Account = rep(names(z),n),
   NumVen = rep(n,n)
)

## which gives:

   Vendor Account NumVen
A1      V1      A1      1
A21     V2      A2      3
A22     V3      A2      3
A23     V1      A2      3
A3      V4      A3      1
A4      V2      A4      1

Of course this also works for Data1

Bill may be able to come up with a slicker version, however.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Nov 17, 2020 at 3:34 PM Tom Woolman <twoolman at ontargettek.com>
wrote:

> Yes, good catch. Thanks
>
>
> Quoting Bert Gunter <bgunter.4567 at gmail.com>:
>
> > Why 0's in the data frame? Shouldn't that be 1 (vendor with that
> account)?
> >
> > Bert
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Nov 17, 2020 at 3:29 PM Tom Woolman <twoolman at ontargettek.com>
> > wrote:
> >
> >> Hi Bill. Sorry to be so obtuse with the example data, I was trying
> >> (too hard) not to share any actual values so I just created randomized
> >> values for my example; of course I should have specified that the
> >> random values would not provide the expected problem pattern. I should
> >> have just used simple dummy codes as Bill Dunlap did.
> >>
> >> So per Bill's example data for Data1, the expected (hoped for) output
> >> should be:
> >>
> >>   Vendor Account Num_Vendors_Sharing_Bank_Acct
> >> 1     V1      A1      0
> >> 2     V2      A2      3
> >> 3     V3      A2      3
> >> 4     V4      A2      3
> >>
> >>
> >> Where the new calculated variable is Num_Vendors_Sharing_Bank_Acct.
> >> The value is 3 for V2, V3 and V4 because they each share bank account
> >> A2.
> >>
> >>
> >> Likewise, in the Data2 frame, the same logic applies:
> >>
> >>   Vendor Account Num_Vendors_Sharing_Bank_Acct
> >> 1     V1      A1     0
> >> 2     V2      A2     3
> >> 3     V3      A2     3
> >> 4     V1      A2     3
> >> 5     V4      A3     0
> >> 6     V2      A4     0
> >>
> >>
> >>
> >>
> >>
> >>
> >> Thanks!
> >>
> >>
> >> Quoting Bill Dunlap <williamwdunlap at gmail.com>:
> >>
> >> > What should the result be for
> >> >   Data1 <- data.frame(Vendor=c("V1","V2","V3","V4"),
> >> > Account=c("A1","A2","A2","A2"))
> >> > ?
> >> >
> >> > Must each vendor have only one account?  If not, what should the
> result
> >> be
> >> > for
> >> >    Data2 <- data.frame(Vendor=c("V1","V2","V3","V1","V4","V2"),
> >> > Account=c("A1","A2","A2","A2","A3","A4"))
> >> > ?
> >> >
> >> > -Bill
> >> >
> >> > On Tue, Nov 17, 2020 at 1:20 PM Tom Woolman <twoolman at ontargettek.com
> >
> >> > wrote:
> >> >
> >> >> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
> >> >> plus a bank account number for each vendor. I'm trying to find a way
> >> >> to count the number of duplicate bank accounts that occur in more
> than
> >> >> one unique Vendor_ID, and then assign the count value for each row in
> >> >> the dataframe in a new variable.
> >> >>
> >> >> I can do a count of bank accounts that occur within the same vendor
> >> >> using dplyr and group_by and count, but I can't figure out a way to
> >> >> count duplicates among multiple Vendor_IDs.
> >> >>
> >> >>
> >> >> Dataframe example code:
> >> >>
> >> >>
> >> >> #Create a sample data frame:
> >> >>
> >> >> set.seed(1)
> >> >>
> >> >> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
> >> >> sample(1:10000))
> >> >>
> >> >>
> >> >>
> >> >>
> >> >> Thanks in advance for any help.
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
>
>
>
>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Nov 18 01:59:40 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Tue, 17 Nov 2020 18:59:40 -0600
Subject: [R] How to pass a character string with a hyphen
In-Reply-To: <CAKBFG3aTxfHO3QEDV0uuJRwSuMZjitq-6zGyRVowrc6kYG0Snw@mail.gmail.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <CAKBFG3aTxfHO3QEDV0uuJRwSuMZjitq-6zGyRVowrc6kYG0Snw@mail.gmail.com>
Message-ID: <000901d6bd46$197a8ab0$4c6fa010$@sbcglobal.net>

Robert

 

I ended up using the paste command, its not pretty but it works thank you

 

Jeff

 

From: Robert Knight <bobby.knight at gmail.com> 
Sent: Tuesday, November 17, 2020 3:56 PM
To: reichmanj at sbcglobal.net
Cc: r-help at r-project.org
Subject: Re: [R] How to pass a character string with a hyphen

 

Strip the left characters and strip the right characters into their own variables using one of the methods that can do that.  Then pass it using something like paste(left, "-", right).

 

On Tue, Nov 17, 2020, 2:43 PM Jeff Reichman <reichmanj at sbcglobal.net <mailto:reichmanj at sbcglobal.net> > wrote:

R-Help



How does one pass a character string containing a hyphen? I have a function
that accesses an api if I hard code the object, for example



key_key <- "xxxx-yyyy" 



it works but when I pass the key  code to the function (say something like
key_code <- code_input)  it returns only xxxx. So R is seeing a string with
a negative operator I'm assuming



Jeff


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Wed Nov 18 05:38:30 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Wed, 18 Nov 2020 12:38:30 +0800
Subject: [R] Language environment
In-Reply-To: <8C6CD0A9-5B1F-438A-8027-C0589EB37DB5@dcn.davis.ca.us>
References: <63274208-6836-ccd2-54e6-67d19d2ab6a3@ntu.edu.tw>
 <8C6CD0A9-5B1F-438A-8027-C0589EB37DB5@dcn.davis.ca.us>
Message-ID: <a2ac11e6-e312-a5fc-fe06-716fde1aed02@ntu.edu.tw>

Thanks. YES, include the line

Sys.setenv(LANG="en");

in my Rprofile file and it worked.

On 2020/11/18 ?? 12:43, Jeff Newmiller wrote:
> put it in your .Rprofile file. Read the R Installation and Administration Manusl for more info.
>
> On November 17, 2020 5:00:06 AM PST, Steven Yen <styen at ntu.edu.tw> wrote:
>> In R, I was able to set the language environment by fixing the line
>>
>> in file "C:\Program Files\R\R-4.0.3\etc\Rconsole", line 70 below, set
>> language to EN:
>>
>> language = EN
>>
>> In RStudio, I am not able to do that, except to include the line
>>
>> Sys.setenv(LANG="en");
>>
>> in every one of my program file. That's too much work. Any idea? Thank
>> you!
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Wed Nov 18 10:40:23 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Wed, 18 Nov 2020 15:10:23 +0530
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <CAGxFJbQY9RaPcEsvj_f1MTBSxqVYT7MGj4Z2j22njcYAoaXuTg@mail.gmail.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
 <CAHqSRuT0=-b6W+WXZc49eqq_OPrgemwf72UR=WMvsO88JN=Z4Q@mail.gmail.com>
 <20201117182939.Horde.hu9HkerrHUlPPJkEAhAu3OX@www.ontargettek.com>
 <CAGxFJbRAFG3jWqx=AM+iKA9A_44rGXhnwj9NQ_dJaVOdy+H-8A@mail.gmail.com>
 <20201117183447.Horde.hTGQlGmxCEAo9V-fh_GmUuM@www.ontargettek.com>
 <CAGxFJbQY9RaPcEsvj_f1MTBSxqVYT7MGj4Z2j22njcYAoaXuTg@mail.gmail.com>
Message-ID: <CADfFDC5SrJZndXOVX96b7BjVMromymk34CBVBNF_xy7oRpSyFg@mail.gmail.com>

On Wed, Nov 18, 2020 at 5:40 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> z <- with(Data2, tapply(Vendor,Account, I))
> n <- vapply(z,length,1)
> data.frame (Vendor = unlist(z),
>    Account = rep(names(z),n),
>    NumVen = rep(n,n)
> )
>
> ## which gives:
>
>    Vendor Account NumVen
> A1      V1      A1      1
> A21     V2      A2      3
> A22     V3      A2      3
> A23     V1      A2      3
> A3      V4      A3      1
> A4      V2      A4      1
>
> Of course this also works for Data1
>
> Bill may be able to come up with a slicker version, however.

Perhaps

transform(Data2, nshare = as.vector(table(Account)[Account]))

(or dplyr::mutate() instead of transform(), if you prefer.)

-Deepayan

>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Nov 17, 2020 at 3:34 PM Tom Woolman <twoolman at ontargettek.com>
> wrote:
>
> > Yes, good catch. Thanks
> >
> >
> > Quoting Bert Gunter <bgunter.4567 at gmail.com>:
> >
> > > Why 0's in the data frame? Shouldn't that be 1 (vendor with that
> > account)?
> > >
> > > Bert
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> > and
> > > sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Tue, Nov 17, 2020 at 3:29 PM Tom Woolman <twoolman at ontargettek.com>
> > > wrote:
> > >
> > >> Hi Bill. Sorry to be so obtuse with the example data, I was trying
> > >> (too hard) not to share any actual values so I just created randomized
> > >> values for my example; of course I should have specified that the
> > >> random values would not provide the expected problem pattern. I should
> > >> have just used simple dummy codes as Bill Dunlap did.
> > >>
> > >> So per Bill's example data for Data1, the expected (hoped for) output
> > >> should be:
> > >>
> > >>   Vendor Account Num_Vendors_Sharing_Bank_Acct
> > >> 1     V1      A1      0
> > >> 2     V2      A2      3
> > >> 3     V3      A2      3
> > >> 4     V4      A2      3
> > >>
> > >>
> > >> Where the new calculated variable is Num_Vendors_Sharing_Bank_Acct.
> > >> The value is 3 for V2, V3 and V4 because they each share bank account
> > >> A2.
> > >>
> > >>
> > >> Likewise, in the Data2 frame, the same logic applies:
> > >>
> > >>   Vendor Account Num_Vendors_Sharing_Bank_Acct
> > >> 1     V1      A1     0
> > >> 2     V2      A2     3
> > >> 3     V3      A2     3
> > >> 4     V1      A2     3
> > >> 5     V4      A3     0
> > >> 6     V2      A4     0
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >> Thanks!
> > >>
> > >>
> > >> Quoting Bill Dunlap <williamwdunlap at gmail.com>:
> > >>
> > >> > What should the result be for
> > >> >   Data1 <- data.frame(Vendor=c("V1","V2","V3","V4"),
> > >> > Account=c("A1","A2","A2","A2"))
> > >> > ?
> > >> >
> > >> > Must each vendor have only one account?  If not, what should the
> > result
> > >> be
> > >> > for
> > >> >    Data2 <- data.frame(Vendor=c("V1","V2","V3","V1","V4","V2"),
> > >> > Account=c("A1","A2","A2","A2","A3","A4"))
> > >> > ?
> > >> >
> > >> > -Bill
> > >> >
> > >> > On Tue, Nov 17, 2020 at 1:20 PM Tom Woolman <twoolman at ontargettek.com
> > >
> > >> > wrote:
> > >> >
> > >> >> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
> > >> >> plus a bank account number for each vendor. I'm trying to find a way
> > >> >> to count the number of duplicate bank accounts that occur in more
> > than
> > >> >> one unique Vendor_ID, and then assign the count value for each row in
> > >> >> the dataframe in a new variable.
> > >> >>
> > >> >> I can do a count of bank accounts that occur within the same vendor
> > >> >> using dplyr and group_by and count, but I can't figure out a way to
> > >> >> count duplicates among multiple Vendor_IDs.
> > >> >>
> > >> >>
> > >> >> Dataframe example code:
> > >> >>
> > >> >>
> > >> >> #Create a sample data frame:
> > >> >>
> > >> >> set.seed(1)
> > >> >>
> > >> >> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
> > >> >> sample(1:10000))
> > >> >>
> > >> >>
> > >> >>
> > >> >>
> > >> >> Thanks in advance for any help.
> > >> >>
> > >> >> ______________________________________________
> > >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> >> PLEASE do read the posting guide
> > >> >> http://www.R-project.org/posting-guide.html
> > >> >> and provide commented, minimal, self-contained, reproducible code.
> > >> >>
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Nov 18 11:22:08 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 18 Nov 2020 21:22:08 +1100
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
Message-ID: <CA+8X3fXkVE1-RUvW=+c-qLZ4dP_17OXd5DsCh+2gy0CUBgW7Vw@mail.gmail.com>

Oops, I sent this to Tom earlier today and forgot to copy to the list:

VendorID=rep(paste0("V",1:10),each=5)
AcctID=paste0("A",sample(1:5,50,TRUE))
Data<-data.frame(VendorID,AcctID)
table(Data)
# get multiple vendors for each account
dupAcctID<-colSums(table(Data)>0)
Data$dupAcct<-NA
# fill in the new column
for(i in 1:length(dupAcctID))
 Data$dupAcct[Data$AcctID == names(dupAcctID[i])]<-dupAcctID[i]

Jim

On Wed, Nov 18, 2020 at 8:20 AM Tom Woolman <twoolman at ontargettek.com>
wrote:

> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
> plus a bank account number for each vendor. I'm trying to find a way
> to count the number of duplicate bank accounts that occur in more than
> one unique Vendor_ID, and then assign the count value for each row in
> the dataframe in a new variable.
>
> I can do a count of bank accounts that occur within the same vendor
> using dplyr and group_by and count, but I can't figure out a way to
> count duplicates among multiple Vendor_IDs.
>
>
> Dataframe example code:
>
>
> #Create a sample data frame:
>
> set.seed(1)
>
> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
> sample(1:10000))
>
>
>
>
> Thanks in advance for any help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Nov 18 11:25:54 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Wed, 18 Nov 2020 05:25:54 -0500
Subject: [R] counting duplicate items that occur in multiple groups
In-Reply-To: <CA+8X3fXkVE1-RUvW=+c-qLZ4dP_17OXd5DsCh+2gy0CUBgW7Vw@mail.gmail.com>
References: <000401d6bd22$42b60090$c82201b0$.ref@sbcglobal.net>
 <000401d6bd22$42b60090$c82201b0$@sbcglobal.net>
 <C1A97FA9-D3FE-41FB-980A-C10463AF32AE@utoronto.ca>
 <20201117161026.Horde.4Swc32csJPyhv_8xs8cNLVP@www.ontargettek.com>
 <CA+8X3fXkVE1-RUvW=+c-qLZ4dP_17OXd5DsCh+2gy0CUBgW7Vw@mail.gmail.com>
Message-ID: <20201118052554.Horde.Zyx8713QSFEfgZrKz-5hhKG@www.ontargettek.com>

Thanks, everyone!



Quoting Jim Lemon <drjimlemon at gmail.com>:

> Oops, I sent this to Tom earlier today and forgot to copy to the list:
>
> VendorID=rep(paste0("V",1:10),each=5)
> AcctID=paste0("A",sample(1:5,50,TRUE))
> Data<-data.frame(VendorID,AcctID)
> table(Data)
> # get multiple vendors for each account
> dupAcctID<-colSums(table(Data)>0)
> Data$dupAcct<-NA
> # fill in the new column
> for(i in 1:length(dupAcctID))
>  Data$dupAcct[Data$AcctID == names(dupAcctID[i])]<-dupAcctID[i]
>
> Jim
>
> On Wed, Nov 18, 2020 at 8:20 AM Tom Woolman <twoolman at ontargettek.com>
> wrote:
>
>> Hi everyone.  I have a dataframe that is a collection of Vendor IDs
>> plus a bank account number for each vendor. I'm trying to find a way
>> to count the number of duplicate bank accounts that occur in more than
>> one unique Vendor_ID, and then assign the count value for each row in
>> the dataframe in a new variable.
>>
>> I can do a count of bank accounts that occur within the same vendor
>> using dplyr and group_by and count, but I can't figure out a way to
>> count duplicates among multiple Vendor_IDs.
>>
>>
>> Dataframe example code:
>>
>>
>> #Create a sample data frame:
>>
>> set.seed(1)
>>
>> Data <- data.frame(Vendor_ID = sample(1:10000), Bank_Account_ID =
>> sample(1:10000))
>>
>>
>>
>>
>> Thanks in advance for any help.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From M@Roo@ @end|ng |rom |1-out@ourc|ng@eu  Wed Nov 18 11:30:07 2020
From: M@Roo@ @end|ng |rom |1-out@ourc|ng@eu (Marc Roos)
Date: Wed, 18 Nov 2020 11:30:07 +0100
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <be0f1a5a-0ec5-e4b5-cf75-7b3fa7729ac5@molbio.mgh.harvard.edu>
Message-ID: <"H0000071001852f5.1605695407.sx.f1-outsourcing.eu*"@MHS>

 
Maybe this could be interesting to verify against found anomalies?

"A second memory card with uncounted votes was found during an audit in 
Fayette County, Georgia, containing 2,755 votes"
https://www.zerohedge.com/political/second-memory-card-2755-votes-found-during-georgia-election-audit-decreasing-biden-lead


From g@@@powe|| @end|ng |rom protonm@||@com  Wed Nov 18 16:11:49 2020
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg)
Date: Wed, 18 Nov 2020 15:11:49 +0000
Subject: [R] - Trying to replicate VLOOKUP in R - help needed
In-Reply-To: <IkbJMS_4gaUyHHbjriqfAZaaprHTwr2mbKOuwuQQ2NwsgOo8RwZowms0bl4SxKgAQG2qGMtfucx6uIDERjiolsb5Ii-ij_4bjVh_GYEVTDQ=@protonmail.com>
References: <IkbJMS_4gaUyHHbjriqfAZaaprHTwr2mbKOuwuQQ2NwsgOo8RwZowms0bl4SxKgAQG2qGMtfucx6uIDERjiolsb5Ii-ij_4bjVh_GYEVTDQ=@protonmail.com>
Message-ID: <v_VHmXUhXdNTapFe_WtjWKUrZKCexqCncKIeQfEmc5W5w1EZnLrymDqmrib1Lms9pTxDzbO2GT7UrcD-qVetPNXF0fud4sBb-KsWnChspjQ=@protonmail.com>

Thanks Andrew and Mitch for your help.

With your assistance, I was able to sort this out.

Since I have to do this type of thing of often, and since there is no existing package/function (yet) that makes this easy, if ever I get to the point were I develop enough skill to build and submit a new package, a simple little VLOOKUP(like) function contained in a package would be of great use.

r/
Gregg




??????? Original Message ???????
On Monday, November 16, 2020 1:56 PM, Gregg via R-help <r-help at r-project.org> wrote:

> PROBLEM: I am trying to replicate something like a VLOOKUP in R but am having no success - need a bit of help.
> 

> GIVEN DATA SET (data.table): (looks something like this, but much bigger)
> 

> NAME TOTALAUTH ASSIGNED_COMPANY
> ABERDEEN PROVING GROUND 1 NA
> ADELPHI LABORATORY CENTER 1 NA
> CARLISLE BARRACKS 1 NA
> DETROIT ARSENAL 1 NA
> DUGWAY PROVING GROUND 1 NA
> FORT A P HILL 1 NA
> FORT BELVOIR 1 NA
> FORT BENNING 1 NA
> FORT BLISS 1 NA
> FORT BRAGG 1 NA
> FORT BUCHANAN 1 NA
> 

> I am trying to update the values in the ASSIGNED_COMPANY column from NAs to a value that matches based on the "key" word like below.
> 

> NAME TOTALAUTH ASSIGNED_COMPANY
> ABERDEEN PROVING GROUND 1 NEC Aberdeen
> ADELPHI LABORATORY CENTER 1 NEC Adelphi
> CARLISLE BARRACKS 1 NEC Carlise
> DETROIT ARSENAL 1 NEC Detroit
> DUGWAY PROVING GROUND 1 NEC Dugway
> FORT A P HILL 1 NEC AP Hill
> FORT BELVOIR 1 NEC Belvoir
> FORT BENNING 1 NEC Benning
> FORT BLISS 1 NEC Bliss
> FORT BRAGG 1 NEC Bragg
> FORT BUCHANAN 1 NEC Buchanon
> 

> In a nutshell, for instance.......
> 

> I want to search for the keyword "ABERDEEN" in the NAME column, and for every row where it exists, I want to update the NA in the ASSIGNED_COMPANY column to "NEC Aberdeen"
> 

> I want to search for the keyword "ADELPHI" in the NAME column, and for every row where it exists, I want to update the NA in the ASSIGNED_COMPANY column to "NEC ADELPHI"
> 

> ....... and so on for every value in the NAME column - so in the end a I have matching names in the ASSIGNED_COMPANY column.
> 

> I can use an if statement because it is not vectorized.
> 

> If I use an ifelse statement, the "else" rewrites any changes with ""
> 

> Something so simple should not be difficult.
> 

> Some of the methods I attempted to use are below along with the errors I get...
> 

> ###################CODE#######################################
> 

> library(data.table)
> library(dplyr)
> library(stringr)
> 

> VLOOKUP_inR <- data.table::fread("DATASET_TESTINGONLY.csv")
> 

> #METHOD 1 FAILS
> VLOOKUP_inR %>% dplyr::rename_if(grepl("ADELPHI", VLOOKUP_inR$NAME, useBytes = TRUE), "NEC Adelphi")
> 

> Error in get(.x, .env, mode = "function") :
> 

> object 'NEC Adelphi' of mode 'function' was not found
> 

> #METHOD 2 FAILS
> if(stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) {
> VLOOKUP_inR$ASSIGNED_COMPANY == "NEC Adelphi"
> }
> 

> Warning message:
> In if (stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) { :
> the condition has length > 1 and only the first element will be used
> 

> #METHOD 3 FAILS
> ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, "ADELPHI"), ASIP_combined_location_tally$ASSIGNED_COMPANY == ASIP_combined_location_tally$ASSIGNED_COMPANY)
> 

> Error in ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, :
> 

> argument "no" is missing, with no default
> 

> #METHOD4 FAILS
> VLOOKUP_inR_matching <- VLOOKUP_inR %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'ABERDEEN', x = NAME), 'NEC Aberdeen', ''))
> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'ADELPHI', x = NAME), 'NEC Adelphi', ''))
> 

> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'CARLISLE', x = NAME), 'NEC Carlisle Barracks', ''))
> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'DETROIT', x = NAME), 'NEC Detroit Arsenal', ''))
> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>% mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'BELVOIR', x = NAME), 'NEC Fort Belvoir', ''))
> 

> -----------the 4th method just over writes all previous changers back to ""
> 

> ######################################################################
> 

> Any help offered would be so very greatly appreciated.
> 

> Thanks you.
> 

> r/
> gregg powell
> AZ
> 

> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201118/3038769b/attachment.sig>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Nov 18 16:36:21 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 18 Nov 2020 07:36:21 -0800
Subject: [R] - Trying to replicate VLOOKUP in R - help needed
In-Reply-To: <v_VHmXUhXdNTapFe_WtjWKUrZKCexqCncKIeQfEmc5W5w1EZnLrymDqmrib1Lms9pTxDzbO2GT7UrcD-qVetPNXF0fud4sBb-KsWnChspjQ=@protonmail.com>
References: <IkbJMS_4gaUyHHbjriqfAZaaprHTwr2mbKOuwuQQ2NwsgOo8RwZowms0bl4SxKgAQG2qGMtfucx6uIDERjiolsb5Ii-ij_4bjVh_GYEVTDQ=@protonmail.com>
 <v_VHmXUhXdNTapFe_WtjWKUrZKCexqCncKIeQfEmc5W5w1EZnLrymDqmrib1Lms9pTxDzbO2GT7UrcD-qVetPNXF0fud4sBb-KsWnChspjQ=@protonmail.com>
Message-ID: <99155CCD-DFA7-4AA8-8FA1-764299085380@dcn.davis.ca.us>

Instead, learn how to use the merge function, or perhaps the dplyr::left_join function. VLOOKUP is really not necessary.

On November 18, 2020 7:11:49 AM PST, Gregg via R-help <r-help at r-project.org> wrote:
>Thanks Andrew and Mitch for your help.
>
>With your assistance, I was able to sort this out.
>
>Since I have to do this type of thing of often, and since there is no
>existing package/function (yet) that makes this easy, if ever I get to
>the point were I develop enough skill to build and submit a new
>package, a simple little VLOOKUP(like) function contained in a package
>would be of great use.
>
>r/
>Gregg
>
>
>
>
>??????? Original Message ???????
>On Monday, November 16, 2020 1:56 PM, Gregg via R-help
><r-help at r-project.org> wrote:
>
>> PROBLEM: I am trying to replicate something like a VLOOKUP in R but
>am having no success - need a bit of help.
>> 
>
>> GIVEN DATA SET (data.table): (looks something like this, but much
>bigger)
>> 
>
>> NAME TOTALAUTH ASSIGNED_COMPANY
>> ABERDEEN PROVING GROUND 1 NA
>> ADELPHI LABORATORY CENTER 1 NA
>> CARLISLE BARRACKS 1 NA
>> DETROIT ARSENAL 1 NA
>> DUGWAY PROVING GROUND 1 NA
>> FORT A P HILL 1 NA
>> FORT BELVOIR 1 NA
>> FORT BENNING 1 NA
>> FORT BLISS 1 NA
>> FORT BRAGG 1 NA
>> FORT BUCHANAN 1 NA
>> 
>
>> I am trying to update the values in the ASSIGNED_COMPANY column from
>NAs to a value that matches based on the "key" word like below.
>> 
>
>> NAME TOTALAUTH ASSIGNED_COMPANY
>> ABERDEEN PROVING GROUND 1 NEC Aberdeen
>> ADELPHI LABORATORY CENTER 1 NEC Adelphi
>> CARLISLE BARRACKS 1 NEC Carlise
>> DETROIT ARSENAL 1 NEC Detroit
>> DUGWAY PROVING GROUND 1 NEC Dugway
>> FORT A P HILL 1 NEC AP Hill
>> FORT BELVOIR 1 NEC Belvoir
>> FORT BENNING 1 NEC Benning
>> FORT BLISS 1 NEC Bliss
>> FORT BRAGG 1 NEC Bragg
>> FORT BUCHANAN 1 NEC Buchanon
>> 
>
>> In a nutshell, for instance.......
>> 
>
>> I want to search for the keyword "ABERDEEN" in the NAME column, and
>for every row where it exists, I want to update the NA in the
>ASSIGNED_COMPANY column to "NEC Aberdeen"
>> 
>
>> I want to search for the keyword "ADELPHI" in the NAME column, and
>for every row where it exists, I want to update the NA in the
>ASSIGNED_COMPANY column to "NEC ADELPHI"
>> 
>
>> ....... and so on for every value in the NAME column - so in the end
>a I have matching names in the ASSIGNED_COMPANY column.
>> 
>
>> I can use an if statement because it is not vectorized.
>> 
>
>> If I use an ifelse statement, the "else" rewrites any changes with ""
>> 
>
>> Something so simple should not be difficult.
>> 
>
>> Some of the methods I attempted to use are below along with the
>errors I get...
>> 
>
>> ###################CODE#######################################
>> 
>
>> library(data.table)
>> library(dplyr)
>> library(stringr)
>> 
>
>> VLOOKUP_inR <- data.table::fread("DATASET_TESTINGONLY.csv")
>> 
>
>> #METHOD 1 FAILS
>> VLOOKUP_inR %>% dplyr::rename_if(grepl("ADELPHI", VLOOKUP_inR$NAME,
>useBytes = TRUE), "NEC Adelphi")
>> 
>
>> Error in get(.x, .env, mode = "function") :
>> 
>
>> object 'NEC Adelphi' of mode 'function' was not found
>> 
>
>> #METHOD 2 FAILS
>> if(stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) {
>> VLOOKUP_inR$ASSIGNED_COMPANY == "NEC Adelphi"
>> }
>> 
>
>> Warning message:
>> In if (stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) { :
>> the condition has length > 1 and only the first element will be used
>> 
>
>> #METHOD 3 FAILS
>> ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME,
>"ADELPHI"), ASIP_combined_location_tally$ASSIGNED_COMPANY ==
>ASIP_combined_location_tally$ASSIGNED_COMPANY)
>> 
>
>> Error in
>ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, :
>> 
>
>> argument "no" is missing, with no default
>> 
>
>> #METHOD4 FAILS
>> VLOOKUP_inR_matching <- VLOOKUP_inR %>% mutate(ASSIGNED_COMPANY =
>ifelse(grepl(pattern = 'ABERDEEN', x = NAME), 'NEC Aberdeen', ''))
>> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>%
>mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'ADELPHI', x = NAME),
>'NEC Adelphi', ''))
>> 
>
>> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>%
>mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'CARLISLE', x = NAME),
>'NEC Carlisle Barracks', ''))
>> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>%
>mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'DETROIT', x = NAME),
>'NEC Detroit Arsenal', ''))
>> VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>%
>mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'BELVOIR', x = NAME),
>'NEC Fort Belvoir', ''))
>> 
>
>> -----------the 4th method just over writes all previous changers back
>to ""
>> 
>
>>
>######################################################################
>> 
>
>> Any help offered would be so very greatly appreciated.
>> 
>
>> Thanks you.
>> 
>
>> r/
>> gregg powell
>> AZ
>> 
>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From g@@@powe|| @end|ng |rom protonm@||@com  Wed Nov 18 17:03:52 2020
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg)
Date: Wed, 18 Nov 2020 16:03:52 +0000
Subject: [R] - Trying to replicate VLOOKUP in R - help needed
In-Reply-To: <99155CCD-DFA7-4AA8-8FA1-764299085380@dcn.davis.ca.us>
References: <IkbJMS_4gaUyHHbjriqfAZaaprHTwr2mbKOuwuQQ2NwsgOo8RwZowms0bl4SxKgAQG2qGMtfucx6uIDERjiolsb5Ii-ij_4bjVh_GYEVTDQ=@protonmail.com>
 <v_VHmXUhXdNTapFe_WtjWKUrZKCexqCncKIeQfEmc5W5w1EZnLrymDqmrib1Lms9pTxDzbO2GT7UrcD-qVetPNXF0fud4sBb-KsWnChspjQ=@protonmail.com>
 <99155CCD-DFA7-4AA8-8FA1-764299085380@dcn.davis.ca.us>
Message-ID: <onTAnDYYFxdUFxTS6WINv5JkQ2HQ9zpMyBm-P3ZwpmaA_KyLbiA0neHZTdvb2TDIpQVGTw07IglmO0fWKHZ8-iccOgXsSya_rIVA6cyTuYY=@protonmail.com>

I will do that...

Thanks again Jeff.

r/
Gregg Powell




??????? Original Message ???????
On Wednesday, November 18, 2020 8:36 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Instead, learn how to use the merge function, or perhaps the dplyr::left_join function. VLOOKUP is really not necessary.
> 

> On November 18, 2020 7:11:49 AM PST, Gregg via R-help r-help at r-project.org wrote:
> 

> > Thanks Andrew and Mitch for your help.
> > With your assistance, I was able to sort this out.
> > Since I have to do this type of thing of often, and since there is no
> > existing package/function (yet) that makes this easy, if ever I get to
> > the point were I develop enough skill to build and submit a new
> > package, a simple little VLOOKUP(like) function contained in a package
> > would be of great use.
> > r/
> > Gregg
> > ??????? Original Message ???????
> > On Monday, November 16, 2020 1:56 PM, Gregg via R-help
> > r-help at r-project.org wrote:
> > 

> > > PROBLEM: I am trying to replicate something like a VLOOKUP in R but
> > > am having no success - need a bit of help.
> > 

> > > GIVEN DATA SET (data.table): (looks something like this, but much
> > > bigger)
> > 

> > > NAME TOTALAUTH ASSIGNED_COMPANY
> > > ABERDEEN PROVING GROUND 1 NA
> > > ADELPHI LABORATORY CENTER 1 NA
> > > CARLISLE BARRACKS 1 NA
> > > DETROIT ARSENAL 1 NA
> > > DUGWAY PROVING GROUND 1 NA
> > > FORT A P HILL 1 NA
> > > FORT BELVOIR 1 NA
> > > FORT BENNING 1 NA
> > > FORT BLISS 1 NA
> > > FORT BRAGG 1 NA
> > > FORT BUCHANAN 1 NA
> > 

> > > I am trying to update the values in the ASSIGNED_COMPANY column from
> > > NAs to a value that matches based on the "key" word like below.
> > 

> > > NAME TOTALAUTH ASSIGNED_COMPANY
> > > ABERDEEN PROVING GROUND 1 NEC Aberdeen
> > > ADELPHI LABORATORY CENTER 1 NEC Adelphi
> > > CARLISLE BARRACKS 1 NEC Carlise
> > > DETROIT ARSENAL 1 NEC Detroit
> > > DUGWAY PROVING GROUND 1 NEC Dugway
> > > FORT A P HILL 1 NEC AP Hill
> > > FORT BELVOIR 1 NEC Belvoir
> > > FORT BENNING 1 NEC Benning
> > > FORT BLISS 1 NEC Bliss
> > > FORT BRAGG 1 NEC Bragg
> > > FORT BUCHANAN 1 NEC Buchanon
> > 

> > > In a nutshell, for instance.......
> > 

> > > I want to search for the keyword "ABERDEEN" in the NAME column, and
> > > for every row where it exists, I want to update the NA in the
> > > ASSIGNED_COMPANY column to "NEC Aberdeen"
> > 

> > > I want to search for the keyword "ADELPHI" in the NAME column, and
> > > for every row where it exists, I want to update the NA in the
> > > ASSIGNED_COMPANY column to "NEC ADELPHI"
> > 

> > > ....... and so on for every value in the NAME column - so in the end
> > > a I have matching names in the ASSIGNED_COMPANY column.
> > 

> > > I can use an if statement because it is not vectorized.
> > 

> > > If I use an ifelse statement, the "else" rewrites any changes with ""
> > 

> > > Something so simple should not be difficult.
> > 

> > > Some of the methods I attempted to use are below along with the
> > > errors I get...
> > 

> > > ###################CODE#######################################
> > 

> > > library(data.table)
> > > library(dplyr)
> > > library(stringr)
> > 

> > > VLOOKUP_inR <- data.table::fread("DATASET_TESTINGONLY.csv")
> > 

> > > #METHOD 1 FAILS
> > > VLOOKUP_inR %>% dplyr::rename_if(grepl("ADELPHI", VLOOKUP_inR$NAME,
> > > useBytes = TRUE), "NEC Adelphi")
> > 

> > > Error in get(.x, .env, mode = "function") :
> > 

> > > object 'NEC Adelphi' of mode 'function' was not found
> > 

> > > #METHOD 2 FAILS
> > > if(stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) {
> > > VLOOKUP_inR$ASSIGNED_COMPANY == "NEC Adelphi"
> > > }
> > 

> > > Warning message:
> > > In if (stringr::str_detect(VLOOKUP_inR$NAME, "ADELPHI")) { :
> > > the condition has length > 1 and only the first element will be used
> > 

> > > #METHOD 3 FAILS
> > > ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME,
> > > "ADELPHI"), ASIP_combined_location_tally$ASSIGNED_COMPANY ==
> > > ASIP_combined_location_tally$ASSIGNED_COMPANY)
> > 

> > > Error in
> > > ifelse(stringr::str_detect(ASIP_combined_location_tally$NAME, :
> > 

> > > argument "no" is missing, with no default
> > 

> > > #METHOD4 FAILS
> > > VLOOKUP_inR_matching <- VLOOKUP_inR %>% mutate(ASSIGNED_COMPANY =
> > > ifelse(grepl(pattern = 'ABERDEEN', x = NAME), 'NEC Aberdeen', ''))
> > > VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>%
> > > mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'ADELPHI', x = NAME),
> > > 'NEC Adelphi', ''))
> > 

> > > VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>%
> > > mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'CARLISLE', x = NAME),
> > > 'NEC Carlisle Barracks', ''))
> > > VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>%
> > > mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'DETROIT', x = NAME),
> > > 'NEC Detroit Arsenal', ''))
> > > VLOOKUP_inR_matching <- VLOOKUP_inR_matching %>%
> > > mutate(ASSIGNED_COMPANY = ifelse(grepl(pattern = 'BELVOIR', x = NAME),
> > > 'NEC Fort Belvoir', ''))
> > 

> > > -----------the 4th method just over writes all previous changers back
> > > to ""
> > 

> > > 

> > 

> > ######################################################################
> > 

> > > 

> > 

> > > Any help offered would be so very greatly appreciated.
> > 

> > > Thanks you.
> > 

> > > r/
> > > gregg powell
> > > AZ
> > 

> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> 

> --
> 

> Sent from my phone. Please excuse my brevity.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201118/13bdf277/attachment.sig>

From tmr@g11 @end|ng |rom gm@||@com  Tue Nov 17 18:43:21 2020
From: tmr@g11 @end|ng |rom gm@||@com (C W)
Date: Tue, 17 Nov 2020 12:43:21 -0500
Subject: [R] How to understand the mentality behind tidyverse and ggplot2?
Message-ID: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>

Dear R list,

I am an old-school R user. I use apply(), with(), and which() in base
package instead of filter(), select(), separate() in Tidyverse. The idea of
pipeline (i.e. %>%) my code was foreign to me for a while. It makes the
code shorter, but sometimes less readable?

With ggplot2, I just don't understand how it is organized. Take this code:

> ggplot(diamonds, aes(x=carat, y=price)) + geom_point(aes(color=cut)) +
geom_smooth()

There are three plus signs. How do you know when to "add" and what to
"add"? I've seen more plus signs.

To me, aes() stands for aesthetic, meaning looks. So, anything related to
looks like points and smooth should be in aes(). Apparently, it's not the
case.

So, how does ggplot2 work? Could someone explain this for an old-school R
user?

Thank you!

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 18 19:28:19 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 18 Nov 2020 10:28:19 -0800
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
Message-ID: <CAGxFJbTrHpkvxfZjxOzW0dhHCVZhdNKQ+ik8=F4Z2FkP3F2v6Q@mail.gmail.com>

This is not the place for tutorials (although I recognize that many
responses and discussions do intersect tutoriality).
If you do a web search on ggplot tutorials you will find many good ones. Or
go to the RStudio website which links to resources, including Hadley
Wickham's book, which is probably the most authoritative. Incidentally,
ggplot is based on Leland WIlkinson's book "The Grammar of Graphics" that
provided the blueprint for Wickham's software (his PhD project at Iowa
State I believe).

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Nov 18, 2020 at 9:37 AM C W <tmrsg11 at gmail.com> wrote:

> Dear R list,
>
> I am an old-school R user. I use apply(), with(), and which() in base
> package instead of filter(), select(), separate() in Tidyverse. The idea of
> pipeline (i.e. %>%) my code was foreign to me for a while. It makes the
> code shorter, but sometimes less readable?
>
> With ggplot2, I just don't understand how it is organized. Take this code:
>
> > ggplot(diamonds, aes(x=carat, y=price)) + geom_point(aes(color=cut)) +
> geom_smooth()
>
> There are three plus signs. How do you know when to "add" and what to
> "add"? I've seen more plus signs.
>
> To me, aes() stands for aesthetic, meaning looks. So, anything related to
> looks like points and smooth should be in aes(). Apparently, it's not the
> case.
>
> So, how does ggplot2 work? Could someone explain this for an old-school R
> user?
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Wed Nov 18 19:31:39 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Wed, 18 Nov 2020 13:31:39 -0500
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
Message-ID: <CALrbzg3qs0dNGY1FvEWZ5xZ9iJd9yKWW8kVRePThzqsh96p=Yw@mail.gmail.com>

Hi,

I feel your pain.  As you have likely discovered yourself, there are
just about 10^14 tutorials/posts/tips out there on ggplot2.  See
https://rseek.org/?q=+ggplot2+tutorial for example.   Yikes!

One resource I found most helpful when I started is
https://evamaerey.github.io/ggplot_flipbook/ggplot_flipbook_xaringan.html#1.
This is a terrific resource for getting the feel of layering-up.

Hope you find it helpful.

CHeers,
Ben

On Wed, Nov 18, 2020 at 12:37 PM C W <tmrsg11 at gmail.com> wrote:
>
> Dear R list,
>
> I am an old-school R user. I use apply(), with(), and which() in base
> package instead of filter(), select(), separate() in Tidyverse. The idea of
> pipeline (i.e. %>%) my code was foreign to me for a while. It makes the
> code shorter, but sometimes less readable?
>
> With ggplot2, I just don't understand how it is organized. Take this code:
>
> > ggplot(diamonds, aes(x=carat, y=price)) + geom_point(aes(color=cut)) +
> geom_smooth()
>
> There are three plus signs. How do you know when to "add" and what to
> "add"? I've seen more plus signs.
>
> To me, aes() stands for aesthetic, meaning looks. So, anything related to
> looks like points and smooth should be in aes(). Apparently, it's not the
> case.
>
> So, how does ggplot2 work? Could someone explain this for an old-school R
> user?
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From ei m@iii@g oii iisse@@@  Wed Nov 18 19:49:12 2020
From: ei m@iii@g oii iisse@@@ (ei m@iii@g oii iisse@@@)
Date: Wed, 18 Nov 2020 20:49:12 +0200
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <CALrbzg3qs0dNGY1FvEWZ5xZ9iJd9yKWW8kVRePThzqsh96p=Yw@mail.gmail.com>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
 <CALrbzg3qs0dNGY1FvEWZ5xZ9iJd9yKWW8kVRePThzqsh96p=Yw@mail.gmail.com>
Message-ID: <965085b3-5cf8-4e93-a9ed-908bc69cf307@Spark>

RTFM, perhaps?

Or even worse, buy his book?

el

?
Sent from Dr Lisse?s iPad Mini 5
On 18 Nov 2020, 20:39 +0200, Ben Tupper <btupper at bigelow.org>, wrote:
> Hi,
>
> I feel your pain. As you have likely discovered yourself, there are
> just about 10^14 tutorials/posts/tips out there on ggplot2. See
> https://rseek.org/?q=+ggplot2+tutorial for example. Yikes!
>
> One resource I found most helpful when I started is
> https://evamaerey.github.io/ggplot_flipbook/ggplot_flipbook_xaringan.html#1.
> This is a terrific resource for getting the feel of layering-up.
>
> Hope you find it helpful.
>
> CHeers,
> Ben
>
> On Wed, Nov 18, 2020 at 12:37 PM C W <tmrsg11 at gmail.com> wrote:
> >
> > Dear R list,
> >
> > I am an old-school R user. I use apply(), with(), and which() in base
> > package instead of filter(), select(), separate() in Tidyverse. The idea of
> > pipeline (i.e. %>%) my code was foreign to me for a while. It makes the
> > code shorter, but sometimes less readable?
> >
> > With ggplot2, I just don't understand how it is organized. Take this code:
> >
> > > ggplot(diamonds, aes(x=carat, y=price)) + geom_point(aes(color=cut)) +
> > geom_smooth()
> >
> > There are three plus signs. How do you know when to "add" and what to
> > "add"? I've seen more plus signs.
> >
> > To me, aes() stands for aesthetic, meaning looks. So, anything related to
> > looks like points and smooth should be in aes(). Apparently, it's not the
> > case.
> >
> > So, how does ggplot2 work? Could someone explain this for an old-school R
> > user?
> >
> > Thank you!
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Ben Tupper
> Bigelow Laboratory for Ocean Science
> East Boothbay, Maine
> http://www.bigelow.org/
> https://eco.bigelow.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com  Wed Nov 18 20:30:03 2020
From: g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com (Gayathri Nagarajan)
Date: Wed, 18 Nov 2020 11:30:03 -0800
Subject: [R] Tutorial/vignette on modified Kneser Ney smoothing
Message-ID: <CANt+qPiBshCiUKYyADYvk-_xpekt_7aZJ-Ty0GmtS6-qTxH4_g@mail.gmail.com>

Hi Team

Iam a new learner trying to build n gram models from text corpus and trying
to understand the modified kneser Ney smoothing algorithm to code and build
my word prediction model.

Can someone point me to a vignette or tutorial that will help me learn this
?

Thanks in advance for your help

Regards
Gayathri

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 18 20:33:30 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 18 Nov 2020 11:33:30 -0800
Subject: [R] Tutorial/vignette on modified Kneser Ney smoothing
In-Reply-To: <CANt+qPiBshCiUKYyADYvk-_xpekt_7aZJ-Ty0GmtS6-qTxH4_g@mail.gmail.com>
References: <CANt+qPiBshCiUKYyADYvk-_xpekt_7aZJ-Ty0GmtS6-qTxH4_g@mail.gmail.com>
Message-ID: <CAGxFJbQL40M9EGug2SUv9cgqH0u0QV0SmSor-rc7sud8_phLAQ@mail.gmail.com>

Wrong list!

Google "kneser Ney smoothing algorithm" for possibilities.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Nov 18, 2020 at 11:30 AM Gayathri Nagarajan <
gayathri.nagarajan at gmail.com> wrote:

> Hi Team
>
> Iam a new learner trying to build n gram models from text corpus and trying
> to understand the modified kneser Ney smoothing algorithm to code and build
> my word prediction model.
>
> Can someone point me to a vignette or tutorial that will help me learn this
> ?
>
> Thanks in advance for your help
>
> Regards
> Gayathri
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 18 20:34:59 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 18 Nov 2020 11:34:59 -0800
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
Message-ID: <CAGxFJbTfN+fyiEfMUVdhwB-XE2oPNxP7RfkjFpAZkX=h5jwbMw@mail.gmail.com>

I should have said: Have you worked through the Vignettes and examples??

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Nov 18, 2020 at 9:37 AM C W <tmrsg11 at gmail.com> wrote:

> Dear R list,
>
> I am an old-school R user. I use apply(), with(), and which() in base
> package instead of filter(), select(), separate() in Tidyverse. The idea of
> pipeline (i.e. %>%) my code was foreign to me for a while. It makes the
> code shorter, but sometimes less readable?
>
> With ggplot2, I just don't understand how it is organized. Take this code:
>
> > ggplot(diamonds, aes(x=carat, y=price)) + geom_point(aes(color=cut)) +
> geom_smooth()
>
> There are three plus signs. How do you know when to "add" and what to
> "add"? I've seen more plus signs.
>
> To me, aes() stands for aesthetic, meaning looks. So, anything related to
> looks like points and smooth should be in aes(). Apparently, it's not the
> case.
>
> So, how does ggplot2 work? Could someone explain this for an old-school R
> user?
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h@w|ckh@m @end|ng |rom gm@||@com  Wed Nov 18 20:37:57 2020
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Wed, 18 Nov 2020 13:37:57 -0600
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
Message-ID: <CABdHhvHWBRQTW5jpkwiQKxhR_VRfex_jt1-6AMVzw8574XSdbg@mail.gmail.com>

I'd recommend two places to get started:

* https://r4ds.had.co.nz/data-visualisation.html for a quick intro to
ggplot2 (and the rest of the book explains the general tidyverse
philosophy)

* https://ggplot2-book.org for the full details of ggplot2.

Hadley

On Wed, Nov 18, 2020 at 11:37 AM C W <tmrsg11 at gmail.com> wrote:
>
> Dear R list,
>
> I am an old-school R user. I use apply(), with(), and which() in base
> package instead of filter(), select(), separate() in Tidyverse. The idea of
> pipeline (i.e. %>%) my code was foreign to me for a while. It makes the
> code shorter, but sometimes less readable?
>
> With ggplot2, I just don't understand how it is organized. Take this code:
>
> > ggplot(diamonds, aes(x=carat, y=price)) + geom_point(aes(color=cut)) +
> geom_smooth()
>
> There are three plus signs. How do you know when to "add" and what to
> "add"? I've seen more plus signs.
>
> To me, aes() stands for aesthetic, meaning looks. So, anything related to
> looks like points and smooth should be in aes(). Apparently, it's not the
> case.
>
> So, how does ggplot2 work? Could someone explain this for an old-school R
> user?
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov 18 21:38:53 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 18 Nov 2020 15:38:53 -0500
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
Message-ID: <a831fe00-5480-f429-2732-5e669e7816b5@gmail.com>

On 17/11/2020 12:43 p.m., C W wrote:
> Dear R list,
> 
> I am an old-school R user. I use apply(), with(), and which() in base
> package instead of filter(), select(), separate() in Tidyverse. The idea of
> pipeline (i.e. %>%) my code was foreign to me for a while. It makes the
> code shorter, but sometimes less readable?

Think of the pipe as pure syntactic sugar.  It doesn't really do 
anything, it just lets you write "f(g(x))" as "x %>% g() %>% f()" (where 
the parens "()" are optional).  Read it as "Take x and pass it to g(); 
take the result and pass it to f()", which is exactly how you'd read 
"f(g(x))".  The pipe  presents it in the same order as in English, which 
sometimes makes it a bit easier to read than the mathematical notation.

There's a lot more to tidyverse ideas besides the pipe.  The overview is 
in the "Tidyverse Manifesto" (a vignette in the tidyverse package), and 
details are in Grolemund and Wickham's book "R for Data Science".

> 
> With ggplot2, I just don't understand how it is organized. Take this code:

ggplot2 is much harder to understand, but Wickham's book "ggplot2: 
Elegant Graphics for Data Analysis" gives a really readable yet thorough 
description.

> 
>> ggplot(diamonds, aes(x=carat, y=price)) + geom_point(aes(color=cut)) +
> geom_smooth()
> 
> There are three plus signs. How do you know when to "add" and what to
> "add"? I've seen more plus signs.
> 
> To me, aes() stands for aesthetic, meaning looks. So, anything related to
> looks like points and smooth should be in aes(). Apparently, it's not the
> case.

Yes "aesthetic" was a really bad choice of word.

> So, how does ggplot2 work? Could someone explain this for an old-school R
> user?

Not in one email, but hopefully the references (which are both available 
online for free, or in a bookstore at some cost) can help.

Duncan Murdoch


From drj|m|emon @end|ng |rom gm@||@com  Wed Nov 18 23:10:30 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 19 Nov 2020 09:10:30 +1100
Subject: [R] Tutorial/vignette on modified Kneser Ney smoothing
In-Reply-To: <CANt+qPiBshCiUKYyADYvk-_xpekt_7aZJ-Ty0GmtS6-qTxH4_g@mail.gmail.com>
References: <CANt+qPiBshCiUKYyADYvk-_xpekt_7aZJ-Ty0GmtS6-qTxH4_g@mail.gmail.com>
Message-ID: <CA+8X3fVFUjgGErdwB0gcQ_kZ7itFFPgkeHYQbqdc9curZJGnCw@mail.gmail.com>

Hi Gayathri,
Maybe the cmscu package?

https://github.com/jasonkdavis/r-cmscu

Jim

On Thu, Nov 19, 2020 at 6:30 AM Gayathri Nagarajan <
gayathri.nagarajan at gmail.com> wrote:

> Hi Team
>
> Iam a new learner trying to build n gram models from text corpus and trying
> to understand the modified kneser Ney smoothing algorithm to code and build
> my word prediction model.
>
> Can someone point me to a vignette or tutorial that will help me learn this
> ?
>
> Thanks in advance for your help
>
> Regards
> Gayathri
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jwd @end|ng |rom @urewe@t@net  Thu Nov 19 00:24:52 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 18 Nov 2020 15:24:52 -0800
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
Message-ID: <20201118152452.30f6e5c6@Draco>

On Tue, 17 Nov 2020 12:43:21 -0500
C W <tmrsg11 at gmail.com> wrote:

> Dear R list,
> 
> I am an old-school R user. I use apply(), with(), and which() in base
> package instead of filter(), select(), separate() in Tidyverse. The
> idea of pipeline (i.e. %>%) my code was foreign to me for a while. It
> makes the code shorter, but sometimes less readable?
> 
> With ggplot2, I just don't understand how it is organized. Take this
> code:
> 
> > ggplot(diamonds, aes(x=carat, y=price)) +
> > geom_point(aes(color=cut)) +  
> geom_smooth()
> 
> There are three plus signs. How do you know when to "add" and what to
> "add"? I've seen more plus signs.
> 
> To me, aes() stands for aesthetic, meaning looks. So, anything
> related to looks like points and smooth should be in aes().
> Apparently, it's not the case.
> 
> So, how does ggplot2 work? Could someone explain this for an
> old-school R user?
> 
> Thank you!
> 
A really short form is to consider that ggplot2 syntax defines an
object, and then additional simply adds to it, which is what all the
plus signs are.  Ideally, you can start a ggplot call with a
designation of a target:

Instead of:
ggplot(diamonds, aes(x=carat, y=price)) + ...

use something like"

fig1 <- ggplot(diamonds, aes(x=carat, y=price)) + ...

This creates an environment object that can then be further modified.
Learning the syntax is a chore, but the output tends to be fine,
especially for publications and final graphics. One the other hand it's
slower and fussier than some of the more traditional approaches, which
are what I would prefer for EDA. 

JWDougherty


From roy@mende|@@ohn @end|ng |rom no@@@gov  Thu Nov 19 00:33:18 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 18 Nov 2020 15:33:18 -0800
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <20201118152452.30f6e5c6@Draco>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
 <20201118152452.30f6e5c6@Draco>
Message-ID: <35E03098-2ABA-4837-AD76-08DAD32B90AF@noaa.gov>

Personally I liked two workshops Thomas Lin Pedersen gave:

https://www.youtube.com/watch?v=h29g21z0a68
https://www.youtube.com/watch?v=0m4yywqNPVY&t=5219s

-Roy

> On Nov 18, 2020, at 3:24 PM, John via R-help <r-help at r-project.org> wrote:
> 
> On Tue, 17 Nov 2020 12:43:21 -0500
> C W <tmrsg11 at gmail.com> wrote:
> 
>> Dear R list,
>> 
>> I am an old-school R user. I use apply(), with(), and which() in base
>> package instead of filter(), select(), separate() in Tidyverse. The
>> idea of pipeline (i.e. %>%) my code was foreign to me for a while. It
>> makes the code shorter, but sometimes less readable?
>> 
>> With ggplot2, I just don't understand how it is organized. Take this
>> code:
>> 
>>> ggplot(diamonds, aes(x=carat, y=price)) +
>>> geom_point(aes(color=cut)) +  
>> geom_smooth()
>> 
>> There are three plus signs. How do you know when to "add" and what to
>> "add"? I've seen more plus signs.
>> 
>> To me, aes() stands for aesthetic, meaning looks. So, anything
>> related to looks like points and smooth should be in aes().
>> Apparently, it's not the case.
>> 
>> So, how does ggplot2 work? Could someone explain this for an
>> old-school R user?
>> 
>> Thank you!
>> 
> A really short form is to consider that ggplot2 syntax defines an
> object, and then additional simply adds to it, which is what all the
> plus signs are.  Ideally, you can start a ggplot call with a
> designation of a target:
> 
> Instead of:
> ggplot(diamonds, aes(x=carat, y=price)) + ...
> 
> use something like"
> 
> fig1 <- ggplot(diamonds, aes(x=carat, y=price)) + ...
> 
> This creates an environment object that can then be further modified.
> Learning the syntax is a chore, but the output tends to be fine,
> especially for publications and final graphics. One the other hand it's
> slower and fussier than some of the more traditional approaches, which
> are what I would prefer for EDA. 
> 
> JWDougherty
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From mh@||89446 @end|ng |rom @tt@net  Wed Nov 18 06:04:46 2020
From: mh@||89446 @end|ng |rom @tt@net (Mark Hall)
Date: Wed, 18 Nov 2020 05:04:46 +0000 (UTC)
Subject: [R] Inappropriate color name
In-Reply-To: <MMLZYTo--3-2@tuta.io>
References: <MMLZYTo--3-2@tuta.io>
Message-ID: <751179068.4552246.1605675886311-8461@mail.yahoo.com>

 
And then there is also the issue of some people seeing it offensive and others not seeing it offensive (and both camps are in the minority group).? Case inpoint is look at the term being used for self-identification with California Native American groups List of Federally-Recognized Tribes in CA | Links and Resources

| 
| 
| 
|  |  |

 |

 |
| 
|  | 
List of Federally-Recognized Tribes in CA | Links and Resources

The Indian Health Service (IHS), an agency within the Department of Health and Human Services, is responsible fo...
 |

 |

 |


I also distinctly remember in the NAGPRA brouha of 2008 on the UC Berkeley campus when the Metis chancellor of UCB at the time told several groups the term Indian was derogatory and shouldn't be used--a variety of California Native Americans gave him a piece of their mind in no uncertain terms...
Best, Mark E Hall
    On Tuesday, November 17, 2020, 7:22:33 AM PST, T. A. Milne via R-help <r-help at r-project.org> wrote:  
 
 
On Tue, 17 Nov 2020 07:54:01 +1100Jim Lemon <drjimlemon at gmail.com> <mailto:drjimlemon at gmail.com> wrote:

> Hi Elaine,There seems to be a popular contest to discover offence everywhere. Idon't think that it does anything against racism, sexism orantidisestablishmentarianism. Words are plucked from our vast lexiconto comfort or insult our fellows depending upon the intent of theuser. It is the intent that matters, not the poor word. Chasing thewords wastes your time, blames those who use the words harmlessly,and gives the real offender time to find another epithet.
>
Jim:? This is superbly expressed.? I wish that I could have saidthat! Your posting should go down in the annals of brilliant rhetoric,alongside Dr. Johnson's "Letter to Lord Chesterfield".cheers,Rolf
-- Honorary Research FellowDepartment of StatisticsUniversity of AucklandPhone: +64-9-373-7599 ext. 88276

To Rolf's excellent example, I would add Mandy Rice-Davies' immortal words from the witness box.



- T. Arthur Milne


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From mrd@v|dwr|ght1980 @end|ng |rom gm@||@com  Thu Nov 19 12:39:11 2020
From: mrd@v|dwr|ght1980 @end|ng |rom gm@||@com (David Wright)
Date: Thu, 19 Nov 2020 11:39:11 +0000
Subject: [R] Inappropriate color name
In-Reply-To: <751179068.4552246.1605675886311-8461@mail.yahoo.com>
References: <MMLZYTo--3-2@tuta.io>
 <751179068.4552246.1605675886311-8461@mail.yahoo.com>
Message-ID: <CAO7k4tMSUn5ccOHbnjN5tsq5d6wvXDFNEbZZxoM1w587gFbRDQ@mail.gmail.com>

Appropriation of Indian Red as 'Chestnut' (or other alternative) will
be viewed by some as 'making appropriate' the label for a colour, and
no doubt by other groups as cultural theft by excising reference to
its origin.

Seems the best option is to recognise the actual etymology carries no
semblance of offense whatsoever, and leave well alone.

On Thu, 19 Nov 2020 at 10:44, Mark Hall <mhall89446 at att.net> wrote:
>
>
> And then there is also the issue of some people seeing it offensive and others not seeing it offensive (and both camps are in the minority group).  Case inpoint is look at the term being used for self-identification with California Native American groups List of Federally-Recognized Tribes in CA | Links and Resources
>
> |
> |
> |
> |  |  |
>
>  |
>
>  |
> |
> |  |
> List of Federally-Recognized Tribes in CA | Links and Resources
>
> The Indian Health Service (IHS), an agency within the Department of Health and Human Services, is responsible fo...
>  |
>
>  |
>
>  |
>
>
> I also distinctly remember in the NAGPRA brouha of 2008 on the UC Berkeley campus when the Metis chancellor of UCB at the time told several groups the term Indian was derogatory and shouldn't be used--a variety of California Native Americans gave him a piece of their mind in no uncertain terms...
> Best, Mark E Hall
>     On Tuesday, November 17, 2020, 7:22:33 AM PST, T. A. Milne via R-help <r-help at r-project.org> wrote:
>
>
> On Tue, 17 Nov 2020 07:54:01 +1100Jim Lemon <drjimlemon at gmail.com> <mailto:drjimlemon at gmail.com> wrote:
>
> > Hi Elaine,There seems to be a popular contest to discover offence everywhere. Idon't think that it does anything against racism, sexism orantidisestablishmentarianism. Words are plucked from our vast lexiconto comfort or insult our fellows depending upon the intent of theuser. It is the intent that matters, not the poor word. Chasing thewords wastes your time, blames those who use the words harmlessly,and gives the real offender time to find another epithet.
> >
> Jim:  This is superbly expressed.  I wish that I could have saidthat! Your posting should go down in the annals of brilliant rhetoric,alongside Dr. Johnson's "Letter to Lord Chesterfield".cheers,Rolf
> -- Honorary Research FellowDepartment of StatisticsUniversity of AucklandPhone: +64-9-373-7599 ext. 88276
>
> To Rolf's excellent example, I would add Mandy Rice-Davies' immortal words from the witness box.
>
>
>
> - T. Arthur Milne
>
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tuech|er @end|ng |rom gmx@@t  Thu Nov 19 23:27:29 2020
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Thu, 19 Nov 2020 23:27:29 +0100
Subject: [R] Inappropriate color name
In-Reply-To: <CAO7k4tMSUn5ccOHbnjN5tsq5d6wvXDFNEbZZxoM1w587gFbRDQ@mail.gmail.com>
References: <MMLZYTo--3-2@tuta.io>
 <751179068.4552246.1605675886311-8461@mail.yahoo.com>
 <CAO7k4tMSUn5ccOHbnjN5tsq5d6wvXDFNEbZZxoM1w587gFbRDQ@mail.gmail.com>
Message-ID: <8f1e022b-69e7-10aa-821c-2c27b5c95842@gmx.at>

inline - David Wright wrote on 19.11.2020 12:39:
> Appropriation of Indian Red as 'Chestnut' (or other alternative) will
> be viewed by some as 'making appropriate' the label for a colour, and
> no doubt by other groups as cultural theft by excising reference to
> its origin.
>
> Seems the best option is to recognise the actual etymology carries no
> semblance of offense whatsoever, and leave well alone.
>

One may remember that people who might feel offended by "Indian Red"
(Native Americans) make up less than 0.5 percent of all "Indians".
It is hardly the fault of the people of India that Native Americans were
called Indians by an Italian navigator who thought he had landed in India.


From @pro @end|ng |rom un|me|b@edu@@u  Fri Nov 20 00:15:31 2020
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 19 Nov 2020 23:15:31 +0000
Subject: [R] [EXT] Re:  Inappropriate color name
In-Reply-To: <8f1e022b-69e7-10aa-821c-2c27b5c95842@gmx.at>
References: <MMLZYTo--3-2@tuta.io>
 <751179068.4552246.1605675886311-8461@mail.yahoo.com>
 <CAO7k4tMSUn5ccOHbnjN5tsq5d6wvXDFNEbZZxoM1w587gFbRDQ@mail.gmail.com>
 <8f1e022b-69e7-10aa-821c-2c27b5c95842@gmx.at>
Message-ID: <911881c6-dab8-4b0d-95e9-cfc4b0996a0b@Spark>

I see a lot of reasoning in this thread that I consider specious at best.

What seems clear to me, writing as a cis-gendered grey white male, is that we need to make more room.  How do we do this?  We do it by listening, reflecting, and responding.  If words that we use are hurtful, then we must change them.  This process will not be perfect. It will be messy.  Our feelings may be hurt, our principles outraged. Treasured words may disappear. That is how we make room.

I find appeals to etymology to be irrelevant. History is rife with examples of innocent symbols and words being co-opted.  We abandon those symbols and words, rightly, because the taint clings to them, rightly or wrongly.

I find appeals to broad usage to also be irrelevant.  Change starts where and when we all decide that it starts.  The R community is its own thing.

Finally, I find appeals to stakeholder group size to be irrelevant. The point is not to count the people who won't be offended.

Here's a personal example: more than 10 years ago, a co-author and I submitted a package to CRAN that was designed to make R a little easier to use.  We called it R-assist.  It sailed through all the checks, and was published on CRAN.  We were then besieged with complaints from native German speakers.  So we changed the name.

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On Nov 20, 2020, 9:28 AM +1100, Heinz Tuechler <tuechler at gmx.at>, wrote:
UoM notice: External email. Be cautious of links, attachments, or impersonation attempts

inline - David Wright wrote on 19.11.2020 12:39:
Appropriation of Indian Red as 'Chestnut' (or other alternative) will
be viewed by some as 'making appropriate' the label for a colour, and
no doubt by other groups as cultural theft by excising reference to
its origin.

Seems the best option is to recognise the actual etymology carries no
semblance of offense whatsoever, and leave well alone.


One may remember that people who might feel offended by "Indian Red"
(Native Americans) make up less than 0.5 percent of all "Indians".
It is hardly the fault of the people of India that Native Americans were
called Indians by an Italian navigator who thought he had landed in India.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From mrd@v|dwr|ght1980 @end|ng |rom gm@||@com  Fri Nov 20 02:06:37 2020
From: mrd@v|dwr|ght1980 @end|ng |rom gm@||@com (David Wright)
Date: Fri, 20 Nov 2020 01:06:37 +0000
Subject: [R] [EXT] Re: Inappropriate color name
In-Reply-To: <911881c6-dab8-4b0d-95e9-cfc4b0996a0b@Spark>
References: <MMLZYTo--3-2@tuta.io>
 <751179068.4552246.1605675886311-8461@mail.yahoo.com>
 <CAO7k4tMSUn5ccOHbnjN5tsq5d6wvXDFNEbZZxoM1w587gFbRDQ@mail.gmail.com>
 <8f1e022b-69e7-10aa-821c-2c27b5c95842@gmx.at>
 <911881c6-dab8-4b0d-95e9-cfc4b0996a0b@Spark>
Message-ID: <CAO7k4tN8wMaC_Fa1M48cFVeMPk-38iMydqHfiqys0f-qt2QcsQ@mail.gmail.com>

Is it really the proposal that the word 'Indian' should not be allowed
when referring to someone or something from India?  Context is
important.  Innumerable words can offend if used with that intent, but
we don't banish them because they have common standard meaning.  Words
which serve only as reminders of historical or present wrongs are
rightly abandoned.

As this started with colours: should the word 'coloured' be banned?
It is rightly deeply offensive to use this in referring to a person
and such usage should be unequivocally admonished.  If I ask on this
forum for advice on better ways in which my data plots could be
coloured for clarity I think that's ok.

Lastly, in the example I fail to see how the name R-assist is
offensive.  It's no doubt a faux pas and I would change the package
name since it conveys the wrong indication of its purpose.  But the
word 'racist' in itself is not offensive.  The act of being racist is
offensive and wrong.  Purging the word 'racist' won't help rid the
world of racism.


On Thu, 19 Nov 2020 at 23:16, Andrew Robinson <apro at unimelb.edu.au> wrote:
>
> I see a lot of reasoning in this thread that I consider specious at best.
>
> What seems clear to me, writing as a cis-gendered grey white male, is that we need to make more room.  How do we do this?  We do it by listening, reflecting, and responding.  If words that we use are hurtful, then we must change them.  This process will not be perfect. It will be messy.  Our feelings may be hurt, our principles outraged. Treasured words may disappear. That is how we make room.
>
> I find appeals to etymology to be irrelevant. History is rife with examples of innocent symbols and words being co-opted.  We abandon those symbols and words, rightly, because the taint clings to them, rightly or wrongly.
>
> I find appeals to broad usage to also be irrelevant.  Change starts where and when we all decide that it starts.  The R community is its own thing.
>
> Finally, I find appeals to stakeholder group size to be irrelevant. The point is not to count the people who won't be offended.
>
> Here's a personal example: more than 10 years ago, a co-author and I submitted a package to CRAN that was designed to make R a little easier to use.  We called it R-assist.  It sailed through all the checks, and was published on CRAN.  We were then besieged with complaints from native German speakers.  So we changed the name.
>
> Best wishes,
>
> Andrew
>
> --
> Andrew Robinson
> Director, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
> On Nov 20, 2020, 9:28 AM +1100, Heinz Tuechler <tuechler at gmx.at>, wrote:
> UoM notice: External email. Be cautious of links, attachments, or impersonation attempts
>
> inline - David Wright wrote on 19.11.2020 12:39:
> Appropriation of Indian Red as 'Chestnut' (or other alternative) will
> be viewed by some as 'making appropriate' the label for a colour, and
> no doubt by other groups as cultural theft by excising reference to
> its origin.
>
> Seems the best option is to recognise the actual etymology carries no
> semblance of offense whatsoever, and leave well alone.
>
>
> One may remember that people who might feel offended by "Indian Red"
> (Native Americans) make up less than 0.5 percent of all "Indians".
> It is hardly the fault of the people of India that Native Americans were
> called Indians by an Italian navigator who thought he had landed in India.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Nov 20 02:20:34 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 19 Nov 2020 17:20:34 -0800
Subject: [R] [EXT] Re: Inappropriate color name
In-Reply-To: <CAO7k4tN8wMaC_Fa1M48cFVeMPk-38iMydqHfiqys0f-qt2QcsQ@mail.gmail.com>
References: <MMLZYTo--3-2@tuta.io>
 <751179068.4552246.1605675886311-8461@mail.yahoo.com>
 <CAO7k4tMSUn5ccOHbnjN5tsq5d6wvXDFNEbZZxoM1w587gFbRDQ@mail.gmail.com>
 <8f1e022b-69e7-10aa-821c-2c27b5c95842@gmx.at>
 <911881c6-dab8-4b0d-95e9-cfc4b0996a0b@Spark>
 <CAO7k4tN8wMaC_Fa1M48cFVeMPk-38iMydqHfiqys0f-qt2QcsQ@mail.gmail.com>
Message-ID: <01298219-9f74-917f-5b1e-c6e9318483d1@comcast.net>

Can you guys take this off the list? I don't think that discussing these 
concerns is within the bounds of the list mandate. The original 
questioner has gotten the answer to his question (namely to correspond 
with the R-Core)? and this section of the thread is clearly not about 
how to solve problems with R.


-- 

David Winsemius

On 11/19/20 5:06 PM, David Wright wrote:
> Is it really the proposal that the word 'Indian' should not be allowed
> when referring to someone or something from India?  Context is
> important.  Innumerable words can offend if used with that intent, but
> we don't banish them because they have common standard meaning.  Words
> which serve only as reminders of historical or present wrongs are
> rightly abandoned.
>
> As this started with colours: should the word 'coloured' be banned?
> It is rightly deeply offensive to use this in referring to a person
> and such usage should be unequivocally admonished.  If I ask on this
> forum for advice on better ways in which my data plots could be
> coloured for clarity I think that's ok.
>
> Lastly, in the example I fail to see how the name R-assist is
> offensive.  It's no doubt a faux pas and I would change the package
> name since it conveys the wrong indication of its purpose.  But the
> word 'racist' in itself is not offensive.  The act of being racist is
> offensive and wrong.  Purging the word 'racist' won't help rid the
> world of racism.
>
>
> On Thu, 19 Nov 2020 at 23:16, Andrew Robinson <apro at unimelb.edu.au> wrote:
>> I see a lot of reasoning in this thread that I consider specious at best.
>>
>> What seems clear to me, writing as a cis-gendered grey white male, is that we need to make more room.  How do we do this?  We do it by listening, reflecting, and responding.  If words that we use are hurtful, then we must change them.  This process will not be perfect. It will be messy.  Our feelings may be hurt, our principles outraged. Treasured words may disappear. That is how we make room.
>>
>> I find appeals to etymology to be irrelevant. History is rife with examples of innocent symbols and words being co-opted.  We abandon those symbols and words, rightly, because the taint clings to them, rightly or wrongly.
>>
>> I find appeals to broad usage to also be irrelevant.  Change starts where and when we all decide that it starts.  The R community is its own thing.
>>
>> Finally, I find appeals to stakeholder group size to be irrelevant. The point is not to count the people who won't be offended.
>>
>> Here's a personal example: more than 10 years ago, a co-author and I submitted a package to CRAN that was designed to make R a little easier to use.  We called it R-assist.  It sailed through all the checks, and was published on CRAN.  We were then besieged with complaints from native German speakers.  So we changed the name.
>>
>> Best wishes,
>>
>> Andrew
>>
>> --
>> Andrew Robinson
>> Director, CEBRA and Professor of Biosecurity,
>> School/s of BioSciences and Mathematics & Statistics
>> University of Melbourne, VIC 3010 Australia
>> Tel: (+61) 0403 138 955
>> Email: apro at unimelb.edu.au
>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>
>> I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
>> On Nov 20, 2020, 9:28 AM +1100, Heinz Tuechler <tuechler at gmx.at>, wrote:
>> UoM notice: External email. Be cautious of links, attachments, or impersonation attempts
>>
>> inline - David Wright wrote on 19.11.2020 12:39:
>> Appropriation of Indian Red as 'Chestnut' (or other alternative) will
>> be viewed by some as 'making appropriate' the label for a colour, and
>> no doubt by other groups as cultural theft by excising reference to
>> its origin.
>>
>> Seems the best option is to recognise the actual etymology carries no
>> semblance of offense whatsoever, and leave well alone.
>>
>>
>> One may remember that people who might feel offended by "Indian Red"
>> (Native Americans) make up less than 0.5 percent of all "Indians".
>> It is hardly the fault of the people of India that Native Americans were
>> called Indians by an Italian navigator who thought he had landed in India.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Fri Nov 20 04:14:02 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 20 Nov 2020 16:14:02 +1300
Subject: [R] Inappropriate color name
In-Reply-To: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
Message-ID: <CAB8pepz2vuvb9X3Uco-BEi=SHQow7ha4vYC=fbB0g2ePBZ9oKA@mail.gmail.com>

> Surely these colors can be changed
> to something less offensive- my suggestion is "blush."
> How can I find out who to contact about making this happen?

Yes, they can.

    blush <- "#CD5C5C"
    mycols <- function () { #your code here...

I note that:

(1)
Changing existing code (esp in base packages) creates considerable problems.
Because code (not just CRAN packages) may depend on whatever is being changed.

(2)
The word "Blush" may also offend someone.
Blush is a type of makeup, often tested on animals.
Hence, we go around in a circle.


From jwd @end|ng |rom @urewe@t@net  Fri Nov 20 02:08:54 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Thu, 19 Nov 2020 17:08:54 -0800
Subject: [R] Inappropriate color name
In-Reply-To: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
References: <CAOvsXQZZUPQzyWKi=DsA88O7-bkj7Eefn2voa5eddMG9R6HokA@mail.gmail.com>
Message-ID: <20201119170854.2dbcd8a6@Draco>

On Sun, 15 Nov 2020 17:35:41 -0900
Lainey Gallenberg <laineygallenberg at gmail.com> wrote:

Lainey,

Assumptions are always fraught.  Your assumption about the "meaning" of
Indian Red is simply wrong.  Indian red is named for a lateritic soil in
India.  It isn't racist, and I have American Indian friends who have
expressed disappointment at the historical facts.  They also prefer
"American Indian" to "Native American."  So, what to do??? 

JWDougherty


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Nov 20 10:27:00 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 20 Nov 2020 04:27:00 -0500
Subject: [R] 
 How to understand the mentality behind tidyverse and ggplot2?
In-Reply-To: <a831fe00-5480-f429-2732-5e669e7816b5@gmail.com>
References: <CAE2FW2nXZUgpL6k4XFXqo4Ce4yOHCRBhGhv2nt1BAcWNncKgdQ@mail.gmail.com>
 <a831fe00-5480-f429-2732-5e669e7816b5@gmail.com>
Message-ID: <126b33b7-0cf8-1608-2939-29c109e55292@gmail.com>

On 18/11/2020 3:38 p.m., Duncan Murdoch wrote:
> On 17/11/2020 12:43 p.m., C W wrote:
>> Dear R list,
>>
>> I am an old-school R user. I use apply(), with(), and which() in base
>> package instead of filter(), select(), separate() in Tidyverse. The idea of
>> pipeline (i.e. %>%) my code was foreign to me for a while. It makes the
>> code shorter, but sometimes less readable?
> 
> Think of the pipe as pure syntactic sugar.  It doesn't really do
> anything, it just lets you write "f(g(x))" as "x %>% g() %>% f()" (where
> the parens "()" are optional).  Read it as "Take x and pass it to g();
> take the result and pass it to f()", which is exactly how you'd read
> "f(g(x))".  The pipe  presents it in the same order as in English, which
> sometimes makes it a bit easier to read than the mathematical notation.
> 
> There's a lot more to tidyverse ideas besides the pipe.  The overview is
> in the "Tidyverse Manifesto" (a vignette in the tidyverse package), and
> details are in Grolemund and Wickham's book "R for Data Science".

Whoops, I got the title wrong:  that's "The tidy tools manifesto".

Duncan Murdoch

> 
>>
>> With ggplot2, I just don't understand how it is organized. Take this code:
> 
> ggplot2 is much harder to understand, but Wickham's book "ggplot2:
> Elegant Graphics for Data Analysis" gives a really readable yet thorough
> description.
> 
>>
>>> ggplot(diamonds, aes(x=carat, y=price)) + geom_point(aes(color=cut)) +
>> geom_smooth()
>>
>> There are three plus signs. How do you know when to "add" and what to
>> "add"? I've seen more plus signs.
>>
>> To me, aes() stands for aesthetic, meaning looks. So, anything related to
>> looks like points and smooth should be in aes(). Apparently, it's not the
>> case.
> 
> Yes "aesthetic" was a really bad choice of word.
> 
>> So, how does ggplot2 work? Could someone explain this for an old-school R
>> user?
> 
> Not in one email, but hopefully the references (which are both available
> online for free, or in a bookstore at some cost) can help.
> 
> Duncan Murdoch
>


From M@Roo@ @end|ng |rom |1-out@ourc|ng@eu  Fri Nov 20 10:30:42 2020
From: M@Roo@ @end|ng |rom |1-out@ourc|ng@eu (Marc Roos)
Date: Fri, 20 Nov 2020 10:30:42 +0100
Subject: [R] [EXT] Re: Inappropriate color name
Message-ID: <"H0000071001855a1.1605864642.sx.f1-outsourcing.eu*"@MHS>


 >name since it conveys the wrong indication of its purpose.  But the
 >word 'racist' in itself is not offensive.  The act of being racist is
 >offensive and wrong.  Purging the word 'racist' won't help rid the
 >world of racism.

Indeed, if you would go down this road, where does it stop? You would be 
eligible getting discussions why the female species is described with a 
longer word than the male. Why is there even a 'man' part in 'woman'. I 
can bet there are man and woman finding this offensive!!!! ;)
What do you think about these symbols for male and female? Should be 
changed also, this male is now pointing up to heaven =  good, and female 
pointing down to hell =  bad? ;) 

 


From jwd @end|ng |rom @urewe@t@net  Fri Nov 20 11:25:31 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Fri, 20 Nov 2020 02:25:31 -0800
Subject: [R] Inappropriate color name
In-Reply-To: <8f1e022b-69e7-10aa-821c-2c27b5c95842@gmx.at>
References: <MMLZYTo--3-2@tuta.io>
 <751179068.4552246.1605675886311-8461@mail.yahoo.com>
 <CAO7k4tMSUn5ccOHbnjN5tsq5d6wvXDFNEbZZxoM1w587gFbRDQ@mail.gmail.com>
 <8f1e022b-69e7-10aa-821c-2c27b5c95842@gmx.at>
Message-ID: <20201120022531.0841fcab@Draco>

On Thu, 19 Nov 2020 23:27:29 +0100
Heinz Tuechler <tuechler at gmx.at> wrote:

> One may remember that people who might feel offended by "Indian Red"
> (Native Americans) make up less than 0.5 percent of all "Indians".
> It is hardly the fault of the people of India that Native Americans
> were called Indians by an Italian navigator who thought he had landed
> in India.

I have worked with and know or knew probably somewhere near 100
American Indians.  None of them were "offended" by "Indian," most
referred to themselves as "Indian," particularly when few outsiders
could even pronounce their tribal names.  Several of them referred me to
the works and words of Russel Means, Ogalala Lakota, an actor and
activist, who mocked the use of phrases such as "Native American" as
silly, and easily as offensive and racist in its failure to distinguish
among tribal peoples as any such sweeping label could be.


From ch@r|e@@@@nt@n@ @end|ng |rom gm@||@com  Fri Nov 20 11:28:16 2020
From: ch@r|e@@@@nt@n@ @end|ng |rom gm@||@com (Charles Novaes de Santana)
Date: Fri, 20 Nov 2020 11:28:16 +0100
Subject: [R] [EXT] Re: Inappropriate color name
In-Reply-To: <H0000071001855a1.1605864642.sx.f1-outsourcing.eu*@MHS>
References: <H0000071001855a1.1605864642.sx.f1-outsourcing.eu*@MHS>
Message-ID: <CAH-FEnjh3mV+f87aLOg179kbE4Nm2exzB2dDFNYyYKSau+jiWA@mail.gmail.com>

The fact that for the first time we have so many messages in this group is
proof that the question asked by Lainey is appropriate and necessary.

No language is static, they evolve thanks to discussions like this.
Remember that github  stopped using the term "master" to describe the main
branch of a repository for example.

I wonder what would happen if there was a color named "redneck" instead of
"indianred".

Charles

On Fri, 20 Nov 2020 at 10:37, Marc Roos <M.Roos at f1-outsourcing.eu> wrote:

>
>  >name since it conveys the wrong indication of its purpose.  But the
>  >word 'racist' in itself is not offensive.  The act of being racist is
>  >offensive and wrong.  Purging the word 'racist' won't help rid the
>  >world of racism.
>
> Indeed, if you would go down this road, where does it stop? You would be
> eligible getting discussions why the female species is described with a
> longer word than the male. Why is there even a 'man' part in 'woman'. I
> can bet there are man and woman finding this offensive!!!! ;)
> What do you think about these symbols for male and female? Should be
> changed also, this male is now pointing up to heaven =  good, and female
> pointing down to hell =  bad? ;)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
https://github.com/cndesantana

	[[alternative HTML version deleted]]


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Fri Nov 20 12:08:21 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments and acoustic tools)
Date: Fri, 20 Nov 2020 05:08:21 -0600
Subject: [R] Indian Red
In-Reply-To: <mailman.361444.1.1605870002.57780.r-help@r-project.org>
References: <mailman.361444.1.1605870002.57780.r-help@r-project.org>
Message-ID: <6c785a5b-29bf-e5e7-1108-69e9fa299840@gmail.com>

FWIW,

There is also Naples Yellow and other colors related to "place names" on 
artist palettes.? "Indian Red" is not related to North American Native 
peoples.
"/India Red/: Originally a natural, more purple iron oxide imported from 
/India/. First synthesized in the 18th century as a ?Mars? color, 
contemporary?...

Let it rest people.

Bruce Miller


-- 
Bruce W. Miller, PhD.
Neotropical bat risk and acoustic assessments
Conservation Fellow - Wildlife Conservation Society
Research Associate, American Museum of Natural History

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


	[[alternative HTML version deleted]]


From mm@|ten @end|ng |rom gm@||@com  Fri Nov 20 13:50:06 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Fri, 20 Nov 2020 07:50:06 -0500
Subject: [R] [EXT] Re: Inappropriate color name
In-Reply-To: <CAH-FEnjh3mV+f87aLOg179kbE4Nm2exzB2dDFNYyYKSau+jiWA@mail.gmail.com>
References: <H0000071001855a1.1605864642.sx.f1-outsourcing.eu*@MHS>
 <CAH-FEnjh3mV+f87aLOg179kbE4Nm2exzB2dDFNYyYKSau+jiWA@mail.gmail.com>
Message-ID: <CANOgrHY0MbGjb5d7V+A8fUoU7DUbYBrZHbL9=_Nv866GND9yTw@mail.gmail.com>

Here?s a daft idea that brings it back to R

For packages where there are problematic names, have aliases with
acceptable names.

Perhaps create a package to hold all those aliases.

Then if a user wants their preferred names, load up the aliasing package
and change them in bulk.  Using a package means everyone has access to a
standardized set of alternative terms.

Just a thought.  Coffee may not have kicked in yet.

On Fri, Nov 20, 2020 at 5:36 AM Charles Novaes de Santana <
charles.santana at gmail.com> wrote:

> The fact that for the first time we have so many messages in this group is
> proof that the question asked by Lainey is appropriate and necessary.
>
> No language is static, they evolve thanks to discussions like this.
> Remember that github  stopped using the term "master" to describe the main
> branch of a repository for example.
>
> I wonder what would happen if there was a color named "redneck" instead of
> "indianred".
>
> Charles
>
> On Fri, 20 Nov 2020 at 10:37, Marc Roos <M.Roos at f1-outsourcing.eu> wrote:
>
> >
> >  >name since it conveys the wrong indication of its purpose.  But the
> >  >word 'racist' in itself is not offensive.  The act of being racist is
> >  >offensive and wrong.  Purging the word 'racist' won't help rid the
> >  >world of racism.
> >
> > Indeed, if you would go down this road, where does it stop? You would be
> > eligible getting discussions why the female species is described with a
> > longer word than the male. Why is there even a 'man' part in 'woman'. I
> > can bet there are man and woman finding this offensive!!!! ;)
> > What do you think about these symbols for male and female? Should be
> > changed also, this male is now pointing up to heaven =  good, and female
> > pointing down to hell =  bad? ;)
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Um ax?! :)
>
> --
> Charles Novaes de Santana, PhD
> https://github.com/cndesantana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From M@Roo@ @end|ng |rom |1-out@ourc|ng@eu  Fri Nov 20 13:59:23 2020
From: M@Roo@ @end|ng |rom |1-out@ourc|ng@eu (Marc Roos)
Date: Fri, 20 Nov 2020 13:59:23 +0100
Subject: [R] [EXT] Re: Inappropriate color name
In-Reply-To: <CAH-FEnjh3mV+f87aLOg179kbE4Nm2exzB2dDFNYyYKSau+jiWA@mail.gmail.com>
Message-ID: <"H000007100185624.1605877163.sx.f1-outsourcing.eu*"@MHS>


> Remember that github  stopped using the term "master" to describe the 
main branch of a repository for example.

Github is some sort of national language institute, with a board of 
literary, sociology, psychology professors? 

Afaik is github owned by Microsoft, and Microsoft is known to be an 
offender of peoples rights. Who the @#$@#$ cares what they do?


From ch@r|e@@@@nt@n@ @end|ng |rom gm@||@com  Fri Nov 20 14:07:45 2020
From: ch@r|e@@@@nt@n@ @end|ng |rom gm@||@com (Charles Novaes de Santana)
Date: Fri, 20 Nov 2020 14:07:45 +0100
Subject: [R] Inappropriate color name
In-Reply-To: <H000007100185624.1605877163.sx.f1-outsourcing.eu*@MHS>
References: <CAH-FEnjh3mV+f87aLOg179kbE4Nm2exzB2dDFNYyYKSau+jiWA@mail.gmail.com>
 <H000007100185624.1605877163.sx.f1-outsourcing.eu*@MHS>
Message-ID: <CAH-FEnhViF8noBQOG0rj+873_VZN+nKcKod6YQexXjgp_=jN1w@mail.gmail.com>

Looks like they do better than us in some aspects.

On Friday, November 20, 2020, Marc Roos <M.Roos at f1-outsourcing.eu> wrote:

>
> > Remember that github  stopped using the term "master" to describe the
> main branch of a repository for example.
>
> Github is some sort of national language institute, with a board of
> literary, sociology, psychology professors?
>
> Afaik is github owned by Microsoft, and Microsoft is known to be an
> offender of peoples rights. Who the @#$@#$ cares what they do?
>
>
>

-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
https://github.com/cndesantana

	[[alternative HTML version deleted]]


From M@Roo@ @end|ng |rom |1-out@ourc|ng@eu  Fri Nov 20 14:20:19 2020
From: M@Roo@ @end|ng |rom |1-out@ourc|ng@eu (Marc Roos)
Date: Fri, 20 Nov 2020 14:20:19 +0100
Subject: [R] Inappropriate color name
In-Reply-To: <CAH-FEnhViF8noBQOG0rj+873_VZN+nKcKod6YQexXjgp_=jN1w@mail.gmail.com>
Message-ID: <"H00000710018562f.1605878419.sx.f1-outsourcing.eu*"@MHS>

 
And how would that relevant?
 
 >
 >Looks like they do better than us in some aspects.
 >
 >
 >
 >>
 >> > Remember that github  stopped using the term "master" to describe 
 >> > the
 >> main branch of a repository for example.
 >>
 >> Github is some sort of national language institute, with a board of 
 >> literary, sociology, psychology professors?
 >>
 >> Afaik is github owned by Microsoft, and Microsoft is known to be an 
 >> offender of peoples rights. Who the @#$@#$ cares what they do?
 >>
 >>
 >>
 >


From r@|ner_krug @end|ng |rom |c|oud@com  Fri Nov 20 12:24:33 2020
From: r@|ner_krug @end|ng |rom |c|oud@com (Rainer Krug)
Date: Fri, 20 Nov 2020 12:24:33 +0100
Subject: [R] [EXT] Re: Inappropriate color name
In-Reply-To: <CAH-FEnjh3mV+f87aLOg179kbE4Nm2exzB2dDFNYyYKSau+jiWA@mail.gmail.com>
References: <H0000071001855a1.1605864642.sx.f1-outsourcing.eu*@MHS>
 <CAH-FEnjh3mV+f87aLOg179kbE4Nm2exzB2dDFNYyYKSau+jiWA@mail.gmail.com>
Message-ID: <631DDF5A-4409-46D1-BCE3-10C4117137DF@icloud.com>

Could we please stop this thread here? Please take any further discussions off-list, or we would need an R-chat list for these kind of discussions (I would subscribe, though).

Cheers,

Rainer


> On 20 Nov 2020, at 11:28, Charles Novaes de Santana <charles.santana at gmail.com> wrote:
> 
> The fact that for the first time we have so many messages in this group is
> proof that the question asked by Lainey is appropriate and necessary.
> 
> No language is static, they evolve thanks to discussions like this.
> Remember that github  stopped using the term "master" to describe the main
> branch of a repository for example.
> 
> I wonder what would happen if there was a color named "redneck" instead of
> "indianred".
> 
> Charles
> 
> On Fri, 20 Nov 2020 at 10:37, Marc Roos <M.Roos at f1-outsourcing.eu> wrote:
> 
>> 
>>> name since it conveys the wrong indication of its purpose.  But the
>>> word 'racist' in itself is not offensive.  The act of being racist is
>>> offensive and wrong.  Purging the word 'racist' won't help rid the
>>> world of racism.
>> 
>> Indeed, if you would go down this road, where does it stop? You would be
>> eligible getting discussions why the female species is described with a
>> longer word than the male. Why is there even a 'man' part in 'woman'. I
>> can bet there are man and woman finding this offensive!!!! ;)
>> What do you think about these symbols for male and female? Should be
>> changed also, this male is now pointing up to heaven =  good, and female
>> pointing down to hell =  bad? ;)
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Um ax?! :)
> 
> --
> Charles Novaes de Santana, PhD
> https://github.com/cndesantana
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From r@|ner_krug @end|ng |rom |c|oud@com  Fri Nov 20 12:26:09 2020
From: r@|ner_krug @end|ng |rom |c|oud@com (Rainer Krug)
Date: Fri, 20 Nov 2020 12:26:09 +0100
Subject: [R] Indian Red
In-Reply-To: <6c785a5b-29bf-e5e7-1108-69e9fa299840@gmail.com>
References: <mailman.361444.1.1605870002.57780.r-help@r-project.org>
 <6c785a5b-29bf-e5e7-1108-69e9fa299840@gmail.com>
Message-ID: <022D1B48-938C-4103-9F58-DDD35D7DDFCA@icloud.com>

Let?s switch to the German name - ?Indisch Rot? instead...

> On 20 Nov 2020, at 12:08, Neotropical bat risk assessments and acoustic tools <neotropical.bats at gmail.com> wrote:
> 
> FWIW,
> 
> There is also Naples Yellow and other colors related to "place names" on 
> artist palettes.  "Indian Red" is not related to North American Native 
> peoples.
> "/India Red/: Originally a natural, more purple iron oxide imported from 
> /India/. First synthesized in the 18th century as a ?Mars? color, 
> contemporary ...
> 
> Let it rest people.
> 
> Bruce Miller
> 
> 
> -- 
> Bruce W. Miller, PhD.
> Neotropical bat risk and acoustic assessments
> Conservation Fellow - Wildlife Conservation Society
> Research Associate, American Museum of Natural History
> 
> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
> 
> Using acoustic sampling to identify and map species distributions
> and pioneering acoustic tools for ecology and conservation of bats for >25 years.
> 
> Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From r@ywong @end|ng |rom t@mu@edu  Fri Nov 20 22:39:31 2020
From: r@ywong @end|ng |rom t@mu@edu (Raymond Wong)
Date: Fri, 20 Nov 2020 15:39:31 -0600
Subject: [R] 2021 John M. Chambers Software Award
Message-ID: <2F461866-E73F-40E9-9F0A-961EA02ECF06@tamu.edu>

Dear R-help listers,

The Statistical Computing Section of the American Statistical Association announces the competition for the John M. Chambers Statistical Software Award. In 1998 the Association for Computing Machinery (ACM) presented the ACM Software System Award to John Chambers for the design and development of S. Dr. Chambers generously donated his award to the Statistical Computing Section to endow an annual prize for statistical software written by, or in collaboration with, an undergraduate or graduate student.

The submission deadline is December 15, 2020. Please visit http://asa.stat.uconn.edu <http://asa.stat.uconn.edu/> for more information.

Best regards,

Raymond Wong

Awards Chair
ASA Section on Statistical Computing

Associate Professor
Department of Statistics
Texas A&M University
	[[alternative HTML version deleted]]


From dunc@nw|| @end|ng |rom gm@||@com  Sat Nov 21 02:36:45 2020
From: dunc@nw|| @end|ng |rom gm@||@com (Duncan Williamson)
Date: Sat, 21 Nov 2020 08:36:45 +0700
Subject: [R] Values of ACF and PACF
Message-ID: <CAE64X0mEqrXSFw4Hw+oyn6r7Qctjd1NtBzrf5nWoXq3rWHN+aQ@mail.gmail.com>

I use the ACF and PACF functions as part of my investigations into
autocorrelation ...

Is there any way of getting R to show the numerical values provided by
these functions?

TIA

Duncan

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Nov 21 04:57:26 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 21 Nov 2020 16:57:26 +1300
Subject: [R] Values of ACF and PACF
In-Reply-To: <CAE64X0mEqrXSFw4Hw+oyn6r7Qctjd1NtBzrf5nWoXq3rWHN+aQ@mail.gmail.com>
References: <CAE64X0mEqrXSFw4Hw+oyn6r7Qctjd1NtBzrf5nWoXq3rWHN+aQ@mail.gmail.com>
Message-ID: <20201121165726.439b662c@rolf-Latitude-E7470>


On Sat, 21 Nov 2020 08:36:45 +0700
Duncan Williamson <duncanwil at gmail.com> wrote:

> I use the ACF and PACF functions as part of my investigations into
> autocorrelation ...
> 
> Is there any way of getting R to show the numerical values provided by
> these functions?

Of course.  Easy-peasy.  E.g.:

set.seed(42)
x <- rnorm(300)
ax0 <- acf(x,plot=FALSE) # The "plot=FALSE" is not actually necessary.
ax1 <- ax0$acf[,,1]

Reading the help file for a function is Always a Good Idea.
You can also always look at the code.  Just type:

    acf

Similarly for pacf()

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dunc@nw|| @end|ng |rom gm@||@com  Sat Nov 21 07:56:10 2020
From: dunc@nw|| @end|ng |rom gm@||@com (Duncan Williamson)
Date: Sat, 21 Nov 2020 13:56:10 +0700
Subject: [R] Values of ACF and PACF
In-Reply-To: <20201121165726.439b662c@rolf-Latitude-E7470>
References: <CAE64X0mEqrXSFw4Hw+oyn6r7Qctjd1NtBzrf5nWoXq3rWHN+aQ@mail.gmail.com>
 <20201121165726.439b662c@rolf-Latitude-E7470>
Message-ID: <CAE64X0nM1pE36tBe27DqLB1RdoOqUanWmtPjnF=8TM5MUTtq-w@mail.gmail.com>

Thank you, Rolf.

I am aware of how to open and read the help files, I searched the web, too.
However, as a not so blessed user of R, I don't always understand what I
read.

I will do my best with your advice.

Duncan

On Sat, 21 Nov 2020, 10:57 Rolf Turner, <r.turner at auckland.ac.nz> wrote:

>
> On Sat, 21 Nov 2020 08:36:45 +0700
> Duncan Williamson <duncanwil at gmail.com> wrote:
>
> > I use the ACF and PACF functions as part of my investigations into
> > autocorrelation ...
> >
> > Is there any way of getting R to show the numerical values provided by
> > these functions?
>
> Of course.  Easy-peasy.  E.g.:
>
> set.seed(42)
> x <- rnorm(300)
> ax0 <- acf(x,plot=FALSE) # The "plot=FALSE" is not actually necessary.
> ax1 <- ax0$acf[,,1]
>
> Reading the help file for a function is Always a Good Idea.
> You can also always look at the code.  Just type:
>
>     acf
>
> Similarly for pacf()
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>

	[[alternative HTML version deleted]]


From @||c|@b|@@|t @end|ng |rom protonm@||@com  Sat Nov 21 10:06:39 2020
From: @||c|@b|@@|t @end|ng |rom protonm@||@com (aliciablasit)
Date: Sat, 21 Nov 2020 09:06:39 +0000
Subject: [R] repeted measures MANOVA - MANOVA.RM package
Message-ID: <IJhXsjuRVgICtZVoeMx-9ApiurCvP6Pk0qerf68pje6_dCHP_6el1-hzKqwHRzEFN1cn-6v7IVLTg3H4eMCNg4yvZk6FWOpbkfB_ZV9nuCI=@protonmail.com>

Dear R-help listers,

I tried to use functions from MANOVA.RM package but without success. In my case, I have several independent and dependent variables. Each subject corresponds to a single combination of IV (because they are not real subjects, but numerical models). For each of them, I have several repeated measures, represented by a ?time? column. I want to explain my DV with my IV (so MANOVA seems appropriate) and consider the effect of several observations at different time (so repeated measures).

Here an example of my dataset:

Subject

Time

IV1

IV2

DV1

DV2

s1

1

1

1

14.1

s1

2

1

1

14.2

?

S2

1

1

2

13.4

S2

2

1

2

?

?

S3

?

I would like to apply a repeated measures MANOVA: multRM(cbind(DV1,DV2) ~ IV1*IV2*time, data = data, subject = ?subject?, within = ?time?).

However, due to my dataset nature, I always have only 1 observation for every factor-level combination. Hence, I am wondering if repeated measures MANOVA is theoretically applicable to my dataset or if another test is recommended instead. How should I deal with it?

Thanks in advance,

abt

Sent with [ProtonMail](https://protonmail.com) Secure Email.
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Nov 22 02:11:53 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 21 Nov 2020 17:11:53 -0800
Subject: [R] repeted measures MANOVA - MANOVA.RM package
In-Reply-To: <IJhXsjuRVgICtZVoeMx-9ApiurCvP6Pk0qerf68pje6_dCHP_6el1-hzKqwHRzEFN1cn-6v7IVLTg3H4eMCNg4yvZk6FWOpbkfB_ZV9nuCI=@protonmail.com>
References: <IJhXsjuRVgICtZVoeMx-9ApiurCvP6Pk0qerf68pje6_dCHP_6el1-hzKqwHRzEFN1cn-6v7IVLTg3H4eMCNg4yvZk6FWOpbkfB_ZV9nuCI=@protonmail.com>
Message-ID: <CAGxFJbREbMekRSQij+n5DJW9gX=HUtHHNOdSHoD1MrD0tZ=4HQ@mail.gmail.com>

From the posting guide (linked below -- please read it):

"*Questions about statistics:* The R mailing lists are primarily intended
for questions and discussion about the R software. However, questions about
statistical methodology are sometimes posted. If the question is well-asked
and of interest to someone on the list, it *may* elicit an informative
up-to-date answer. See also the Usenet groups sci.stat.consult (applied
statistics and consulting) and sci.stat.math (mathematical stat and
probability)."

and:

"If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

So don't be surprised if you get no useful responses here. You *might* try
stats.stackexchange.com for such statistics questions, but no guarantee
there either.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Nov 21, 2020 at 4:12 PM aliciablasit via R-help <
r-help at r-project.org> wrote:

> Dear R-help listers,
>
> I tried to use functions from MANOVA.RM package but without success. In my
> case, I have several independent and dependent variables. Each subject
> corresponds to a single combination of IV (because they are not real
> subjects, but numerical models). For each of them, I have several repeated
> measures, represented by a ?time? column. I want to explain my DV with my
> IV (so MANOVA seems appropriate) and consider the effect of several
> observations at different time (so repeated measures).
>
> Here an example of my dataset:
>
> Subject
>
> Time
>
> IV1
>
> IV2
>
> DV1
>
> DV2
>
> s1
>
> 1
>
> 1
>
> 1
>
> 14.1
>
> s1
>
> 2
>
> 1
>
> 1
>
> 14.2
>
> ?
>
> S2
>
> 1
>
> 1
>
> 2
>
> 13.4
>
> S2
>
> 2
>
> 1
>
> 2
>
> ?
>
> ?
>
> S3
>
> ?
>
> I would like to apply a repeated measures MANOVA: multRM(cbind(DV1,DV2) ~
> IV1*IV2*time, data = data, subject = ?subject?, within = ?time?).
>
> However, due to my dataset nature, I always have only 1 observation for
> every factor-level combination. Hence, I am wondering if repeated measures
> MANOVA is theoretically applicable to my dataset or if another test is
> recommended instead. How should I deal with it?
>
> Thanks in advance,
>
> abt
>
> Sent with [ProtonMail](https://protonmail.com) Secure Email.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dunc@nw|| @end|ng |rom gm@||@com  Sun Nov 22 09:57:53 2020
From: dunc@nw|| @end|ng |rom gm@||@com (Duncan Williamson)
Date: Sun, 22 Nov 2020 15:57:53 +0700
Subject: [R] Values of ACF and PACF
In-Reply-To: <CAGxFJbTdTw9_1Noa7COk+cvbZ3aCOMJGCenZBsm2unT6ABZAHg@mail.gmail.com>
References: <CAE64X0mEqrXSFw4Hw+oyn6r7Qctjd1NtBzrf5nWoXq3rWHN+aQ@mail.gmail.com>
 <20201121165726.439b662c@rolf-Latitude-E7470>
 <CAE64X0nM1pE36tBe27DqLB1RdoOqUanWmtPjnF=8TM5MUTtq-w@mail.gmail.com>
 <CAGxFJbTdTw9_1Noa7COk+cvbZ3aCOMJGCenZBsm2unT6ABZAHg@mail.gmail.com>
Message-ID: <CAE64X0kLuVg51iHAXsWszfZHqZFwVNO6cxCMWG+0V7thLzSdhA@mail.gmail.com>

There's a thought. Any suggestions in this case?

Duncan

On Sat, 21 Nov 2020, 22:47 Bert Gunter, <bgunter.4567 at gmail.com> wrote:

> There are also numerous R tutorials available that take it much slower and
> easier than the admittedly terse, dense Help files. You should take
> advantage of those that suit your needs.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Nov 20, 2020 at 10:56 PM Duncan Williamson <duncanwil at gmail.com>
> wrote:
>
>> Thank you, Rolf.
>>
>> I am aware of how to open and read the help files, I searched the web,
>> too.
>> However, as a not so blessed user of R, I don't always understand what I
>> read.
>>
>> I will do my best with your advice.
>>
>> Duncan
>>
>> On Sat, 21 Nov 2020, 10:57 Rolf Turner, <r.turner at auckland.ac.nz> wrote:
>>
>> >
>> > On Sat, 21 Nov 2020 08:36:45 +0700
>> > Duncan Williamson <duncanwil at gmail.com> wrote:
>> >
>> > > I use the ACF and PACF functions as part of my investigations into
>> > > autocorrelation ...
>> > >
>> > > Is there any way of getting R to show the numerical values provided by
>> > > these functions?
>> >
>> > Of course.  Easy-peasy.  E.g.:
>> >
>> > set.seed(42)
>> > x <- rnorm(300)
>> > ax0 <- acf(x,plot=FALSE) # The "plot=FALSE" is not actually necessary.
>> > ax1 <- ax0$acf[,,1]
>> >
>> > Reading the help file for a function is Always a Good Idea.
>> > You can also always look at the code.  Just type:
>> >
>> >     acf
>> >
>> > Similarly for pacf()
>> >
>> > cheers,
>> >
>> > Rolf Turner
>> >
>> > --
>> > Honorary Research Fellow
>> > Department of Statistics
>> > University of Auckland
>> > Phone: +64-9-373-7599 ext. 88276
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Nov 23 00:07:42 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 23 Nov 2020 10:07:42 +1100
Subject: [R] the invisible question
Message-ID: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>

Hi all,
I have encountered a problem in some emails with invisible characters
in code snippets that throw an error when pasted into the terminal
window:

Error: unexpected input in:
"star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
?"

This morning, after two hours of intense frustration, I found that I
could reproduce this by typing code containing the above line into
Kwrite, the text editor I use. When I pasted the code from Kwrite, it
worked in the R terminal window. When I pasted it into a gmail message
(set to Plain Text), copied that and pasted it into the R terminal
window, I got the error. I was helping a young friend with one of
those introductory R courses, but I have had this happen with other
requests on the R help list. I thought that it was the fault of the
fancy formatting in some emails, and could grumpily blame that, but
this is worse as I can't seem to edit it out. Anybody else had this
problem? I have sent a message to Gmail help.

Jim


From drj|m|emon @end|ng |rom gm@||@com  Mon Nov 23 00:17:21 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 23 Nov 2020 10:17:21 +1100
Subject: [R] the invisible question
In-Reply-To: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>
References: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>
Message-ID: <CA+8X3fXpXDN8b6R+FRyFvD1oKJiASwsDRVrWJyZZu-O+3kr=1A@mail.gmail.com>

Hi again,
I finally trapped the character (hexadecimal C2 capital A hat) with
some low trickery.

Jim

On Mon, Nov 23, 2020 at 10:07 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi all,
> I have encountered a problem in some emails with invisible characters
> in code snippets that throw an error when pasted into the terminal
> window:
>
> Error: unexpected input in:
> "star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
> ?"
>
> This morning, after two hours of intense frustration, I found that I
> could reproduce this by typing code containing the above line into
> Kwrite, the text editor I use. When I pasted the code from Kwrite, it
> worked in the R terminal window. When I pasted it into a gmail message
> (set to Plain Text), copied that and pasted it into the R terminal
> window, I got the error. I was helping a young friend with one of
> those introductory R courses, but I have had this happen with other
> requests on the R help list. I thought that it was the fault of the
> fancy formatting in some emails, and could grumpily blame that, but
> this is worse as I can't seem to edit it out. Anybody else had this
> problem? I have sent a message to Gmail help.
>
> Jim


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Nov 23 02:20:16 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 23 Nov 2020 14:20:16 +1300
Subject: [R] the invisible question
In-Reply-To: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>
References: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>
Message-ID: <20201123142016.5c20e70a@rolf-Latitude-E7470>


On Mon, 23 Nov 2020 10:07:42 +1100
Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi all,
> I have encountered a problem in some emails with invisible characters
> in code snippets that throw an error when pasted into the terminal
> window:
> 
> Error: unexpected input in:
> "star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
> ?"
> 
> This morning, after two hours of intense frustration, I found that I
> could reproduce this by typing code containing the above line into
> Kwrite, the text editor I use. When I pasted the code from Kwrite, it
> worked in the R terminal window. When I pasted it into a gmail message
> (set to Plain Text), copied that and pasted it into the R terminal
> window, I got the error. I was helping a young friend with one of
> those introductory R courses, but I have had this happen with other
> requests on the R help list. I thought that it was the fault of the
> fancy formatting in some emails, and could grumpily blame that, but
> this is worse as I can't seem to edit it out. Anybody else had this
> problem? I have sent a message to Gmail help.

(1) Don't use Kwrite (whatever that is) --- use vi[m] like civilised
( :-) ) people do. It's even available for Windoze.  Yes, there is
a steep learning curve, but once you've climbed it you'll never look
back.  (And for what it's worth, the curve is not as steep as that for
emacs!!! :-) )

(2) The function tools::showNonASCII might be helpful to you.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Nov 23 02:35:06 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 22 Nov 2020 17:35:06 -0800
Subject: [R] the invisible question
In-Reply-To: <20201123142016.5c20e70a@rolf-Latitude-E7470>
References: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>
 <20201123142016.5c20e70a@rolf-Latitude-E7470>
Message-ID: <eacb5d33-b97c-f034-24cb-52dddd397632@comcast.net>


On 11/22/20 5:20 PM, Rolf Turner wrote:
> On Mon, 23 Nov 2020 10:07:42 +1100
> Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi all,
>> I have encountered a problem in some emails with invisible characters
>> in code snippets that throw an error when pasted into the terminal
>> window:
>>
>> Error: unexpected input in:
>> "star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
>> ?"
>>
>> This morning, after two hours of intense frustration, I found that I
>> could reproduce this by typing code containing the above line into
>> Kwrite, the text editor I use. When I pasted the code from Kwrite, it
>> worked in the R terminal window. When I pasted it into a gmail message
>> (set to Plain Text), copied that and pasted it into the R terminal
>> window, I got the error. I was helping a young friend with one of
>> those introductory R courses, but I have had this happen with other
>> requests on the R help list. I thought that it was the fault of the
>> fancy formatting in some emails, and could grumpily blame that, but
>> this is worse as I can't seem to edit it out. Anybody else had this
>> problem? I have sent a message to Gmail help.
> (1) Don't use Kwrite (whatever that is) --- use vi[m] like civilised
> ( :-) ) people do. It's even available for Windoze.  Yes, there is
> a steep learning curve, but once you've climbed it you'll never look
> back.  (And for what it's worth, the curve is not as steep as that for
> emacs!!! :-) )
>
> (2) The function tools::showNonASCII might be helpful to you.

Thunderbird on Ubuntu displays it ats:

"star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,

followed by a line feed and then a diamond with a question-mark and a closing double-quote.


library(tools)
showNonASCII("star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
+ ?")
1: star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
<ef><bf><bd>


-- 

David.

>
> cheers,
>
> Rolf
>


From drj|m|emon @end|ng |rom gm@||@com  Mon Nov 23 03:34:43 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 23 Nov 2020 13:34:43 +1100
Subject: [R] the invisible question
In-Reply-To: <eacb5d33-b97c-f034-24cb-52dddd397632@comcast.net>
References: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>
 <20201123142016.5c20e70a@rolf-Latitude-E7470>
 <eacb5d33-b97c-f034-24cb-52dddd397632@comcast.net>
Message-ID: <CA+8X3fWAcMNEbXLyhtotTjy2woEBOeio0bkW-wuBaS8nWseZCg@mail.gmail.com>

Yep, that's it. It's not Kwrite that is doing it, but Gmail. I'll try
to find a Gmail help list or help desk that can provide info. thanks.

Jim

On Mon, Nov 23, 2020 at 12:35 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
>
> On 11/22/20 5:20 PM, Rolf Turner wrote:
> > On Mon, 23 Nov 2020 10:07:42 +1100
> > Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi all,
> >> I have encountered a problem in some emails with invisible characters
> >> in code snippets that throw an error when pasted into the terminal
> >> window:
> >>
> >> Error: unexpected input in:
> >> "star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
> >> ?"
> >>
> >> This morning, after two hours of intense frustration, I found that I
> >> could reproduce this by typing code containing the above line into
> >> Kwrite, the text editor I use. When I pasted the code from Kwrite, it
> >> worked in the R terminal window. When I pasted it into a gmail message
> >> (set to Plain Text), copied that and pasted it into the R terminal
> >> window, I got the error. I was helping a young friend with one of
> >> those introductory R courses, but I have had this happen with other
> >> requests on the R help list. I thought that it was the fault of the
> >> fancy formatting in some emails, and could grumpily blame that, but
> >> this is worse as I can't seem to edit it out. Anybody else had this
> >> problem? I have sent a message to Gmail help.
> > (1) Don't use Kwrite (whatever that is) --- use vi[m] like civilised
> > ( :-) ) people do. It's even available for Windoze.  Yes, there is
> > a steep learning curve, but once you've climbed it you'll never look
> > back.  (And for what it's worth, the curve is not as steep as that for
> > emacs!!! :-) )
> >
> > (2) The function tools::showNonASCII might be helpful to you.
>
> Thunderbird on Ubuntu displays it ats:
>
> "star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
>
> followed by a line feed and then a diamond with a question-mark and a closing double-quote.
>
>
> library(tools)
> showNonASCII("star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
> + ?")
> 1: star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
> <ef><bf><bd>
>
>
> --
>
> David.
>
> >
> > cheers,
> >
> > Rolf
> >


From @purd|e@@ @end|ng |rom gm@||@com  Mon Nov 23 05:53:30 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 23 Nov 2020 17:53:30 +1300
Subject: [R] the invisible question
In-Reply-To: <CA+8X3fXpXDN8b6R+FRyFvD1oKJiASwsDRVrWJyZZu-O+3kr=1A@mail.gmail.com>
References: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>
 <CA+8X3fXpXDN8b6R+FRyFvD1oKJiASwsDRVrWJyZZu-O+3kr=1A@mail.gmail.com>
Message-ID: <CAB8pepy_VR6jjR=UCk8F3-rw719LAPyVRWgp_iq1-z1R1As1=A@mail.gmail.com>

I have no idea what everyone's talking about.
What invisible character????

The black triangle triangle with a question mark renders fine in (my) gmail.
And it's a unicode character used when there was a problem reading
(presumably text) data.

https://en.wikipedia.org/wiki/Specials_(Unicode_block)

If I copy and paste it into R, it's replaced by a regular question mark.


On Mon, Nov 23, 2020 at 12:18 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi again,
> I finally trapped the character (hexadecimal C2 capital A hat) with
> some low trickery.
>
> Jim
>
> On Mon, Nov 23, 2020 at 10:07 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi all,
> > I have encountered a problem in some emails with invisible characters
> > in code snippets that throw an error when pasted into the terminal
> > window:
> >
> > Error: unexpected input in:
> > "star_wars_matrix<-matrix(box_office,nrow=3,byrow=TRUE,
> > ?"
> >
> > This morning, after two hours of intense frustration, I found that I
> > could reproduce this by typing code containing the above line into
> > Kwrite, the text editor I use. When I pasted the code from Kwrite, it
> > worked in the R terminal window. When I pasted it into a gmail message
> > (set to Plain Text), copied that and pasted it into the R terminal
> > window, I got the error. I was helping a young friend with one of
> > those introductory R courses, but I have had this happen with other
> > requests on the R help list. I thought that it was the fault of the
> > fancy formatting in some emails, and could grumpily blame that, but
> > this is worse as I can't seem to edit it out. Anybody else had this
> > problem? I have sent a message to Gmail help.
> >
> > Jim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Nov 23 06:14:22 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 23 Nov 2020 18:14:22 +1300
Subject: [R] the invisible question
In-Reply-To: <CAB8pepy_VR6jjR=UCk8F3-rw719LAPyVRWgp_iq1-z1R1As1=A@mail.gmail.com>
References: <CA+8X3fW2cfu8UzCWLh4K6kQeRCMQXYV7zuzOnu-WP2Fy3TeznA@mail.gmail.com>
 <CA+8X3fXpXDN8b6R+FRyFvD1oKJiASwsDRVrWJyZZu-O+3kr=1A@mail.gmail.com>
 <CAB8pepy_VR6jjR=UCk8F3-rw719LAPyVRWgp_iq1-z1R1As1=A@mail.gmail.com>
Message-ID: <CAB8pepxVay9W4Mff0JnU8n4xqBOJCmk-bkea+yto8E7Y239V-Q@mail.gmail.com>

If I copy a paste into Consulus (my Java/Swing based software), I get a square.
(Screenshot, attached).

But the interesting thing is, that there's a different result, running
the code via the source function (with the defaults anyway), from
piping it in.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: ss.png
Type: image/png
Size: 21526 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201123/0813b900/attachment.png>

From |orre@t@wh|te @end|ng |rom getexpo@d@t@@com  Mon Nov 23 18:08:33 2020
From: |orre@t@wh|te @end|ng |rom getexpo@d@t@@com (Forrest White)
Date: Mon, 23 Nov 2020 17:08:33 +0000
Subject: [R] R-Project
Message-ID: <MAXPR01MB2846A0CEC8CF053AE917106980FC0@MAXPR01MB2846.INDPRD01.PROD.OUTLOOK.COM>



Hi,

I am following up to confirm if you are interested in acquiring the Visitors/Registrants List.

World Pork Expo 2020
Jun-2020 ( Cancelled )
New Date-09-Jun-2021
Des Moines,USA
Registrants Counts: 3,000

Each record of the list contains: Contact Name, Email Address, Company Name, URL/Website, Phone No, Title/Designation.

It is difficult to physically perform the event because of the corona virus. However, currently the best way to grow your business is through digital. This list will help you pass information about your organization and products directly and digitally to the buyer. This list will help you to acquire many potential clients/leads.

If you are interested in acquiring the list, we can provide you the cost and additional details.

I look forward to hearing from you.
Thanks & Regards,
Forrest White
Business Analyst
If you don't want to hear from me again Please unsub



	[[alternative HTML version deleted]]


From z|xu@n@q| @end|ng |rom duke@edu  Tue Nov 24 21:12:21 2020
From: z|xu@n@q| @end|ng |rom duke@edu (Zixuan Qi)
Date: Tue, 24 Nov 2020 20:12:21 +0000
Subject: [R] high-frequency data in R
Message-ID: <BYAPR05MB59597D111F9DF663442FD33898FB0@BYAPR05MB5959.namprd05.prod.outlook.com>

Hello,

I attach the sample data in the email and you can use the data to try my code.
My code is as follow.

library('highfrequency')
library('xts')
data=read.table("sample data.csv",header=F,skip = 1,stringsAsFactors=FALSE,sep="\t")
colnames(data)=c(" ",'SYMBOL',"PRICE","PERMNO")
id <- unique(data$PERMNO)
mydata <- data.frame()
for (i in id){
  tmp <-data[data$PERMNO==i,]
  row.names(tmp)=tmp[,1]
  tmp=tmp[,-1]
  tmp.xts <- as.xts(tmp, order.by=as.POSIXlt(rownames(tmp),format="%Y/%m/%d %H:%M"))
  mydata <- rbind(mydata,tmp.xts)
}

The problem is that when I try to program tmp.xts <- as.xts(tmp, order.by=as.POSIXlt(rownames(tmp),format="%Y/%m/%d %H:%M")), then I get NaN rownames. I don't know why.

Thanks very much.

From z|xu@n@q| @end|ng |rom duke@edu  Tue Nov 24 21:20:15 2020
From: z|xu@n@q| @end|ng |rom duke@edu (Zixuan Qi)
Date: Tue, 24 Nov 2020 20:20:15 +0000
Subject: [R] =?gb2312?b?u9i4tDogaGlnaC1mcmVxdWVuY3kgZGF0YSBpbiBS?=
In-Reply-To: <BYAPR05MB59597D111F9DF663442FD33898FB0@BYAPR05MB5959.namprd05.prod.outlook.com>
References: <BYAPR05MB59597D111F9DF663442FD33898FB0@BYAPR05MB5959.namprd05.prod.outlook.com>
Message-ID: <BYAPR05MB595942509D6610E02EF989E598FB0@BYAPR05MB5959.namprd05.prod.outlook.com>

DATE    SYMBOL  price   permno
10/1/2019 9:30  AA      93.26   24109
10/1/2019 9:31  AA      93.44   24109
10/1/2019 9:32  AA      93.44   24109
10/1/2019 9:33  AA      93.28   24109
10/1/2019 9:34  AA      93.37   24109
10/1/2019 9:35  AA      93.37   24109
10/1/2019 9:36  AA      93.33   24109
10/1/2019 9:30  AA      114.47  10138
10/1/2019 9:32  AA      114.22  10138
10/1/2019 9:33  AA      114.26  10138
10/1/2019 9:34  AA      114.27  10138
10/1/2019 9:35  AA      114.01  10138
10/1/2019 9:36  AA      114.07  10138
10/1/2019 9:37  AA      114.39  10138
10/1/2019 9:38  AA      114.32  10138
The sample data is here.
________________________________
??????: Zixuan Qi
???????: 2020??11??25?? 4:12
?????: r-help at r-project.org <r-help at r-project.org>
????: high-frequency data in R

Hello,

I attach the sample data in the email and you can use the data to try my code.
My code is as follow.

library('highfrequency')
library('xts')
data=read.table("sample data.csv",header=F,skip = 1,stringsAsFactors=FALSE,sep="\t")
colnames(data)=c(" ",'SYMBOL',"PRICE","PERMNO")
id <- unique(data$PERMNO)
mydata <- data.frame()
for (i in id){
  tmp <-data[data$PERMNO==i,]
  row.names(tmp)=tmp[,1]
  tmp=tmp[,-1]
  tmp.xts <- as.xts(tmp, order.by=as.POSIXlt(rownames(tmp),format="%Y/%m/%d %H:%M"))
  mydata <- rbind(mydata,tmp.xts)
}

The problem is that when I try to program tmp.xts <- as.xts(tmp, order.by=as.POSIXlt(rownames(tmp),format="%Y/%m/%d %H:%M")), then I get NaN rownames. I don't know why.

Thanks very much.

	[[alternative HTML version deleted]]


From djnord|und @end|ng |rom gm@||@com  Tue Nov 24 22:02:19 2020
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Tue, 24 Nov 2020 13:02:19 -0800
Subject: [R] =?utf-8?b?5Zue5aSNOiBoaWdoLWZyZXF1ZW5jeSBkYXRhIGluIFI=?=
In-Reply-To: <BYAPR05MB595942509D6610E02EF989E598FB0@BYAPR05MB5959.namprd05.prod.outlook.com>
References: <BYAPR05MB59597D111F9DF663442FD33898FB0@BYAPR05MB5959.namprd05.prod.outlook.com>
 <BYAPR05MB595942509D6610E02EF989E598FB0@BYAPR05MB5959.namprd05.prod.outlook.com>
Message-ID: <de040900-a337-5f0b-9c82-4fa9103b3790@gmail.com>

On 11/24/2020 12:20 PM, Zixuan Qi wrote:
> DATE    SYMBOL  price   permno
> 10/1/2019 9:30  AA      93.26   24109
> 10/1/2019 9:31  AA      93.44   24109
> 10/1/2019 9:32  AA      93.44   24109
> 10/1/2019 9:33  AA      93.28   24109
> 10/1/2019 9:34  AA      93.37   24109
> 10/1/2019 9:35  AA      93.37   24109
> 10/1/2019 9:36  AA      93.33   24109
> 10/1/2019 9:30  AA      114.47  10138
> 10/1/2019 9:32  AA      114.22  10138
> 10/1/2019 9:33  AA      114.26  10138
> 10/1/2019 9:34  AA      114.27  10138
> 10/1/2019 9:35  AA      114.01  10138
> 10/1/2019 9:36  AA      114.07  10138
> 10/1/2019 9:37  AA      114.39  10138
> 10/1/2019 9:38  AA      114.32  10138
> The sample data is here.
> ________________________________
> ??????: Zixuan Qi
> ???????: 2020??11??25?? 4:12
> ?????: r-help at r-project.org <r-help at r-project.org>
> ????: high-frequency data in R
>
> Hello,
>
> I attach the sample data in the email and you can use the data to try my code.
> My code is as follow.
>
> library('highfrequency')
> library('xts')
> data=read.table("sample data.csv",header=F,skip = 1,stringsAsFactors=FALSE,sep="\t")
> colnames(data)=c(" ",'SYMBOL',"PRICE","PERMNO")
> id <- unique(data$PERMNO)
> mydata <- data.frame()
> for (i in id){
>    tmp <-data[data$PERMNO==i,]
>    row.names(tmp)=tmp[,1]
>    tmp=tmp[,-1]
>    tmp.xts <- as.xts(tmp, order.by=as.POSIXlt(rownames(tmp),format="%Y/%m/%d %H:%M"))
>    mydata <- rbind(mydata,tmp.xts)
> }
>
> The problem is that when I try to program tmp.xts <- as.xts(tmp, order.by=as.POSIXlt(rownames(tmp),format="%Y/%m/%d %H:%M")), then I get NaN rownames. I don't know why.
>
> Thanks very much.
>
> 	[[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

You have the wrong format for your date conversion.? It should be

format="%m/%d/%Y %H:%M"


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From r-p@ck@ge@ @end|ng |rom r-project@org  Wed Nov 25 14:27:03 2020
From: r-p@ck@ge@ @end|ng |rom r-project@org (Marc Schwartz via R-packages)
Date: Wed, 25 Nov 2020 08:27:03 -0500
Subject: [R] [R-pkgs] WriteXLS Version 6.1.0 - Bug Fix Release
Message-ID: <A60CA282-CCCF-4A50-82E2-505AA9B424D7@me.com>

Hi All,

WriteXLS version 6.1.0 has been released and is in the process of becoming available via CRAN.

This is a bug fix release, as in version 6.0.0, there were occasions where certain integer values in source data frames, containing specific patterns of trailing and embedded zeros, were written to the Excel worksheets as left justified text values, as opposed to right justified numeric values.

Please download and install the updated version at your convenience.

Thanks and regards,

Marc Schwartz

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Wed Nov 25 22:26:46 2020
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Thu, 26 Nov 2020 02:26:46 +0500
Subject: [R] Need help to calculate allele score
Message-ID: <CAG0CrLjOmJLrspAB64FugcC_7i5dP01zXy7otUrkU1oi9xkW2w@mail.gmail.com>

Go to page http://zzz.bwh.harvard.edu/plink/profile.shtml and follow the
help to generate a basic allele score using your independently associated
SNPs.  Use R to make the myprofile.rawfile required.

I am unable to generate .raw file which will contain allele score

I have tried this script:
results_2049669_adjusted <-
read.table("results_2049669.assoc.linear.adjusted", header=T)

#display first 15 SNPs
results_2049669_adjusted [1:15,]

system("plink_mac/plink --bfile BB5707 --clump results_2049669.assoc.linear
--clump-p1 5e-08 --clump-p2 0.05 --clump-r2 0.1 --clump-kb 250 --out
results_2049669.assoc.linear_clumped")

results_2049669_clumped <-
read.table("results_2049669.assoc.linear_clumped.clumped", header=T)
results_2049669_clumped[1:15 ,1:6] ## 2 hits we have

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 25 22:51:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 25 Nov 2020 13:51:10 -0800
Subject: [R] Need help to calculate allele score
In-Reply-To: <CAG0CrLjOmJLrspAB64FugcC_7i5dP01zXy7otUrkU1oi9xkW2w@mail.gmail.com>
References: <CAG0CrLjOmJLrspAB64FugcC_7i5dP01zXy7otUrkU1oi9xkW2w@mail.gmail.com>
Message-ID: <CAGxFJbRVx_bM4OBRDyN=rnbKsnqLKZi53AHFTYZUGc5=NRWS+A@mail.gmail.com>

This list has a no-homework policy. Referring to the posting guide linked
below:

"*Basic statistics and classroom homework:* R-help is not intended for
these."

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Nov 25, 2020 at 1:27 PM Anas Jamshed <anasjamshed1994 at gmail.com>
wrote:

> Go to page http://zzz.bwh.harvard.edu/plink/profile.shtml and follow the
> help to generate a basic allele score using your independently associated
> SNPs.  Use R to make the myprofile.rawfile required.
>
> I am unable to generate .raw file which will contain allele score
>
> I have tried this script:
> results_2049669_adjusted <-
> read.table("results_2049669.assoc.linear.adjusted", header=T)
>
> #display first 15 SNPs
> results_2049669_adjusted [1:15,]
>
> system("plink_mac/plink --bfile BB5707 --clump results_2049669.assoc.linear
> --clump-p1 5e-08 --clump-p2 0.05 --clump-r2 0.1 --clump-kb 250 --out
> results_2049669.assoc.linear_clumped")
>
> results_2049669_clumped <-
> read.table("results_2049669.assoc.linear_clumped.clumped", header=T)
> results_2049669_clumped[1:15 ,1:6] ## 2 hits we have
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||u|@@rev|||@ @end|ng |rom gm@||@com  Wed Nov 25 11:29:00 2020
From: ||u|@@rev|||@ @end|ng |rom gm@||@com (=?UTF-8?Q?Llu=C3=ADs_Revilla?=)
Date: Wed, 25 Nov 2020 11:29:00 +0100
Subject: [R] [R-pkgs] experDesign
Message-ID: <CAN+W6_sOwBn7MNCgBN0LoKRMgF5HxdOs78jptj=nzHv54q0Mvg@mail.gmail.com>

Hello,

Some weeks ago the experDesign package was released on CRAN:
https://CRAN.R-project.org/package=experDesign
The package helps designing experiments to avoid batch effects
confounding the result by distributing the samples on batches
according to their features.

If you or your colleagues design this kind of analysis I hope
experDesign will be useful. I greatly appreciate your feedback,
especially if you find bugs (despite the testing) or think of any
improvement.

To all developers, maintainers and the CRAN team that made this
possible: Thank you!

Best regards,

Llu?s

GitHub: https://github.com/llrs/experDesign
CRAN: https://CRAN.R-project.org/package=experDesign

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @rn@ud@g@boury @end|ng |rom gm@||@com  Wed Nov 25 16:37:12 2020
From: @rn@ud@g@boury @end|ng |rom gm@||@com (arnaud gaboury)
Date: Wed, 25 Nov 2020 16:37:12 +0100
Subject: [R] getting historical data from cryptocurrency exchange
Message-ID: <d94a655f-0c4e-dea4-7d38-e0107869d2fb@gmail.com>

I need to download basic OHLCV (Open, High, Low, Close, Volume) in a
hourly format from various cryptocurrency exchanges.
There is the crypto package[0] but it has been removed from CRAN. Then
there is the coinmarketcapr[1] package on CRAN, but it is limited to a
paid service, coinmarketcap, which sell data.

Browsing the web, I mainly found Python scripts to fetch the data, which
I would like to avoid. Can anyone point me to any github or website with
material about crypto data fetching with R?

Thank you


[0]https://cran.r-project.org/web/packages/crypto/index.html
[1]https://github.com/amrrs/coinmarketcapr


From gerge|y @end|ng |rom @now|@net  Thu Nov 26 00:17:42 2020
From: gerge|y @end|ng |rom @now|@net (=?UTF-8?Q?Gergely_Dar=C3=B3czi?=)
Date: Thu, 26 Nov 2020 00:17:42 +0100
Subject: [R] getting historical data from cryptocurrency exchange
In-Reply-To: <d94a655f-0c4e-dea4-7d38-e0107869d2fb@gmail.com>
References: <d94a655f-0c4e-dea4-7d38-e0107869d2fb@gmail.com>
Message-ID: <CAPvvxJUct1bHuE95N8iofsG6eGQGxUTeaW-Yps6QFQq7-1N0QQ@mail.gmail.com>

Hi,

I've started https://github.com/daroczig/binancer for educational
purposes, but since then, it became pretty feature-rich for the
Binance API, and you can get historical data for free (see
binance_klines).

Best,
Gergely


On Thu, Nov 26, 2020 at 12:13 AM arnaud gaboury
<arnaud.gaboury at gmail.com> wrote:
>
> I need to download basic OHLCV (Open, High, Low, Close, Volume) in a
> hourly format from various cryptocurrency exchanges.
> There is the crypto package[0] but it has been removed from CRAN. Then
> there is the coinmarketcapr[1] package on CRAN, but it is limited to a
> paid service, coinmarketcap, which sell data.
>
> Browsing the web, I mainly found Python scripts to fetch the data, which
> I would like to avoid. Can anyone point me to any github or website with
> material about crypto data fetching with R?
>
> Thank you
>
>
> [0]https://cran.r-project.org/web/packages/crypto/index.html
> [1]https://github.com/amrrs/coinmarketcapr
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Fri Nov 27 17:47:54 2020
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Fri, 27 Nov 2020 16:47:54 +0000
Subject: [R] calling r from java
Message-ID: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>

Dear all,

As a java developer I prefer to develop rest services using jax-rs.

Now I developed a service that executes Rscript (Using ProcessBuilder),
sends text to stdin of the process and reads from stdout of the
process.

Works fine, but this is inefficient, because every call reloads all
that is needed.

I have looked into this:

https://github.com/microsoft/java-client-library
https://rforge.net/Rserve/
several other sources on stackoverflow etc.

A lot of these sources seem old or not maintained.

Now my question: Is there a preferred and maintained way to efficiently
call R from Java? Preferrably available in maven central?

Regards, Eduard


-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201127/7d818716/attachment.sig>

From bgunter@4567 @end|ng |rom gm@||@com  Sat Nov 28 01:55:39 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 27 Nov 2020 16:55:39 -0800
Subject: [R] calling r from java
In-Reply-To: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
Message-ID: <CAGxFJbR5Xa_WSa2iM8_hUsZ5bqBHLnqkK-UHR8Qq1dc9MJdCkw@mail.gmail.com>

Well ... google is your friend.
"calling R from Java"
brought up what looked to me like useful resources, including this:
https://www.cnblogs.com/mavlarn/archive/2012/12/24/2831688.html

Have you done this already?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Nov 27, 2020 at 4:01 PM Eduard Drenth <edrenth at fryske-akademy.nl>
wrote:

> Dear all,
>
> As a java developer I prefer to develop rest services using jax-rs.
>
> Now I developed a service that executes Rscript (Using ProcessBuilder),
> sends text to stdin of the process and reads from stdout of the
> process.
>
> Works fine, but this is inefficient, because every call reloads all
> that is needed.
>
> I have looked into this:
>
> https://github.com/microsoft/java-client-library
> https://rforge.net/Rserve/
> several other sources on stackoverflow etc.
>
> A lot of these sources seem old or not maintained.
>
> Now my question: Is there a preferred and maintained way to efficiently
> call R from Java? Preferrably available in maven central?
>
> Regards, Eduard
>
>
> --
> Eduard Drenth, Software Architekt
>
> edrenth at fryske-akademy.nl
>
> Doelestrjitte 8
> 8911 DX  Ljouwert
> +31 58 234 30 47
> +31 62 094 34 28 (priv?)
>
> skype: eduarddrenth
> https://github.com/eduarddrenth
> frisian.eu
> gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth
>
>
> Op freed bin ik th?s/wurkje ik minder
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov 28 02:13:57 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Nov 2020 17:13:57 -0800
Subject: [R] calling r from java
In-Reply-To: <CAGxFJbR5Xa_WSa2iM8_hUsZ5bqBHLnqkK-UHR8Qq1dc9MJdCkw@mail.gmail.com>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
 <CAGxFJbR5Xa_WSa2iM8_hUsZ5bqBHLnqkK-UHR8Qq1dc9MJdCkw@mail.gmail.com>
Message-ID: <E136CF22-4A01-45CF-BFA9-7ED9CDFEB9FB@dcn.davis.ca.us>

Not being a Java programmer I was going to sit this one out, but when Bert points at an 8-year old blog that OP was already saying was too old I figure even I can Google better than that.

https://github.com/oracle/fastr

which has activity within the last 3 days, though I really don't know anything about it beyond that.

FWIW I can't recall ever seeing mention of calling R from Java on this list before, so don't get your hopes up. Of course, that subject would in general be off topic so that isn't saying much.

On November 27, 2020 4:55:39 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Well ... google is your friend.
>"calling R from Java"
>brought up what looked to me like useful resources, including this:
>https://www.cnblogs.com/mavlarn/archive/2012/12/24/2831688.html
>
>Have you done this already?
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Fri, Nov 27, 2020 at 4:01 PM Eduard Drenth
><edrenth at fryske-akademy.nl>
>wrote:
>
>> Dear all,
>>
>> As a java developer I prefer to develop rest services using jax-rs.
>>
>> Now I developed a service that executes Rscript (Using
>ProcessBuilder),
>> sends text to stdin of the process and reads from stdout of the
>> process.
>>
>> Works fine, but this is inefficient, because every call reloads all
>> that is needed.
>>
>> I have looked into this:
>>
>> https://github.com/microsoft/java-client-library
>> https://rforge.net/Rserve/
>> several other sources on stackoverflow etc.
>>
>> A lot of these sources seem old or not maintained.
>>
>> Now my question: Is there a preferred and maintained way to
>efficiently
>> call R from Java? Preferrably available in maven central?
>>
>> Regards, Eduard
>>
>>
>> --
>> Eduard Drenth, Software Architekt
>>
>> edrenth at fryske-akademy.nl
>>
>> Doelestrjitte 8
>> 8911 DX  Ljouwert
>> +31 58 234 30 47
>> +31 62 094 34 28 (priv?)
>>
>> skype: eduarddrenth
>> https://github.com/eduarddrenth
>> frisian.eu
>> gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth
>>
>>
>> Op freed bin ik th?s/wurkje ik minder
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Nov 28 03:50:54 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 27 Nov 2020 18:50:54 -0800
Subject: [R] calling r from java
In-Reply-To: <E136CF22-4A01-45CF-BFA9-7ED9CDFEB9FB@dcn.davis.ca.us>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
 <CAGxFJbR5Xa_WSa2iM8_hUsZ5bqBHLnqkK-UHR8Qq1dc9MJdCkw@mail.gmail.com>
 <E136CF22-4A01-45CF-BFA9-7ED9CDFEB9FB@dcn.davis.ca.us>
Message-ID: <CAGxFJbRUvS7BNFRFespGJ89ApHAShO82kYP78r8Tsw+YedQ0SQ@mail.gmail.com>

Heh heh. Criticism accepted. However...

1. Web searching first is still a good idea.
2. Old in not **necessarily** useless -- I fervently hope(calculus has been
around since, umm...).

This also **might** be useful to the OP:
https://cran.r-project.org/web/views/WebTechnologies.html

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Nov 27, 2020 at 5:14 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Not being a Java programmer I was going to sit this one out, but when Bert
> points at an 8-year old blog that OP was already saying was too old I
> figure even I can Google better than that.
>
> https://github.com/oracle/fastr
>
> which has activity within the last 3 days, though I really don't know
> anything about it beyond that.
>
> FWIW I can't recall ever seeing mention of calling R from Java on this
> list before, so don't get your hopes up. Of course, that subject would in
> general be off topic so that isn't saying much.
>
> On November 27, 2020 4:55:39 PM PST, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >Well ... google is your friend.
> >"calling R from Java"
> >brought up what looked to me like useful resources, including this:
> >https://www.cnblogs.com/mavlarn/archive/2012/12/24/2831688.html
> >
> >Have you done this already?
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Fri, Nov 27, 2020 at 4:01 PM Eduard Drenth
> ><edrenth at fryske-akademy.nl>
> >wrote:
> >
> >> Dear all,
> >>
> >> As a java developer I prefer to develop rest services using jax-rs.
> >>
> >> Now I developed a service that executes Rscript (Using
> >ProcessBuilder),
> >> sends text to stdin of the process and reads from stdout of the
> >> process.
> >>
> >> Works fine, but this is inefficient, because every call reloads all
> >> that is needed.
> >>
> >> I have looked into this:
> >>
> >> https://github.com/microsoft/java-client-library
> >> https://rforge.net/Rserve/
> >> several other sources on stackoverflow etc.
> >>
> >> A lot of these sources seem old or not maintained.
> >>
> >> Now my question: Is there a preferred and maintained way to
> >efficiently
> >> call R from Java? Preferrably available in maven central?
> >>
> >> Regards, Eduard
> >>
> >>
> >> --
> >> Eduard Drenth, Software Architekt
> >>
> >> edrenth at fryske-akademy.nl
> >>
> >> Doelestrjitte 8
> >> 8911 DX  Ljouwert
> >> +31 58 234 30 47
> >> +31 62 094 34 28 (priv?)
> >>
> >> skype: eduarddrenth
> >> https://github.com/eduarddrenth
> >> frisian.eu
> >> gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth
> >>
> >>
> >> Op freed bin ik th?s/wurkje ik minder
> >>
> >>
> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sat Nov 28 03:55:36 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 28 Nov 2020 15:55:36 +1300
Subject: [R] calling r from java
In-Reply-To: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
Message-ID: <CAB8pepxoOo-=Nj7c0Jhk443AVsZANw_H7J0iTn8tZ0OhMKFVhw@mail.gmail.com>

Hi Eduard,

> Now I developed a service that executes Rscript (Using ProcessBuilder),
> sends text to stdin of the process and reads from stdout of the
> process.

This doesn't answer your question, but may be relevant.
I have a java-based application that works on a similar principle.
(The code is horrendously bad and most of it should be thrown away).

I'm planning to write a terminal emulator, in the near future.
(Currently, second place on my top-level todo list).

The primary objective is to build object-oriented and message passing
APIs on top of the core terminal emulation system, with at least some
cross platform functionality.
Noting that, in my opinion, the cross-platform aspect is more
important for R, than in many other IPC topics.

Hence, I'm interested in hearing "wishlist" items for such APIs.


From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Sat Nov 28 12:57:49 2020
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Sat, 28 Nov 2020 11:57:49 +0000
Subject: [R] calling r from java
In-Reply-To: <CAB8pepxoOo-=Nj7c0Jhk443AVsZANw_H7J0iTn8tZ0OhMKFVhw@mail.gmail.com>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
 <CAB8pepxoOo-=Nj7c0Jhk443AVsZANw_H7J0iTn8tZ0OhMKFVhw@mail.gmail.com>
Message-ID: <d44b09923c04e49e95f57d2714af14ae609ca64e.camel@fryske-akademy.nl>

Thanks all, I'll go for https://www.rforge.net/JRI/ and the libraries
in maven https://search.maven.org/search?q=jri

The maven library is build from  here 
https://www.rforge.net/rJava/files/ back in 2017.

After this no new libs are published to maven.

It would be nice (understatement) if publishing new rJava components to
maven becomes a regular part of R deveopment processes.

This would promote R use from Java which I think is good.

And of course I can help.

Bye, Eduard

-----Original Message-----
From: Abby Spurdle <spurdle.a at gmail.com>
To: Eduard Drenth <edrenth at fryske-akademy.nl>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] calling r from java
Date: Sat, 28 Nov 2020 15:55:36 +1300

Hi Eduard,
> Now I developed a service that executes Rscript (Using
> ProcessBuilder),sends text to stdin of the process and reads from
> stdout of theprocess.

This doesn't answer your question, but may be relevant.I have a java-
based application that works on a similar principle.(The code is
horrendously bad and most of it should be thrown away).
I'm planning to write a terminal emulator, in the near
future.(Currently, second place on my top-level todo list).
The primary objective is to build object-oriented and message
passingAPIs on top of the core terminal emulation system, with at least
somecross platform functionality.Noting that, in my opinion, the cross-
platform aspect is moreimportant for R, than in many other IPC topics.
Hence, I'm interested in hearing "wishlist" items for such APIs.
-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201128/7e81dbbe/attachment.sig>

From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Sat Nov 28 13:09:53 2020
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Sat, 28 Nov 2020 12:09:53 +0000
Subject: [R] calling r from java
In-Reply-To: <d44b09923c04e49e95f57d2714af14ae609ca64e.camel@fryske-akademy.nl>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
 <CAB8pepxoOo-=Nj7c0Jhk443AVsZANw_H7J0iTn8tZ0OhMKFVhw@mail.gmail.com>
 <d44b09923c04e49e95f57d2714af14ae609ca64e.camel@fryske-akademy.nl>
Message-ID: <e38f3855b2005d0a25e67960ec1bddf3d21c7541.camel@fryske-akademy.nl>

Found this https://github.com/s-u/rJava as the place for rJava
development and issues

-----Original Message-----
From: Eduard Drenth <edrenth at fryske-akademy.nl>
To: spurdle.a at gmail.com <spurdle.a at gmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] calling r from java
Date: Sat, 28 Nov 2020 11:57:49 +0000

Thanks all, I'll go for https://www.rforge.net/JRI/ and the librariesin
maven https://search.maven.org/search?q=jri

The maven library is build from  here 
https://www.rforge.net/rJava/files/ back in 2017.
After this no new libs are published to maven.
It would be nice (understatement) if publishing new rJava components
tomaven becomes a regular part of R deveopment processes.
This would promote R use from Java which I think is good.
And of course I can help.
Bye, Eduard
-----Original Message-----From: Abby Spurdle <spurdle.a at gmail.com>To:
Eduard Drenth <edrenth at fryske-akademy.nl>Cc: r-help at r-project.org <
r-help at r-project.org>Subject: Re: [R] calling r from javaDate: Sat, 28
Nov 2020 15:55:36 +1300
Hi Eduard,
> Now I developed a service that executes Rscript
> (UsingProcessBuilder),sends text to stdin of the process and reads
> fromstdout of theprocess.

This doesn't answer your question, but may be relevant.I have a java-
based application that works on a similar principle.(The code
ishorrendously bad and most of it should be thrown away).I'm planning
to write a terminal emulator, in the nearfuture.(Currently, second
place on my top-level todo list).The primary objective is to build
object-oriented and messagepassingAPIs on top of the core terminal
emulation system, with at leastsomecross platform functionality.Noting
that, in my opinion, the cross-platform aspect is moreimportant for R,
than in many other IPC topics.Hence, I'm interested in hearing
"wishlist" items for such
APIs.______________________________________________R-help at r-project.org 
mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201128/449ed73e/attachment.sig>

From @dr|@n @end|ng |rom tr@p|ett|@org  Sat Nov 28 20:36:14 2020
From: @dr|@n @end|ng |rom tr@p|ett|@org (Adrian Trapletti)
Date: Sat, 28 Nov 2020 20:36:14 +0100
Subject: [R] calling r from java (Eduard Drenth)
In-Reply-To: <mailman.361480.1.1606561201.44767.r-help@r-project.org>
References: <mailman.361480.1.1606561201.44767.r-help@r-project.org>
Message-ID: <CAFmikf35C4PrU3rWhQf6fTrOpgGuPa=UmqrK8R4TmQr7xDnY7w@mail.gmail.com>

Hi Eduard,

I recommend separating the R quant code from Java and deploy the R code as
a REST service, e.g. using https://github.com/opencpu/opencpu

Best regards
Adrian

Adrian Trapletti

Steinstrasse 9b, 8610 Uster, Switzerland
P +41 44 994 56 30  |  M +41 79 103 71 31
adrian at trapletti.org  |  www.trapletti.org

On Sat, Nov 28, 2020 at 12:00 PM <r-help-request at r-project.org> wrote:
>
> Send R-help mailing list submissions to
>         r-help at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-help
> or, via email, send a message with subject or body 'help' to
>         r-help-request at r-project.org
>
> You can reach the person managing the list at
>         r-help-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-help digest..."
>
>
> Today's Topics:
>
>    1. calling r from java (Eduard Drenth)
>    2. Re: calling r from java (Bert Gunter)
>    3. Re: calling r from java (Jeff Newmiller)
>    4. Re: calling r from java (Bert Gunter)
>    5. Re: calling r from java (Abby Spurdle)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 27 Nov 2020 16:47:54 +0000
> From: Eduard Drenth <edrenth at fryske-akademy.nl>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] calling r from java
> Message-ID:
>         <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel at fryske-akademy.nl>
> Content-Type: text/plain; charset="utf-8"
>
> Dear all,
>
> As a java developer I prefer to develop rest services using jax-rs.
>
> Now I developed a service that executes Rscript (Using ProcessBuilder),
> sends text to stdin of the process and reads from stdout of the
> process.
>
> Works fine, but this is inefficient, because every call reloads all
> that is needed.
>
> I have looked into this:
>
> https://github.com/microsoft/java-client-library
> https://rforge.net/Rserve/
> several other sources on stackoverflow etc.
>
> A lot of these sources seem old or not maintained.
>
> Now my question: Is there a preferred and maintained way to efficiently
> call R from Java? Preferrably available in maven central?
>
> Regards, Eduard
>
>
> --
> Eduard Drenth, Software Architekt
>
> edrenth at fryske-akademy.nl
>
> Doelestrjitte 8
> 8911 DX  Ljouwert
> +31 58 234 30 47
> +31 62 094 34 28 (priv?)
>
> skype: eduarddrenth
> https://github.com/eduarddrenth
> frisian.eu
> gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth
>
>
> Op freed bin ik th?s/wurkje ik minder
>
>
>
>
>
> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: signature.asc
> Type: application/pgp-signature
> Size: 488 bytes
> Desc: This is a digitally signed message part
> URL: <
https://stat.ethz.ch/pipermail/r-help/attachments/20201127/7d818716/attachment-0001.sig
>
>
>

	[[alternative HTML version deleted]]


From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Sun Nov 29 09:12:43 2020
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Sun, 29 Nov 2020 08:12:43 +0000
Subject: [R] calling r from java (Eduard Drenth)
In-Reply-To: <CAFmikf35C4PrU3rWhQf6fTrOpgGuPa=UmqrK8R4TmQr7xDnY7w@mail.gmail.com>
References: <mailman.361480.1.1606561201.44767.r-help@r-project.org>
 <CAFmikf35C4PrU3rWhQf6fTrOpgGuPa=UmqrK8R4TmQr7xDnY7w@mail.gmail.com>
Message-ID: <8700ec87b5ff0498447c41af4fd732002b9ff3ff.camel@fryske-akademy.nl>

Because of efficiency? But almost all development I do is in
Java/Xml/XQuery so I am interested in efficiently integrating the two.
And for our small institution it is important to limit the number of
technologies / frameworks.
Bye, Eduard
-----Original Message-----From: Adrian Trapletti <adrian at trapletti.org>
To: Eduard Drenth <edrenth at fryske-akademy.nl>Cc: 
R-help at r-project.orgSubject: Re: calling r from java (Eduard
Drenth)Date: Sat, 28 Nov 2020 20:36:14 +0100
Hi Eduard,
I recommend separating the R quant code from Java and deploy the R code
as a REST service, e.g. using https://github.com/opencpu/opencpu  

Best regards
Adrian

Adrian Trapletti

Steinstrasse 9b, 8610 Uster, Switzerland
P +41 44 994 56 30  |  M +41 79 103 71 31
adrian at trapletti.org  |  www.trapletti.org

On Sat, Nov 28, 2020 at 12:00 PM <r-help-request at r-project.org> wrote:
>
> Send R-help mailing list submissions to
>         r-help at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-help
> or, via email, send a message with subject or body 'help' to
>         r-help-request at r-project.org
>
> You can reach the person managing the list at
>         r-help-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-help digest..."
>
>
> Today's Topics:
>
>    1. calling r from java (Eduard Drenth)
>    2. Re: calling r from java (Bert Gunter)
>    3. Re: calling r from java (Jeff Newmiller)
>    4. Re: calling r from java (Bert Gunter)
>    5. Re: calling r from java (Abby Spurdle)
>
> -------------------------------------------------------------------
---
>
> Message: 1
> Date: Fri, 27 Nov 2020 16:47:54 +0000
> From: Eduard Drenth <edrenth at fryske-akademy.nl>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] calling r from java
> Message-ID:
>         <
fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel at fryske-akademy.nl>
> Content-Type: text/plain; charset="utf-8"
>
> Dear all,
>
> As a java developer I prefer to develop rest services using jax-rs.
>
> Now I developed a service that executes Rscript (Using
ProcessBuilder),
> sends text to stdin of the process and reads from stdout of the
> process.
>
> Works fine, but this is inefficient, because every call reloads all
> that is needed.
>
> I have looked into this:
>
> https://github.com/microsoft/java-client-library
> https://rforge.net/Rserve/
> several other sources on stackoverflow etc.
>
> A lot of these sources seem old or not maintained.
>
> Now my question: Is there a preferred and maintained way to
efficiently
> call R from Java? Preferrably available in maven central?
>
> Regards, Eduard
>
>
> --
> Eduard Drenth, Software Architekt
>
> edrenth at fryske-akademy.nl
>
> Doelestrjitte 8
> 8911 DX  Ljouwert
> +31 58 234 30 47
> +31 62 094 34 28 (priv?)
>
> skype: eduarddrenth
> https://github.com/eduarddrenth
> frisian.eu
> gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth
>
>
> Op freed bin ik th?s/wurkje ik minder
>
>
>
>
>
> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: signature.asc
> Type: application/pgp-signature
> Size: 488 bytes
> Desc: This is a digitally signed message part
> URL: <
https://stat.ethz.ch/pipermail/r-help/attachments/20201127/7d818716/attachment-0001.sig
>
>
>



-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201129/a23fe030/attachment.sig>

From gm@ne @end|ng |rom kno@o|@co@uk  Sun Nov 29 01:25:57 2020
From: gm@ne @end|ng |rom kno@o|@co@uk (Derek Jones)
Date: Sun, 29 Nov 2020 00:25:57 +0000
Subject: [R] RGB -> CYMK, with consistent colors
Message-ID: <rpupql$99c$1@ciao.gmane.io>

All,

I used the very useful colorspace package for the plots in my book
(pdf available here): http://knosof.co.uk/ESEUR/

The color makes the plots look great, on screen.
To get lots printed, the printer requires converting the images to use cmyk
(a common requirement for larger  printers, I'm told).  See page 11 here:
https://www.ingramspark.com/hubfs/downloads/file-creation-guide.pdf

No problem, the script below uses ghostscript to achieve this:

gs -o ESEUR-cmyk.pdf \
     -sDEVICE=pdfwrite \
     -sProcessColorModel=DeviceCMYK \
     -sColorConversionStrategy=CMYK \
     -sColorConversionStrategyForImages=CMYK \
      ESEUR.pdf

the problem is that the converted colors don't look nearly as
good.  For instance the cyan now looks blue, and prints as pure blue.

I can regenerate the images, and explicitly specify cmyk.  But using:

pdf.options(colormodel="cymk")

does not change anything.  The colors look remarkably similar to
those produced via the ghostview route.

I have been looking at color profiles and trying to find a
way of modifying an ICC profile (yes, it looks difficult).

Does anybody have any ideas for producing cmyk images that have
the same (or close enough) look as the RGB?


From ny@rkoer|c5 @end|ng |rom gm@||@com  Sun Nov 29 18:06:02 2020
From: ny@rkoer|c5 @end|ng |rom gm@||@com (Nyarko Eric)
Date: Sun, 29 Nov 2020 09:06:02 -0800
Subject: [R] SIMULATE choice experiments
Message-ID: <CA+1r2QQsr5fuAw==9qq_h=a4y=yFUr4SehUHSpN0b52ucvq59A@mail.gmail.com>

Dear all,

Please, any assistance on how to SIMULATE choice experiments to obtain the
multinomial logit choice probabilities as well as the model parameters for
the design matrix F having 7 factors and 12 blocks of size 2.

Thank you.

F<-
c(1,-1,1,-1,1,-1,1,-1,1,1,1,1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,1,-1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,-1,1,1,-1,-1,1,1,-1,1,-1,-1,1,-1,1,1,1,1,1,-1,-1,-1,-1,1,-1,1,-1,-1,1,-1,1,1,1,-1,-1,-1,-1,1,1,1,-1,-1,1,1,-1,-1,1,1,1,-1,-1,-1,-1,1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,1,1,-1,1,-1,1,-1,-1,1,-1,1)

F

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Sun Nov 29 19:11:05 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Sun, 29 Nov 2020 19:11:05 +0100
Subject: [R] RGB -> CYMK, with consistent colors
In-Reply-To: <rpupql$99c$1@ciao.gmane.io>
References: <rpupql$99c$1@ciao.gmane.io>
Message-ID: <CAGAA5bfU3vrdCHCfZC9yY8Vb_MENY--BjE=5Pz+paTO98Aa_dg@mail.gmail.com>

On Sun, 29 Nov 2020 at 14:26, Derek Jones <gmane at knosof.co.uk> wrote:

[...]

> I can regenerate the images, and explicitly specify cmyk.  But using:
>
> pdf.options(colormodel="cymk")
>
> does not change anything.  The colors look remarkably similar to
> those produced via the ghostview route.

[...]

> Does anybody have any ideas for producing cmyk images that have
> the same (or close enough) look as the RGB?

Have you tried printed a few pages in CMYK?

A monitor is based on mixing light using Red-Green-Blue. So it is not
possible for the monitor to show
CMYK which must be printed on paper to view correctly.

Regards
Martin

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Nov 29 19:21:12 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 29 Nov 2020 10:21:12 -0800
Subject: [R] SIMULATE choice experiments
In-Reply-To: <CA+1r2QQsr5fuAw==9qq_h=a4y=yFUr4SehUHSpN0b52ucvq59A@mail.gmail.com>
References: <CA+1r2QQsr5fuAw==9qq_h=a4y=yFUr4SehUHSpN0b52ucvq59A@mail.gmail.com>
Message-ID: <CAGxFJbSyLZaJLkTktFCMHgZW7APcys4iVBC1_xoUdsxUy46HXA@mail.gmail.com>

I do not believe you will get a useful response to your query. Per the
posting guide linked below (please read it):

*Questions about statistics:* The R mailing lists are primarily intended
for questions and discussion about the R software. However, questions about
statistical methodology are sometimes posted. If the question is well-asked
and of interest to someone on the list, it *may* elicit an informative
up-to-date answer. See also the Usenet groups sci.stat.consult (applied
statistics and consulting) and sci.stat.math (mathematical stat and
probability).

Posters are also typically asked to post their own code to highlight their
difficulties.

You may find perusing this to be useful:
https://cran.r-project.org/web/views/
Note the Social Science Task view in particular, perhaps?

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Nov 29, 2020 at 9:06 AM Nyarko Eric <nyarkoeric5 at gmail.com> wrote:

> Dear all,
>
> Please, any assistance on how to SIMULATE choice experiments to obtain the
> multinomial logit choice probabilities as well as the model parameters for
> the design matrix F having 7 factors and 12 blocks of size 2.
>
> Thank you.
>
> F<-
>
> c(1,-1,1,-1,1,-1,1,-1,1,1,1,1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,1,-1,-1,-1,-1,1,1,1,1,1,1,-1,-1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,-1,1,-1,1,-1,1,-1,-1,1,1,-1,-1,1,1,-1,1,-1,-1,1,-1,1,1,1,1,1,-1,-1,-1,-1,1,-1,1,-1,-1,1,-1,1,1,1,-1,-1,-1,-1,1,1,1,-1,-1,1,1,-1,-1,1,1,1,-1,-1,-1,-1,1,1,1,-1,-1,1,1,-1,-1,1,1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,1,1,-1,1,-1,-1,1,-1,1,1,-1,1,-1,1,-1,-1,1,-1,1)
>
> F
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From derek @end|ng |rom kno@o|@co@uk  Sun Nov 29 19:22:43 2020
From: derek @end|ng |rom kno@o|@co@uk (Derek M Jones)
Date: Sun, 29 Nov 2020 18:22:43 +0000
Subject: [R] RGB -> CYMK, with consistent colors
In-Reply-To: <CAGAA5bfU3vrdCHCfZC9yY8Vb_MENY--BjE=5Pz+paTO98Aa_dg@mail.gmail.com>
References: <rpupql$99c$1@ciao.gmane.io>
 <CAGAA5bfU3vrdCHCfZC9yY8Vb_MENY--BjE=5Pz+paTO98Aa_dg@mail.gmail.com>
Message-ID: <e8a1008c-82bf-b1a0-953a-bbedccee04a9@knosof.co.uk>

Martin,

> Have you tried printed a few pages in CMYK?
> 
> A monitor is based on mixing light using Red-Green-Blue. So it is not
> possible for the monitor to show
> CMYK which must be printed on paper to view correctly.

Yes, I have printed some 'CMYK' pages.

The blue is very obviously not cyan, as compared to printing the
RGB version.

-- 
Derek M. Jones           Evidence-based software engineering
tel: +44 (0)1252 520667  blog:shape-of-code.coding-guidelines.com


From gm@ne @end|ng |rom kno@o|@co@uk  Sun Nov 29 21:02:39 2020
From: gm@ne @end|ng |rom kno@o|@co@uk (Derek Jones)
Date: Sun, 29 Nov 2020 20:02:39 +0000
Subject: [R] RGB -> CYMK, with consistent colors
In-Reply-To: <e8a1008c-82bf-b1a0-953a-bbedccee04a9@knosof.co.uk>
References: <rpupql$99c$1@ciao.gmane.io>
 <CAGAA5bfU3vrdCHCfZC9yY8Vb_MENY--BjE=5Pz+paTO98Aa_dg@mail.gmail.com>
 <e8a1008c-82bf-b1a0-953a-bbedccee04a9@knosof.co.uk>
Message-ID: <rq0uov$7i9$1@ciao.gmane.io>

Martin,

>> Have you tried printed a few pages in CMYK?
>>
>> A monitor is based on mixing light using Red-Green-Blue. So it is not
>> possible for the monitor to show
>> CMYK which must be printed on paper to view correctly.
> 
> Yes, I have printed some 'CMYK' pages.
> 
> The blue is very obviously not cyan, as compared to printing the
> RGB version.

Let me correct the last sentence.
The printed blue is obviously not cyan when printing 'rgb' and 'cmyk'
pages.

Somebody pointed out in an email that probably I am the only one who
is going to notice the difference, and he may be right.

My frustration is that the printer supports cyan as a base color.
I understand that rgb->cmyk involves lots of variables, and I'm hoping
that somebody will point me at one that allows me to tweak the output.

library("colorspace")

two_c=rainbow(2)

x=runif(20)
y=runif(20)

plot(x, y, col=two_c[2])


pdf(file="cmyk.pdf", colormodel="cmyk")
plot(x, y, col=two_c[2])
dev.off()


From rmh @end|ng |rom temp|e@edu  Sun Nov 29 21:26:53 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sun, 29 Nov 2020 15:26:53 -0500
Subject: [R] [External]  RGB -> CYMK, with consistent colors
In-Reply-To: <rpupql$99c$1@ciao.gmane.io>
References: <rpupql$99c$1@ciao.gmane.io>
Message-ID: <CAGx1TMAL3P-bLNYyAufLW-x1y_K_2ugOp4jqY7rF_HCW8O8kCA@mail.gmail.com>

I had a long discussion on this topic with the Springer production
group when my book was in production.
Statistical Analysis and Data Display: An Intermediate Course with
Examples in R, second edition
Richard M. Heiberger and Burt Holland.
https://www.springer.com/gp/book/9781493921218

As I now understand it, the physical inks used in printing cannot
produce the same range of colors as the computer screens.
The issue is not the notation, but rather the underlying technology.

I chose to let the publisher make the conversion.  I looked at the set
of pdfs for your book, and to
anyone else but you, I think they would look fine in slightly different colors.

Rich

On Sun, Nov 29, 2020 at 8:26 AM Derek Jones <gmane at knosof.co.uk> wrote:
>
> All,
>
> I used the very useful colorspace package for the plots in my book
> (pdf available here): http://knosof.co.uk/ESEUR/
>
> The color makes the plots look great, on screen.
> To get lots printed, the printer requires converting the images to use cmyk
> (a common requirement for larger  printers, I'm told).  See page 11 here:
> https://www.ingramspark.com/hubfs/downloads/file-creation-guide.pdf
>
> No problem, the script below uses ghostscript to achieve this:
>
> gs -o ESEUR-cmyk.pdf \
>      -sDEVICE=pdfwrite \
>      -sProcessColorModel=DeviceCMYK \
>      -sColorConversionStrategy=CMYK \
>      -sColorConversionStrategyForImages=CMYK \
>       ESEUR.pdf
>
> the problem is that the converted colors don't look nearly as
> good.  For instance the cyan now looks blue, and prints as pure blue.
>
> I can regenerate the images, and explicitly specify cmyk.  But using:
>
> pdf.options(colormodel="cymk")
>
> does not change anything.  The colors look remarkably similar to
> those produced via the ghostview route.
>
> I have been looking at color profiles and trying to find a
> way of modifying an ICC profile (yes, it looks difficult).
>
> Does anybody have any ideas for producing cmyk images that have
> the same (or close enough) look as the RGB?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Mon Nov 30 08:18:46 2020
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Mon, 30 Nov 2020 07:18:46 +0000
Subject: [R] calling r from java
In-Reply-To: <d44b09923c04e49e95f57d2714af14ae609ca64e.camel@fryske-akademy.nl>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
 <CAB8pepxoOo-=Nj7c0Jhk443AVsZANw_H7J0iTn8tZ0OhMKFVhw@mail.gmail.com>
 <d44b09923c04e49e95f57d2714af14ae609ca64e.camel@fryske-akademy.nl>
Message-ID: <6d917f8f1c537cdb4afcfba1de75b35b4b6da206.camel@fryske-akademy.nl>

First attempts to use jri on ubuntu 20.04 stranded.

Steps I followed:

1) download rJava from https://www.rforge.net/rJava/files/
2) create a symlink /usr/lib/libjvm.so to /usr/lib/jvm/java-8-openjdk-
amd64/jre/lib/amd64/server/libjvm.so
3) configure and make jri
4) create a symlink /usr/lib/libjri.so
5) put the built JRI.jar in local maven repo
6) include a dependency to the jar
7) create and run a hello world test for Rengine

The test fails because com.misc.Unsafe.prefetchRead isn't found. As I
understand depending on com.misc.Unsafe.* is a risk.

I will not follow this route any further for now, though I still think
having jri available would be great. Steps to get there are I think:

1) remove com.misc.Unsafe usage from the solution
2) make libjri available in repositories (apt, yum, other)
3) make JRI.jar available in maven central

Bye, Eduard

-----Original Message-----
From: Eduard Drenth <edrenth at fryske-akademy.nl>
To: spurdle.a at gmail.com <spurdle.a at gmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] calling r from java
Date: Sat, 28 Nov 2020 11:57:49 +0000

Thanks all, I'll go for https://www.rforge.net/JRI/ and the librariesin
maven https://search.maven.org/search?q=jri

The maven library is build from  here 
https://www.rforge.net/rJava/files/ back in 2017.
After this no new libs are published to maven.
It would be nice (understatement) if publishing new rJava components
tomaven becomes a regular part of R deveopment processes.
This would promote R use from Java which I think is good.
And of course I can help.
Bye, Eduard
-----Original Message-----From: Abby Spurdle <spurdle.a at gmail.com>To:
Eduard Drenth <edrenth at fryske-akademy.nl>Cc: r-help at r-project.org <
r-help at r-project.org>Subject: Re: [R] calling r from javaDate: Sat, 28
Nov 2020 15:55:36 +1300
Hi Eduard,
> Now I developed a service that executes Rscript
> (UsingProcessBuilder),sends text to stdin of the process and reads
> fromstdout of theprocess.

This doesn't answer your question, but may be relevant.I have a java-
based application that works on a similar principle.(The code
ishorrendously bad and most of it should be thrown away).I'm planning
to write a terminal emulator, in the nearfuture.(Currently, second
place on my top-level todo list).The primary objective is to build
object-oriented and messagepassingAPIs on top of the core terminal
emulation system, with at leastsomecross platform functionality.Noting
that, in my opinion, the cross-platform aspect is moreimportant for R,
than in many other IPC topics.Hence, I'm interested in hearing
"wishlist" items for such
APIs.______________________________________________R-help at r-project.org 
mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201130/52b422b6/attachment.sig>

From petr@p|k@| @end|ng |rom prechez@@cz  Mon Nov 30 08:26:56 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 30 Nov 2020 07:26:56 +0000
Subject: [R] RGB -> CYMK, with consistent colors
In-Reply-To: <e8a1008c-82bf-b1a0-953a-bbedccee04a9@knosof.co.uk>
References: <rpupql$99c$1@ciao.gmane.io>
 <CAGAA5bfU3vrdCHCfZC9yY8Vb_MENY--BjE=5Pz+paTO98Aa_dg@mail.gmail.com>
 <e8a1008c-82bf-b1a0-953a-bbedccee04a9@knosof.co.uk>
Message-ID: <541735a9e7ca4c83a5f7fcf70d2686c1@SRVEXCHCM1302.precheza.cz>

Hi.

CMYK and RGB are physically different concepts of colour mixing
(subtractive/additive) and the only way how to achieve good results is to
calibrate the monitor and the printer (which is hardly achievable in home
conditions). Usually DTP professionals are equipped for such kind of work.
Even then, the results could be slightly different as the whole colour space
is not achievable by only several (4 at least) pigments. And also colour is
not simple thing but basically a process involving light, target and person
who perceives it.

If you insist on achieving good printed results, the best way is to print it
and adjust colour(s) to be pleasing. However you cannot control others so if
anybody prints your book he hardly get the same result as you.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Derek M Jones
> Sent: Sunday, November 29, 2020 7:23 PM
> To: Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com>
> Cc: R mailing list <r-help at r-project.org>
> Subject: Re: [R] RGB -> CYMK, with consistent colors
> 
> Martin,
> 
> > Have you tried printed a few pages in CMYK?
> >
> > A monitor is based on mixing light using Red-Green-Blue. So it is not
> > possible for the monitor to show CMYK which must be printed on paper
> > to view correctly.
> 
> Yes, I have printed some 'CMYK' pages.
> 
> The blue is very obviously not cyan, as compared to printing the RGB
version.
> 
> --
> Derek M. Jones           Evidence-based software engineering
> tel: +44 (0)1252 520667  blog:shape-of-code.coding-guidelines.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @tyen @end|ng |rom ntu@edu@tw  Mon Nov 30 09:14:35 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 30 Nov 2020 16:14:35 +0800
Subject: [R] Printing upon calling a function
Message-ID: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>

I hope I can get away without presenting a replicable set of codes 
because doing so would impose burdens.

I call a function which return a data frame, with the final line

return(out)

In one case the data frame gets printed (similar to a regression 
printout), with simply a call

me.probit(obj)

In another case with a similar function, I could not get the results 
printed and the only way to print is to do the following:

v<-me.oprobit(obj); v

This is a puzzle, and I hope to find some clues. Thanks to all.

My function looks like the following:

me.oprobit0 <- function(obj,mean=FALSE,vb.method,jindex=NA,
resampling=FALSE,ndraws=100,mc.method=1,times100=TRUE,
 ??????????????????????? Stata.mu=FALSE,testing=FALSE,digits=3){
...
return(out) # out is a data frame
}


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Nov 30 09:23:56 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 30 Nov 2020 00:23:56 -0800
Subject: [R] Printing upon calling a function
In-Reply-To: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
Message-ID: <29B6D678-19FC-4A6F-91F2-AE510223A469@dcn.davis.ca.us>

Answering you is also a burden without the reprodicible code. I'll pass on that.

But I will say that mixing analysis with output in the same function is a terrible habit. Come to the functional side of coding... it is much more re-usable here.

On November 30, 2020 12:14:35 AM PST, Steven Yen <styen at ntu.edu.tw> wrote:
>I hope I can get away without presenting a replicable set of codes 
>because doing so would impose burdens.
>
>I call a function which return a data frame, with the final line
>
>return(out)
>
>In one case the data frame gets printed (similar to a regression 
>printout), with simply a call
>
>me.probit(obj)
>
>In another case with a similar function, I could not get the results 
>printed and the only way to print is to do the following:
>
>v<-me.oprobit(obj); v
>
>This is a puzzle, and I hope to find some clues. Thanks to all.
>
>My function looks like the following:
>
>me.oprobit0 <- function(obj,mean=FALSE,vb.method,jindex=NA,
>resampling=FALSE,ndraws=100,mc.method=1,times100=TRUE,
> ??????????????????????? Stata.mu=FALSE,testing=FALSE,digits=3){
>...
>return(out) # out is a data frame
>}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Mon Nov 30 09:36:16 2020
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Mon, 30 Nov 2020 08:36:16 +0000
Subject: [R] calling r from java
In-Reply-To: <6d917f8f1c537cdb4afcfba1de75b35b4b6da206.camel@fryske-akademy.nl>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
 <CAB8pepxoOo-=Nj7c0Jhk443AVsZANw_H7J0iTn8tZ0OhMKFVhw@mail.gmail.com>
 <d44b09923c04e49e95f57d2714af14ae609ca64e.camel@fryske-akademy.nl>
 <6d917f8f1c537cdb4afcfba1de75b35b4b6da206.camel@fryske-akademy.nl>
Message-ID: <f3180f4d80dcdc1a8bb6b1809bb82ae7e24595c8.camel@fryske-akademy.nl>

sun.misc that is

-----Original Message-----
From: Eduard Drenth <edrenth at fryske-akademy.nl>
To: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] calling r from java
Date: Mon, 30 Nov 2020 07:18:46 +0000

First attempts to use jri on ubuntu 20.04 stranded.
Steps I followed:
1) download rJava from https://www.rforge.net/rJava/files/
2) create a symlink /usr/lib/libjvm.so to /usr/lib/jvm/java-8-openjdk-
amd64/jre/lib/amd64/server/libjvm.so3) configure and make jri4) create
a symlink /usr/lib/libjri.so5) put the built JRI.jar in local maven
repo6) include a dependency to the jar7) create and run a hello world
test for Rengine
The test fails because com.misc.Unsafe.prefetchRead isn't found. As
Iunderstand depending on com.misc.Unsafe.* is a risk.
I will not follow this route any further for now, though I still
thinkhaving jri available would be great. Steps to get there are I
think:
1) remove com.misc.Unsafe usage from the solution2) make libjri
available in repositories (apt, yum, other)3) make JRI.jar available in
maven central
Bye, Eduard
-----Original Message-----From: Eduard Drenth <
edrenth at fryske-akademy.nl>To: spurdle.a at gmail.com <spurdle.a at gmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>Subject: Re: [R] calling
r from javaDate: Sat, 28 Nov 2020 11:57:49 +0000
Thanks all, I'll go for https://www.rforge.net/JRI/ and the
librariesinmaven https://search.maven.org/search?q=jri

The maven library is build from  here 
https://www.rforge.net/rJava/files/ back in 2017.After this no new libs
are published to maven.It would be nice (understatement) if publishing
new rJava componentstomaven becomes a regular part of R deveopment
processes.This would promote R use from Java which I think is good.And
of course I can help.Bye, Eduard-----Original Message-----From: Abby
Spurdle <spurdle.a at gmail.com>To:Eduard Drenth <edrenth at fryske-
akademy.nl>Cc: r-help at r-project.org <r-help at r-project.org>Subject: Re:
[R] calling r from javaDate: Sat, 28Nov 2020 15:55:36 +1300Hi Eduard,
> Now I developed a service that executes
> Rscript(UsingProcessBuilder),sends text to stdin of the process and
> readsfromstdout of theprocess.

This doesn't answer your question, but may be relevant.I have a java-
based application that works on a similar principle.(The
codeishorrendously bad and most of it should be thrown away).I'm
planningto write a terminal emulator, in the nearfuture.(Currently,
secondplace on my top-level todo list).The primary objective is to
buildobject-oriented and messagepassingAPIs on top of the core
terminalemulation system, with at leastsomecross platform
functionality.Notingthat, in my opinion, the cross-platform aspect is
moreimportant for R,than in many other IPC topics.Hence, I'm interested
in hearing"wishlist" items for
suchAPIs.______________________________________________R-help at r-
project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.______________________________________________R-help at r-project.org 
mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201130/430e4bc3/attachment.sig>

From m@rk@c|ement@ @end|ng |rom k|@@e  Mon Nov 30 09:40:04 2020
From: m@rk@c|ement@ @end|ng |rom k|@@e (Mark Clements)
Date: Mon, 30 Nov 2020 09:40:04 +0100
Subject: [R] C++11 requirements for package dependencies
Message-ID: <a2a0cdb7-0c7c-960d-0af9-f3ad6882f337@ki.se>

A colleague uses a package I maintain (rstpm2) as a dependency in their
package (rsimsum) with testing using GitHub Actions. They found that
testing failed against R versions 3.3, 3.4 and 3.5 because recent
versions of RcppArmadillo (which is a dependency in rstpm2) require
C++11. As a dependency diagram:

rsimsum --> rstpm2 --> RcppArmadillo

Should I update rstpm2 to include "CXX_STD = CXX11" in the Makevars and
Makevars.win files and add "SystemRequirements: C++11" to the
DESCRIPTION, or is there a simple way in GitHub Actions to use C++11 for
older versions of R?

Moreover, as a principle, should a package need to change the Makevars
and DESCRIPTION files to suit the most recent updates of their
dependencies? I would have thought that such a need would break many
packages.

Sincerely, Mark.




N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI kommer att behandla dina personuppgifter. H?r finns information om hur KI behandlar personuppgifter<https://ki.se/medarbetare/integritetsskyddspolicy>.


Sending email to Karolinska Institutet (KI) will result in KI processing your personal data. You can read more about KI?s processing of personal data here<https://ki.se/en/staff/data-protection-policy>.


From drj|m|emon @end|ng |rom gm@||@com  Mon Nov 30 10:33:40 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 30 Nov 2020 20:33:40 +1100
Subject: [R] Printing upon calling a function
In-Reply-To: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
Message-ID: <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>

Hi Steven,
You seem to be assigning the result of me.oprobit(obj) to v instead of
printing it. By appending ";v" tp that command line, you implicitly
call "print".

Jim

On Mon, Nov 30, 2020 at 7:15 PM Steven Yen <styen at ntu.edu.tw> wrote:
>
> I hope I can get away without presenting a replicable set of codes
> because doing so would impose burdens.
>
> I call a function which return a data frame, with the final line
>
> return(out)
>
> In one case the data frame gets printed (similar to a regression
> printout), with simply a call
>
> me.probit(obj)
>
> In another case with a similar function, I could not get the results
> printed and the only way to print is to do the following:
>
> v<-me.oprobit(obj); v
>
> This is a puzzle, and I hope to find some clues. Thanks to all.
>
> My function looks like the following:
>
> me.oprobit0 <- function(obj,mean=FALSE,vb.method,jindex=NA,
> resampling=FALSE,ndraws=100,mc.method=1,times100=TRUE,
>                          Stata.mu=FALSE,testing=FALSE,digits=3){
> ...
> return(out) # out is a data frame
> }
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Mon Nov 30 10:41:59 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 30 Nov 2020 17:41:59 +0800
Subject: [R] Printing upon calling a function
In-Reply-To: <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
Message-ID: <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>

Thanks. I know, my point was on why I get something printed by simply 
doing line 1 below and at other occasions had to do line 2.

me.probit(obj)

v<-me.probit(obj); v

On 2020/11/30 ?? 05:33, Jim Lemon wrote:
> Hi Steven,
> You seem to be assigning the result of me.oprobit(obj) to v instead of
> printing it. By appending ";v" tp that command line, you implicitly
> call "print".
>
> Jim
>
> On Mon, Nov 30, 2020 at 7:15 PM Steven Yen <styen at ntu.edu.tw> wrote:
>> I hope I can get away without presenting a replicable set of codes
>> because doing so would impose burdens.
>>
>> I call a function which return a data frame, with the final line
>>
>> return(out)
>>
>> In one case the data frame gets printed (similar to a regression
>> printout), with simply a call
>>
>> me.probit(obj)
>>
>> In another case with a similar function, I could not get the results
>> printed and the only way to print is to do the following:
>>
>> v<-me.oprobit(obj); v
>>
>> This is a puzzle, and I hope to find some clues. Thanks to all.
>>
>> My function looks like the following:
>>
>> me.oprobit0 <- function(obj,mean=FALSE,vb.method,jindex=NA,
>> resampling=FALSE,ndraws=100,mc.method=1,times100=TRUE,
>>                           Stata.mu=FALSE,testing=FALSE,digits=3){
>> ...
>> return(out) # out is a data frame
>> }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @te|@nML @end|ng |rom co||oc@t|on@@de  Mon Nov 30 11:41:35 2020
From: @te|@nML @end|ng |rom co||oc@t|on@@de (Stefan Evert)
Date: Mon, 30 Nov 2020 11:41:35 +0100
Subject: [R] Printing upon calling a function
In-Reply-To: <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
Message-ID: <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>


> On 30 Nov 2020, at 10:41, Steven Yen <styen at ntu.edu.tw> wrote:
> 
> Thanks. I know, my point was on why I get something printed by simply doing line 1 below and at other occasions had to do line 2.
> 
> me.probit(obj)

That means the return value of me.probit() has been marked as invisible, so it won't auto-print.  You have to use an explicit print

	print(me.probit(obj))

or use your work-around to convince R that you actually meant to print the output.

If you dig through the full code of me.probit(), you'll probably find the function invisible() called somewhere.

Best,
Stefan

From @tyen @end|ng |rom ntu@edu@tw  Mon Nov 30 11:54:57 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 30 Nov 2020 18:54:57 +0800
Subject: [R] Printing upon calling a function
In-Reply-To: <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
 <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
Message-ID: <76745d93-c2e4-0864-79b5-9280cf577b1a@ntu.edu.tw>

No. I wrote the function so I am sure no "invisible" command was used. 
Strangely enough, compiling the function isto part of a package, results 
were NOT printed. Yes if I call the function during run, by preceding 
the call with a line that attach the source code:

source("A:/.../R/oprobit.R")

it did print. I do not understand.

On 2020/11/30 ?? 06:41, Stefan Evert wrote:
>> On 30 Nov 2020, at 10:41, Steven Yen <styen at ntu.edu.tw> wrote:
>>
>> Thanks. I know, my point was on why I get something printed by simply doing line 1 below and at other occasions had to do line 2.
>>
>> me.probit(obj)
> That means the return value of me.probit() has been marked as invisible, so it won't auto-print.  You have to use an explicit print
>
> 	print(me.probit(obj))
>
> or use your work-around to convince R that you actually meant to print the output.
>
> If you dig through the full code of me.probit(), you'll probably find the function invisible() called somewhere.
>
> Best,
> Stefan


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov 30 12:00:48 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 30 Nov 2020 06:00:48 -0500
Subject: [R] Printing upon calling a function
In-Reply-To: <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
 <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
Message-ID: <131f5f06-1ebf-76e9-a4e1-087d5081506c@gmail.com>

On 30/11/2020 5:41 a.m., Stefan Evert wrote:
> 
>> On 30 Nov 2020, at 10:41, Steven Yen <styen at ntu.edu.tw> wrote:
>>
>> Thanks. I know, my point was on why I get something printed by simply doing line 1 below and at other occasions had to do line 2.
>>
>> me.probit(obj)
> 
> That means the return value of me.probit() has been marked as invisible, so it won't auto-print.  You have to use an explicit print
> 
> 	print(me.probit(obj))
> 
> or use your work-around to convince R that you actually meant to print the output.
> 
> If you dig through the full code of me.probit(), you'll probably find the function invisible() called somewhere.
> 

I think you misread his post.  "me.probit(obj)" on its own *did* print. 
  It was when he assigned it to a variable using "v <- me.probit(obj)" 
that it didn't.  Assignments are almost always invisible in R.

The other thing that people sometimes find confusing is that evaluating 
expressions that are visible are the top level doesn't make them print 
when they are nested in a block of code.  Usually this happens in a 
function, e.g. typing a number normally makes it visible, but

f <- function() {
   1
   2
}
f()

doesn't print 1, it only prints 2, and that happens because 2 is the 
return value of the function.

Duncan Murdoch


From @tyen @end|ng |rom ntu@edu@tw  Mon Nov 30 12:06:17 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 30 Nov 2020 19:06:17 +0800
Subject: [R] Printing upon calling a function
In-Reply-To: <131f5f06-1ebf-76e9-a4e1-087d5081506c@gmail.com>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
 <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
 <131f5f06-1ebf-76e9-a4e1-087d5081506c@gmail.com>
Message-ID: <a239faf3-bfae-763e-b8f6-6ffe01952b0e@ntu.edu.tw>

No, sorry. Line 1 below did not print for me and I had to go around and 
do line 2 to print:

me.probit(obj)

v<-me.probit(obj); v

A puzzle.


On 2020/11/30 ?? 07:00, Duncan Murdoch wrote:
> On 30/11/2020 5:41 a.m., Stefan Evert wrote:
>>
>>> On 30 Nov 2020, at 10:41, Steven Yen <styen at ntu.edu.tw> wrote:
>>>
>>> Thanks. I know, my point was on why I get something printed by 
>>> simply doing line 1 below and at other occasions had to do line 2.
>>>
>>> me.probit(obj)
>>
>> That means the return value of me.probit() has been marked as 
>> invisible, so it won't auto-print.? You have to use an explicit print
>>
>> ????print(me.probit(obj))
>>
>> or use your work-around to convince R that you actually meant to 
>> print the output.
>>
>> If you dig through the full code of me.probit(), you'll probably find 
>> the function invisible() called somewhere.
>>
>
> I think you misread his post.? "me.probit(obj)" on its own *did* 
> print. ?It was when he assigned it to a variable using "v <- 
> me.probit(obj)" that it didn't.? Assignments are almost always 
> invisible in R.
>
> The other thing that people sometimes find confusing is that 
> evaluating expressions that are visible are the top level doesn't make 
> them print when they are nested in a block of code.? Usually this 
> happens in a function, e.g. typing a number normally makes it visible, 
> but
>
> f <- function() {
> ? 1
> ? 2
> }
> f()
>
> doesn't print 1, it only prints 2, and that happens because 2 is the 
> return value of the function.
>
> Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov 30 12:21:01 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 30 Nov 2020 06:21:01 -0500
Subject: [R] Printing upon calling a function
In-Reply-To: <a239faf3-bfae-763e-b8f6-6ffe01952b0e@ntu.edu.tw>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
 <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
 <131f5f06-1ebf-76e9-a4e1-087d5081506c@gmail.com>
 <a239faf3-bfae-763e-b8f6-6ffe01952b0e@ntu.edu.tw>
Message-ID: <7d7492bf-6e4b-8acc-34d1-5f6f5cb66545@gmail.com>


By not posting a reproducible example, you're wasting everyone's time.

Duncan Murdoch

On 30/11/2020 6:06 a.m., Steven Yen wrote:
> No, sorry. Line 1 below did not print for me and I had to go around and
> do line 2 to print:
> 
> me.probit(obj)
> 
> v<-me.probit(obj); v
> 
> A puzzle.
> 
> 
> On 2020/11/30 ?? 07:00, Duncan Murdoch wrote:
>> On 30/11/2020 5:41 a.m., Stefan Evert wrote:
>>>
>>>> On 30 Nov 2020, at 10:41, Steven Yen <styen at ntu.edu.tw> wrote:
>>>>
>>>> Thanks. I know, my point was on why I get something printed by
>>>> simply doing line 1 below and at other occasions had to do line 2.
>>>>
>>>> me.probit(obj)
>>>
>>> That means the return value of me.probit() has been marked as
>>> invisible, so it won't auto-print.? You have to use an explicit print
>>>
>>>  ????print(me.probit(obj))
>>>
>>> or use your work-around to convince R that you actually meant to
>>> print the output.
>>>
>>> If you dig through the full code of me.probit(), you'll probably find
>>> the function invisible() called somewhere.
>>>
>>
>> I think you misread his post.? "me.probit(obj)" on its own *did*
>> print. ?It was when he assigned it to a variable using "v <-
>> me.probit(obj)" that it didn't.? Assignments are almost always
>> invisible in R.
>>
>> The other thing that people sometimes find confusing is that
>> evaluating expressions that are visible are the top level doesn't make
>> them print when they are nested in a block of code.? Usually this
>> happens in a function, e.g. typing a number normally makes it visible,
>> but
>>
>> f <- function() {
>>  ? 1
>>  ? 2
>> }
>> f()
>>
>> doesn't print 1, it only prints 2, and that happens because 2 is the
>> return value of the function.
>>
>> Duncan Murdoch


From Georg@K|nderm@nn @end|ng |rom gmx@@t  Mon Nov 30 11:12:40 2020
From: Georg@K|nderm@nn @end|ng |rom gmx@@t (Georg Kindermann)
Date: Mon, 30 Nov 2020 11:12:40 +0100
Subject: [R] Why is R making a copy-on-modification after using str?
Message-ID: <trinity-4420798e-945f-4280-a3cc-b59fe317de08-1606731160638@3c-app-gmx-bs55>

Dear list members,

I was wondering why R is making a copy-on-modification after using str.

m <- matrix(1:12, 3)
tracemem(m)
#[1] "<0x559df861af28>"
dim(m) <- 4:3
m[1,1] <- 0L
m[] <- 12:1
str(m)
# int [1:4, 1:3] 12 11 10 9 8 7 6 5 4 3 ...
dim(m) <- 3:4  #Here after str a copy is made
#tracemem[0x559df861af28 -> 0x559df838e4a8]:
dim(m) <- 3:4
str(m)
# int [1:3, 1:4] 12 11 10 9 8 7 6 5 4 3 ...
dim(m) <- 3:4 #Here again after str a copy
#tracemem[0x559df838e4a8 -> 0x559df82c9d78]:

Also I was wondering why a copy is made when having a Task Callback.

TCB <- addTaskCallback(function(...) TRUE)
m <- matrix(1:12, nrow = 3)
tracemem(m)
#[1] "<0x559dfa79def8>"
dim(m) <- 4:3  #Copy on modification
#tracemem[0x559dfa79def8 -> 0x559dfa8998e8]:
removeTaskCallback(TCB)
#[1] TRUE
dim(m) <- 4:3  #No copy

I am using R version 4.0.3.

Kind regards,
Georg


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov 30 16:25:56 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 30 Nov 2020 10:25:56 -0500
Subject: [R] Why is R making a copy-on-modification after using str?
In-Reply-To: <trinity-4420798e-945f-4280-a3cc-b59fe317de08-1606731160638@3c-app-gmx-bs55>
References: <trinity-4420798e-945f-4280-a3cc-b59fe317de08-1606731160638@3c-app-gmx-bs55>
Message-ID: <53c46591-db71-4e47-5c3d-2372f243a16c@gmail.com>

On 30/11/2020 5:12 a.m., Georg Kindermann wrote:
> Dear list members,
> 
> I was wondering why R is making a copy-on-modification after using str.

This isn't really an explanation, but adds a bit more data.  If you 
inspect m before and after str(), you'll see that str(m) leaves it with 
two references:

 > m <- matrix(1:12, 3)
 >   .Internal(inspect(m))
@7fcb0ad682c8 13 INTSXP g0c4 [REF(1),ATT] (len=12, tl=0) 1,2,3,4,5,...
ATTRIB:
   @7fcaf5f7b8a0 02 LISTSXP g0c0 [REF(1)]
     TAG: @7fcafd091a80 01 SYMSXP g1c0 [MARK,REF(65535),LCK,gp=0x6000] 
"dim" (has value)
     @7fcb0afecc80 13 INTSXP g0c1 [REF(65535)] (len=2, tl=0) 3,4
 >   str(m)
  int [1:3, 1:4] 1 2 3 4 5 6 7 8 9 10 ...
 >   .Internal(inspect(m))
@7fcb0ad682c8 13 INTSXP g0c4 [REF(2),ATT] (len=12, tl=0) 1,2,3,4,5,...
ATTRIB:
   @7fcaf5f7b8a0 02 LISTSXP g0c0 [REF(1)]
     TAG: @7fcafd091a80 01 SYMSXP g1c0 [MARK,REF(65535),LCK,gp=0x6000] 
"dim" (has value)
     @7fcb0afecc80 13 INTSXP g0c1 [REF(65535)] (len=2, tl=0) 3,4


It's not just str():  this sequence also does it.

   m <- matrix(1:12, 3)
   debug(mean)
   mean(m)

Hit c a couple of times now to get out of debugging, and m is left with 
two references to it.  I don't see that if mean isn't being debugged.

Duncan Murdoch


> 
> m <- matrix(1:12, 3)
> tracemem(m)
> #[1] "<0x559df861af28>"
> dim(m) <- 4:3
> m[1,1] <- 0L
> m[] <- 12:1
> str(m)
> # int [1:4, 1:3] 12 11 10 9 8 7 6 5 4 3 ...
> dim(m) <- 3:4  #Here after str a copy is made
> #tracemem[0x559df861af28 -> 0x559df838e4a8]:
> dim(m) <- 3:4
> str(m)
> # int [1:3, 1:4] 12 11 10 9 8 7 6 5 4 3 ...
> dim(m) <- 3:4 #Here again after str a copy
> #tracemem[0x559df838e4a8 -> 0x559df82c9d78]:
> 
> Also I was wondering why a copy is made when having a Task Callback.
> 
> TCB <- addTaskCallback(function(...) TRUE)
> m <- matrix(1:12, nrow = 3)
> tracemem(m)
> #[1] "<0x559dfa79def8>"
> dim(m) <- 4:3  #Copy on modification
> #tracemem[0x559dfa79def8 -> 0x559dfa8998e8]:
> removeTaskCallback(TCB)
> #[1] TRUE
> dim(m) <- 4:3  #No copy
> 
> I am using R version 4.0.3.
> 
> Kind regards,
> Georg
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Mon Nov 30 16:48:00 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments and acoustic tools)
Date: Mon, 30 Nov 2020 08:48:00 -0700
Subject: [R] Need guidance on summarizing time data
In-Reply-To: <mailman.361501.1.1606734351.51804.r-help@r-project.org>
References: <mailman.361501.1.1606734351.51804.r-help@r-project.org>
Message-ID: <22c3faa4-10c4-ad76-5a1c-2f1ba51fd361@gmail.com>

Hi all,

I need to summarize temporal activity. However date\times in R seem to 
be not easily handled.
Seems I may need to convert date\time values to a recognizable format?

My "raw data" is tab (text) includes a location ID, date and time(24 hr 
format).
Format is like this:
Location??? Date??? Time
156??? 2/25/2008??? 18:31
156??? 2/25/2008??? 18:31
156??? 2/25/2008??? 18:32
156??? 2/25/2008??? 18:35
156??? 2/25/2008??? 18:38
156??? 2/25/2008??? 18:41
156??? 2/25/2008??? 18:42
156??? 2/25/2008??? 18:43
156??? 2/25/2008??? 18:43
156??? 2/25/2008??? 18:55
156??? 2/25/2008??? 18:56
156??? 2/25/2008??? 18:56
156??? 2/26/2008??? 18:35
156??? 2/26/2008??? 18:35
156??? 2/26/2008??? 18:35
156??? 2/26/2008??? 18:35
196??? 7/16/2006??? 4:47
250??? 4/9/2004??? 18:41
250??? 4/9/2004??? 18:44
253??? 3/5/2004??? 18:30
1268??? 2/11/2001??? 18:39
1268??? 2/11/2001??? 18:39
1344??? 4/17/2003??? 19:06
1409??? 2/28/2004??? 5:51
...etc. for 10,390 rows of data.

I am aiming for a summary by times for all of the data such that I have 
total number of "events" or count for each time period. So something like

18:31 41
18:32 38

and so on.

So a "simple" count of the time occurrences.

I tried to do a summary running frequencies
descriptive.table(vars = d(Time) ,
+ strata = d(Date),data= Active,
+ func.names =c("Valid N","Minimum","Maximum"))


Warning message:
In descriptive.table(vars = d(Time), strata = d(Date), data = Active,? :
 ? Non-numeric variables dropped from descriptive table
 > Active[,3]<-as.POSIXct(Active[,3], format='%m-%d-%y %H:%M:%S')
 > Active[,2]<-as.Date(Active[,2], format= '%m/%d/%y')
 > frequencies(Active[c("Time")] , r.digits = 1)
Error in names(x) <- value :
 ? 'names' attribute [4] must be the same length as the vector [3]

Suggestions welcomed.

Cheers all

-- 
Bruce W. Miller, PhD.
Neotropical bat risk and acoustic assessments
Conservation Fellow - Wildlife Conservation Society
Research Associate, American Museum of Natural History

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


From bgunter@4567 @end|ng |rom gm@||@com  Mon Nov 30 16:56:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 30 Nov 2020 07:56:21 -0800
Subject: [R] C++11 requirements for package dependencies
In-Reply-To: <a2a0cdb7-0c7c-960d-0af9-f3ad6882f337@ki.se>
References: <a2a0cdb7-0c7c-960d-0af9-f3ad6882f337@ki.se>
Message-ID: <CAGxFJbTe2M5aGL2G1ZqXDJ74nab2xck9korFWiwhw1NLBfkt0w@mail.gmail.com>

package questions are usually better posted at r-package-devel

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 30, 2020 at 12:45 AM Mark Clements <mark.clements at ki.se> wrote:

> A colleague uses a package I maintain (rstpm2) as a dependency in their
> package (rsimsum) with testing using GitHub Actions. They found that
> testing failed against R versions 3.3, 3.4 and 3.5 because recent
> versions of RcppArmadillo (which is a dependency in rstpm2) require
> C++11. As a dependency diagram:
>
> rsimsum --> rstpm2 --> RcppArmadillo
>
> Should I update rstpm2 to include "CXX_STD = CXX11" in the Makevars and
> Makevars.win files and add "SystemRequirements: C++11" to the
> DESCRIPTION, or is there a simple way in GitHub Actions to use C++11 for
> older versions of R?
>
> Moreover, as a principle, should a package need to change the Makevars
> and DESCRIPTION files to suit the most recent updates of their
> dependencies? I would have thought that such a need would break many
> packages.
>
> Sincerely, Mark.
>
>
>
>
> N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI
> kommer att behandla dina personuppgifter. H?r finns information om hur KI
> behandlar personuppgifter<
> https://ki.se/medarbetare/integritetsskyddspolicy>.
>
>
> Sending email to Karolinska Institutet (KI) will result in KI processing
> your personal data. You can read more about KI?s processing of personal
> data here<https://ki.se/en/staff/data-protection-policy>.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Nov 30 17:01:45 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 30 Nov 2020 17:01:45 +0100
Subject: [R] Need guidance on summarizing time data
In-Reply-To: <22c3faa4-10c4-ad76-5a1c-2f1ba51fd361@gmail.com>
References: <mailman.361501.1.1606734351.51804.r-help@r-project.org>
 <22c3faa4-10c4-ad76-5a1c-2f1ba51fd361@gmail.com>
Message-ID: <CAJuCY5xkcJm-ePu5wzDJPqB9+vR1rL6p5oRZDOX_Cd87Q6k50w@mail.gmail.com>

Dear Bruce,

I think this should be straightforward with tidyverse. If not please
provide a small reproducible data set with dput().

library(tidyverse)
count(Active, Time)
count(Active, Date, Time)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 30 nov. 2020 om 16:48 schreef Neotropical bat risk assessments and
acoustic tools <neotropical.bats at gmail.com>:

> Hi all,
>
> I need to summarize temporal activity. However date\times in R seem to
> be not easily handled.
> Seems I may need to convert date\time values to a recognizable format?
>
> My "raw data" is tab (text) includes a location ID, date and time(24 hr
> format).
> Format is like this:
> Location    Date    Time
> 156    2/25/2008    18:31
> 156    2/25/2008    18:31
> 156    2/25/2008    18:32
> 156    2/25/2008    18:35
> 156    2/25/2008    18:38
> 156    2/25/2008    18:41
> 156    2/25/2008    18:42
> 156    2/25/2008    18:43
> 156    2/25/2008    18:43
> 156    2/25/2008    18:55
> 156    2/25/2008    18:56
> 156    2/25/2008    18:56
> 156    2/26/2008    18:35
> 156    2/26/2008    18:35
> 156    2/26/2008    18:35
> 156    2/26/2008    18:35
> 196    7/16/2006    4:47
> 250    4/9/2004    18:41
> 250    4/9/2004    18:44
> 253    3/5/2004    18:30
> 1268    2/11/2001    18:39
> 1268    2/11/2001    18:39
> 1344    4/17/2003    19:06
> 1409    2/28/2004    5:51
> ...etc. for 10,390 rows of data.
>
> I am aiming for a summary by times for all of the data such that I have
> total number of "events" or count for each time period. So something like
>
> 18:31 41
> 18:32 38
>
> and so on.
>
> So a "simple" count of the time occurrences.
>
> I tried to do a summary running frequencies
> descriptive.table(vars = d(Time) ,
> + strata = d(Date),data= Active,
> + func.names =c("Valid N","Minimum","Maximum"))
>
>
> Warning message:
> In descriptive.table(vars = d(Time), strata = d(Date), data = Active,  :
>    Non-numeric variables dropped from descriptive table
>  > Active[,3]<-as.POSIXct(Active[,3], format='%m-%d-%y %H:%M:%S')
>  > Active[,2]<-as.Date(Active[,2], format= '%m/%d/%y')
>  > frequencies(Active[c("Time")] , r.digits = 1)
> Error in names(x) <- value :
>    'names' attribute [4] must be the same length as the vector [3]
>
> Suggestions welcomed.
>
> Cheers all
>
> --
> Bruce W. Miller, PhD.
> Neotropical bat risk and acoustic assessments
> Conservation Fellow - Wildlife Conservation Society
> Research Associate, American Museum of Natural History
>
> If we lose the bats, we may lose much of the tropical vegetation and the
> lungs of the planet
>
> Using acoustic sampling to identify and map species distributions
> and pioneering acoustic tools for ecology and conservation of bats for >25
> years.
>
> Key projects include providing free interactive identification keys and
> call fact sheets for the vocal signatures of New World Bats
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Nov 30 17:04:02 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 30 Nov 2020 08:04:02 -0800
Subject: [R] Need guidance on summarizing time data
In-Reply-To: <22c3faa4-10c4-ad76-5a1c-2f1ba51fd361@gmail.com>
References: <mailman.361501.1.1606734351.51804.r-help@r-project.org>
 <22c3faa4-10c4-ad76-5a1c-2f1ba51fd361@gmail.com>
Message-ID: <918A3B2A-144F-4296-9C48-0130030AF6D0@dcn.davis.ca.us>

Does table(DF$Time) do what you want?

Seems kinda odd to me that you want to distinguish between 18:31 and 18:32 but you don't care which days those occur on.  If your phenomenon is related to local time-of-day then perhaps you might want to correlate with sun elevation relative to the horizon. If you have lat/lon and timezone then the maptools package can estimate local sun position from datetime.

On November 30, 2020 7:48:00 AM PST, Neotropical bat risk assessments and acoustic tools <neotropical.bats at gmail.com> wrote:
>Hi all,
>
>I need to summarize temporal activity. However date\times in R seem to 
>be not easily handled.
>Seems I may need to convert date\time values to a recognizable format?
>
>My "raw data" is tab (text) includes a location ID, date and time(24 hr
>
>format).
>Format is like this:
>Location??? Date??? Time
>156??? 2/25/2008??? 18:31
>156??? 2/25/2008??? 18:31
>156??? 2/25/2008??? 18:32
>156??? 2/25/2008??? 18:35
>156??? 2/25/2008??? 18:38
>156??? 2/25/2008??? 18:41
>156??? 2/25/2008??? 18:42
>156??? 2/25/2008??? 18:43
>156??? 2/25/2008??? 18:43
>156??? 2/25/2008??? 18:55
>156??? 2/25/2008??? 18:56
>156??? 2/25/2008??? 18:56
>156??? 2/26/2008??? 18:35
>156??? 2/26/2008??? 18:35
>156??? 2/26/2008??? 18:35
>156??? 2/26/2008??? 18:35
>196??? 7/16/2006??? 4:47
>250??? 4/9/2004??? 18:41
>250??? 4/9/2004??? 18:44
>253??? 3/5/2004??? 18:30
>1268??? 2/11/2001??? 18:39
>1268??? 2/11/2001??? 18:39
>1344??? 4/17/2003??? 19:06
>1409??? 2/28/2004??? 5:51
>...etc. for 10,390 rows of data.
>
>I am aiming for a summary by times for all of the data such that I have
>
>total number of "events" or count for each time period. So something
>like
>
>18:31 41
>18:32 38
>
>and so on.
>
>So a "simple" count of the time occurrences.
>
>I tried to do a summary running frequencies
>descriptive.table(vars = d(Time) ,
>+ strata = d(Date),data= Active,
>+ func.names =c("Valid N","Minimum","Maximum"))
>
>
>Warning message:
>In descriptive.table(vars = d(Time), strata = d(Date), data = Active,?
>:
> ? Non-numeric variables dropped from descriptive table
> > Active[,3]<-as.POSIXct(Active[,3], format='%m-%d-%y %H:%M:%S')
> > Active[,2]<-as.Date(Active[,2], format= '%m/%d/%y')
> > frequencies(Active[c("Time")] , r.digits = 1)
>Error in names(x) <- value :
> ? 'names' attribute [4] must be the same length as the vector [3]
>
>Suggestions welcomed.
>
>Cheers all

-- 
Sent from my phone. Please excuse my brevity.


From @tyen @end|ng |rom ntu@edu@tw  Mon Nov 30 17:51:57 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Tue, 1 Dec 2020 00:51:57 +0800
Subject: [R] Printing upon calling a function
In-Reply-To: <7d7492bf-6e4b-8acc-34d1-5f6f5cb66545@gmail.com>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
 <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
 <131f5f06-1ebf-76e9-a4e1-087d5081506c@gmail.com>
 <a239faf3-bfae-763e-b8f6-6ffe01952b0e@ntu.edu.tw>
 <7d7492bf-6e4b-8acc-34d1-5f6f5cb66545@gmail.com>
Message-ID: <3171da90-ce9f-515e-aaa0-64373634e922@ntu.edu.tw>

Thanks to all. Presenting a large-scale, replicable example can be a 
burden to the READERs which was why I was reluctant.

I am embarrassed to report that after having to restart Windows after 
the system hang on something unrelated, the issue was resolved and 
printing was normal. I bet it had nothing to do with the R function. 
Problem caused by my Windows system memory or something. This sometimes 
yes, sometimes no situation makes i thard to pinpoint the problem and 
present a replicable example. I am OK now. Thanks to all.

On 2020/11/30 ?? 07:21, Duncan Murdoch wrote:
>
> By not posting a reproducible example, you're wasting everyone's time.
>
> Duncan Murdoch
>
> On 30/11/2020 6:06 a.m., Steven Yen wrote:
>> No, sorry. Line 1 below did not print for me and I had to go around and
>> do line 2 to print:
>>
>> me.probit(obj)
>>
>> v<-me.probit(obj); v
>>
>> A puzzle.
>>
>>
>> On 2020/11/30 ?? 07:00, Duncan Murdoch wrote:
>>> On 30/11/2020 5:41 a.m., Stefan Evert wrote:
>>>>
>>>>> On 30 Nov 2020, at 10:41, Steven Yen <styen at ntu.edu.tw> wrote:
>>>>>
>>>>> Thanks. I know, my point was on why I get something printed by
>>>>> simply doing line 1 below and at other occasions had to do line 2.
>>>>>
>>>>> me.probit(obj)
>>>>
>>>> That means the return value of me.probit() has been marked as
>>>> invisible, so it won't auto-print.? You have to use an explicit print
>>>>
>>>> ?????print(me.probit(obj))
>>>>
>>>> or use your work-around to convince R that you actually meant to
>>>> print the output.
>>>>
>>>> If you dig through the full code of me.probit(), you'll probably find
>>>> the function invisible() called somewhere.
>>>>
>>>
>>> I think you misread his post.? "me.probit(obj)" on its own *did*
>>> print. ?It was when he assigned it to a variable using "v <-
>>> me.probit(obj)" that it didn't.? Assignments are almost always
>>> invisible in R.
>>>
>>> The other thing that people sometimes find confusing is that
>>> evaluating expressions that are visible are the top level doesn't make
>>> them print when they are nested in a block of code.? Usually this
>>> happens in a function, e.g. typing a number normally makes it visible,
>>> but
>>>
>>> f <- function() {
>>> ?? 1
>>> ?? 2
>>> }
>>> f()
>>>
>>> doesn't print 1, it only prints 2, and that happens because 2 is the
>>> return value of the function.
>>>
>>> Duncan Murdoch
>


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Nov 30 17:53:28 2020
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 30 Nov 2020 11:53:28 -0500
Subject: [R] Printing upon calling a function
In-Reply-To: <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
Message-ID: <022401d6c739$54457630$fcd06290$@verizon.net>

TOPIC: Why some returned values do not automatically print.

Again, not seeing the internals, my guess is the function returned not the expected but "invisible(expected)" which just marks it as not to be automatically printed.

So if you want it printed, ask for it explicitly as in:

print(me.probit(obj))

What you did was to copy the object and then the copy does not keep the invisibility so when invoked, gets the default print action.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
Sent: Monday, November 30, 2020 4:42 AM
To: Jim Lemon <drjimlemon at gmail.com>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Printing upon calling a function

Thanks. I know, my point was on why I get something printed by simply doing line 1 below and at other occasions had to do line 2.

me.probit(obj)

v<-me.probit(obj); v

On 2020/11/30 ?? 05:33, Jim Lemon wrote:
> Hi Steven,
> You seem to be assigning the result of me.oprobit(obj) to v instead of 
> printing it. By appending ";v" tp that command line, you implicitly 
> call "print".
>
> Jim
>
> On Mon, Nov 30, 2020 at 7:15 PM Steven Yen <styen at ntu.edu.tw> wrote:
>> I hope I can get away without presenting a replicable set of codes 
>> because doing so would impose burdens.
>>
>> I call a function which return a data frame, with the final line
>>
>> return(out)
>>
>> In one case the data frame gets printed (similar to a regression 
>> printout), with simply a call
>>
>> me.probit(obj)
>>
>> In another case with a similar function, I could not get the results 
>> printed and the only way to print is to do the following:
>>
>> v<-me.oprobit(obj); v
>>
>> This is a puzzle, and I hope to find some clues. Thanks to all.
>>
>> My function looks like the following:
>>
>> me.oprobit0 <- function(obj,mean=FALSE,vb.method,jindex=NA,
>> resampling=FALSE,ndraws=100,mc.method=1,times100=TRUE,
>>                           Stata.mu=FALSE,testing=FALSE,digits=3){
>> ...
>> return(out) # out is a data frame
>> }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Scanned by McAfee and confirmed virus-free.	
Find out more here: https://bit.ly/2zCJMrO


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov 30 18:04:24 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 30 Nov 2020 12:04:24 -0500
Subject: [R] Printing upon calling a function
In-Reply-To: <3171da90-ce9f-515e-aaa0-64373634e922@ntu.edu.tw>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
 <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
 <131f5f06-1ebf-76e9-a4e1-087d5081506c@gmail.com>
 <a239faf3-bfae-763e-b8f6-6ffe01952b0e@ntu.edu.tw>
 <7d7492bf-6e4b-8acc-34d1-5f6f5cb66545@gmail.com>
 <3171da90-ce9f-515e-aaa0-64373634e922@ntu.edu.tw>
Message-ID: <3f3e3d8a-b919-e050-ba4d-b74045001350@gmail.com>

On 30/11/2020 11:51 a.m., Steven Yen wrote:
> Thanks to all. Presenting a large-scale, replicable example can be a
> burden to the READERs which was why I was reluctant.

You shouldn't post a large scale reproducible example, you should 
simplify it to just the essentials.  Often in doing that you will find 
some error, and don't need to post at all.

Duncan Murdoch

> 
> I am embarrassed to report that after having to restart Windows after
> the system hang on something unrelated, the issue was resolved and
> printing was normal. I bet it had nothing to do with the R function.
> Problem caused by my Windows system memory or something. This sometimes
> yes, sometimes no situation makes i thard to pinpoint the problem and
> present a replicable example. I am OK now. Thanks to all.
> 
> On 2020/11/30 ?? 07:21, Duncan Murdoch wrote:
>>
>> By not posting a reproducible example, you're wasting everyone's time.
>>
>> Duncan Murdoch
>>
>> On 30/11/2020 6:06 a.m., Steven Yen wrote:
>>> No, sorry. Line 1 below did not print for me and I had to go around and
>>> do line 2 to print:
>>>
>>> me.probit(obj)
>>>
>>> v<-me.probit(obj); v
>>>
>>> A puzzle.
>>>
>>>
>>> On 2020/11/30 ?? 07:00, Duncan Murdoch wrote:
>>>> On 30/11/2020 5:41 a.m., Stefan Evert wrote:
>>>>>
>>>>>> On 30 Nov 2020, at 10:41, Steven Yen <styen at ntu.edu.tw> wrote:
>>>>>>
>>>>>> Thanks. I know, my point was on why I get something printed by
>>>>>> simply doing line 1 below and at other occasions had to do line 2.
>>>>>>
>>>>>> me.probit(obj)
>>>>>
>>>>> That means the return value of me.probit() has been marked as
>>>>> invisible, so it won't auto-print.? You have to use an explicit print
>>>>>
>>>>>  ?????print(me.probit(obj))
>>>>>
>>>>> or use your work-around to convince R that you actually meant to
>>>>> print the output.
>>>>>
>>>>> If you dig through the full code of me.probit(), you'll probably find
>>>>> the function invisible() called somewhere.
>>>>>
>>>>
>>>> I think you misread his post.? "me.probit(obj)" on its own *did*
>>>> print. ?It was when he assigned it to a variable using "v <-
>>>> me.probit(obj)" that it didn't.? Assignments are almost always
>>>> invisible in R.
>>>>
>>>> The other thing that people sometimes find confusing is that
>>>> evaluating expressions that are visible are the top level doesn't make
>>>> them print when they are nested in a block of code.? Usually this
>>>> happens in a function, e.g. typing a number normally makes it visible,
>>>> but
>>>>
>>>> f <- function() {
>>>>  ?? 1
>>>>  ?? 2
>>>> }
>>>> f()
>>>>
>>>> doesn't print 1, it only prints 2, and that happens because 2 is the
>>>> return value of the function.
>>>>
>>>> Duncan Murdoch
>>


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Nov 30 18:06:29 2020
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 30 Nov 2020 12:06:29 -0500
Subject: [R] Printing upon calling a function
In-Reply-To: <76745d93-c2e4-0864-79b5-9280cf577b1a@ntu.edu.tw>
References: <8e75eae5-a142-5da2-fa80-2ba5770c7205@ntu.edu.tw>
 <CA+8X3fXBxjz-6cvgrhd4ZAkA+f7vTr0Anqo_A_6iY-WzYiYmYw@mail.gmail.com>
 <d6896b30-6080-8b48-226b-27ce491082c7@ntu.edu.tw>
 <B00D2E4C-3D36-41F6-9895-390CA59CB1BA@collocations.de>
 <76745d93-c2e4-0864-79b5-9280cf577b1a@ntu.edu.tw>
Message-ID: <024f01d6c73b$254030d0$6fc09270$@verizon.net>

Steven,

You need to mention what you actually did to get proper advice. Your problem is at the source.

Simply put, the R interpreter does have somewhat different behavior when the program is directly typed in (or slightly indirectly as in R STUDIO) than when you ask it to open another file as a source, perhaps recursively.

If you read the manual page, "source()" has lots of options.

https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/source

The default is to change some of the behavior with the assumption there is no user typing things in and waiting for responses. One of the options will change the behavior to make statements auto-print.  Look to see if

source(..., echo=TRUE)

gets what you want. Obviously the "..." above is replaced with your additional code. Of course, an explicit print statement works too. You may also want to look at the print.eval option.

What next? Will you now tell us you forgot that you used the sink(file="hide.txt") function in the code and wonder why it does not print to your terminal? 


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
Sent: Monday, November 30, 2020 5:55 AM
To: Stefan Evert <stefanML at collocations.de>
Cc: R-help Mailing List <r-help at r-project.org>
Subject: Re: [R] Printing upon calling a function

No. I wrote the function so I am sure no "invisible" command was used. 
Strangely enough, compiling the function isto part of a package, results were NOT printed. Yes if I call the function during run, by preceding the call with a line that attach the source code:

source("A:/.../R/oprobit.R")

it did print. I do not understand.

On 2020/11/30 ?? 06:41, Stefan Evert wrote:
>> On 30 Nov 2020, at 10:41, Steven Yen <styen at ntu.edu.tw> wrote:
>>
>> Thanks. I know, my point was on why I get something printed by simply doing line 1 below and at other occasions had to do line 2.
>>
>> me.probit(obj)
> That means the return value of me.probit() has been marked as 
> invisible, so it won't auto-print.  You have to use an explicit print
>
> 	print(me.probit(obj))
>
> or use your work-around to convince R that you actually meant to print the output.
>
> If you dig through the full code of me.probit(), you'll probably find the function invisible() called somewhere.
>
> Best,
> Stefan

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Scanned by McAfee and confirmed virus-free.	
Find out more here: https://bit.ly/2zCJMrO


From @dr|@n @end|ng |rom tr@p|ett|@org  Mon Nov 30 18:34:35 2020
From: @dr|@n @end|ng |rom tr@p|ett|@org (Adrian Trapletti)
Date: Mon, 30 Nov 2020 18:34:35 +0100
Subject: [R] calling r from java (Eduard Drenth)
In-Reply-To: <8700ec87b5ff0498447c41af4fd732002b9ff3ff.camel@fryske-akademy.nl>
References: <mailman.361480.1.1606561201.44767.r-help@r-project.org>
 <CAFmikf35C4PrU3rWhQf6fTrOpgGuPa=UmqrK8R4TmQr7xDnY7w@mail.gmail.com>
 <8700ec87b5ff0498447c41af4fd732002b9ff3ff.camel@fryske-akademy.nl>
Message-ID: <CAFmikf3u=UtPCF4xROAFzPPXo5BZrANSe34_u4jMpMXeTR49qQ@mail.gmail.com>

Calling R via Rserve is faster than a REST based solution. However, if you
do some non-trivial computation in R, then the calling overhead is
insignificant. A REST based solution is more flexible. A REST API can be
called e.g. directly from a Javascript UI and the indirection via a Java
backend is not necessary. I see that there is a Javascript client for
Rserve https://github.com/cscheid/rserve-js but the last release is from
2013. Or if you think later that Python is more suited to do this type of
work, then you can simply replace the R REST service with a Python REST
service without touching the Java code.

Cheers,
Adrian

*Adrian Trapletti*

Steinstrasse 9b, 8610 Uster, Switzerland
P +41 44 994 56 30  |  M +41 79 103 71 31
adrian at trapletti.org  |  www.trapletti.org


On Sun, Nov 29, 2020 at 9:12 AM Eduard Drenth <edrenth at fryske-akademy.nl>
wrote:

> Because of efficiency? But almost all development I do is in
> Java/Xml/XQuery so I am interested in efficiently integrating the two. And
> for our small institution it is important to limit the number of
> technologies / frameworks.
>
> Bye, Eduard
>
> -----Original Message-----
> *From*: Adrian Trapletti <adrian at trapletti.org
> <Adrian%20Trapletti%20%3cadrian at trapletti.org%3e>>
> *To*: Eduard Drenth <edrenth at fryske-akademy.nl
> <Eduard%20Drenth%20%3cedrenth at fryske-akademy.nl%3e>>
> *Cc*: R-help at r-project.org
> *Subject*: Re: calling r from java (Eduard Drenth)
> *Date*: Sat, 28 Nov 2020 20:36:14 +0100
>
> Hi Eduard,
>
> I recommend separating the R quant code from Java and deploy the R code as
> a REST service, e.g. using https://github.com/opencpu/opencpu
>
> Best regards
> Adrian
>
> Adrian Trapletti
>
> Steinstrasse 9b, 8610 Uster, Switzerland
> P +41 44 994 56 30  |  M +41 79 103 71 31
> adrian at trapletti.org  |  www.trapletti.org
>
> On Sat, Nov 28, 2020 at 12:00 PM <r-help-request at r-project.org> wrote:
> >
> > Send R-help mailing list submissions to
> >         r-help at r-project.org
> >
> > To subscribe or unsubscribe via the World Wide Web, visit
> >         https://stat.ethz.ch/mailman/listinfo/r-help
> > or, via email, send a message with subject or body 'help' to
> >         r-help-request at r-project.org
> >
> > You can reach the person managing the list at
> >         r-help-owner at r-project.org
> >
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of R-help digest..."
> >
> >
> > Today's Topics:
> >
> >    1. calling r from java (Eduard Drenth)
> >    2. Re: calling r from java (Bert Gunter)
> >    3. Re: calling r from java (Jeff Newmiller)
> >    4. Re: calling r from java (Bert Gunter)
> >    5. Re: calling r from java (Abby Spurdle)
> >
> > ----------------------------------------------------------------------
> >
> > Message: 1
> > Date: Fri, 27 Nov 2020 16:47:54 +0000
> > From: Eduard Drenth <edrenth at fryske-akademy.nl>
> > To: "r-help at r-project.org" <r-help at r-project.org>
> > Subject: [R] calling r from java
> > Message-ID:
> >         <
> fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel at fryske-akademy.nl>
> > Content-Type: text/plain; charset="utf-8"
> >
> > Dear all,
> >
> > As a java developer I prefer to develop rest services using jax-rs.
> >
> > Now I developed a service that executes Rscript (Using ProcessBuilder),
> > sends text to stdin of the process and reads from stdout of the
> > process.
> >
> > Works fine, but this is inefficient, because every call reloads all
> > that is needed.
> >
> > I have looked into this:
> >
> > https://github.com/microsoft/java-client-library
> > https://rforge.net/Rserve/
> > several other sources on stackoverflow etc.
> >
> > A lot of these sources seem old or not maintained.
> >
> > Now my question: Is there a preferred and maintained way to efficiently
> > call R from Java? Preferrably available in maven central?
> >
> > Regards, Eduard
> >
> >
> > --
> > Eduard Drenth, Software Architekt
> >
> > edrenth at fryske-akademy.nl
> >
> > Doelestrjitte 8
> > 8911 DX  Ljouwert
> > +31 58 234 30 47
> > +31 62 094 34 28 (priv?)
> >
> > skype: eduarddrenth
> > https://github.com/eduarddrenth
> > frisian.eu
> > gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth
> >
> >
> > Op freed bin ik th?s/wurkje ik minder
> >
> >
> >
> >
> >
> > -------------- next part --------------
> > A non-text attachment was scrubbed...
> > Name: signature.asc
> > Type: application/pgp-signature
> > Size: 488 bytes
> > Desc: This is a digitally signed message part
> > URL: <
> https://stat.ethz.ch/pipermail/r-help/attachments/20201127/7d818716/attachment-0001.sig
> >
> >
> >
>
> --
>
> Eduard Drenth, Software Architekt
>
> edrenth at fryske-akademy.nl
>
> Doelestrjitte 8
> 8911 DX  Ljouwert
> +31 58 234 30 47
> +31 62 094 34 28 (priv?)
>
> skype: eduarddrenth
> https://github.com/eduarddrenth
> frisian.eu
> gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth
>
>
> Op freed bin ik th?s/wurkje ik minder
>
>
>
>

	[[alternative HTML version deleted]]


From iuke-tier@ey m@iii@g oii uiow@@edu  Mon Nov 30 19:30:34 2020
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Mon, 30 Nov 2020 12:30:34 -0600 (CST)
Subject: [R] 
 [External] Why is R making a copy-on-modification after using str?
In-Reply-To: <trinity-4420798e-945f-4280-a3cc-b59fe317de08-1606731160638@3c-app-gmx-bs55>
References: <trinity-4420798e-945f-4280-a3cc-b59fe317de08-1606731160638@3c-app-gmx-bs55>
Message-ID: <alpine.DEB.2.21.2011301224020.3003@luke-Latitude-7480>

On Mon, 30 Nov 2020, Georg Kindermann wrote:

> Dear list members,
>
> I was wondering why R is making a copy-on-modification after using str.
>
> m <- matrix(1:12, 3)
> tracemem(m)
> #[1] "<0x559df861af28>"
> dim(m) <- 4:3
> m[1,1] <- 0L
> m[] <- 12:1
> str(m)
> # int [1:4, 1:3] 12 11 10 9 8 7 6 5 4 3 ...
> dim(m) <- 3:4  #Here after str a copy is made
> #tracemem[0x559df861af28 -> 0x559df838e4a8]:
> dim(m) <- 3:4
> str(m)
> # int [1:3, 1:4] 12 11 10 9 8 7 6 5 4 3 ...
> dim(m) <- 3:4 #Here again after str a copy
> #tracemem[0x559df838e4a8 -> 0x559df82c9d78]:

As of R 4.0.0 it is in some cases possible to reduce reference counts
internally and so avoid a copy in cases like this. It would be too
costly to try to detect all cases where a count can be dropped, but it
this case we can do better. It turns out that the internals of
pos.to.env were unnecessarily creating an extra reference to the call
environment (here in a call to exists()). This is fixed in r79528.
Thanks.

> Also I was wondering why a copy is made when having a Task Callback.
>
> TCB <- addTaskCallback(function(...) TRUE)
> m <- matrix(1:12, nrow = 3)
> tracemem(m)
> #[1] "<0x559dfa79def8>"
> dim(m) <- 4:3  #Copy on modification
> #tracemem[0x559dfa79def8 -> 0x559dfa8998e8]:
> removeTaskCallback(TCB)
> #[1] TRUE
> dim(m) <- 4:3  #No copy
>

This _may_ be related to references created in the process of
protecting the return value from evaluation. If so, addressing the
debug issue raised by Duncan may resolve this. If not, someone will
have to take a closer look.

Best,

luke

> I am using R version 4.0.3.
>
> Kind regards,
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From iuke-tier@ey m@iii@g oii uiow@@edu  Mon Nov 30 19:32:47 2020
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Mon, 30 Nov 2020 12:32:47 -0600 (CST)
Subject: [R] [External] Re: Why is R making a copy-on-modification after
 using str?
In-Reply-To: <53c46591-db71-4e47-5c3d-2372f243a16c@gmail.com>
References: <trinity-4420798e-945f-4280-a3cc-b59fe317de08-1606731160638@3c-app-gmx-bs55>
 <53c46591-db71-4e47-5c3d-2372f243a16c@gmail.com>
Message-ID: <alpine.DEB.2.21.2011301230430.3003@luke-Latitude-7480>

On Mon, 30 Nov 2020, Duncan Murdoch wrote:

> On 30/11/2020 5:12 a.m., Georg Kindermann wrote:
>> Dear list members,
>> 
>> I was wondering why R is making a copy-on-modification after using str.
>
> This isn't really an explanation, but adds a bit more data.  If you inspect m 
> before and after str(), you'll see that str(m) leaves it with two references:
>
>> m <- matrix(1:12, 3)
>>   .Internal(inspect(m))
> @7fcb0ad682c8 13 INTSXP g0c4 [REF(1),ATT] (len=12, tl=0) 1,2,3,4,5,...
> ATTRIB:
>  @7fcaf5f7b8a0 02 LISTSXP g0c0 [REF(1)]
>    TAG: @7fcafd091a80 01 SYMSXP g1c0 [MARK,REF(65535),LCK,gp=0x6000] "dim" 
> (has value)
>    @7fcb0afecc80 13 INTSXP g0c1 [REF(65535)] (len=2, tl=0) 3,4
>>   str(m)
> int [1:3, 1:4] 1 2 3 4 5 6 7 8 9 10 ...
>>   .Internal(inspect(m))
> @7fcb0ad682c8 13 INTSXP g0c4 [REF(2),ATT] (len=12, tl=0) 1,2,3,4,5,...
> ATTRIB:
>  @7fcaf5f7b8a0 02 LISTSXP g0c0 [REF(1)]
>    TAG: @7fcafd091a80 01 SYMSXP g1c0 [MARK,REF(65535),LCK,gp=0x6000] "dim" 
> (has value)
>    @7fcb0afecc80 13 INTSXP g0c1 [REF(65535)] (len=2, tl=0) 3,4
>
>
> It's not just str():  this sequence also does it.
>
>  m <- matrix(1:12, 3)
>  debug(mean)
>  mean(m)

This is due to the restarts needed by do_browser() creating links to
the environment that could be cleaned up in endcontext. There is a
runtime cost to doing so, but probably worth looking into.

Best,

luke

>
> Hit c a couple of times now to get out of debugging, and m is left with two 
> references to it.  I don't see that if mean isn't being debugged.
>
> Duncan Murdoch
>
>
>> 
>> m <- matrix(1:12, 3)
>> tracemem(m)
>> #[1] "<0x559df861af28>"
>> dim(m) <- 4:3
>> m[1,1] <- 0L
>> m[] <- 12:1
>> str(m)
>> # int [1:4, 1:3] 12 11 10 9 8 7 6 5 4 3 ...
>> dim(m) <- 3:4  #Here after str a copy is made
>> #tracemem[0x559df861af28 -> 0x559df838e4a8]:
>> dim(m) <- 3:4
>> str(m)
>> # int [1:3, 1:4] 12 11 10 9 8 7 6 5 4 3 ...
>> dim(m) <- 3:4 #Here again after str a copy
>> #tracemem[0x559df838e4a8 -> 0x559df82c9d78]:
>> 
>> Also I was wondering why a copy is made when having a Task Callback.
>> 
>> TCB <- addTaskCallback(function(...) TRUE)
>> m <- matrix(1:12, nrow = 3)
>> tracemem(m)
>> #[1] "<0x559dfa79def8>"
>> dim(m) <- 4:3  #Copy on modification
>> #tracemem[0x559dfa79def8 -> 0x559dfa8998e8]:
>> removeTaskCallback(TCB)
>> #[1] TRUE
>> dim(m) <- 4:3  #No copy
>> 
>> I am using R version 4.0.3.
>> 
>> Kind regards,
>> Georg
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From tr@xp|@yer @end|ng |rom gm@||@com  Mon Nov 30 21:15:10 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Mon, 30 Nov 2020 21:15:10 +0100
Subject: [R] RGB -> CYMK, with consistent colors
In-Reply-To: <65f2cb57-0b88-9de9-acee-97c224f0d64d@knosof.co.uk>
References: <rpupql$99c$1@ciao.gmane.io>
 <CAGAA5bfU3vrdCHCfZC9yY8Vb_MENY--BjE=5Pz+paTO98Aa_dg@mail.gmail.com>
 <e8a1008c-82bf-b1a0-953a-bbedccee04a9@knosof.co.uk>
 <CAGAA5betTMJu5yKDev5q2P7sBoTYEcub4y7q-haO7yk5n5v06g@mail.gmail.com>
 <65f2cb57-0b88-9de9-acee-97c224f0d64d@knosof.co.uk>
Message-ID: <CAGAA5bcZMLXm6-3izgs8hw26PKOem_e8zf3D4=YEEyuuZv2MTQ@mail.gmail.com>

On Sun, 29 Nov 2020 at 20:55, Derek M Jones <derek at knosof.co.uk> wrote:
[...]
>
> library("colorspace")
>
> two_c=rainbow(2)
> x=runif(20)
> y=runif(20)
> plot(x, y, col=two_c[2])
> pdf(file="cmyk.pdf", colormodel="cmyk")
> plot(x, y, col=two_c[2])
> dev.off()

rainbow(2) gives two RGB-colours: #FF0000 (=pure red) and #00FFFF (=pure
cyan).
So it should be no problem to match two_c[2] perfect in CMYK-colourspace

However after some testing.
I totally agree that CMYK handling in R using pdf(..., colormodel = "cmyk")
is not correct.

One solution:
Output in tiff or png instead and then convert to CMYK using external tools.

Try this:
png("plot.png")
plot(runif(10), runif(10), col =  ""#00FFFF") # cyan
dev.off()

And then convert plot.png using:
https://www.online-utility.org/image/convert/to/CMYK

Regards
Martin

	[[alternative HTML version deleted]]


From gm@ne @end|ng |rom kno@o|@co@uk  Mon Nov 30 21:40:27 2020
From: gm@ne @end|ng |rom kno@o|@co@uk (Derek Jones)
Date: Mon, 30 Nov 2020 20:40:27 +0000
Subject: [R] RGB -> CYMK, with consistent colors
In-Reply-To: <CAGAA5bcZMLXm6-3izgs8hw26PKOem_e8zf3D4=YEEyuuZv2MTQ@mail.gmail.com>
References: <rpupql$99c$1@ciao.gmane.io>
 <CAGAA5bfU3vrdCHCfZC9yY8Vb_MENY--BjE=5Pz+paTO98Aa_dg@mail.gmail.com>
 <e8a1008c-82bf-b1a0-953a-bbedccee04a9@knosof.co.uk>
 <CAGAA5betTMJu5yKDev5q2P7sBoTYEcub4y7q-haO7yk5n5v06g@mail.gmail.com>
 <65f2cb57-0b88-9de9-acee-97c224f0d64d@knosof.co.uk>
 <CAGAA5bcZMLXm6-3izgs8hw26PKOem_e8zf3D4=YEEyuuZv2MTQ@mail.gmail.com>
Message-ID: <rq3lbr$r71$1@ciao.gmane.io>

Martin,

> However after some testing.
> I totally agree that CMYK handling in R using pdf(..., colormodel = "cmyk")
> is not correct.

I thought the issue may be OS specific, but I get similar behavior on a Mac.

I have discovered the Cyan tool: http://cyan.fxarena.net/
and will try it out.

As various people have pointed out, RGB -> CMYK conversion is never going
to be perfect.  It just so happens that my book contains many plots that use
red and cyan, and a good conversion to cyan is most of what I am after.

 > One solution:
 > Output in tiff or png instead and then convert to CMYK using external tools.

There are 600+ figures.  There are png versions here:
http://knosof.co.uk/ESEUR/figures/index.html


From @nthonytrev|@@n @end|ng |rom gm@||@com  Mon Nov 30 19:29:36 2020
From: @nthonytrev|@@n @end|ng |rom gm@||@com (Anthony Trevisan)
Date: Mon, 30 Nov 2020 13:29:36 -0500
Subject: [R] [R-pkgs] Automated Investing - etrader
Message-ID: <CAB035rJoen8J-s+wYGtxuSD+80+tm4Mr_HfQ4r8eFqzd6a9S-w@mail.gmail.com>

Hello,

I wanted to notify the R community about a new package for trading on the
ETRADE platform through an API. The package `etrader` (
https://CRAN.R-project.org/package=etrader
<https://cran.r-project.org/package=etrader>) interacts with the ETRADE API
to allow for authentication, trading, account details and more. You can
find more details about the package here:
https://tonytrevisan.github.io/etrader/.

This completes a suite of three finance packages I developed to allow for
automated trading and investing. `rameritrade` and `etrader` allow for
trading on TD Ameritrade and ETRADE which collectively hold more than 16
million accounts and $1.5 trillion in Assets. `fmpcloudr` is a package to
pull data from Financial Modeling Prep (
https://financialmodelingprep.com/developer/docs/companies-key-stats-free-api/)
to perform in-depth analysis on a range of financial metrics.

I have a number of articles and 'How To' guides on my blog that show
someone how to fully automate their retirement investing (
https://tonytrevisan.github.io/blog.html). I hope these tools prove useful
to the R community.

Best regards,
Tony

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


