From fisher at plessthan.com  Sat Nov  1 02:32:48 2014
From: fisher at plessthan.com (Fisher Dennis)
Date: Fri, 31 Oct 2014 18:32:48 -0700
Subject: [R] Creating a new column from a series of columns
Message-ID: <FDB73B73-4EDA-43E7-A342-44ACA702768C@plessthan.com>

R 3.1.1
OS X

Colleagues,
I have a dataset containing multiple columns indicating race for subjects in a clinical trial.  A subset of the data (obtained with dput) is shown here:

structure(list(PLTID = c(7157, 8138, 8150, 9112, 9114, 9115, 
9124, 9133, 9141, 9144, 9148, 12110, 12111, 12116, 12134, 12136, 
12137, 12142, 12143, 12146, 12147, 13159), Indian..RACE1. = c(NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA), Asian..RACE2. = c("", "Yes", "", "", "", 
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", 
""), Black..RACE3. = c("Yes", "", "", "Yes", "Yes", "Yes", "Yes", 
"Yes", "", "Yes", "", "", "", "", "", "", "", "Yes", "Yes", "", 
"", ""), Native.Hawaiian.or.other.Pacif..RACE4. = c(NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA), White..RACE5. = c("", "", "Yes", "", "", "", "", 
"", "Yes", "", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", 
"", "", "Yes", "Yes", "Yes"), Other.Race..RACE6. = c(NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA), Specify.Other.Race..RACEOTH. = c(NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA)), .Names = c("PLTID", "Indian..RACE1.", "Asian..RACE2.", 
"Black..RACE3.", "Native.Hawaiian.or.other.Pacif..RACE4.", "White..RACE5.", 
"Other.Race..RACE6.", "Specify.Other.Race..RACEOTH."), class = "data.frame", row.names = 43:64)

I would like to add a column that indicates which of the other columns contains ?Yes?.  In other words, that column would contain:
	Black..RACE3.
	Asian..RACE2.
	White..RACE5.
	Black..RACE3.
	?

Even better would be
	Black
	Asian
	White
	Black
	?
(which I can accomplish with strsplit)

None of the rows contains more than one ?Yes? although it is possible that none of the entries in a row would be ?Yes? (in which case, the entry in the new column should be NA)

I could do this by looping through each of the columns with something like this:
	DATA$RACE	 	<- NA
	for (COL in 2:8)	DATA$RACE[which(DATA[,COL] == "Yes")]	<- names(DATA)[COL] 
But, I suspect that there is some more elegant way to accomplish this.

Thanks in advance.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From jorgeivanvelez at gmail.com  Sat Nov  1 03:27:39 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Sat, 1 Nov 2014 13:27:39 +1100
Subject: [R] Creating a new column from a series of columns
In-Reply-To: <FDB73B73-4EDA-43E7-A342-44ACA702768C@plessthan.com>
References: <FDB73B73-4EDA-43E7-A342-44ACA702768C@plessthan.com>
Message-ID: <CAKL8G3HcBJYh+6Arhyd4rsWmWAJTOPe=vnvjpDO82DjaSpGQAA@mail.gmail.com>

Dear Dennis,

Assuming that your data.frame() is called dd, the following should get you
started:

colnames(dd[,-1])[apply(dd[,-1], 1, function(x) which(x == 'Yes'))]

HTH,
Jorge.-


On Sat, Nov 1, 2014 at 12:32 PM, Fisher Dennis <fisher at plessthan.com> wrote:

> R 3.1.1
> OS X
>
> Colleagues,
> I have a dataset containing multiple columns indicating race for subjects
> in a clinical trial.  A subset of the data (obtained with dput) is shown
> here:
>
> structure(list(PLTID = c(7157, 8138, 8150, 9112, 9114, 9115,
> 9124, 9133, 9141, 9144, 9148, 12110, 12111, 12116, 12134, 12136,
> 12137, 12142, 12143, 12146, 12147, 13159), Indian..RACE1. = c(NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA), Asian..RACE2. = c("", "Yes", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> ""), Black..RACE3. = c("Yes", "", "", "Yes", "Yes", "Yes", "Yes",
> "Yes", "", "Yes", "", "", "", "", "", "", "", "Yes", "Yes", "",
> "", ""), Native.Hawaiian.or.other.Pacif..RACE4. = c(NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA), White..RACE5. = c("", "", "Yes", "", "", "", "",
> "", "Yes", "", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes",
> "", "", "Yes", "Yes", "Yes"), Other.Race..RACE6. = c(NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA), Specify.Other.Race..RACEOTH. = c(NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA)), .Names = c("PLTID", "Indian..RACE1.", "Asian..RACE2.",
> "Black..RACE3.", "Native.Hawaiian.or.other.Pacif..RACE4.", "White..RACE5.",
> "Other.Race..RACE6.", "Specify.Other.Race..RACEOTH."), class =
> "data.frame", row.names = 43:64)
>
> I would like to add a column that indicates which of the other columns
> contains "Yes".  In other words, that column would contain:
>         Black..RACE3.
>         Asian..RACE2.
>         White..RACE5.
>         Black..RACE3.
>         ...
>
> Even better would be
>         Black
>         Asian
>         White
>         Black
>         ...
> (which I can accomplish with strsplit)
>
> None of the rows contains more than one 'Yes' although it is possible that
> none of the entries in a row would be 'Yes' (in which case, the entry in
> the new column should be NA)
>
> I could do this by looping through each of the columns with something like
> this:
>         DATA$RACE               <- NA
>         for (COL in 2:8)        DATA$RACE[which(DATA[,COL] == "Yes")]   <-
> names(DATA)[COL]
> But, I suspect that there is some more elegant way to accomplish this.
>
> Thanks in advance.
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Nov  1 04:13:57 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 31 Oct 2014 20:13:57 -0700
Subject: [R] Creating a new column from a series of columns
In-Reply-To: <FDB73B73-4EDA-43E7-A342-44ACA702768C@plessthan.com>
References: <FDB73B73-4EDA-43E7-A342-44ACA702768C@plessthan.com>
Message-ID: <alpine.BSF.2.00.1410312010090.20391@pedal.dcn.davis.ca.us>

This method handles cases where multiple columns are "Yes".

library(reshape2)
ddl <- melt( dd, id.vars = "PLTID" )
ddl[ is.na( ddl$value ), "value" ] <- ""
ddl <- ddl[ "Yes" == ddl$value, ]
result <- merge( dd[ , "PLTID", drop=FALSE ]
                , ddl[ , c( "PLTID", "variable", "value" ) ]
                     , all.x=TRUE
                )

On Fri, 31 Oct 2014, Fisher Dennis wrote:

> R 3.1.1
> OS X
>
> Colleagues,
> I have a dataset containing multiple columns indicating race for subjects in a clinical trial.  A subset of the data (obtained with dput) is shown here:
>
> structure(list(PLTID = c(7157, 8138, 8150, 9112, 9114, 9115,
> 9124, 9133, 9141, 9144, 9148, 12110, 12111, 12116, 12134, 12136,
> 12137, 12142, 12143, 12146, 12147, 13159), Indian..RACE1. = c(NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA), Asian..RACE2. = c("", "Yes", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> ""), Black..RACE3. = c("Yes", "", "", "Yes", "Yes", "Yes", "Yes",
> "Yes", "", "Yes", "", "", "", "", "", "", "", "Yes", "Yes", "",
> "", ""), Native.Hawaiian.or.other.Pacif..RACE4. = c(NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA), White..RACE5. = c("", "", "Yes", "", "", "", "",
> "", "Yes", "", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes",
> "", "", "Yes", "Yes", "Yes"), Other.Race..RACE6. = c(NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA), Specify.Other.Race..RACEOTH. = c(NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA)), .Names = c("PLTID", "Indian..RACE1.", "Asian..RACE2.",
> "Black..RACE3.", "Native.Hawaiian.or.other.Pacif..RACE4.", "White..RACE5.",
> "Other.Race..RACE6.", "Specify.Other.Race..RACEOTH."), class = "data.frame", row.names = 43:64)
>
> I would like to add a column that indicates which of the other columns contains ?Yes?.  In other words, that column would contain:
> 	Black..RACE3.
> 	Asian..RACE2.
> 	White..RACE5.
> 	Black..RACE3.
> 	?
>
> Even better would be
> 	Black
> 	Asian
> 	White
> 	Black
> 	?
> (which I can accomplish with strsplit)
>
> None of the rows contains more than one ?Yes? although it is possible that none of the entries in a row would be ?Yes? (in which case, the entry in the new column should be NA)
>
> I could do this by looping through each of the columns with something like this:
> 	DATA$RACE	 	<- NA
> 	for (COL in 2:8)	DATA$RACE[which(DATA[,COL] == "Yes")]	<- names(DATA)[COL]
> But, I suspect that there is some more elegant way to accomplish this.
>
> Thanks in advance.
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From neda.nikiforova at yahoo.it  Sat Nov  1 00:20:30 2014
From: neda.nikiforova at yahoo.it (Neda Nikiforova)
Date: Fri, 31 Oct 2014 23:20:30 +0000
Subject: [R] problem with posting question: This post has NOT been accepted
	by the mailing list yet
Message-ID: <1414797630.59497.YahooMailNeo@web133205.mail.ir2.yahoo.com>

Dear administrator,
my name is Neda Nikiforova and I'm trying to post a question in R help . I subscribed the list but it gives me the following problem:
This post has NOT been accepted by the mailing list yet


Is it possible to risolve this problem as soon as possible? 

Thank you very much in advance.

Neda Nikiforova

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Nov  1 07:28:24 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 31 Oct 2014 23:28:24 -0700
Subject: [R] problem with posting question: This post has NOT been
	accepted by the mailing list yet
In-Reply-To: <1414797630.59497.YahooMailNeo@web133205.mail.ir2.yahoo.com>
References: <1414797630.59497.YahooMailNeo@web133205.mail.ir2.yahoo.com>
Message-ID: <00E6475B-4D39-4679-BD55-AD9AB80133B0@comcast.net>


On Oct 31, 2014, at 4:20 PM, Neda Nikiforova wrote:

> Dear administrator,
> my name is Neda Nikiforova and I'm trying to post a question in R help . I subscribed the list but it gives me the following problem:
> This post has NOT been accepted by the mailing list yet
> 

That is not a message from the Rhelp mail server but rather from Nabble. Nabble is not the Rhelp archive regardless of its attempt to masquerade as such.


> 
> Is it possible to risolve this problem as soon as possible? 
> 
> Thank you very much in advance.
> 
> Neda Nikiforova
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

Do read the posting guide.


> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From upananda.pani at gmail.com  Sat Nov  1 10:58:13 2014
From: upananda.pani at gmail.com (Upananda Pani)
Date: Sat, 1 Nov 2014 15:28:13 +0530
Subject: [R] treating missing values in timeSeries package
Message-ID: <CAEezrQT4L1UNnHNbs+RoMrio4tVOF54cjg7WS59FDUJSD0tPRQ@mail.gmail.com>

Dear All,

I am getting the following error when i am using interpNA function from
timeSeries package

# Missing Value Treatment (Linear Interpolation)
> spt = interpNA(spt, method = c("linear"))
Error in interpNA(spt, method = c("linear")) : spt is not a tis object
> fut = interpNA(fut, method = c("linear"))
Error in interpNA(fut, method = c("linear")) : fut is not a tis object
> spt = ts(spt, start=c(2006,4), frequency=305)
> fut = ts(fut, start=c(2006,4), frequency=305)
> spt = interpNA(spt, method = c("linear"))

Would you please help me in this regard.

With sincere regards,
Upananda

-- 


You may delay, but time will not.


Research Scholar
alternative mail id: upani at iitkgp.ac.in
Department of HSS, IIT KGP
KGP

From a-morkovin at ya.ru  Sat Nov  1 16:31:35 2014
From: a-morkovin at ya.ru (=?koi8-r?B?4c7Uz84g7c/Sy8/Xyc4=?=)
Date: Sat, 01 Nov 2014 18:31:35 +0300
Subject: [R] =?koi8-r?b?829sb3Igc3BlY2lmaWNhdGlvbiBpbiBLTUwoKSB7cmFzdGVy?=
	=?koi8-r?b?fSBmdW5jdGlvbg==?=
Message-ID: <1431471414855895@web26m.yandex.ru>

Good morning,

I use raster package to process sattelite image maps. Could anyone help me with exporting data into KML? I have a raster image which I need to transfer into Google Maps. The colors of this image is described in raster at legend@colortable slot. Each color corresponds to raster cell values, so the color of a cell is raster at legend@colortable[cell.value+1]. 

All colors of my raster printed correctly by plot(), jpeg() or png() functions.

By default, KML() function uses standart color palettes but I need to save raster's own colors. I tried to set this colors into 'col' argument of KML() {raster} function. But in this case they are not displayed in a right way: so I can't understand which value of a raster cell correspond to a color. How to define the colors correctly? Thanks. 

--?
Sincerely yours,
A.A. Morkovin


From aljehani-k at hotmail.com  Sat Nov  1 13:03:54 2014
From: aljehani-k at hotmail.com (Khulood Aljehani)
Date: Sat, 1 Nov 2014 15:03:54 +0300
Subject: [R] MSE increased by increasing the sample size for Nadaraya-Watson
 kernel regression
Message-ID: <DUB120-W878E95645094361E02019859B0@phx.gbl>


Hello
I hope that you will help me in my problem with the Nadaraya-Watson kernel regression estimation method (NW)  I used a simulation data and made a loop ??to calculate the NW estimator for the regression model Y=1-X+exp(-200*(X-0.5)^2)+E where, Y: the response variable,       X: the explanatory variable from uniform (0,1)       E: error term, i.i.d from normal(0,0.1) Then i calculate the MSE  But the MSE increases with increasing the sample size, and this is my program that i wrote it
n1=25
set.seed(4455)
E<-rnorm(n1,mean=0,sd=0.1)
X<-runif(n1, min = 0, max = 1)
mx=1-X+exp(-200*(X-0.5)^2)
Y <- mx+E
nrep <- 1000

#----------------------------------------Fixed NW
mse_rep1<-c()
for(i in 1:1500){
set.seed(i+236)
E<-rnorm(n1,mean=0,sd=0.1)
X<-runif(n1, min = 0, max = 1)
mx=1-X+exp(-200*(X-0.5)^2)
Y <- mx+E
hmax <- 2 * sqrt(var(X)) * n1^(-1/5) 
lower = 0.01 * hmax              
h<- bw.ucv(X,nb = 1000, lower=lower, upper=hmax, tol=0.1*lower)
est1 <- ksmooth(X, Y, kernel = "normal", bandwidth = h)$y
mse1<-(n1^-1)*sum((Y - est1)^2)

mse_rep1 <- cbind(mse_rep1,mse1)

dimnames(mse_rep1)<-list(c("MSE1"),paste("rep",1:i))

}
library(functional)
MSE_rep1<-mse_rep1[,apply(mse_rep1, 2, Compose(is.finite, any))]

MSE_fixedNW<- apply(MSE_rep1[1:1000], 1, mean)     #calculate the average of the 1000 MSEBut i got NA value first, i made 1500 replication then i choose 1000 without NA value
When i change the sample size to 50 or 100 the MSE decrease , but more than 100 the MSE increas. this is the main problem.
I hope I was able to clarify the problem well
Regards 
    		 	   		  
	[[alternative HTML version deleted]]


From hsk1404 at hotmail.com  Sat Nov  1 14:11:45 2014
From: hsk1404 at hotmail.com (hadeel kalktawi)
Date: Sat, 1 Nov 2014 16:11:45 +0300
Subject: [R] mixdist to mixture of exponential
Message-ID: <DUB119-W21B84DA8255C23FFC87884BE9B0@phx.gbl>

Dear R-useres,Please help me on using "mix" function under package "mixdist"..I would like to model an one-dimensional data (x), with a mixture of exponential, using "mix"what I understand that we can do this through "gamma" distribution, in the argument of dist, then we need to set that mu of gamma is fixed and equal to one, I tried to domix(x,data.frame(0.5,0.4),dist="gamma",constr=list(conmu="MFX"),fixmu=1), but it dose not work,If anyone could help me out, I would be extremely gratefulThanksHSK 		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sat Nov  1 19:28:17 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 1 Nov 2014 11:28:17 -0700
Subject: [R] MSE increased by increasing the sample size for
 Nadaraya-Watson kernel regression
In-Reply-To: <DUB120-W878E95645094361E02019859B0@phx.gbl>
References: <DUB120-W878E95645094361E02019859B0@phx.gbl>
Message-ID: <CACk-te1i+RT5Qh=_5mm_6ZO8JsDrWV+C3eRKAvoCO=TLwUvZ-Q@mail.gmail.com>

1. I am unfamiliar with the functional package.

2. I think the proper question is: Why do you expect the mse to
decrease with decreasing sample size?
Example: the precision of an average (as an estimator of the
population mean) increases (gets smaller) as sample size increases,
but the mse is essentially constant as an estimator of the population
variance.
Note: for nonparametric smoothers, mse is related to bandwidth choice
also. This might change by default with different sample sizes.

3. In future, please post in plain text, not html, as the posting
guide requests.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Nov 1, 2014 at 5:03 AM, Khulood Aljehani <aljehani-k at hotmail.com> wrote:
>
> Hello
> I hope that you will help me in my problem with the Nadaraya-Watson kernel regression estimation method (NW)  I used a simulation data and made a loop to calculate the NW estimator for the regression model Y=1-X+exp(-200*(X-0.5)^2)+E where, Y: the response variable,       X: the explanatory variable from uniform (0,1)       E: error term, i.i.d from normal(0,0.1) Then i calculate the MSE  But the MSE increases with increasing the sample size, and this is my program that i wrote it
> n1=25
> set.seed(4455)
> E<-rnorm(n1,mean=0,sd=0.1)
> X<-runif(n1, min = 0, max = 1)
> mx=1-X+exp(-200*(X-0.5)^2)
> Y <- mx+E
> nrep <- 1000
>
> #----------------------------------------Fixed NW
> mse_rep1<-c()
> for(i in 1:1500){
> set.seed(i+236)
> E<-rnorm(n1,mean=0,sd=0.1)
> X<-runif(n1, min = 0, max = 1)
> mx=1-X+exp(-200*(X-0.5)^2)
> Y <- mx+E
> hmax <- 2 * sqrt(var(X)) * n1^(-1/5)
> lower = 0.01 * hmax
> h<- bw.ucv(X,nb = 1000, lower=lower, upper=hmax, tol=0.1*lower)
> est1 <- ksmooth(X, Y, kernel = "normal", bandwidth = h)$y
> mse1<-(n1^-1)*sum((Y - est1)^2)
>
> mse_rep1 <- cbind(mse_rep1,mse1)
>
> dimnames(mse_rep1)<-list(c("MSE1"),paste("rep",1:i))
>
> }
> library(functional)
> MSE_rep1<-mse_rep1[,apply(mse_rep1, 2, Compose(is.finite, any))]
>
> MSE_fixedNW<- apply(MSE_rep1[1:1000], 1, mean)     #calculate the average of the 1000 MSEBut i got NA value first, i made 1500 replication then i choose 1000 without NA value
> When i change the sample size to 50 or 100 the MSE decrease , but more than 100 the MSE increas. this is the main problem.
> I hope I was able to clarify the problem well
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Nov  1 19:35:10 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 1 Nov 2014 19:35:10 +0100
Subject: [R] MSE increased by increasing the sample size for
	Nadaraya-Watson kernel regression
In-Reply-To: <DUB120-W878E95645094361E02019859B0@phx.gbl>
References: <DUB120-W878E95645094361E02019859B0@phx.gbl>
Message-ID: <1C023764-BD8F-4AE4-94B2-56999D7CCCD3@gmail.com>

You seem to be using bw.ucv to set the bandwidth for ksmooth. However, bw.ucv selects the bandwidth for estimating the _density_ of x. I see no reason to believe that the same bandwidth selection should be optimal or even consistent for a kernel smoother like ksmooth. 

Check out the KernSmooth package, in particular the dpik() and dpill() function and the book that the package supports.

-pd


> On 01 Nov 2014, at 13:03 , Khulood Aljehani <aljehani-k at hotmail.com> wrote:
> 
> 
> Hello
> I hope that you will help me in my problem with the Nadaraya-Watson kernel regression estimation method (NW)  I used a simulation data and made a loop ??to calculate the NW estimator for the regression model Y=1-X+exp(-200*(X-0.5)^2)+E where, Y: the response variable,       X: the explanatory variable from uniform (0,1)       E: error term, i.i.d from normal(0,0.1) Then i calculate the MSE  But the MSE increases with increasing the sample size, and this is my program that i wrote it
> n1=25
> set.seed(4455)
> E<-rnorm(n1,mean=0,sd=0.1)
> X<-runif(n1, min = 0, max = 1)
> mx=1-X+exp(-200*(X-0.5)^2)
> Y <- mx+E
> nrep <- 1000
> 
> #----------------------------------------Fixed NW
> mse_rep1<-c()
> for(i in 1:1500){
> set.seed(i+236)
> E<-rnorm(n1,mean=0,sd=0.1)
> X<-runif(n1, min = 0, max = 1)
> mx=1-X+exp(-200*(X-0.5)^2)
> Y <- mx+E
> hmax <- 2 * sqrt(var(X)) * n1^(-1/5) 
> lower = 0.01 * hmax              
> h<- bw.ucv(X,nb = 1000, lower=lower, upper=hmax, tol=0.1*lower)
> est1 <- ksmooth(X, Y, kernel = "normal", bandwidth = h)$y
> mse1<-(n1^-1)*sum((Y - est1)^2)
> 
> mse_rep1 <- cbind(mse_rep1,mse1)
> 
> dimnames(mse_rep1)<-list(c("MSE1"),paste("rep",1:i))
> 
> }
> library(functional)
> MSE_rep1<-mse_rep1[,apply(mse_rep1, 2, Compose(is.finite, any))]
> 
> MSE_fixedNW<- apply(MSE_rep1[1:1000], 1, mean)     #calculate the average of the 1000 MSEBut i got NA value first, i made 1500 replication then i choose 1000 without NA value
> When i change the sample size to 50 or 100 the MSE decrease , but more than 100 the MSE increas. this is the main problem.
> I hope I was able to clarify the problem well
> Regards 
>    		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From fabrice.ciup at gmail.com  Sun Nov  2 06:21:28 2014
From: fabrice.ciup at gmail.com (Fabrice Tourre)
Date: Sun, 2 Nov 2014 13:21:28 +0800
Subject: [R] How to fine control bar plot width?
Message-ID: <CAN31xkewb78_NXGY_ypTRvkjs51ayxLcMVyehYUEvs8OZ9F40Q@mail.gmail.com>

Dear expert,

I want to combine 4 figures in the same plot. Each bar plot is related
to the image() plot. I want to bar width is extractly the same width
as grid width in the image() plot. The up-barplot and the
left-barplot. I have pasted my code to follow. How can I modify for
this purpose? Thank you very much in advance.

#######################My example code###########################
datMat <- matrix(rep(1,100),nrow=10)

op=par(oma=c(1,1,1,1),mar=c(1,1,1,1),lwd = 0.2,cex=.5)

nf <- layout(matrix(c(0,1,0,2,3,4),2,3,byrow=TRUE), widths=c(1,6,1),
heights=c(1,3), respect=TRUE)


par(mar=c(3,0.5,3,0),mgp=c(0,1,-2.2))

barplot(seq(1,10),width=1,xlim=c(0,ncol(datMat)),xlab="",
space=0,col="blue",border = "white" )

box("inner", lty="dotted", col="green")

box("outer", lty="solid", col="green")


par(mar=c(0,0,0,0),mgp=c(0,1,-1))

barplot(-seq(1,10),ylim=c(0,nrow(datMat)),width=1.025,horiz=TRUE,,axes
= T,space=0,col="blue", border = "white" )


par(mar=c(1,0,0,0))

x.len=ncol(datMat)

y.len=nrow(datMat)

single.col= 'chartreuse4'

double.col= 'blue4'

triple.col= '#FFFF33'

four.col= '#FF7F00'

five.col= '#E41A1C'

colors=c('grey90',single.col, double.col,triple.col,four.col,five.col);

image(x=1:x.len, y=1:y.len, z=t(datMat), col = colors, breaks=c(-0.5
,0.5 ,1.5 ,2.5 ,3.5 ,4.5 ,5.5),

        axes = FALSE, ann=F);

abline(h=seq(0.5,0.5+y.len),col='white',lwd=0.5);

abline(v=seq(0.5,0.5+x.len),col='white',lwd=0.5)


par(mar=c(0,0,0,0),mgp=c(0,1,0))

barplot(seq(1,10),ylim=c(0,nrow(datMat)),width=.5,horiz=TRUE,axes =
FALSE, space=0,col="blue",border ="white" )

axis(side=1)






######################
sessionInfo()

R version 3.1.1 (2014-07-10)

Platform: x86_64-apple-darwin13.1.0 (64-bit)


locale:

[1] C/UTF-8/C/C/C/C


attached base packages:

[1] datasets  utils     stats     graphics  grDevices methods   base


other attached packages:

[1] xlsx_0.5.7                  xlsxjars_0.6.1

[3] rJava_0.9-6                 nutshell_2.0

[5] nutshell.audioscrobbler_1.0 nutshell.bbdb_1.0

[7] faraway_1.0.6               MASS_7.3-35


loaded via a namespace (and not attached):

[1] tools_3.1.1


From teotjunk at hotmail.com  Sun Nov  2 12:19:45 2014
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Sun, 2 Nov 2014 19:19:45 +0800
Subject: [R] Variable Length Differ
Message-ID: <SNT148-W7764E0B74148D57D312255DF980@phx.gbl>

This is my code

    BSUPred<-(forecast(BSU,h=h)[[2]])
    PressurePred<-(forecast(Pressure,h=h)[[2]])
    Placer<-(rep(1,h))
    test<-as.data.frame(cbind(BSUPred,PressurePred))
    test$Placer<-rep(1:2,h/12)
    test$Placer<-i
    test<-as.data.frame((test[c("Placer","BSUPred","PressurePred")]))
    resp<-predict(fit,newdata=test,type="response")
    Pred<-ifelse((predict(fit,newdata=test,type="response")>0.5),1,0)

But I get this error message

Error in model.frame.default(Terms, newdata, na.action = na.action, xlev = object$xlevels) : 
  variable lengths differ (found for 'Placer') 

Can anyone help?

Thanks

Tjun Kiat
 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Nov  2 19:33:24 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 02 Nov 2014 10:33:24 -0800
Subject: [R] Variable Length Differ
In-Reply-To: <SNT148-W7764E0B74148D57D312255DF980@phx.gbl>
References: <SNT148-W7764E0B74148D57D312255DF980@phx.gbl>
Message-ID: <4A9EEE93-D7FB-4B68-9B22-20295B8C8ACF@dcn.davis.CA.us>

This is not reproducible (see for example [1]), so it is very difficult to know exactly what the problem is. Also, you need to post on this list using the plain text format option in your email software, since the HTML format you used can mess up your code.

I can say that using "[" indexing on a data frame will give you back a data frame as long as you have multiple result columns, and cbind converts that to a matrix. Since data frames typically have columns of a variety of types ("storage modes") while matrices do not, you are likely damaging your data frames every time you use cbind. I recommend that you interactively execute (e.g. using copy/paste) one line at a time in your script and use the str() function after each line to learn the structure of the the objects you are creating and modifying. 

The best way to make a data frame from vector is:

test <- data.frame( BSUPred, PressurePred )

or

test <- data.frame( BSUPred=BSUPred, PressurePred=PressurePred )

A couple of ways to add columns to data frames that don't damage the data frame are:

test$Placer <- i

or (an example where specifying only one column identifies a vector rather than the usual data frame result)

test[ , "Placer" ] <- i

or even (not recommended for efficiency reasons):

test <- data.frame( test, Placer=i )

If this is not enough help, make your example reproducible using the advice in [1] and try posting again.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 2, 2014 3:19:45 AM PST, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:
>This is my code
>
>    BSUPred<-(forecast(BSU,h=h)[[2]])
>    PressurePred<-(forecast(Pressure,h=h)[[2]])
>    Placer<-(rep(1,h))
>    test<-as.data.frame(cbind(BSUPred,PressurePred))
>    test$Placer<-rep(1:2,h/12)
>    test$Placer<-i
>    test<-as.data.frame((test[c("Placer","BSUPred","PressurePred")]))
>    resp<-predict(fit,newdata=test,type="response")
>    Pred<-ifelse((predict(fit,newdata=test,type="response")>0.5),1,0)
>
>But I get this error message
>
>Error in model.frame.default(Terms, newdata, na.action = na.action,
>xlev = object$xlevels) : 
>  variable lengths differ (found for 'Placer') 
>
>Can anyone help?
>
>Thanks
>
>Tjun Kiat
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hannah.hlx at gmail.com  Sun Nov  2 19:36:56 2014
From: hannah.hlx at gmail.com (li li)
Date: Sun, 2 Nov 2014 13:36:56 -0500
Subject: [R] Finding MLE
Message-ID: <CAHLnndb-Z5mJ66QvvbQ8-ULsJio8yaDSFYaAC3Jb9-V93ybGsw@mail.gmail.com>

Hi all,
  I am trying to use the mle function in R to find the maximum likelihood
estimator. The ll function below is the negative of the log likelihood.
Suppose x0 is the observed values, I want to find the maximum likelihood
for a and b. After running the code below, I get the error message "Error
in eval(expr, envir, enclos) : argument is missing, with no default".
  Could anyone familiar with this function give some suggetion? Thanks very
much!
     Hanna

> n <- 8
> x0 <- c(2,3)
>
> ll<- function(a,b,x=x0,size=n){
+
-sum(log(gamma((n-1)/2+a-1)/(gamma((n-1)/2)*gamma(a))*1/(2*b^a)*(x/2)^((n-1)/2-1)*(1/b+x/2)^(-((n-1)/2+a-1))))}
>
> fit <- mle(ll, nobs = length(x0))

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Nov  2 20:57:55 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 2 Nov 2014 11:57:55 -0800
Subject: [R] Finding MLE
In-Reply-To: <CAHLnndb-Z5mJ66QvvbQ8-ULsJio8yaDSFYaAC3Jb9-V93ybGsw@mail.gmail.com>
References: <CAHLnndb-Z5mJ66QvvbQ8-ULsJio8yaDSFYaAC3Jb9-V93ybGsw@mail.gmail.com>
Message-ID: <CACk-te3h2MgX5gEeu6ZTzMwkgKPS9eug93McuDrpTRbiO8TzPQ@mail.gmail.com>

You do not appear to provide initial values for a and b , i.e. the
"start" argument for mle.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Nov 2, 2014 at 10:36 AM, li li <hannah.hlx at gmail.com> wrote:
> Hi all,
>   I am trying to use the mle function in R to find the maximum likelihood
> estimator. The ll function below is the negative of the log likelihood.
> Suppose x0 is the observed values, I want to find the maximum likelihood
> for a and b. After running the code below, I get the error message "Error
> in eval(expr, envir, enclos) : argument is missing, with no default".
>   Could anyone familiar with this function give some suggetion? Thanks very
> much!
>      Hanna
>
>> n <- 8
>> x0 <- c(2,3)
>>
>> ll<- function(a,b,x=x0,size=n){
> +
> -sum(log(gamma((n-1)/2+a-1)/(gamma((n-1)/2)*gamma(a))*1/(2*b^a)*(x/2)^((n-1)/2-1)*(1/b+x/2)^(-((n-1)/2+a-1))))}
>>
>> fit <- mle(ll, nobs = length(x0))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Mon Nov  3 00:30:14 2014
From: tmrsg11 at gmail.com (C W)
Date: Sun, 2 Nov 2014 18:30:14 -0500
Subject: [R] How to calculate correlation of a vector in R?
Message-ID: <CAE2FW2nVPryQXDGBgTp3jpJBn-79M6YgK5p6WEF4h4wVx9LXNQ@mail.gmail.com>

Hi list,
I have trying to calculate the covariance/correlation of three elements.  I
have vector say,

v <- c(700, 800, 1000)

I want to have a 3 by 3 correlation matrix, meaning cor(v1, c2), cor(v1,
c3), cor(v2, v3), etc...

So far I get,
> cor(v)
Error in cor(v) : supply both 'x' and 'y' or a matrix-like 'x'

> vvv <- cbind(v, v, v)
> cor(vvv)
  v v v
v 1 1 1
v 1 1 1
v 1 1 1


I am calculating squared exponential kernel as seen here.
http://mlg.eng.cam.ac.uk/duvenaud/cookbook/index.html

Thanks a bunch,

Mike

	[[alternative HTML version deleted]]


From cranatic at gmail.com  Mon Nov  3 00:40:05 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 2 Nov 2014 18:40:05 -0500
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <5456c0d5c3619_4f124661134189@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* addreg (1.2)
  Maintainer: Mark Donoghoe
  Author(s): Mark Donoghoe <mark.donoghoe at mq.edu.au>
  License: GPL (>= 2)
  http://crantastic.org/packages/addreg

  Methods for fitting identity-link GLMs and GAMs to discrete data. The
  package uses EM-type algorithms with more stable convergence
  properties than standard methods.

* CateSelection (1.0)
  Maintainer: Yi Xu
  Author(s): Yi Xu and Jixiang Wu
  License: GPL (>= 2)
  http://crantastic.org/packages/CateSelection

  A multi-factor dimensionality reduction based forward selection method
  for genetic association mapping.

* DAMOCLES (1.0)
  Maintainer: Rampal S. Etienne
  Author(s): Rampal S. Etienne & Alex L. Pigot
  License: GPL-2
  http://crantastic.org/packages/DAMOCLES

  Simulates and computes (maximum) likelihood of a dynamical model of
  community assembly that takes into account the phylogenetic history

* exCon (0.1-0)
  Maintainer: Bryan A. Hanson
  Author(s): Bryan Hanson [aut, cre], Kristina Mulry [ctb]
  License: GPL-3
  http://crantastic.org/packages/exCon

  exCon is an interactive tool to explore topographic-like data sets. 
  Such data sets take the form of a matrix in which the rows and
  columns provide location/frequency information, and the matrix
  elements contain altitude/response information.  Such data is found
  in cartography, 2D spectroscopy and chemometrics.  exCon creates an
  interactive web page showing the contoured data set along with
  slices from the original matrix parallel to each dimension. The page
  is written in d3/javascript.

* genpathmox (0.1)
  Maintainer: &quot;Giuseppe Lamberti&quot;
  Author(s): "Giuseppe Lamberti" [aut, cre]
  License: GPL-3
  http://crantastic.org/packages/genpathmox

  genpathmox provides a very interesting solution for handling
  segmentation variables in complex statistical methodology. It
  contains en extended version of the PATHMOX algorithm in the context
  of partial least square path modeling (Sanchez, 2009) including the
  F-block test (to detect the responsible latent endogenous equations
  of the difference), the F-coefficient (to detect the path
  coefficients responsible of the difference) and the invariance test
  (to realize a comparison between the sub-models&#39; latent variables).
  Furthermore, the package contains a generalized version of the
  PATHMOX algorithm to approach different methodologies: linear
  regression and least absolute regression models.

* hermite (1.0)
  Maintainer: David Mori??a Soler
  Author(s): David Mori??a (Centre for Research in Environmental Epidemiology,
             CREAL), Manuel Higueras (Universitat Aut??noma de
             Barcelona and Public Health England) and Pedro Puig
             (Universitat Aut??noma de Barcelona)
  License: GPL (>= 2)
  http://crantastic.org/packages/hermite

  Probability functions for the generalized Hermite distribution

* MfUSampler (0.9)
  Maintainer: Alireza S. Mahani
  Author(s): Alireza S. Mahani, Mansour T.A. Sharabiani
  License: GPL (>= 2)
  http://crantastic.org/packages/MfUSampler

  Convenience Functions for Multivariate MCMC Using Univariate Samplers,
  including Slice Sampler with Stepout and Shrinkage (Neal, 2003), and
  Adaptive Rejection Sampler (Gilks and Wild, 1992).

* myTAI (0.0.1)
  Maintainer: Hajk-Georg Drost
  Author(s): Hajk-Georg Drost
  License: GPL-3
  http://crantastic.org/packages/myTAI

  The present collection of functions can be used to perform
  phylotranscriptomics analyses to investigate phenomena within the
  field of Evolutionary Developmental Biology

* PrevMap (1.0)
  Maintainer: Emanuele Giorgi
  Author(s): Emanuele Giorgi, Peter J. Diggle
  License: GPL (>= 2)
  http://crantastic.org/packages/PrevMap

  The PrevMap package provides functions for both likelihood-based and
  Bayesian analysis of spatially referenced prevalence data. &#39;PrevMap&#39;
  is also an extension of the &#39;geoR&#39; package which should be installed
  first together with the &#39;maxLik&#39;, &#39;raster&#39; and &#39;pdist&#39; packages.

* qdm (0.1-0)
  Maintainer: Nora Umbach
  Author(s): Nora Umbach [aut, cre], Florian Wickelmaier [aut]
  License: GPL (>= 2)
  http://crantastic.org/packages/qdm

  This package provides different specifications of a Quadrilateral
  Dissimilarity Model which can be used to fit same-different
  judgments in order to get a predicted matrix that satisfies regular
  minimality [Colonius &amp; Dzhafarov, 2006, Measurement and
  representations of sensations, Erlbaum]. From such a matrix,
  Fechnerian distances can be computed.

* RealVAMS (0.3-1)
  Maintainer: Andrew Karl
  Author(s): Andrew Karl, Jennifer Broatch, and Jennifer Green
  License: GPL-2
  http://crantastic.org/packages/RealVAMS

  The RealVAMs package fits a multivariate value-added model (VAM) (see
  Broatch and Lohr 2012) with normally distributed test scores and a
  binary outcome indicator. This material is based upon work supported
  by the National Science Foundation under grants DRL-1336027 and
  DRL-1336265.

* rqPen (1.0)
  Maintainer: Ben Sherwood
  Author(s): Ben Sherwood
  License: MIT + file LICENSE
  http://crantastic.org/packages/rqPen

  Performs penalized quantile regression for LASSO, SCAD and MCP
  functions. Provides a function that automatically generates lambdas
  and evaluates different models with cross validation or BIC,
  including a large p version of BIC.

* safi (1.0)
  Maintainer: Jana Fruth
  Author(s): Jana Fruth, Malte Jastrow
  License: GPL (>= 2)
  http://crantastic.org/packages/safi

  Design and sensitivity analysis for computer experiments with
  scalar-valued output and functional input, e.g. over time or space.
  The aim is to explore the behavior of the sensitivity over the
  functional domain.

* settings (0.1.1)
  Maintainer: Mark van der Loo
  Author(s): Mark van der Loo
  License: GPL-3
  http://crantastic.org/packages/settings

  Provides option settings management that goes beyond R&#39;s default
  &#39;options&#39; function. With this package, users can define their own
  option settings manager holding option names and default values.
  Settings can then be retrieved, altered and reset to defaults with
  ease. For R programmers and package developers it offers cloning and
  merging functionality which allows for conveniently defining global
  and local options, possibly in a multilevel options hierarchy. See
  the package vignette for some examples concerning functions, S4
  classes, and reference classes.

* smac (1.0)
  Maintainer: Chong Zhang
  Author(s): Chong Zhang, Guo Xian Yau, Yufeng Liu
  License: GPL-2
  http://crantastic.org/packages/smac

  This package provides a solution path for L1-penalized angle-based
  classification. Three loss functions are implemented in smac,
  including the deviance loss in logistic regression, the exponential
  loss in boosting, and the proximal support vector machine loss.

* smacpod (1.0.0)
  Maintainer: Joshua French
  Author(s): Joshua French
  License: GPL (>= 2)
  http://crantastic.org/packages/smacpod

  Various statistical methods for analyzing case-control point data. The
  methods available closely follow those in chapter 6 of Applied
  Spatial Statistics for Public Health Data by Waller and Gotway
  (2004).

* webutils (0.2)
  Maintainer: Jeroen Ooms
  Author(s): Jeroen Ooms
  License: MIT + file LICENSE
  http://crantastic.org/packages/webutils

  Utility functions for developing web applications. Includes parsers
  for application/x-www-form-urlencoded as well as multipart/form-data
  and examples of using the parser with either httpuv or rhttpd.


Updated packages
----------------

astsa (1.3), BatchExperiments (1.4), BatchJobs (1.5), BBmisc (1.8),
bdscale (1.1), bio3d (2.1-3), CountsEPPM (2.0), DALY (1.4.0), deSolve
(1.11), eHOF (1.5.4), energy (1.6.2), FAOSTAT (1.9), fAssets
(3011.83), fBasics (3011.87), fPortfolio (3011.81), GLDEX (2.0.0.1),
hglm (2.0-11), hht (2.1.1), isdals (2.0-4), kaps (1.0.2),
knitcitations (1.0.4), ldr (1.3.3), logconPH (1.3), mapplots (1.5),
MortalitySmooth (2.3.3), nullabor (0.3.0), pander (0.5.0), pander
(0.5.1), pitchRx (1.6), PopGenReport (2.1), PrivateLR (1.2-21), qtl
(1.34-16), qtl (1.34-17), rangeMapper (0.2-8), Rcmdr (2.1-4),
RcppArmadillo (0.4.500.0), rex (0.1.2), rgl (0.95.1157), rjags (3-14),
RMTstat (0.3), rNOMADS (2.0.4), robustreg (0.1-7), ropensecretsapi
(1.0.1), RQDA (0.2-7), seqinr (3.0-9), seqMeta (1.5), sirt (1.0-3),
SKAT (1.0), sn (1.1-1), sqldf (0.4-9), statar (0.1.2), surveillance
(1.8-1), Taxonstand (1.5), texreg (1.34), timeDate (3011.99),
timeSeries (3011.98), TSclust (1.2.2), vcdExtra (0.6-3), vegdata
(0.6-7)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From jdnewmil at dcn.davis.CA.us  Mon Nov  3 01:04:28 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 02 Nov 2014 16:04:28 -0800
Subject: [R] How to calculate correlation of a vector in R?
In-Reply-To: <CAE2FW2nVPryQXDGBgTp3jpJBn-79M6YgK5p6WEF4h4wVx9LXNQ@mail.gmail.com>
References: <CAE2FW2nVPryQXDGBgTp3jpJBn-79M6YgK5p6WEF4h4wVx9LXNQ@mail.gmail.com>
Message-ID: <DE497DCF-616B-483D-B442-4E574BFDE339@dcn.davis.CA.us>

What is your question? The matrix form is probably what you are looking for, but you put the same vector in three times so if course it is all ones. I don't know what you expected to happen when you entered cor(v) since there is nothing to correlate if you only have one vector.

Please post in plain text as the footer and Posting Guide request.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 2, 2014 3:30:14 PM PST, C W <tmrsg11 at gmail.com> wrote:
>Hi list,
>I have trying to calculate the covariance/correlation of three
>elements.  I
>have vector say,
>
>v <- c(700, 800, 1000)
>
>I want to have a 3 by 3 correlation matrix, meaning cor(v1, c2),
>cor(v1,
>c3), cor(v2, v3), etc...
>
>So far I get,
>> cor(v)
>Error in cor(v) : supply both 'x' and 'y' or a matrix-like 'x'
>
>> vvv <- cbind(v, v, v)
>> cor(vvv)
>  v v v
>v 1 1 1
>v 1 1 1
>v 1 1 1
>
>
>I am calculating squared exponential kernel as seen here.
>http://mlg.eng.cam.ac.uk/duvenaud/cookbook/index.html
>
>Thanks a bunch,
>
>Mike
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Mon Nov  3 01:19:56 2014
From: tmrsg11 at gmail.com (C W)
Date: Sun, 2 Nov 2014 19:19:56 -0500
Subject: [R] How to calculate correlation of a vector in R?
In-Reply-To: <DE497DCF-616B-483D-B442-4E574BFDE339@dcn.davis.CA.us>
References: <CAE2FW2nVPryQXDGBgTp3jpJBn-79M6YgK5p6WEF4h4wVx9LXNQ@mail.gmail.com>
	<DE497DCF-616B-483D-B442-4E574BFDE339@dcn.davis.CA.us>
Message-ID: <CAE2FW2nYKJqtz21RF04ZEWszSXp5Fb5Xh+y-T4uj4tBkhKg+ZQ@mail.gmail.com>

Thanks, Jeff.  I had some misunderstanding.

So, I want to calculate the squared exponential of vector v

v = c(700, 800, 1029)

formula is:
k(x_i, x_j)=sigma^2 * exp(-1/(2*l^2) * (x_i - x_j) ^2)

where,
sigma=7, l=100


I used,
> v <- c(700, 800, 1029)
> corr.matrix(cbind(v),scales=0.5)
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    1    0
[3,]    0    0    1

the output should be covariance matrix = [49, 29.7, 0.02; 29.7, 49, 3.6;
0.2,  3.6, 49]



On Sun, Nov 2, 2014 at 7:04 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> What is your question? The matrix form is probably what you are looking
> for, but you put the same vector in three times so if course it is all
> ones. I don't know what you expected to happen when you entered cor(v)
> since there is nothing to correlate if you only have one vector.
>
> Please post in plain text as the footer and Posting Guide request.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 2, 2014 3:30:14 PM PST, C W <tmrsg11 at gmail.com> wrote:
> >Hi list,
> >I have trying to calculate the covariance/correlation of three
> >elements.  I
> >have vector say,
> >
> >v <- c(700, 800, 1000)
> >
> >I want to have a 3 by 3 correlation matrix, meaning cor(v1, c2),
> >cor(v1,
> >c3), cor(v2, v3), etc...
> >
> >So far I get,
> >> cor(v)
> >Error in cor(v) : supply both 'x' and 'y' or a matrix-like 'x'
> >
> >> vvv <- cbind(v, v, v)
> >> cor(vvv)
> >  v v v
> >v 1 1 1
> >v 1 1 1
> >v 1 1 1
> >
> >
> >I am calculating squared exponential kernel as seen here.
> >http://mlg.eng.cam.ac.uk/duvenaud/cookbook/index.html
> >
> >Thanks a bunch,
> >
> >Mike
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Nov  3 03:20:42 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 02 Nov 2014 18:20:42 -0800
Subject: [R] How to calculate correlation of a vector in R?
In-Reply-To: <CAE2FW2nYKJqtz21RF04ZEWszSXp5Fb5Xh+y-T4uj4tBkhKg+ZQ@mail.gmail.com>
References: <CAE2FW2nVPryQXDGBgTp3jpJBn-79M6YgK5p6WEF4h4wVx9LXNQ@mail.gmail.com>
	<DE497DCF-616B-483D-B442-4E574BFDE339@dcn.davis.CA.us>
	<CAE2FW2nYKJqtz21RF04ZEWszSXp5Fb5Xh+y-T4uj4tBkhKg+ZQ@mail.gmail.com>
Message-ID: <95CDB7D6-BB7F-4BF2-8FE4-5868113EBCDD@dcn.davis.CA.us>

k <- sigma^2 * exp( -1/(2*l^2) * outer( v,v,FUN=function(x,y){(x-y)^2}))

but perhaps you should look at the e1071 package instead?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 2, 2014 4:19:56 PM PST, C W <tmrsg11 at gmail.com> wrote:
>Thanks, Jeff.  I had some misunderstanding.
>
>So, I want to calculate the squared exponential of vector v
>
>v = c(700, 800, 1029)
>
>formula is:
>k(x_i, x_j)=sigma^2 * exp(-1/(2*l^2) * (x_i - x_j) ^2)
>
>where,
>sigma=7, l=100
>
>
>I used,
>> v <- c(700, 800, 1029)
>> corr.matrix(cbind(v),scales=0.5)
>     [,1] [,2] [,3]
>[1,]    1    0    0
>[2,]    0    1    0
>[3,]    0    0    1
>
>the output should be covariance matrix = [49, 29.7, 0.02; 29.7, 49,
>3.6;
>0.2,  3.6, 49]
>
>
>
>On Sun, Nov 2, 2014 at 7:04 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> What is your question? The matrix form is probably what you are
>looking
>> for, but you put the same vector in three times so if course it is
>all
>> ones. I don't know what you expected to happen when you entered
>cor(v)
>> since there is nothing to correlate if you only have one vector.
>>
>> Please post in plain text as the footer and Posting Guide request.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 2, 2014 3:30:14 PM PST, C W <tmrsg11 at gmail.com> wrote:
>> >Hi list,
>> >I have trying to calculate the covariance/correlation of three
>> >elements.  I
>> >have vector say,
>> >
>> >v <- c(700, 800, 1000)
>> >
>> >I want to have a 3 by 3 correlation matrix, meaning cor(v1, c2),
>> >cor(v1,
>> >c3), cor(v2, v3), etc...
>> >
>> >So far I get,
>> >> cor(v)
>> >Error in cor(v) : supply both 'x' and 'y' or a matrix-like 'x'
>> >
>> >> vvv <- cbind(v, v, v)
>> >> cor(vvv)
>> >  v v v
>> >v 1 1 1
>> >v 1 1 1
>> >v 1 1 1
>> >
>> >
>> >I am calculating squared exponential kernel as seen here.
>> >http://mlg.eng.cam.ac.uk/duvenaud/cookbook/index.html
>> >
>> >Thanks a bunch,
>> >
>> >Mike
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From hannah.hlx at gmail.com  Mon Nov  3 04:04:41 2014
From: hannah.hlx at gmail.com (li li)
Date: Sun, 2 Nov 2014 22:04:41 -0500
Subject: [R] Finding MLE
In-Reply-To: <CACk-te3h2MgX5gEeu6ZTzMwkgKPS9eug93McuDrpTRbiO8TzPQ@mail.gmail.com>
References: <CAHLnndb-Z5mJ66QvvbQ8-ULsJio8yaDSFYaAC3Jb9-V93ybGsw@mail.gmail.com>
	<CACk-te3h2MgX5gEeu6ZTzMwkgKPS9eug93McuDrpTRbiO8TzPQ@mail.gmail.com>
Message-ID: <CAHLnndbajSbwsF_mCH1qzK3C3t+Hxu+65WrawioK_uHTDN5qQw@mail.gmail.com>

Thanks Bert for the reply. I still get a message when adding the start
argument.



> n <- 8
> x0 <- c(2,3)
>
> ll<- function(a,b,x=x0,size=n){
+
-sum(log(gamma((n-1)/2+a-1)/(gamma((n-1)/2)*gamma(a))*1/(2*b^a)*(x/2)^((n-1)/2-1)*(1/b+x/2)^(-((n-1)/2+a-1))))}
>
> fit <- mle(ll, start=list(a=3, b=1), nobs = length(x0))
Error in validObject(.Object) :
  invalid class ?mle? object: invalid object for slot "fullcoef" in class
"mle": got class "list", should be or extend class "numeric"
>
>






2014-11-02 14:57 GMT-05:00 Bert Gunter <gunter.berton at gene.com>:

> You do not appear to provide initial values for a and b , i.e. the
> "start" argument for mle.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Sun, Nov 2, 2014 at 10:36 AM, li li <hannah.hlx at gmail.com> wrote:
> > Hi all,
> >   I am trying to use the mle function in R to find the maximum likelihood
> > estimator. The ll function below is the negative of the log likelihood.
> > Suppose x0 is the observed values, I want to find the maximum likelihood
> > for a and b. After running the code below, I get the error message "Error
> > in eval(expr, envir, enclos) : argument is missing, with no default".
> >   Could anyone familiar with this function give some suggetion? Thanks
> very
> > much!
> >      Hanna
> >
> >> n <- 8
> >> x0 <- c(2,3)
> >>
> >> ll<- function(a,b,x=x0,size=n){
> > +
> >
> -sum(log(gamma((n-1)/2+a-1)/(gamma((n-1)/2)*gamma(a))*1/(2*b^a)*(x/2)^((n-1)/2-1)*(1/b+x/2)^(-((n-1)/2+a-1))))}
> >>
> >> fit <- mle(ll, nobs = length(x0))
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Mon Nov  3 04:35:07 2014
From: hannah.hlx at gmail.com (li li)
Date: Sun, 2 Nov 2014 22:35:07 -0500
Subject: [R] Finding MLE
In-Reply-To: <CAHLnndbajSbwsF_mCH1qzK3C3t+Hxu+65WrawioK_uHTDN5qQw@mail.gmail.com>
References: <CAHLnndb-Z5mJ66QvvbQ8-ULsJio8yaDSFYaAC3Jb9-V93ybGsw@mail.gmail.com>
	<CACk-te3h2MgX5gEeu6ZTzMwkgKPS9eug93McuDrpTRbiO8TzPQ@mail.gmail.com>
	<CAHLnndbajSbwsF_mCH1qzK3C3t+Hxu+65WrawioK_uHTDN5qQw@mail.gmail.com>
Message-ID: <CAHLnndYUK9LKktqHbuiZ-mYdS7UbA3R844p9ZrhKOuzjGvCCiA@mail.gmail.com>

I think I made an error in my funciton. Now it works.


library(stats4)
n <- 8
ll<- function(a,b,x){
-sum(log(gamma((n-1)/2+a-1)/(gamma((n-1)/2)*gamma(a))*1/(2*b^a)*(x/2)^((n-1)/2-1)*(1/b+x/2)^(-((n-1)/2+a-1))))}
fit <- mle(ll, start=list(a=3, b=1), fixed=list(x=c(2,3)))





2014-11-02 22:04 GMT-05:00 li li <hannah.hlx at gmail.com>:

> Thanks Bert for the reply. I still get a message when adding the start
> argument.
>
>
>
> > n <- 8
> > x0 <- c(2,3)
> >
> > ll<- function(a,b,x=x0,size=n){
> +
> -sum(log(gamma((n-1)/2+a-1)/(gamma((n-1)/2)*gamma(a))*1/(2*b^a)*(x/2)^((n-1)/2-1)*(1/b+x/2)^(-((n-1)/2+a-1))))}
> >
> > fit <- mle(ll, start=list(a=3, b=1), nobs = length(x0))
> Error in validObject(.Object) :
>   invalid class ?mle? object: invalid object for slot "fullcoef" in class
> "mle": got class "list", should be or extend class "numeric"
> >
> >
>
>
>
>
>
>
> 2014-11-02 14:57 GMT-05:00 Bert Gunter <gunter.berton at gene.com>:
>
> You do not appear to provide initial values for a and b , i.e. the
>> "start" argument for mle.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sun, Nov 2, 2014 at 10:36 AM, li li <hannah.hlx at gmail.com> wrote:
>> > Hi all,
>> >   I am trying to use the mle function in R to find the maximum
>> likelihood
>> > estimator. The ll function below is the negative of the log likelihood.
>> > Suppose x0 is the observed values, I want to find the maximum likelihood
>> > for a and b. After running the code below, I get the error message
>> "Error
>> > in eval(expr, envir, enclos) : argument is missing, with no default".
>> >   Could anyone familiar with this function give some suggetion? Thanks
>> very
>> > much!
>> >      Hanna
>> >
>> >> n <- 8
>> >> x0 <- c(2,3)
>> >>
>> >> ll<- function(a,b,x=x0,size=n){
>> > +
>> >
>> -sum(log(gamma((n-1)/2+a-1)/(gamma((n-1)/2)*gamma(a))*1/(2*b^a)*(x/2)^((n-1)/2-1)*(1/b+x/2)^(-((n-1)/2+a-1))))}
>> >>
>> >> fit <- mle(ll, nobs = length(x0))
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Nov  3 05:34:28 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 2 Nov 2014 20:34:28 -0800
Subject: [R] treating missing values in timeSeries package
In-Reply-To: <CAEezrQT4L1UNnHNbs+RoMrio4tVOF54cjg7WS59FDUJSD0tPRQ@mail.gmail.com>
References: <CAEezrQT4L1UNnHNbs+RoMrio4tVOF54cjg7WS59FDUJSD0tPRQ@mail.gmail.com>
Message-ID: <5985C9FC-3FAB-4977-9A74-F8BDE33A697A@comcast.net>


On Nov 1, 2014, at 2:58 AM, Upananda Pani wrote:

> Dear All,
> 
> I am getting the following error when i am using interpNA function from
> timeSeries package
> 
> # Missing Value Treatment (Linear Interpolation)
>> spt = interpNA(spt, method = c("linear"))
> Error in interpNA(spt, method = c("linear")) : spt is not a tis object

It puzzles me why you have not investigated an error message that seems quite informative. When I looked at the code of timeSeries::interpNA I was puzzled that the package seems to use "timeSeries" as the class name. This error reports a different class name, but it does seem that the function is designed to take only a particular set of intputs and yours fails that test.


>> fut = interpNA(fut, method = c("linear"))
> Error in interpNA(fut, method = c("linear")) : fut is not a tis object
>> spt = ts(spt, start=c(2006,4), frequency=305)
>> fut = ts(fut, start=c(2006,4), frequency=305)
>> spt = interpNA(spt, method = c("linear"))

So the lack of an error here suggests that a ts-object might be acceptable to the same function that you were asking about.


-- 
David.

> 
> Would you please help me in this regard.
> 
> With sincere regards,
> Upananda
> 
> -- 
> 
> 
> You may delay, but time will not.
> 
> 
> Research Scholar
> alternative mail id: upani at iitkgp.ac.in
> Department of HSS, IIT KGP
> KGP
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Vidar.Hjellvik at fhi.no  Mon Nov  3 11:02:17 2014
From: Vidar.Hjellvik at fhi.no (Hjellvik, Vidar)
Date: Mon, 3 Nov 2014 10:02:17 +0000
Subject: [R] how to get likelihood function and negative hessian matrix
Message-ID: <50EB3A890DDBA44DB4D73C3BF9D2655EE10FE6CE@BAMAKO04.fhi.no>

I would like to implement in R a method that was proposed in a paper recently published in Am J Epidemiol: Adjustment for Missing Confounders in Studies Based on Observational Databases: 2-Stage Calibration Combining Propensity Scores From Primary and Validation Data. Am J Epidemiol. 2014;180(3):308-317. http://aje.oxfordjournals.org/content/180/3/308

My question is: Is it possible to obtain the U_i's in the lines below (from the web-appendix - somewhat modified) in R if the model G is a cox or poisson regression model?

Let gamma be a parameter estimate obtained from a model G based on data for subjects {i=1,...,N}. E.g. the effect of an exposure on an outcome.
Let  < \sum{i=1}^N Q_i > be the likelihood function and < I > the negative hessian (information) matrix of the likelihood for the model .
Let < U_i  > be the efficient score of gamma for the i'th subject, defined by the subset of components in the vector < I^{-1}Q_i > that corresponds to the parameter gamma.
Then < {U_i, i=1,...,N} > are variables with identical and independent distributions and < gamma = \sum_{i=1}^N U_i > asymptotically.

Best regards,
Vidar Hjellvik


	[[alternative HTML version deleted]]


From cjohndavies at gmail.com  Mon Nov  3 13:45:03 2014
From: cjohndavies at gmail.com (CJ Davies)
Date: Mon, 03 Nov 2014 12:45:03 +0000
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <4408509.xBT3BS7zPY@localhost.localdomain>
References: <54511FF3.5090606@gmail.com>	<8472588.RvbE93ndq3@localhost.localdomain>
	<4408509.xBT3BS7zPY@localhost.localdomain>
Message-ID: <545778CF.3090301@gmail.com>

On 30/10/14 21:33, Jim Lemon wrote:
> On Fri, 31 Oct 2014 07:19:01 AM Jim Lemon wrote:
>> On Wed, 29 Oct 2014 05:12:19 PM CJ Davies wrote:
>>> I am trying to show that the red line ('yaw') in the upper of the two
>>> plots here;
>>>
>>> http://i.imgur.com/N4Xxb4f.png
>>>
>>> varies more within the pink sections ('transition 1') than in the 
> light
>>> blue sections ('real').
>>>
>>> I tried to use var.test() however this runs into a problem because
>>> although the red line doesn't vary much *within* any particular 
> light
>>> blue section, it does vary a lot *between* light blue sections.
>>>
>>> For example, in the light blue section around t=90 the red line
>> doesn't
>>
>>> move much & likewise in the light blue section around t=160 the
>> red line
>>
>>> doesn't move much. But between these two sections the red line
>> has moved
>>
>>> substantially.
>>>
>>> So if I simply subset the data according to pink/light blue & then 
> put
>>> those resultant subsets into var.test(), the answer does not show
>> the
>>
>>> relationship that I want it to.
>>>
>>> Can anybody shed some light on a sensible method of solving 
> this?
>> Hi CJ,
>> If your dataset has the transition type coded for each observation:
>>
>> rotation	transition
>> 90		blue
>> 90		blue
>> 115		pink
>> -10		pink
>> 30		green
>> ...
>>
>> you could aggregate all the observations within each transition type
>> and test that.
>>
>> Jim
>>
> Oops,
> What I meant was aggregate all the _deviations_ within each transition 
> type.
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
If I understand, you mean to calculate deviations for each individual
'chunk' of each transition & then aggregate the results? This is what
I'd been thinking about, but is there a sensible manner within R to
achieve this, or is it something for which it would be easier to
preprocess the data in an external tool? Is there some way to subset the
data such that I can work over just contiguous 'chunks'?

Regards,
CJ Davies


From alessio.dantuono at mps.it  Mon Nov  3 13:07:30 2014
From: alessio.dantuono at mps.it (D'ANTUONO ALESSIO (MPS-8875))
Date: Mon, 3 Nov 2014 12:07:30 +0000
Subject: [R]  column names in write.table
Message-ID: <419364B1066F2B42A0696385737059213BBB990F@SE000010010364.servinternet.local>

Dear all,
about the problem shown by Foehl, I suggest one shortcut to reach the aim in a simply way:


write.table(matrix(c("Index","Rate","Demand","Supply"),nrow=1,ncol=4,byrow=T,dimnames=NULL),  "fs.csv",sep =";", row.names=F, col.names=F)
write.table(fs, file="fs.csv", append=T, sep=","  row.names=T, col.names=F)
As doing so, append will provide a solution by which avoid the problem of col.names.

Cheers, Alessio
________________________________
Non stampare questa e-mail.

Questo documento e' formato esclusivamente per il destinatario. Tutte le informazioni ivi contenute, compresi eventuali allegati, sono soggette a riservatezza a termini del vigente D.Lgs. 196/2003 in materia di privacy e quindi ne e' proibita l'utilizzazione. Se avete ricevuto per errore questo messaggio, Vi preghiamo cortesemente di contattare immediatamente il mittente e cancellare la e-mail. Grazie.

Please don't print this e-mail.

Confidentiality Notice - This e-mail message including a...{{dropped:9}}


From atesh.koul at gmail.com  Mon Nov  3 13:51:52 2014
From: atesh.koul at gmail.com (atesh koul)
Date: Mon, 3 Nov 2014 13:51:52 +0100
Subject: [R] mclust for time series
Message-ID: <CAHmbE3qE8v5A+pLQJZZW55E+y6LCQy=BiUfX7MQBys8G1q9ojw@mail.gmail.com>

Hi all,

I am new to using model based clustering. I am using the clustering to find
how many clusters could be there in the data and the assignment of trials
to these clusters.

The data are hand kinematics data- 12 variables at 10 discrete time points
for 17 subjects. I have previously seen use of mclust for time series.
However, I am not sure how it would be applied in terms of the formula. I
have seen couple of papers that use it from a theoretical point of view
(but not as a command in R). I would like to know if mclust can be used for
multivariate time series data.

I would really appreciate any help with this.

Thanks in anticipation,


Best,
Atesh

	[[alternative HTML version deleted]]


From maitra.mbox.ignored at inbox.com  Mon Nov  3 17:06:27 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Mon, 3 Nov 2014 10:06:27 -0600
Subject: [R] mclust for time series
In-Reply-To: <CAHmbE3qE8v5A+pLQJZZW55E+y6LCQy=BiUfX7MQBys8G1q9ojw@mail.gmail.com>
References: <CAHmbE3qE8v5A+pLQJZZW55E+y6LCQy=BiUfX7MQBys8G1q9ojw@mail.gmail.com>
Message-ID: <20141103100627.7284a12ad1d02d84b6d397db@inbox.com>

On Mon, 3 Nov 2014 13:51:52 +0100 atesh koul <atesh.koul at gmail.com> wrote:

> Hi all,
> 
> I am new to using model based clustering. I am using the clustering to find
> how many clusters could be there in the data and the assignment of trials
> to these clusters.
> 
> The data are hand kinematics data- 12 variables at 10 discrete time points
> for 17 subjects. I have previously seen use of mclust for time series.
> However, I am not sure how it would be applied in terms of the formula. I
> have seen couple of papers that use it from a theoretical point of view
> (but not as a command in R). I would like to know if mclust can be used for
> multivariate time series data.
> 
> I would really appreciate any help with this.

Atesh,

I am not sure how useful it will be to cluster 17 12-variate observations (subjects) using (presumably) Gaussian model-based clustering, but you may look at the following paper:

Chen, W.-C. and Maitra, R. (2011). Model-Based Clustering of Regression Time Series Data via APECM
? An AECM Algorithm Sung to An Even Faster Beat. Statistical Analysis and Data Mining, 4:567-78. DOI
information: 10.1002/sam.10143.

There is R code available (not R package), but again, it is not clear to me how useful this is going to be unless there is a structure in the 12 variables you are willing to give in (of course, unless I have misunderstood the context of your question). 

Best wishes,
Ranjan




> 
> Thanks in anticipation,
> 
> 
> Best,
> Atesh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From mboldi at bluewin.ch  Mon Nov  3 16:17:43 2014
From: mboldi at bluewin.ch (Boldi)
Date: Mon, 03 Nov 2014 16:17:43 +0100
Subject: [R] nlme Indometh SSbiexp
Message-ID: <54579C97.8080309@bluewin.ch>

Dear all,
Probably a very stupid question.
I am trying to reproduce the example of Pinheiro & Bates pp.278--287 on 
R 3.0.2 (Windows).

I'd like to run :

###
mod.nls <- nls(conc ~ SSbiexp(time, A1, lrc1, A2, lrc2), data=Indometh)
mod.lis <- nlsList(conc ~ SSbiexp(time, A1, lrc1, A2, lrc2), data=Indometh)

mod1 <- nlme(model=mod.lis, data=Indometh,
              random = pdDiag(A1 + lrc1 + A2 + lrc2 ~ 1))

>mod1
Nonlinear mixed-effects model fit by maximum likelihood
   Model: conc ~ SSbiexp(time, A1, lrc1, A2, lrc2)
   Data: Indometh
   Log-likelihood: 54.59671
   Fixed: list(A1 ~ 1, lrc1 ~ 1, A2 ~ 1, lrc2 ~ 1)
         A1       lrc1         A2       lrc2
  2.8275372  0.7736221  0.4614716 -1.3441022

Random effects:
  Formula: list(A1 ~ 1, lrc1 ~ 1, A2 ~ 1, lrc2 ~ 1)
  Level: Subject
  Structure: Diagonal
                A1      lrc1        A2       lrc2   Residual
StdDev: 0.5714106 0.1580778 0.1115978 7.3195e-06 0.08149341

Number of Observations: 66
Number of Groups: 6


###

which works well. But I'd like to directly specify the model with nlme, 
not going through "nls" or "nlsList" (please don't ask why...). Below 
the result. I don't get what I am missing?

###

>mod2 <- nlme(model=conc ~ SSbiexp(time, A1, lrc1, A2, lrc2), data=Indometh,
+fixed = A1+lrc1+A2+lrc2~1,
+random = pdDiag(A1 + lrc1 + A2 + lrc2 ~ 1))
Error in nlme.formula(model = conc ~ SSbiexp(time, A1, lrc1, A2, lrc2),  :
   subscript out of bounds

###




	[[alternative HTML version deleted]]


From Matthias.Weber at fntsoftware.com  Mon Nov  3 17:05:01 2014
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Mon, 3 Nov 2014 17:05:01 +0100
Subject: [R] split a field in dependence of the semicolon
Message-ID: <7E39CF5278A2C948968C39502CF451020174CEADF327@mail.ell.fnt.de>


Hello togehter,

i have a little problem, maybe anyone can help me.

I have a data.frame, which look like this one:
      ID         Members
1     1         ; abc; def; ghi
2     2         ; abc;
3     3         ;def;

How can I create another column for each value between 2 semicolons?

The result look like this one:

      ID         Members                Member1            Member2             Member3
1     1         ; abc; def; ghi         abc                     def                     ghi
2     2         ; abc;                     abc
3     3         ;def;                      def

Maybe anyone can help me. Thank you.

Best regards.

Mat


________________________________
This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Nov  3 19:47:23 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 3 Nov 2014 10:47:23 -0800
Subject: [R] split a field in dependence of the semicolon
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF327@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF327@mail.ell.fnt.de>
Message-ID: <CACk-te1F_48OU1tkHNhdowwY4+yx7oWDWCE57n3URauQ_n++JQ@mail.gmail.com>

See ?strsplit using the fixed =";" argument on the column containing
the character vector you wish to split.

The trickier part is that the result is a list that needs to be
manipulated -- ?do.call might be useful here, although I haven't
thought about it seriously -- to build your data frame containing
missings. There are various ways to do this, but  "An Introduction to
R" (ships with R) -- you have read it right? -- should provide the
info you need.

That should get you started. Others may provide a more complete
solution, but that's much less fun.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Nov 3, 2014 at 8:05 AM, Matthias Weber
<Matthias.Weber at fntsoftware.com> wrote:
>
> Hello togehter,
>
> i have a little problem, maybe anyone can help me.
>
> I have a data.frame, which look like this one:
>       ID         Members
> 1     1         ; abc; def; ghi
> 2     2         ; abc;
> 3     3         ;def;
>
> How can I create another column for each value between 2 semicolons?
>
> The result look like this one:
>
>       ID         Members                Member1            Member2             Member3
> 1     1         ; abc; def; ghi         abc                     def                     ghi
> 2     2         ; abc;                     abc
> 3     3         ;def;                      def
>
> Maybe anyone can help me. Thank you.
>
> Best regards.
>
> Mat
>
>
> ________________________________
> This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.
>
> Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Nov  4 00:02:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 3 Nov 2014 15:02:13 -0800
Subject: [R] split a field in dependence of the semicolon
In-Reply-To: <CACk-te1F_48OU1tkHNhdowwY4+yx7oWDWCE57n3URauQ_n++JQ@mail.gmail.com>
References: <7E39CF5278A2C948968C39502CF451020174CEADF327@mail.ell.fnt.de>
	<CACk-te1F_48OU1tkHNhdowwY4+yx7oWDWCE57n3URauQ_n++JQ@mail.gmail.com>
Message-ID: <4D8E99BB-5FC2-4CD1-8972-3E6FB899711C@comcast.net>


On Nov 3, 2014, at 10:47 AM, Bert Gunter wrote:

> See ?strsplit using the fixed =";" argument on the column containing
> the character vector you wish to split.
> 
> The trickier part is that the result is a list that needs to be
> manipulated -- ?do.call might be useful here, although I haven't
> thought about it seriously -- to build your data frame containing
> missings. There are various ways to do this, but  "An Introduction to
> R" (ships with R) -- you have read it right? -- should provide the
> info you need.
> 
> That should get you started. Others may provide a more complete
> solution, but that's much less fun.

Here's a start using the fill argument to read.table and the 'Members' column as text data:

cbind(dat,  
      read.table(text=as.character(dat$Members), sep=";", fill =TRUE)[-1] )

#----------------------
     ID            Members   V2   V3   V4
1     1    ; abc; def; ghi  abc  def  ghi
2     2             ; abc;  abc          
3     3              ;def;  def     


> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Mon, Nov 3, 2014 at 8:05 AM, Matthias Weber
> <Matthias.Weber at fntsoftware.com> wrote:
>> 
>> Hello togehter,
>> 
>> i have a little problem, maybe anyone can help me.
>> 
>> I have a data.frame, which look like this one:
>>      ID         Members
>> 1     1         ; abc; def; ghi
>> 2     2         ; abc;
>> 3     3         ;def;
>> 
>> How can I create another column for each value between 2 semicolons?
>> 
>> The result look like this one:
>> 
>>      ID         Members                Member1            Member2             Member3
>> 1     1         ; abc; def; ghi         abc                     def                     ghi
>> 2     2         ; abc;                     abc
>> 3     3         ;def;                      def
>> 
>> Maybe anyone can help me. Thank you.
>> 
>> Best regards.
>> 
>> Mat
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From steve.taylor at aut.ac.nz  Tue Nov  4 02:41:06 2014
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Tue, 4 Nov 2014 01:41:06 +0000
Subject: [R] Webdings font on pdf device
Message-ID: <CCE952776B6679469977532BD863C39C9A624FB3@Lewis.autuni.aut.ac.nz>

Dear R-helpers

Has anyone successfully used the Webdings font on a pdf or postscript device?  
I'm tearing my hair out trying to figure out how to make it work.

# It works on a png() device:
windowsFonts(Webdings = windowsFont("Webdings"))
png('Webdings.png', family = 'Webdings')
plot(-3:3,-3:3,type='n',xlab='',ylab='',axes=FALSE)
text (rnorm(26),rnorm(26),LETTERS,cex=2)
graphics.off()

I have tried to set up the Webdings font using the extrafont package but it gives warnings.  The output file says it has Webdings in it, but the characters do not show.

R> library(extrafont)
Registering fonts with R
R> loadfonts(device = "pdf", quiet=TRUE)
R> pdf('Webdings.pdf', family='Webdings')
Warning messages:
1: In pdf("Webdings.pdf", family = "Webdings") :
  unknown AFM entity encountered
2: In pdf("Webdings.pdf", family = "Webdings") :
  unknown AFM entity encountered
3: In pdf("Webdings.pdf", family = "Webdings") :
  unknown AFM entity encountered
4: In pdf("Webdings.pdf", family = "Webdings") :
  unknown AFM entity encountered
R> plot(-3:3,-3:3,type='n',xlab='',ylab='',axes=FALSE)
R> text (rnorm(26),rnorm(26),LETTERS,cex=2)
There were 27 warnings (use warnings() to see them)
R> graphics.off()
R> warnings()[1]
Warning message:
In text.default(rnorm(26), rnorm(26), LETTERS, cex = 2) :
  font width unknown for character 0x41  


Any assistance would be much appreciated.

cheers,
    Steve


From teotjunk at hotmail.com  Mon Nov  3 23:09:32 2014
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Tue, 4 Nov 2014 06:09:32 +0800
Subject: [R] Convert time format to character
Message-ID: <SNT148-W591F69BE5EF6958FF864BDF990@phx.gbl>

Suppose I have a object in time format

2014-08-13 00:30:00

I want to convert it to a character string 20140813003000

Is is possible ?

Tjun Kiat
 		 	   		  
	[[alternative HTML version deleted]]


From osman.al.radi at gmail.com  Mon Nov  3 23:54:45 2014
From: osman.al.radi at gmail.com (Osman Al-Radi)
Date: Tue, 4 Nov 2014 01:54:45 +0300
Subject: [R] Stacked squares plots
Message-ID: <F7C53E7F-2E70-4F58-994A-634570B9F6DB@gmail.com>

Dear R-help users,

I would like to produce a plot of ordered stacked coloured square where each square would represent a level of a categorical variable CAT (aprox. 150 levels), the size of the square would represent the frequency FREQ (count) of that level, the color would represent a proportion of failure FAILURE (0 to 1) and the squares would be organized by size from bottom left to top right. 

It would be an extra bonus if one could produce one such plot for each level of a higher order categorical variable GROUP with say 6 levels. All in one plot similar to panels in lattice but without the gaps between panels. 

Any ideas. I played around with mosaicplot and rectangle but without a satisfactory result. 

example data

GROUP    CAT    FREQ     FAILURE      
1                a          100          0.05
1                b            20          0.1

And so forth.

Thanks a million

Osman

Sent from my iPad

From Peter.Alspach at plantandfood.co.nz  Tue Nov  4 03:01:55 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Tue, 4 Nov 2014 15:01:55 +1300
Subject: [R] Convert time format to character
In-Reply-To: <SNT148-W591F69BE5EF6958FF864BDF990@phx.gbl>
References: <SNT148-W591F69BE5EF6958FF864BDF990@phx.gbl>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC247166D217@AKLEXM01.PFR.CO.NZ>

Tena koe

For example:

myTime <- Sys.time()
myTime
[1] "2014-11-04 14:58:10 NZDT"
format(myTime, '%Y%m%d:%H%M%S')
[1] "20141104:145810"

My information in ?strptime.

HTH ....

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of TJUN KIAT TEO
Sent: Tuesday, 4 November 2014 11:10 a.m.
To: r-help at r-project.org
Subject: [R] Convert time format to character

Suppose I have a object in time format

2014-08-13 00:30:00

I want to convert it to a character string 20140813003000

Is is possible ?

Tjun Kiat
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From jdnewmil at dcn.davis.CA.us  Tue Nov  4 03:38:05 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 03 Nov 2014 21:38:05 -0500
Subject: [R] Convert time format to character
In-Reply-To: <ED8CD182D432434485C7D1787FB06DDC247166D217@AKLEXM01.PFR.CO.NZ>
References: <SNT148-W591F69BE5EF6958FF864BDF990@phx.gbl>
	<ED8CD182D432434485C7D1787FB06DDC247166D217@AKLEXM01.PFR.CO.NZ>
Message-ID: <3F8DCA0E-FA1F-448B-A637-B93E4DFF6288@dcn.davis.CA.us>

I think the OP is being vague by saying "time format" (wouldn't a small reproducible example from the OP help right now)... if that is really another character string laid out as described then you might have difficulty with time zones for some values by converting to POSIXct first. If so, you can avoid the double conversion by using sub:

timestr <- "2014-08-13 00:30:00"
result <- sub("^(\\d{4})-(\\d{2})-(\\d{2}) (\\d{2}):(\\d{2}):(\\d{2})$", "\\1\\2\\3\\4\\5\\6", timestr )

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 3, 2014 9:01:55 PM EST, Peter Alspach <Peter.Alspach at plantandfood.co.nz> wrote:
>Tena koe
>
>For example:
>
>myTime <- Sys.time()
>myTime
>[1] "2014-11-04 14:58:10 NZDT"
>format(myTime, '%Y%m%d:%H%M%S')
>[1] "20141104:145810"
>
>My information in ?strptime.
>
>HTH ....
>
>Peter Alspach
>
>-----Original Message-----
>From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org] On Behalf Of TJUN KIAT TEO
>Sent: Tuesday, 4 November 2014 11:10 a.m.
>To: r-help at r-project.org
>Subject: [R] Convert time format to character
>
>Suppose I have a object in time format
>
>2014-08-13 00:30:00
>
>I want to convert it to a character string 20140813003000
>
>Is is possible ?
>
>Tjun Kiat
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>The contents of this e-mail are confidential and may be
>...{{dropped:14}}
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Tue Nov  4 10:05:11 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 04 Nov 2014 20:05:11 +1100
Subject: [R] Stacked squares plots
In-Reply-To: <F7C53E7F-2E70-4F58-994A-634570B9F6DB@gmail.com>
References: <F7C53E7F-2E70-4F58-994A-634570B9F6DB@gmail.com>
Message-ID: <1639192.tSuOMIIMfS@localhost.localdomain>

On Tue, 4 Nov 2014 01:54:45 AM Osman Al-Radi wrote:
> Dear R-help users,
> 
> I would like to produce a plot of ordered stacked coloured square 
where each
> square would represent a level of a categorical variable CAT (aprox. 
150
> levels), the size of the square would represent the frequency FREQ 
(count)
> of that level, the color would represent a proportion of failure 
FAILURE (0
> to 1) and the squares would be organized by size from bottom left 
to top
> right.
> 
> It would be an extra bonus if one could produce one such plot for 
each level
> of a higher order categorical variable GROUP with say 6 levels. All in 
one
> plot similar to panels in lattice but without the gaps between panels.
> 
> Any ideas. I played around with mosaicplot and rectangle but 
without a
> satisfactory result.
> 
> example data
> 
> GROUP    CAT    FREQ     FAILURE
> 1                a          100          0.05
> 1                b            20          0.1
> 
> And so forth.
> 
Hi Osman,
The function color2D.matplot (plotrix) has a Hinton diagram option 
that might do what you want. The squares will be distributed on a plot 
in the same positions as the matrix that is passed as the "x" 
argument. The sizes of the squares will be proportional to "x" and the 
colors can be anything you pass as "cellcolors". Let me know if you 
have trouble working it out.

Jim


From jim at bitwrit.com.au  Tue Nov  4 10:11:22 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 04 Nov 2014 20:11:22 +1100
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <545778CF.3090301@gmail.com>
References: <54511FF3.5090606@gmail.com>
	<4408509.xBT3BS7zPY@localhost.localdomain>
	<545778CF.3090301@gmail.com>
Message-ID: <2336490.6CSPGQ4BGf@localhost.localdomain>

On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
> ...
> On 30/10/14 21:33, Jim Lemon wrote:
> If I understand, you mean to calculate deviations for each individual
> 'chunk' of each transition & then aggregate the results? This is what
> I'd been thinking about, but is there a sensible manner within R to
> achieve this, or is it something for which it would be easier to
> preprocess the data in an external tool? Is there some way to subset 
the
> data such that I can work over just contiguous 'chunks'?
> 
Exactly. If there is some combination of existing variables that can be 
combined to make a set of unique values for each "chunk", you can 
calculate the deviations within each "chunk", then average the squared 
deviations for each type of "chunk", weighting by the duration of the 
"chunks" so that you don't bias the pooled variance toward the longer 
"chunks".

Jim


From ntfredo at gmail.com  Tue Nov  4 11:01:29 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 4 Nov 2014 13:01:29 +0300
Subject: [R] Function that create day of the year column.
Message-ID: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>

Dear All,

I would like to make a function that create Day of the year column in a
dataset.
State of the problem: write a function that create a day column either from
a single date column (string/or factors) or from date in 3 columns (year,
month, day).

I made the following function for a single date. I would like to add a
condition for date in 3 columns (year, month, day). My data is daily
climate data.
#write a function that create a day column either from a single date column
(string/or factors)
#or from date in 3 columns (year, month, day).

DOY=function(data){

#=================================================================
#This function create day of teh year from a single date
column(ex:2009-08-02) or/and
#from the date in 3 columns (Year, month, Day).
#================================================================
  data$Rain=as.numeric(as.character(data$Rain))
  dt=yday(data$Date) # single date of the data
  datelp= dt>59 & !leap_year(data$Date)# tell us that the date occurs
during a leap year
  dt[datelp]=dt[datelp]+1 # add one for non leap_year
  cbind(data, dt) # combining columns of data
  conames(data)="DOY" # name of new column. ??I have a problem on how I can
precise the column in gerenal.
}

ex: year  month day   Date         Rain Tmin Tmax
      1971   1         1    1971-01-01   0     8.2  15
       1971  1         2    1971-01-02   0     4.2  11
        .        .          .       .               .      .      .
        .        .          .       .               .      .      .
        .        .          .       .               .      .      .

Any ideal on how I can make this function is welcome. thanks!
Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Tue Nov  4 12:40:27 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 4 Nov 2014 14:40:27 +0300
Subject: [R] Function that create day of the year column.
Message-ID: <CAGh51gSVXq6t8JDtag158idqO=3h4RX2A-uD_CoJr+svWbzX9A@mail.gmail.com>

Dear All,

I would like to make a function that create Day of the year column in a
dataset.
State of the problem: write a function that create a day column either from
a single date column (string/or factors) or from date in 3 columns (year,
month, day).

I made the following function for a single date. I would like to add a
condition for date in 3 columns (year, month, day). My data is daily
climate data.

DOY=function(data){

#=================================================================
#This function create day of teh year from a single date
column(ex:2009-08-02) or/and
#from the date in 3 columns (Year, month, Day).
#================================================================
  data$Rain=as.numeric(as.character(data$Rain))
  dt=yday(data$Date) # single date of the data
  datelp= dt>59 & !leap_year(data$Date)# tell us that the date occurs
during a leap year
  dt[datelp]=dt[datelp]+1 # add one for non leap_year
  cbind(data, dt) # combining columns of data
  conames(data)="DOY" # name of new column. ??I have a problem on how I can
precise the column in gerenal.
}

ex: year  month day   Date          Rain Tmin Tmax
      1971  1         1    1971-01-01  0        8     18
      1971   1         2   1971-01-02   1.2     3     8.2
        .       .          .         .               .       .      .
        .       .          .         .               .       .      .
        .       .          .         .               .       .      .


Any idea of how I can make this function is welcome. Thanks

Regards,
frederic.


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From daniel319 at gmail.com  Tue Nov  4 13:20:36 2014
From: daniel319 at gmail.com (daniel)
Date: Tue, 4 Nov 2014 09:20:36 -0300
Subject: [R] Function that create day of the year column.
In-Reply-To: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
References: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
Message-ID: <CAPfrkhmNFA=Huy6uFD2uJC6Mf4J6-_+X3v2aHP0gnU5G2qhpGw@mail.gmail.com>

Frederic,

Check the lubridate library.

install.packages("lubridate")
library(lubridate)
yday(Sys.Date())
d <- 4
m <- 11
y <- 2014
yday(as.Date(paste(y,m,d,sep="-")))

Daniel Merino

2014-11-04 7:01 GMT-03:00 Frederic Ntirenganya <ntfredo at gmail.com>:

> Dear All,
>
> I would like to make a function that create Day of the year column in a
> dataset.
> State of the problem: write a function that create a day column either from
> a single date column (string/or factors) or from date in 3 columns (year,
> month, day).
>
> I made the following function for a single date. I would like to add a
> condition for date in 3 columns (year, month, day). My data is daily
> climate data.
> #write a function that create a day column either from a single date column
> (string/or factors)
> #or from date in 3 columns (year, month, day).
>
> DOY=function(data){
>
> #=================================================================
> #This function create day of teh year from a single date
> column(ex:2009-08-02) or/and
> #from the date in 3 columns (Year, month, Day).
> #================================================================
>   data$Rain=as.numeric(as.character(data$Rain))
>   dt=yday(data$Date) # single date of the data
>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date occurs
> during a leap year
>   dt[datelp]=dt[datelp]+1 # add one for non leap_year
>   cbind(data, dt) # combining columns of data
>   conames(data)="DOY" # name of new column. ??I have a problem on how I can
> precise the column in gerenal.
> }
>
> ex: year  month day   Date         Rain Tmin Tmax
>       1971   1         1    1971-01-01   0     8.2  15
>        1971  1         2    1971-01-02   0     4.2  11
>         .        .          .       .               .      .      .
>         .        .          .       .               .      .      .
>         .        .          .       .               .      .      .
>
> Any ideal on how I can make this function is welcome. thanks!
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Daniel

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Tue Nov  4 13:30:40 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 4 Nov 2014 15:30:40 +0300
Subject: [R] Function that create day of the year column.
In-Reply-To: <CAPfrkhmNFA=Huy6uFD2uJC6Mf4J6-_+X3v2aHP0gnU5G2qhpGw@mail.gmail.com>
References: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
	<CAPfrkhmNFA=Huy6uFD2uJC6Mf4J6-_+X3v2aHP0gnU5G2qhpGw@mail.gmail.com>
Message-ID: <CAGh51gRw-_iZfEhAFKi7XvLL=dL8umAuPS4HKQ+qACj0voiytg@mail.gmail.com>

Hi Daniel,

How can I add an if conditiopn or for loop to implement this in my
function?

ex: option1 : single date
     option2: date in 3 columns (year,moth,day)

yday(Sys.Date())
yday(as.Date(paste(y,m,d,sep="-")))

Regards,
Frederic.


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Nov 4, 2014 at 3:20 PM, daniel <daniel319 at gmail.com> wrote:

> Frederic,
>
> Check the lubridate library.
>
> install.packages("lubridate")
> library(lubridate)
> yday(Sys.Date())
> d <- 4
> m <- 11
> y <- 2014
> yday(as.Date(paste(y,m,d,sep="-")))
>
> Daniel Merino
>
> 2014-11-04 7:01 GMT-03:00 Frederic Ntirenganya <ntfredo at gmail.com>:
>
>> Dear All,
>>
>> I would like to make a function that create Day of the year column in a
>> dataset.
>> State of the problem: write a function that create a day column either
>> from
>> a single date column (string/or factors) or from date in 3 columns (year,
>> month, day).
>>
>> I made the following function for a single date. I would like to add a
>> condition for date in 3 columns (year, month, day). My data is daily
>> climate data.
>> #write a function that create a day column either from a single date
>> column
>> (string/or factors)
>> #or from date in 3 columns (year, month, day).
>>
>> DOY=function(data){
>>
>> #=================================================================
>> #This function create day of teh year from a single date
>> column(ex:2009-08-02) or/and
>> #from the date in 3 columns (Year, month, Day).
>> #================================================================
>>   data$Rain=as.numeric(as.character(data$Rain))
>>   dt=yday(data$Date) # single date of the data
>>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date occurs
>> during a leap year
>>   dt[datelp]=dt[datelp]+1 # add one for non leap_year
>>   cbind(data, dt) # combining columns of data
>>   conames(data)="DOY" # name of new column. ??I have a problem on how I
>> can
>> precise the column in gerenal.
>> }
>>
>> ex: year  month day   Date         Rain Tmin Tmax
>>       1971   1         1    1971-01-01   0     8.2  15
>>        1971  1         2    1971-01-02   0     4.2  11
>>         .        .          .       .               .      .      .
>>         .        .          .       .               .      .      .
>>         .        .          .       .               .      .      .
>>
>> Any ideal on how I can make this function is welcome. thanks!
>> Frederic Ntirenganya
>> Maseno University,
>> African Maths Initiative,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Daniel
>

	[[alternative HTML version deleted]]


From daniel319 at gmail.com  Tue Nov  4 14:29:33 2014
From: daniel319 at gmail.com (daniel)
Date: Tue, 4 Nov 2014 10:29:33 -0300
Subject: [R] Function that create day of the year column.
In-Reply-To: <CAGh51gRw-_iZfEhAFKi7XvLL=dL8umAuPS4HKQ+qACj0voiytg@mail.gmail.com>
References: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
	<CAPfrkhmNFA=Huy6uFD2uJC6Mf4J6-_+X3v2aHP0gnU5G2qhpGw@mail.gmail.com>
	<CAGh51gRw-_iZfEhAFKi7XvLL=dL8umAuPS4HKQ+qACj0voiytg@mail.gmail.com>
Message-ID: <CAPfrkhnQARgCsg6S=2+Sjn_tXNaswnZ4o2N0PMk6dGYtFu0pkg@mail.gmail.com>

Maybe, you can add a parameter with a list of the column names and inside
the function an if statement, if the list lenght is 1 use the function with
1 column else the 3 columns.  I am sure you can find better solutions.

Daniel Merino

2014-11-04 9:30 GMT-03:00 Frederic Ntirenganya <ntfredo at gmail.com>:

> Hi Daniel,
>
> How can I add an if conditiopn or for loop to implement this in my
> function?
>
> ex: option1 : single date
>      option2: date in 3 columns (year,moth,day)
>
> yday(Sys.Date())
> yday(as.Date(paste(y,m,d,sep="-")))
>
> Regards,
> Frederic.
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Nov 4, 2014 at 3:20 PM, daniel <daniel319 at gmail.com> wrote:
>
>> Frederic,
>>
>> Check the lubridate library.
>>
>> install.packages("lubridate")
>> library(lubridate)
>> yday(Sys.Date())
>> d <- 4
>> m <- 11
>> y <- 2014
>> yday(as.Date(paste(y,m,d,sep="-")))
>>
>> Daniel Merino
>>
>> 2014-11-04 7:01 GMT-03:00 Frederic Ntirenganya <ntfredo at gmail.com>:
>>
>>> Dear All,
>>>
>>> I would like to make a function that create Day of the year column in a
>>> dataset.
>>> State of the problem: write a function that create a day column either
>>> from
>>> a single date column (string/or factors) or from date in 3 columns (year,
>>> month, day).
>>>
>>> I made the following function for a single date. I would like to add a
>>> condition for date in 3 columns (year, month, day). My data is daily
>>> climate data.
>>> #write a function that create a day column either from a single date
>>> column
>>> (string/or factors)
>>> #or from date in 3 columns (year, month, day).
>>>
>>> DOY=function(data){
>>>
>>> #=================================================================
>>> #This function create day of teh year from a single date
>>> column(ex:2009-08-02) or/and
>>> #from the date in 3 columns (Year, month, Day).
>>> #================================================================
>>>   data$Rain=as.numeric(as.character(data$Rain))
>>>   dt=yday(data$Date) # single date of the data
>>>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date occurs
>>> during a leap year
>>>   dt[datelp]=dt[datelp]+1 # add one for non leap_year
>>>   cbind(data, dt) # combining columns of data
>>>   conames(data)="DOY" # name of new column. ??I have a problem on how I
>>> can
>>> precise the column in gerenal.
>>> }
>>>
>>> ex: year  month day   Date         Rain Tmin Tmax
>>>       1971   1         1    1971-01-01   0     8.2  15
>>>        1971  1         2    1971-01-02   0     4.2  11
>>>         .        .          .       .               .      .      .
>>>         .        .          .       .               .      .      .
>>>         .        .          .       .               .      .      .
>>>
>>> Any ideal on how I can make this function is welcome. thanks!
>>> Frederic Ntirenganya
>>> Maseno University,
>>> African Maths Initiative,
>>> Kenya.
>>> Mobile:(+254)718492836
>>> Email: fredo at aims.ac.za
>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> Daniel
>>
>
>


-- 
Daniel

	[[alternative HTML version deleted]]


From cjohndavies at gmail.com  Tue Nov  4 14:50:25 2014
From: cjohndavies at gmail.com (CJ Davies)
Date: Tue, 04 Nov 2014 13:50:25 +0000
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <2336490.6CSPGQ4BGf@localhost.localdomain>
References: <54511FF3.5090606@gmail.com>
	<4408509.xBT3BS7zPY@localhost.localdomain>
	<545778CF.3090301@gmail.com>
	<2336490.6CSPGQ4BGf@localhost.localdomain>
Message-ID: <5458D9A1.9020401@gmail.com>

On 04/11/14 09:11, Jim Lemon wrote:
> On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
>> ...
>> On 30/10/14 21:33, Jim Lemon wrote:
>> If I understand, you mean to calculate deviations for each individual
>> 'chunk' of each transition & then aggregate the results? This is what
>> I'd been thinking about, but is there a sensible manner within R to
>> achieve this, or is it something for which it would be easier to
>> preprocess the data in an external tool? Is there some way to subset
> the
>> data such that I can work over just contiguous 'chunks'?
>>
> Exactly. If there is some combination of existing variables that can be
> combined to make a set of unique values for each "chunk", you can
> calculate the deviations within each "chunk", then average the squared
> deviations for each type of "chunk", weighting by the duration of the
> "chunks" so that you don't bias the pooled variance toward the longer
> "chunks".
>
> Jim
>

I am stumped for a way of automating this process though. Each line of 
log data looks like this;

2406	55.4	(-11.2, 1.0, -0.9)	(-4.1, 1.0, 0.0)	7.077912	0.9203392	(0.0, 
0.7, -0.1, 0.7)	8.129684	89.41537	-8.212769	(0.0, 0.7, -0.1, 0.7) 
8.129684	89.41537	351.7872	1	0	0	False	0.15	3	37.76761	True	False	0 
transition 1

Where the last variable defines which transition is currently active. 
However to separate these data into 'chunks' would involve making a 
comparison between each line of data & the preceding line of data to 
determine whether it is part of the same contiguous 'chunk'. Is this 
something that would be better achieved using external preprocessing 
written in a language I am more familiar with, as I haven't the foggiest 
how I would approach this within R?

Regards,
CJ Davies


From ntfredo at gmail.com  Tue Nov  4 15:45:20 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 4 Nov 2014 17:45:20 +0300
Subject: [R] Function that creates a Date column
Message-ID: <CAGh51gRbvYs_eSARprcw_thPxOiq+SR2kEH+rEw315iUPi7YOQ@mail.gmail.com>

Dear All,

I would like to Write a function that creates a Date column stored as a
factor given a date column stored as string in a dataframe.  Any idea is
more helpful.

Regards,
Frederic.


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Nov  4 16:55:22 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 4 Nov 2014 15:55:22 +0000
Subject: [R] Function that create day of the year column.
In-Reply-To: <CAGh51gRw-_iZfEhAFKi7XvLL=dL8umAuPS4HKQ+qACj0voiytg@mail.gmail.com>
References: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
	<CAPfrkhmNFA=Huy6uFD2uJC6Mf4J6-_+X3v2aHP0gnU5G2qhpGw@mail.gmail.com>
	<CAGh51gRw-_iZfEhAFKi7XvLL=dL8umAuPS4HKQ+qACj0voiytg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED894@SRVEXCHMBX.precheza.cz>

Hi

You want a function with input of either single value or a data frame? This is very strange. One option is to make a method for function but it is quite beyond my capabilities and it is used by "professional" developers.

methods(c) or methods(plot)

So you need to set method for your function DOY something like

DOY.single_value and DOY.data.frame

Anyway

Function yday takes some value in time/date format regardless it is single value or a vector, so the problem is how do you want your function to work and more importantly how general you want it. I simple case you need to check if data is single value or data frame.

DOY=function(data){

if (is.data.frame(data)) {

do stuff for data frame} else {

do stuff for single value}

return something

}

Other comments see in line

>>   data$Rain=as.numeric(as.character(data$Rain))
> >>   dt=yday(data$Date) # single date of the data

If data is data frame dt shall be vector uf numbers not a single date

> >>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date

datelp is (maybe) a logical vector with the same length as dt

> occurs
> >> during a leap year
> >>   dt[datelp]=dt[datelp]+1 # add one for non leap_year

Why you do this?
dt<-1:365 # e.g. length is 365
datelp<-dt>59 # logical vector


dt[datelp]<-dt[datelp]+1 # change all numbers greater than 59
dt
  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18
 [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36
 [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54
 [55]  55  56  57  58  59  61  62  63  64  65  66  67  68  69  70  71  72  73
                       ^^^^^^
now you have day 60 missing

 [73]  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91
 [91]  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109
[109] 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
[127] 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
[145] 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
[163] 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
[181] 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199
[199] 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
[217] 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
[235] 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
[253] 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
[271] 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
[289] 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
[307] 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
[325] 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
[343] 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
[361] 362 363 364 365 366

But length of dt stays the same
 length(dt)
[1] 365

Cheers
Petr

> >>   cbind(data, dt) # combining columns of data
> >>   conames(data)="DOY" # name of new column. ??I have a problem on
> how
> >> I can precise the column in gerenal.
> >> }
> >>
> >>


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Frederic Ntirenganya
> Sent: Tuesday, November 04, 2014 1:31 PM
> To: daniel
> Cc: r-help at r-project.org
> Subject: Re: [R] Function that create day of the year column.
>
> Hi Daniel,
>
> How can I add an if conditiopn or for loop to implement this in my
> function?
>
> ex: option1 : single date
>      option2: date in 3 columns (year,moth,day)
>
> yday(Sys.Date())
> yday(as.Date(paste(y,m,d,sep="-")))
>
> Regards,
> Frederic.
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Nov 4, 2014 at 3:20 PM, daniel <daniel319 at gmail.com> wrote:
>
> > Frederic,
> >
> > Check the lubridate library.
> >
> > install.packages("lubridate")
> > library(lubridate)
> > yday(Sys.Date())
> > d <- 4
> > m <- 11
> > y <- 2014
> > yday(as.Date(paste(y,m,d,sep="-")))
> >
> > Daniel Merino
> >
> > 2014-11-04 7:01 GMT-03:00 Frederic Ntirenganya <ntfredo at gmail.com>:
> >
> >> Dear All,
> >>
> >> I would like to make a function that create Day of the year column
> in
> >> a dataset.
> >> State of the problem: write a function that create a day column
> >> either from a single date column (string/or factors) or from date in
> >> 3 columns (year, month, day).
> >>
> >> I made the following function for a single date. I would like to add
> >> a condition for date in 3 columns (year, month, day). My data is
> >> daily climate data.
> >> #write a function that create a day column either from a single date
> >> column (string/or factors) #or from date in 3 columns (year, month,
> >> day).
> >>
> >> DOY=function(data){
> >>
> >> #=================================================================
> >> #This function create day of teh year from a single date
> >> column(ex:2009-08-02) or/and
> >> #from the date in 3 columns (Year, month, Day).
> >> #================================================================
> >>   data$Rain=as.numeric(as.character(data$Rain))
> >>   dt=yday(data$Date) # single date of the data
> >>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date
> occurs
> >> during a leap year
> >>   dt[datelp]=dt[datelp]+1 # add one for non leap_year
> >>   cbind(data, dt) # combining columns of data
> >>   conames(data)="DOY" # name of new column. ??I have a problem on
> how
> >> I can precise the column in gerenal.
> >> }
> >>
> >> ex: year  month day   Date         Rain Tmin Tmax
> >>       1971   1         1    1971-01-01   0     8.2  15
> >>        1971  1         2    1971-01-02   0     4.2  11
> >>         .        .          .       .               .      .      .
> >>         .        .          .       .               .      .      .
> >>         .        .          .       .               .      .      .
> >>
> >> Any ideal on how I can make this function is welcome. thanks!
> >> Frederic Ntirenganya
> >> Maseno University,
> >> African Maths Initiative,
> >> Kenya.
> >> Mobile:(+254)718492836
> >> Email: fredo at aims.ac.za
> >> https://sites.google.com/a/aims.ac.za/fredo/
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > Daniel
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Tue Nov  4 16:59:59 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 4 Nov 2014 15:59:59 +0000
Subject: [R] Function that creates a Date column
In-Reply-To: <CAGh51gRbvYs_eSARprcw_thPxOiq+SR2kEH+rEw315iUPi7YOQ@mail.gmail.com>
References: <CAGh51gRbvYs_eSARprcw_thPxOiq+SR2kEH+rEw315iUPi7YOQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8A3@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Frederic Ntirenganya
> Sent: Tuesday, November 04, 2014 3:45 PM
> To: r-help at r-project.org
> Subject: [R] Function that creates a Date column
>
> Dear All,
>
> I would like to Write a function that creates a Date column stored as a
> factor given a date column stored as string in a dataframe.  Any idea
> is more helpful.

Why? For almost any purpose is factor and character column same. Factors are useful for manipulating their levels and in models.

Anyway

Date <- as.factor(string)

Cheers
Petr

>
> Regards,
> Frederic.
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Tue Nov  4 17:13:00 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 4 Nov 2014 16:13:00 +0000
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <5458D9A1.9020401@gmail.com>
References: <54511FF3.5090606@gmail.com>
	<4408509.xBT3BS7zPY@localhost.localdomain>	<545778CF.3090301@gmail.com>
	<2336490.6CSPGQ4BGf@localhost.localdomain> <5458D9A1.9020401@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8BC@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of CJ Davies
> Sent: Tuesday, November 04, 2014 2:50 PM
> To: Jim Lemon; r-help at r-project.org
> Subject: Re: [R] Variance of multiple non-contiguous time periods?
>
> On 04/11/14 09:11, Jim Lemon wrote:
> > On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
> >> ...
> >> On 30/10/14 21:33, Jim Lemon wrote:
> >> If I understand, you mean to calculate deviations for each
> individual
> >> 'chunk' of each transition & then aggregate the results? This is
> what
> >> I'd been thinking about, but is there a sensible manner within R to
> >> achieve this, or is it something for which it would be easier to
> >> preprocess the data in an external tool? Is there some way to subset
> > the
> >> data such that I can work over just contiguous 'chunks'?
> >>
> > Exactly. If there is some combination of existing variables that can
> > be combined to make a set of unique values for each "chunk", you can
> > calculate the deviations within each "chunk", then average the
> squared
> > deviations for each type of "chunk", weighting by the duration of the
> > "chunks" so that you don't bias the pooled variance toward the longer
> > "chunks".
> >
> > Jim
> >
>
> I am stumped for a way of automating this process though. Each line of
> log data looks like this;
>
> 2406  55.4    (-11.2, 1.0, -0.9)      (-4.1, 1.0, 0.0)        7.077912
>       0.9203392       (0.0,
> 0.7, -0.1, 0.7)       8.129684        89.41537        -8.212769       (0.0, 0.7, -0.1,
> 0.7)
> 8.129684      89.41537        351.7872        1       0       0       False   0.15    3
>       37.76761        True    False   0
> transition 1

First you need to import it to R which could be tricky based on above line.
Some values will probably need to process through regular expression.

If I understand correctly number after transition is a signal which estimets continuous chunks. If it is true then

?rle is a function which can estimate length of chunks.

Cheers
Petr

>
> Where the last variable defines which transition is currently active.
> However to separate these data into 'chunks' would involve making a
> comparison between each line of data & the preceding line of data to
> determine whether it is part of the same contiguous 'chunk'. Is this
> something that would be better achieved using external preprocessing
> written in a language I am more familiar with, as I haven't the
> foggiest how I would approach this within R?
>
> Regards,
> CJ Davies
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From cjohndavies at gmail.com  Tue Nov  4 17:35:56 2014
From: cjohndavies at gmail.com (CJ Davies)
Date: Tue, 04 Nov 2014 16:35:56 +0000
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8BC@SRVEXCHMBX.precheza.cz>
References: <54511FF3.5090606@gmail.com>	<4408509.xBT3BS7zPY@localhost.localdomain>	<545778CF.3090301@gmail.com>	<2336490.6CSPGQ4BGf@localhost.localdomain>
	<5458D9A1.9020401@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8BC@SRVEXCHMBX.precheza.cz>
Message-ID: <5459006C.8040903@gmail.com>

On 04/11/14 16:13, PIKAL Petr wrote:
> Hi
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of CJ Davies
>> Sent: Tuesday, November 04, 2014 2:50 PM
>> To: Jim Lemon; r-help at r-project.org
>> Subject: Re: [R] Variance of multiple non-contiguous time periods?
>>
>> On 04/11/14 09:11, Jim Lemon wrote:
>>> On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
>>>> ...
>>>> On 30/10/14 21:33, Jim Lemon wrote:
>>>> If I understand, you mean to calculate deviations for each
>> individual
>>>> 'chunk' of each transition & then aggregate the results? This is
>> what
>>>> I'd been thinking about, but is there a sensible manner within R to
>>>> achieve this, or is it something for which it would be easier to
>>>> preprocess the data in an external tool? Is there some way to subset
>>> the
>>>> data such that I can work over just contiguous 'chunks'?
>>>>
>>> Exactly. If there is some combination of existing variables that can
>>> be combined to make a set of unique values for each "chunk", you can
>>> calculate the deviations within each "chunk", then average the
>> squared
>>> deviations for each type of "chunk", weighting by the duration of the
>>> "chunks" so that you don't bias the pooled variance toward the longer
>>> "chunks".
>>>
>>> Jim
>>>
>>
>> I am stumped for a way of automating this process though. Each line of
>> log data looks like this;
>>
>> 2406  55.4    (-11.2, 1.0, -0.9)      (-4.1, 1.0, 0.0)        7.077912
>>        0.9203392       (0.0,
>> 0.7, -0.1, 0.7)       8.129684        89.41537        -8.212769       (0.0, 0.7, -0.1,
>> 0.7)
>> 8.129684      89.41537        351.7872        1       0       0       False   0.15    3
>>        37.76761        True    False   0
>> transition 1
>
> First you need to import it to R which could be tricky based on above line.
> Some values will probably need to process through regular expression.
>
> If I understand correctly number after transition is a signal which estimets continuous chunks. If it is true then
>
> ?rle is a function which can estimate length of chunks.
>
> Cheers
> Petr
>
>>
>> Where the last variable defines which transition is currently active.
>> However to separate these data into 'chunks' would involve making a
>> comparison between each line of data & the preceding line of data to
>> determine whether it is part of the same contiguous 'chunk'. Is this
>> something that would be better achieved using external preprocessing
>> written in a language I am more familiar with, as I haven't the
>> foggiest how I would approach this within R?
>>
>> Regards,
>> CJ Davies
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>

Importing into R wasn't an issue; some of the fields contain spaces & 
symbols, but all the fields are tab separated so I can simply use;

foo <- read.csv("bar",header=T,sep="\t")

I've just written a hacky bit of Java that gives me the lines of each 
'chunk' as a separate list & I think I'll then calculate these 
particular values using Java's Math class rather than trying to come up 
with a sensible way to import these 'chunks' back into R. When it comes 
to string/list manipulation like this I think my knowledge in Java & 
lack of knowledge in R makes the former the better option!

Regards,
CJ Davies


From dwinsemius at comcast.net  Tue Nov  4 18:02:53 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Nov 2014 09:02:53 -0800
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <5459006C.8040903@gmail.com>
References: <54511FF3.5090606@gmail.com>	<4408509.xBT3BS7zPY@localhost.localdomain>	<545778CF.3090301@gmail.com>	<2336490.6CSPGQ4BGf@localhost.localdomain>
	<5458D9A1.9020401@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8BC@SRVEXCHMBX.precheza.cz>
	<5459006C.8040903@gmail.com>
Message-ID: <0164DC64-D1E5-4128-B51D-8C6AE9D5500A@comcast.net>


On Nov 4, 2014, at 8:35 AM, CJ Davies wrote:

> On 04/11/14 16:13, PIKAL Petr wrote:
>> Hi
>> 
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>> project.org] On Behalf Of CJ Davies
>>> Sent: Tuesday, November 04, 2014 2:50 PM
>>> To: Jim Lemon; r-help at r-project.org
>>> Subject: Re: [R] Variance of multiple non-contiguous time periods?
>>> 
>>> On 04/11/14 09:11, Jim Lemon wrote:
>>>> On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
>>>>> ...
>>>>> On 30/10/14 21:33, Jim Lemon wrote:
>>>>> If I understand, you mean to calculate deviations for each
>>> individual
>>>>> 'chunk' of each transition & then aggregate the results? This is
>>> what
>>>>> I'd been thinking about, but is there a sensible manner within R to
>>>>> achieve this, or is it something for which it would be easier to
>>>>> preprocess the data in an external tool? Is there some way to subset
>>>> the
>>>>> data such that I can work over just contiguous 'chunks'?
>>>>> 
>>>> Exactly. If there is some combination of existing variables that can
>>>> be combined to make a set of unique values for each "chunk", you can
>>>> calculate the deviations within each "chunk", then average the
>>> squared
>>>> deviations for each type of "chunk", weighting by the duration of the
>>>> "chunks" so that you don't bias the pooled variance toward the longer
>>>> "chunks".
>>>> 
>>>> Jim
>>>> 
>>> 
>>> I am stumped for a way of automating this process though. Each line of
>>> log data looks like this;
>>> 
>>> 2406  55.4    (-11.2, 1.0, -0.9)      (-4.1, 1.0, 0.0)        7.077912
>>>       0.9203392       (0.0,
>>> 0.7, -0.1, 0.7)       8.129684        89.41537        -8.212769       (0.0, 0.7, -0.1,
>>> 0.7)
>>> 8.129684      89.41537        351.7872        1       0       0       False   0.15    3
>>>       37.76761        True    False   0
>>> transition 1
>> 
>> First you need to import it to R which could be tricky based on above line.
>> Some values will probably need to process through regular expression.
>> 
>> If I understand correctly number after transition is a signal which estimets continuous chunks. If it is true then
>> 
>> ?rle is a function which can estimate length of chunks.
>> 
>> Cheers
>> Petr
>> 
>>> 
>>> Where the last variable defines which transition is currently active.
>>> However to separate these data into 'chunks' would involve making a
>>> comparison between each line of data & the preceding line of data to
>>> determine whether it is part of the same contiguous 'chunk'. Is this
>>> something that would be better achieved using external preprocessing
>>> written in a language I am more familiar with, as I haven't the
>>> foggiest how I would approach this within R?
>>> 
>>> Regards,
>>> CJ Davies
>>> 
>>> ______________________________________________
>> 
snipped
>> 
> 
> Importing into R wasn't an issue; some of the fields contain spaces & symbols, but all the fields are tab separated so I can simply use;
> 
> foo <- read.csv("bar",header=T,sep="\t")
> 
> I've just written a hacky bit of Java that gives me the lines of each 'chunk' as a separate list & I think I'll then calculate these particular values using Java's Math class rather than trying to come up with a sensible way to import these 'chunks' back into R. When it comes to string/list manipulation like this I think my knowledge in Java & lack of knowledge in R makes the former the better option!
> 

If you had offered the output of dput(head(foo, 20) ) and explained what defined a "chunk-defining transition", it would have been fairly easy to show you how to use cumsum in an ave() call to construct a grouping variable.

 
> Regards,
> CJ Davies
> 
> ______________________________


David Winsemius
Alameda, CA, USA


From cjohndavies at gmail.com  Tue Nov  4 18:16:45 2014
From: cjohndavies at gmail.com (CJ Davies)
Date: Tue, 04 Nov 2014 17:16:45 +0000
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <0164DC64-D1E5-4128-B51D-8C6AE9D5500A@comcast.net>
References: <54511FF3.5090606@gmail.com>	<4408509.xBT3BS7zPY@localhost.localdomain>	<545778CF.3090301@gmail.com>	<2336490.6CSPGQ4BGf@localhost.localdomain>
	<5458D9A1.9020401@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8BC@SRVEXCHMBX.precheza.cz>
	<5459006C.8040903@gmail.com>
	<0164DC64-D1E5-4128-B51D-8C6AE9D5500A@comcast.net>
Message-ID: <545909FD.40307@gmail.com>

On 04/11/14 17:02, David Winsemius wrote:
>
> On Nov 4, 2014, at 8:35 AM, CJ Davies wrote:
>
>> On 04/11/14 16:13, PIKAL Petr wrote:
>>> Hi
>>>
>>>> -----Original Message-----
>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>>> project.org] On Behalf Of CJ Davies
>>>> Sent: Tuesday, November 04, 2014 2:50 PM
>>>> To: Jim Lemon; r-help at r-project.org
>>>> Subject: Re: [R] Variance of multiple non-contiguous time periods?
>>>>
>>>> On 04/11/14 09:11, Jim Lemon wrote:
>>>>> On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
>>>>>> ...
>>>>>> On 30/10/14 21:33, Jim Lemon wrote:
>>>>>> If I understand, you mean to calculate deviations for each
>>>> individual
>>>>>> 'chunk' of each transition & then aggregate the results? This is
>>>> what
>>>>>> I'd been thinking about, but is there a sensible manner within R to
>>>>>> achieve this, or is it something for which it would be easier to
>>>>>> preprocess the data in an external tool? Is there some way to subset
>>>>> the
>>>>>> data such that I can work over just contiguous 'chunks'?
>>>>>>
>>>>> Exactly. If there is some combination of existing variables that can
>>>>> be combined to make a set of unique values for each "chunk", you can
>>>>> calculate the deviations within each "chunk", then average the
>>>> squared
>>>>> deviations for each type of "chunk", weighting by the duration of the
>>>>> "chunks" so that you don't bias the pooled variance toward the longer
>>>>> "chunks".
>>>>>
>>>>> Jim
>>>>>
>>>>
>>>> I am stumped for a way of automating this process though. Each line of
>>>> log data looks like this;
>>>>
>>>> 2406  55.4    (-11.2, 1.0, -0.9)      (-4.1, 1.0, 0.0)        7.077912
>>>>        0.9203392       (0.0,
>>>> 0.7, -0.1, 0.7)       8.129684        89.41537        -8.212769       (0.0, 0.7, -0.1,
>>>> 0.7)
>>>> 8.129684      89.41537        351.7872        1       0       0       False   0.15    3
>>>>        37.76761        True    False   0
>>>> transition 1
>>>
>>> First you need to import it to R which could be tricky based on above line.
>>> Some values will probably need to process through regular expression.
>>>
>>> If I understand correctly number after transition is a signal which estimets continuous chunks. If it is true then
>>>
>>> ?rle is a function which can estimate length of chunks.
>>>
>>> Cheers
>>> Petr
>>>
>>>>
>>>> Where the last variable defines which transition is currently active.
>>>> However to separate these data into 'chunks' would involve making a
>>>> comparison between each line of data & the preceding line of data to
>>>> determine whether it is part of the same contiguous 'chunk'. Is this
>>>> something that would be better achieved using external preprocessing
>>>> written in a language I am more familiar with, as I haven't the
>>>> foggiest how I would approach this within R?
>>>>
>>>> Regards,
>>>> CJ Davies
>>>>
>>>> ______________________________________________
>>>
> snipped
>>>
>>
>> Importing into R wasn't an issue; some of the fields contain spaces & symbols, but all the fields are tab separated so I can simply use;
>>
>> foo <- read.csv("bar",header=T,sep="\t")
>>
>> I've just written a hacky bit of Java that gives me the lines of each 'chunk' as a separate list & I think I'll then calculate these particular values using Java's Math class rather than trying to come up with a sensible way to import these 'chunks' back into R. When it comes to string/list manipulation like this I think my knowledge in Java & lack of knowledge in R makes the former the better option!
>>
>
> If you had offered the output of dput(head(foo, 20) ) and explained what defined a "chunk-defining transition", it would have been fairly easy to show you how to use cumsum in an ave() call to construct a grouping variable.
>
>
>> Regards,
>> CJ Davies
>>
>> ______________________________
>
>
> David Winsemius
> Alameda, CA, USA
>

Here is an example 100 lines of the input --> http://paste2.org/2LZVGP5K

The final value on each line, under the header "environment", is always 
one of ["real", "transition 1", "transition 2", "transition 3", 
"transition 4"]. A 'chunk-defining transition' is when this value changes.

If there is a way to do this in R in a more elegant fashion than my 
hacky Java, then I would be glad to learn.

Regards,
CJ Davies


From marycrossland at gmail.com  Tue Nov  4 15:37:13 2014
From: marycrossland at gmail.com (Mary Crossland)
Date: Tue, 4 Nov 2014 14:37:13 +0000
Subject: [R] Help with glm and glht for analysing count data
Message-ID: <CALO9V5vX4fL6iRQay4nBVMHVBbGhT0B=0x=FcZhRLnTB_Jdrrw@mail.gmail.com>

Dear all,


I?d like some help with analysing some count data. I am very new to R (and
statistical analysis for that matter!) and have done my best to work it out
on my own ? but seemed to have got stuck!


I am looking at the effects of cutting hedges on invertebrates (I?m not
that interested in the difference of inverts collected on the east side of
a hedge compared to the west)

The experimental design consists of paired cut and uncut plots established
in 3 different hedgerow types. Invertebrate counts were taken from each
plot (6 plots overall) four times over 4 weeks.


  Plot

Cut state

Orientation

No. inverts







Week 1

Week 2

Week 3

Blackthorn



Cut

East







Cut

West







Uncut

East







Uncut

West







Hawthorn

Cut

East







Cut

West







Uncut

East







Uncut

West







Hazel

Cut

East







Cut

West







Uncut

East







Uncut

West







Table 1. Example of data.


The data was very skewed and contained a fair few zero counts. I therefore
decided to use glm.


##I first started with a saturated model##

model1<-glm(Inverts~Plot*Cut.Uncut*orientation,quasipoisson)

##Three way interactions are removed##

model2<-update(model1,~.-Plot:Cut.Uncut:orientation)

##anova tests whether the three way interaction is significant or not##

anova(model1,model2,test="Chi")

##I continued to strip down the model##

model3<-update(model2,~.-Plot:Cut.Uncut)

anova(model3,model2,test="Chi")

model4<-update(model2,~.-Plot:orientation)

anova(model4,model2,test="Chi")

## I then looked to see whether just plot had an effect##

model5<-update(model3,~.-Plot:orientation)

model6<-update(model5,~.-Plot)

anova(model6,model5,test="Chi")



Plot was found to be significant. I then wanted to know where this was
coming from so looked at the glht function?.


Summary(glht(model5,mcp(Plot=?Tukey?)))


This showed Blackthorn to be significantly different to the other two
hedges which looking at a box plot seems about right. However if an
interaction between Plot and Cut.Uncut variables was found how would I
explore this further? The glht with Tukey specified seems to only work with
one variable?


Apologies if my explanation is poor, I would be more than happy to give you
more information if it would help.


I?m not sure if anything I?ve done if right or even if I?m on the right
lines?

Any help would be fantastic!


Many thanks,

Mary

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Nov  4 18:34:01 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 4 Nov 2014 09:34:01 -0800
Subject: [R] Help with glm and glht for analysing count data
In-Reply-To: <CALO9V5vX4fL6iRQay4nBVMHVBbGhT0B=0x=FcZhRLnTB_Jdrrw@mail.gmail.com>
References: <CALO9V5vX4fL6iRQay4nBVMHVBbGhT0B=0x=FcZhRLnTB_Jdrrw@mail.gmail.com>
Message-ID: <CACk-te1CCeJ7Nd1vTiP3iwOLboOZeJ_Hd_9=ssr+W_9io1-3Og@mail.gmail.com>

It appears that these are primarily statistical issues and, as such,
are somewhat off topic here. I suggest you post on
stats.stackexchange.com instead for statistical help.

Also, if you insist on posting here, post in plain text, not HTML (as
requested by the posting guide, which you would do well to read and
follow).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Nov 4, 2014 at 6:37 AM, Mary Crossland <marycrossland at gmail.com> wrote:
> Dear all,
>
>
> I?d like some help with analysing some count data. I am very new to R (and
> statistical analysis for that matter!) and have done my best to work it out
> on my own ? but seemed to have got stuck!
>
>
> I am looking at the effects of cutting hedges on invertebrates (I?m not
> that interested in the difference of inverts collected on the east side of
> a hedge compared to the west)
>
> The experimental design consists of paired cut and uncut plots established
> in 3 different hedgerow types. Invertebrate counts were taken from each
> plot (6 plots overall) four times over 4 weeks.
>
>
>   Plot
>
> Cut state
>
> Orientation
>
> No. inverts
>
>
>
>
>
>
>
> Week 1
>
> Week 2
>
> Week 3
>
> Blackthorn
>
>
>
> Cut
>
> East
>
>
>
>
>
>
>
> Cut
>
> West
>
>
>
>
>
>
>
> Uncut
>
> East
>
>
>
>
>
>
>
> Uncut
>
> West
>
>
>
>
>
>
>
> Hawthorn
>
> Cut
>
> East
>
>
>
>
>
>
>
> Cut
>
> West
>
>
>
>
>
>
>
> Uncut
>
> East
>
>
>
>
>
>
>
> Uncut
>
> West
>
>
>
>
>
>
>
> Hazel
>
> Cut
>
> East
>
>
>
>
>
>
>
> Cut
>
> West
>
>
>
>
>
>
>
> Uncut
>
> East
>
>
>
>
>
>
>
> Uncut
>
> West
>
>
>
>
>
>
>
> Table 1. Example of data.
>
>
> The data was very skewed and contained a fair few zero counts. I therefore
> decided to use glm.
>
>
> ##I first started with a saturated model##
>
> model1<-glm(Inverts~Plot*Cut.Uncut*orientation,quasipoisson)
>
> ##Three way interactions are removed##
>
> model2<-update(model1,~.-Plot:Cut.Uncut:orientation)
>
> ##anova tests whether the three way interaction is significant or not##
>
> anova(model1,model2,test="Chi")
>
> ##I continued to strip down the model##
>
> model3<-update(model2,~.-Plot:Cut.Uncut)
>
> anova(model3,model2,test="Chi")
>
> model4<-update(model2,~.-Plot:orientation)
>
> anova(model4,model2,test="Chi")
>
> ## I then looked to see whether just plot had an effect##
>
> model5<-update(model3,~.-Plot:orientation)
>
> model6<-update(model5,~.-Plot)
>
> anova(model6,model5,test="Chi")
>
>
>
> Plot was found to be significant. I then wanted to know where this was
> coming from so looked at the glht function?.
>
>
> Summary(glht(model5,mcp(Plot=?Tukey?)))
>
>
> This showed Blackthorn to be significantly different to the other two
> hedges which looking at a box plot seems about right. However if an
> interaction between Plot and Cut.Uncut variables was found how would I
> explore this further? The glht with Tukey specified seems to only work with
> one variable?
>
>
> Apologies if my explanation is poor, I would be more than happy to give you
> more information if it would help.
>
>
> I?m not sure if anything I?ve done if right or even if I?m on the right
> lines?
>
> Any help would be fantastic!
>
>
> Many thanks,
>
> Mary
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Nov  4 18:42:39 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Nov 2014 09:42:39 -0800
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <545909FD.40307@gmail.com>
References: <54511FF3.5090606@gmail.com>	<4408509.xBT3BS7zPY@localhost.localdomain>	<545778CF.3090301@gmail.com>	<2336490.6CSPGQ4BGf@localhost.localdomain>
	<5458D9A1.9020401@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8BC@SRVEXCHMBX.precheza.cz>
	<5459006C.8040903@gmail.com>
	<0164DC64-D1E5-4128-B51D-8C6AE9D5500A@comcast.net>
	<545909FD.40307@gmail.com>
Message-ID: <D249EFE1-59ED-4FC6-8EEC-65177F25CC9B@comcast.net>


On Nov 4, 2014, at 9:16 AM, CJ Davies wrote:

> On 04/11/14 17:02, David Winsemius wrote:
>> 
>> On Nov 4, 2014, at 8:35 AM, CJ Davies wrote:
>> 
>>> On 04/11/14 16:13, PIKAL Petr wrote:
>>>> Hi
>>>> 
>>>>> -----Original Message-----
>>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>>>> project.org] On Behalf Of CJ Davies
>>>>> Sent: Tuesday, November 04, 2014 2:50 PM
>>>>> To: Jim Lemon; r-help at r-project.org
>>>>> Subject: Re: [R] Variance of multiple non-contiguous time periods?
>>>>> 
>>>>> On 04/11/14 09:11, Jim Lemon wrote:
>>>>>> On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
>>>>>>> ...
>>>>>>> On 30/10/14 21:33, Jim Lemon wrote:
>>>>>>> If I understand, you mean to calculate deviations for each
>>>>> individual
>>>>>>> 'chunk' of each transition & then aggregate the results? This is
>>>>> what
>>>>>>> I'd been thinking about, but is there a sensible manner within R to
>>>>>>> achieve this, or is it something for which it would be easier to
>>>>>>> preprocess the data in an external tool? Is there some way to subset
>>>>>> the
>>>>>>> data such that I can work over just contiguous 'chunks'?
>>>>>>> 
>>>>>> Exactly. If there is some combination of existing variables that can
>>>>>> be combined to make a set of unique values for each "chunk", you can
>>>>>> calculate the deviations within each "chunk", then average the
>>>>> squared
>>>>>> deviations for each type of "chunk", weighting by the duration of the
>>>>>> "chunks" so that you don't bias the pooled variance toward the longer
>>>>>> "chunks".
>>>>>> 
>>>>>> Jim
>>>>>> 
>>>>> 
>>>>> I am stumped for a way of automating this process though. Each line of
>>>>> log data looks like this;
>>>>> 
>>>>> 2406  55.4    (-11.2, 1.0, -0.9)      (-4.1, 1.0, 0.0)        7.077912
>>>>>       0.9203392       (0.0,
>>>>> 0.7, -0.1, 0.7)       8.129684        89.41537        -8.212769       (0.0, 0.7, -0.1,
>>>>> 0.7)
>>>>> 8.129684      89.41537        351.7872        1       0       0       False   0.15    3
>>>>>       37.76761        True    False   0
>>>>> transition 1
>>>> 
>>>> First you need to import it to R which could be tricky based on above line.
>>>> Some values will probably need to process through regular expression.
>>>> 
>>>> If I understand correctly number after transition is a signal which estimets continuous chunks. If it is true then
>>>> 
>>>> ?rle is a function which can estimate length of chunks.
>>>> 
>>>> Cheers
>>>> Petr
>>>> 
>>>>> 
>>>>> Where the last variable defines which transition is currently active.
>>>>> However to separate these data into 'chunks' would involve making a
>>>>> comparison between each line of data & the preceding line of data to
>>>>> determine whether it is part of the same contiguous 'chunk'. Is this
>>>>> something that would be better achieved using external preprocessing
>>>>> written in a language I am more familiar with, as I haven't the
>>>>> foggiest how I would approach this within R?
>>>>> 
>>>>> Regards,
>>>>> CJ Davies
>>>>> 
>>>>> ______________________________________________
>>>> 
>> snipped
>>>> 
>>> 
>>> Importing into R wasn't an issue; some of the fields contain spaces & symbols, but all the fields are tab separated so I can simply use;
>>> 
>>> foo <- read.csv("bar",header=T,sep="\t")
>>> 
>>> I've just written a hacky bit of Java that gives me the lines of each 'chunk' as a separate list & I think I'll then calculate these particular values using Java's Math class rather than trying to come up with a sensible way to import these 'chunks' back into R. When it comes to string/list manipulation like this I think my knowledge in Java & lack of knowledge in R makes the former the better option!
>>> 
>> 
>> If you had offered the output of dput(head(foo, 20) ) and explained what defined a "chunk-defining transition", it would have been fairly easy to show you how to use cumsum in an ave() call to construct a grouping variable.
>> 
>> 
>>> Regards,
>>> CJ Davies
>>> 
>>> ______________________________
>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 
> Here is an example 100 lines of the input --> http://paste2.org/2LZVGP5K
> 
> The final value on each line, under the header "environment", is always one of ["real", "transition 1", "transition 2", "transition 3", "transition 4"]. A 'chunk-defining transition' is when this value changes.
> 
> If there is a way to do this in R in a more elegant fashion than my hacky Java, then I would be glad to learn.

That pasted material does not appear to preserve the tabs. Input with your suggested code "does not work" in the sense that it brings in an object like this. 

> download.file("http://paste2.org/2LZVGP5K", "bar.txt")
trying URL 'http://paste2.org/2LZVGP5K'
Content type 'text/html; charset=UTF-8' length unknown
opened URL
.......... .......... ........
downloaded 28 Kb

> foo <- read.csv("bar.txt",header=T,sep="\t")
> str(foo)
'data.frame':	2829 obs. of  1 variable:
 $ X..DOCTYPE.html.: Factor w/ 669 levels "","          ",..: 106 104 219 233 220 222 221 215 217 79 ...

I SAY AGAIN:

Need ; output of dput(head(foo, 100) )


> 
> Regards,
> CJ Davies

David Winsemius
Alameda, CA, USA


From igauravsehrawat at gmail.com  Tue Nov  4 20:22:43 2014
From: igauravsehrawat at gmail.com (Gaurav Sehrawat)
Date: Wed, 5 Nov 2014 00:52:43 +0530
Subject: [R] Volunteers for Google Code-in mentor & co-admin/admin
Message-ID: <CAC2qNN4+bFPEwZ7uKM0AFGNAQ5qyBO=KM0J1txPDdNKPxO6wcA@mail.gmail.com>

Hello everyone ,

I would like to bring everyone's attention to this thread :
https://groups.google.com/forum/#!topic/gsoc-r/dtYY_5NBvyc .

R-project has been participating for Google Summer of Code since long time
. This R-project is planning for Google Code-in ,to introduce school kids
about the r-language .

If anyone is available to volunteer for the same , that would be great .

More about code-in is here :
http://www.google-melange.com/gci/homepage/google/gci2014

Thanks

Cheers

	[[alternative HTML version deleted]]


From cjohndavies at gmail.com  Wed Nov  5 00:41:40 2014
From: cjohndavies at gmail.com (CJ Davies)
Date: Tue, 04 Nov 2014 23:41:40 +0000
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <D249EFE1-59ED-4FC6-8EEC-65177F25CC9B@comcast.net>
References: <54511FF3.5090606@gmail.com>	<4408509.xBT3BS7zPY@localhost.localdomain>	<545778CF.3090301@gmail.com>	<2336490.6CSPGQ4BGf@localhost.localdomain>
	<5458D9A1.9020401@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8BC@SRVEXCHMBX.precheza.cz>
	<5459006C.8040903@gmail.com>
	<0164DC64-D1E5-4128-B51D-8C6AE9D5500A@comcast.net>
	<545909FD.40307@gmail.com>
	<D249EFE1-59ED-4FC6-8EEC-65177F25CC9B@comcast.net>
Message-ID: <54596434.40002@gmail.com>

On 04/11/14 17:42, David Winsemius wrote:
> On Nov 4, 2014, at 9:16 AM, CJ Davies wrote:
>
>> On 04/11/14 17:02, David Winsemius wrote:
>>> On Nov 4, 2014, at 8:35 AM, CJ Davies wrote:
>>>
>>>> On 04/11/14 16:13, PIKAL Petr wrote:
>>>>> Hi
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>>>>> project.org] On Behalf Of CJ Davies
>>>>>> Sent: Tuesday, November 04, 2014 2:50 PM
>>>>>> To: Jim Lemon; r-help at r-project.org
>>>>>> Subject: Re: [R] Variance of multiple non-contiguous time periods?
>>>>>>
>>>>>> On 04/11/14 09:11, Jim Lemon wrote:
>>>>>>> On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
>>>>>>>> ...
>>>>>>>> On 30/10/14 21:33, Jim Lemon wrote:
>>>>>>>> If I understand, you mean to calculate deviations for each
>>>>>> individual
>>>>>>>> 'chunk' of each transition & then aggregate the results? This is
>>>>>> what
>>>>>>>> I'd been thinking about, but is there a sensible manner within R to
>>>>>>>> achieve this, or is it something for which it would be easier to
>>>>>>>> preprocess the data in an external tool? Is there some way to subset
>>>>>>> the
>>>>>>>> data such that I can work over just contiguous 'chunks'?
>>>>>>>>
>>>>>>> Exactly. If there is some combination of existing variables that can
>>>>>>> be combined to make a set of unique values for each "chunk", you can
>>>>>>> calculate the deviations within each "chunk", then average the
>>>>>> squared
>>>>>>> deviations for each type of "chunk", weighting by the duration of the
>>>>>>> "chunks" so that you don't bias the pooled variance toward the longer
>>>>>>> "chunks".
>>>>>>>
>>>>>>> Jim
>>>>>>>
>>>>>> I am stumped for a way of automating this process though. Each line of
>>>>>> log data looks like this;
>>>>>>
>>>>>> 2406  55.4    (-11.2, 1.0, -0.9)      (-4.1, 1.0, 0.0)        7.077912
>>>>>>       0.9203392       (0.0,
>>>>>> 0.7, -0.1, 0.7)       8.129684        89.41537        -8.212769       (0.0, 0.7, -0.1,
>>>>>> 0.7)
>>>>>> 8.129684      89.41537        351.7872        1       0       0       False   0.15    3
>>>>>>       37.76761        True    False   0
>>>>>> transition 1
>>>>> First you need to import it to R which could be tricky based on above line.
>>>>> Some values will probably need to process through regular expression.
>>>>>
>>>>> If I understand correctly number after transition is a signal which estimets continuous chunks. If it is true then
>>>>>
>>>>> ?rle is a function which can estimate length of chunks.
>>>>>
>>>>> Cheers
>>>>> Petr
>>>>>
>>>>>> Where the last variable defines which transition is currently active.
>>>>>> However to separate these data into 'chunks' would involve making a
>>>>>> comparison between each line of data & the preceding line of data to
>>>>>> determine whether it is part of the same contiguous 'chunk'. Is this
>>>>>> something that would be better achieved using external preprocessing
>>>>>> written in a language I am more familiar with, as I haven't the
>>>>>> foggiest how I would approach this within R?
>>>>>>
>>>>>> Regards,
>>>>>> CJ Davies
>>>>>>
>>>>>> ______________________________________________
>>> snipped
>>>> Importing into R wasn't an issue; some of the fields contain spaces & symbols, but all the fields are tab separated so I can simply use;
>>>>
>>>> foo <- read.csv("bar",header=T,sep="\t")
>>>>
>>>> I've just written a hacky bit of Java that gives me the lines of each 'chunk' as a separate list & I think I'll then calculate these particular values using Java's Math class rather than trying to come up with a sensible way to import these 'chunks' back into R. When it comes to string/list manipulation like this I think my knowledge in Java & lack of knowledge in R makes the former the better option!
>>>>
>>> If you had offered the output of dput(head(foo, 20) ) and explained what defined a "chunk-defining transition", it would have been fairly easy to show you how to use cumsum in an ave() call to construct a grouping variable.
>>>
>>>
>>>> Regards,
>>>> CJ Davies
>>>>
>>>> ______________________________
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>> Here is an example 100 lines of the input --> http://paste2.org/2LZVGP5K
>>
>> The final value on each line, under the header "environment", is always one of ["real", "transition 1", "transition 2", "transition 3", "transition 4"]. A 'chunk-defining transition' is when this value changes.
>>
>> If there is a way to do this in R in a more elegant fashion than my hacky Java, then I would be glad to learn.
> That pasted material does not appear to preserve the tabs. Input with your suggested code "does not work" in the sense that it brings in an object like this. 
>
>> download.file("http://paste2.org/2LZVGP5K", "bar.txt")
> trying URL 'http://paste2.org/2LZVGP5K'
> Content type 'text/html; charset=UTF-8' length unknown
> opened URL
> .......... .......... ........
> downloaded 28 Kb
>
>> foo <- read.csv("bar.txt",header=T,sep="\t")
>> str(foo)
> 'data.frame':	2829 obs. of  1 variable:
>  $ X..DOCTYPE.html.: Factor w/ 669 levels "","          ",..: 106 104 219 233 220 222 221 215 217 79 ...
>
> I SAY AGAIN:
>
> Need ; output of dput(head(foo, 100) )
>
>
>> Regards,
>> CJ Davies
> David Winsemius
> Alameda, CA, USA
>
That was a pastebin URI, so what you downloaded was HTML instead of raw
text. This is the raw text;

http://cjdavies.org/foo

Regards,
CJ Davies


From cargyropoulos at unm.edu  Wed Nov  5 00:46:16 2014
From: cargyropoulos at unm.edu (Christos Argyropoulos)
Date: Tue, 4 Nov 2014 23:46:16 +0000
Subject: [R] Frailty and tt terms in coxph
Message-ID: <be4695dbfabb43e083d7bfa9ec4205d2@DM2PR07MB414.namprd07.prod.outlook.com>

Dear all,

I am receiving the following error when trying to include both tt (time transforms) and frailty terms in coxph

> coxph(Surv(time, status) ~ ph.ecog + tt(age)+cluster(sex), data=lung,
+      tt=function(x,t,...) pspline(x + t/365.25))
Error in residuals.coxph(fit2, type = "dfbeta", collapse = cluster, weighted = TRUE) :
  Wrong length for 'collapse'

I tried both 64 bit (R.3.1.0) and 32 bit (R.3.1.2) in Windows 7 64bit and get the same errors

Inclusion of tt and cluster terms worked fine in R2.9.2-2.15.1 under Windows Vista 32 bit and Ubuntu 64 bit

Any ideas?

Christos Argyropoulos
Assistant Professor of Nephrology,
Department of Internal Medicine
University of New Mexico School of Medicine


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Nov  5 01:29:15 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Nov 2014 16:29:15 -0800
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <54596434.40002@gmail.com>
References: <54511FF3.5090606@gmail.com>	<4408509.xBT3BS7zPY@localhost.localdomain>	<545778CF.3090301@gmail.com>	<2336490.6CSPGQ4BGf@localhost.localdomain>
	<5458D9A1.9020401@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED8BC@SRVEXCHMBX.precheza.cz>
	<5459006C.8040903@gmail.com>
	<0164DC64-D1E5-4128-B51D-8C6AE9D5500A@comcast.net>
	<545909FD.40307@gmail.com>
	<D249EFE1-59ED-4FC6-8EEC-65177F25CC9B@comcast.net>
	<54596434.40002@gmail.com>
Message-ID: <6DC13F66-2200-45DB-8703-74365B412A68@comcast.net>


On Nov 4, 2014, at 3:41 PM, CJ Davies wrote:

> On 04/11/14 17:42, David Winsemius wrote:
>> On Nov 4, 2014, at 9:16 AM, CJ Davies wrote:
>> 
>>> On 04/11/14 17:02, David Winsemius wrote:
>>>> On Nov 4, 2014, at 8:35 AM, CJ Davies wrote:
>>>> 
>>>>> On 04/11/14 16:13, PIKAL Petr wrote:
>>>>>> Hi
>>>>>> 
>>>>>>> -----Original Message-----
>>>>>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>>>>>> project.org] On Behalf Of CJ Davies
>>>>>>> Sent: Tuesday, November 04, 2014 2:50 PM
>>>>>>> To: Jim Lemon; r-help at r-project.org
>>>>>>> Subject: Re: [R] Variance of multiple non-contiguous time periods?
>>>>>>> 
>>>>>>> On 04/11/14 09:11, Jim Lemon wrote:
>>>>>>>> On Mon, 3 Nov 2014 12:45:03 PM CJ Davies wrote:
>>>>>>>>> ...
>>>>>>>>> On 30/10/14 21:33, Jim Lemon wrote:
>>>>>>>>> If I understand, you mean to calculate deviations for each
>>>>>>> individual
>>>>>>>>> 'chunk' of each transition & then aggregate the results? This is
>>>>>>> what
>>>>>>>>> I'd been thinking about, but is there a sensible manner within R to
>>>>>>>>> achieve this, or is it something for which it would be easier to
>>>>>>>>> preprocess the data in an external tool? Is there some way to subset
>>>>>>>> the
>>>>>>>>> data such that I can work over just contiguous 'chunks'?
>>>>>>>>> 
>>>>>>>> Exactly. If there is some combination of existing variables that can
>>>>>>>> be combined to make a set of unique values for each "chunk", you can
>>>>>>>> calculate the deviations within each "chunk", then average the
>>>>>>> squared
>>>>>>>> deviations for each type of "chunk", weighting by the duration of the
>>>>>>>> "chunks" so that you don't bias the pooled variance toward the longer
>>>>>>>> "chunks".
>>>>>>>> 
>>>>>>>> Jim
>>>>>>>> 
>>>>>>> I am stumped for a way of automating this process though. Each line of
>>>>>>> log data looks like this;
>>>>>>> 
>>>>>>> 2406  55.4    (-11.2, 1.0, -0.9)      (-4.1, 1.0, 0.0)        7.077912
>>>>>>>      0.9203392       (0.0,
>>>>>>> 0.7, -0.1, 0.7)       8.129684        89.41537        -8.212769       (0.0, 0.7, -0.1,
>>>>>>> 0.7)
>>>>>>> 8.129684      89.41537        351.7872        1       0       0       False   0.15    3
>>>>>>>      37.76761        True    False   0
>>>>>>> transition 1
>>>>>> First you need to import it to R which could be tricky based on above line.
>>>>>> Some values will probably need to process through regular expression.
>>>>>> 
>>>>>> If I understand correctly number after transition is a signal which estimets continuous chunks. If it is true then
>>>>>> 
>>>>>> ?rle is a function which can estimate length of chunks.
>>>>>> 
>>>>>> Cheers
>>>>>> Petr
>>>>>> 
>>>>>>> Where the last variable defines which transition is currently active.
>>>>>>> However to separate these data into 'chunks' would involve making a
>>>>>>> comparison between each line of data & the preceding line of data to
>>>>>>> determine whether it is part of the same contiguous 'chunk'. Is this
>>>>>>> something that would be better achieved using external preprocessing
>>>>>>> written in a language I am more familiar with, as I haven't the
>>>>>>> foggiest how I would approach this within R?
>>>>>>> 
>>>>>>> Regards,
>>>>>>> CJ Davies
>>>>>>> 
>>>>>>> ______________________________________________
>>>> snipped
>>>>> Importing into R wasn't an issue; some of the fields contain spaces & symbols, but all the fields are tab separated so I can simply use;
>>>>> 
>>>>> foo <- read.csv("bar",header=T,sep="\t")
>>>>> 
>>>>> I've just written a hacky bit of Java that gives me the lines of each 'chunk' as a separate list & I think I'll then calculate these particular values using Java's Math class rather than trying to come up with a sensible way to import these 'chunks' back into R. When it comes to string/list manipulation like this I think my knowledge in Java & lack of knowledge in R makes the former the better option!
>>>>> 
>>>> If you had offered the output of dput(head(foo, 20) ) and explained what defined a "chunk-defining transition", it would have been fairly easy to show you how to use cumsum in an ave() call to construct a grouping variable.
>>>> 
>>>> 
>>>>> Regards,
>>>>> CJ Davies
>>>>> 
>>>>> ______________________________
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>>> Here is an example 100 lines of the input --> http://paste2.org/2LZVGP5K
>>> 
>>> The final value on each line, under the header "environment", is always one of ["real", "transition 1", "transition 2", "transition 3", "transition 4"]. A 'chunk-defining transition' is when this value changes.
>>> 
>>> If there is a way to do this in R in a more elegant fashion than my hacky Java, then I would be glad to learn.
>> That pasted material does not appear to preserve the tabs. Input with your suggested code "does not work" in the sense that it brings in an object like this. 
>> 
>>> download.file("http://paste2.org/2LZVGP5K", "bar.txt")
>> trying URL 'http://paste2.org/2LZVGP5K'
>> Content type 'text/html; charset=UTF-8' length unknown
>> opened URL
>> .......... .......... ........
>> downloaded 28 Kb
>> 
>>> foo <- read.csv("bar.txt",header=T,sep="\t")
>>> str(foo)
>> 'data.frame':	2829 obs. of  1 variable:
>> $ X..DOCTYPE.html.: Factor w/ 669 levels "","          ",..: 106 104 219 233 220 222 221 215 217 79 ...
>> 
>> I SAY AGAIN:
>> 
>> Need ; output of dput(head(foo, 100) )
>> 
>> 
>>> Regards,
>>> CJ Davies
>> David Winsemius
>> Alameda, CA, USA
>> 
> That was a pastebin URI, so what you downloaded was HTML instead of raw
> text. This is the raw text;

Well, it was text but it had no tabs. On this mailing list, HTML is considered evil.

> foo$chunk <- c(NA, foo$environment[-1] != head(foo$environment,-1) )
> table(foo$chunk)

FALSE  TRUE 
  503   106 
> foo$chunk <- cumsum(c(1, foo$chunk[-1]) )
> table(foo$chunk)

  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26 
 20   1   6   1   1   1   4   1   1   2  16   1   7   4  14   2   6   1   2   4   1   4   2   8   6   2 
 27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52 
  2   1   7   1   1   2   2   2   6  10   3   1  12   3   1  10  18   6   1   6  14   4   1  19  13  10 
 53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78 
  6   2  10  14   3   2   1   2   1   1   1  15   4   2   2   6  21   5   1  16   5   3   1   2  21   3 
 79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 
  1   2   3   4   4   3   5   1   9   1   3   3   7   2   5   6   6   5  13   1   1   8   1   2   2   3 
105 106 107 
  6   9  70 

So now you have a chunking index and can use `by` or `ave` or `for()`-loops

> 
> http://cjdavies.org/foo

That was displayed as it it had tabs and after correcting the error of using T for TRUE it did succeed.


> 
> Regards,
> CJ Davies

David Winsemius
Alameda, CA, USA


From alok.jadhav at credit-suisse.com  Wed Nov  5 01:04:18 2014
From: alok.jadhav at credit-suisse.com (Alok Jadhav)
Date: Tue, 4 Nov 2014 16:04:18 -0800 (PST)
Subject: [R] why RODBC on windows 7 with Sybase, returns garbage?
In-Reply-To: <1415135036322-4699208.post@n4.nabble.com>
References: <1336116903098-4607986.post@n4.nabble.com>
	<1415135036322-4699208.post@n4.nabble.com>
Message-ID: <5CC618D74A5E2747BD49AEB4F19B85AE1A7E35FB@HKW20030007.gbl.ad.hedani.net>

Hi James,

Is your server name correct in the string below? Looks like you are using incorrect server name.  If you don't give full server name, then the server has to be registered with ODBC management tool so that it can be picked up automatically.

Regards,
Alok

From: James Mathew [via R] [mailto:ml-node+s789695n4699208h81 at n4.nabble.com]
Sent: Wednesday, November 05, 2014 5:04 AM
To: Jadhav, Alok (KFET 63)
Subject: Re: why RODBC on windows 7 with Sybase, returns garbage?

Hi Alok and all,

I am trying to connect to sybase from R with the RODBC package. I am using native sybase driver "Adaptive server Enterprise" and using the following example code.

conn <- sprintf("driver=Adaptive server Enterprise;server=PHKSESMD01;database=smd_live;uid=temp_user;password=temp_pass;port=2301")
chan <- odbcDriverConnect(conn)
x <- sqlQuery(chan,sql,as.is=as.is)
odbcClose(chan)

However I am not able to connect to the database and I get the following error.
1: In odbcDriverConnect(conn)
  [RODBC] ERROR: state IM002, code 0, message [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified
2: In odbcDriverConnect(conn) : ODBC connection failed

Any tips will be greatly appreciated.

________________________________
If you reply to this email, your message will be added to the discussion below:
http://r.789695.n4.nabble.com/why-RODBC-on-windows-7-with-Sybase-returns-garbage-tp4607986p4699208.html
To unsubscribe from why RODBC on windows 7 with Sybase, returns garbage?, click here<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4607986&code=YWxvay5qYWRoYXZAY3JlZGl0LXN1aXNzZS5jb218NDYwNzk4NnwxMTg4ODMyMzg0>.
NAML<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>


=============================================================================== 
Please access the attached hyperlink for an important el...{{dropped:14}}


From ntfredo at gmail.com  Wed Nov  5 09:34:31 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 5 Nov 2014 11:34:31 +0300
Subject: [R] Function that create day of the year column.
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED894@SRVEXCHMBX.precheza.cz>
References: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
	<CAPfrkhmNFA=Huy6uFD2uJC6Mf4J6-_+X3v2aHP0gnU5G2qhpGw@mail.gmail.com>
	<CAGh51gRw-_iZfEhAFKi7XvLL=dL8umAuPS4HKQ+qACj0voiytg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED894@SRVEXCHMBX.precheza.cz>
Message-ID: <CAGh51gQjxUdpctWieuS5iWQyYxEYABLupf73=pSZjC_VAp2NQA@mail.gmail.com>

Dear PIKAL,

I am using a data frame not a single value. I wanted to add a new column
"DOY" on a dataset. I made it but I want to make it General. i.e. You will
see in the dataset I am using columns names (Year,month and day.) What if I
have this information in other columns names? In this function I will be
pushed to change my columns names which I don't think it is a good idea.
How can I make it in such away that I can use any column's name which
contains the informations I want to use?

In the previous comment this is what I mean saying a single date "single
date column(ex:2009-08-02)"

The following is the function and head-tail of the data after running the
function.


library(lubridate)
DOY=function(data){
   attach(data)
#=================================================================
#This function create day of teh year from a single date
column(ex:2009-08-02) or/and
#from the date in 3 columns (Year, month, Day).
#================================================================
if (is.data.frame(data)) { # check if the data is a dataframe
  dt1=yday(as.Date(paste(Year, Month, Day,sep="-")))
  # check if the year is leap or not.
  datelp= dt1>59 & !leap_year(year(as.Date(paste(Year,Month, Day,sep="-"))))
  datelp[is.na(datelp)]=FALSE
  dt1[datelp]=dt1[datelp]+1 # add one for non leap_year
  data2=cbind(data, dt1) # combining columns of data
  n<-ncol(data)
  colnames(data2)[n+1] = "DOY"
}
  data2
}

head(DOY(Kitale))

  Year Month Day Rain DOY
1 1979     1   1    0   1
2 1979     1   2    0   2
3 1979     1   3    0   3
4 1979     1   4    0   4
5 1979     1   5    0   5
6 1979     1   6    0   6

tail(DOY(Kitale))

     Year Month Day Rain DOY
11315 2009    12  26 40.7 361
11316 2009    12  27 13.6 362
11317 2009    12  28 42.2 363
11318 2009    12  29 53.6 364
11319 2009    12  30 19.8 365
11320 2009    12  31  0.5 366

Thanks for the help.
Regards,
Frederic.











Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Nov 4, 2014 at 6:55 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> You want a function with input of either single value or a data frame?
> This is very strange. One option is to make a method for function but it is
> quite beyond my capabilities and it is used by "professional" developers.
>
> methods(c) or methods(plot)
>
> So you need to set method for your function DOY something like
>
> DOY.single_value and DOY.data.frame
>
> Anyway
>
> Function yday takes some value in time/date format regardless it is single
> value or a vector, so the problem is how do you want your function to work
> and more importantly how general you want it. I simple case you need to
> check if data is single value or data frame.
>
> DOY=function(data){
>
> if (is.data.frame(data)) {
>
> do stuff for data frame} else {
>
> do stuff for single value}
>
> return something
>
> }
>
> Other comments see in line
>
> >>   data$Rain=as.numeric(as.character(data$Rain))
> > >>   dt=yday(data$Date) # single date of the data
>
> If data is data frame dt shall be vector uf numbers not a single date
>
> > >>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date
>
> datelp is (maybe) a logical vector with the same length as dt
>
> > occurs
> > >> during a leap year
> > >>   dt[datelp]=dt[datelp]+1 # add one for non leap_year
>
> Why you do this?
> dt<-1:365 # e.g. length is 365
> datelp<-dt>59 # logical vector
>
>
> dt[datelp]<-dt[datelp]+1 # change all numbers greater than 59
> dt
>   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
> 18
>  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
> 36
>  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
> 54
>  [55]  55  56  57  58  59  61  62  63  64  65  66  67  68  69  70  71  72
> 73
>                        ^^^^^^
> now you have day 60 missing
>
>  [73]  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
> 91
>  [91]  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108
> 109
> [109] 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
> 127
> [127] 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
> 145
> [145] 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162
> 163
> [163] 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
> 181
> [181] 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
> 199
> [199] 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
> 217
> [217] 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
> 235
> [235] 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
> 253
> [253] 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
> 271
> [271] 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
> 289
> [289] 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
> 307
> [307] 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
> 325
> [325] 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
> 343
> [343] 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360
> 361
> [361] 362 363 364 365 366
>
> But length of dt stays the same
>  length(dt)
> [1] 365
>
> Cheers
> Petr
>
> > >>   cbind(data, dt) # combining columns of data
> > >>   conames(data)="DOY" # name of new column. ??I have a problem on
> > how
> > >> I can precise the column in gerenal.
> > >> }
> > >>
> > >>
>
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Frederic Ntirenganya
> > Sent: Tuesday, November 04, 2014 1:31 PM
> > To: daniel
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Function that create day of the year column.
> >
> > Hi Daniel,
> >
> > How can I add an if conditiopn or for loop to implement this in my
> > function?
> >
> > ex: option1 : single date
> >      option2: date in 3 columns (year,moth,day)
> >
> > yday(Sys.Date())
> > yday(as.Date(paste(y,m,d,sep="-")))
> >
> > Regards,
> > Frederic.
> >
> >
> > Frederic Ntirenganya
> > Maseno University,
> > African Maths Initiative,
> > Kenya.
> > Mobile:(+254)718492836
> > Email: fredo at aims.ac.za
> > https://sites.google.com/a/aims.ac.za/fredo/
> >
> > On Tue, Nov 4, 2014 at 3:20 PM, daniel <daniel319 at gmail.com> wrote:
> >
> > > Frederic,
> > >
> > > Check the lubridate library.
> > >
> > > install.packages("lubridate")
> > > library(lubridate)
> > > yday(Sys.Date())
> > > d <- 4
> > > m <- 11
> > > y <- 2014
> > > yday(as.Date(paste(y,m,d,sep="-")))
> > >
> > > Daniel Merino
> > >
> > > 2014-11-04 7:01 GMT-03:00 Frederic Ntirenganya <ntfredo at gmail.com>:
> > >
> > >> Dear All,
> > >>
> > >> I would like to make a function that create Day of the year column
> > in
> > >> a dataset.
> > >> State of the problem: write a function that create a day column
> > >> either from a single date column (string/or factors) or from date in
> > >> 3 columns (year, month, day).
> > >>
> > >> I made the following function for a single date. I would like to add
> > >> a condition for date in 3 columns (year, month, day). My data is
> > >> daily climate data.
> > >> #write a function that create a day column either from a single date
> > >> column (string/or factors) #or from date in 3 columns (year, month,
> > >> day).
> > >>
> > >> DOY=function(data){
> > >>
> > >> #=================================================================
> > >> #This function create day of teh year from a single date
> > >> column(ex:2009-08-02) or/and
> > >> #from the date in 3 columns (Year, month, Day).
> > >> #================================================================
> > >>   data$Rain=as.numeric(as.character(data$Rain))
> > >>   dt=yday(data$Date) # single date of the data
> > >>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date
> > occurs
> > >> during a leap year
> > >>   dt[datelp]=dt[datelp]+1 # add one for non leap_year
> > >>   cbind(data, dt) # combining columns of data
> > >>   conames(data)="DOY" # name of new column. ??I have a problem on
> > how
> > >> I can precise the column in gerenal.
> > >> }
> > >>
> > >> ex: year  month day   Date         Rain Tmin Tmax
> > >>       1971   1         1    1971-01-01   0     8.2  15
> > >>        1971  1         2    1971-01-02   0     4.2  11
> > >>         .        .          .       .               .      .      .
> > >>         .        .          .       .               .      .      .
> > >>         .        .          .       .               .      .      .
> > >>
> > >> Any ideal on how I can make this function is welcome. thanks!
> > >> Frederic Ntirenganya
> > >> Maseno University,
> > >> African Maths Initiative,
> > >> Kenya.
> > >> Mobile:(+254)718492836
> > >> Email: fredo at aims.ac.za
> > >> https://sites.google.com/a/aims.ac.za/fredo/
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >
> > >
> > > --
> > > Daniel
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Nov  5 10:57:55 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 5 Nov 2014 09:57:55 +0000
Subject: [R] Function that create day of the year column.
In-Reply-To: <CAGh51gQjxUdpctWieuS5iWQyYxEYABLupf73=pSZjC_VAp2NQA@mail.gmail.com>
References: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
	<CAPfrkhmNFA=Huy6uFD2uJC6Mf4J6-_+X3v2aHP0gnU5G2qhpGw@mail.gmail.com>
	<CAGh51gRw-_iZfEhAFKi7XvLL=dL8umAuPS4HKQ+qACj0voiytg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED894@SRVEXCHMBX.precheza.cz>
	<CAGh51gQjxUdpctWieuS5iWQyYxEYABLupf73=pSZjC_VAp2NQA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BED9F0@SRVEXCHMBX.precheza.cz>

Hi

single date and vector of dates is something quite different. Your bithday is single date, birthdays of country population is vector of dates.

You want to check that some columns in your data are those you want directly inside the function?

Or you just want to be able to select columns on your own when calling the function?

The first option is quite complicated and it would require huge amount of checking.

If you just want use one or another option = 3 columns or 1 column you can do it by adding some parameter to your function.


DOY=function(data, single = FALSE, which = c(1,2,3) {

if (single) {
....
dt1=yday(as.Date(data[,which])) } else {

....
dt1=yday(as.Date(paste(data[,which[1]], data[,which[2]], data[,which[,3]], sep="-")))
}
....

Something like that although I am not sure if it does not restrict input for which to have always three values. If yes you can for single column option use only the first value, specifying required column.

dt1=yday(as.Date(data[,which[1]]))

Cheers
Petr

PS. No HTML post please.



From: Frederic Ntirenganya [mailto:ntfredo at gmail.com]
Sent: Wednesday, November 05, 2014 9:35 AM
To: PIKAL Petr
Cc: r-help at r-project.org
Subject: Re: [R] Function that create day of the year column.

Dear PIKAL,
I am using a data frame not a single value. I wanted to add a new column "DOY" on a dataset. I made it but I want to make it General. i.e. You will see in the dataset I am using columns names (Year,month and day.) What if I have this information in other columns names? In this function I will be pushed to change my columns names which I don't think it is a good idea. How can I make it in such away that I can use any column's name which contains the informations I want to use?
In the previous comment this is what I mean saying a single date "single date column(ex:2009-08-02)"

The following is the function and head-tail of the data after running the function.

library(lubridate)
DOY=function(data){
   attach(data)
#=================================================================
#This function create day of teh year from a single date column(ex:2009-08-02) or/and
#from the date in 3 columns (Year, month, Day).
#================================================================
if (is.data.frame(data)) { # check if the data is a dataframe
  dt1=yday(as.Date(paste(Year, Month, Day,sep="-")))
  # check if the year is leap or not.
  datelp= dt1>59 & !leap_year(year(as.Date(paste(Year,Month, Day,sep="-"))))
  datelp[is.na<http://is.na>(datelp)]=FALSE
  dt1[datelp]=dt1[datelp]+1 # add one for non leap_year
  data2=cbind(data, dt1) # combining columns of data
  n<-ncol(data)
  colnames(data2)[n+1] = "DOY"
}
  data2
}

head(DOY(Kitale))

  Year Month Day Rain DOY
1 1979     1   1    0   1
2 1979     1   2    0   2
3 1979     1   3    0   3
4 1979     1   4    0   4
5 1979     1   5    0   5
6 1979     1   6    0   6

tail(DOY(Kitale))

     Year Month Day Rain DOY
11315 2009    12  26 40.7 361
11316 2009    12  27 13.6 362
11317 2009    12  28 42.2 363
11318 2009    12  29 53.6 364
11319 2009    12  30 19.8 365
11320 2009    12  31  0.5 366
Thanks for the help.
Regards,
Frederic.









Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za<mailto:fredo at aims.ac.za>
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Nov 4, 2014 at 6:55 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

You want a function with input of either single value or a data frame? This is very strange. One option is to make a method for function but it is quite beyond my capabilities and it is used by "professional" developers.

methods(c) or methods(plot)

So you need to set method for your function DOY something like

DOY.single_value and DOY.data.frame

Anyway

Function yday takes some value in time/date format regardless it is single value or a vector, so the problem is how do you want your function to work and more importantly how general you want it. I simple case you need to check if data is single value or data frame.

DOY=function(data){

if (is.data.frame(data)) {

do stuff for data frame} else {

do stuff for single value}

return something

}

Other comments see in line

>>   data$Rain=as.numeric(as.character(data$Rain))
> >>   dt=yday(data$Date) # single date of the data

If data is data frame dt shall be vector uf numbers not a single date

> >>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date

datelp is (maybe) a logical vector with the same length as dt

> occurs
> >> during a leap year
> >>   dt[datelp]=dt[datelp]+1 # add one for non leap_year

Why you do this?
dt<-1:365 # e.g. length is 365
datelp<-dt>59 # logical vector


dt[datelp]<-dt[datelp]+1 # change all numbers greater than 59
dt
  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18
 [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36
 [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54
 [55]  55  56  57  58  59  61  62  63  64  65  66  67  68  69  70  71  72  73
                       ^^^^^^
now you have day 60 missing

 [73]  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91
 [91]  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109
[109] 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127
[127] 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
[145] 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163
[163] 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181
[181] 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199
[199] 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
[217] 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
[235] 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
[253] 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
[271] 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
[289] 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
[307] 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
[325] 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
[343] 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
[361] 362 363 364 365 366

But length of dt stays the same
 length(dt)
[1] 365

Cheers
Petr

> >>   cbind(data, dt) # combining columns of data
> >>   conames(data)="DOY" # name of new column. ??I have a problem on
> how
> >> I can precise the column in gerenal.
> >> }
> >>
> >>

> -----Original Message-----
> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-<mailto:r-help-bounces at r->
> project.org<http://project.org>] On Behalf Of Frederic Ntirenganya
> Sent: Tuesday, November 04, 2014 1:31 PM
> To: daniel
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] Function that create day of the year column.
>
> Hi Daniel,
>
> How can I add an if conditiopn or for loop to implement this in my
> function?
>
> ex: option1 : single date
>      option2: date in 3 columns (year,moth,day)
>
> yday(Sys.Date())
> yday(as.Date(paste(y,m,d,sep="-")))
>
> Regards,
> Frederic.
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za<mailto:fredo at aims.ac.za>
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Nov 4, 2014 at 3:20 PM, daniel <daniel319 at gmail.com<mailto:daniel319 at gmail.com>> wrote:
>
> > Frederic,
> >
> > Check the lubridate library.
> >
> > install.packages("lubridate")
> > library(lubridate)
> > yday(Sys.Date())
> > d <- 4
> > m <- 11
> > y <- 2014
> > yday(as.Date(paste(y,m,d,sep="-")))
> >
> > Daniel Merino
> >
> > 2014-11-04 7:01 GMT-03:00 Frederic Ntirenganya <ntfredo at gmail.com<mailto:ntfredo at gmail.com>>:
> >
> >> Dear All,
> >>
> >> I would like to make a function that create Day of the year column
> in
> >> a dataset.
> >> State of the problem: write a function that create a day column
> >> either from a single date column (string/or factors) or from date in
> >> 3 columns (year, month, day).
> >>
> >> I made the following function for a single date. I would like to add
> >> a condition for date in 3 columns (year, month, day). My data is
> >> daily climate data.
> >> #write a function that create a day column either from a single date
> >> column (string/or factors) #or from date in 3 columns (year, month,
> >> day).
> >>
> >> DOY=function(data){
> >>
> >> #=================================================================
> >> #This function create day of teh year from a single date
> >> column(ex:2009-08-02) or/and
> >> #from the date in 3 columns (Year, month, Day).
> >> #================================================================
> >>   data$Rain=as.numeric(as.character(data$Rain))
> >>   dt=yday(data$Date) # single date of the data
> >>   datelp= dt>59 & !leap_year(data$Date)# tell us that the date
> occurs
> >> during a leap year
> >>   dt[datelp]=dt[datelp]+1 # add one for non leap_year
> >>   cbind(data, dt) # combining columns of data
> >>   conames(data)="DOY" # name of new column. ??I have a problem on
> how
> >> I can precise the column in gerenal.
> >> }
> >>
> >> ex: year  month day   Date         Rain Tmin Tmax
> >>       1971   1         1    1971-01-01   0     8.2  15
> >>        1971  1         2    1971-01-02   0     4.2  11
> >>         .        .          .       .               .      .      .
> >>         .        .          .       .               .      .      .
> >>         .        .          .       .               .      .      .
> >>
> >> Any ideal on how I can make this function is welcome. thanks!
> >> Frederic Ntirenganya
> >> Maseno University,
> >> African Maths Initiative,
> >> Kenya.
> >> Mobile:(+254)718492836
> >> Email: fredo at aims.ac.za<mailto:fredo at aims.ac.za>
> >> https://sites.google.com/a/aims.ac.za/fredo/
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > Daniel
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Wed Nov  5 11:04:49 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 05 Nov 2014 10:04:49 +0000
Subject: [R] Fwd: Re:  Function that create day of the year column.
In-Reply-To: <5459F598.90707@aghmed.fsnet.co.uk>
References: <5459F598.90707@aghmed.fsnet.co.uk>
Message-ID: <5459F641.4040107@aghmed.fsnet.co.uk>


Dear Federic

You need to do something like

function(p, weights = NULL, data = NULL, subset = NULL, na.action =
na.fail)  { # but you will have Day, Month, Year, data
#  instead of the first three
    if(is.null(data)) data <- sys.frame(sys.parent())
    mf <- match.call()
    mf$data <- NULL
    mf$subset <- NULL
    mf$na.action <- NULL
    mf[[1]] <- as.name("data.frame")
    mf <- eval(mf, data)
    if(!is.null(subset)) mf <- mf[subset,]
    mf <- na.action(mf)
    p <- as.numeric(mf$p) # here you will have Day <- mf$Day and so on
    weights <- mf$weights

After this code (stolen from somewhere, it is definitely not original to
me) you will find that the variables you need (in my case p and weights)
have been found from data. So if your variables happen to be called
jour, mois and an you will then be able to write Day = jour, Month =
mois, Year = an, data = mesdonnees and have them picked up from your
data frame mesdonnees.

You do not need to attach data in this system and in general it is a bad
idea.


On 05/11/2014 08:34, Frederic Ntirenganya wrote:
> Dear PIKAL,
>
> I am using a data frame not a single value. I wanted to add a new column
> "DOY" on a dataset. I made it but I want to make it General. i.e. You will
> see in the dataset I am using columns names (Year,month and day.) What if I
> have this information in other columns names? In this function I will be
> pushed to change my columns names which I don't think it is a good idea.
> How can I make it in such away that I can use any column's name which
> contains the informations I want to use?
>
> In the previous comment this is what I mean saying a single date "single
> date column(ex:2009-08-02)"
>
> The following is the function and head-tail of the data after running the
> function.
>
>
> library(lubridate)
> DOY=function(data){
>     attach(data)
> #=================================================================
> #This function create day of teh year from a single date
> column(ex:2009-08-02) or/and
> #from the date in 3 columns (Year, month, Day).
> #================================================================
> if (is.data.frame(data)) { # check if the data is a dataframe
>    dt1=yday(as.Date(paste(Year, Month, Day,sep="-")))
>    # check if the year is leap or not.
>    datelp= dt1>59 & !leap_year(year(as.Date(paste(Year,Month, Day,sep="-"))))
>    datelp[is.na(datelp)]=FALSE
>    dt1[datelp]=dt1[datelp]+1 # add one for non leap_year
>    data2=cbind(data, dt1) # combining columns of data
>    n<-ncol(data)
>    colnames(data2)[n+1] = "DOY"
> }
>    data2
> }
>
> head(DOY(Kitale))
>
>    Year Month Day Rain DOY
> 1 1979     1   1    0   1
> 2 1979     1   2    0   2
> 3 1979     1   3    0   3
> 4 1979     1   4    0   4
> 5 1979     1   5    0   5
> 6 1979     1   6    0   6
>
> tail(DOY(Kitale))
>
>       Year Month Day Rain DOY
> 11315 2009    12  26 40.7 361
> 11316 2009    12  27 13.6 362
> 11317 2009    12  28 42.2 363
> 11318 2009    12  29 53.6 364
> 11319 2009    12  30 19.8 365
> 11320 2009    12  31  0.5 366
>
> Thanks for the help.
> Regards,
> Frederic.
>
>
>
>
>
>
>
>
>
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Nov 4, 2014 at 6:55 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> You want a function with input of either single value or a data frame?
>> This is very strange. One option is to make a method for function but it is
>> quite beyond my capabilities and it is used by "professional" developers.
>>
>> methods(c) or methods(plot)
>>
>> So you need to set method for your function DOY something like
>>
>> DOY.single_value and DOY.data.frame
>>
>> Anyway
>>
>> Function yday takes some value in time/date format regardless it is single
>> value or a vector, so the problem is how do you want your function to work
>> and more importantly how general you want it. I simple case you need to
>> check if data is single value or data frame.
>>
>> DOY=function(data){
>>
>> if (is.data.frame(data)) {
>>
>> do stuff for data frame} else {
>>
>> do stuff for single value}
>>
>> return something
>>
>> }
>>
>> Other comments see in line
>>
>>>>    data$Rain=as.numeric(as.character(data$Rain))
>>>>>    dt=yday(data$Date) # single date of the data
>>
>> If data is data frame dt shall be vector uf numbers not a single date
>>
>>>>>    datelp= dt>59 & !leap_year(data$Date)# tell us that the date
>>
>> datelp is (maybe) a logical vector with the same length as dt
>>
>>> occurs
>>>>> during a leap year
>>>>>    dt[datelp]=dt[datelp]+1 # add one for non leap_year
>>
>> Why you do this?
>> dt<-1:365 # e.g. length is 365
>> datelp<-dt>59 # logical vector
>>
>>
>> dt[datelp]<-dt[datelp]+1 # change all numbers greater than 59
>> dt
>>    [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
>> 18
>>   [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
>> 36
>>   [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
>> 54
>>   [55]  55  56  57  58  59  61  62  63  64  65  66  67  68  69  70  71  72
>> 73
>>                         ^^^^^^
>> now you have day 60 missing
>>
>>   [73]  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90
>> 91
>>   [91]  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108
>> 109
>> [109] 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126
>> 127
>> [127] 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144
>> 145
>> [145] 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162
>> 163
>> [163] 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180
>> 181
>> [181] 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198
>> 199
>> [199] 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216
>> 217
>> [217] 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234
>> 235
>> [235] 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252
>> 253
>> [253] 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270
>> 271
>> [271] 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288
>> 289
>> [289] 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306
>> 307
>> [307] 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324
>> 325
>> [325] 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342
>> 343
>> [343] 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360
>> 361
>> [361] 362 363 364 365 366
>>
>> But length of dt stays the same
>>   length(dt)
>> [1] 365
>>
>> Cheers
>> Petr
>>
>>>>>    cbind(data, dt) # combining columns of data
>>>>>    conames(data)="DOY" # name of new column. ??I have a problem on
>>> how
>>>>> I can precise the column in gerenal.
>>>>> }
>>>>>
>>>>>
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>> project.org] On Behalf Of Frederic Ntirenganya
>>> Sent: Tuesday, November 04, 2014 1:31 PM
>>> To: daniel
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Function that create day of the year column.
>>>
>>> Hi Daniel,
>>>
>>> How can I add an if conditiopn or for loop to implement this in my
>>> function?
>>>
>>> ex: option1 : single date
>>>       option2: date in 3 columns (year,moth,day)
>>>
>>> yday(Sys.Date())
>>> yday(as.Date(paste(y,m,d,sep="-")))
>>>
>>> Regards,
>>> Frederic.
>>>
>>>
>>> Frederic Ntirenganya
>>> Maseno University,
>>> African Maths Initiative,
>>> Kenya.
>>> Mobile:(+254)718492836
>>> Email: fredo at aims.ac.za
>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>
>>> On Tue, Nov 4, 2014 at 3:20 PM, daniel <daniel319 at gmail.com> wrote:
>>>
>>>> Frederic,
>>>>
>>>> Check the lubridate library.
>>>>
>>>> install.packages("lubridate")
>>>> library(lubridate)
>>>> yday(Sys.Date())
>>>> d <- 4
>>>> m <- 11
>>>> y <- 2014
>>>> yday(as.Date(paste(y,m,d,sep="-")))
>>>>
>>>> Daniel Merino
>>>>
>>>> 2014-11-04 7:01 GMT-03:00 Frederic Ntirenganya <ntfredo at gmail.com>:
>>>>
>>>>> Dear All,
>>>>>
>>>>> I would like to make a function that create Day of the year column
>>> in
>>>>> a dataset.
>>>>> State of the problem: write a function that create a day column
>>>>> either from a single date column (string/or factors) or from date in
>>>>> 3 columns (year, month, day).
>>>>>
>>>>> I made the following function for a single date. I would like to add
>>>>> a condition for date in 3 columns (year, month, day). My data is
>>>>> daily climate data.
>>>>> #write a function that create a day column either from a single date
>>>>> column (string/or factors) #or from date in 3 columns (year, month,
>>>>> day).
>>>>>
>>>>> DOY=function(data){
>>>>>
>>>>> #=================================================================
>>>>> #This function create day of teh year from a single date
>>>>> column(ex:2009-08-02) or/and
>>>>> #from the date in 3 columns (Year, month, Day).
>>>>> #================================================================
>>>>>    data$Rain=as.numeric(as.character(data$Rain))
>>>>>    dt=yday(data$Date) # single date of the data
>>>>>    datelp= dt>59 & !leap_year(data$Date)# tell us that the date
>>> occurs
>>>>> during a leap year
>>>>>    dt[datelp]=dt[datelp]+1 # add one for non leap_year
>>>>>    cbind(data, dt) # combining columns of data
>>>>>    conames(data)="DOY" # name of new column. ??I have a problem on
>>> how
>>>>> I can precise the column in gerenal.
>>>>> }
>>>>>
>>>>> ex: year  month day   Date         Rain Tmin Tmax
>>>>>        1971   1         1    1971-01-01   0     8.2  15
>>>>>         1971  1         2    1971-01-02   0     4.2  11
>>>>>          .        .          .       .               .      .      .
>>>>>          .        .          .       .               .      .      .
>>>>>          .        .          .       .               .      .      .
>>>>>
>>>>> Any ideal on how I can make this function is welcome. thanks!
>>>>> Frederic Ntirenganya
>>>>> Maseno University,
>>>>> African Maths Initiative,
>>>>> Kenya.
>>>>> Mobile:(+254)718492836
>>>>> Email: fredo at aims.ac.za
>>>>> https://sites.google.com/a/aims.ac.za/fredo/
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Daniel
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5557 / Virus Database: 4189/8514 - Release Date: 11/05/14
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From silvano at uel.br  Wed Nov  5 14:15:28 2014
From: silvano at uel.br (silvano)
Date: Wed, 5 Nov 2014 11:15:28 -0200
Subject: [R] Differences between MTDFReml and kinship2
Message-ID: <4457FCCD5105461280E13F7B9F391D2F@uelHP>

Hi,

I fitted a genetic model using kinship2 and I compared it with MTDFReml program output.

The residual variance of both are very close but the genetic variance are very differents.

The output are:

MTDFReml:
genetic variance = 1.24015
residual variance = 5.93424

R (Kinship2):
genetic variance = 0.767187
residual variance = 5.6712

Both of them use REML method. Could someone tell why the difference?

Thanks a lot,

Silvano.
	[[alternative HTML version deleted]]


From therneau at mayo.edu  Wed Nov  5 14:50:25 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 05 Nov 2014 07:50:25 -0600
Subject: [R] cluster + tt terms in coxph
In-Reply-To: <mailman.27.1415185208.18362.r-help@r-project.org>
References: <mailman.27.1415185208.18362.r-help@r-project.org>
Message-ID: <31062c$9bbqlq@ironport10.mayo.edu>

This is fixed in version 2.37-8 of the survival package, which has been in my "send to 
CRAN real-soon-now" queue for 6 months.  Your note is a prod to get it done.  I've been 
updating and adding vignettes.

Terry Therneau


On 11/05/2014 05:00 AM, r-help-request at r-project.org wrote:
> I am receiving the following error when trying to include both tt (time transforms) and frailty terms in coxph
>
>> >coxph(Surv(time, status) ~ ph.ecog + tt(age)+cluster(sex), data=lung,
> +      tt=function(x,t,...) pspline(x + t/365.25))
> Error in residuals.coxph(fit2, type = "dfbeta", collapse = cluster, weighted = TRUE) :
>    Wrong length for 'collapse'
>
> I tried both 64 bit (R.3.1.0) and 32 bit (R.3.1.2) in Windows 7 64bit and get the same errors
>
> Inclusion of tt and cluster terms worked fine in R2.9.2-2.15.1 under Windows Vista 32 bit and Ubuntu 64 bit
>
> Any ideas?


From roger.bos at rothschild.com  Wed Nov  5 16:44:16 2014
From: roger.bos at rothschild.com (Bos, Roger)
Date: Wed, 5 Nov 2014 15:44:16 +0000
Subject: [R] better two column output from rmarkdown
Message-ID: <0765308CD028654885F30322557308D81ED3DC31@NYCSM0208.rth.ad.rothschild.com>

Disclaimer: This question is more about HTML than R, but since I am using rmarkdown, I am not sure of a better forum to ask this.  The code example below produces two column HTML output.  If you run the example you will see that the "bbbb" paragram starts off at the bottom of the first column and wraps around to the top of the second column.  I am wondering if there is a HTML tag or anything so I can keep the "bbbb" section together and not have it wrap to the next column.  Also, if you know of a better way to create two column output, I would be happy hear that as well.  I have placed the CSS inside the .Rmd file to make it easier to run.

library(rmarkdown)
render('example.Rmd')


example.Rmd file:
---
output:
  html_document:
    theme: readable
    highlight: null
    css: null
    fig_width: 1
    fig_height: 1
    fig_caption: true

---
<style type="text/css">
#TEST {
       -moz-column-count: 2;
       -moz-column-gap: 20px;
       -webkit-column-count: 2;
       -webkit-column-gap: 20px;
}
</style>

```{r test, eval=TRUE, echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}

aa <- paste(rep('aaaaa', 49), collapse=" ")
bb <- paste(rep('bbbb', 49), collapse=" ")
cc <- paste(rep('ccc', 49), collapse=" ")
dd <- paste(rep('dd', 49), collapse=" ")
ee <- paste(rep('e', 49), collapse=" ")
```

### TEST ### {#TEST}
`r aa`

`r bb`

`r cc`

`r dd`

`r ee`



***************************************************************
This message and any attachments are for the named person's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies. You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.



From nmo_138 at usc.edu  Wed Nov  5 14:41:15 2014
From: nmo_138 at usc.edu (Noha Osman)
Date: Wed, 5 Nov 2014 13:41:15 +0000
Subject: [R] loops in R
Message-ID: <1415194874494.80290@usc.edu>

Hi Folks

Iam  a new user of R and I have a question . Hopefully anyone help me in that issue


I have that dataset as following

 Sample      Population  Species  Tissue         R         G        B
1 Bari1_062-1      Bari1     ret   seed  94.52303  80.70346 67.91760
2 Bari1_062-2      Bari1     ret   seed  98.27683  82.68690 68.55485
3 Bari1_062-3      Bari1     ret   seed 100.53170  86.56411 73.27528
4 Bari1_062-4      Bari1     ret   seed  96.65940  84.09197 72.05974
5 Bari1_062-5      Bari1     ret   seed 117.62474  98.49354 84.65656
6 Bari1_063-1      Bari1     ret   seed 144.39547 113.76170 99.95633

and I have 20 populations as following

[1] Bari1      Bari2      Bari3      Besev      Cermik     Cudi       Derici     Destek     Egil
[10] Gunasan    Kalkan     Karabace   Kayatepe   Kesentas   Ortanca    Oyali      Cultivated Sarikaya
[19] Savur      Sirnak

I need to calculate mean and variance of each population using column [R] using  for-loop


Thanks

	[[alternative HTML version deleted]]


From javlacalle at yahoo.es  Wed Nov  5 15:33:41 2014
From: javlacalle at yahoo.es (=?UTF-8?Q?Javier_L=C3=B3pez-de-Lacalle?=)
Date: Wed, 5 Nov 2014 14:33:41 +0000 (UTC)
Subject: [R] Function StructTS: covariance matrix of the initial state vector
Message-ID: <432788423.910337.1415198021716.JavaMail.yahoo@jws11133.mail.ir2.yahoo.com>

Hi everyone:

My question is about the function "StructTS" of the core package "stats", which fits by maximum likelihood the basic structural time series model.

According to theory and the references given in "?StructTS", the covariance matrix of the initial state vector is a diagonal matrix. However, in "StructTS" it is defined as a matrix containing the same value in the diagonal and off-diagonal elements of the matrix. The matrix is defined as follows in "StructTS":

Z$P[] <- 1e+06 * vx

Does anybody know why is this matrix defined as non-diagonal? May it be some kind of diffuse initialization? That's not the way I understand it in textbooks though, as it still involves diagonal matrices.

I thought it may be a bug in the code. However, as "StructTS" has been defined in this way for years and as the documentation claims that the result for the "AirPassengers" data is superior to the results reported in other source, I wondered whether there may be a reason to use a non-diagonal matrix.

I used the package "stsm" [http://cran.r-project.org/package=stsm] to compare some results based on a non-diagonal and a diagonal initial covariance matrix.

# original result obtained with StructTS
res0 <- stats::StructTS(log(AirPassengers), type = "BSM")
res0
# Variances:
#     level      slope       seas    epsilon 
# 0.0007719  0.0000000  0.0013969  0.0000000 

# StructTS can be replicated using the interface in package "stsm" as follows
require("stsm")
mairp <- stsm.model(model = "BSM", y = log(AirPassengers), transPars = "StructTS")
res1 <- maxlik.td.optim(mairp, KF.version = "KFKSDS",
KF.args = list(P0cov = TRUE), method = "L-BFGS-B")
mairp1 <- set.pars(mairp, pmax(res1$par, .Machine$double.eps))
round(get.pars(mairp1)[c(4,1:3)], 7)
#      var4      var1      var2      var3
# 0.0013969 0.0000000 0.0007719 0.0000000
all.equal(get.pars(mairp1), res0$coef[c(4,1:3)],
tol = 1e-04, check.attributes = FALSE)
# [1] TRUE

# next, the likelihood function and the optimization procedure
# are defined as in StructTS except for Z$P, which is now a diagonal matrix
res2 <- maxlik.td.optim(mairp, KF.version = "KFKSDS",
KF.args = list(P0cov = FALSE), method = "L-BFGS-B")
mairp2 <- set.pars(mairp, pmax(res2$par, .Machine$double.eps))
round(get.pars(mairp2)[c(4,1:3)], 7)
#      var4      var1      var2      var3
# 0.0000642 0.0001293 0.0006995 0.0000000

The results imply a different allocation of the variance across the components, as reflected by these ratios:

round(get.pars(mairp1)[-4]/get.pars(mairp1)[4], 3)
#  var1  var2  var3
# 0.000 0.553 0.000
round(get.pars(mairp2)[-4]/get.pars(mairp2)[4], 3)
#  var1   var2   var3
# 2.014 10.898  0.000

The estimated seasonal component for the modified "StructTS" version (i.e., the standard approach using a diagonal matrix) looks better, because the range is more homogeneous.

ss2 <- char2numeric(mairp2, P0cov = FALSE)
kf2 <- KFKSDS::KF(mairp1 at y, ss2)
ks2 <- KFKSDS::KS(mairp1 at y, ss2, kf2)
par(mfcol = c(2,2), mar = c(2.5,5.1,3,2.1))
plot(tsSmooth(res0)[,1], main = "StructTS", ylab = "level")
plot(tsSmooth(res0)[,3], ylab = "seasonal")
plot(ks2$ahat[,1], main = "Modified StructTS", ylab = "level")
plot(ks2$ahat[,3], ylab = "seasonal") 

[image in attachment airp1.pdf]

Yet, I am still doubtful whether this is a bug or intentional. In some cases, I have found it useful to use P0cov=TRUE (non-diagonal matrix) when the likelihood function is evaluated by the optimization algorithm. Then, given the parameter estimates, the smoothed components can be extracted setting P0cov=FALSE (diagonal matrix) in the Kalman smoother, in order to avoid the erratic behaviour at the beginning of the sample observed in the plot above. See for example my answer in this post [http://stats.stackexchange.com/questions/115506/forecasting-a-seasonal-time-series-in-r].


I wonder if this qualifies as a bug or if there is a reason that explains the non-diagonal matrix used in "StructTS". I would be grateful for some feedback.

Thanks.

--
javi 
http://jalobe.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: airp1.pdf
Type: application/pdf
Size: 43816 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141105/2a470a8a/attachment.pdf>

From dmck at u.washington.edu  Wed Nov  5 19:02:11 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 5 Nov 2014 10:02:11 -0800
Subject: [R] loops in R
In-Reply-To: <1415194874494.80290@usc.edu>
References: <1415194874494.80290@usc.edu>
Message-ID: <CAEC1983-7632-49BB-8542-65502F9A1D96@u.washington.edu>

Have you read the tutorial that comes with the R distribution?  This is a very basic database calculation that you will
encounter (or some slight variation of it) over and over.  The solution is a few lines of code, and someone may write it 
out for you, but if no one does

You have 20 populations, so you will have 20 iterations in your for loop. For each one, you will need a unique identifier that points to
the rows of ?R? associated with that population. You?ll calculate a mean and variance 20 times, and will need a data object to store
those calculations. 

Look in the tutorial for syntax for identifying subsets of your data frame.

> On Nov 5, 2014, at 5:41 AM, Noha Osman <nmo_138 at usc.edu> wrote:
> 
> Hi Folks
> 
> Iam  a new user of R and I have a question . Hopefully anyone help me in that issue
> 
> 
> I have that dataset as following
> 
> Sample      Population  Species  Tissue         R         G        B
> 1 Bari1_062-1      Bari1     ret   seed  94.52303  80.70346 67.91760
> 2 Bari1_062-2      Bari1     ret   seed  98.27683  82.68690 68.55485
> 3 Bari1_062-3      Bari1     ret   seed 100.53170  86.56411 73.27528
> 4 Bari1_062-4      Bari1     ret   seed  96.65940  84.09197 72.05974
> 5 Bari1_062-5      Bari1     ret   seed 117.62474  98.49354 84.65656
> 6 Bari1_063-1      Bari1     ret   seed 144.39547 113.76170 99.95633
> 
> and I have 20 populations as following
> 
> [1] Bari1      Bari2      Bari3      Besev      Cermik     Cudi       Derici     Destek     Egil
> [10] Gunasan    Kalkan     Karabace   Kayatepe   Kesentas   Ortanca    Oyali      Cultivated Sarikaya
> [19] Savur      Sirnak
> 
> I need to calculate mean and variance of each population using column [R] using  for-loop
> 
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Faculty
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From djnordlund at frontier.com  Wed Nov  5 19:12:33 2014
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Wed, 05 Nov 2014 10:12:33 -0800
Subject: [R] loops in R
In-Reply-To: <1415194874494.80290@usc.edu>
References: <1415194874494.80290@usc.edu>
Message-ID: <545A6891.7060209@frontier.com>

On 11/5/2014 5:41 AM, Noha Osman wrote:
> Hi Folks
>
> Iam  a new user of R and I have a question . Hopefully anyone help me in that issue
>
>
> I have that dataset as following
>
>   Sample      Population  Species  Tissue         R         G        B
> 1 Bari1_062-1      Bari1     ret   seed  94.52303  80.70346 67.91760
> 2 Bari1_062-2      Bari1     ret   seed  98.27683  82.68690 68.55485
> 3 Bari1_062-3      Bari1     ret   seed 100.53170  86.56411 73.27528
> 4 Bari1_062-4      Bari1     ret   seed  96.65940  84.09197 72.05974
> 5 Bari1_062-5      Bari1     ret   seed 117.62474  98.49354 84.65656
> 6 Bari1_063-1      Bari1     ret   seed 144.39547 113.76170 99.95633
>
> and I have 20 populations as following
>
> [1] Bari1      Bari2      Bari3      Besev      Cermik     Cudi       Derici     Destek     Egil
> [10] Gunasan    Kalkan     Karabace   Kayatepe   Kesentas   Ortanca    Oyali      Cultivated Sarikaya
> [19] Savur      Sirnak
>
> I need to calculate mean and variance of each population using column [R] using  for-loop
>
>
> Thanks
>

You don't want to use loops here, but rather some vectorized function. 
One possibility is some thing like the following:

with(your_data_frame,aggregate(R,list(Population), mean))
with(your_data_frame,aggregate(R,list(Population), var))

hope this is helpful,

Dan

Daniel Nordlund
Bothell, WA  USA


From lianoglou.steve at gene.com  Wed Nov  5 19:18:46 2014
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Wed, 5 Nov 2014 10:18:46 -0800
Subject: [R] loops in R
In-Reply-To: <CAEC1983-7632-49BB-8542-65502F9A1D96@u.washington.edu>
References: <1415194874494.80290@usc.edu>
	<CAEC1983-7632-49BB-8542-65502F9A1D96@u.washington.edu>
Message-ID: <CAHA9McOtvunwZ1rshtpJo_s1RMsR+Lmtm6xLQeSD2CzWdpLEUw@mail.gmail.com>

While you should definitely read the tutorial that Don is referring
to, I'd recommend you take a different approach and use more R
idiomatic code here.

In base R, this could be addressed with few approaches. Look for help
on the following functions:

  * tapply
  * by
  * aggregate

I'd rather recommend you also learn about some of the packages that
are better suited to deal with computing over data.frames,
particularly:

  * dplyr
  * data.table

You can certainly achieve what you want with for loops, but you'll
likely find that going this route will be more rewarding in the long
run.

HTH,
-steve


On Wed, Nov 5, 2014 at 10:02 AM, Don McKenzie <dmck at u.washington.edu> wrote:
> Have you read the tutorial that comes with the R distribution?  This is a very basic database calculation that you will
> encounter (or some slight variation of it) over and over.  The solution is a few lines of code, and someone may write it
> out for you, but if no one does
>
> You have 20 populations, so you will have 20 iterations in your for loop. For each one, you will need a unique identifier that points to
> the rows of "R" associated with that population. You'll calculate a mean and variance 20 times, and will need a data object to store
> those calculations.
>
> Look in the tutorial for syntax for identifying subsets of your data frame.
>
>> On Nov 5, 2014, at 5:41 AM, Noha Osman <nmo_138 at usc.edu> wrote:
>>
>> Hi Folks
>>
>> Iam  a new user of R and I have a question . Hopefully anyone help me in that issue
>>
>>
>> I have that dataset as following
>>
>> Sample      Population  Species  Tissue         R         G        B
>> 1 Bari1_062-1      Bari1     ret   seed  94.52303  80.70346 67.91760
>> 2 Bari1_062-2      Bari1     ret   seed  98.27683  82.68690 68.55485
>> 3 Bari1_062-3      Bari1     ret   seed 100.53170  86.56411 73.27528
>> 4 Bari1_062-4      Bari1     ret   seed  96.65940  84.09197 72.05974
>> 5 Bari1_062-5      Bari1     ret   seed 117.62474  98.49354 84.65656
>> 6 Bari1_063-1      Bari1     ret   seed 144.39547 113.76170 99.95633
>>
>> and I have 20 populations as following
>>
>> [1] Bari1      Bari2      Bari3      Besev      Cermik     Cudi       Derici     Destek     Egil
>> [10] Gunasan    Kalkan     Karabace   Kayatepe   Kesentas   Ortanca    Oyali      Cultivated Sarikaya
>> [19] Savur      Sirnak
>>
>> I need to calculate mean and variance of each population using column [R] using  for-loop
>>
>>
>> Thanks
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Faculty
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Steve Lianoglou
Computational Biologist
Genentech


From bhh at xs4all.nl  Wed Nov  5 20:24:55 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 5 Nov 2014 20:24:55 +0100
Subject: [R] loops in R
In-Reply-To: <1415194874494.80290@usc.edu>
References: <1415194874494.80290@usc.edu>
Message-ID: <9269E6EB-9C8D-4AFE-8057-E63F0068D9F4@xs4all.nl>


On 05-11-2014, at 14:41, Noha Osman <nmo_138 at usc.edu> wrote:

> Hi Folks
> 
> Iam  a new user of R and I have a question . Hopefully anyone help me in that issue
> 
> 
> I have that dataset as following
> 
> Sample      Population  Species  Tissue         R         G        B
> 1 Bari1_062-1      Bari1     ret   seed  94.52303  80.70346 67.91760
> 2 Bari1_062-2      Bari1     ret   seed  98.27683  82.68690 68.55485
> 3 Bari1_062-3      Bari1     ret   seed 100.53170  86.56411 73.27528
> 4 Bari1_062-4      Bari1     ret   seed  96.65940  84.09197 72.05974
> 5 Bari1_062-5      Bari1     ret   seed 117.62474  98.49354 84.65656
> 6 Bari1_063-1      Bari1     ret   seed 144.39547 113.76170 99.95633
> 
> and I have 20 populations as following
> 
> [1] Bari1      Bari2      Bari3      Besev      Cermik     Cudi       Derici     Destek     Egil
> [10] Gunasan    Kalkan     Karabace   Kayatepe   Kesentas   Ortanca    Oyali      Cultivated Sarikaya
> [19] Savur      Sirnak
> 
> I need to calculate mean and variance of each population using column [R] using  for-loop

If I?m correct you asked an almost identical question Stackoverflow (http://stackoverflow.com/questions/26742023/how-can-i-use-loops-in-r).

You got all the answers you need.

Berend


From macqueen1 at llnl.gov  Wed Nov  5 22:01:36 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 5 Nov 2014 21:01:36 +0000
Subject: [R] Function that create day of the year column.
In-Reply-To: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
References: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
Message-ID: <D07FCDF1.1115DA%macqueen1@llnl.gov>

I would start with this example, which is available from base R, without
additional packages, to help understand the suggestions that follow.

> unclass(as.POSIXlt(Sys.Date()))
$sec
[1] 0

$min
[1] 0

$hour
[1] 0

$mday
[1] 5

$mon
[1] 10

$year
[1] 114

$wday
[1] 3

$yday
[1] 308

$isdst
[1] 0

attr(,"tzone")
[1] "UTC"

And then see the $yday element

For example:


>   as.POSIXlt( as.Date('2014-9-13') )$yday
[1] 255
>   as.POSIXlt( as.Date('2014-1-1') )$yday
[1] 0

Note that the year starts with day 0, which might not be what you expect.

If you have three columns try
  as.POSIXlt( as.Date( paste(year, month, day, sep='-') )$yday


Which can be illustrated by
>   as.POSIXlt( as.Date( paste(2014, 1, 31, sep='-') ) )$yday
[1] 30

If your ?date? column is already of class Date
   > class(Sys.Date())
   [1] "Date"

then
  as.POSIXlt( date )$yday
is sufficient. Otherwise you have to convert it to Date class.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/4/14, 2:01 AM, "Frederic Ntirenganya" <ntfredo at gmail.com> wrote:

>Dear All,
>
>I would like to make a function that create Day of the year column in a
>dataset.
>State of the problem: write a function that create a day column either
>from
>a single date column (string/or factors) or from date in 3 columns (year,
>month, day).
>
>I made the following function for a single date. I would like to add a
>condition for date in 3 columns (year, month, day). My data is daily
>climate data.
>#write a function that create a day column either from a single date
>column
>(string/or factors)
>#or from date in 3 columns (year, month, day).
>
>DOY=function(data){
>
>#=================================================================
>#This function create day of teh year from a single date
>column(ex:2009-08-02) or/and
>#from the date in 3 columns (Year, month, Day).
>#================================================================
>  data$Rain=as.numeric(as.character(data$Rain))
>  dt=yday(data$Date) # single date of the data
>  datelp= dt>59 & !leap_year(data$Date)# tell us that the date occurs
>during a leap year
>  dt[datelp]=dt[datelp]+1 # add one for non leap_year
>  cbind(data, dt) # combining columns of data
>  conames(data)="DOY" # name of new column. ??I have a problem on how I
>can
>precise the column in gerenal.
>}
>
>ex: year  month day   Date         Rain Tmin Tmax
>      1971   1         1    1971-01-01   0     8.2  15
>       1971  1         2    1971-01-02   0     4.2  11
>        .        .          .       .               .      .      .
>        .        .          .       .               .      .      .
>        .        .          .       .               .      .      .
>
>Any ideal on how I can make this function is welcome. thanks!
>Frederic Ntirenganya
>Maseno University,
>African Maths Initiative,
>Kenya.
>Mobile:(+254)718492836
>Email: fredo at aims.ac.za
>https://sites.google.com/a/aims.ac.za/fredo/
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Nov  5 23:35:37 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 05 Nov 2014 17:35:37 -0500
Subject: [R] Function that create day of the year column.
In-Reply-To: <D07FCDF1.1115DA%macqueen1@llnl.gov>
References: <CAGh51gT2CdqR59Rfu4Lbn3pm+_tS9vcPR2qVbUBZmCdnrGtQ8Q@mail.gmail.com>
	<D07FCDF1.1115DA%macqueen1@llnl.gov>
Message-ID: <DEDCF070-BF34-4596-A358-1ADA2B1278D9@dcn.davis.CA.us>

Beware of Sys.Date, since it returns GMT, so depending on your local timezone you may be surprised by the result. I prefer to explicitly set the TZ environment variable and use Sys.time to get local time. You can use trunc() to chop off the time part.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 5, 2014 4:01:36 PM EST, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>I would start with this example, which is available from base R,
>without
>additional packages, to help understand the suggestions that follow.
>
>> unclass(as.POSIXlt(Sys.Date()))
>$sec
>[1] 0
>
>$min
>[1] 0
>
>$hour
>[1] 0
>
>$mday
>[1] 5
>
>$mon
>[1] 10
>
>$year
>[1] 114
>
>$wday
>[1] 3
>
>$yday
>[1] 308
>
>$isdst
>[1] 0
>
>attr(,"tzone")
>[1] "UTC"
>
>And then see the $yday element
>
>For example:
>
>
>>   as.POSIXlt( as.Date('2014-9-13') )$yday
>[1] 255
>>   as.POSIXlt( as.Date('2014-1-1') )$yday
>[1] 0
>
>Note that the year starts with day 0, which might not be what you
>expect.
>
>If you have three columns try
>  as.POSIXlt( as.Date( paste(year, month, day, sep='-') )$yday
>
>
>Which can be illustrated by
>>   as.POSIXlt( as.Date( paste(2014, 1, 31, sep='-') ) )$yday
>[1] 30
>
>If your ?date? column is already of class Date
>   > class(Sys.Date())
>   [1] "Date"
>
>then
>  as.POSIXlt( date )$yday
>is sufficient. Otherwise you have to convert it to Date class.


From kawasima.m at jp.fujitsu.com  Thu Nov  6 05:50:49 2014
From: kawasima.m at jp.fujitsu.com (Kawashima, Masayuki)
Date: Thu, 6 Nov 2014 04:50:49 +0000
Subject: [R] limit of cmdscale function
Message-ID: <E673DB2DA8BABB4C9DBAF835C3DB54F809C7125E@g01jpexmbkw22>

Hi

We have a few questions regarding the use of the "isoMDS" function.

When we run "isoMDS" function using 60,000 x 60,000 data matrix, 
we get the following error message:

------------------------------------
cmdscale(d, k) : invalid value of 'n'
Calls: isoMDS -> cmdscale
------------------------------------

We checked the source code of "cmdscale" and found the following limitation:
------------------------------------
## we need to handle nxn internally in dblcen
if(is.na(n) || n > 46340) stop("invalid value of 'n'")
------------------------------------

1. This cmdscale limitation ('n > 46340') is due to the limitation of BLAS and LAPACK variables(int4) which can only handle '2^31-1' amount of data?

2. Is there any workaround to run isoMDS using large data (i.e. greater than 46340)?
   We would like to run isoMDS using a maximum of 150,000x150,000 data matrix.

Best regards

Masayuki Kawashima
Email: kawasima.m at jp.fujitsu.com


From katherine_gobin at yahoo.com  Thu Nov  6 07:04:59 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Thu, 6 Nov 2014 14:04:59 +0800
Subject: [R] VGAM package : Frechet distribution - 2 parameter estimation
Message-ID: <1415253899.16934.YahooMailNeo@web193306.mail.sg3.yahoo.com>

Dear R forum,

I am trying to execute following code (Page no 259 - VGAM.pdf)

# .........................................................................................................................

library(VGAM)

set.seed(123)
fdata <- data.frame(y1 = rfrechet(nn <- 1000, shape = 2 + exp(1)))
with(fdata, hist(y1))
fit2 <- vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE)

# .........................................................................................................................


However, I receive following error 

Error in vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE) : 
  object 'frechet' not found


Earlier there used to be a function called "frechet3" which I guess has been withdrawn by VGAM. 

Kindly guide 

Katherine
	[[alternative HTML version deleted]]


From paula.isomarkku at gmail.com  Thu Nov  6 08:26:39 2014
From: paula.isomarkku at gmail.com (Paula Iso-Markku)
Date: Thu, 6 Nov 2014 09:26:39 +0200
Subject: [R] Time dependant covariate
Message-ID: <CA+8SW_PvZoZvLZxk_j6GBm7xWiik_NATC7kA-9mpSWyryAQRRw@mail.gmail.com>

Hello,

Can I get help? I have the attached kind of material and I should create a
time-dependant covariate from the variate "Optime"? I have tried using
survsplit function but I don't know exactly how to do it. Or I can't get it
to work. How can I split every id's follow-up time into two rows according
the time of optime (The time they get treatment)?

Best regards,
Paula Iso-Markku
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Time-dep.PNG
Type: image/png
Size: 17177 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141106/7ea76292/attachment.png>

From info at aghmed.fsnet.co.uk  Thu Nov  6 10:24:58 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 06 Nov 2014 09:24:58 +0000
Subject: [R] VGAM package : Frechet distribution - 2 parameter estimation
In-Reply-To: <1415253899.16934.YahooMailNeo@web193306.mail.sg3.yahoo.com>
References: <1415253899.16934.YahooMailNeo@web193306.mail.sg3.yahoo.com>
Message-ID: <545B3E6A.7060002@aghmed.fsnet.co.uk>



On 06/11/2014 06:04, Katherine Gobin wrote:
> Dear R forum,
>
> I am trying to execute following code (Page no 259 - VGAM.pdf)
>
> # .........................................................................................................................
>
> library(VGAM)
>
> set.seed(123)
> fdata <- data.frame(y1 = rfrechet(nn <- 1000, shape = 2 + exp(1)))
> with(fdata, hist(y1))
> fit2 <- vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE)
>
> # .........................................................................................................................
>

Is it not called frechet2?
>
> However, I receive following error
>
> Error in vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE) :
>    object 'frechet' not found
>
>
> Earlier there used to be a function called "frechet3" which I guess has been withdrawn by VGAM.
>
> Kindly guide
>
> Katherine
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5557 / Virus Database: 4189/8518 - Release Date: 11/05/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From katherine_gobin at yahoo.com  Thu Nov  6 10:34:41 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Thu, 6 Nov 2014 17:34:41 +0800
Subject: [R] VGAM package : Frechet distribution - 2 parameter estimation
In-Reply-To: <545B3E6A.7060002@aghmed.fsnet.co.uk>
References: <1415253899.16934.YahooMailNeo@web193306.mail.sg3.yahoo.com>
	<545B3E6A.7060002@aghmed.fsnet.co.uk>
Message-ID: <1415266481.31006.YahooMailNeo@web193304.mail.sg3.yahoo.com>

Dear Mr Michael,

Thanks a lot for your guidance. The pdf file describing VGAM package has mentioned 'frechet' in the example, so I got the error.

Regards
Katherine


On Thursday, 6 November 2014 2:54 PM, Michael Dewey <info at aghmed.fsnet.co.uk> wrote:
 




On 06/11/2014 06:04, Katherine Gobin wrote:
> Dear R forum,
>
> I am trying to execute following code (Page no 259 - VGAM.pdf)
>
> # .........................................................................................................................
>
> library(VGAM)
>
> set.seed(123)
> fdata <- data.frame(y1 = rfrechet(nn <- 1000, shape = 2 + exp(1)))
> with(fdata, hist(y1))
> fit2 <- vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE)
>
> # .........................................................................................................................
>

Is it not called frechet2?

>
> However, I receive following error
>
> Error in vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE) :
>    object 'frechet' not found
>
>
> Earlier there used to be a function called "frechet3" which I guess has been withdrawn by VGAM.
>
> Kindly guide
>
> Katherine
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5557 / Virus Database: 4189/8518 - Release Date: 11/05/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Nov  6 11:12:16 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 06 Nov 2014 23:12:16 +1300
Subject: [R] VGAM package : Frechet distribution - 2 parameter estimation
In-Reply-To: <1415266481.31006.YahooMailNeo@web193304.mail.sg3.yahoo.com>
References: <1415253899.16934.YahooMailNeo@web193306.mail.sg3.yahoo.com>	<545B3E6A.7060002@aghmed.fsnet.co.uk>
	<1415266481.31006.YahooMailNeo@web193304.mail.sg3.yahoo.com>
Message-ID: <545B4980.2060104@auckland.ac.nz>


Dear Ms. Gobin,

There would appear to be a typo in the package manual that appears on 
CRAN.  Doing ?Frechet (it would be nice to have this aliased also to 
"frechet") points you immediately to frechet.  With "frechet2" 
substituted for "frechet" your code, everything works.

cheers,

Rolf Turner

On 06/11/14 22:34, Katherine Gobin wrote:
> Dear Mr Michael,
>
> Thanks a lot for your guidance. The pdf file describing VGAM package has mentioned 'frechet' in the example, so I got the error.
>
> Regards
> Katherine
>
>
> On Thursday, 6 November 2014 2:54 PM, Michael Dewey <info at aghmed.fsnet.co.uk> wrote:
>
>
>
>
>
> On 06/11/2014 06:04, Katherine Gobin wrote:
>> Dear R forum,
>>
>> I am trying to execute following code (Page no 259 - VGAM.pdf)
>>
>> # .........................................................................................................................
>>
>> library(VGAM)
>>
>> set.seed(123)
>> fdata <- data.frame(y1 = rfrechet(nn <- 1000, shape = 2 + exp(1)))
>> with(fdata, hist(y1))
>> fit2 <- vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE)
>>
>> # .........................................................................................................................
>>
>
> Is it not called frechet2?
>
>>
>> However, I receive following error
>>
>> Error in vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE) :
>>     object 'frechet' not found
>>
>>
>> Earlier there used to be a function called "frechet3" which I guess has been withdrawn by VGAM.
>>
>> Kindly guide
>>
>> Katherine

-- 
Rolf Turner
Technical Editor ANZJS


From dcarlson at tamu.edu  Thu Nov  6 15:40:23 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 6 Nov 2014 14:40:23 +0000
Subject: [R] limit of cmdscale function
In-Reply-To: <E673DB2DA8BABB4C9DBAF835C3DB54F809C7125E@g01jpexmbkw22>
References: <E673DB2DA8BABB4C9DBAF835C3DB54F809C7125E@g01jpexmbkw22>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB05B0@mb02.ads.tamu.edu>

You avoid the call to cmdscale() by supplying your own starting configuration (see the manual page for the y= argument). You could still hit other barriers within isoMDS() or insufficient memory on your computer.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Kawashima, Masayuki
Sent: Wednesday, November 5, 2014 10:51 PM
To: r-help at r-project.org
Subject: [R] limit of cmdscale function

Hi

We have a few questions regarding the use of the "isoMDS" function.

When we run "isoMDS" function using 60,000 x 60,000 data matrix, 
we get the following error message:

------------------------------------
cmdscale(d, k) : invalid value of 'n'
Calls: isoMDS -> cmdscale
------------------------------------

We checked the source code of "cmdscale" and found the following limitation:
------------------------------------
## we need to handle nxn internally in dblcen
if(is.na(n) || n > 46340) stop("invalid value of 'n'")
------------------------------------

1. This cmdscale limitation ('n > 46340') is due to the limitation of BLAS and LAPACK variables(int4) which can only handle '2^31-1' amount of data?

2. Is there any workaround to run isoMDS using large data (i.e. greater than 46340)?
   We would like to run isoMDS using a maximum of 150,000x150,000 data matrix.

Best regards

Masayuki Kawashima
Email: kawasima.m at jp.fujitsu.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From matteo.richiardi at gmail.com  Thu Nov  6 15:47:12 2014
From: matteo.richiardi at gmail.com (Matteo Richiardi)
Date: Thu, 6 Nov 2014 15:47:12 +0100
Subject: [R] speed issue in simulating a stochastic process
Message-ID: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>

I wish to simulate the following stochastic process, for i = 1...N
individuals and t=1...T periods:

y_{i,t} = y_0 + lambda Ey_{t-1} + epsilon_{i,t}

where Ey_{t-1} is the average of y over the N individuals computed at time
t-1.

My solution (below) works but is incredibly slow. Is there a faster but
still clear and readable alternative?

Thanks a lot. Matteo

rm(list=ls())
library(plyr)
y0 = 0
lambda = 0.1
N = 20
T = 100
m_e = 0
sd_e = 1

# construct the data frame and initialize y
D = data.frame(
  id = rep(1:N,T),
  t = rep(1:T, each = N),
  y = rep(y0,N*T)
)

# update y
for(t in 2:T){
  ybar.L1 = mean(D[D$t==t-1,"y"])
  for(i in 1:N){
    epsilon = rnorm(1,mean=m_e,sd=sd_e)
    D[D$id==i & D$t==t,]$y = lambda*y0+(1-lambda)*ybar.L1+epsilon
  }
}

ybar <- ddply(D,~t,summarise,mean=mean(y))

plot(ybar, col = "blue", type = "l")

	[[alternative HTML version deleted]]


From tea3rd at gmail.com  Thu Nov  6 16:13:01 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Thu, 6 Nov 2014 08:13:01 -0700
Subject: [R] speed issue in simulating a stochastic process
In-Reply-To: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>
References: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>
Message-ID: <CAGxgkWgmV22VMe1J_f2LXK+GqWscBnp1Xp3sdx1a5KCfz3RsDA@mail.gmail.com>

Matteo,

I tried your example code using R 3.1.1 on an iMac (24-inch, Early 2009), 3.06
GHz Intel Core 2 Duo, 8 GB 1333 MHz DDR3, NVIDIA GeForce GT 130 512 MB
running Mac OS X 10.10 (Yosemite).

After entering your code, the elapsed time from the time I hit return to
when the graphics appeared was about 2 seconds ? is this about what you are
seeing?

Regards,
Tom



On Thu, Nov 6, 2014 at 7:47 AM, Matteo Richiardi <matteo.richiardi at gmail.com
> wrote:

> I wish to simulate the following stochastic process, for i = 1...N
> individuals and t=1...T periods:
>
> y_{i,t} = y_0 + lambda Ey_{t-1} + epsilon_{i,t}
>
> where Ey_{t-1} is the average of y over the N individuals computed at time
> t-1.
>
> My solution (below) works but is incredibly slow. Is there a faster but
> still clear and readable alternative?
>
> Thanks a lot. Matteo
>
> rm(list=ls())
> library(plyr)
> y0 = 0
> lambda = 0.1
> N = 20
> T = 100
> m_e = 0
> sd_e = 1
>
> # construct the data frame and initialize y
> D = data.frame(
>   id = rep(1:N,T),
>   t = rep(1:T, each = N),
>   y = rep(y0,N*T)
> )
>
> # update y
> for(t in 2:T){
>   ybar.L1 = mean(D[D$t==t-1,"y"])
>   for(i in 1:N){
>     epsilon = rnorm(1,mean=m_e,sd=sd_e)
>     D[D$id==i & D$t==t,]$y = lambda*y0+(1-lambda)*ybar.L1+epsilon
>   }
> }
>
> ybar <- ddply(D,~t,summarise,mean=mean(y))
>
> plot(ybar, col = "blue", type = "l")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nilsson.henric at gmail.com  Thu Nov  6 12:59:59 2014
From: nilsson.henric at gmail.com (Henric Winell)
Date: Thu, 06 Nov 2014 12:59:59 +0100
Subject: [R] cluster + tt terms in coxph
In-Reply-To: <31062c$9bbqlq@ironport10.mayo.edu>
References: <mailman.27.1415185208.18362.r-help@r-project.org>
	<31062c$9bbqlq@ironport10.mayo.edu>
Message-ID: <545B62BF.4040902@gmail.com>

On 2014-11-05 14:50, Therneau, Terry M., Ph.D. wrote:

> This is fixed in version 2.37-8 of the survival package, which has been
> in my "send to CRAN real-soon-now" queue for 6 months.  Your note is a
> prod to get it done.  I've been updating and adding vignettes.

Is your fixed code publicly available somewhere?  (The 'survival' 
repository at R-forge doesn't seem to have been updated since January.)

Henric Winell


>
> Terry Therneau
>
>
> On 11/05/2014 05:00 AM, r-help-request at r-project.org wrote:
>> I am receiving the following error when trying to include both tt
>> (time transforms) and frailty terms in coxph
>>
>>> >coxph(Surv(time, status) ~ ph.ecog + tt(age)+cluster(sex), data=lung,
>> +      tt=function(x,t,...) pspline(x + t/365.25))
>> Error in residuals.coxph(fit2, type = "dfbeta", collapse = cluster,
>> weighted = TRUE) :
>>    Wrong length for 'collapse'
>>
>> I tried both 64 bit (R.3.1.0) and 32 bit (R.3.1.2) in Windows 7 64bit
>> and get the same errors
>>
>> Inclusion of tt and cluster terms worked fine in R2.9.2-2.15.1 under
>> Windows Vista 32 bit and Ubuntu 64 bit
>>
>> Any ideas?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tea3rd at gmail.com  Thu Nov  6 17:42:43 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Thu, 6 Nov 2014 09:42:43 -0700
Subject: [R] speed issue in simulating a stochastic process
In-Reply-To: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>
References: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>
Message-ID: <CAGxgkWhW__M1ZhSnKd4=RVFEHPXzt=J-vkHaKs83mJggM5cAJg@mail.gmail.com>

Matteo,

Ah ? OK, N=20, I did not catch that. You have nested for loops, which R is
known to be exceedingly slow at handling ? if you can reorganize the code
to eliminate the loops, your performance will increase significantly.

Tom

On Thu, Nov 6, 2014 at 7:47 AM, Matteo Richiardi <matteo.richiardi at gmail.com
> wrote:

> I wish to simulate the following stochastic process, for i = 1...N
> individuals and t=1...T periods:
>
> y_{i,t} = y_0 + lambda Ey_{t-1} + epsilon_{i,t}
>
> where Ey_{t-1} is the average of y over the N individuals computed at time
> t-1.
>
> My solution (below) works but is incredibly slow. Is there a faster but
> still clear and readable alternative?
>
> Thanks a lot. Matteo
>
> rm(list=ls())
> library(plyr)
> y0 = 0
> lambda = 0.1
> N = 20
> T = 100
> m_e = 0
> sd_e = 1
>
> # construct the data frame and initialize y
> D = data.frame(
>   id = rep(1:N,T),
>   t = rep(1:T, each = N),
>   y = rep(y0,N*T)
> )
>
> # update y
> for(t in 2:T){
>   ybar.L1 = mean(D[D$t==t-1,"y"])
>   for(i in 1:N){
>     epsilon = rnorm(1,mean=m_e,sd=sd_e)
>     D[D$id==i & D$t==t,]$y = lambda*y0+(1-lambda)*ybar.L1+epsilon
>   }
> }
>
> ybar <- ddply(D,~t,summarise,mean=mean(y))
>
> plot(ybar, col = "blue", type = "l")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Nov  6 18:46:57 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 6 Nov 2014 09:46:57 -0800
Subject: [R] speed issue in simulating a stochastic process
In-Reply-To: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>
References: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>
Message-ID: <CAF8bMcYOjwHtr8Yf59WGvYDx=y=aRuhLbVw4k4jB1T3PHpVu+A@mail.gmail.com>

I find that representing the simulated data as a T row by N column matrix
allows for a clearer and faster simulation function.  E.g., compare the
output of the following two functions, the first of which uses your code
and the second a matrix representation (which I convert to a data.frame at
the end so I can compare outputs easily).  I timed both of them for T=10^3
times and N=50 individuals; both gave the same results and f1 was 10000
times faster than f0:
  > set.seed(1); t0 <- system.time(s0 <- f0(N=50,T=1000))
  > set.seed(1); t1 <- system.time(s1 <- f1(N=50,T=1000))
  > rbind(t0, t1)
     user.self sys.self elapsed user.child sys.child
  t0    436.87     0.11  438.48         NA        NA
  t1      0.04     0.00    0.04         NA        NA
  > all.equal(s0, s1)
  [1] TRUE

The functions are:

f0 <- function(N = 20, T = 100, lambda = 0.1, m_e = 0, sd_e = 1, y0 = 0)
{
  # construct the data frame and initialize y
  D <- data.frame(
    id = rep(1:N,T),
    t = rep(1:T, each = N),
    y = rep(y0,N*T)
  )

  # update y
  for(t in 2:T){
    ybar.L1 = mean(D[D$t==t-1,"y"])
    for(i in 1:N){
      epsilon = rnorm(1,mean=m_e,sd=sd_e)
      D[D$id==i & D$t==t,]$y = lambda*y0+(1-lambda)*ybar.L1+epsilon
    }
  }
  D
}

f1 <- function(N = 20, T = 100, lambda = 0.1, m_e = 0, sd_e = 1, y0 = 0)
{
  # same process simulated using a matrix representation
  #   The T rows are times, the N columns are individuals
  M <- matrix(y0, nrow=T, ncol=N)
  if (T > 1) for(t in 2:T) {
    ybar.L1 <- mean(M[t-1L,])
    epsilon <- rnorm(N, mean=m_e, sd=sd_e)
    M[t,] <- lambda * y0 + (1-lambda)*ybar.L1 + epsilon
  }
  # convert to the data.frame representation that f0 uses
  tM <- t(M)
  data.frame(id = as.vector(row(tM)), t = as.vector(col(tM)), y =
as.vector(tM))
}



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 6, 2014 at 6:47 AM, Matteo Richiardi <matteo.richiardi at gmail.com
> wrote:

> I wish to simulate the following stochastic process, for i = 1...N
> individuals and t=1...T periods:
>
> y_{i,t} = y_0 + lambda Ey_{t-1} + epsilon_{i,t}
>
> where Ey_{t-1} is the average of y over the N individuals computed at time
> t-1.
>
> My solution (below) works but is incredibly slow. Is there a faster but
> still clear and readable alternative?
>
> Thanks a lot. Matteo
>
> rm(list=ls())
> library(plyr)
> y0 = 0
> lambda = 0.1
> N = 20
> T = 100
> m_e = 0
> sd_e = 1
>
> # construct the data frame and initialize y
> D = data.frame(
>   id = rep(1:N,T),
>   t = rep(1:T, each = N),
>   y = rep(y0,N*T)
> )
>
> # update y
> for(t in 2:T){
>   ybar.L1 = mean(D[D$t==t-1,"y"])
>   for(i in 1:N){
>     epsilon = rnorm(1,mean=m_e,sd=sd_e)
>     D[D$id==i & D$t==t,]$y = lambda*y0+(1-lambda)*ybar.L1+epsilon
>   }
> }
>
> ybar <- ddply(D,~t,summarise,mean=mean(y))
>
> plot(ybar, col = "blue", type = "l")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From info.vasukv at gmail.com  Thu Nov  6 19:16:06 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Thu, 6 Nov 2014 23:46:06 +0530
Subject: [R] Daylight Saving Time
Message-ID: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>

Hi,

I am working R on windows 2012 R2 platform, I have updated the latest
hotfixes for time zone information(Microsoft KB 2981580.
<http://support.microsoft.com/kb/2981580>).

But still R is not populating correct date time values(Standard and
Daylight saving).

Could you please advise me, how to enable R to pick up the latest time zone
information/configurations.

Example:

R --vanilla
Sys.setenv(TZ = "America/Eirunepe");
dt<-c(seq(as.POSIXct("2013-11-09 20:00:00",tz="America/Eirunepe"),
as.POSIXct("2013-11-10 10:00:00" ,tz="America/Eirunepe"), by="hour"));
> dt
 [1] "2013-11-09 20:00:00 AMT" "2013-11-09 21:00:00 AMT"
 [3] "2013-11-09 22:00:00 AMT" "2013-11-09 23:00:00 AMT"
 [5] "2013-11-10 00:00:00 AMT" "2013-11-10 01:00:00 AMT"
 [7] "2013-11-10 02:00:00 AMT" "2013-11-10 03:00:00 AMT"
 [9] "2013-11-10 04:00:00 AMT" "2013-11-10 05:00:00 AMT"
[11] "2013-11-10 06:00:00 AMT" "2013-11-10 07:00:00 AMT"
[13] "2013-11-10 08:00:00 AMT" "2013-11-10 09:00:00 AMT"
[15] "2013-11-10 10:00:00 AMT"

For the ?*America/Eirunepe*? time zone, the DST ended on Sun 10-Nov-2013 at
12:00:00 A.M. when local clocks were set backward 1 hour.


as per the latest timezone configuration, the date time sequence should
have "2013-11-09 23:00:00" twice.


Thanks

Vasanth

	[[alternative HTML version deleted]]


From info.vasukv at gmail.com  Thu Nov  6 19:28:37 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Thu, 6 Nov 2014 23:58:37 +0530
Subject: [R] Timezone Upgrade
Message-ID: <CAJhrTnqOMu9VJqkKiBqWh3BgJihL-43izLC_+TeR-m_4uahYOw@mail.gmail.com>

Hi,

I would like to know, once the operating system timezone information is
updated, what step should be carried out at R for reflecting the operating
system(LINUX X64 SOLARIS X64 and WINDOWS X64) update.


Thanks
Vasanth

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Nov  6 20:34:29 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 06 Nov 2014 14:34:29 -0500
Subject: [R] Timezone Upgrade
In-Reply-To: <CAJhrTnqOMu9VJqkKiBqWh3BgJihL-43izLC_+TeR-m_4uahYOw@mail.gmail.com>
References: <CAJhrTnqOMu9VJqkKiBqWh3BgJihL-43izLC_+TeR-m_4uahYOw@mail.gmail.com>
Message-ID: <57B0D9DA-8C9A-4902-981A-9E5946CD5F5D@dcn.davis.CA.us>

Log out and log back in again. For many people this may happen in the normal course of daily use.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2014 1:28:37 PM EST, Vasantha Kumar Kesavan <info.vasukv at gmail.com> wrote:
>Hi,
>
>I would like to know, once the operating system timezone information is
>updated, what step should be carried out at R for reflecting the
>operating
>system(LINUX X64 SOLARIS X64 and WINDOWS X64) update.
>
>
>Thanks
>Vasanth
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From info.vasukv at gmail.com  Thu Nov  6 20:36:43 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Fri, 7 Nov 2014 01:06:43 +0530
Subject: [R] Timezone Upgrade
In-Reply-To: <57B0D9DA-8C9A-4902-981A-9E5946CD5F5D@dcn.davis.CA.us>
References: <CAJhrTnqOMu9VJqkKiBqWh3BgJihL-43izLC_+TeR-m_4uahYOw@mail.gmail.com>
	<57B0D9DA-8C9A-4902-981A-9E5946CD5F5D@dcn.davis.CA.us>
Message-ID: <CAJhrTnrdMvuPvtxRopJcMQ08J-3SmQvoKieO5mi7O8Zk-oC2eQ@mail.gmail.com>

I am log out and login many times. but no luck.

Thanks
Vasanth

On Fri, Nov 7, 2014 at 1:04 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Log out and log back in again. For many people this may happen in the
> normal course of daily use.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 6, 2014 1:28:37 PM EST, Vasantha Kumar Kesavan <
> info.vasukv at gmail.com> wrote:
> >Hi,
> >
> >I would like to know, once the operating system timezone information is
> >updated, what step should be carried out at R for reflecting the
> >operating
> >system(LINUX X64 SOLARIS X64 and WINDOWS X64) update.
> >
> >
> >Thanks
> >Vasanth
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Nov  6 20:48:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 06 Nov 2014 14:48:48 -0500
Subject: [R] Daylight Saving Time
In-Reply-To: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>
References: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>
Message-ID: <694A85C0-0894-4EB4-AA7F-F11942957369@dcn.davis.CA.us>

R on Windows uses the Olsen timezone database, a copy of which is stored with R in the Program Files directory (e.g. R/R-3.1.1/share/zoneinfo). You could update the file yourself if you can find a corrected version, or download an updated version of R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2014 1:16:06 PM EST, Vasantha Kumar Kesavan <info.vasukv at gmail.com> wrote:
>Hi,
>
>I am working R on windows 2012 R2 platform, I have updated the latest
>hotfixes for time zone information(Microsoft KB 2981580.
><http://support.microsoft.com/kb/2981580>).
>
>But still R is not populating correct date time values(Standard and
>Daylight saving).
>
>Could you please advise me, how to enable R to pick up the latest time
>zone
>information/configurations.
>
>Example:
>
>R --vanilla
>Sys.setenv(TZ = "America/Eirunepe");
>dt<-c(seq(as.POSIXct("2013-11-09 20:00:00",tz="America/Eirunepe"),
>as.POSIXct("2013-11-10 10:00:00" ,tz="America/Eirunepe"), by="hour"));
>> dt
> [1] "2013-11-09 20:00:00 AMT" "2013-11-09 21:00:00 AMT"
> [3] "2013-11-09 22:00:00 AMT" "2013-11-09 23:00:00 AMT"
> [5] "2013-11-10 00:00:00 AMT" "2013-11-10 01:00:00 AMT"
> [7] "2013-11-10 02:00:00 AMT" "2013-11-10 03:00:00 AMT"
> [9] "2013-11-10 04:00:00 AMT" "2013-11-10 05:00:00 AMT"
>[11] "2013-11-10 06:00:00 AMT" "2013-11-10 07:00:00 AMT"
>[13] "2013-11-10 08:00:00 AMT" "2013-11-10 09:00:00 AMT"
>[15] "2013-11-10 10:00:00 AMT"
>
>For the ?*America/Eirunepe*? time zone, the DST ended on Sun
>10-Nov-2013 at
>12:00:00 A.M. when local clocks were set backward 1 hour.
>
>
>as per the latest timezone configuration, the date time sequence should
>have "2013-11-09 23:00:00" twice.
>
>
>Thanks
>
>Vasanth
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From info.vasukv at gmail.com  Thu Nov  6 21:36:38 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Fri, 7 Nov 2014 02:06:38 +0530
Subject: [R] Daylight Saving Time
In-Reply-To: <694A85C0-0894-4EB4-AA7F-F11942957369@dcn.davis.CA.us>
References: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>
	<694A85C0-0894-4EB4-AA7F-F11942957369@dcn.davis.CA.us>
Message-ID: <CAJhrTno2Wt8XEBAb0uzBU1D2+YYb3xUNm2VC33wPSHbNK57U0A@mail.gmail.com>

Thanks Jeff Newmiller, it is working now.

I would like to know, the same kind of configuration can be done in Linux
and Solaris platform.

Instead of R is mapping to operating system(/usr/share/. /usr/share/lib/)
zoneinfo directory.

Thanks
Vasanth

On Fri, Nov 7, 2014 at 1:18 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> R on Windows uses the Olsen timezone database, a copy of which is stored
> with R in the Program Files directory (e.g. R/R-3.1.1/share/zoneinfo). You
> could update the file yourself if you can find a corrected version, or
> download an updated version of R.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 6, 2014 1:16:06 PM EST, Vasantha Kumar Kesavan <
> info.vasukv at gmail.com> wrote:
> >Hi,
> >
> >I am working R on windows 2012 R2 platform, I have updated the latest
> >hotfixes for time zone information(Microsoft KB 2981580.
> ><http://support.microsoft.com/kb/2981580>).
> >
> >But still R is not populating correct date time values(Standard and
> >Daylight saving).
> >
> >Could you please advise me, how to enable R to pick up the latest time
> >zone
> >information/configurations.
> >
> >Example:
> >
> >R --vanilla
> >Sys.setenv(TZ = "America/Eirunepe");
> >dt<-c(seq(as.POSIXct("2013-11-09 20:00:00",tz="America/Eirunepe"),
> >as.POSIXct("2013-11-10 10:00:00" ,tz="America/Eirunepe"), by="hour"));
> >> dt
> > [1] "2013-11-09 20:00:00 AMT" "2013-11-09 21:00:00 AMT"
> > [3] "2013-11-09 22:00:00 AMT" "2013-11-09 23:00:00 AMT"
> > [5] "2013-11-10 00:00:00 AMT" "2013-11-10 01:00:00 AMT"
> > [7] "2013-11-10 02:00:00 AMT" "2013-11-10 03:00:00 AMT"
> > [9] "2013-11-10 04:00:00 AMT" "2013-11-10 05:00:00 AMT"
> >[11] "2013-11-10 06:00:00 AMT" "2013-11-10 07:00:00 AMT"
> >[13] "2013-11-10 08:00:00 AMT" "2013-11-10 09:00:00 AMT"
> >[15] "2013-11-10 10:00:00 AMT"
> >
> >For the ?*America/Eirunepe*? time zone, the DST ended on Sun
> >10-Nov-2013 at
> >12:00:00 A.M. when local clocks were set backward 1 hour.
> >
> >
> >as per the latest timezone configuration, the date time sequence should
> >have "2013-11-09 23:00:00" twice.
> >
> >
> >Thanks
> >
> >Vasanth
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Nov  6 22:04:15 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 06 Nov 2014 16:04:15 -0500
Subject: [R] Daylight Saving Time
In-Reply-To: <CAJhrTno2Wt8XEBAb0uzBU1D2+YYb3xUNm2VC33wPSHbNK57U0A@mail.gmail.com>
References: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>
	<694A85C0-0894-4EB4-AA7F-F11942957369@dcn.davis.CA.us>
	<CAJhrTno2Wt8XEBAb0uzBU1D2+YYb3xUNm2VC33wPSHbNK57U0A@mail.gmail.com>
Message-ID: <4F87A5B4-6903-4B13-9180-04E66FDC64CF@dcn.davis.CA.us>

Working now... after what action?

AFAIK on *NIX systems R uses the OS installation of the Olsen database, so on a fresh login R should pick up any OS update you have installed.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2014 3:36:38 PM EST, Vasantha Kumar Kesavan <info.vasukv at gmail.com> wrote:
>Thanks Jeff Newmiller, it is working now.
>
>I would like to know, the same kind of configuration can be done in
>Linux
>and Solaris platform.
>
>Instead of R is mapping to operating system(/usr/share/.
>/usr/share/lib/)
>zoneinfo directory.
>
>Thanks
>Vasanth
>
>On Fri, Nov 7, 2014 at 1:18 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> R on Windows uses the Olsen timezone database, a copy of which is
>stored
>> with R in the Program Files directory (e.g.
>R/R-3.1.1/share/zoneinfo). You
>> could update the file yourself if you can find a corrected version,
>or
>> download an updated version of R.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 6, 2014 1:16:06 PM EST, Vasantha Kumar Kesavan <
>> info.vasukv at gmail.com> wrote:
>> >Hi,
>> >
>> >I am working R on windows 2012 R2 platform, I have updated the
>latest
>> >hotfixes for time zone information(Microsoft KB 2981580.
>> ><http://support.microsoft.com/kb/2981580>).
>> >
>> >But still R is not populating correct date time values(Standard and
>> >Daylight saving).
>> >
>> >Could you please advise me, how to enable R to pick up the latest
>time
>> >zone
>> >information/configurations.
>> >
>> >Example:
>> >
>> >R --vanilla
>> >Sys.setenv(TZ = "America/Eirunepe");
>> >dt<-c(seq(as.POSIXct("2013-11-09 20:00:00",tz="America/Eirunepe"),
>> >as.POSIXct("2013-11-10 10:00:00" ,tz="America/Eirunepe"),
>by="hour"));
>> >> dt
>> > [1] "2013-11-09 20:00:00 AMT" "2013-11-09 21:00:00 AMT"
>> > [3] "2013-11-09 22:00:00 AMT" "2013-11-09 23:00:00 AMT"
>> > [5] "2013-11-10 00:00:00 AMT" "2013-11-10 01:00:00 AMT"
>> > [7] "2013-11-10 02:00:00 AMT" "2013-11-10 03:00:00 AMT"
>> > [9] "2013-11-10 04:00:00 AMT" "2013-11-10 05:00:00 AMT"
>> >[11] "2013-11-10 06:00:00 AMT" "2013-11-10 07:00:00 AMT"
>> >[13] "2013-11-10 08:00:00 AMT" "2013-11-10 09:00:00 AMT"
>> >[15] "2013-11-10 10:00:00 AMT"
>> >
>> >For the ?*America/Eirunepe*? time zone, the DST ended on Sun
>> >10-Nov-2013 at
>> >12:00:00 A.M. when local clocks were set backward 1 hour.
>> >
>> >
>> >as per the latest timezone configuration, the date time sequence
>should
>> >have "2013-11-09 23:00:00" twice.
>> >
>> >
>> >Thanks
>> >
>> >Vasanth
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From info.vasukv at gmail.com  Thu Nov  6 22:10:58 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Fri, 7 Nov 2014 02:40:58 +0530
Subject: [R] Daylight Saving Time
In-Reply-To: <4F87A5B4-6903-4B13-9180-04E66FDC64CF@dcn.davis.CA.us>
References: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>
	<694A85C0-0894-4EB4-AA7F-F11942957369@dcn.davis.CA.us>
	<CAJhrTno2Wt8XEBAb0uzBU1D2+YYb3xUNm2VC33wPSHbNK57U0A@mail.gmail.com>
	<4F87A5B4-6903-4B13-9180-04E66FDC64CF@dcn.davis.CA.us>
Message-ID: <CAJhrTnqxsNWK2rYSie6uJyc0K9_JW+7x-Xv=qtjne_vA6edYTA@mail.gmail.com>

In LINUX, I don't want R to use the operating system zoneinfo(Olsen
database) instead of that I like to point different path which has the
latest zoneinfo(latest Olsen database).

On Fri, Nov 7, 2014 at 2:34 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Working now... after what action?
>
> AFAIK on *NIX systems R uses the OS installation of the Olsen database, so
> on a fresh login R should pick up any OS update you have installed.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 6, 2014 3:36:38 PM EST, Vasantha Kumar Kesavan <
> info.vasukv at gmail.com> wrote:
> >Thanks Jeff Newmiller, it is working now.
> >
> >I would like to know, the same kind of configuration can be done in
> >Linux
> >and Solaris platform.
> >
> >Instead of R is mapping to operating system(/usr/share/.
> >/usr/share/lib/)
> >zoneinfo directory.
> >
> >Thanks
> >Vasanth
> >
> >On Fri, Nov 7, 2014 at 1:18 AM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> R on Windows uses the Olsen timezone database, a copy of which is
> >stored
> >> with R in the Program Files directory (e.g.
> >R/R-3.1.1/share/zoneinfo). You
> >> could update the file yourself if you can find a corrected version,
> >or
> >> download an updated version of R.
> >>
>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >> Go...
> >>                                       Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
>
> >---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On November 6, 2014 1:16:06 PM EST, Vasantha Kumar Kesavan <
> >> info.vasukv at gmail.com> wrote:
> >> >Hi,
> >> >
> >> >I am working R on windows 2012 R2 platform, I have updated the
> >latest
> >> >hotfixes for time zone information(Microsoft KB 2981580.
> >> ><http://support.microsoft.com/kb/2981580>).
> >> >
> >> >But still R is not populating correct date time values(Standard and
> >> >Daylight saving).
> >> >
> >> >Could you please advise me, how to enable R to pick up the latest
> >time
> >> >zone
> >> >information/configurations.
> >> >
> >> >Example:
> >> >
> >> >R --vanilla
> >> >Sys.setenv(TZ = "America/Eirunepe");
> >> >dt<-c(seq(as.POSIXct("2013-11-09 20:00:00",tz="America/Eirunepe"),
> >> >as.POSIXct("2013-11-10 10:00:00" ,tz="America/Eirunepe"),
> >by="hour"));
> >> >> dt
> >> > [1] "2013-11-09 20:00:00 AMT" "2013-11-09 21:00:00 AMT"
> >> > [3] "2013-11-09 22:00:00 AMT" "2013-11-09 23:00:00 AMT"
> >> > [5] "2013-11-10 00:00:00 AMT" "2013-11-10 01:00:00 AMT"
> >> > [7] "2013-11-10 02:00:00 AMT" "2013-11-10 03:00:00 AMT"
> >> > [9] "2013-11-10 04:00:00 AMT" "2013-11-10 05:00:00 AMT"
> >> >[11] "2013-11-10 06:00:00 AMT" "2013-11-10 07:00:00 AMT"
> >> >[13] "2013-11-10 08:00:00 AMT" "2013-11-10 09:00:00 AMT"
> >> >[15] "2013-11-10 10:00:00 AMT"
> >> >
> >> >For the ?*America/Eirunepe*? time zone, the DST ended on Sun
> >> >10-Nov-2013 at
> >> >12:00:00 A.M. when local clocks were set backward 1 hour.
> >> >
> >> >
> >> >as per the latest timezone configuration, the date time sequence
> >should
> >> >have "2013-11-09 23:00:00" twice.
> >> >
> >> >
> >> >Thanks
> >> >
> >> >Vasanth
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Nov  6 22:25:51 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 06 Nov 2014 16:25:51 -0500
Subject: [R] Daylight Saving Time
In-Reply-To: <CAJhrTnqxsNWK2rYSie6uJyc0K9_JW+7x-Xv=qtjne_vA6edYTA@mail.gmail.com>
References: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>
	<694A85C0-0894-4EB4-AA7F-F11942957369@dcn.davis.CA.us>
	<CAJhrTno2Wt8XEBAb0uzBU1D2+YYb3xUNm2VC33wPSHbNK57U0A@mail.gmail.com>
	<4F87A5B4-6903-4B13-9180-04E66FDC64CF@dcn.davis.CA.us>
	<CAJhrTnqxsNWK2rYSie6uJyc0K9_JW+7x-Xv=qtjne_vA6edYTA@mail.gmail.com>
Message-ID: <87FDFAAC-6E4E-4AC9-80E6-5F261AE6E18A@dcn.davis.CA.us>

?timezones

You probably need to recompile R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2014 4:10:58 PM EST, Vasantha Kumar Kesavan <info.vasukv at gmail.com> wrote:
>In LINUX, I don't want R to use the operating system zoneinfo(Olsen
>database) instead of that I like to point different path which has the
>latest zoneinfo(latest Olsen database).
>
>On Fri, Nov 7, 2014 at 2:34 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Working now... after what action?
>>
>> AFAIK on *NIX systems R uses the OS installation of the Olsen
>database, so
>> on a fresh login R should pick up any OS update you have installed.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 6, 2014 3:36:38 PM EST, Vasantha Kumar Kesavan <
>> info.vasukv at gmail.com> wrote:
>> >Thanks Jeff Newmiller, it is working now.
>> >
>> >I would like to know, the same kind of configuration can be done in
>> >Linux
>> >and Solaris platform.
>> >
>> >Instead of R is mapping to operating system(/usr/share/.
>> >/usr/share/lib/)
>> >zoneinfo directory.
>> >
>> >Thanks
>> >Vasanth
>> >
>> >On Fri, Nov 7, 2014 at 1:18 AM, Jeff Newmiller
>> ><jdnewmil at dcn.davis.ca.us>
>> >wrote:
>> >
>> >> R on Windows uses the Olsen timezone database, a copy of which is
>> >stored
>> >> with R in the Program Files directory (e.g.
>> >R/R-3.1.1/share/zoneinfo). You
>> >> could update the file yourself if you can find a corrected
>version,
>> >or
>> >> download an updated version of R.
>> >>
>>
>>
>>---------------------------------------------------------------------------
>> >> Jeff Newmiller                        The     .....       ..... 
>Go
>> >Live...
>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>> >> Go...
>> >>                                       Live:   OO#.. Dead: OO#..
>> >Playing
>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>> >> /Software/Embedded Controllers)               .OO#.       .OO#.
>> >rocks...1k
>> >>
>>
>>
>>---------------------------------------------------------------------------
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On November 6, 2014 1:16:06 PM EST, Vasantha Kumar Kesavan <
>> >> info.vasukv at gmail.com> wrote:
>> >> >Hi,
>> >> >
>> >> >I am working R on windows 2012 R2 platform, I have updated the
>> >latest
>> >> >hotfixes for time zone information(Microsoft KB 2981580.
>> >> ><http://support.microsoft.com/kb/2981580>).
>> >> >
>> >> >But still R is not populating correct date time values(Standard
>and
>> >> >Daylight saving).
>> >> >
>> >> >Could you please advise me, how to enable R to pick up the latest
>> >time
>> >> >zone
>> >> >information/configurations.
>> >> >
>> >> >Example:
>> >> >
>> >> >R --vanilla
>> >> >Sys.setenv(TZ = "America/Eirunepe");
>> >> >dt<-c(seq(as.POSIXct("2013-11-09
>20:00:00",tz="America/Eirunepe"),
>> >> >as.POSIXct("2013-11-10 10:00:00" ,tz="America/Eirunepe"),
>> >by="hour"));
>> >> >> dt
>> >> > [1] "2013-11-09 20:00:00 AMT" "2013-11-09 21:00:00 AMT"
>> >> > [3] "2013-11-09 22:00:00 AMT" "2013-11-09 23:00:00 AMT"
>> >> > [5] "2013-11-10 00:00:00 AMT" "2013-11-10 01:00:00 AMT"
>> >> > [7] "2013-11-10 02:00:00 AMT" "2013-11-10 03:00:00 AMT"
>> >> > [9] "2013-11-10 04:00:00 AMT" "2013-11-10 05:00:00 AMT"
>> >> >[11] "2013-11-10 06:00:00 AMT" "2013-11-10 07:00:00 AMT"
>> >> >[13] "2013-11-10 08:00:00 AMT" "2013-11-10 09:00:00 AMT"
>> >> >[15] "2013-11-10 10:00:00 AMT"
>> >> >
>> >> >For the ?*America/Eirunepe*? time zone, the DST ended on Sun
>> >> >10-Nov-2013 at
>> >> >12:00:00 A.M. when local clocks were set backward 1 hour.
>> >> >
>> >> >
>> >> >as per the latest timezone configuration, the date time sequence
>> >should
>> >> >have "2013-11-09 23:00:00" twice.
>> >> >
>> >> >
>> >> >Thanks
>> >> >
>> >> >Vasanth
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >>
>>
>>


From wdunlap at tibco.com  Thu Nov  6 23:22:15 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 6 Nov 2014 14:22:15 -0800
Subject: [R] speed issue in simulating a stochastic process
In-Reply-To: <CABSrU1JKEoozzoAAzka0Df6RLDMbQum8+FK1s6VZNHDvwCS6sQ@mail.gmail.com>
References: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>
	<CAF8bMcYOjwHtr8Yf59WGvYDx=y=aRuhLbVw4k4jB1T3PHpVu+A@mail.gmail.com>
	<CABSrU1JKEoozzoAAzka0Df6RLDMbQum8+FK1s6VZNHDvwCS6sQ@mail.gmail.com>
Message-ID: <CAF8bMcaL55ZBN2e=wvWu=mQspCfY0rmnDJ8r+GB+8d9cROt9iw@mail.gmail.com>

Loops are not slow, but your code did a lot of unneeded operations in each
loop.
E.g, you computed
    D$id==i & D$t==t
for each row of D.  That involves 2*nrow(D) equality tests for each of the
nrow(D)
rows, i.e., it is quadratic in N*T.

Then you did a data.frame replacement operation
    D[k,]$y <- newValue
where k is D$id==1&D$t==t.  This extracts the k'th row of D, then extracts
the 1-row 'y' column
from it, replaces it with the new value, then puts that row back into D.
If you must use
a data.frame, the equivalent
   D$y[k] <- newValue
is probably much faster (data.frames are lists of columns, so replacing a
column is fast).

Using a matrix to organize things is less flexible, but faster because you
don't have to search
when you want to find the element for a given id and time - you just do a
little arithmetic to
get the offset from the start of the matrix.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 6, 2014 at 2:05 PM, Matteo Richiardi <matteo.richiardi at gmail.com
> wrote:

> Hi William,
> that's super. Thanks a lot. I knew that R is slow with loops, but did not
> imagine so slow! B.t.w., what's the reason?
> Final question: in your code you have mean(M[t-1L,]): what is the 'L'
> for? I removed it at apparently the code produces the same output...
>
> Thanks again,
> Matteo
>
> On 6 November 2014 18:46, William Dunlap <wdunlap at tibco.com> wrote:
>
>> I find that representing the simulated data as a T row by N column matrix
>> allows for a clearer and faster simulation function.  E.g., compare the
>> output of the following two functions, the first of which uses your code
>> and the second a matrix representation (which I convert to a data.frame at
>> the end so I can compare outputs easily).  I timed both of them for T=10^3
>> times and N=50 individuals; both gave the same results and f1 was 10000
>> times faster than f0:
>>   > set.seed(1); t0 <- system.time(s0 <- f0(N=50,T=1000))
>>   > set.seed(1); t1 <- system.time(s1 <- f1(N=50,T=1000))
>>   > rbind(t0, t1)
>>      user.self sys.self elapsed user.child sys.child
>>   t0    436.87     0.11  438.48         NA        NA
>>   t1      0.04     0.00    0.04         NA        NA
>>   > all.equal(s0, s1)
>>   [1] TRUE
>>
>> The functions are:
>>
>> f0 <- function(N = 20, T = 100, lambda = 0.1, m_e = 0, sd_e = 1, y0 = 0)
>> {
>>   # construct the data frame and initialize y
>>   D <- data.frame(
>>     id = rep(1:N,T),
>>     t = rep(1:T, each = N),
>>     y = rep(y0,N*T)
>>   )
>>
>>   # update y
>>   for(t in 2:T){
>>     ybar.L1 = mean(D[D$t==t-1,"y"])
>>     for(i in 1:N){
>>       epsilon = rnorm(1,mean=m_e,sd=sd_e)
>>       D[D$id==i & D$t==t,]$y = lambda*y0+(1-lambda)*ybar.L1+epsilon
>>     }
>>   }
>>   D
>> }
>>
>> f1 <- function(N = 20, T = 100, lambda = 0.1, m_e = 0, sd_e = 1, y0 = 0)
>> {
>>   # same process simulated using a matrix representation
>>   #   The T rows are times, the N columns are individuals
>>   M <- matrix(y0, nrow=T, ncol=N)
>>   if (T > 1) for(t in 2:T) {
>>     ybar.L1 <- mean(M[t-1L,])
>>     epsilon <- rnorm(N, mean=m_e, sd=sd_e)
>>     M[t,] <- lambda * y0 + (1-lambda)*ybar.L1 + epsilon
>>   }
>>   # convert to the data.frame representation that f0 uses
>>   tM <- t(M)
>>   data.frame(id = as.vector(row(tM)), t = as.vector(col(tM)), y =
>> as.vector(tM))
>> }
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Thu, Nov 6, 2014 at 6:47 AM, Matteo Richiardi <
>> matteo.richiardi at gmail.com> wrote:
>>
>>> I wish to simulate the following stochastic process, for i = 1...N
>>> individuals and t=1...T periods:
>>>
>>> y_{i,t} = y_0 + lambda Ey_{t-1} + epsilon_{i,t}
>>>
>>> where Ey_{t-1} is the average of y over the N individuals computed at
>>> time
>>> t-1.
>>>
>>> My solution (below) works but is incredibly slow. Is there a faster but
>>> still clear and readable alternative?
>>>
>>> Thanks a lot. Matteo
>>>
>>> rm(list=ls())
>>> library(plyr)
>>> y0 = 0
>>> lambda = 0.1
>>> N = 20
>>> T = 100
>>> m_e = 0
>>> sd_e = 1
>>>
>>> # construct the data frame and initialize y
>>> D = data.frame(
>>>   id = rep(1:N,T),
>>>   t = rep(1:T, each = N),
>>>   y = rep(y0,N*T)
>>> )
>>>
>>> # update y
>>> for(t in 2:T){
>>>   ybar.L1 = mean(D[D$t==t-1,"y"])
>>>   for(i in 1:N){
>>>     epsilon = rnorm(1,mean=m_e,sd=sd_e)
>>>     D[D$id==i & D$t==t,]$y = lambda*y0+(1-lambda)*ybar.L1+epsilon
>>>   }
>>> }
>>>
>>> ybar <- ddply(D,~t,summarise,mean=mean(y))
>>>
>>> plot(ybar, col = "blue", type = "l")
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From David.Duffy at qimr.edu.au  Thu Nov  6 23:45:59 2014
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 7 Nov 2014 08:45:59 +1000
Subject: [R] Differences between MTDFReml and kinship2
In-Reply-To: <mailman.31.1415271609.891.r-help@r-project.org>
References: <mailman.31.1415271609.891.r-help@r-project.org>
Message-ID: <alpine.LMD.2.00.1411070828320.11464@orpheus.qimr.edu.au>

> From: "silvano" <silvano at uel.br>
>
> I fitted a genetic model using kinship2 and I compared it with MTDFReml program output.
> The residual variance of both are very close but the genetic variance are very differents.
>
> The output are:
>
> MTDFReml:
> genetic variance = 1.24015
> residual variance = 5.93424
>
> R (Kinship2):
> genetic variance = 0.767187
> residual variance = 5.6712
>
> Both of them use REML method. Could someone tell why the difference?


Hi Silvano.

You haven't given us enough information, I'm afraid.  We would need the
commands you used, the versions of the software,  plus output from both
jobs, and your data, or a smaller subset that exhibits the same problem.

You may have made an error, there may be a problem in one program, or the
likelihood might be flat around those solutions (ie your data are not very
informative).

It might be better to continue this on the R-sig-mixed-models list.

Cheers, David Duffy.


From t.yee at auckland.ac.nz  Fri Nov  7 00:48:41 2014
From: t.yee at auckland.ac.nz (Thomas Yee)
Date: Fri, 07 Nov 2014 12:48:41 +1300
Subject: [R] VGAM package : Frechet distribution - 2 parameter estimation
In-Reply-To: <545B4980.2060104@auckland.ac.nz>
References: <1415253899.16934.YahooMailNeo@web193306.mail.sg3.yahoo.com>	<545B3E6A.7060002@aghmed.fsnet.co.uk>
	<1415266481.31006.YahooMailNeo@web193304.mail.sg3.yahoo.com>
	<545B4980.2060104@auckland.ac.nz>
Message-ID: <545C08D9.4020009@auckland.ac.nz>

Hello,

a day or two ago I submitted VGAM 0.9-5 to CRAN, which has
myriads of changes to family functions---their names, their
arguments, and their order thereof. Especially regarding
family functions for discrete and continuous distributions.

In a nutshell, I found lots of inconsistencies while writing
my book, and it was deemed necessary to standardize things.
I just had to bite the bullet, so to speak. I have tried
to summarize all changes in the NEWS file, however, a few
might have gone undocumented. Users of previous versions
of VGAM are cautioned to check their code. My apologies
for this inconvenience.

I have always tried to make it plain that while the
version number was less than 1.0-0, everything was subject
to change. But the book "Vector Generalized Linear and
Additive Models", for Springer, should appear next year,
it is synchronized with version 1.0-0, so that should end
most of these disruptive changes :) Or at least, curtail them
(hopefully).

cheers

Thomas

ps. for this particular problem, only frechet() remains.




On 06/11/14 23:12, Rolf Turner wrote:
>
> Dear Ms. Gobin,
>
> There would appear to be a typo in the package manual that appears on 
> CRAN.  Doing ?Frechet (it would be nice to have this aliased also to 
> "frechet") points you immediately to frechet.  With "frechet2" 
> substituted for "frechet" your code, everything works.
>
> cheers,
>
> Rolf Turner
>
> On 06/11/14 22:34, Katherine Gobin wrote:
>> Dear Mr Michael,
>>
>> Thanks a lot for your guidance. The pdf file describing VGAM package 
>> has mentioned 'frechet' in the example, so I got the error.
>>
>> Regards
>> Katherine
>>
>>
>> On Thursday, 6 November 2014 2:54 PM, Michael Dewey 
>> <info at aghmed.fsnet.co.uk> wrote:
>>
>>
>>
>>
>>
>> On 06/11/2014 06:04, Katherine Gobin wrote:
>>> Dear R forum,
>>>
>>> I am trying to execute following code (Page no 259 - VGAM.pdf)
>>>
>>> # 
>>> .........................................................................................................................
>>>
>>> library(VGAM)
>>>
>>> set.seed(123)
>>> fdata <- data.frame(y1 = rfrechet(nn <- 1000, shape = 2 + exp(1)))
>>> with(fdata, hist(y1))
>>> fit2 <- vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE)
>>>
>>> # 
>>> .........................................................................................................................
>>>
>>
>> Is it not called frechet2?
>>
>>>
>>> However, I receive following error
>>>
>>> Error in vglm(y1 ~ 1, frechet, data = fdata, trace = TRUE) :
>>>     object 'frechet' not found
>>>
>>>
>>> Earlier there used to be a function called "frechet3" which I guess 
>>> has been withdrawn by VGAM.
>>>
>>> Kindly guide
>>>
>>> Katherine
>


From deepansh1989 at gmail.com  Thu Nov  6 20:21:19 2014
From: deepansh1989 at gmail.com (Deepansh Dalela)
Date: Thu, 6 Nov 2014 14:21:19 -0500
Subject: [R] R 2.14.2 installation on mac OS X yosemite
Message-ID: <6B6B8AD0-59C4-4589-98D3-2B8D5D3C8908@gmail.com>

Hi, 

I noticed your email on the R support page. I am currently using SPSS 21 for mac, and need to install a macro plug-in which requires me o install R 2.14 (I already have R 3.0). When i download the R 2.14 package from the CRAN website, and try to install it on my Macintosh HD, it gives me an error message : ? R 2.14.2 for Mac OS X 10.5 or higher (Leopard build) can?t be installed on this disk. Leopard build of R requires Mac OS X 10.5 or higher. Use Tiger build (available from CRAN) for older systems.? 

I dont understand this, since I have OS X Yosemite on my mac. I tried installing 2.14.0, but got the exact same error message.

Would appreciate your help greatly.

Deepansh

From ddalela1 at hfhs.org  Thu Nov  6 20:20:04 2014
From: ddalela1 at hfhs.org (Dalela, Deepansh)
Date: Thu, 6 Nov 2014 19:20:04 +0000
Subject: [R] R version 2.14.2 installation on mac OS X Yosemite
Message-ID: <2377E38C-198B-455A-8569-894C1178BB30@hfhs.org>

Hi,

I noticed your email on the R support page. I am currently using SPSS 21 for mac, and need to install a macro plug-in which requires me o install R 2.14 (I already have R 3.0). When i download the R 2.14 package from the CRAN website, and try to install it on my Macintosh HD, it gives me an error message : ? R 2.14.2 for Mac OS X 10.5 or higher (Leopard build) can?t be installed on this disk. Leopard build of R requires Mac OS X 10.5 or higher. Use Tiger build (available from CRAN) for older systems.?

I dont understand this, since I have OS X Yosemite on my mac. I tried installing 2.14.0, but got the exact same error message.

Would appreciate your help greatly.

Deepansh

________________________________

CONFIDENTIALITY NOTICE: This email contains information from the sender that may be CONFIDENTIAL, LEGALLY PRIVILEGED, PROPRIETARY or otherwise protected from disclosure. This email is intended for use only by the person or entity to whom it is addressed. If you are not the intended recipient, any use, disclosure, copying, distribution, printing, or any action taken in reliance on the contents of this email, is strictly prohibited. If you received this email in error, please contact the sending party by reply email, delete the email from your computer system and shred any paper copies.

Note to Patients: There are a number of risks you should consider before using e-mail to communicate with us. See our Privacy & Security page on www.henryford.com for more detailed information as well as information concerning MyChart, our new patient portal. If you do not believe that our policy gives you the privacy and security protection you need, do not send e-mail or Internet communications to us.

From dmello2 at ucmerced.edu  Fri Nov  7 00:23:43 2014
From: dmello2 at ucmerced.edu (Daniel Mello)
Date: Thu, 6 Nov 2014 23:23:43 +0000
Subject: [R] Lme4 Package Help!
Message-ID: <4942E23E-2428-412D-B4CE-1D1CF81F0623@ucmerced.edu>

Hello, all! 

So, as stated in the title, the Lme4 package used to output p-values for the
fixed effects. What happened?!

Literally 2 weeks ago, I ran code, got output with no errors, and had
p-values listed for my fixed effects.

Now, running THE SAME CODE with THE SAME DATASET (nothing at all has
changed, not the data, not my computer, not R, nothing), I do not get
p-values.

I've tried other computers, I've tried resetting R.

Any ideas? I'd really need to get some p-values.

Thank you!

D


From ligges at statistik.tu-dortmund.de  Fri Nov  7 00:59:54 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 07 Nov 2014 00:59:54 +0100
Subject: [R] R 2.14.2 installation on mac OS X yosemite
In-Reply-To: <6B6B8AD0-59C4-4589-98D3-2B8D5D3C8908@gmail.com>
References: <6B6B8AD0-59C4-4589-98D3-2B8D5D3C8908@gmail.com>
Message-ID: <545C0B7A.1070703@statistik.tu-dortmund.de>



On 06.11.2014 20:21, Deepansh Dalela wrote:
> Hi,
>
> I noticed your email on the R support page. I am currently using SPSS 21 for mac, and need to install a macro plug-in which requires me o install R 2.14 (I already have R 3.0). When i download the R 2.14 package from the CRAN website, and try to install it on my Macintosh HD, it gives me an error message : ? R 2.14.2 for Mac OS X 10.5 or higher (Leopard build) can?t be installed on this disk. Leopard build of R requires Mac OS X 10.5 or higher. Use Tiger build (available from CRAN) for older systems.?
>
> I dont understand this, since I have OS X Yosemite on my mac. I tried installing 2.14.0, but got the exact same error message.


Such old versions of R are not supported, particularly not on more 
recent OS.
If you need help, ask the company for support that tells you to install 
an obsolete version of R.

Best,
Uwe Ligges




> Would appreciate your help greatly.
>
> Deepansh
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Fri Nov  7 01:00:34 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 07 Nov 2014 01:00:34 +0100
Subject: [R] R version 2.14.2 installation on mac OS X Yosemite
In-Reply-To: <2377E38C-198B-455A-8569-894C1178BB30@hfhs.org>
References: <2377E38C-198B-455A-8569-894C1178BB30@hfhs.org>
Message-ID: <545C0BA2.2000706@statistik.tu-dortmund.de>



On 06.11.2014 20:20, Dalela, Deepansh wrote:
> Hi,
>
> I noticed your email on the R support page. I am currently using SPSS 21 for mac, and need to install a macro plug-in which requires me o install R 2.14 (I already have R 3.0). When i download the R 2.14 package from the CRAN website, and try to install it on my Macintosh HD, it gives me an error message : ? R 2.14.2 for Mac OS X 10.5 or higher (Leopard build) can?t be installed on this disk. Leopard build of R requires Mac OS X 10.5 or higher. Use Tiger build (available from CRAN) for older systems.?
>
> I dont understand this, since I have OS X Yosemite on my mac. I tried installing 2.14.0, but got the exact same error message.
>
> Would appreciate your help greatly.



Such old versions of R are not supported, particularly not on more 
recent OS.
If you need help, ask the company for support that tells you to install 
an obsolete version of R.

Best,
Uwe Ligges

>
> Deepansh
>
> ________________________________
>
> CONFIDENTIALITY NOTICE: This email contains information from the sender that may be CONFIDENTIAL, LEGALLY PRIVILEGED, PROPRIETARY or otherwise protected from disclosure. This email is intended for use only by the person or entity to whom it is addressed. If you are not the intended recipient, any use, disclosure, copying, distribution, printing, or any action taken in reliance on the contents of this email, is strictly prohibited. If you received this email in error, please contact the sending party by reply email, delete the email from your computer system and shred any paper copies.
>
> Note to Patients: There are a number of risks you should consider before using e-mail to communicate with us. See our Privacy & Security page on www.henryford.com for more detailed information as well as information concerning MyChart, our new patient portal. If you do not believe that our policy gives you the privacy and security protection you need, do not send e-mail or Internet communications to us.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bbolker at gmail.com  Fri Nov  7 01:01:03 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 7 Nov 2014 00:01:03 +0000
Subject: [R] Lme4 Package Help!
References: <4942E23E-2428-412D-B4CE-1D1CF81F0623@ucmerced.edu>
Message-ID: <loom.20141107T005819-733@post.gmane.org>

Daniel Mello <dmello2 <at> ucmerced.edu> writes:

> 
> Hello, all! 
> 
> So, as stated in the title, the Lme4 package used
> to output p-values for the
> fixed effects. What happened?!
> 
> Literally 2 weeks ago, I ran code, got output with no errors, and had
> p-values listed for my fixed effects.
> 
> Now, running THE SAME CODE with THE SAME DATASET (nothing at all has
> changed, not the data, not my computer, not R, nothing), I do not get
> p-values.
> 
> I've tried other computers, I've tried resetting R.
> 
> Any ideas? I'd really need to get some p-values.
> 
> Thank you!
> 
> D
> 
> 

  Applying my mind-reading skills, I'm going to guess that you are
running anova() and that you had previously loaded the lmerTest package
(which extends the anova() method from lme4 in several ways), and that
now you are loading only the base lme4 package and not the lmerTest 
package.

  If my guess isn't right, then you're going to have to provide more
information.

  Follow-ups to r-sig-mixed-models at r-project.org , please .

  Ben Bolker


From r.turner at auckland.ac.nz  Fri Nov  7 01:17:13 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 07 Nov 2014 13:17:13 +1300
Subject: [R] speed issue in simulating a stochastic process
In-Reply-To: <CAF8bMcaL55ZBN2e=wvWu=mQspCfY0rmnDJ8r+GB+8d9cROt9iw@mail.gmail.com>
References: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>	<CAF8bMcYOjwHtr8Yf59WGvYDx=y=aRuhLbVw4k4jB1T3PHpVu+A@mail.gmail.com>	<CABSrU1JKEoozzoAAzka0Df6RLDMbQum8+FK1s6VZNHDvwCS6sQ@mail.gmail.com>
	<CAF8bMcaL55ZBN2e=wvWu=mQspCfY0rmnDJ8r+GB+8d9cROt9iw@mail.gmail.com>
Message-ID: <545C0F89.1040700@auckland.ac.nz>


<SNIP>

> On Thu, Nov 6, 2014 at 2:05 PM, Matteo Richiardi <matteo.richiardi at gmail.com
>> wrote:

<SNIP>

>> Final question: in your code you have mean(M[t-1L,]): what is the 'L'
>> for? I removed it at apparently the code produces the same output...

<SNIP>

The constant "1L" is stored as an integer; the constant "1" is stored as 
double precision.  This sometimes makes no difference and sometimes 
makes a huge difference (especially in the context of numerical 
comparisons).  If something is supposed to be an integer it is safer to 
use the "L" form.

See ?NumericConstants.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From michel.arnaud at cirad.fr  Fri Nov  7 09:37:17 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Fri, 07 Nov 2014 09:37:17 +0100
Subject: [R] To calculate the month number between 2 dates
In-Reply-To: <545C0F89.1040700@auckland.ac.nz>
References: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>	<CAF8bMcYOjwHtr8Yf59WGvYDx=y=aRuhLbVw4k4jB1T3PHpVu+A@mail.gmail.com>	<CABSrU1JKEoozzoAAzka0Df6RLDMbQum8+FK1s6VZNHDvwCS6sQ@mail.gmail.com>	<CAF8bMcaL55ZBN2e=wvWu=mQspCfY0rmnDJ8r+GB+8d9cROt9iw@mail.gmail.com>
	<545C0F89.1040700@auckland.ac.nz>
Message-ID: <545C84BD.8030803@cirad.fr>

Hello
Can one calculate the month number between two dates
D1 <- "01/01/2007"  and D2 <- "01/04/2009" ?
Thank you


-- 
Michel ARNAUD
Cirad


From Achim.Zeileis at uibk.ac.at  Fri Nov  7 10:08:32 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 7 Nov 2014 10:08:32 +0100 (CET)
Subject: [R] To calculate the month number between 2 dates
In-Reply-To: <545C84BD.8030803@cirad.fr>
References: <CABSrU1J4vJ3fZxF_n36mN7ORg8dYcJNaxUFJf6F2Q=Bk0gyKtg@mail.gmail.com>
	<CAF8bMcYOjwHtr8Yf59WGvYDx=y=aRuhLbVw4k4jB1T3PHpVu+A@mail.gmail.com>
	<CABSrU1JKEoozzoAAzka0Df6RLDMbQum8+FK1s6VZNHDvwCS6sQ@mail.gmail.com>
	<CAF8bMcaL55ZBN2e=wvWu=mQspCfY0rmnDJ8r+GB+8d9cROt9iw@mail.gmail.com>
	<545C0F89.1040700@auckland.ac.nz> <545C84BD.8030803@cirad.fr>
Message-ID: <alpine.DEB.2.11.1411071005020.6959@paninaro.uibk.ac.at>

On Fri, 7 Nov 2014, Arnaud Michel wrote:

> Hello
> Can one calculate the month number between two dates
> D1 <- "01/01/2007"  and D2 <- "01/04/2009" ?
> Thank you

One way is through zoo's yearmon class:

R> library("zoo")
R> D1 <- as.yearmon("01/01/2007", format = "%d/%m/%Y")
R> D2 <- as.yearmon("01/04/2009", format = "%d/%m/%Y")
R> D2 - D1
[1] 2.25
R> 12 * (D2 - D1)
[1] 27

Other solutions could go through base R's POSIXlt class, see strptime() 
and difftime().

hth,
Z

>
> -- 
> Michel ARNAUD
> Cirad
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From info.vasukv at gmail.com  Fri Nov  7 11:21:30 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Fri, 7 Nov 2014 15:51:30 +0530
Subject: [R] Daylight Saving Time
In-Reply-To: <87FDFAAC-6E4E-4AC9-80E6-5F261AE6E18A@dcn.davis.CA.us>
References: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>
	<694A85C0-0894-4EB4-AA7F-F11942957369@dcn.davis.CA.us>
	<CAJhrTno2Wt8XEBAb0uzBU1D2+YYb3xUNm2VC33wPSHbNK57U0A@mail.gmail.com>
	<4F87A5B4-6903-4B13-9180-04E66FDC64CF@dcn.davis.CA.us>
	<CAJhrTnqxsNWK2rYSie6uJyc0K9_JW+7x-Xv=qtjne_vA6edYTA@mail.gmail.com>
	<87FDFAAC-6E4E-4AC9-80E6-5F261AE6E18A@dcn.davis.CA.us>
Message-ID: <CAJhrTnoSj7gQm_46-LrUvvYHJ0+Y1xDEw+eDg-WEoB6COrG6-w@mail.gmail.com>

I am Sorry for not explained my requirement to you properly.

As you told in Windows I need to update the $R_HOME/share/zoneinfo with the
latest time zone information, since R is not using the operating system
time zone files. Then I have updated the zoneinfo directory, after that it
is working fine for me in the windows.

In the linux platform by default R is using the operating system timezone
files available at "/usr/share/zoneinfo" path. Yesterday my question was is
it there are any way to configure the R to use different path
("/tmp/zoneinfo") instead of "/usr/share/zoneinfo".

Then from the internet I came to know that the TZDIR
(TZDIR="/tmp/zoneinfo") environment variable can be used for configure
different time zone path instead of the default path. By setting the TZDIR
environment variable in Linux does the need as I am expected. So my
requirement in Windows and Linux platform are worked out.

Now I like to know, how to do the same in Solaris operating system (when I
am tried with setting TZDIR environment variable as like Linux but no luck).

Thanks
Vasanth



On Fri, Nov 7, 2014 at 2:55 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> ?timezones
>
> You probably need to recompile R.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 6, 2014 4:10:58 PM EST, Vasantha Kumar Kesavan <
> info.vasukv at gmail.com> wrote:
> >In LINUX, I don't want R to use the operating system zoneinfo(Olsen
> >database) instead of that I like to point different path which has the
> >latest zoneinfo(latest Olsen database).
> >
> >On Fri, Nov 7, 2014 at 2:34 AM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Working now... after what action?
> >>
> >> AFAIK on *NIX systems R uses the OS installation of the Olsen
> >database, so
> >> on a fresh login R should pick up any OS update you have installed.
> >>
>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >> Go...
> >>                                       Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
>
> >---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On November 6, 2014 3:36:38 PM EST, Vasantha Kumar Kesavan <
> >> info.vasukv at gmail.com> wrote:
> >> >Thanks Jeff Newmiller, it is working now.
> >> >
> >> >I would like to know, the same kind of configuration can be done in
> >> >Linux
> >> >and Solaris platform.
> >> >
> >> >Instead of R is mapping to operating system(/usr/share/.
> >> >/usr/share/lib/)
> >> >zoneinfo directory.
> >> >
> >> >Thanks
> >> >Vasanth
> >> >
> >> >On Fri, Nov 7, 2014 at 1:18 AM, Jeff Newmiller
> >> ><jdnewmil at dcn.davis.ca.us>
> >> >wrote:
> >> >
> >> >> R on Windows uses the Olsen timezone database, a copy of which is
> >> >stored
> >> >> with R in the Program Files directory (e.g.
> >> >R/R-3.1.1/share/zoneinfo). You
> >> >> could update the file yourself if you can find a corrected
> >version,
> >> >or
> >> >> download an updated version of R.
> >> >>
> >>
> >>
>
> >>---------------------------------------------------------------------------
> >> >> Jeff Newmiller                        The     .....       .....
> >Go
> >> >Live...
> >> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> >Live
> >> >> Go...
> >> >>                                       Live:   OO#.. Dead: OO#..
> >> >Playing
> >> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.
> >with
> >> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >> >rocks...1k
> >> >>
> >>
> >>
>
> >>---------------------------------------------------------------------------
> >> >> Sent from my phone. Please excuse my brevity.
> >> >>
> >> >> On November 6, 2014 1:16:06 PM EST, Vasantha Kumar Kesavan <
> >> >> info.vasukv at gmail.com> wrote:
> >> >> >Hi,
> >> >> >
> >> >> >I am working R on windows 2012 R2 platform, I have updated the
> >> >latest
> >> >> >hotfixes for time zone information(Microsoft KB 2981580.
> >> >> ><http://support.microsoft.com/kb/2981580>).
> >> >> >
> >> >> >But still R is not populating correct date time values(Standard
> >and
> >> >> >Daylight saving).
> >> >> >
> >> >> >Could you please advise me, how to enable R to pick up the latest
> >> >time
> >> >> >zone
> >> >> >information/configurations.
> >> >> >
> >> >> >Example:
> >> >> >
> >> >> >R --vanilla
> >> >> >Sys.setenv(TZ = "America/Eirunepe");
> >> >> >dt<-c(seq(as.POSIXct("2013-11-09
> >20:00:00",tz="America/Eirunepe"),
> >> >> >as.POSIXct("2013-11-10 10:00:00" ,tz="America/Eirunepe"),
> >> >by="hour"));
> >> >> >> dt
> >> >> > [1] "2013-11-09 20:00:00 AMT" "2013-11-09 21:00:00 AMT"
> >> >> > [3] "2013-11-09 22:00:00 AMT" "2013-11-09 23:00:00 AMT"
> >> >> > [5] "2013-11-10 00:00:00 AMT" "2013-11-10 01:00:00 AMT"
> >> >> > [7] "2013-11-10 02:00:00 AMT" "2013-11-10 03:00:00 AMT"
> >> >> > [9] "2013-11-10 04:00:00 AMT" "2013-11-10 05:00:00 AMT"
> >> >> >[11] "2013-11-10 06:00:00 AMT" "2013-11-10 07:00:00 AMT"
> >> >> >[13] "2013-11-10 08:00:00 AMT" "2013-11-10 09:00:00 AMT"
> >> >> >[15] "2013-11-10 10:00:00 AMT"
> >> >> >
> >> >> >For the ?*America/Eirunepe*? time zone, the DST ended on Sun
> >> >> >10-Nov-2013 at
> >> >> >12:00:00 A.M. when local clocks were set backward 1 hour.
> >> >> >
> >> >> >
> >> >> >as per the latest timezone configuration, the date time sequence
> >> >should
> >> >> >have "2013-11-09 23:00:00" twice.
> >> >> >
> >> >> >
> >> >> >Thanks
> >> >> >
> >> >> >Vasanth
> >> >> >
> >> >> >       [[alternative HTML version deleted]]
> >> >> >
> >> >> >______________________________________________
> >> >> >R-help at r-project.org mailing list
> >> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >PLEASE do read the posting guide
> >> >> >http://www.R-project.org/posting-guide.html
> >> >> >and provide commented, minimal, self-contained, reproducible
> >code.
> >> >>
> >> >>
> >>
> >>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Nov  7 13:42:39 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 7 Nov 2014 13:42:39 +0100
Subject: [R] R version 2.14.2 installation on mac OS X Yosemite
In-Reply-To: <545C0BA2.2000706@statistik.tu-dortmund.de>
References: <2377E38C-198B-455A-8569-894C1178BB30@hfhs.org>
	<545C0BA2.2000706@statistik.tu-dortmund.de>
Message-ID: <36061D50-7C2F-4129-8018-FE8A21FEBCBC@gmail.com>


On 07 Nov 2014, at 01:00 , Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> 
> 
> On 06.11.2014 20:20, Dalela, Deepansh wrote:
>> Hi,
>> 
>> I noticed your email on the R support page. I am currently using SPSS 21 for mac, and need to install a macro plug-in which requires me o install R 2.14 (I already have R 3.0). When i download the R 2.14 package from the CRAN website, and try to install it on my Macintosh HD, it gives me an error message : ? R 2.14.2 for Mac OS X 10.5 or higher (Leopard build) can?t be installed on this disk. Leopard build of R requires Mac OS X 10.5 or higher. Use Tiger build (available from CRAN) for older systems.?
>> 
>> I dont understand this, since I have OS X Yosemite on my mac. I tried installing 2.14.0, but got the exact same error message.
>> 
>> Would appreciate your help greatly.
> 
> 
> 
> Such old versions of R are not supported, particularly not on more recent OS.
> If you need help, ask the company for support that tells you to install an obsolete version of R.
> 
> Best,
> Uwe Ligges
> 

As Uwe says, if SPSS insists that you use outdated versions of R, SPSS should take on the maintenance rather than expect an academic/volunteer group to do it for them.  

However, Yosemite has the alphabetical-sort problem of making version 10.10 come after 10.9 and not between 10.1 and 10.2 and I wonder if that is what is biting the 2.14.2 installer. There is no way that we'll be rebuilding old packages, but in other contexts, people have gotten around the problem by temporarily setting the version of Yosemite to 10.9.



>> 
>> Deepansh
>> 
>> ________________________________
>> 
>> CONFIDENTIALITY NOTICE: This email contains information from the sender that may be CONFIDENTIAL, LEGALLY PRIVILEGED, PROPRIETARY or otherwise protected from disclosure. This email is intended for use only by the person or entity to whom it is addressed. If you are not the intended recipient, any use, disclosure, copying, distribution, printing, or any action taken in reliance on the contents of this email, is strictly prohibited. If you received this email in error, please contact the sending party by reply email, delete the email from your computer system and shred any paper copies.
>> 
>> Note to Patients: There are a number of risks you should consider before using e-mail to communicate with us. See our Privacy & Security page on www.henryford.com for more detailed information as well as information concerning MyChart, our new patient portal. If you do not believe that our policy gives you the privacy and security protection you need, do not send e-mail or Internet communications to us.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Eric.Elguero at ird.fr  Fri Nov  7 16:05:08 2014
From: Eric.Elguero at ird.fr (Eric Elguero)
Date: Fri, 07 Nov 2014 16:05:08 +0100
Subject: [R] problem with function "polygon"
Message-ID: <545CDFA4.4020205@ird.fr>

Hi all,

I'm trying to use the polygon function from
the graphics package, and get this error
message :

 > polygon(x=c(1,2,3,1),y=c(1,4,5,1))
Error in .Internal(polygon(xy$x, xy$y, col, border, lty, ...)) :
   there is no .Internal function 'polygon'

That annoys me because polygon is actually
called by several other functions I need.

my R version:

R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

and I just updated everything.

e.e.


From HDoran at air.org  Fri Nov  7 16:24:08 2014
From: HDoran at air.org (Doran, Harold)
Date: Fri, 7 Nov 2014 15:24:08 +0000
Subject: [R] Lme4 Package Help!
In-Reply-To: <4942E23E-2428-412D-B4CE-1D1CF81F0623@ucmerced.edu>
References: <4942E23E-2428-412D-B4CE-1D1CF81F0623@ucmerced.edu>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686CF33B7FA@DC1VEX10MB001.air.org>

Daniel

Lmer has never returned p-values from a model summary; this is a well-known and discussed issue. You must have post-processed the data in some way to get the p-values.

Our only way of helping is for you to provide sample code on what you did

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel Mello
Sent: Thursday, November 06, 2014 6:24 PM
To: r-help at r-project.org
Subject: [R] Lme4 Package Help!

Hello, all! 

So, as stated in the title, the Lme4 package used to output p-values for the fixed effects. What happened?!

Literally 2 weeks ago, I ran code, got output with no errors, and had p-values listed for my fixed effects.

Now, running THE SAME CODE with THE SAME DATASET (nothing at all has changed, not the data, not my computer, not R, nothing), I do not get p-values.

I've tried other computers, I've tried resetting R.

Any ideas? I'd really need to get some p-values.

Thank you!

D

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Nov  7 16:35:28 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 07 Nov 2014 10:35:28 -0500
Subject: [R] problem with function "polygon"
In-Reply-To: <545CDFA4.4020205@ird.fr>
References: <545CDFA4.4020205@ird.fr>
Message-ID: <545CE6C0.5050702@gmail.com>

On 07/11/2014 10:05 AM, Eric Elguero wrote:
> Hi all,
>
> I'm trying to use the polygon function from
> the graphics package, and get this error
> message :
>
>   > polygon(x=c(1,2,3,1),y=c(1,4,5,1))
> Error in .Internal(polygon(xy$x, xy$y, col, border, lty, ...)) :
>     there is no .Internal function 'polygon'
>
> That annoys me because polygon is actually
> called by several other functions I need.
>
> my R version:
>
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> and I just updated everything.

You are not using the polygon() function from the graphics package, 
you're using one coming from somewhere else (maybe an old version of R, 
or some package).  The polygon() function in the graphics package 
doesn't call .Internal(polygon(..., it calls

.External.graphics(C_polygon, ...

This is one reason why it's a really bad idea to say "yes" when asked 
whether you want to save your R workspace.  If at some point you made a 
copy of the polygon() function and saved it, you're stuck with that one 
forever (or at least until you delete it from your workspace, or even 
better, delete the whole saved workspace).

Duncan Murdoch


From ripley at stats.ox.ac.uk  Fri Nov  7 16:56:18 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 07 Nov 2014 15:56:18 +0000
Subject: [R] Daylight Saving Time
In-Reply-To: <CAJhrTnoSj7gQm_46-LrUvvYHJ0+Y1xDEw+eDg-WEoB6COrG6-w@mail.gmail.com>
References: <CAJhrTnrHLU_SsgAOYMn=b-2P2a4vY2_X=CmuPKKRQi8dLAS5CA@mail.gmail.com>	<694A85C0-0894-4EB4-AA7F-F11942957369@dcn.davis.CA.us>	<CAJhrTno2Wt8XEBAb0uzBU1D2+YYb3xUNm2VC33wPSHbNK57U0A@mail.gmail.com>	<4F87A5B4-6903-4B13-9180-04E66FDC64CF@dcn.davis.CA.us>	<CAJhrTnqxsNWK2rYSie6uJyc0K9_JW+7x-Xv=qtjne_vA6edYTA@mail.gmail.com>	<87FDFAAC-6E4E-4AC9-80E6-5F261AE6E18A@dcn.davis.CA.us>
	<CAJhrTnoSj7gQm_46-LrUvvYHJ0+Y1xDEw+eDg-WEoB6COrG6-w@mail.gmail.com>
Message-ID: <545CEBA2.7060809@stats.ox.ac.uk>

On 07/11/2014 10:21, Vasantha Kumar Kesavan wrote:
> I am Sorry for not explained my requirement to you properly.
>
> As you told in Windows I need to update the $R_HOME/share/zoneinfo with the
> latest time zone information, since R is not using the operating system
> time zone files. Then I have updated the zoneinfo directory, after that it
> is working fine for me in the windows.
>
> In the linux platform by default R is using the operating system timezone
> files available at "/usr/share/zoneinfo" path. Yesterday my question was is
> it there are any way to configure the R to use different path
> ("/tmp/zoneinfo") instead of "/usr/share/zoneinfo".
>
> Then from the internet I came to know that the TZDIR

Well, it is in the R help file: give credit where it is due!

> (TZDIR="/tmp/zoneinfo") environment variable can be used for configure
> different time zone path instead of the default path. By setting the TZDIR
> environment variable in Linux does the need as I am expected. So my
> requirement in Windows and Linux platform are worked out.
>
> Now I like to know, how to do the same in Solaris operating system (when I
> am tried with setting TZDIR environment variable as like Linux but no luck).

Go back to the R manuals: the recommendation for recent R on Solaris is 
to use the tzcode included in R, for which TZDIR does work.

We can write the help and manuals for you, but it is your responsibility 
to do your own homework: see the posting guide.

>
> Thanks
> Vasanth
>
>
>
> On Fri, Nov 7, 2014 at 2:55 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> ?timezones
>>
>> You probably need to recompile R.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 6, 2014 4:10:58 PM EST, Vasantha Kumar Kesavan <
>> info.vasukv at gmail.com> wrote:
>>> In LINUX, I don't want R to use the operating system zoneinfo(Olsen
>>> database) instead of that I like to point different path which has the
>>> latest zoneinfo(latest Olsen database).
>>>
>>> On Fri, Nov 7, 2014 at 2:34 AM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>>> Working now... after what action?
>>>>
>>>> AFAIK on *NIX systems R uses the OS installation of the Olsen
>>> database, so
>>>> on a fresh login R should pick up any OS update you have installed.
>>>>
>>
>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>                                        Live:   OO#.. Dead: OO#..
>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>>
>>
>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On November 6, 2014 3:36:38 PM EST, Vasantha Kumar Kesavan <
>>>> info.vasukv at gmail.com> wrote:
>>>>> Thanks Jeff Newmiller, it is working now.
>>>>>
>>>>> I would like to know, the same kind of configuration can be done in
>>>>> Linux
>>>>> and Solaris platform.
>>>>>
>>>>> Instead of R is mapping to operating system(/usr/share/.
>>>>> /usr/share/lib/)
>>>>> zoneinfo directory.
>>>>>
>>>>> Thanks
>>>>> Vasanth
>>>>>
>>>>> On Fri, Nov 7, 2014 at 1:18 AM, Jeff Newmiller
>>>>> <jdnewmil at dcn.davis.ca.us>
>>>>> wrote:
>>>>>
>>>>>> R on Windows uses the Olsen timezone database, a copy of which is
>>>>> stored
>>>>>> with R in the Program Files directory (e.g.
>>>>> R/R-3.1.1/share/zoneinfo). You
>>>>>> could update the file yourself if you can find a corrected
>>> version,
>>>>> or
>>>>>> download an updated version of R.
>>>>>>
>>>>
>>>>
>>
>>>> ---------------------------------------------------------------------------
>>>>>> Jeff Newmiller                        The     .....       .....
>>> Go
>>>>> Live...
>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
>>> Live
>>>>>> Go...
>>>>>>                                        Live:   OO#.. Dead: OO#..
>>>>> Playing
>>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.
>>> with
>>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>> rocks...1k
>>>>>>
>>>>
>>>>
>>
>>>> ---------------------------------------------------------------------------
>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>
>>>>>> On November 6, 2014 1:16:06 PM EST, Vasantha Kumar Kesavan <
>>>>>> info.vasukv at gmail.com> wrote:
>>>>>>> Hi,
>>>>>>>
>>>>>>> I am working R on windows 2012 R2 platform, I have updated the
>>>>> latest
>>>>>>> hotfixes for time zone information(Microsoft KB 2981580.
>>>>>>> <http://support.microsoft.com/kb/2981580>).
>>>>>>>
>>>>>>> But still R is not populating correct date time values(Standard
>>> and
>>>>>>> Daylight saving).
>>>>>>>
>>>>>>> Could you please advise me, how to enable R to pick up the latest
>>>>> time
>>>>>>> zone
>>>>>>> information/configurations.
>>>>>>>
>>>>>>> Example:
>>>>>>>
>>>>>>> R --vanilla
>>>>>>> Sys.setenv(TZ = "America/Eirunepe");
>>>>>>> dt<-c(seq(as.POSIXct("2013-11-09
>>> 20:00:00",tz="America/Eirunepe"),
>>>>>>> as.POSIXct("2013-11-10 10:00:00" ,tz="America/Eirunepe"),
>>>>> by="hour"));
>>>>>>>> dt
>>>>>>> [1] "2013-11-09 20:00:00 AMT" "2013-11-09 21:00:00 AMT"
>>>>>>> [3] "2013-11-09 22:00:00 AMT" "2013-11-09 23:00:00 AMT"
>>>>>>> [5] "2013-11-10 00:00:00 AMT" "2013-11-10 01:00:00 AMT"
>>>>>>> [7] "2013-11-10 02:00:00 AMT" "2013-11-10 03:00:00 AMT"
>>>>>>> [9] "2013-11-10 04:00:00 AMT" "2013-11-10 05:00:00 AMT"
>>>>>>> [11] "2013-11-10 06:00:00 AMT" "2013-11-10 07:00:00 AMT"
>>>>>>> [13] "2013-11-10 08:00:00 AMT" "2013-11-10 09:00:00 AMT"
>>>>>>> [15] "2013-11-10 10:00:00 AMT"
>>>>>>>
>>>>>>> For the ?*America/Eirunepe*? time zone, the DST ended on Sun
>>>>>>> 10-Nov-2013 at
>>>>>>> 12:00:00 A.M. when local clocks were set backward 1 hour.
>>>>>>>
>>>>>>>
>>>>>>> as per the latest timezone configuration, the date time sequence
>>>>> should
>>>>>>> have "2013-11-09 23:00:00" twice.
>>>>>>>
>>>>>>>
>>>>>>> Thanks
>>>>>>>
>>>>>>> Vasanth
>>>>>>>
>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>
>>>>>>
>>>>
>>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From Eric.Elguero at ird.fr  Fri Nov  7 17:04:01 2014
From: Eric.Elguero at ird.fr (Eric Elguero)
Date: Fri, 07 Nov 2014 17:04:01 +0100
Subject: [R] problem with function "polygon"
In-Reply-To: <545CE6C0.5050702@gmail.com>
References: <545CDFA4.4020205@ird.fr> <545CE6C0.5050702@gmail.com>
Message-ID: <545CED71.10906@ird.fr>

On 11/07/2014 04:35 PM, Duncan Murdoch wrote:

> You are not using the polygon() function from the graphics package,
> you're using one coming from somewhere else (maybe an old version of R,
> or some package).  The polygon() function in the graphics package
> doesn't call .Internal(polygon(..., it calls
>
> .External.graphics(C_polygon, ...
>
> If at some point you made a
> copy of the polygon() function and saved it, you're stuck with that one
> forever (or at least until you delete it from your workspace, or even
> better, delete the whole saved workspace).
>

you're absolutely right. I was usin a "polygon" function
from package ade4 (that I copied to my workspace, don't
remember why). I will ask ade4 developpers.

thank you.

e.e.


From mathias_m_93 at hotmail.com  Fri Nov  7 16:23:37 2014
From: mathias_m_93 at hotmail.com (Mathias Martens)
Date: Fri, 7 Nov 2014 13:23:37 -0200
Subject: [R] EM algorithm for ARIMA models
Message-ID: <COL128-W70681A48F7E0B12CC7638AC3850@phx.gbl>

Hi there,I am working on a time series dataset with a lot of missing data (around60%).Specifically, I need to fit an ARIMA model to this data and I found thatExpectation-Maximization (EM) algorithm using Kalman filter could beusefull.Anyone know if already exist a package for this?Another approaches are usefull as well.
Thanks,Mathias Martens 		 	   		  
	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Fri Nov  7 21:51:37 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 7 Nov 2014 21:51:37 +0100
Subject: [R] EM algorithm for ARIMA models
In-Reply-To: <COL128-W70681A48F7E0B12CC7638AC3850@phx.gbl>
References: <COL128-W70681A48F7E0B12CC7638AC3850@phx.gbl>
Message-ID: <CALJKBv_vbMSHMT=s31gYvodtsv8dSfPuSx9Fb5yAnPD2-Y7pRg@mail.gmail.com>

EBarrays
http://www.bioconductor.org/packages/release/bioc/html/EBarrays.html

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Fri, Nov 7, 2014 at 4:23 PM, Mathias Martens <mathias_m_93 at hotmail.com>
wrote:

> Hi there,I am working on a time series dataset with a lot of missing data
> (around60%).Specifically, I need to fit an ARIMA model to this data and I
> found thatExpectation-Maximization (EM) algorithm using Kalman filter could
> beusefull.Anyone know if already exist a package for this?Another
> approaches are usefull as well.
> Thanks,Mathias Martens
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From yannikin at gmail.com  Fri Nov  7 22:54:11 2014
From: yannikin at gmail.com (Yan Wu)
Date: Fri, 7 Nov 2014 13:54:11 -0800
Subject: [R] Help with a for complex for loop that looks into another data
	frame
Message-ID: <CAOk2wpNb0PYjoFR-SfD2dAYFY-V=qpYkUdyVKxkNAUcxftFi6g@mail.gmail.com>

Hello everyone!

I am working on a stock trading algorithm. I have created a data frame with
the stocks, and a summary data frame, master_df_ex, and master_df_ex_sum,
respectively.

The goal is to create something each day that has equal long and shorts,
and thus for each day, the sum of the ls_flag = 0.

For master_df_ex, there is a rank by strength of magnitude column, up or
down column, then a long or short column.

The ls_flag is set by the updn_flag for the stocks that are ranked in the
top half (in this case, since we have 4 per day, rank = 1 and rank = 2 are
set by updn_flag.

*I need to create a process to fill in the NA's in the ls_flag.*

My thinking is to create a summary table, where i run a summary,replace the
contents, until both the NA are 0 and the sum of the ls_flag =0.

For example, here is the current data:

asof_dt<-rep(seq(as.Date("2014-10-01"), as.Date("2014-10-03"), "days"),4)

rank_mag<-(rep(seq(1,4),3))

updn_flag<-c(-1,-1,-1,1,-1,-1,1,1,-1,1,-1,-1)

ls_flag<-c(-1,-1,NA,NA,-1,-1,NA,NA,-1,1,NA,NA)

master_df_ex<-data.frame(asof_dt,rank_mag,updn_flag,ls_flag)

master_df_ex<-arrange(master_df_ex,asof_dt,rank_mag)

master_df_ex_sum<-summarise(master_df,tot_flag = sum(ls_flag, na.rm = TRUE),

                        tot_NA = sum(is.na(ls_flag)))

> master_df_ex

      asof_dt rank_mag updn_flag ls_flag

1  2014-10-01        1        -1      -1

2  2014-10-01        2         1       1

3  2014-10-01        3         1      NA

4  2014-10-01        4         1      NA

5  2014-10-02        1        -1      -1

6  2014-10-02        2        -1      -1

7  2014-10-02        3        -1      NA

8  2014-10-02        4         1      NA

9  2014-10-03        1         1       1

10 2014-10-03        2         1       1

11 2014-10-03        3         1      NA

12 2014-10-03        4        -1      NA

> master_df_ex_sum

Source: local data frame [3 x 3]


 asof_dt tot_flag tot_NA

1 2014-10-01        0      2

2 2014-10-02       -2      2

3 2014-10-03        2      2

For 2014-10-02, since the the tot_flag = -2, the NA's for this date should
both be -1

For 2014-10-03, since the tot_flag = 2, the NA's should both be -1

For 2014-10-01 (hardest one):

The logic should look at 2014-10-01 in master_df_ex_sum, since tot_NA is
not 0, go into master_df_ex and find the lowest rank by rank_mag where
ls_flag is NA. Assign ls_flag = 1.

Then run the summary again, the NAs will be 1, and the sum of ls_flag will
be 1.

Then it should go into master_df_ex again, and assign a -1 to line 4. Then
the summary will have 0 and 0 and this date should be done.

I hope that makes sense! Any help is appreciated! Thank you very much.

-- 
Yan Wu
510-333-3188 <http://bigkidsbighearts.org>
yannikin at gmail.com

	[[alternative HTML version deleted]]


From chidambaramselvakumar at gmail.com  Sat Nov  8 07:10:31 2014
From: chidambaramselvakumar at gmail.com (Chidambaram Selvakumar)
Date: Sat, 8 Nov 2014 11:40:31 +0530
Subject: [R] Urgent Help - Editing XML through R
Message-ID: <CA+WmytSNO-_dEjNp-Jabo-eLcEwdLeNui9-3VgNF09AAmODziw@mail.gmail.com>

Hi Team,

I have the below xml file where i have to find and remove all the email
address in <string> tag and need to append the new email address using R
script.May be string tag needs to be added or decreased based on the email
list.

*XM File *

<?xml version="1.0" encoding="utf-8"?>
<as:Job xmlns:as="urn:tibco:spotfire.dxp.automation">
  <as:Tasks>
    <OpenAnalysisFromLibrary
xmlns="urn:tibco:spotfire.dxp.automation.tasks">
      <as:Title>Open Analysis from Library</as:Title>
      <AnalysisPath>/Z- Archive - TO BE
purged/ConditionEmailTest</AnalysisPath>
    </OpenAnalysisFromLibrary>
    <SendEmail xmlns="urn:tibco:spotfire.dxp.automation.tasks">
      <as:Title>Send Email</as:Title>
      <Recipients>
       * <string>chidambaramselvakumar at gmail.com
<chidambaramselvakumar at gmail.com></string>*
* <string>chidambaramselvakumar at gmail.com
<chidambaramselvakumar at gmail.com></string>*
      </Recipients>
      <Subject>Sales Report</Subject>
      <Message>Hi,

Good Day!

Thanks for achieving your sales target.

Regards,
Chidambaram</Message>
      <Links />
      <Attachments />
    </SendEmail>
  </as:Tasks>
</as:Job>

Kindly help me. It is little urgent.

Thanks in advance for your effort and support.

Regards,
Chidambaram

	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Sat Nov  8 12:49:14 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sat, 8 Nov 2014 07:49:14 -0400
Subject: [R] how to determine power in my analysis?
Message-ID: <COL130-W8371DEF1C9AA8BA098B904FA820@phx.gbl>

Hi R Users, 
I was trying to determine whether I have enough samples and power in my analysis. Would you mind to provide some hints?.  I found a several packages for power analysis but did not find any example data. I have two sites and each site has 4 groups. I wanted to test whether there was an effect of restoration activities and sites on the observed value. I used a two way factorial ANOVA and now I wanted to test the power of the analysis (whether the sample sizes are enough for the analysis? what are the alpha and power in the analysis using this data set? if it is not enough, how much samples should be collected for alpha 0.05 and power=0.8 and 0.9 for the analysis (two way factorial analysis). 
The example data:data<-structure(list(observedValue = c(0.08, 0.53, 0.14, 0.66, 0.37, 0.88, 0.84, 0.46, 0.3, 0.61, 0.75, 0.82, 0.67, 0.37, 0.95, 0.73, 0.74, 0.69, 0.06, 0.97, 0.97, 0.07, 0.75, 0.68, 0.53, 0.72, 0.34, 0.12, 0.49, 0.77, 0.45, 0.07, 0.97, 0.34, 0.68, 0.48, 0.65, 0.7, 0.57, 0.66, 0.4, 0.29, 0.88, 0.36, 0.68, 0.32, 0.8, 0, 0.11, 0.48, 0.85, 0.94, 0.12, 0.12, 0, 0.89, 0.66, 0.2, 0.57, 0.09, 0.27, 0.81, 0.53, 0.09, 0.5, 0.41, 0.89, 0.47, 0.39, 0.85, 0.71, 0.89, 0.01, 0.71, 0.42, 0.72, 0.62, 0.3, 0.56, 0.99, 0.97, 0.03, 0.09, 0.27, 0.27, 0.94, 0.23, 0.97, 0.81, 0.95), condition = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("good", "medium", "poor", "verygood"), class = "factor"), areas = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Restored", "unrestored"), class = "factor")), .Names = c("observedValue", "condition", "areas"), class = "data.frame", row.names = c(NA, -90L))
test= aov(observedValue~condition*areas,data=data)summary(test)
power of the analysis?
thanks for your help. 
Sincerely, KG
 		 	   		  
	[[alternative HTML version deleted]]


From ecnolasco at gmail.com  Sat Nov  8 16:16:38 2014
From: ecnolasco at gmail.com (Erica Cseko Nolasco)
Date: Sat, 8 Nov 2014 12:16:38 -0300
Subject: [R] Distance matrix for Spatial Filtering {spdep}
Message-ID: <CAMbrGjFngsOFUdo1PBb2A1Ysqk8cVLvEV5AEL-K9_3v2pLnZjQ@mail.gmail.com>

Hi all,

I?m working on a species distribution modeling, and I want to build
eigenvectors to represent my spatial varuable. I?m trying to use
SpatialFiltering(spdep) for it, but I?m having problems to create the nb
object. My weights would be a truncated pairwise distance matrix that I was
pretty able to build. However, I?m going out resources to create a nb
object. Or it doesn?t match the matrix or the R-Studio crashes. Here is the
code I?m trying:

> ###creating the distance matrix

> library(fossil)

> setwd("G:/database/mapas/registros")

> coo=read.table("coordinates16.txt",sep=" ")

> coor1=as.data.frame(coo)

> length(coor1[,1]

[1] 4922

> matriz3=earth.dist(coor1, dist=T)

> length(matriz3)

[1] 12110581

> ###truncating the distance matrix

> matriz3[matriz3>=230]=230
> ###creating the nb object to link to the distance matrix

> library(spdep)

>coord=read.table("coordinates16.txt",sep=" ", header=T)

> coo=cbind(coord[,1],coord[,2])

> length(coo[,1])
[1] 4922

>nb=dnearneigh(coo,0, 10000, longlat=T) ###large nb (4922 elements,92.9Mb)

> nb2listw(nb,glist=matriz3,style="W")

*Error in nb2listw(nb, glist = matriz3, style = "W") : glist wrong length*

>nb=knearneigh(coo,4921,longlat=T) ##second try to create nb, 4921 is the
required number for my project

*R session aborted. R encoutered a fatal error. The session was terminated*

>nb=knearneigh(coo,1000,longlat=T) ##second try to create nb

*R session aborted. R encoutered a fatal error. The session was terminated*

> nb=knearneigh(coo,500,longlat=T) ###tentativa de criar nb

*Error in knearneigh(coo, 500, longlat = T) : too many ties in knearneigh*

>nb=knearneigh(coo,400,longlat=T) #Large knn (5 elements,7.6Mb), I believe
I need the same number of elements as my distance matrix (12110581)

> nb2listw(nb,glist=matriz3,style="W")

*Error in nb2listw(nb, glist = matriz3, style = "W") : *
  *Not a neighbours list*

Any ideas would help a lot! Thanks in advance

*Erica Csek? Nolasco*
Mestranda em Modelagem em Ci?ncias da Terra e do Ambiente
http://lattes.cnpq.br/2117508819823917
Laborat?rio de Ornitologia - Sala 03, LABIO
Universidade Estadual de Feira de Santana
Avenida Transnordestina s/n, Novo Horizonte
Feira de Santana - BA, Brasil CEP 44.036-900.
Tel/Fax: 55(75)3224-8295

Graduate Student in Modeling of Environmental and Earth Sciences
http://lattes.cnpq.br/2117508819823917
Ornithology Lab - 03 room, LABIO
Universidade Estadual de Feira de Santana
Transnordestina Ave, Novo Horizonte
Feira de Santana - BA, Brazil 44.036-900.
55(75)3224-8295

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Nov  8 18:39:10 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 08 Nov 2014 12:39:10 -0500
Subject: [R] Urgent Help - Editing XML through R
In-Reply-To: <CA+WmytSNO-_dEjNp-Jabo-eLcEwdLeNui9-3VgNF09AAmODziw@mail.gmail.com>
References: <CA+WmytSNO-_dEjNp-Jabo-eLcEwdLeNui9-3VgNF09AAmODziw@mail.gmail.com>
Message-ID: <545E553E.7090103@gmail.com>

On 08/11/2014, 1:10 AM, Chidambaram Selvakumar wrote:
> Hi Team,
> 
> I have the below xml file where i have to find and remove all the email
> address in <string> tag and need to append the new email address using R
> script.May be string tag needs to be added or decreased based on the email
> list.
> 
> *XM File *
> 
> <?xml version="1.0" encoding="utf-8"?>
> <as:Job xmlns:as="urn:tibco:spotfire.dxp.automation">
>   <as:Tasks>
>     <OpenAnalysisFromLibrary
> xmlns="urn:tibco:spotfire.dxp.automation.tasks">
>       <as:Title>Open Analysis from Library</as:Title>
>       <AnalysisPath>/Z- Archive - TO BE
> purged/ConditionEmailTest</AnalysisPath>
>     </OpenAnalysisFromLibrary>
>     <SendEmail xmlns="urn:tibco:spotfire.dxp.automation.tasks">

Shouldn't you be contacting Tibco for help with Tibco Spotfire?

Duncan Murdoch

>       <as:Title>Send Email</as:Title>
>       <Recipients>
>        * <string>chidambaramselvakumar at gmail.com
> <chidambaramselvakumar at gmail.com></string>*
> * <string>chidambaramselvakumar at gmail.com
> <chidambaramselvakumar at gmail.com></string>*
>       </Recipients>
>       <Subject>Sales Report</Subject>
>       <Message>Hi,
> 
> Good Day!
> 
> Thanks for achieving your sales target.
> 
> Regards,
> Chidambaram</Message>
>       <Links />
>       <Attachments />
>     </SendEmail>
>   </as:Tasks>
> </as:Job>
> 
> Kindly help me. It is little urgent.
> 
> Thanks in advance for your effort and support.
> 
> Regards,
> Chidambaram
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From eiovidal at hotmail.com  Sat Nov  8 19:34:25 2014
From: eiovidal at hotmail.com (Edison Iglesias de Oliveira)
Date: Sat, 8 Nov 2014 16:34:25 -0200
Subject: [R] Help with sample size calculation for inter-rater reliability
	study
Message-ID: <BLU174-W2D5DCF9170612253A9AB1DA820@phx.gbl>

Dear R masters,

I am attempting to calculate the sample size for an inter-rater reliability
study using the N2.cohen.kappa function of the irr package. 

It is a study of 2 raters for a single item with three possible ordinal
outcomes. The expected marginal probabilities for those outcomes are 0.2,
0.6 and 0.2. 

The null hypothesis is that kappa < 0.8
The alternative hypotheis is kappa >=0.8

The following example comes from the irr package manual

require(lpSolve)
     # Testing H0: kappa = 0.4 vs. HA: kappa > 0.4 (=0.6) given that
     # Marginal Probabilities by two raters are (0.2, 0.25, 0.55).
     #
     # one sided test with 80% power:
     N2.cohen.kappa(c(0.2, 0.25, 0.55), k1=0.6, k0=0.4)
     # one sided test with 90% power:
     N2.cohen.kappa(c(0.2, 0.25, 0.55), k1=0.6, k0=0.4, power=0.9)
     # Marginal Probabilities by two raters are (0.2, 0.05, 0.2, 0.05, 0.2,
0.3)
     # Testing H0: kappa = 0.1 vs. HA: kappa > 0.1 (=0.5) given that
     #
     # one sided test with 80% power:
     N2.cohen.kappa(c(0.2, 0.05, 0.2, 0.05, 0.2, 0.3), k1=0.5, k0=0.1)


In my case I would be testing H0: kappa < 0.8 vs HA: kappa >= 08 given
Marginal probabilities by two raters as (0.2, 0.6, 0.2)

However the following argument will not work

N2.cohen.kappa (mrg=c(0.2,0.6,0.2), k1>=0.8, k0<0.8, alpha=0.05, power= 0.8,
twosided=FALSE)

I have also tried the kappaSize package without success

Power3Cats(kappa0<0.8, kappa1>=0.8, props=c(0.2,0.6,0.2), raters=2,
alpha=0.05, power=0.80)

Can anyone offer me some guidance?

Best regards,

Edison 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sat Nov  8 19:55:56 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 8 Nov 2014 10:55:56 -0800
Subject: [R] how to determine power in my analysis?
In-Reply-To: <COL130-W8371DEF1C9AA8BA098B904FA820@phx.gbl>
References: <COL130-W8371DEF1C9AA8BA098B904FA820@phx.gbl>
Message-ID: <CACk-te1B5dL22S+VyX4MYRTcRXmLuJ-cxs_z6LXOFEoHmO4sZA@mail.gmail.com>

Kristi:

Power is a prespecified property of the design, not a post hoc
property of the analysis (SAS procedures notwithstanding). So you're a
day late and a dollar short.

I suggest you consult with a local statistician about such matters, as
you appear to be out of your depth.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Nov 8, 2014 at 3:49 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> Hi R Users,
> I was trying to determine whether I have enough samples and power in my analysis. Would you mind to provide some hints?.  I found a several packages for power analysis but did not find any example data. I have two sites and each site has 4 groups. I wanted to test whether there was an effect of restoration activities and sites on the observed value. I used a two way factorial ANOVA and now I wanted to test the power of the analysis (whether the sample sizes are enough for the analysis? what are the alpha and power in the analysis using this data set? if it is not enough, how much samples should be collected for alpha 0.05 and power=0.8 and 0.9 for the analysis (two way factorial analysis).
> The example data:data<-structure(list(observedValue = c(0.08, 0.53, 0.14, 0.66, 0.37, 0.88, 0.84, 0.46, 0.3, 0.61, 0.75, 0.82, 0.67, 0.37, 0.95, 0.73, 0.74, 0.69, 0.06, 0.97, 0.97, 0.07, 0.75, 0.68, 0.53, 0.72, 0.34, 0.12, 0.49, 0.77, 0.45, 0.07, 0.97, 0.34, 0.68, 0.48, 0.65, 0.7, 0.57, 0.66, 0.4, 0.29, 0.88, 0.36, 0.68, 0.32, 0.8, 0, 0.11, 0.48, 0.85, 0.94, 0.12, 0.12, 0, 0.89, 0.66, 0.2, 0.57, 0.09, 0.27, 0.81, 0.53, 0.09, 0.5, 0.41, 0.89, 0.47, 0.39, 0.85, 0.71, 0.89, 0.01, 0.71, 0.42, 0.72, 0.62, 0.3, 0.56, 0.99, 0.97, 0.03, 0.09, 0.27, 0.27, 0.94, 0.23, 0.97, 0.81, 0.95), condition = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("good", "!
>  medium", "poor", "verygood"), class = "factor"), areas = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Restored", "unrestored"), class = "factor")), .Names = c("observedValue", "condition", "areas"), class = "data.frame", row.names = c(NA, -90L))
> test= aov(observedValue~condition*areas,data=data)summary(test)
> power of the analysis?
> thanks for your help.
> Sincerely, KG
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kristi.glover at hotmail.com  Sat Nov  8 20:25:18 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sat, 8 Nov 2014 15:25:18 -0400
Subject: [R] how to determine power in my analysis?
In-Reply-To: <CACk-te1B5dL22S+VyX4MYRTcRXmLuJ-cxs_z6LXOFEoHmO4sZA@mail.gmail.com>
References: <COL130-W8371DEF1C9AA8BA098B904FA820@phx.gbl>,
	<CACk-te1B5dL22S+VyX4MYRTcRXmLuJ-cxs_z6LXOFEoHmO4sZA@mail.gmail.com>
Message-ID: <COL130-W79D2E75FA0D1528AC206C4FA820@phx.gbl>

Hi Bert, Thanks for the message. So far I know we can test whether my sample size in my analysis is enough or not. It is also post hoc property. For example, we can calculate standard deviations, error variance  etc in the data sets, and then we can use them to determine whether the sample size was enough or not with certain level of alpha and power. we can do it is some of the statistical programs, but I was not aware in R. thanks KG

> Date: Sat, 8 Nov 2014 10:55:56 -0800
> Subject: Re: [R] how to determine power in my analysis?
> From: gunter.berton at gene.com
> To: kristi.glover at hotmail.com
> CC: r-help at stat.math.ethz.ch
> 
> Kristi:
> 
> Power is a prespecified property of the design, not a post hoc
> property of the analysis (SAS procedures notwithstanding). So you're a
> day late and a dollar short.
> 
> I suggest you consult with a local statistician about such matters, as
> you appear to be out of your depth.
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Sat, Nov 8, 2014 at 3:49 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> > Hi R Users,
> > I was trying to determine whether I have enough samples and power in my analysis. Would you mind to provide some hints?.  I found a several packages for power analysis but did not find any example data. I have two sites and each site has 4 groups. I wanted to test whether there was an effect of restoration activities and sites on the observed value. I used a two way factorial ANOVA and now I wanted to test the power of the analysis (whether the sample sizes are enough for the analysis? what are the alpha and power in the analysis using this data set? if it is not enough, how much samples should be collected for alpha 0.05 and power=0.8 and 0.9 for the analysis (two way factorial analysis).
> > The example data:data<-structure(list(observedValue = c(0.08, 0.53, 0.14, 0.66, 0.37, 0.88, 0.84, 0.46, 0.3, 0.61, 0.75, 0.82, 0.67, 0.37, 0.95, 0.73, 0.74, 0.69, 0.06, 0.97, 0.97, 0.07, 0.75, 0.68, 0.53, 0.72, 0.34, 0.12, 0.49, 0.77, 0.45, 0.07, 0.97, 0.34, 0.68, 0.48, 0.65, 0.7, 0.57, 0.66, 0.4, 0.29, 0.88, 0.36, 0.68, 0.32, 0.8, 0, 0.11, 0.48, 0.85, 0.94, 0.12, 0.12, 0, 0.89, 0.66, 0.2, 0.57, 0.09, 0.27, 0.81, 0.53, 0.09, 0.5, 0.41, 0.89, 0.47, 0.39, 0.85, 0.71, 0.89, 0.01, 0.71, 0.42, 0.72, 0.62, 0.3, 0.56, 0.99, 0.97, 0.03, 0.09, 0.27, 0.27, 0.94, 0.23, 0.97, 0.81, 0.95), condition = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("good", "!
> >  medium", "poor", "verygood"), class = "factor"), areas = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Restored", "unrestored"), class = "factor")), .Names = c("observedValue", "condition", "areas"), class = "data.frame", row.names = c(NA, -90L))
> > test= aov(observedValue~condition*areas,data=data)summary(test)
> > power of the analysis?
> > thanks for your help.
> > Sincerely, KG
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From djmuser at gmail.com  Sat Nov  8 22:36:35 2014
From: djmuser at gmail.com (Dennis Murphy)
Date: Sat, 8 Nov 2014 13:36:35 -0800
Subject: [R] how to determine power in my analysis?
In-Reply-To: <COL130-W79D2E75FA0D1528AC206C4FA820@phx.gbl>
References: <COL130-W8371DEF1C9AA8BA098B904FA820@phx.gbl>
	<CACk-te1B5dL22S+VyX4MYRTcRXmLuJ-cxs_z6LXOFEoHmO4sZA@mail.gmail.com>
	<COL130-W79D2E75FA0D1528AC206C4FA820@phx.gbl>
Message-ID: <CADv2QyGomWC+0TpjUfkJ+f_KsZYzE-YQLKahbo=mg+D296khRg@mail.gmail.com>

Hi Kristi:

I think this paper elucidates the problem Bert mentioned. A thorough
and careful reading of the last two sections should clarify what
post-hoc power is and is not.

http://www.stat.uiowa.edu/files/stat/techrep/tr378.pdf

Dennis

On Sat, Nov 8, 2014 at 11:25 AM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi Bert, Thanks for the message. So far I know we can test whether my sample size in my analysis is enough or not. It is also post hoc property. For example, we can calculate standard deviations, error variance  etc in the data sets, and then we can use them to determine whether the sample size was enough or not with certain level of alpha and power. we can do it is some of the statistical programs, but I was not aware in R. thanks KG
>
>> Date: Sat, 8 Nov 2014 10:55:56 -0800
>> Subject: Re: [R] how to determine power in my analysis?
>> From: gunter.berton at gene.com
>> To: kristi.glover at hotmail.com
>> CC: r-help at stat.math.ethz.ch
>>
>> Kristi:
>>
>> Power is a prespecified property of the design, not a post hoc
>> property of the analysis (SAS procedures notwithstanding). So you're a
>> day late and a dollar short.
>>
>> I suggest you consult with a local statistician about such matters, as
>> you appear to be out of your depth.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Sat, Nov 8, 2014 at 3:49 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
>> > Hi R Users,
>> > I was trying to determine whether I have enough samples and power in my analysis. Would you mind to provide some hints?.  I found a several packages for power analysis but did not find any example data. I have two sites and each site has 4 groups. I wanted to test whether there was an effect of restoration activities and sites on the observed value. I used a two way factorial ANOVA and now I wanted to test the power of the analysis (whether the sample sizes are enough for the analysis? what are the alpha and power in the analysis using this data set? if it is not enough, how much samples should be collected for alpha 0.05 and power=0.8 and 0.9 for the analysis (two way factorial analysis).
>> > The example data:data<-structure(list(observedValue = c(0.08, 0.53, 0.14, 0.66, 0.37, 0.88, 0.84, 0.46, 0.3, 0.61, 0.75, 0.82, 0.67, 0.37, 0.95, 0.73, 0.74, 0.69, 0.06, 0.97, 0.97, 0.07, 0.75, 0.68, 0.53, 0.72, 0.34, 0.12, 0.49, 0.77, 0.45, 0.07, 0.97, 0.34, 0.68, 0.48, 0.65, 0.7, 0.57, 0.66, 0.4, 0.29, 0.88, 0.36, 0.68, 0.32, 0.8, 0, 0.11, 0.48, 0.85, 0.94, 0.12, 0.12, 0, 0.89, 0.66, 0.2, 0.57, 0.09, 0.27, 0.81, 0.53, 0.09, 0.5, 0.41, 0.89, 0.47, 0.39, 0.85, 0.71, 0.89, 0.01, 0.71, 0.42, 0.72, 0.62, 0.3, 0.56, 0.99, 0.97, 0.03, 0.09, 0.27, 0.27, 0.94, 0.23, 0.97, 0.81, 0.95), condition = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("good!
>  ", "!
>> >  medium", "poor", "verygood"), class = "factor"), areas = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Restored", "unrestored"), class = "factor")), .Names = c("observedValue", "condition", "areas"), class = "data.frame", row.names = c(NA, -90L))
>> > test= aov(observedValue~condition*areas,data=data)summary(test)
>> > power of the analysis?
>> > thanks for your help.
>> > Sincerely, KG
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kristi.glover at hotmail.com  Sat Nov  8 23:56:05 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sat, 8 Nov 2014 18:56:05 -0400
Subject: [R] how to determine power in my analysis?
In-Reply-To: <CADv2QyGomWC+0TpjUfkJ+f_KsZYzE-YQLKahbo=mg+D296khRg@mail.gmail.com>
References: <COL130-W8371DEF1C9AA8BA098B904FA820@phx.gbl>,
	<CACk-te1B5dL22S+VyX4MYRTcRXmLuJ-cxs_z6LXOFEoHmO4sZA@mail.gmail.com>,
	<COL130-W79D2E75FA0D1528AC206C4FA820@phx.gbl>,
	<CADv2QyGomWC+0TpjUfkJ+f_KsZYzE-YQLKahbo=mg+D296khRg@mail.gmail.com>
Message-ID: <COL130-W8653DBA99BC7F5C9470AE9FA820@phx.gbl>

Dear Dennis, I really appreciated for your and Bert's help. I read the paper and it seems that once the study is completed, power calculations do not inform us in any way as to the conclusions of the present study. But I am really now confused whether we can't improve the research design for future or next year monitoring based on the present results. I would really be grateful for your suggestions and insights. Can't we take reference from the present study for improving future sampling?Thanks KG

> Date: Sat, 8 Nov 2014 13:36:35 -0800
> Subject: Re: [R] how to determine power in my analysis?
> From: djmuser at gmail.com
> To: kristi.glover at hotmail.com
> CC: gunter.berton at gene.com; r-help at stat.math.ethz.ch
> 
> Hi Kristi:
> 
> I think this paper elucidates the problem Bert mentioned. A thorough
> and careful reading of the last two sections should clarify what
> post-hoc power is and is not.
> 
> http://www.stat.uiowa.edu/files/stat/techrep/tr378.pdf
> 
> Dennis
> 
> On Sat, Nov 8, 2014 at 11:25 AM, Kristi Glover
> <kristi.glover at hotmail.com> wrote:
> > Hi Bert, Thanks for the message. So far I know we can test whether my sample size in my analysis is enough or not. It is also post hoc property. For example, we can calculate standard deviations, error variance  etc in the data sets, and then we can use them to determine whether the sample size was enough or not with certain level of alpha and power. we can do it is some of the statistical programs, but I was not aware in R. thanks KG
> >
> >> Date: Sat, 8 Nov 2014 10:55:56 -0800
> >> Subject: Re: [R] how to determine power in my analysis?
> >> From: gunter.berton at gene.com
> >> To: kristi.glover at hotmail.com
> >> CC: r-help at stat.math.ethz.ch
> >>
> >> Kristi:
> >>
> >> Power is a prespecified property of the design, not a post hoc
> >> property of the analysis (SAS procedures notwithstanding). So you're a
> >> day late and a dollar short.
> >>
> >> I suggest you consult with a local statistician about such matters, as
> >> you appear to be out of your depth.
> >>
> >> Cheers,
> >> Bert
> >>
> >> Bert Gunter
> >> Genentech Nonclinical Biostatistics
> >> (650) 467-7374
> >>
> >> "Data is not information. Information is not knowledge. And knowledge
> >> is certainly not wisdom."
> >> Clifford Stoll
> >>
> >>
> >>
> >>
> >> On Sat, Nov 8, 2014 at 3:49 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> >> > Hi R Users,
> >> > I was trying to determine whether I have enough samples and power in my analysis. Would you mind to provide some hints?.  I found a several packages for power analysis but did not find any example data. I have two sites and each site has 4 groups. I wanted to test whether there was an effect of restoration activities and sites on the observed value. I used a two way factorial ANOVA and now I wanted to test the power of the analysis (whether the sample sizes are enough for the analysis? what are the alpha and power in the analysis using this data set? if it is not enough, how much samples should be collected for alpha 0.05 and power=0.8 and 0.9 for the analysis (two way factorial analysis).
> >> > The example data:data<-structure(list(observedValue = c(0.08, 0.53, 0.14, 0.66, 0.37, 0.88, 0.84, 0.46, 0.3, 0.61, 0.75, 0.82, 0.67, 0.37, 0.95, 0.73, 0.74, 0.69, 0.06, 0.97, 0.97, 0.07, 0.75, 0.68, 0.53, 0.72, 0.34, 0.12, 0.49, 0.77, 0.45, 0.07, 0.97, 0.34, 0.68, 0.48, 0.65, 0.7, 0.57, 0.66, 0.4, 0.29, 0.88, 0.36, 0.68, 0.32, 0.8, 0, 0.11, 0.48, 0.85, 0.94, 0.12, 0.12, 0, 0.89, 0.66, 0.2, 0.57, 0.09, 0.27, 0.81, 0.53, 0.09, 0.5, 0.41, 0.89, 0.47, 0.39, 0.85, 0.71, 0.89, 0.01, 0.71, 0.42, 0.72, 0.62, 0.3, 0.56, 0.99, 0.97, 0.03, 0.09, 0.27, 0.27, 0.94, 0.23, 0.97, 0.81, 0.95), condition = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("good!
> >  ", "!
> >> >  medium", "poor", "verygood"), class = "factor"), areas = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Restored", "unrestored"), class = "factor")), .Names = c("observedValue", "condition", "areas"), class = "data.frame", row.names = c(NA, -90L))
> >> > test= aov(observedValue~condition*areas,data=data)summary(test)
> >> > power of the analysis?
> >> > thanks for your help.
> >> > Sincerely, KG
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Nov  9 01:55:38 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 8 Nov 2014 16:55:38 -0800
Subject: [R] how to determine power in my analysis?
In-Reply-To: <COL130-W8653DBA99BC7F5C9470AE9FA820@phx.gbl>
References: <COL130-W8371DEF1C9AA8BA098B904FA820@phx.gbl>
	<CACk-te1B5dL22S+VyX4MYRTcRXmLuJ-cxs_z6LXOFEoHmO4sZA@mail.gmail.com>
	<COL130-W79D2E75FA0D1528AC206C4FA820@phx.gbl>
	<CADv2QyGomWC+0TpjUfkJ+f_KsZYzE-YQLKahbo=mg+D296khRg@mail.gmail.com>
	<COL130-W8653DBA99BC7F5C9470AE9FA820@phx.gbl>
Message-ID: <CACk-te3vTJAuK-b0VqWX75KRO1ag3=gsEeJHBxx9kHLV_-qjJQ@mail.gmail.com>

This is discussion is now off topic here. Either post elsewhere, e.g
stats.stackexchange.com, or consult your local statistician for help,
as I previously suggested.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Nov 8, 2014 at 2:56 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> Dear Dennis,
> I really appreciated for your and Bert's help. I read the paper and it seems
> that once the study is completed, power calculations do not inform us in any
> way as to the conclusions of the present study. But I am really now confused
> whether we can't improve the research design for future or next year
> monitoring based on the present results. I would really be grateful for your
> suggestions and insights. Can't we take reference from the present study for
> improving future sampling?
> Thanks
> KG
>
>> Date: Sat, 8 Nov 2014 13:36:35 -0800
>> Subject: Re: [R] how to determine power in my analysis?
>> From: djmuser at gmail.com
>> To: kristi.glover at hotmail.com
>> CC: gunter.berton at gene.com; r-help at stat.math.ethz.ch
>>
>> Hi Kristi:
>>
>> I think this paper elucidates the problem Bert mentioned. A thorough
>> and careful reading of the last two sections should clarify what
>> post-hoc power is and is not.
>>
>> http://www.stat.uiowa.edu/files/stat/techrep/tr378.pdf
>>
>> Dennis
>>
>> On Sat, Nov 8, 2014 at 11:25 AM, Kristi Glover
>> <kristi.glover at hotmail.com> wrote:
>> > Hi Bert, Thanks for the message. So far I know we can test whether my
>> > sample size in my analysis is enough or not. It is also post hoc property.
>> > For example, we can calculate standard deviations, error variance etc in the
>> > data sets, and then we can use them to determine whether the sample size was
>> > enough or not with certain level of alpha and power. we can do it is some of
>> > the statistical programs, but I was not aware in R. thanks KG
>> >
>> >> Date: Sat, 8 Nov 2014 10:55:56 -0800
>> >> Subject: Re: [R] how to determine power in my analysis?
>> >> From: gunter.berton at gene.com
>> >> To: kristi.glover at hotmail.com
>> >> CC: r-help at stat.math.ethz.ch
>> >>
>> >> Kristi:
>> >>
>> >> Power is a prespecified property of the design, not a post hoc
>> >> property of the analysis (SAS procedures notwithstanding). So you're a
>> >> day late and a dollar short.
>> >>
>> >> I suggest you consult with a local statistician about such matters, as
>> >> you appear to be out of your depth.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >> Bert Gunter
>> >> Genentech Nonclinical Biostatistics
>> >> (650) 467-7374
>> >>
>> >> "Data is not information. Information is not knowledge. And knowledge
>> >> is certainly not wisdom."
>> >> Clifford Stoll
>> >>
>> >>
>> >>
>> >>
>> >> On Sat, Nov 8, 2014 at 3:49 AM, Kristi Glover
>> >> <kristi.glover at hotmail.com> wrote:
>> >> > Hi R Users,
>> >> > I was trying to determine whether I have enough samples and power in
>> >> > my analysis. Would you mind to provide some hints?. I found a several
>> >> > packages for power analysis but did not find any example data. I have two
>> >> > sites and each site has 4 groups. I wanted to test whether there was an
>> >> > effect of restoration activities and sites on the observed value. I used a
>> >> > two way factorial ANOVA and now I wanted to test the power of the analysis
>> >> > (whether the sample sizes are enough for the analysis? what are the alpha
>> >> > and power in the analysis using this data set? if it is not enough, how much
>> >> > samples should be collected for alpha 0.05 and power=0.8 and 0.9 for the
>> >> > analysis (two way factorial analysis).
>> >> > The example data:data<-structure(list(observedValue = c(0.08, 0.53,
>> >> > 0.14, 0.66, 0.37, 0.88, 0.84, 0.46, 0.3, 0.61, 0.75, 0.82, 0.67, 0.37, 0.95,
>> >> > 0.73, 0.74, 0.69, 0.06, 0.97, 0.97, 0.07, 0.75, 0.68, 0.53, 0.72, 0.34,
>> >> > 0.12, 0.49, 0.77, 0.45, 0.07, 0.97, 0.34, 0.68, 0.48, 0.65, 0.7, 0.57, 0.66,
>> >> > 0.4, 0.29, 0.88, 0.36, 0.68, 0.32, 0.8, 0, 0.11, 0.48, 0.85, 0.94, 0.12,
>> >> > 0.12, 0, 0.89, 0.66, 0.2, 0.57, 0.09, 0.27, 0.81, 0.53, 0.09, 0.5, 0.41,
>> >> > 0.89, 0.47, 0.39, 0.85, 0.71, 0.89, 0.01, 0.71, 0.42, 0.72, 0.62, 0.3, 0.56,
>> >> > 0.99, 0.97, 0.03, 0.09, 0.27, 0.27, 0.94, 0.23, 0.97, 0.81, 0.95), condition
>> >> > = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>> >> > 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>> >> > 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> >> > 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> >> > 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L),
>> >> > .Label = c("good!
>> > ", "!
>> >> > medium", "poor", "verygood"), class = "factor"), areas =
>> >> > structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> >> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> >> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> >> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> >> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label
>> >> > = c("Restored", "unrestored"), class = "factor")), .Names =
>> >> > c("observedValue", "condition", "areas"), class = "data.frame", row.names =
>> >> > c(NA, -90L))
>> >> > test= aov(observedValue~condition*areas,data=data)summary(test)
>> >> > power of the analysis?
>> >> > thanks for your help.
>> >> > Sincerely, KG
>> >> >
>> >> > [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sun Nov  9 02:15:11 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 9 Nov 2014 14:15:11 +1300
Subject: [R] how to determine power in my analysis?
In-Reply-To: <COL130-W8653DBA99BC7F5C9470AE9FA820@phx.gbl>
References: <COL130-W8371DEF1C9AA8BA098B904FA820@phx.gbl>,
	<CACk-te1B5dL22S+VyX4MYRTcRXmLuJ-cxs_z6LXOFEoHmO4sZA@mail.gmail.com>,
	<COL130-W79D2E75FA0D1528AC206C4FA820@phx.gbl>,
	<CADv2QyGomWC+0TpjUfkJ+f_KsZYzE-YQLKahbo=mg+D296khRg@mail.gmail.com>
	<COL130-W8653DBA99BC7F5C9470AE9FA820@phx.gbl>
Message-ID: <545EC01F.6010909@auckland.ac.nz>


To chip in with my (possibly not-too-well-informed) opinion:

What your current study gives you is a handle on the *variability* that 
data gathered in a future study will have.  You need to have an estimate 
of this variability in order to calculate power.

To design a future study you need to:

(1) Decide what effect size you are interested in; i.e. what effect size 
is of *practical* significance.  Call this effect size, say, e_0.

(2) Choose the significance level at which you wish to test your 
hypothesis.  (Probably 0.05).

(3) Choose what power you wish to achieve.  (E.g. the value 0.80 is 
often used.)

(4) Determine an estimate of the variability in the data which you will 
collect.  (This is where your current study comes in.)

(5) Do some more-or-less intricate calculations (depending on the nature 
of the study) to produce a study design such that if the true
effect size is at least e_0 then a test conducted at the 0.05 
significance level will have a probability of at least 0.80 of rejecting 
the null hypothesis.

In real life it is usually the case that the sample sizes required to
achieve the specified power at the specified effect size are far larger 
than what your budget will stretch to.

That's one of the (many) reasons why so much crap research is
produced! :-)

cheers,

Rolf Turner

On 09/11/14 11:56, Kristi Glover wrote:
> Dear Dennis, I really appreciated for your and Bert's help. I read
> thepaper and it seems that once the study is completed, power calculations
> do not inform us in any way as to the conclusions of the present study.
> But I am really now confused whether we can't improve the research
> design for future or next year monitoring based on the present results.
> I would really be grateful for your suggestions and insights. Can't we
> take reference from the present study for improving future
> sampling?Thanks KG
>> Date: Sat, 8 Nov 2014 13:36:35 -0800
>> Subject: Re: [R] how to determine power in my analysis?
>> From: djmuser at gmail.com
>> To: kristi.glover at hotmail.com
>> CC: gunter.berton at gene.com; r-help at stat.math.ethz.ch
>>
>> Hi Kristi:
>>
>> I think this paper elucidates the problem Bert mentioned. A thorough
>> and careful reading of the last two sections should clarify what
>> post-hoc power is and is not.
>>
>> http://www.stat.uiowa.edu/files/stat/techrep/tr378.pdf
>>
>> Dennis
>>
>> On Sat, Nov 8, 2014 at 11:25 AM, Kristi Glover
>> <kristi.glover at hotmail.com> wrote:
>>> Hi Bert, Thanks for the message. So far I know we can test whether my sample size in my analysis is enough or not. It is also post hoc property. For example, we can calculate standard deviations, error variance  etc in the data sets, and then we can use them to determine whether the sample size was enough or not with certain level of alpha and power. we can do it is some of the statistical programs, but I was not aware in R. thanks KG
>>>
>>>> Date: Sat, 8 Nov 2014 10:55:56 -0800
>>>> Subject: Re: [R] how to determine power in my analysis?
>>>> From: gunter.berton at gene.com
>>>> To: kristi.glover at hotmail.com
>>>> CC: r-help at stat.math.ethz.ch
>>>>
>>>> Kristi:
>>>>
>>>> Power is a prespecified property of the design, not a post hoc
>>>> property of the analysis (SAS procedures notwithstanding). So you're a
>>>> day late and a dollar short.
>>>>
>>>> I suggest you consult with a local statistician about such matters, as
>>>> you appear to be out of your depth.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>> Bert Gunter
>>>> Genentech Nonclinical Biostatistics
>>>> (650) 467-7374
>>>>
>>>> "Data is not information. Information is not knowledge. And knowledge
>>>> is certainly not wisdom."
>>>> Clifford Stoll
>>>>
>>>>
>>>>
>>>>
>>>> On Sat, Nov 8, 2014 at 3:49 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
>>>>> Hi R Users,
>>>>> I was trying to determine whether I have enough samples and power in my analysis. Would you mind to provide some hints?.  I found a several packages for power analysis but did not find any example data. I have two sites and each site has 4 groups. I wanted to test whether there was an effect of restoration activities and sites on the observed value. I used a two way factorial ANOVA and now I wanted to test the power of the analysis (whether the sample sizes are enough for the analysis? what are the alpha and power in the analysis using this data set? if it is not enough, how much samples should be collected for alpha 0.05 and power=0.8 and 0.9 for the analysis (two way factorial analysis).
>>>>> The example data:data<-structure(list(observedValue = c(0.08, 0.53, 0.14, 0.66, 0.37, 0.88, 0.84, 0.46, 0.3, 0.61, 0.75, 0.82, 0.67, 0.37, 0.95, 0.73, 0.74, 0.69, 0.06, 0.97, 0.97, 0.07, 0.75, 0.68, 0.53, 0.72, 0.34, 0.12, 0.49, 0.77, 0.45, 0.07, 0.97, 0.34, 0.68, 0.48, 0.65, 0.7, 0.57, 0.66, 0.4, 0.29, 0.88, 0.36, 0.68, 0.32, 0.8, 0, 0.11, 0.48, 0.85, 0.94, 0.12, 0.12, 0, 0.89, 0.66, 0.2, 0.57, 0.09, 0.27, 0.81, 0.53, 0.09, 0.5, 0.41, 0.89, 0.47, 0.39, 0.85, 0.71, 0.89, 0.01, 0.71, 0.42, 0.72, 0.62, 0.3, 0.56, 0.99, 0.97, 0.03, 0.09, 0.27, 0.27, 0.94, 0.23, 0.97, 0.81, 0.95), condition = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("g!
>   ood!
>>>   ", "!
>>>>>   medium", "poor", "verygood"), class = "factor"), areas = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Restored", "unrestored"), class = "factor")), .Names = c("observedValue", "condition", "areas"), class = "data.frame", row.names = c(NA, -90L))
>>>>> test= aov(observedValue~condition*areas,data=data)summary(test)
>>>>> power of the analysis?
>>>>> thanks for your help.
>>>>> Sincerely, KG
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Rolf Turner
Technical Editor ANZJS


From bbolker at gmail.com  Sun Nov  9 03:48:09 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 9 Nov 2014 02:48:09 +0000
Subject: [R] Lme4 Package Help!
References: <4942E23E-2428-412D-B4CE-1D1CF81F0623@ucmerced.edu>
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF33B7FA@DC1VEX10MB001.air.org>
Message-ID: <loom.20141109T034708-607@post.gmane.org>

Doran, Harold <HDoran <at> air.org> writes:

> 
> Daniel
> 
> Lmer has never returned p-values from a model summary; 
> this is a well-known and discussed issue. You must
> have post-processed the data in some way to get the p-values.

  But it's worth noting that lmerTest does, and the way it works
makes it pretty hard to see that the results are not coming from
vanilla lme4.  If this is what happened I wouldn't blame the OP
for getting confused.


From Lee.Hachadoorian+L at gmail.com  Sun Nov  9 05:34:19 2014
From: Lee.Hachadoorian+L at gmail.com (Lee Hachadoorian)
Date: Sat, 08 Nov 2014 23:34:19 -0500
Subject: [R] How to generate mtable output from lm with response matrix
Message-ID: <545EEECB.4030500@gmail.com>

lm can accept a multiple response variables, and produces a list 
containing one model per response variable. I would like to compare 
those models using the mtable function from the memisc package. I cannot 
figure out the indexing of the list produced by the lm call. How can I 
extract an lm from the list produced by a call of the form:

     data(mtcars)
     lmTest = lm(cbind(mpg, hp) ~ disp + wt + carb, data=mtcars)


Best,
--Lee

-- 
Lee Hachadoorian
Assistant Professor in Geography, Dartmouth College
http://geospatial.commons.gc.cuny.edu
http://freecity.commons.gc.cuny.edu


From Pradip.Muhuri at samhsa.hhs.gov  Sun Nov  9 05:40:33 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 9 Nov 2014 04:40:33 +0000
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>

Hello,



The example data frame in the reproducible code below has 5 columns (1 column for id and 4 columns for dates), and there are 7 observations.  I would like to insert the most recent date from those 4 date columns into a new column (oiddate) using the mutate() function in the dplyr package.   I am getting correct results (NA in the new column) if a given row has all NA's in the four columns.  However, the issue is that the date value inserted into the new column (oidflag) is incorrect for 5 of the remaining 6 rows (with a non-NA value in at least 1 of the four columns).



I would appreciate receiving your help toward resolving the issue.  Please see the R console and the R script (reproducible example)below.



Thanks in advance.



Pradip





######  from the console ########

print (data2)

  id    mrjdate    cocdate    inhdate    haldate    oidflag

1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2011-11-04

2  2       <NA>       <NA>       <NA>       <NA>       <NA>

3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-11-04

4  4 2007-10-10       <NA>       <NA>       <NA> 2011-11-04

5  5 2006-09-01 2005-08-10       <NA>       <NA> 2011-11-04

6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-11-04

7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04





##################  Reproducible code and data #####################################



library(dplyr)

library(lubridate)

library(zoo)

# data object - description of the



temp <- "id  mrjdate cocdate inhdate haldate

1     2004-11-04 2008-07-18 2005-07-07 2007-11-07

2             NA         NA         NA         NA

3     2009-10-24         NA 2011-10-13         NA

4     2007-10-10         NA         NA         NA

5     2006-09-01 2005-08-10         NA         NA

6     2007-09-04 2011-10-05         NA         NA

7     2005-10-25         NA         NA 2011-11-04"



# read the data object



data1 <- read.table(textConnection(temp),

                    colClasses=c("character", "Date", "Date", "Date", "Date"),

                    header=TRUE, as.is=TRUE

                    )

# create a new column



data2 <- mutate(data1,

                oidflag= ifelse(is.na(mrjdate) & is.na(cocdate) & is.na(inhdate)  & is.na(haldate), NA,

                                  max(mrjdate, cocdate, inhdate, haldate,na.rm=TRUE )

                                )

                )



# convert to date

data2$oidflag = as.Date(data2$oidflag, origin="1970-01-01")



# print records



print (data2)





Pradip K. Muhuri, PhD

SAMHSA/CBHSQ

1 Choke Cherry Road, Room 2-1071

Rockville, MD 20857

Tel: 240-276-1070

Fax: 240-276-1260





	[[alternative HTML version deleted]]


From info.vasukv at gmail.com  Sun Nov  9 09:50:58 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Sun, 9 Nov 2014 14:20:58 +0530
Subject: [R] Solaris: --with-internal-tzcode
Message-ID: <CAJhrTnpaXqoEfjXjMnLucHxRE79ZPWiUK_iU9y-Z3S-E6Qjz9w@mail.gmail.com>

Hi,

what is this parameter on Solaris?

when I am executing the below command, it is failed with the error message.

configure ?--with-internal-tzcode?

configure: WARNING: unrecognized options: --with-internal-tzcode

Version output:

platform       x86_64-pc-solaris2.10

arch           x86_64

os             solaris2.10

system         x86_64, solaris2.10

status

major          3

minor          0.1

year           2013

month          05

day            16

svn rev        62743

language       R


Thanks

Vasanth

	[[alternative HTML version deleted]]


From sorenh at math.aau.dk  Sun Nov  9 10:16:51 2014
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sun, 9 Nov 2014 09:16:51 +0000
Subject: [R] Lme4 Package Help!
In-Reply-To: <loom.20141109T034708-607@post.gmane.org>
References: <4942E23E-2428-412D-B4CE-1D1CF81F0623@ucmerced.edu>
	<B08B6AF0CF8CA44F81B9983EEBDCD686CF33B7FA@DC1VEX10MB001.air.org>
	<loom.20141109T034708-607@post.gmane.org>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3A166215F@AD-EXCHMBX2-1.aau.dk>

Actually, I believe that for a brief period (around 2006) lmer did return p-values (chisq-based), but then 2006 is a long time ago...

If the question pertains p-values in the usual output of coef( summary( model ) ), I'll just mention that with doBy and pbkrtest you can do

linest( model, diag(1, length(coef(model)) ) )

With the next release of doBy you do not need to specify the diag-stuff, but for now you have to.

Cheers
S?ren







|-----Original Message-----
|From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
|On Behalf Of Ben Bolker
|Sent: 9. november 2014 03:48
|To: r-help at stat.math.ethz.ch
|Subject: Re: [R] Lme4 Package Help!
|
|Doran, Harold <HDoran <at> air.org> writes:
|
|>
|> Daniel
|>
|> Lmer has never returned p-values from a model summary; this is a
|> well-known and discussed issue. You must have post-processed the data
|> in some way to get the p-values.
|
|  But it's worth noting that lmerTest does, and the way it works makes it
|pretty hard to see that the results are not coming from vanilla lme4.  If
|this is what happened I wouldn't blame the OP for getting confused.
|
|______________________________________________
|R-help at r-project.org mailing list
|https://stat.ethz.ch/mailman/listinfo/r-help
|PLEASE do read the posting guide http://www.R-project.org/posting-
|guide.html
|and provide commented, minimal, self-contained, reproducible code.


From djnordlund at frontier.com  Sun Nov  9 11:32:42 2014
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Sun, 09 Nov 2014 02:32:42 -0800
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
Message-ID: <545F42CA.7050809@frontier.com>

On 11/8/2014 8:40 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hello,
>
>
>
> The example data frame in the reproducible code below has 5 columns (1 column for id and 4 columns for dates), and there are 7 observations.  I would like to insert the most recent date from those 4 date columns into a new column (oiddate) using the mutate() function in the dplyr package.   I am getting correct results (NA in the new column) if a given row has all NA's in the four columns.  However, the issue is that the date value inserted into the new column (oidflag) is incorrect for 5 of the remaining 6 rows (with a non-NA value in at least 1 of the four columns).
>
>
>
> I would appreciate receiving your help toward resolving the issue.  Please see the R console and the R script (reproducible example)below.
>
>
>
> Thanks in advance.
>
>
>
> Pradip
>
>
>
>
>
> ######  from the console ########
>
> print (data2)
>
>    id    mrjdate    cocdate    inhdate    haldate    oidflag
>
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2011-11-04
>
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-11-04
>
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2011-11-04
>
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2011-11-04
>
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-11-04
>
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>
>
>
>
>
> ##################  Reproducible code and data #####################################
>
>
>
> library(dplyr)
>
> library(lubridate)
>
> library(zoo)
>
> # data object - description of the
>
>
>
> temp <- "id  mrjdate cocdate inhdate haldate
>
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
>
> 2             NA         NA         NA         NA
>
> 3     2009-10-24         NA 2011-10-13         NA
>
> 4     2007-10-10         NA         NA         NA
>
> 5     2006-09-01 2005-08-10         NA         NA
>
> 6     2007-09-04 2011-10-05         NA         NA
>
> 7     2005-10-25         NA         NA 2011-11-04"
>
>
>
> # read the data object
>
>
>
> data1 <- read.table(textConnection(temp),
>
>                      colClasses=c("character", "Date", "Date", "Date", "Date"),
>
>                      header=TRUE, as.is=TRUE
>
>                      )
>
> # create a new column
>
>
>
> data2 <- mutate(data1,
>
>                  oidflag= ifelse(is.na(mrjdate) & is.na(cocdate) & is.na(inhdate)  & is.na(haldate), NA,
>
>                                    max(mrjdate, cocdate, inhdate, haldate,na.rm=TRUE )
>
>                                  )
>
>                  )
>
>
>
> # convert to date
>
> data2$oidflag = as.Date(data2$oidflag, origin="1970-01-01")
>
>
>
> # print records
>
>
>
> print (data2)
>
>
>
>
>
> Pradip K. Muhuri, PhD
>
> SAMHSA/CBHSQ
>
> 1 Choke Cherry Road, Room 2-1071
>
> Rockville, MD 20857
>
> Tel: 240-276-1070
>
> Fax: 240-276-1260
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

I am not familiar with the mutate() function from dplyr, but you can get 
your wanted results as follows:

data2 <- within(data1, oidflag <- apply(data1[,-1], 1, max, na.rm=TRUE))


Hope this is helpful,

Dan

Daniel Nordlund
Bothell, WA USA


From Pradip.Muhuri at samhsa.hhs.gov  Sun Nov  9 12:05:33 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 9 Nov 2014 11:05:33 +0000
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <545F42CA.7050809@frontier.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<545F42CA.7050809@frontier.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5D025@pl-emsmb11>

Hi Dan,

Thank you so much for sending me your code that provides me desired results. But, I don't understand  why I am getting the follow warning message, In FUN(newX[, i], ...) : no non-missing arguments, returning NA. Any thoughts?

Regards,

Pradip



data2x <- within(data1, oidflag <- apply(data1[,-1], 1, max, na.rm=TRUE))

Warning message:
In FUN(newX[, i], ...) : no non-missing arguments, returning NA
> data2x
  id    mrjdate    cocdate    inhdate    haldate    oidflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04


Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel Nordlund
Sent: Sunday, November 09, 2014 5:33 AM
To: r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

On 11/8/2014 8:40 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hello,
>
>
>
> The example data frame in the reproducible code below has 5 columns (1 column for id and 4 columns for dates), and there are 7 observations.  I would like to insert the most recent date from those 4 date columns into a new column (oiddate) using the mutate() function in the dplyr package.   I am getting correct results (NA in the new column) if a given row has all NA's in the four columns.  However, the issue is that the date value inserted into the new column (oidflag) is incorrect for 5 of the remaining 6 rows (with a non-NA value in at least 1 of the four columns).
>
>
>
> I would appreciate receiving your help toward resolving the issue.  Please see the R console and the R script (reproducible example)below.
>
>
>
> Thanks in advance.
>
>
>
> Pradip
>
>
>
>
>
> ######  from the console ########
>
> print (data2)
>
>    id    mrjdate    cocdate    inhdate    haldate    oidflag
>
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2011-11-04
>
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-11-04
>
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2011-11-04
>
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2011-11-04
>
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-11-04
>
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>
>
>
>
>
> ##################  Reproducible code and data 
> #####################################
>
>
>
> library(dplyr)
>
> library(lubridate)
>
> library(zoo)
>
> # data object - description of the
>
>
>
> temp <- "id  mrjdate cocdate inhdate haldate
>
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
>
> 2             NA         NA         NA         NA
>
> 3     2009-10-24         NA 2011-10-13         NA
>
> 4     2007-10-10         NA         NA         NA
>
> 5     2006-09-01 2005-08-10         NA         NA
>
> 6     2007-09-04 2011-10-05         NA         NA
>
> 7     2005-10-25         NA         NA 2011-11-04"
>
>
>
> # read the data object
>
>
>
> data1 <- read.table(textConnection(temp),
>
>                      colClasses=c("character", "Date", "Date", "Date", 
> "Date"),
>
>                      header=TRUE, as.is=TRUE
>
>                      )
>
> # create a new column
>
>
>
> data2 <- mutate(data1,
>
>                  oidflag= ifelse(is.na(mrjdate) & is.na(cocdate) & 
> is.na(inhdate)  & is.na(haldate), NA,
>
>                                    max(mrjdate, cocdate, inhdate, 
> haldate,na.rm=TRUE )
>
>                                  )
>
>                  )
>
>
>
> # convert to date
>
> data2$oidflag = as.Date(data2$oidflag, origin="1970-01-01")
>
>
>
> # print records
>
>
>
> print (data2)
>
>
>
>
>
> Pradip K. Muhuri, PhD
>
> SAMHSA/CBHSQ
>
> 1 Choke Cherry Road, Room 2-1071
>
> Rockville, MD 20857
>
> Tel: 240-276-1070
>
> Fax: 240-276-1260
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

I am not familiar with the mutate() function from dplyr, but you can get your wanted results as follows:

data2 <- within(data1, oidflag <- apply(data1[,-1], 1, max, na.rm=TRUE))


Hope this is helpful,

Dan

Daniel Nordlund
Bothell, WA USA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Nov  9 13:00:15 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 9 Nov 2014 12:00:15 +0000 (UTC)
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
Message-ID: <1717977485.112425.1415534415311.JavaMail.yahoo@jws10640.mail.bf1.yahoo.com>

You could try

library(dplyr)
data1 %>% 

      rowwise() %>%
       mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                                       na.rm=TRUE), origin='1970-01-01'))
Source: local data frame [7 x 6]
Groups: <by row>

id    mrjdate    cocdate    inhdate    haldate    oldflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04

A.K.


On Saturday, November 8, 2014 11:42 PM, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
Hello,



The example data frame in the reproducible code below has 5 columns (1 column for id and 4 columns for dates), and there are 7 observations.  I would like to insert the most recent date from those 4 date columns into a new column (oiddate) using the mutate() function in the dplyr package.   I am getting correct results (NA in the new column) if a given row has all NA's in the four columns.  However, the issue is that the date value inserted into the new column (oidflag) is incorrect for 5 of the remaining 6 rows (with a non-NA value in at least 1 of the four columns).



I would appreciate receiving your help toward resolving the issue.  Please see the R console and the R script (reproducible example)below.



Thanks in advance.



Pradip





######  from the console ########

print (data2)

  id    mrjdate    cocdate    inhdate    haldate    oidflag

1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2011-11-04

2  2       <NA>       <NA>       <NA>       <NA>       <NA>

3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-11-04

4  4 2007-10-10       <NA>       <NA>       <NA> 2011-11-04

5  5 2006-09-01 2005-08-10       <NA>       <NA> 2011-11-04

6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-11-04

7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04





##################  Reproducible code and data #####################################



library(dplyr)

library(lubridate)

library(zoo)

# data object - description of the



temp <- "id  mrjdate cocdate inhdate haldate

1     2004-11-04 2008-07-18 2005-07-07 2007-11-07

2             NA         NA         NA         NA

3     2009-10-24         NA 2011-10-13         NA

4     2007-10-10         NA         NA         NA

5     2006-09-01 2005-08-10         NA         NA

6     2007-09-04 2011-10-05         NA         NA

7     2005-10-25         NA         NA 2011-11-04"



# read the data object



data1 <- read.table(textConnection(temp),

                    colClasses=c("character", "Date", "Date", "Date", "Date"),

                    header=TRUE, as.is=TRUE

                    )

# create a new column



data2 <- mutate(data1,

                oidflag= ifelse(is.na(mrjdate) & is.na(cocdate) & is.na(inhdate)  & is.na(haldate), NA,

                                  max(mrjdate, cocdate, inhdate, haldate,na.rm=TRUE )

                                )

                )



# convert to date

data2$oidflag = as.Date(data2$oidflag, origin="1970-01-01")



# print records



print (data2)





Pradip K. Muhuri, PhD

SAMHSA/CBHSQ

1 Choke Cherry Road, Room 2-1071

Rockville, MD 20857

Tel: 240-276-1070

Fax: 240-276-1260





    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wush978 at gmail.com  Sun Nov  9 13:27:49 2014
From: wush978 at gmail.com (Wush Wu)
Date: Sun, 9 Nov 2014 20:27:49 +0800
Subject: [R]  Compression variable in memory with gzcon
Message-ID: <CABjzuv5EgRAeuszDQ7q6HJR7MKH_ud16ivq9MLUhN7SYJu11bA@mail.gmail.com>

Hello,

I cannot figure out how to compress a raw vector in memory with gzip format
that is compatible with `gzfile`. (`memCompress` does not compatible with
`gzfile`.)

I modified the example in `rawConnection`, but it does not work:

```
> zz <- gzcon(rawConnection(raw(0), "r+b")) # start with empty raw vector
Error in gzcon(rawConnection(raw(0), "r+b")) :
  can only use read- or write- binary connections
```

If I used a write-only connections, then writing is ok but I don't know how
to read the data after writing. The `rawConnectionValue` won't work:

```
> zz <- gzcon(con1 <- rawConnection(raw(0), "wb")) # start with empty raw
vector
> writeBin(LETTERS, zz)
> flush(zz)
> rawConnectionValue(con1)
R(18294,0x7fff73eff310) malloc: *** mach_vm_map(size=140652713885696)
failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug

R(18294,0x7fff73eff310) malloc: *** mach_vm_map(size=140652713885696)
failed (error code=3)
*** error: can't allocate region
*** set a breakpoint in malloc_error_break to debug
Error: cannot allocate vector of size 130993.0 Gb
```

Note that the above script works if I remove the `gzcon`. Is there another
way to read the raw vector from the connection?

Here is my `sessionInfo`:

```
> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] zh_TW.UTF-8/zh_TW.UTF-8/zh_TW.UTF-8/C/zh_TW.UTF-8/zh_TW.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
```

Thanks,
Wush
PhD Student Graduate Institute of Electrical Engineering, National Taiwan
University

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Sun Nov  9 14:43:41 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 09 Nov 2014 13:43:41 +0000
Subject: [R] Solaris: --with-internal-tzcode
In-Reply-To: <CAJhrTnpaXqoEfjXjMnLucHxRE79ZPWiUK_iU9y-Z3S-E6Qjz9w@mail.gmail.com>
References: <CAJhrTnpaXqoEfjXjMnLucHxRE79ZPWiUK_iU9y-Z3S-E6Qjz9w@mail.gmail.com>
Message-ID: <545F6F8D.9070705@stats.ox.ac.uk>

On 09/11/2014 08:50, Vasantha Kumar Kesavan wrote:
> Hi,
>
> what is this parameter on Solaris?

You are using a current option (for any platform, not just for Solaris) 
on a long-obsolete version of R.  Please do study the posting guide and 
update (to R 3.1.2) *before posting*.  (And also send properly formatted 
ASCII, not HTML, as it asks.)

>
> when I am executing the below command, it is failed with the error message.
>
> configure ?--with-internal-tzcode?
>
> configure: WARNING: unrecognized options: --with-internal-tzcode
>
> Version output:
>
> platform       x86_64-pc-solaris2.10
>
> arch           x86_64
>
> os             solaris2.10
>
> system         x86_64, solaris2.10
>
> status
>
> major          3
>
> minor          0.1
>
> year           2013
>
> month          05
>
> day            16
>
> svn rev        62743
>
> language       R
>
>
> Thanks
>
> Vasanth
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From roger.bivand at nhh.no  Sun Nov  9 14:43:45 2014
From: roger.bivand at nhh.no (Roger Bivand)
Date: Sun, 9 Nov 2014 13:43:45 +0000
Subject: [R]
	=?utf-8?q?Distance_matrix_for_Spatial_Filtering_=7Bspdep=7D?=
References: <CAMbrGjFngsOFUdo1PBb2A1Ysqk8cVLvEV5AEL-K9_3v2pLnZjQ@mail.gmail.com>
Message-ID: <loom.20141109T140659-208@post.gmane.org>

Erica Cseko Nolasco <ecnolasco <at> gmail.com> writes:

> 
> Hi all,
> 
> I?m working on a species distribution modeling, and I want to build
> eigenvectors to represent my spatial varuable. I?m trying to use
> SpatialFiltering(spdep) for it, but I?m having problems to create the nb
> object. My weights would be a truncated pairwise distance matrix that I was
> pretty able to build. However, I?m going out resources to create a nb
> object. Or it doesn?t match the matrix or the R-Studio crashes. Here is the
> code I?m trying:

You have not provided a reproducible example, it usually helps. Also always
run code that fails in R-Studio outside it, as this frees memory and aids
debugging (nothing between you and R). In addition, we know nothing of your
platform, I guess Windows (G: isn't common elsewhere). Your posting is HTML
which is discouraged.

> 
....
> > matriz3=earth.dist(coor1, dist=T)

This function takes a matrix of geographical coordinates, and returns a
triangular matrix of distances (n*(n-1)), hence the length:

> 
> > length(matriz3)
> 
> [1] 12110581
> 
> > ###truncating the distance matrix
> 
> > matriz3[matriz3>=230]=230
> > ###creating the nb object to link to the distance matrix
> 
> > library(spdep)
> 
> >coord=read.table("coordinates16.txt",sep=" ", header=T)
> 
> > coo=cbind(coord[,1],coord[,2])
> 
> > length(coo[,1])
> [1] 4922
> 
> >nb=dnearneigh(coo,0, 10000, longlat=T) ###large nb (4922 elements,92.9Mb)
> 
> > nb2listw(nb,glist=matriz3,style="W")
> 
> *Error in nb2listw(nb, glist = matriz3, style = "W") : glist wrong length*
> 

The documentation of nb2listw says that the glist argument is a list, not a
triangular matrix. In addition, it is highly unlikely that you expect the
spatial autocorrelation to increase in distance. The examples for the
nb2listw function show how to construct truncated inverse distance weights
using km distances, here with a cutoff at 230km and using geographical
coordinates:

nb <- dnearneigh(coo, 0, 230, longlat=TRUE)
dists <- nbdists(nb, coo, longlat=TRUE)
glist <- lapply(dists, function(x) 1/x)
lw <- nb2listw(nb, glist, style="W")

The use of functions to create nb objects is described in vignette("nb") in
the spdep package.

...
> 
> *R session aborted. R encoutered a fatal error. The session was terminated*
> 

Such things have happened before with R-Studio as a front end when Windows
platforms have run out of memory, but do not repeat outside R-Studio
(reported but no action taken that I know of).

> > nb=knearneigh(coo,500,longlat=T) ###tentativa de criar nb
> 
> *Error in knearneigh(coo, 500, longlat = T) : too many ties in knearneigh*
> 

Almost certainly your choice of k=500 is erroneous, and also suggests that
you are flailing around without a clear grasp of what you should be doing.

1) until the problem is resolved, drop R-Studio; once resolved outside
R-Studio, you may go back to using it, but beware of memory problems.

2) construct the list of weights object as shown (maybe modify the threshold
if too many observations have no neighbour)

3) think carefully about the use of SpatialFiltering - is your response
continuous? You have about 5000 observations, so you will be operation on
5000x5000 matrices in order to construct the Moran eigenvectors, and will be
doing a brute force search for combinations of these eigenvectors to add to
your model. Are you sure that the model you are starting from is
well-specified (included variables and their functional forms)? If not, you
risk including many eigenvectors that simply mop up other misspecifications.
This search will be very time-consuming.

Consider using the R-sig-geo list, which may be more appropriate for this
kind of question.

Roger

...
> 
> Any ideas would help a lot! Thanks in advance
> 
> *Erica Csek? Nolasco*


From Pradip.Muhuri at samhsa.hhs.gov  Sun Nov  9 15:16:51 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 9 Nov 2014 14:16:51 +0000
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <1717977485.112425.1415534415311.JavaMail.yahoo@jws10640.mail.bf1.yahoo.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<1717977485.112425.1415534415311.JavaMail.yahoo@jws10640.mail.bf1.yahoo.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5D52A@pl-emsmb11>

Dear Arun,

Thank you so much for sending me the dplyr/mutate() solution to my code.    But,  I am getting the following warning message.  Any suggestions on how to avoid this message?

Pradip

Warning message:
In max(13081, NA_real_, NA_real_, 15282, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf


#################################################################
data1 %>% 
+   
+   rowwise() %>%
+   mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
+                              na.rm=TRUE), origin='1970-01-01'))
Source: local data frame [7 x 6]
Groups: <by row>

  id    mrjdate    cocdate    inhdate    haldate    oldflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
Warning message:
In max(13081, NA_real_, NA_real_, 15282, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf


Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Sunday, November 09, 2014 7:00 AM
To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

You could try

library(dplyr)
data1 %>% 

      rowwise() %>%
       mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                                       na.rm=TRUE), origin='1970-01-01'))
Source: local data frame [7 x 6]
Groups: <by row>

id    mrjdate    cocdate    inhdate    haldate    oldflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04

A.K.


On Saturday, November 8, 2014 11:42 PM, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
Hello,



The example data frame in the reproducible code below has 5 columns (1 column for id and 4 columns for dates), and there are 7 observations.  I would like to insert the most recent date from those 4 date columns into a new column (oiddate) using the mutate() function in the dplyr package.   I am getting correct results (NA in the new column) if a given row has all NA's in the four columns.  However, the issue is that the date value inserted into the new column (oidflag) is incorrect for 5 of the remaining 6 rows (with a non-NA value in at least 1 of the four columns).



I would appreciate receiving your help toward resolving the issue.  Please see the R console and the R script (reproducible example)below.



Thanks in advance.



Pradip





######  from the console ########

print (data2)

  id    mrjdate    cocdate    inhdate    haldate    oidflag

1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2011-11-04

2  2       <NA>       <NA>       <NA>       <NA>       <NA>

3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-11-04

4  4 2007-10-10       <NA>       <NA>       <NA> 2011-11-04

5  5 2006-09-01 2005-08-10       <NA>       <NA> 2011-11-04

6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-11-04

7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04





##################  Reproducible code and data #####################################



library(dplyr)

library(lubridate)

library(zoo)

# data object - description of the



temp <- "id  mrjdate cocdate inhdate haldate

1     2004-11-04 2008-07-18 2005-07-07 2007-11-07

2             NA         NA         NA         NA

3     2009-10-24         NA 2011-10-13         NA

4     2007-10-10         NA         NA         NA

5     2006-09-01 2005-08-10         NA         NA

6     2007-09-04 2011-10-05         NA         NA

7     2005-10-25         NA         NA 2011-11-04"



# read the data object



data1 <- read.table(textConnection(temp),

                    colClasses=c("character", "Date", "Date", "Date", "Date"),

                    header=TRUE, as.is=TRUE

                    )

# create a new column



data2 <- mutate(data1,

                oidflag= ifelse(is.na(mrjdate) & is.na(cocdate) & is.na(inhdate)  & is.na(haldate), NA,

                                  max(mrjdate, cocdate, inhdate, haldate,na.rm=TRUE )

                                )

                )



# convert to date

data2$oidflag = as.Date(data2$oidflag, origin="1970-01-01")



# print records



print (data2)





Pradip K. Muhuri, PhD

SAMHSA/CBHSQ

1 Choke Cherry Road, Room 2-1071

Rockville, MD 20857

Tel: 240-276-1070

Fax: 240-276-1260





    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From marc_grt at yahoo.fr  Sun Nov  9 19:07:30 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sun, 09 Nov 2014 19:07:30 +0100
Subject: [R] Is it possible to define another kind of NA
Message-ID: <545FAD62.10101@yahoo.fr>

Dear member list,

In many experimental sciences, there is a lower detection limit (LDL) 
when a dosage of a product is done. Then some samples are evaluated to 
be below this limit.
I search for the best way to indicate in a data.frame that some values 
are such LDL. Ideally, an equivalent of NA would be the best.
Until now I manage by indicating all the column in characters.
So the question is: is it possible to define a value that could be named 
LDL and that could take place in vectors or data.frame such as:
v <- c(0.2, 0.28, LDL, 0.9) is the same way that NA can be used.
with of course a function is.ldl(v) that would return F F T F

Thanks a lot for any direction to solve this

Marc


From chl948 at mail.usask.ca  Sun Nov  9 19:30:11 2014
From: chl948 at mail.usask.ca (Lee, Chel Hee)
Date: Sun, 09 Nov 2014 12:30:11 -0600
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <545FAD62.10101@yahoo.fr>
References: <545FAD62.10101@yahoo.fr>
Message-ID: <545FB2B3.9010100@mail.usask.ca>

 > LDL <- NA_real_
 > is.LDL <- is.na
 > v <- c(0.2, 0.28, LDL, 0.9)
 > v
[1] 0.20 0.28   NA 0.90
 > is.LDL(v)
[1] FALSE FALSE  TRUE FALSE
 >

Hope this helps.

Chel Hee Lee

On 11/9/2014 12:07 PM, Marc Girondot wrote:
> Dear member list,
>
> In many experimental sciences, there is a lower detection limit (LDL) 
> when a dosage of a product is done. Then some samples are evaluated to 
> be below this limit.
> I search for the best way to indicate in a data.frame that some values 
> are such LDL. Ideally, an equivalent of NA would be the best.
> Until now I manage by indicating all the column in characters.
> So the question is: is it possible to define a value that could be 
> named LDL and that could take place in vectors or data.frame such as:
> v <- c(0.2, 0.28, LDL, 0.9) is the same way that NA can be used.
> with of course a function is.ldl(v) that would return F F T F
>
> Thanks a lot for any direction to solve this
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Nov  9 16:17:35 2014
From: smartpink111 at yahoo.com (arun)
Date: Sun, 9 Nov 2014 15:17:35 +0000 (UTC)
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5D52A@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5D52A@pl-emsmb11>
Message-ID: <552929448.127879.1415546255329.JavaMail.yahoo@jws10684.mail.bf1.yahoo.com>



Dear Pradip,

>From the documentation of ?max: 


   The minimum and maximum of a numeric empty set are ?+Inf? and
        ?-Inf? 

One of the rows in your dataset is all `NAs.`  I am not sure you want to keep that row with all NAs.  You could remove it and run the code or keep it and run with that warning.

data1 <- data1[rowSums(is.na(data1[,-1]))!=4,]

data1 %>% 

      rowwise()%>%
      mutate(oldflag= as.Date(max(mrjdate, cocdate, inhdate, haldate, na.rm=TRUE), origin='1970-01-01')


A.K.
On Sunday, November 9, 2014 9:16 AM, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:



Dear Arun,

Thank you so much for sending me the dplyr/mutate() solution to my code.    But,  I am getting the following warning message.  Any suggestions on how to avoid this message?

Pradip

Warning message:
In max(13081, NA_real_, NA_real_, 15282, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf


#################################################################
data1 %>% 
+  
+   rowwise() %>%
+   mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
+                              na.rm=TRUE), origin='1970-01-01'))
Source: local data frame [7 x 6]
Groups: <by row>

  id    mrjdate    cocdate    inhdate    haldate    oldflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
Warning message:
In max(13081, NA_real_, NA_real_, 15282, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf


Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----

Sent: Sunday, November 09, 2014 7:00 AM
To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

You could try

library(dplyr)
data1 %>% 

      rowwise() %>%
       mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                                       na.rm=TRUE), origin='1970-01-01'))
Source: local data frame [7 x 6]
Groups: <by row>

id    mrjdate    cocdate    inhdate    haldate    oldflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04

A.K.


On Saturday, November 8, 2014 11:42 PM, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
Hello,



The example data frame in the reproducible code below has 5 columns (1 column for id and 4 columns for dates), and there are 7 observations.  I would like to insert the most recent date from those 4 date columns into a new column (oiddate) using the mutate() function in the dplyr package.   I am getting correct results (NA in the new column) if a given row has all NA's in the four columns.  However, the issue is that the date value inserted into the new column (oidflag) is incorrect for 5 of the remaining 6 rows (with a non-NA value in at least 1 of the four columns).



I would appreciate receiving your help toward resolving the issue.  Please see the R console and the R script (reproducible example)below.



Thanks in advance.



Pradip





######  from the console ########

print (data2)

  id    mrjdate    cocdate    inhdate    haldate    oidflag

1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2011-11-04

2  2       <NA>       <NA>       <NA>       <NA>       <NA>

3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-11-04

4  4 2007-10-10       <NA>       <NA>       <NA> 2011-11-04

5  5 2006-09-01 2005-08-10       <NA>       <NA> 2011-11-04

6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-11-04

7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04





##################  Reproducible code and data #####################################



library(dplyr)

library(lubridate)

library(zoo)

# data object - description of the



temp <- "id  mrjdate cocdate inhdate haldate

1     2004-11-04 2008-07-18 2005-07-07 2007-11-07

2             NA         NA         NA         NA

3     2009-10-24         NA 2011-10-13         NA

4     2007-10-10         NA         NA         NA

5     2006-09-01 2005-08-10         NA         NA

6     2007-09-04 2011-10-05         NA         NA

7     2005-10-25         NA         NA 2011-11-04"



# read the data object



data1 <- read.table(textConnection(temp),

                    colClasses=c("character", "Date", "Date", "Date", "Date"),

                    header=TRUE, as.is=TRUE

                    )

# create a new column



data2 <- mutate(data1,

                oidflag= ifelse(is.na(mrjdate) & is.na(cocdate) & is.na(inhdate)  & is.na(haldate), NA,

                                  max(mrjdate, cocdate, inhdate, haldate,na.rm=TRUE )

                                )

                )



# convert to date

data2$oidflag = as.Date(data2$oidflag, origin="1970-01-01")



# print records



print (data2)





Pradip K. Muhuri, PhD

SAMHSA/CBHSQ

1 Choke Cherry Road, Room 2-1071

Rockville, MD 20857

Tel: 240-276-1070

Fax: 240-276-1260





    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dustinviettran at gmail.com  Sun Nov  9 19:40:20 2014
From: dustinviettran at gmail.com (Dustin Tran)
Date: Sun, 9 Nov 2014 13:40:20 -0500
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <545FAD62.10101@yahoo.fr>
References: <545FAD62.10101@yahoo.fr>
Message-ID: <C93E21E9-4C85-4310-BF43-AF39B4B91CCA@gmail.com>

Hi Marc,

This may be a helpful link: http://stackoverflow.com/questions/16074384/specify-different-types-of-missing-values-nas
> On Nov 9, 2014, at 1:07 PM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> 
> Dear member list,
> 
> In many experimental sciences, there is a lower detection limit (LDL) when a dosage of a product is done. Then some samples are evaluated to be below this limit.
> I search for the best way to indicate in a data.frame that some values are such LDL. Ideally, an equivalent of NA would be the best.
> Until now I manage by indicating all the column in characters.
> So the question is: is it possible to define a value that could be named LDL and that could take place in vectors or data.frame such as:
> v <- c(0.2, 0.28, LDL, 0.9) is the same way that NA can be used.
> with of course a function is.ldl(v) that would return F F T F
> 
> Thanks a lot for any direction to solve this
> 
> Marc
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From djnordlund at frontier.com  Sun Nov  9 20:26:59 2014
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Sun, 09 Nov 2014 11:26:59 -0800
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5D025@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<545F42CA.7050809@frontier.com>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5D025@pl-emsmb11>
Message-ID: <545FC003.4000006@frontier.com>

On 11/9/2014 3:05 AM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hi Dan,
>
> Thank you so much for sending me your code that provides me desired results. But, I don't understand  why I am getting the follow warning message, In FUN(newX[, i], ...) : no non-missing arguments, returning NA. Any thoughts?
>
> Regards,
>
> Pradip
>
>
>
> data2x <- within(data1, oidflag <- apply(data1[,-1], 1, max, na.rm=TRUE))
>
> Warning message:
> In FUN(newX[, i], ...) : no non-missing arguments, returning NA
>> data2x
>    id    mrjdate    cocdate    inhdate    haldate    oidflag
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel Nordlund
> Sent: Sunday, November 09, 2014 5:33 AM
> To: r-help at r-project.org
> Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)
>
> On 11/8/2014 8:40 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
>> Hello,
>>
>>
>>
>> The example data frame in the reproducible code below has 5 columns (1 column for id and 4 columns for dates), and there are 7 observations.  I would like to insert the most recent date from those 4 date columns into a new column (oiddate) using the mutate() function in the dplyr package.   I am getting correct results (NA in the new column) if a given row has all NA's in the four columns.  However, the issue is that the date value inserted into the new column (oidflag) is incorrect for 5 of the remaining 6 rows (with a non-NA value in at least 1 of the four columns).
>>
>>
>>
>> I would appreciate receiving your help toward resolving the issue.  Please see the R console and the R script (reproducible example)below.
>>
>>
>>
>> Thanks in advance.
>>
>>
>>
>> Pradip
>>
>>
>>
>>
>>
>> ######  from the console ########
>>
>> print (data2)
>>
>>     id    mrjdate    cocdate    inhdate    haldate    oidflag
>>
>> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2011-11-04
>>
>> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
>>
>> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-11-04
>>
>> 4  4 2007-10-10       <NA>       <NA>       <NA> 2011-11-04
>>
>> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2011-11-04
>>
>> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-11-04
>>
>> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>>
>>
>>
>>
>>
>> ##################  Reproducible code and data
>> #####################################
>>
>>
>>
>> library(dplyr)
>>
>> library(lubridate)
>>
>> library(zoo)
>>
>> # data object - description of the
>>
>>
>>
>> temp <- "id  mrjdate cocdate inhdate haldate
>>
>> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
>>
>> 2             NA         NA         NA         NA
>>
>> 3     2009-10-24         NA 2011-10-13         NA
>>
>> 4     2007-10-10         NA         NA         NA
>>
>> 5     2006-09-01 2005-08-10         NA         NA
>>
>> 6     2007-09-04 2011-10-05         NA         NA
>>
>> 7     2005-10-25         NA         NA 2011-11-04"
>>
>>
>>
>> # read the data object
>>
>>
>>
>> data1 <- read.table(textConnection(temp),
>>
>>                       colClasses=c("character", "Date", "Date", "Date",
>> "Date"),
>>
>>                       header=TRUE, as.is=TRUE
>>
>>                       )
>>
>> # create a new column
>>
>>
>>
>> data2 <- mutate(data1,
>>
>>                   oidflag= ifelse(is.na(mrjdate) & is.na(cocdate) &
>> is.na(inhdate)  & is.na(haldate), NA,
>>
>>                                     max(mrjdate, cocdate, inhdate,
>> haldate,na.rm=TRUE )
>>
>>                                   )
>>
>>                   )
>>
>>
>>
>> # convert to date
>>
>> data2$oidflag = as.Date(data2$oidflag, origin="1970-01-01")
>>
>>
>>
>> # print records
>>
>>
>>
>> print (data2)
>>
>>
>>
>>
>>
>> Pradip K. Muhuri, PhD
>>
>> SAMHSA/CBHSQ
>>
>> 1 Choke Cherry Road, Room 2-1071
>>
>> Rockville, MD 20857
>>
>> Tel: 240-276-1070
>>
>> Fax: 240-276-1260
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> I am not familiar with the mutate() function from dplyr, but you can get your wanted results as follows:
>
> data2 <- within(data1, oidflag <- apply(data1[,-1], 1, max, na.rm=TRUE))
>
>
> Hope this is helpful,
>
> Dan
>
> Daniel Nordlund
> Bothell, WA USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

It means what it says.  In this case, for id=2 there are no non-missing 
values.  Since, na.rm was set to true, it is just warning you that since 
there was nothing left to get the max of, it is returning NA.

Dan

-- 
Daniel Nordlund
Bothell, WA USA


From Pradip.Muhuri at samhsa.hhs.gov  Sun Nov  9 20:44:55 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 9 Nov 2014 19:44:55 +0000
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <552929448.127879.1415546255329.JavaMail.yahoo@jws10684.mail.bf1.yahoo.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5D52A@pl-emsmb11>
	<552929448.127879.1415546255329.JavaMail.yahoo@jws10684.mail.bf1.yahoo.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5DD8F@pl-emsmb11>

Hi Arun and Dennis,

This is just an FYI.

You're right - In one row, there are all NA's in  the four  "date" columns.  I have tested below the "TRUEness" of the condition Arun has set.

is.logical(data1[rowSums(is.na(data1[,-1]))!=4,])
[1] FALSE

All these 3 approaches below provide the exact same results.

# Approach 1 (suggested by Arun): The code gives the expected results, but with a warning message.
data1 %>% 

   rowwise() %>%
   mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                             na.rm=TRUE), origin='1970-01-01'))

# Approach 2: This code (suggested by Dan) does not provide now a warning message although it provided such message earlier.
data2x <- within(data1, oidflag <- apply(data1[,-1], 1, max, na.rm=TRUE))


# Approach 2: This code (suggested by Mark) does not provide a warning message
data2 <- data1
data2$oidflag <- as.Date(sapply(seq_along(data2$id), function(row) {
  if (all(is.na(unlist(data1[row, -1])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")


##########################  ends here ################

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Sunday, November 09, 2014 10:18 AM
To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)



Dear Pradip,

From the documentation of ?max: 


   The minimum and maximum of a numeric empty set are ?+Inf? and
        ?-Inf? 

One of the rows in your dataset is all `NAs.`  I am not sure you want to keep that row with all NAs.  You could remove it and run the code or keep it and run with that warning.

data1 <- data1[rowSums(is.na(data1[,-1]))!=4,]

data1 %>% 

      rowwise()%>%
      mutate(oldflag= as.Date(max(mrjdate, cocdate, inhdate, haldate, na.rm=TRUE), origin='1970-01-01')


A.K.
On Sunday, November 9, 2014 9:16 AM, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:



Dear Arun,

Thank you so much for sending me the dplyr/mutate() solution to my code.    But,  I am getting the following warning message.  Any suggestions on how to avoid this message?

Pradip

Warning message:
In max(13081, NA_real_, NA_real_, 15282, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf


#################################################################
data1 %>% 
+  
+   rowwise() %>%
+   mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
+                              na.rm=TRUE), origin='1970-01-01'))
Source: local data frame [7 x 6]
Groups: <by row>

  id    mrjdate    cocdate    inhdate    haldate    oldflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
Warning message:
In max(13081, NA_real_, NA_real_, 15282, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf


Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Sunday, November 09, 2014 7:00 AM
To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

You could try

library(dplyr)
data1 %>% 

      rowwise() %>%
       mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                                       na.rm=TRUE), origin='1970-01-01'))
Source: local data frame [7 x 6]
Groups: <by row>

id    mrjdate    cocdate    inhdate    haldate    oldflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04

A.K.


On Saturday, November 8, 2014 11:42 PM, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
Hello,



The example data frame in the reproducible code below has 5 columns (1 column for id and 4 columns for dates), and there are 7 observations.  I would like to insert the most recent date from those 4 date columns into a new column (oiddate) using the mutate() function in the dplyr package.   I am getting correct results (NA in the new column) if a given row has all NA's in the four columns.  However, the issue is that the date value inserted into the new column (oidflag) is incorrect for 5 of the remaining 6 rows (with a non-NA value in at least 1 of the four columns).



I would appreciate receiving your help toward resolving the issue.  Please see the R console and the R script (reproducible example)below.



Thanks in advance.



Pradip





######  from the console ########

print (data2)

  id    mrjdate    cocdate    inhdate    haldate    oidflag

1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2011-11-04

2  2       <NA>       <NA>       <NA>       <NA>       <NA>

3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-11-04

4  4 2007-10-10       <NA>       <NA>       <NA> 2011-11-04

5  5 2006-09-01 2005-08-10       <NA>       <NA> 2011-11-04

6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-11-04

7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04





##################  Reproducible code and data #####################################



library(dplyr)

library(lubridate)

library(zoo)

# data object - description of the



temp <- "id  mrjdate cocdate inhdate haldate

1     2004-11-04 2008-07-18 2005-07-07 2007-11-07

2             NA         NA         NA         NA

3     2009-10-24         NA 2011-10-13         NA

4     2007-10-10         NA         NA         NA

5     2006-09-01 2005-08-10         NA         NA

6     2007-09-04 2011-10-05         NA         NA

7     2005-10-25         NA         NA 2011-11-04"



# read the data object



data1 <- read.table(textConnection(temp),

                    colClasses=c("character", "Date", "Date", "Date", "Date"),

                    header=TRUE, as.is=TRUE

                    )

# create a new column



data2 <- mutate(data1,

                oidflag= ifelse(is.na(mrjdate) & is.na(cocdate) & is.na(inhdate)  & is.na(haldate), NA,

                                  max(mrjdate, cocdate, inhdate, haldate,na.rm=TRUE )

                                )

                )



# convert to date

data2$oidflag = as.Date(data2$oidflag, origin="1970-01-01")



# print records



print (data2)





Pradip K. Muhuri, PhD

SAMHSA/CBHSQ

1 Choke Cherry Road, Room 2-1071

Rockville, MD 20857

Tel: 240-276-1070

Fax: 240-276-1260





    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bogaso.christofer at gmail.com  Sun Nov  9 20:58:12 2014
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 10 Nov 2014 01:43:12 +0545
Subject: [R] Working with data-frame
Message-ID: <CA+dpOJnYOKX33M-kp9MmvooKa-hp8ORs_U_3RwTd+=LVT_7P9Q@mail.gmail.com>

Hi again,

Let say, I have following data frame:


Dat <- structure(list(A1 = structure(c(3L, 3L, 1L, 3L, 3L, 3L, 3L, 2L,
3L, 3L, 1L, 2L, 3L, 2L, 1L, 1L, 3L, 3L, 2L, 3L, 2L, 2L, 3L, 3L,
3L, 2L, 3L, 1L, 1L, 3L), .Label = c("a", "b", "c"), class = "factor"),
    A2 = c(2, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, 1, 3, 3, 2, 2, 1,
    2, 1, 2, 1, 3, 3, 2, 1, 2, 3, 2, 2, 2), C1 = 1:30), .Names = c("A1",
"A2", "C1"), row.names = c(NA, -30L), class = "data.frame")


Now my goal is :
1: Find all possible unique combinations of column 'A1' & column 'A2'.
For example A1 = c, A2 = 2 is 1 unique combination.

2. For each such unique combination, calculate sum for 'A3'.

Is there any direct R function to achieve this faster way? I have very
large data-frame to handle with such calculation.

I tried with spilt() function. However it looks to me that, it can
split a data-frame w.r.t. only one column.

Thanks for your suggestion


From gunter.berton at gene.com  Sun Nov  9 21:50:05 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 9 Nov 2014 12:50:05 -0800
Subject: [R] Working with data-frame
In-Reply-To: <CA+dpOJnYOKX33M-kp9MmvooKa-hp8ORs_U_3RwTd+=LVT_7P9Q@mail.gmail.com>
References: <CA+dpOJnYOKX33M-kp9MmvooKa-hp8ORs_U_3RwTd+=LVT_7P9Q@mail.gmail.com>
Message-ID: <CACk-te2OXdtO4SPYYdq7YJMbYuAE+ua=8t6yZX9mVzm0vB_BCA@mail.gmail.com>

Christopher:

If I understand correctly, see ?ave, or ?tapply, depending on what
form you want to be returned.

The trick is to first paste the columns together on whose unique you
want to split to form a singtl factor. e.g. of the form

lapply(split(yourcolumn,paste0(...)),FUN= sum)

However, the above functions already have this "built" in, so you
don't need to do this explicitly, although my impression is that it
may be a tad more efficient to do it the long way. But don't quote me
on this!

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Nov 9, 2014 at 11:58 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> Let say, I have following data frame:
>
>
> Dat <- structure(list(A1 = structure(c(3L, 3L, 1L, 3L, 3L, 3L, 3L, 2L,
> 3L, 3L, 1L, 2L, 3L, 2L, 1L, 1L, 3L, 3L, 2L, 3L, 2L, 2L, 3L, 3L,
> 3L, 2L, 3L, 1L, 1L, 3L), .Label = c("a", "b", "c"), class = "factor"),
>     A2 = c(2, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, 1, 3, 3, 2, 2, 1,
>     2, 1, 2, 1, 3, 3, 2, 1, 2, 3, 2, 2, 2), C1 = 1:30), .Names = c("A1",
> "A2", "C1"), row.names = c(NA, -30L), class = "data.frame")
>
>
> Now my goal is :
> 1: Find all possible unique combinations of column 'A1' & column 'A2'.
> For example A1 = c, A2 = 2 is 1 unique combination.
>
> 2. For each such unique combination, calculate sum for 'A3'.
>
> Is there any direct R function to achieve this faster way? I have very
> large data-frame to handle with such calculation.
>
> I tried with spilt() function. However it looks to me that, it can
> split a data-frame w.r.t. only one column.
>
> Thanks for your suggestion
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sun Nov  9 21:54:13 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 9 Nov 2014 12:54:13 -0800
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <C93E21E9-4C85-4310-BF43-AF39B4B91CCA@gmail.com>
References: <545FAD62.10101@yahoo.fr>
	<C93E21E9-4C85-4310-BF43-AF39B4B91CCA@gmail.com>
Message-ID: <CACk-te3WmkO+VVHj6Y3QW6yE1w3fbxVEgO9YuVJDV6RXdVkDtA@mail.gmail.com>

Ouch!

The values are **NOT** missing -- they are (left) censored, and need
to be handled by appropriate censored data methods. I suggest you
(all!) either read up on this or consult someone locally who has
knowledge of such methods.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Nov 9, 2014 at 10:40 AM, Dustin Tran <dustinviettran at gmail.com> wrote:
> Hi Marc,
>
> This may be a helpful link: http://stackoverflow.com/questions/16074384/specify-different-types-of-missing-values-nas
>> On Nov 9, 2014, at 1:07 PM, Marc Girondot <marc_grt at yahoo.fr> wrote:
>>
>> Dear member list,
>>
>> In many experimental sciences, there is a lower detection limit (LDL) when a dosage of a product is done. Then some samples are evaluated to be below this limit.
>> I search for the best way to indicate in a data.frame that some values are such LDL. Ideally, an equivalent of NA would be the best.
>> Until now I manage by indicating all the column in characters.
>> So the question is: is it possible to define a value that could be named LDL and that could take place in vectors or data.frame such as:
>> v <- c(0.2, 0.28, LDL, 0.9) is the same way that NA can be used.
>> with of course a function is.ldl(v) that would return F F T F
>>
>> Thanks a lot for any direction to solve this
>>
>> Marc
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sun Nov  9 22:39:45 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 9 Nov 2014 13:39:45 -0800
Subject: [R] Working with data-frame
In-Reply-To: <CA+dpOJnYOKX33M-kp9MmvooKa-hp8ORs_U_3RwTd+=LVT_7P9Q@mail.gmail.com>
References: <CA+dpOJnYOKX33M-kp9MmvooKa-hp8ORs_U_3RwTd+=LVT_7P9Q@mail.gmail.com>
Message-ID: <CAF8bMcZFeyYNoK2bUEfXkBSmu_snVcdHw4KsHe=SnGdFUbqTeg@mail.gmail.com>

> I tried with spilt() function. However it looks to me that, it can
> split a data-frame w.r.t. only one column.

(I assume you you meant 'split', not 'spilt'.)

You did not show what you tried, but the following splits Dat by its "A1"
and "A2" columns (creating a list of data.frames):
   split(Dat, f=Dat[,c("A1","A2")])

aggregate(), in core R, combine the split and the lapply needed to
calculate groupwise sums.  E.g.,
  aggregate(Dat$C1, by=Dat[,c("A1","A2")], FUN=sum)
  aggregate(C1 ~ A1 + A2, data=Dat, FUN=sum)

The plyr and dplyr packages have other ways to do this sort of thing.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Nov 9, 2014 at 11:58 AM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi again,
>
> Let say, I have following data frame:
>
>
> Dat <- structure(list(A1 = structure(c(3L, 3L, 1L, 3L, 3L, 3L, 3L, 2L,
> 3L, 3L, 1L, 2L, 3L, 2L, 1L, 1L, 3L, 3L, 2L, 3L, 2L, 2L, 3L, 3L,
> 3L, 2L, 3L, 1L, 1L, 3L), .Label = c("a", "b", "c"), class = "factor"),
>     A2 = c(2, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, 1, 3, 3, 2, 2, 1,
>     2, 1, 2, 1, 3, 3, 2, 1, 2, 3, 2, 2, 2), C1 = 1:30), .Names = c("A1",
> "A2", "C1"), row.names = c(NA, -30L), class = "data.frame")
>
>
> Now my goal is :
> 1: Find all possible unique combinations of column 'A1' & column 'A2'.
> For example A1 = c, A2 = 2 is 1 unique combination.
>
> 2. For each such unique combination, calculate sum for 'A3'.
>
> Is there any direct R function to achieve this faster way? I have very
> large data-frame to handle with such calculation.
>
> I tried with spilt() function. However it looks to me that, it can
> split a data-frame w.r.t. only one column.
>
> Thanks for your suggestion
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cranatic at gmail.com  Mon Nov 10 00:40:05 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 9 Nov 2014 18:40:05 -0500
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <545ffb5578101_213a281a13016c@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* anim.plots (0.1)
  Maintainer: David Hugh-Jones
  Author(s): David Hugh-Jones <davidhughjones at gmail.com>
  License: GPL-2
  http://crantastic.org/packages/anim-plots

  Simple animated versions of basic R plots, using the &#39;animation&#39;
  package. Includes animated versions of plot, barplot, persp,
  contour, filled.contour, hist, curve, points, lines, text, symbols,
  segments, and arrows.

* aoos (0.0.1)
  Maintainer: Sebastian Warnholz
  Author(s): Sebastian Warnholz
  License: GPL-3 | file LICENSE
  http://crantastic.org/packages/aoos

  Another implementation of object-orientation in R. Private and public
  methods are part of the class-definition. Allows to write a lot of
  small methods as part of the class definition without cluttering the
  object.

* CpGFilter (1.0)
  Maintainer: Jun Chen
  Author(s): Jun Chen
  License: GPL-2
  http://crantastic.org/packages/CpGFilter

  Filter CpGs based on Intra-class Correlation Coefficients (ICCs) when
  replicates are available. ICCs are calculated by fitting linear
  mixed effects models to all samples including the un-replicated
  samples. Including the large number of un-replicated samples
  improves ICC estimates dramatically. The method accommodates any
  replicate design.

* dfcomb (1.0-1)
  Maintainer: Marie-Karelle Riviere
  Author(s): Marie-Karelle Riviere and Jacques-Henri Jourdan
  License: GPL-3
  http://crantastic.org/packages/dfcomb

  Phase I/II adaptive dose-finding design for combination studies.
  Several methods are proposed depending on the type of combinations:
  (1) the combination of two cytotoxic agents, and (2) combination of
  a molecularly targeted agent with a cytotoxic agent.

* dfmta (1.0-1)
  Maintainer: Marie-Karelle Riviere
  Author(s): Marie-Karelle Riviere and Jacques-Henri Jourdan
  License: GPL-3
  http://crantastic.org/packages/dfmta

  Phase I/II adaptive dose-finding design for single-agent Molecularly
  Targeted Agent (MTA), according to the paper &quot;Phase I/II
  Dose-Finding Design for Molecularly Targeted Agent: Plateau
  Determination using Adaptive Randomization&quot;, Statistics in Medicine,
  2014.

* dummy (0.1.0)
  Maintainer: Michel Ballings
  Author(s): Michel Ballings and Dirk Van den Poel
  License: GPL (>= 2)
  http://crantastic.org/packages/dummy

  Efficiently create dummies of all factors and character vectors in a
  data frame. Support is included for learning the categories on one
  data set (e.g., a training set) and deploying them on another (e.g.,
  a test set).

* FAMILY (0.1.18)
  Maintainer: Asad Haris
  Author(s): Asad Haris
  License: GPL (>= 2)
  http://crantastic.org/packages/FAMILY

  Fits penalized linear and logistic regression models with pairwise
  interaction terms.

* geesmv (1.0)
  Maintainer: Zheng Li
  Author(s): Ming Wang <mwang at phs.psu.edu>
  License: GPL (>= 3)
  http://crantastic.org/packages/geesmv

  Generalized estimating equations with the original sandwich variance
  estimator proposed by Liang and Zeger (1986), and eight types of
  more recent modified variance estimators for improving the finite
  small-sample performance.

* geocodeHERE (0.1)
  Maintainer: Cory Nissen
  Author(s): "Cory Nissen <corynissen at gmail.com> [aut, cre]"
  License: MIT + file LICENSE
  http://crantastic.org/packages/geocodeHERE

  Wrapper for Nokia&#39;s HERE geocoding API. See http://here.com/ for more
  information on HERE and https://developer.here.com/geocoder for more
  information on the HERE geocoding API.

* ggswissmaps (0.0.2)
  Maintainer: Sandro Petrillo Burri
  Author(s): Sandro Petrillo Burri <gibo.gaf at gmail.com>
  License: GPL-2
  http://crantastic.org/packages/ggswissmaps

  Offers various swiss maps as ggplot2 objects and gives the possibility
  to add layers of data on the maps. Data are publicly available from
  the swiss federal statistical office.

* hcp (0.1)
  Maintainer: Yulei Wang
  Author(s): Stephen J.Ganocy, Jiayang Sun, and Yulei Wang
  License: GPL-2 | GPL-3
  http://crantastic.org/packages/hcp

  Estimation of parameters in 3-segment (i.e. 2 change-point) regression
  models with heteroscedastic variances is provided based on both
  likelihood and hybrid Bayesian approaches, with and without
  continuity constraints at the change points.

* heritability (1.0)
  Maintainer: Willem Kruijer
  Author(s): Willem Kruijer, with a contribution from Ian White (the internal
             function pin). Contains data collected by Padraic Flood
             and Rik Kooke.
  License: GPL-3
  http://crantastic.org/packages/heritability

  implements marker-based estimation of heritability when observations
  on genetically identical replicates are available. These can be
  either observations on individual plants or plot-level data in a
  field trial. Heritability can then be estimated using a mixed model
  for the individual plant or plot data. For comparison, also
  mixed-model based estimation using genotypic means and estimation of
  repeatability with ANOVA are implemented. For illustration the
  package contains several datasets for the model species Arabidopsis
  thaliana.

* ionflows (1.0)
  Maintainer: Michael Bockmayr
  Author(s): Michael Bockmayr and Jan Budczies
  License: GPL-3
  http://crantastic.org/packages/ionflows

  Two methods for calculation of the number of required flows for
  semiconductor sequencing: 1. Using a simulation, the number of flows
  can be calculated for a concrete list of amplicons. 2. An exact
  combinatorial model is evaluated to calculate the number of flows
  for a random ensemble of sequences.

* LinCal (1.0)
  Maintainer: Derick L. Rivers
  Author(s): Derick L. Rivers <riversdl at vcu.edu> and Edward L. Boone
  License: GPL-2
  http://crantastic.org/packages/LinCal

  Estimate and confidence/credible intervals for an unknown regressor x0
  given an observed y0.

* lpme (1.0.0)
  Maintainer: Haiming Zhou
  Author(s): Haiming Zhou <zhouh at email.sc.edu> and Xianzheng Huang
             <huang at stat.sc.edu>
  License: GPL (>= 2)
  http://crantastic.org/packages/lpme

  Two local polynomial estimators for solving the errors-in-variables
  problem: one is in Delaigle, Fan, and Carroll (2009), and one is in
  Huang and Zhou (2014+). The SIMEX bandwidth selection method is also
  provided for both estimators.

* MGL (1.1)
  Maintainer: Safiye Celik
  Author(s): Safiye Celik
  License: GPL (>= 2)
  http://crantastic.org/packages/MGL

  An aggressive dimensionality reduction and network estimation
  technique for a high-dimensional Gaussian graphical model (GGM).
  Please refer to: Efficient Dimensionality Reduction for
  High-Dimensional Network Estimation, Safiye Celik, Benjamin A.
  Logsdon, Su-In Lee, Proceedings of The 31st International Conference
  on Machine Learning, 2014, p. 1953--1961.

* OptionPricing (0.1)
  Maintainer: Wolfgang Hormann
  Author(s): Kemal Dingec, Wolfgang Hormann
  License: GPL-2 | GPL-3
  http://crantastic.org/packages/OptionPricing

  Efficient Monte Carlo Algorithms for the price and the sensitivities
  of Asian and European Options under Geometric Brownian Motion.

* PANDA (0.9.9)
  Maintainer: Hua Li
  Author(s): Hua Li and Pan Tong
  License: Artistic-2.0
  http://crantastic.org/packages/PANDA

  PANDA (Preferential Attachment based common Neighbor Distribution
  derived Associations) is designed to perform the following tasks in
  PPI networks: (1) identify significantly functionally associated
  protein pairs, (2) predict GO terms and KEGG pathways for proteins,
  (3) make a cluster of proteins based on the significant protein
  pairs, (4) identify subclusters whose members are enriched in KEGG
  pathways. For other types of biological networks, (1) and (3) can
  still be performed.

* pez (0.9-0)
  Maintainer: William D. Pearse
  Author(s): William D. Pearse, Marc W. Cadotte, Jeannine Cavender-Bares, Caroline
             Tucker, Steve C. Walker, Matthew R. Helmus
  License: GPL-3
  http://crantastic.org/packages/pez

  Eco-phylogenetic and community phylogenetic analyses. Keeps community
  ecological and phylogenetic data matched up and comparable using
  &#39;comparative.comm&#39; objects. Wrappers for common community
  phylogenetic indices (&#39;shape&#39;, &#39;evenness&#39;, &#39;dispersion&#39;, and
  &#39;dissimilarity&#39; metrics). Implementation of Cavender-Bares (2004)
  correlation of phylogenetic and ecological matrices
  (&#39;fingerprint.regression&#39;). Simulation of null assemblages, traits,
  and phylogenies (&#39;scape&#39;, &#39;sim.meta.comm&#39;).

* PLSbiplot1 (0.1)
  Maintainer: Opeoluwa F. Oyedele
  Author(s): Opeoluwa F. Oyedele [aut, cre], Sugnet Gardner-Lubbe [aut]
  License: GPL-2
  http://crantastic.org/packages/PLSbiplot1

  Principal Component Analysis (PCA) biplots, Covariance monoplots and
  biplots, Partial Least Squares (PLS) biplots, Partial Least Squares
  for Generalized Linear Model (PLS-GLM) biplots, Sparse Partial Least
  Squares (SPLS) biplots and Sparse Partial Least Squares for
  Generalized Linear Model (SPLS-GLM) biplots.

* poplite (0.99.5)
  Maintainer: Daniel Bottomly
  Author(s): Daniel Bottomly
  License: GPL-3
  http://crantastic.org/packages/poplite

  Provides objects and accompanying methods which facilitates populating
  and querying SQLite databases.

* prc (2014.11-4)
  Maintainer: Youyi Fong
  Author(s): Youyi Fong
  License: GPL (>= 2)
  http://crantastic.org/packages/prc

  Estimation, prediction and testing for analyzing serial dilution assay
  data using paired response curve.

* ScoreGGUM (1.0)
  Maintainer: David R. King
  Author(s): David R. King and James S. Roberts
  License: GPL (>= 2)
  http://crantastic.org/packages/ScoreGGUM

  Estimate GGUM Person Parameters Using Pre-Calibrated Item Parameters
  and Binary or Graded Disagree-Agree Responses

* sdcTarget (0.9-11)
  Maintainer: Emmanuel Lazaridis
  Author(s): Emmanuel Lazaridis [aut, cre]
  License: CC BY-NC 4.0
  http://crantastic.org/packages/sdcTarget

  Classes and methods to calculate and evaluate target matrices for
  statistical disclosure control.

* snht (1.0)
  Maintainer: Josh Browning
  Author(s): Josh Browning
  License: GPL-3
  http://crantastic.org/packages/snht

  Robust and non-robust SNHT tests for changepoint detection.

* spareserver (1.0.0)
  Maintainer: &quot;Gabor Csardi&quot;
  Author(s): "Gabor Csardi" [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/spareserver

  Client size load balancing. Decide which server to connect to, based
  on previous response times, and configuration.

* sudokuAlt (0.1-2)
  Maintainer: Bill Venables
  Author(s): Bill Venables <Bill.Venables at gmail.com>
  License: GPL (>= 2)
  http://crantastic.org/packages/sudokuAlt

  Tools for making, retrieving, displaying and solving sudoku games.
  This package is an alternative to the earlier sudoku-solver package,
  &#39;sudoku&#39;.  The present package uses a slightly different algorithm,
  has a simpler coding and presents a few more sugar tools, such as
  plot and print methods.

* TRSbook (1.0.1)
  Maintainer: P. Lafaye de Micheaux
  Author(s): Lafaye de Micheaux Pierre, Drouilhet Remy, Liquet Benoit
  License: GPL (>= 2)
  http://crantastic.org/packages/TRSbook

  Functions and datasets for the reader of the book &quot;The R Software:
  Fundamentals of Programming and Statistical Analysis&quot;.

* Watersheds (1.0)
  Maintainer: J. A. Torres
  Author(s): J.A. Torres
  License: GPL (>= 2)
  http://crantastic.org/packages/Watersheds

  Methods for watersheds aggregation and spatial drainage network
  analysis.

* WhiteStripe (1.0)
  Maintainer: John Muschelli
  Author(s): Taki Shinohara, John Muschelli
  License: GPL-2
  http://crantastic.org/packages/WhiteStripe

  Whitestripe normalization from Shinohara et. al does For
  intensity-based normalization of T1 and T2 images, where normal
  appearing white matter performs well, but requires segmentation. 
  This method performs white matter mean and standard deviation
  estimates on data that has been rigidly-registered to the MNI
  template and uses histogram-based methods.

* wikipediatrend (0.2.0)
  Maintainer: Peter Meissner
  Author(s): Peter Meissner [aut, cre], R Core team [ctb] (wp_date derived from
             base package as.Date)
  License: GPL (>= 2)
  http://crantastic.org/packages/wikipediatrend

  Public attention is an interesting field of study. The internet not
  only allows to access information in no time on virtually any
  subject but via page access statistics gathered by website authors
  the subject of attention as well can be studied. For the omnipresent
  Wikipedia those access statistics are made available via
  stats.grok.se a server providing the information as file dumps as
  well as as web API. This package provides an easy to  use,
  consistent and traffic minimizing approach to make those data
  accessible within R.

* xtal (1.0)
  Maintainer: Qingan Sun
  Author(s): Qingan Sun, Xiaojun Li
  License: GPL-2 | GPL-3
  http://crantastic.org/packages/xtal

  Tool set for crystallographer to design and analyze crystallization
  experiments of ribosome from Mycobacterium tuberculosis


Updated packages
----------------

afex (0.12-135), aRxiv (0.5.5), bayesTFR (4.0-9), BayesTree (0.3-1.2),
BB (2014.10-1), biwavelet (0.17.5), biwavelet (0.17.4), BNSP (1.0.1),
BTYD (2.4), circlize (0.1.3), cvAUC (1.0.1), descr (1.0.4), dfcomb
(1.0-1), dfmta (1.0-1), dglm (1.8), dglm (1.8.1), diagram (1.6.3), dma
(1.2-2), elliptic (1.3-5), extraTrees (1.0.4), feature (1.2.11), FME
(1.3.2), gdimap (0.1-8), geometry (0.3-5), geomorph (2.1.2), GGIR
(1.1-4), hypergeo (1.2-9), limSolve (1.5.5.1), lpSolveAPI
(5.5.2.0-12), marelac (2.1.4), marmap (0.9), MAT (2.2), MGL (1.1),
msgl (2.0.125.1), NMOF (0.34-0), openssl (0.2), ordinalgmifs (1.0.2),
pca3d (0.3), pracma (1.7.7), prim (1.0.15), pvar (2.0), Quandl
(2.4.0), readBrukerFlexData (1.8.1), Rfit (0.21), rgbif (0.7.7),
RJSDMX (1.2), rminer (1.4), RobustAFT (1.3), rootSolve (1.6.5.1),
RPPanalyzer (1.4), rugarch (1.3-4), shape (1.4.2), SKAT (1.0.1),
snpEnrichment (1.6.0), sqldf (0.4-10), SSN (1.1.4), tagcloud (0.5),
tagcloud (0.4), tm.plugin.webmining (1.2.2), TreePar (3.2), trip
(1.1-19), TRSbook (1.0.1), usl (1.4.0), vcrpart (0.2-2), VGAM (0.9-5),
VGAMdata (0.9-5), WARN (1.1), weightedScores (0.9.1)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From jdnewmil at dcn.davis.CA.us  Mon Nov 10 01:15:37 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 09 Nov 2014 16:15:37 -0800
Subject: [R] Working with data-frame
In-Reply-To: <CAF8bMcZFeyYNoK2bUEfXkBSmu_snVcdHw4KsHe=SnGdFUbqTeg@mail.gmail.com>
References: <CA+dpOJnYOKX33M-kp9MmvooKa-hp8ORs_U_3RwTd+=LVT_7P9Q@mail.gmail.com>
	<CAF8bMcZFeyYNoK2bUEfXkBSmu_snVcdHw4KsHe=SnGdFUbqTeg@mail.gmail.com>
Message-ID: <3732CF1B-7CEB-485B-B950-FB15E54A3881@dcn.davis.CA.us>

... so...

#1 ... flexible syntax for split-apply-combine, not very efficient for large data
library(plyr)
ddply(Dat,c("A1", "A2"), function(DF){data.frame(C1=sum(DF$C1))})

#2 ... compatible with large data on disk
library(sqldf)
sqldf("select A1,A2,sum(C1) as C1 from Dat group by A1, A2")

#3 ... better for large data in memory
library(data.table)
dtt <- data.table(Dat)
#speed for large data
setkeyv(dtt,c("A1", "A2"))
dtt[,list(C1=sum(C1)),by=list(A1,A2)]

#4 ... package still under development, but potentially can support operations on data stored in memory or relational databases
library(dplyr)
Dat %>% group_by(A1,A2) %>% summarise( C1=sum( C1 ) )

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 9, 2014 1:39:45 PM PST, William Dunlap <wdunlap at tibco.com> wrote:
>> I tried with spilt() function. However it looks to me that, it can
>> split a data-frame w.r.t. only one column.
>
>(I assume you you meant 'split', not 'spilt'.)
>
>You did not show what you tried, but the following splits Dat by its
>"A1"
>and "A2" columns (creating a list of data.frames):
>   split(Dat, f=Dat[,c("A1","A2")])
>
>aggregate(), in core R, combine the split and the lapply needed to
>calculate groupwise sums.  E.g.,
>  aggregate(Dat$C1, by=Dat[,c("A1","A2")], FUN=sum)
>  aggregate(C1 ~ A1 + A2, data=Dat, FUN=sum)
>
>The plyr and dplyr packages have other ways to do this sort of thing.
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Sun, Nov 9, 2014 at 11:58 AM, Christofer Bogaso <
>bogaso.christofer at gmail.com> wrote:
>
>> Hi again,
>>
>> Let say, I have following data frame:
>>
>>
>> Dat <- structure(list(A1 = structure(c(3L, 3L, 1L, 3L, 3L, 3L, 3L,
>2L,
>> 3L, 3L, 1L, 2L, 3L, 2L, 1L, 1L, 3L, 3L, 2L, 3L, 2L, 2L, 3L, 3L,
>> 3L, 2L, 3L, 1L, 1L, 3L), .Label = c("a", "b", "c"), class =
>"factor"),
>>     A2 = c(2, 3, 2, 1, 3, 3, 2, 2, 3, 1, 3, 1, 3, 3, 2, 2, 1,
>>     2, 1, 2, 1, 3, 3, 2, 1, 2, 3, 2, 2, 2), C1 = 1:30), .Names =
>c("A1",
>> "A2", "C1"), row.names = c(NA, -30L), class = "data.frame")
>>
>>
>> Now my goal is :
>> 1: Find all possible unique combinations of column 'A1' & column
>'A2'.
>> For example A1 = c, A2 = 2 is 1 unique combination.
>>
>> 2. For each such unique combination, calculate sum for 'A3'.
>>
>> Is there any direct R function to achieve this faster way? I have
>very
>> large data-frame to handle with such calculation.
>>
>> I tried with spilt() function. However it looks to me that, it can
>> split a data-frame w.r.t. only one column.
>>
>> Thanks for your suggestion
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From yueyun at 139.com  Mon Nov 10 08:55:15 2014
From: yueyun at 139.com (=?gb2312?B?1MDaUw==?=)
Date: Mon, 10 Nov 2014 15:55:15 +0800
Subject: [R] the bug of function base::order
Message-ID: <004f01cffcbb$a9f4a460$fddded20$@139.com>

Hi, all:

  I find a bug of the function base::order. For example, 

y = rep(9, 9:1); rbind(y,order(y, decreasing=FALSE));

the result is:

  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]

y    9    9    8    7    6    5    4    3    2     1

    10    9    8    7    6    5    4    3    1     2

The last two numbers have the wrong orders!

 

Is there any one met the same situation?

 


	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Mon Nov 10 09:02:58 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 10 Nov 2014 08:02:58 +0000
Subject: [R] the bug of function base::order
In-Reply-To: <004f01cffcbb$a9f4a460$fddded20$@139.com>
References: <004f01cffcbb$a9f4a460$fddded20$@139.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B363E0@inbomail.inbo.be>

No that is not a bug. You are confusing order() with sort(). Please do read the helpfiles.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

________________________________________
Van: r-help-bounces at r-project.org [r-help-bounces at r-project.org] namens ???S [yueyun at 139.com]
Verzonden: maandag 10 november 2014 8:55
Aan: r-help at r-project.org
Onderwerp: [R] the bug of function base::order

Hi, all:

  I find a bug of the function base::order. For example,

y = rep(9, 9:1); rbind(y,order(y, decreasing=FALSE));

the result is:

  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]

y    9    9    8    7    6    5    4    3    2     1

    10    9    8    7    6    5    4    3    1     2

The last two numbers have the wrong orders!



Is there any one met the same situation?




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From yueyun at 139.com  Mon Nov 10 09:14:01 2014
From: yueyun at 139.com (=?gb2312?B?1MDaUw==?=)
Date: Mon, 10 Nov 2014 16:14:01 +0800
Subject: [R] =?gb2312?b?tPC4tDogIHRoZSBidWcgb2YgZnVuY3Rpb24gYmFzZTo6b3Jk?=
	=?gb2312?b?ZXI=?=
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3B363E0@inbomail.inbo.be>
References: <004f01cffcbb$a9f4a460$fddded20$@139.com>
	<AA818EAD2576BC488B4F623941DA7427F3B363E0@inbomail.inbo.be>
Message-ID: <005401cffcbe$495ea940$dc1bfbc0$@139.com>

Oh, Thank you! I made a stupid mistake!

-----????????-----
??????: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
????????: 2014??11??10?? 16:03
??????: ???S; r-help at r-project.org
????: RE: [R] the bug of function base::order

No that is not a bug. You are confusing order() with sort(). Please do read
the helpfiles.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be
To call in the statistician after the experiment is done may be no more than
asking him to perform a post-mortem examination: he may be able to say what
the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is
not data. ~ Roger Brinner The combination of some data and an aching desire
for an answer does not ensure that a reasonable answer can be extracted from
a given body of data. ~ John Tukey

________________________________________
Van: r-help-bounces at r-project.org [r-help-bounces at r-project.org] namens ???S
[yueyun at 139.com]
Verzonden: maandag 10 november 2014 8:55
Aan: r-help at r-project.org
Onderwerp: [R] the bug of function base::order

Hi, all:

  I find a bug of the function base::order. For example,

y = rep(9, 9:1); rbind(y,order(y, decreasing=FALSE));

the result is:

  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]

y    9    9    8    7    6    5    4    3    2     1

    10    9    8    7    6    5    4    3    1     2

The last two numbers have the wrong orders!



Is there any one met the same situation?




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit
bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en
binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd
is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the
writer and may not be regarded as stating an official position of INBO, as
long as the message is not confirmed by a duly signed document.


From davidhughjones at gmail.com  Thu Nov  6 12:22:55 2014
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Thu, 6 Nov 2014 11:22:55 +0000
Subject: [R] [R-pkgs] anim.plots - simple animated plots for R
Message-ID: <CAARY7kiMGUJrTG1t2omQBgYSGa3JS3L89QEvmfscv3Gxa_Trtw@mail.gmail.com>

Announcing the first release of anim.plots, a package for simple animated
plots in R, using Yihui Xie's animation package.

http://cran.r-project.org/web/packages/anim.plots/index.html

Functions are very similar to basic R graphics. Currently the package
includes animated versions of plot, barplot, persp, contour,
filled.contour, hist, curve, points, lines, text, symbols, segments, and
arrows.

There's a brief introduction here:
http://davidhughjones.blogspot.co.uk/2014/10/easy-animations-in-r.html

And an HTML presentation:
http://hughjonesd.github.io/anim-plots-presentation.html

Code is hosted on GitHub:
https://github.com/hughjonesd/anim.plots

Cheers,
David

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From Pradip.Muhuri at samhsa.hhs.gov  Sun Nov  9 12:11:07 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 9 Nov 2014 11:11:07 +0000
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>

Hi Mark,

Your code has also given me the results I expected.  Thank you so much for your help.

Regards,

Pradip

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----
From: Mark Sharp [mailto:msharp at TxBiomed.org] 
Sent: Sunday, November 09, 2014 3:01 AM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

Pradip,

mutate() works on the entire column as a vector so that you find the maximum of the entire data set.

I am almost certain there is some nice way to handle this, but the sapply() function is a standard approach.

max() does not want a dataframe thus the use of unlist().

Using your definition of data1:

data3 <- data1
data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
  if (all(is.na(unlist(data1[row, -1])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

data3
  id    mrjdate    cocdate    inhdate    haldate    oidflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04



R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center Texas Biomedical Research Institute P.O. Box 760549 San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org





NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From msharp at txbiomed.org  Sun Nov  9 09:00:42 2014
From: msharp at txbiomed.org (Mark Sharp)
Date: Sun, 9 Nov 2014 02:00:42 -0600
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
Message-ID: <9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>

Pradip,

mutate() works on the entire column as a vector so that you find the maximum of the entire data set.

I am almost certain there is some nice way to handle this, but the sapply() function is a standard approach.

max() does not want a dataframe thus the use of unlist().

Using your definition of data1:

data3 <- data1
data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
  if (all(is.na(unlist(data1[row, -1])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

data3
  id    mrjdate    cocdate    inhdate    haldate    oidflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04



R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org





NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From francesca.pancotto at gmail.com  Mon Nov 10 13:14:28 2014
From: francesca.pancotto at gmail.com (Francesca)
Date: Mon, 10 Nov 2014 13:14:28 +0100
Subject: [R] Compressing code help in a loop
Message-ID: <CAKFaUKhjKkn2+0jVkTAQxsFT1fUgKzf9hSGh4niTRQTwQ_28Ug@mail.gmail.com>

Dear Contributors

I have a problem with a loop.

I needed to create a variable that takes values 1,2.. to 19 corresponding
to the value of a variable in a data.frame whose name is p_int$p_made and

which takes values from 406  to 211.

The problem is that this values come ordered in the wrong way when I try to
compress the loop as the system reads


107,111,207,211,311,406,407,408,409,410,411,


while they correspond to quarters-years so they should be ordered as


406-107-207-307-407?

the only solution I found was really silly. It is the following.




p_m<-matrix(0,dim(p_int)[1],1)

for (i in 1:length(p_int$p_made)){

  if (p_int$p_made[i]==406) p_m[i]<-1 else

    if (p_int$p_made[i]==107) p_m[i]<-2 else

      if (p_int$p_made[i]==207) p_m[i]<-3 else

        if (p_int$p_made[i]==307) p_m[i]<-4 else

          if (p_int$p_made[i]==407) p_m[i]<-5 else

            if (p_int$p_made[i]==108) p_m[i]<-6 else

              if (p_int$p_made[i]==208) p_m[i]<-7 else

                if (p_int$p_made[i]==308) p_m[i]<-8 else

                  if (p_int$p_made[i]==408) p_m[i]<-9 else

                    if (p_int$p_made[i]==109) p_m[i]<-10 else

                      if (p_int$p_made[i]==209) p_m[i]<-11 else

                        if (p_int$p_made[i]==309) p_m[i]<-12 else

                          if (p_int$p_made[i]==409) p_m[i]<-13 else

                            if (p_int$p_made[i]==110) p_m[i]<-14 else

                              if (p_int$p_made[i]==210) p_m[i]<-15 else

                                if (p_int$p_made[i]==310) p_m[i]<-16 else

                                  if (p_int$p_made[i]==410) p_m[i]<-17 else

                                    if (p_int$p_made[i]==111) p_m[i]<-18
else

                                      if (p_int$p_made[i]==211) p_m[i]<-19

}

Can anyone help to find something more efficient?


Thanks in advance.


Francesca

-- 

Francesca

----------------------------------
Francesca Pancotto
Associate Professor
University of Modena and Reggio Emilia
Viale A. Allegri, 9
40121 Reggio Emilia
Office: +39 0522 523264
Web: https://sites.google.com/site/francescapancotto/
----------------------------------

	[[alternative HTML version deleted]]


From cstangor at charlesstangor.com  Mon Nov 10 13:50:42 2014
From: cstangor at charlesstangor.com (Charles Stangor)
Date: Mon, 10 Nov 2014 06:50:42 -0600
Subject: [R] which LETTERS?
Message-ID: <CAJji86sP=JRSgdYRSeqCHY700_uwK36SjsWEp6zx1fWC+gQxvw@mail.gmail.com>

I'm confused:

Thanks in advance.

> which(LETTERS == c("A"))
[1] 1
> which(LETTERS == c("A","B"))
[1] 1 2
> which(LETTERS == c("A","B","C"))
[1] 1 2 3
Warning message:
In LETTERS == c("A", "B", "C") :
  longer object length is not a multiple of shorter object length


Charles Stangor
Professor
Dept of Psychology
University of Maryland
Academic Achievement Research Group <http://www.charlesstangor.com/AARG>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Nov 10 14:06:56 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 10 Nov 2014 08:06:56 -0500
Subject: [R] which LETTERS?
In-Reply-To: <CAJji86sP=JRSgdYRSeqCHY700_uwK36SjsWEp6zx1fWC+gQxvw@mail.gmail.com>
References: <CAJji86sP=JRSgdYRSeqCHY700_uwK36SjsWEp6zx1fWC+gQxvw@mail.gmail.com>
Message-ID: <5460B870.9030906@gmail.com>

On 10/11/2014 7:50 AM, Charles Stangor wrote:
> I'm confused:
>
> Thanks in advance.
>
> > which(LETTERS == c("A"))

This computes

LETTERS == c("A")

then returns the indices where it is TRUE.  Since LETTERS has 26 
elements, but "A" has only one, the "A" is repeated 26 times.  Only the 
first one matches LETTERS.
> [1] 1
> > which(LETTERS == c("A","B"))

The c("A", "B") needs to be repeated 13 times to get to length 26. Only 
the first two match.
> [1] 1 2
> > which(LETTERS == c("A","B","C"))

c("A", "B", "C") can't be repeated a whole number of times to extend to 
length 26, so it is repeated 8 2/3 times, and you get a warning.
> [1] 1 2 3
> Warning message:
> In LETTERS == c("A", "B", "C") :
>    longer object length is not a multiple of shorter object length

You probably want to use

which(LETTERS %in% c("A","B","C"))

instead.

Duncan Murdoch


>
> Charles Stangor
> Professor
> Dept of Psychology
> University of Maryland
> Academic Achievement Research Group <http://www.charlesstangor.com/AARG>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at univ-reims.fr  Mon Nov 10 14:03:17 2014
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 10 Nov 2014 14:03:17 +0100
Subject: [R] which LETTERS?
In-Reply-To: <CAJji86sP=JRSgdYRSeqCHY700_uwK36SjsWEp6zx1fWC+gQxvw@mail.gmail.com>
References: <CAJji86sP=JRSgdYRSeqCHY700_uwK36SjsWEp6zx1fWC+gQxvw@mail.gmail.com>
Message-ID: <5460B795.5010706@univ-reims.fr>

Hi Charles,

I think you're looking for %in%:
which(LETTERS %in% c("A", "B", "C"))

See ?"%in%" for details

Basically, with "==", the vector c("A","B") or c("A","B","C") will be 
recycled and compared with LETTERS, which is not what you want. You want 
to match() LETTERS with the vector.

Maybe someone who better knows the correct terms will be able to explain 
better how it works.

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENA? - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 10/11/14 13:50, Charles Stangor a ?crit :
> I'm confused:
>
> Thanks in advance.
>
>> which(LETTERS == c("A"))
> [1] 1
>> which(LETTERS == c("A","B"))
> [1] 1 2
>> which(LETTERS == c("A","B","C"))
> [1] 1 2 3
> Warning message:
> In LETTERS == c("A", "B", "C") :
>    longer object length is not a multiple of shorter object length
>
>
> Charles Stangor
> Professor
> Dept of Psychology
> University of Maryland
> Academic Achievement Research Group <http://www.charlesstangor.com/AARG>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wush978 at gmail.com  Mon Nov 10 14:29:56 2014
From: wush978 at gmail.com (Wush Wu)
Date: Mon, 10 Nov 2014 21:29:56 +0800
Subject: [R] Compressing code help in a loop
In-Reply-To: <CAKFaUKhjKkn2+0jVkTAQxsFT1fUgKzf9hSGh4niTRQTwQ_28Ug@mail.gmail.com>
References: <CAKFaUKhjKkn2+0jVkTAQxsFT1fUgKzf9hSGh4niTRQTwQ_28Ug@mail.gmail.com>
Message-ID: <CABjzuv6QO5p=0H3njh1jLFVeJqGtzJ7FvqJfWTb+gOmba5N_GA@mail.gmail.com>

Dear Francesca,

Is this what you want?

```r
index <- c(406, 107, 207, 307, 407, 108, 208, 308, 408, 109, 209, 309, 409,
110, 210, 310, 410, 111, 211)
p_m <- match( p_int$p_made, index)
dim(p_m) <- c(dim(p_int)[1],1)
```

Best,
Wush
PhD Student Graduate Institute of Electrical Engineering, National Taiwan
University



2014-11-10 20:14 GMT+08:00 Francesca <francesca.pancotto at gmail.com>:

> Dear Contributors
>
> I have a problem with a loop.
>
> I needed to create a variable that takes values 1,2.. to 19 corresponding
> to the value of a variable in a data.frame whose name is p_int$p_made and
>
> which takes values from 406  to 211.
>
> The problem is that this values come ordered in the wrong way when I try to
> compress the loop as the system reads
>
>
> 107,111,207,211,311,406,407,408,409,410,411,
>
>
> while they correspond to quarters-years so they should be ordered as
>
>
> 406-107-207-307-407?
>
> the only solution I found was really silly. It is the following.
>
>
>
>
> p_m<-matrix(0,dim(p_int)[1],1)
>
> for (i in 1:length(p_int$p_made)){
>
>   if (p_int$p_made[i]==406) p_m[i]<-1 else
>
>     if (p_int$p_made[i]==107) p_m[i]<-2 else
>
>       if (p_int$p_made[i]==207) p_m[i]<-3 else
>
>         if (p_int$p_made[i]==307) p_m[i]<-4 else
>
>           if (p_int$p_made[i]==407) p_m[i]<-5 else
>
>             if (p_int$p_made[i]==108) p_m[i]<-6 else
>
>               if (p_int$p_made[i]==208) p_m[i]<-7 else
>
>                 if (p_int$p_made[i]==308) p_m[i]<-8 else
>
>                   if (p_int$p_made[i]==408) p_m[i]<-9 else
>
>                     if (p_int$p_made[i]==109) p_m[i]<-10 else
>
>                       if (p_int$p_made[i]==209) p_m[i]<-11 else
>
>                         if (p_int$p_made[i]==309) p_m[i]<-12 else
>
>                           if (p_int$p_made[i]==409) p_m[i]<-13 else
>
>                             if (p_int$p_made[i]==110) p_m[i]<-14 else
>
>                               if (p_int$p_made[i]==210) p_m[i]<-15 else
>
>                                 if (p_int$p_made[i]==310) p_m[i]<-16 else
>
>                                   if (p_int$p_made[i]==410) p_m[i]<-17 else
>
>                                     if (p_int$p_made[i]==111) p_m[i]<-18
> else
>
>                                       if (p_int$p_made[i]==211) p_m[i]<-19
>
> }
>
> Can anyone help to find something more efficient?
>
>
> Thanks in advance.
>
>
> Francesca
>
> --
>
> Francesca
>
> ----------------------------------
> Francesca Pancotto
> Associate Professor
> University of Modena and Reggio Emilia
> Viale A. Allegri, 9
> 40121 Reggio Emilia
> Office: +39 0522 523264
> Web: https://sites.google.com/site/francescapancotto/
> ----------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From huangpsych at gmail.com  Mon Nov 10 15:20:08 2014
From: huangpsych at gmail.com (huang jialin)
Date: Mon, 10 Nov 2014 08:20:08 -0600
Subject: [R] MAd and trim-and-fill plot in R meta-analysis
Message-ID: <CACdH1VgzEPHi6=xwBtNrJepW8N5sDaRQmVByCxqm38X0MOJnRA@mail.gmail.com>

Hi,

I am planning to use BHHR method to conduct a meta-analysis, including
calculation of a summary effect size and subgroup analysis. Meanwhile, I
need to draw a trim-and-fill plot of all the effect sizes. However, MAd
package cannot achieve the goal, while meta and metafor do. But it seems
meta and metafor do not include BHHR method. What can I do to have both
BHHR method and trim-and-fill plot? I would deeply appreciate your
response. Thanks.

	[[alternative HTML version deleted]]


From studerov at gmail.com  Mon Nov 10 15:39:47 2014
From: studerov at gmail.com (David Studer)
Date: Mon, 10 Nov 2014 15:39:47 +0100
Subject: [R] Counting within groups / means by groups
Message-ID: <CAA1twZSRbyEpNyuvOwq8W4o6dP+goEDNm9ARyrzxPtBsAteNSQ@mail.gmail.com>

Hi everyone!

I have problems finding a solution to the following two problems:

My sample-dataframe consists of two variables "group" and "value":

group<-c("A", "A", "A", "B", "B", "B", "B", "C")
value<-c(1,3,2,2,2,4,4,1)
df<-as.data.frame(cbind(group, value))

Problem 1:
**********

Now I'd like to count the number of group-A-cases, group-B-cases etc and
write
this number into a new column. It should be like:

count_group<-c(3, 3, 3, 4, 4, 4, 4, 1)

Problem 2:
***********

I'd like to add new column with the mean values (or any other function)
within
my groups. E.g:

Group A: (1+3+2)/3=2
Group B: (2+2+4+4)/4=3
Group C: =1

Now I'd add another column 2 2 3 3 3 3 1


Can anyone help me, how this can be done best?

Thank you!
David

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Nov 10 16:19:27 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 10 Nov 2014 07:19:27 -0800
Subject: [R] Counting within groups / means by groups
In-Reply-To: <CAA1twZSRbyEpNyuvOwq8W4o6dP+goEDNm9ARyrzxPtBsAteNSQ@mail.gmail.com>
References: <CAA1twZSRbyEpNyuvOwq8W4o6dP+goEDNm9ARyrzxPtBsAteNSQ@mail.gmail.com>
Message-ID: <EF358900-4D0F-4D2A-B18D-64B6C8674A05@dcn.davis.CA.us>

Help file ?ave should apply here.

Please read the Posting Guide mentioned in the footer of every email on this list and on the list manager page for this mailing list. It warns you to read the archives before posting and to post in plain text format rather than HTML format.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 10, 2014 6:39:47 AM PST, David Studer <studerov at gmail.com> wrote:
>Hi everyone!
>
>I have problems finding a solution to the following two problems:
>
>My sample-dataframe consists of two variables "group" and "value":
>
>group<-c("A", "A", "A", "B", "B", "B", "B", "C")
>value<-c(1,3,2,2,2,4,4,1)
>df<-as.data.frame(cbind(group, value))
>
>Problem 1:
>**********
>
>Now I'd like to count the number of group-A-cases, group-B-cases etc
>and
>write
>this number into a new column. It should be like:
>
>count_group<-c(3, 3, 3, 4, 4, 4, 4, 1)
>
>Problem 2:
>***********
>
>I'd like to add new column with the mean values (or any other function)
>within
>my groups. E.g:
>
>Group A: (1+3+2)/3=2
>Group B: (2+2+4+4)/4=3
>Group C: =1
>
>Now I'd add another column 2 2 3 3 3 3 1
>
>
>Can anyone help me, how this can be done best?
>
>Thank you!
>David
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Nov 10 16:51:52 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 10 Nov 2014 15:51:52 +0000
Subject: [R] Counting within groups / means by groups
In-Reply-To: <EF358900-4D0F-4D2A-B18D-64B6C8674A05@dcn.davis.CA.us>
References: <CAA1twZSRbyEpNyuvOwq8W4o6dP+goEDNm9ARyrzxPtBsAteNSQ@mail.gmail.com>
	<EF358900-4D0F-4D2A-B18D-64B6C8674A05@dcn.davis.CA.us>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB0F7F@mb02.ads.tamu.edu>

In addition to Jeff's recommendation, you need to read a basic introduction to R. Your data frame is probably not what you think it is:

> group<-c("A", "A", "A", "B", "B", "B", "B", "C")
> value<-c(1,3,2,2,2,4,4,1)
> df<-as.data.frame(cbind(group, value))
> str(df)
'data.frame':   8 obs. of  2 variables:
 $ group: Factor w/ 3 levels "A","B","C": 1 1 1 2 2 2 2 3
 $ value: Factor w/ 4 levels "1","2","3","4": 1 3 2 2 2 4 4 1

By using cbind() you combined a character vector and a numeric vector into a matrix so R converted the numeric value to characters since a matrix can hold only a single data type. The cbind() function is generic and which version you get depends on the first argument.
> cbind(group, value)
     group value
[1,] "A"   "1"  
[2,] "A"   "3"  
[3,] "A"   "2"  
[4,] "B"   "2"  
[5,] "B"   "2"  
[6,] "B"   "4"  
[7,] "B"   "4"  
[8,] "C"   "1"  

Then you used as.data.frame() to convert the character matrix to a data.frame. The default for character variables is to convert those to factors. All you need is
> dfa <- data.frame(group, value)
> str(dfa)
'data.frame':   8 obs. of  2 variables:
 $ group: Factor w/ 3 levels "A","B","C": 1 1 1 2 2 2 2 3
 $ value: num  1 3 2 2 2 4 4 1

I changed df to dfa since df() is the density function for the f distribution. R is not likely to get confused, but you might.

Then read the manual page on ave() to see why these work and how to adapt them:

> ave(dfa$value, dfa$group, FUN=length)
[1] 3 3 3 4 4 4 4 1
> ave(dfa$value, dfa$group)
[1] 2 2 2 3 3 3 3 1

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Newmiller
Sent: Monday, November 10, 2014 9:19 AM
To: studerov at gmail.com; r-help at r-project.org
Subject: Re: [R] Counting within groups / means by groups

Help file ?ave should apply here.

Please read the Posting Guide mentioned in the footer of every email on this list and on the list manager page for this mailing list. It warns you to read the archives before posting and to post in plain text format rather than HTML format.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On November 10, 2014 6:39:47 AM PST, David Studer <studerov at gmail.com> wrote:
>Hi everyone!
>
>I have problems finding a solution to the following two problems:
>
>My sample-dataframe consists of two variables "group" and "value":
>
>group<-c("A", "A", "A", "B", "B", "B", "B", "C")
>value<-c(1,3,2,2,2,4,4,1)
>df<-as.data.frame(cbind(group, value))
>
>Problem 1:
>**********
>
>Now I'd like to count the number of group-A-cases, group-B-cases etc
>and
>write
>this number into a new column. It should be like:
>
>count_group<-c(3, 3, 3, 4, 4, 4, 4, 1)
>
>Problem 2:
>***********
>
>I'd like to add new column with the mean values (or any other function)
>within
>my groups. E.g:
>
>Group A: (1+3+2)/3=2
>Group B: (2+2+4+4)/4=3
>Group C: =1
>
>Now I'd add another column 2 2 3 3 3 3 1
>
>
>Can anyone help me, how this can be done best?
>
>Thank you!
>David
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Pradip.Muhuri at samhsa.hhs.gov  Mon Nov 10 17:10:14 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Mon, 10 Nov 2014 16:10:14 +0000
Subject: [R] range () does not remove NA's with complete.cases() for dates
 (dplyr/mutate)
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>

Hello,

The range() with complete.cases() removes NA's for the date variables that are read from a data frame.  However, the issue is that the same function does not remove NA's for the other date variable that is created using the dplyr/mutate().  The console and the reproducible example are given below. Any advice how to resolve this issue would be appreciated.

Thanks,

Pradip Muhuri


#################  cut and pasted from the R console ####################

id    mrjdate    cocdate    inhdate    haldate    oiddate
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>
> # range of dates
>
> range(data2$mrjdate[complete.cases(data2$mrjdate)])
[1] "2004-11-04" "2009-10-24"
> range(data2$cocdate[complete.cases(data2$cocdate)])
[1] "2005-08-10" "2011-10-05"
> range(data2$inhdate[complete.cases(data2$inhdate)])
[1] "2005-07-07" "2011-10-13"
> range(data2$haldate[complete.cases(data2$haldate)])
[1] "2007-11-07" "2011-11-04"
> range(data2$oiddate[complete.cases(data2$oiddate)])
[1] NA           "2011-11-04"


################  reproducible code #############################

library(dplyr)
library(lubridate)
library(zoo)
# data object - description of the

temp <- "id  mrjdate cocdate inhdate haldate
1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
2             NA         NA         NA         NA
3     2009-10-24         NA 2011-10-13         NA
4     2007-10-10         NA         NA         NA
5     2006-09-01 2005-08-10         NA         NA
6     2007-09-04 2011-10-05         NA         NA
7     2005-10-25         NA         NA 2011-11-04"

# read the data object

data1 <- read.table(textConnection(temp),
                    colClasses=c("character", "Date", "Date", "Date", "Date"),
                    header=TRUE, as.is=TRUE
                    )


# create a new column

data2 <- data1 %>%
     rowwise() %>%
      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                                                               na.rm=TRUE), origin='1970-01-01'))

# print records

print (data2)

# range of dates

range(data2$mrjdate[complete.cases(data2$mrjdate)])
range(data2$cocdate[complete.cases(data2$cocdate)])
range(data2$inhdate[complete.cases(data2$inhdate)])
range(data2$haldate[complete.cases(data2$haldate)])
range(data2$oiddate[complete.cases(data2$oiddate)])





Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260



	[[alternative HTML version deleted]]


From aps6dl at yahoo.com  Mon Nov 10 14:12:10 2014
From: aps6dl at yahoo.com (Aditya Singh)
Date: Mon, 10 Nov 2014 13:12:10 +0000 (UTC)
Subject: [R] 1. What function to use to read all the files in a directory to
 a vector in R code? 2. What function to use to coerce character string into
 numeric?
Message-ID: <666010385.273467.1415625130588.JavaMail.yahoo@jws10681.mail.bf1.yahoo.com>

Hi,
I have 2 queries:
1. What function to use to read all the files in a directory to a vector in R code?
2. What function to use to coerce character string into numeric?
As a help to others, I figured out to use setwd("C:/....") to set working directory!
Aditya
	[[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Mon Nov 10 17:30:28 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 10 Nov 2014 16:30:28 +0000 (UTC)
Subject: [R] range () does not remove NA's with complete.cases() for
 dates (dplyr/mutate)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>
Message-ID: <532837432.336128.1415637028335.JavaMail.yahoo@jws10601.mail.bf1.yahoo.com>

Try

range(data2$oiddate[complete.cases(data2$oiddate) & is.finite(data2$oiddate)])
#[1] "2006-09-01" "2011-11-04"



If you look at the `dput` output, it is `Inf` for oiddate
dput(data2$oiddate)
structure(c(14078, -Inf, 15260, 13796, 13392, 15252, 15282), class = "Date")

   

A.K.

On Monday, November 10, 2014 11:15 AM, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
Hello,

The range() with complete.cases() removes NA's for the date variables that are read from a data frame.  However, the issue is that the same function does not remove NA's for the other date variable that is created using the dplyr/mutate().  The console and the reproducible example are given below. Any advice how to resolve this issue would be appreciated.

Thanks,

Pradip Muhuri


#################  cut and pasted from the R console ####################

id    mrjdate    cocdate    inhdate    haldate    oiddate
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>
> # range of dates
>
> range(data2$mrjdate[complete.cases(data2$mrjdate)])
[1] "2004-11-04" "2009-10-24"
> range(data2$cocdate[complete.cases(data2$cocdate)])
[1] "2005-08-10" "2011-10-05"
> range(data2$inhdate[complete.cases(data2$inhdate)])
[1] "2005-07-07" "2011-10-13"
> range(data2$haldate[complete.cases(data2$haldate)])
[1] "2007-11-07" "2011-11-04"
> range(data2$oiddate[complete.cases(data2$oiddate)])
[1] NA           "2011-11-04"


################  reproducible code #############################

library(dplyr)
library(lubridate)
library(zoo)
# data object - description of the

temp <- "id  mrjdate cocdate inhdate haldate
1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
2             NA         NA         NA         NA
3     2009-10-24         NA 2011-10-13         NA
4     2007-10-10         NA         NA         NA
5     2006-09-01 2005-08-10         NA         NA
6     2007-09-04 2011-10-05         NA         NA
7     2005-10-25         NA         NA 2011-11-04"

# read the data object

data1 <- read.table(textConnection(temp),
                    colClasses=c("character", "Date", "Date", "Date", "Date"),
                    header=TRUE, as.is=TRUE
                    )


# create a new column

data2 <- data1 %>%
     rowwise() %>%
      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                                                               na.rm=TRUE), origin='1970-01-01'))

# print records

print (data2)

# range of dates

range(data2$mrjdate[complete.cases(data2$mrjdate)])
range(data2$cocdate[complete.cases(data2$cocdate)])
range(data2$inhdate[complete.cases(data2$inhdate)])
range(data2$haldate[complete.cases(data2$haldate)])
range(data2$oiddate[complete.cases(data2$oiddate)])





Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260



    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Pradip.Muhuri at samhsa.hhs.gov  Mon Nov 10 17:38:13 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Mon, 10 Nov 2014 16:38:13 +0000
Subject: [R] range () does not remove NA's with complete.cases() for
 dates (dplyr/mutate)
In-Reply-To: <532837432.336128.1415637028335.JavaMail.yahoo@jws10601.mail.bf1.yahoo.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>
	<532837432.336128.1415637028335.JavaMail.yahoo@jws10601.mail.bf1.yahoo.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5EEAB@pl-emsmb11>

Hello Arun,

Thank you so much for your help.

Regards, 

Pradip

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, November 10, 2014 11:30 AM
To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
Subject: Re: [R] range () does not remove NA's with complete.cases() for dates (dplyr/mutate)

Try

range(data2$oiddate[complete.cases(data2$oiddate) & is.finite(data2$oiddate)]) #[1] "2006-09-01" "2011-11-04"



If you look at the `dput` output, it is `Inf` for oiddate
dput(data2$oiddate)
structure(c(14078, -Inf, 15260, 13796, 13392, 15252, 15282), class = "Date")

   

A.K.

On Monday, November 10, 2014 11:15 AM, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
Hello,

The range() with complete.cases() removes NA's for the date variables that are read from a data frame.  However, the issue is that the same function does not remove NA's for the other date variable that is created using the dplyr/mutate().  The console and the reproducible example are given below. Any advice how to resolve this issue would be appreciated.

Thanks,

Pradip Muhuri


#################  cut and pasted from the R console ####################

id    mrjdate    cocdate    inhdate    haldate    oiddate
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>
> # range of dates
>
> range(data2$mrjdate[complete.cases(data2$mrjdate)])
[1] "2004-11-04" "2009-10-24"
> range(data2$cocdate[complete.cases(data2$cocdate)])
[1] "2005-08-10" "2011-10-05"
> range(data2$inhdate[complete.cases(data2$inhdate)])
[1] "2005-07-07" "2011-10-13"
> range(data2$haldate[complete.cases(data2$haldate)])
[1] "2007-11-07" "2011-11-04"
> range(data2$oiddate[complete.cases(data2$oiddate)])
[1] NA           "2011-11-04"


################  reproducible code #############################

library(dplyr)
library(lubridate)
library(zoo)
# data object - description of the

temp <- "id  mrjdate cocdate inhdate haldate
1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
2             NA         NA         NA         NA
3     2009-10-24         NA 2011-10-13         NA
4     2007-10-10         NA         NA         NA
5     2006-09-01 2005-08-10         NA         NA
6     2007-09-04 2011-10-05         NA         NA
7     2005-10-25         NA         NA 2011-11-04"

# read the data object

data1 <- read.table(textConnection(temp),
                    colClasses=c("character", "Date", "Date", "Date", "Date"),
                    header=TRUE, as.is=TRUE
                    )


# create a new column

data2 <- data1 %>%
     rowwise() %>%
      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                                                               na.rm=TRUE), origin='1970-01-01'))

# print records

print (data2)

# range of dates

range(data2$mrjdate[complete.cases(data2$mrjdate)])
range(data2$cocdate[complete.cases(data2$cocdate)])
range(data2$inhdate[complete.cases(data2$inhdate)])
range(data2$haldate[complete.cases(data2$haldate)])
range(data2$oiddate[complete.cases(data2$oiddate)])





Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260



    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From david at revolutionanalytics.com  Mon Nov 10 18:04:21 2014
From: david at revolutionanalytics.com (David Smith)
Date: Mon, 10 Nov 2014 11:04:21 -0600
Subject: [R] Revolutions blog: October roundup
Message-ID: <CABgvEC9Nv-HA5Kk4-eKvVGBbOFtc16xN1UVQBBSk=+SMWK5LBw@mail.gmail.com>

Revolution Analytics staff and guests write about R every weekday at
the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of October:

R hits a new milestone with 6,000 CRAN packages, and R 3.1.2 released:
http://bit.ly/1xDbIzZ

Revolution Analytics announces Revolution R Open, a supported and
enhanced downstream distribution of R: http://bit.ly/1xDbKrn . (I'll
be presenting a webinar on this topic on Wednesday November 12:
http://bit.ly/1xDbKro )

Some benchmarks on the performance improvements that come from linking
Revolution R Open with the Intel Math Kernel Libraries:
http://bit.ly/1xDbIzX

Now available: the Reproducible R Toolkit: a package ("checkpoint")
and a server containing archived CRAN packages to make it easy to
reproduce the results of R code that uses packages:
http://bit.ly/1xDbIzW

Revolution Analytics has released DeployR Open, a new open-source
framework for integrating R into other applications:
http://bit.ly/1xDbIzY

The new MRAN website mran.revolutionanalytics.com provides a
dependency graph for every R package on CRAN: http://bit.ly/1xDbIQc

A new package miniCRAN makes it easy to create a local package
repository with a subset of CRAN packages: http://bit.ly/1xDbIQe

The ACM held an unconference near San Francisco, and featured a
comparison of principal components analysis in R and Python:
http://bit.ly/1xDbIQd

The author of the survival package, Dr Terry Therneau, on the state of
Type III tests in R: http://bit.ly/1xDbKrp

Using R to create a "fashion fingerprint" to visualize colours in a
fashion collection: http://bit.ly/1xDbIQg

The new "Rocker" project provides easy-to-use Docker containers
(similar to virtual machines) including R: http://bit.ly/1xDbIQf

HP releases "Distributed R", an R package to integrate with the HP
Vertica database: http://bit.ly/1xDbKrt

Some tips on controlling R resource usage when deployed in a
production environment: http://bit.ly/1xDbIQi

An exhortation to explore complex (and even not-so-complex)
statistical problems with simulation: http://bit.ly/1xDbIQh

Presentations from R user groups on image analysis, data mapping and
data journalism: http://bit.ly/1xDbIQj

The Fantasy Football Analytics blog suggests 14 reasons why R is
better than Excel for data analysis: http://bit.ly/1xDbKrs

An overview of the Tweedie distribution, which judging from citations
is becoming more widely used: http://bit.ly/1xDbKru

A look at the GLDEX package and the Generalized Lambda Distribution to
model financial returns: http://bit.ly/1xDbKrv

In a video interview, RStudio's Joe Cheng discusses how the design of
the R language supports the implementation of domain-specific
languages: http://bit.ly/1xDbIQm

Slides from the webinar "R and Data Science", presented by Joseph
Rickert: http://bit.ly/1xDbKry

An article in the New York Times contrasts Bayesian and Frequentist
statistics: http://bit.ly/1xDbKrx

General interest stories (not related to R) in the past month
included: a Halloween prank (http://bit.ly/1xDbIQn), teaching robots
to walk with a genetic algorithm (http://bit.ly/1xDbKrw), if dogs and
cats kept diaries (http://bit.ly/1xDbIQo), the "bookbook"
(http://bit.ly/1xDbIQp), and the direction techniques of David Fincher
(http://bit.ly/1xDbIQq).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid

-- 
 

Revolution R Plus <http://revolutionanalytics.com/plus>

Subscribe to Technical Support & Indemnification for R


From info at aghmed.fsnet.co.uk  Mon Nov 10 18:08:48 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 10 Nov 2014 17:08:48 +0000
Subject: [R] MAd and trim-and-fill plot in R meta-analysis
In-Reply-To: <CACdH1VgzEPHi6=xwBtNrJepW8N5sDaRQmVByCxqm38X0MOJnRA@mail.gmail.com>
References: <CACdH1VgzEPHi6=xwBtNrJepW8N5sDaRQmVByCxqm38X0MOJnRA@mail.gmail.com>
Message-ID: <5460F120.1050201@aghmed.fsnet.co.uk>



On 10/11/2014 14:20, huang jialin wrote:
> Hi,
>
> I am planning to use BHHR method to conduct a meta-analysis, including
> calculation of a summary effect size and subgroup analysis. Meanwhile, I
> need to draw a trim-and-fill plot of all the effect sizes. However, MAd
> package cannot achieve the goal, while meta and metafor do. But it seems
> meta and metafor do not include BHHR method. What can I do to have both
> BHHR method and trim-and-fill plot? I would deeply appreciate your
> response.

Why not use MAd to produce an aggregated data frame and then input that 
to meta or metafor? Disclaimer: I am not saying I recommend the BHHR method.

And please do not (a) post in HTML (b) also post on StackOverflow

  Thanks.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5557 / Virus Database: 4189/8536 - Release Date: 11/08/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From jdnewmil at dcn.davis.CA.us  Mon Nov 10 18:12:35 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 10 Nov 2014 09:12:35 -0800
Subject: [R] 1. What function to use to read all the files in a
	directory to a vector in R code? 2. What function to use to
	coerce character string into numeric?
In-Reply-To: <666010385.273467.1415625130588.JavaMail.yahoo@jws10681.mail.bf1.yahoo.com>
References: <666010385.273467.1415625130588.JavaMail.yahoo@jws10681.mail.bf1.yahoo.com>
Message-ID: <496CF7CA-5D28-4460-8DEE-6CE24890ABDD@dcn.davis.CA.us>

1. There is no built-in function to do that, but it can be done if you learn the basics of R [1]. For one thing, there is no assurance that all files in a directory will fit into vectors.. Most data fit better into data frames, and some data like XML need to be stored in lists of lists. So your first task is to work this out and use the str function to make sure you understand how your data for one file looks when imported into R variables.

Once you figure out how your files can be read in (perhaps with read.csv or read.table?) then you can use list.files to get a vector of filenames, and lapply to create a list of contents of files. You may need to re-read the discussions of lists and indexing in [1] again to see how to get the pieces out of the list. If all your files actually do have the same data frame structure, then you might find it useful to merge the list into a single data frame. Something like:

fnames <- list.files( pattern="\\.csv$" )
dtalist <- lapply(fnames,function(fn){read.csv(fn,stringsAsFactors=FALSE)})
alldta <- do.call(rbind,dtalist)

2. Read help file ?numeric.

You should also read the Posting Guide, which among other advice mentions that you should post using plain text format on this list rather than HTML (since we don't see what you see if you use the latter).

[1] Introduction to R, supplied with the software.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 10, 2014 5:12:10 AM PST, Aditya Singh <aps6dl at yahoo.com> wrote:
>Hi,
>I have 2 queries:
>1. What function to use to read all the files in a directory to a
>vector in R code?
>2. What function to use to coerce character string into numeric?
>As a help to others, I figured out to use setwd("C:/....") to set
>working directory!
>Aditya
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Mon Nov 10 18:23:21 2014
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 10 Nov 2014 11:23:21 -0600
Subject: [R] range () does not remove NA's with complete.cases() for
 dates (dplyr/mutate)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>
Message-ID: <4170D4A5-A345-4E31-958A-44FEC62A00FD@TxBiomed.org>

Pradip,

For some reason mutate is not setting the is.NA value for the new column. Note the output below using your data structures.

> ## It looks at first as if the second element of both columns are NA.
> data2$mrjdate[2]
[1] NA
> data2$oiddate[2]
[1] NA
> ## for convenience
> mrj <- data2$mrjdate[2]
> oid <- data2$oiddate[2]
> mode(mrj)
[1] "numeric"
> mode(oid)
[1] "numeric"
> str(mrj)
 Date[1:1], format: NA
> str(oid)
 Date[1:1], format: NA
> class(mrj)
[1] "Date"
> class(oid)
[1] "Date"
> ## But note:
> identical(mrj, oid)
[1] FALSE
> all.equal(mrj, oid)
[1] "'is.NA' value mismatch: 0 in current 1 in target"
## functioning code
data2$mrjdate[2]
data2$oiddate[2]
mrj <- data2$mrjdate[2]
oid <- data2$oiddate[2]
mode(mrj)
mode(oid)
str(mrj)
str(oid)
class(mrj)
class(oid)
# But note:
identical(mrj, oid)
all.equal(mrj, oid)

## This ugly solution does not have the problem.
> data3 <- data1
> data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
+   if (all(is.na(unlist(data1[row, -1])))) {
+     max_d <- NA
+   } else {
+     max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
+   }
+   max_d}),
+   origin = "1970-01-01")
>
> range(data3$mrjdate[complete.cases(data3$mrjdate)])
[1] "2004-11-04" "2009-10-24"
> range(data3$cocdate[complete.cases(data3$cocdate)])
[1] "2005-08-10" "2011-10-05"
> range(data3$inhdate[complete.cases(data3$inhdate)])
[1] "2005-07-07" "2011-10-13"
> range(data3$haldate[complete.cases(data3$haldate)])
[1] "2007-11-07" "2011-11-04"
> range(data3$oiddate[complete.cases(data3$oiddate)])
[1] "2006-09-01" "2011-11-04"
>
Working code below.

data3 <- data1
data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
  if (all(is.na(unlist(data1[row, -1])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

range(data3$mrjdate[complete.cases(data3$mrjdate)])
range(data3$cocdate[complete.cases(data3$cocdate)])
range(data3$inhdate[complete.cases(data3$inhdate)])
range(data3$haldate[complete.cases(data3$haldate)])
range(data3$oiddate[complete.cases(data3$oiddate)])


On Nov 10, 2014, at 10:10 AM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:

> Hello,
>
> The range() with complete.cases() removes NA's for the date variables that are read from a data frame.  However, the issue is that the same function does not remove NA's for the other date variable that is created using the dplyr/mutate().  The console and the reproducible example are given below. Any advice how to resolve this issue would be appreciated.
>
> Thanks,
>
> Pradip Muhuri
>
>
> #################  cut and pasted from the R console ####################
>
> id    mrjdate    cocdate    inhdate    haldate    oiddate
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>>
>> # range of dates
>>
>> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> [1] "2004-11-04" "2009-10-24"
>> range(data2$cocdate[complete.cases(data2$cocdate)])
> [1] "2005-08-10" "2011-10-05"
>> range(data2$inhdate[complete.cases(data2$inhdate)])
> [1] "2005-07-07" "2011-10-13"
>> range(data2$haldate[complete.cases(data2$haldate)])
> [1] "2007-11-07" "2011-11-04"
>> range(data2$oiddate[complete.cases(data2$oiddate)])
> [1] NA           "2011-11-04"
>
>
> ################  reproducible code #############################
>
> library(dplyr)
> library(lubridate)
> library(zoo)
> # data object - description of the
>
> temp <- "id  mrjdate cocdate inhdate haldate
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> 2             NA         NA         NA         NA
> 3     2009-10-24         NA 2011-10-13         NA
> 4     2007-10-10         NA         NA         NA
> 5     2006-09-01 2005-08-10         NA         NA
> 6     2007-09-04 2011-10-05         NA         NA
> 7     2005-10-25         NA         NA 2011-11-04"
>
> # read the data object
>
> data1 <- read.table(textConnection(temp),
>                    colClasses=c("character", "Date", "Date", "Date", "Date"),
>                    header=TRUE, as.is=TRUE
>                    )
>
>
> # create a new column
>
> data2 <- data1 %>%
>     rowwise() %>%
>      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>                                                               na.rm=TRUE), origin='1970-01-01'))
>
> # print records
>
> print (data2)
>
> # range of dates
>
> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> range(data2$cocdate[complete.cases(data2$cocdate)])
> range(data2$inhdate[complete.cases(data2$inhdate)])
> range(data2$haldate[complete.cases(data2$haldate)])
> range(data2$oiddate[complete.cases(data2$oiddate)])
>
>
>
>
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From mlarruda at terra.com.br  Mon Nov 10 18:15:58 2014
From: mlarruda at terra.com.br (Marcelo L. Arruda)
Date: Mon, 10 Nov 2014 15:15:58 -0200
Subject: [R] Help on CHAID info
Message-ID: <5460F2CE.90601@terra.com.br>

Dear friends,

     I am analyzing a big dataset via CHAID and the resulting tree has 
dozens of terminal nodes. My question is: since I want to use these 
categories in further analysis, how can I get a summarized listing 
(preferably in a vector format) about the content of each category. For 
example, suppose that my resulting tree was like that:


Fitted party:
[1] root
|   [2] color in 0
|   |   [3] year in 0: 0 (n = 311, err = 49.5%)
|   |   [4] year in 1: 1 (n = 249, err = 35.3%)
|   [5] color in 1
|   |   [6] size in 0: 0 (n = 159, err = 47.8%)
|   |   [7] size in 1:
|   |   |   [8] price in 0: 0 (n = 127, err = 22.0%)
|   |   |   [9] price in 1: 0 (n = 115, err = 40.9%)

     So, I wished a function which could return a list of informations 
like that:

         terminal node 3: color = 0 and year = 0
         terminal node 4: color = 0 and year = 1
         terminal node 6: color = 1 and size = 0
         terminal node 8: color = 1, size = 1 and price = 0
         terminal node 9: color = 1, size = 1 and price = 1

     For example, a matrix like that would be more than good to my goals:

      term_node color year size price
[1,]         3     0    0   NA    NA
[2,]         4     0    1   NA    NA
[3,]         6     1   NA    0    NA
[4,]         8     1   NA    1     0
[5,]         9     1   NA    1     1

     Many thanks in advance for any help,

Marcelo L. Arruda

	[[alternative HTML version deleted]]


From huangpsych at gmail.com  Mon Nov 10 18:30:43 2014
From: huangpsych at gmail.com (huang jialin)
Date: Mon, 10 Nov 2014 11:30:43 -0600
Subject: [R] MAd and trim-and-fill plot in R meta-analysis
In-Reply-To: <5460F120.1050201@aghmed.fsnet.co.uk>
References: <CACdH1VgzEPHi6=xwBtNrJepW8N5sDaRQmVByCxqm38X0MOJnRA@mail.gmail.com>
	<5460F120.1050201@aghmed.fsnet.co.uk>
Message-ID: <CACdH1Vix9ZnH0G=2v73VSayPRuZb4Rc9-Y2LLxneD5k5+Q4EcA@mail.gmail.com>

Thank you for your response. I apologize for cross posting. I will try the
way you suggested. Thanks again.

On Mon, Nov 10, 2014 at 11:08 AM, Michael Dewey <info at aghmed.fsnet.co.uk>
wrote:

>
>
> On 10/11/2014 14:20, huang jialin wrote:
>
>> Hi,
>>
>> I am planning to use BHHR method to conduct a meta-analysis, including
>> calculation of a summary effect size and subgroup analysis. Meanwhile, I
>> need to draw a trim-and-fill plot of all the effect sizes. However, MAd
>> package cannot achieve the goal, while meta and metafor do. But it seems
>> meta and metafor do not include BHHR method. What can I do to have both
>> BHHR method and trim-and-fill plot? I would deeply appreciate your
>> response.
>>
>
> Why not use MAd to produce an aggregated data frame and then input that to
> meta or metafor? Disclaimer: I am not saying I recommend the BHHR method.
>
> And please do not (a) post in HTML (b) also post on StackOverflow
>
>  Thanks.
>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> -----
>> No virus found in this message.
>> Checked by AVG - www.avg.com
>> Version: 2015.0.5557 / Virus Database: 4189/8536 - Release Date: 11/08/14
>>
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk
>

	[[alternative HTML version deleted]]


From Pradip.Muhuri at samhsa.hhs.gov  Mon Nov 10 19:09:09 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Mon, 10 Nov 2014 18:09:09 +0000
Subject: [R] range () does not remove NA's with complete.cases() for
 dates (dplyr/mutate)
In-Reply-To: <4170D4A5-A345-4E31-958A-44FEC62A00FD@TxBiomed.org>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>
	<4170D4A5-A345-4E31-958A-44FEC62A00FD@TxBiomed.org>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5EEEC@pl-emsmb11>

Mark,

Thank you very much for further looking into this issue.  So, the "ugly" solution is better!  Would you like to bring to Hadley's attention that mutate does set the NA value for the new column?

Regards,

Pradip

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----
From: Mark Sharp [mailto:msharp at TxBiomed.org] 
Sent: Monday, November 10, 2014 12:23 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org
Subject: Re: [R] range () does not remove NA's with complete.cases() for dates (dplyr/mutate)

Pradip,

For some reason mutate is not setting the is.NA value for the new column. Note the output below using your data structures.

> ## It looks at first as if the second element of both columns are NA.
> data2$mrjdate[2]
[1] NA
> data2$oiddate[2]
[1] NA
> ## for convenience
> mrj <- data2$mrjdate[2]
> oid <- data2$oiddate[2]
> mode(mrj)
[1] "numeric"
> mode(oid)
[1] "numeric"
> str(mrj)
 Date[1:1], format: NA
> str(oid)
 Date[1:1], format: NA
> class(mrj)
[1] "Date"
> class(oid)
[1] "Date"
> ## But note:
> identical(mrj, oid)
[1] FALSE
> all.equal(mrj, oid)
[1] "'is.NA' value mismatch: 0 in current 1 in target"
## functioning code
data2$mrjdate[2]
data2$oiddate[2]
mrj <- data2$mrjdate[2]
oid <- data2$oiddate[2]
mode(mrj)
mode(oid)
str(mrj)
str(oid)
class(mrj)
class(oid)
# But note:
identical(mrj, oid)
all.equal(mrj, oid)

## This ugly solution does not have the problem.
> data3 <- data1
> data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
+   if (all(is.na(unlist(data1[row, -1])))) {
+     max_d <- NA
+   } else {
+     max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
+   }
+   max_d}),
+   origin = "1970-01-01")
>
> range(data3$mrjdate[complete.cases(data3$mrjdate)])
[1] "2004-11-04" "2009-10-24"
> range(data3$cocdate[complete.cases(data3$cocdate)])
[1] "2005-08-10" "2011-10-05"
> range(data3$inhdate[complete.cases(data3$inhdate)])
[1] "2005-07-07" "2011-10-13"
> range(data3$haldate[complete.cases(data3$haldate)])
[1] "2007-11-07" "2011-11-04"
> range(data3$oiddate[complete.cases(data3$oiddate)])
[1] "2006-09-01" "2011-11-04"
>
Working code below.

data3 <- data1
data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
  if (all(is.na(unlist(data1[row, -1])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

range(data3$mrjdate[complete.cases(data3$mrjdate)])
range(data3$cocdate[complete.cases(data3$cocdate)])
range(data3$inhdate[complete.cases(data3$inhdate)])
range(data3$haldate[complete.cases(data3$haldate)])
range(data3$oiddate[complete.cases(data3$oiddate)])


On Nov 10, 2014, at 10:10 AM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:

> Hello,
>
> The range() with complete.cases() removes NA's for the date variables that are read from a data frame.  However, the issue is that the same function does not remove NA's for the other date variable that is created using the dplyr/mutate().  The console and the reproducible example are given below. Any advice how to resolve this issue would be appreciated.
>
> Thanks,
>
> Pradip Muhuri
>
>
> #################  cut and pasted from the R console ####################
>
> id    mrjdate    cocdate    inhdate    haldate    oiddate
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>>
>> # range of dates
>>
>> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> [1] "2004-11-04" "2009-10-24"
>> range(data2$cocdate[complete.cases(data2$cocdate)])
> [1] "2005-08-10" "2011-10-05"
>> range(data2$inhdate[complete.cases(data2$inhdate)])
> [1] "2005-07-07" "2011-10-13"
>> range(data2$haldate[complete.cases(data2$haldate)])
> [1] "2007-11-07" "2011-11-04"
>> range(data2$oiddate[complete.cases(data2$oiddate)])
> [1] NA           "2011-11-04"
>
>
> ################  reproducible code #############################
>
> library(dplyr)
> library(lubridate)
> library(zoo)
> # data object - description of the
>
> temp <- "id  mrjdate cocdate inhdate haldate
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> 2             NA         NA         NA         NA
> 3     2009-10-24         NA 2011-10-13         NA
> 4     2007-10-10         NA         NA         NA
> 5     2006-09-01 2005-08-10         NA         NA
> 6     2007-09-04 2011-10-05         NA         NA
> 7     2005-10-25         NA         NA 2011-11-04"
>
> # read the data object
>
> data1 <- read.table(textConnection(temp),
>                    colClasses=c("character", "Date", "Date", "Date", "Date"),
>                    header=TRUE, as.is=TRUE
>                    )
>
>
> # create a new column
>
> data2 <- data1 %>%
>     rowwise() %>%
>      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>                                                               na.rm=TRUE), origin='1970-01-01'))
>
> # print records
>
> print (data2)
>
> # range of dates
>
> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> range(data2$cocdate[complete.cases(data2$cocdate)])
> range(data2$inhdate[complete.cases(data2$inhdate)])
> range(data2$haldate[complete.cases(data2$haldate)])
> range(data2$oiddate[complete.cases(data2$oiddate)])
>
>
>
>
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From rus314 at gmail.com  Mon Nov 10 18:46:45 2014
From: rus314 at gmail.com (Alexandr M)
Date: Mon, 10 Nov 2014 17:46:45 +0000
Subject: [R] Strange error while passing string as an argument to the
 function in bnlearn package
Message-ID: <CAJ4nbUq=jEWy6L3TWdS6vSO2WUJOCGj9pRRWJ=cPysU4FpCmvg@mail.gmail.com>

Hello everybody,

I am working with the package bnlear, but, probably, error is caused not by
the package itself.

There is a function cpquery() to which I pass argument str2:

str2="(lag1=='s')"
prob.s = cpquery(fitted1,
                             event=eval(parse(text="(M=='s')")),
                             evidence=eval(parse(text=str2)))

- Error in parse(text = str2) : object 'str2' not found

fitted1 is a fitted model

But if I put value of str2 directly into function call:

prob.s = cpquery(fitted1,
                             event=eval(parse(text="(M=='s')")),
                             evidence="(lag1.M1=='s')")
it works fine.

Does anybody have any idea how to fix it?

PS:
- I used documentation to the package:
http://cran.r-project.org/web/packages/bnlearn/bnlearn.pdf
function cpquery()
- I also trued to use backslashes \' \" - doesn't work too

-- 
Best regards,
Alexandr

	[[alternative HTML version deleted]]


From emma.gerald at gmail.com  Mon Nov 10 19:18:51 2014
From: emma.gerald at gmail.com (Emma Gerald Boyer)
Date: Mon, 10 Nov 2014 13:18:51 -0500
Subject: [R] Remove from listserv
Message-ID: <CAHKoFnrPwVyjrNK708L-LnLxY1GUUikvhtQTXYMkDKrV3rGnpw@mail.gmail.com>

Hello

Is there any way that I can be removed from the list-serv?  Let me know if
I need to do anything.

Thanks so much

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Nov 10 19:30:15 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 10 Nov 2014 10:30:15 -0800
Subject: [R] range () does not remove NA's with complete.cases() for
	dates (dplyr/mutate)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5EEEC@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>
	<4170D4A5-A345-4E31-958A-44FEC62A00FD@TxBiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5EEEC@pl-emsmb11>
Message-ID: <CAF8bMcaFbPooet=LYwR-oadVTCQhbMvmCUXMqATYi32KbtwZeA@mail.gmail.com>

> Would you like to bring to Hadley's attention that mutate does
> set the NA value for the new column?

This may not be mutate()'s problem.

The Date class is messed up with regard to NA's and Inf's.  E.g., what gets
printed as NA does not correspond to what is.na() returns and its range()
method does not appear to pass the finite=TRUE argument to range.default:
  > d <- as.Date(c("2014-10-31", c("2014-11-10")))
  > d1 <- range(d[0], finite=TRUE)
  Warning messages:
  1: In min.default(numeric(0), na.rm = FALSE) :
    no non-missing arguments to min; returning Inf
  2: In max.default(numeric(0), na.rm = FALSE) :
    no non-missing arguments to max; returning -Inf
  > d1
  [1] NA NA
  > is.na(d1)
  [1] FALSE FALSE
  > dput(d1)
  structure(c(Inf, -Inf), class = "Date")
  > range(c(d1, d), finite=TRUE)
  [1] NA NA
  > range(c(d1, d), finite=TRUE, na.rm=TRUE)
  [1] NA NA



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 10, 2014 at 10:09 AM, Muhuri, Pradip (SAMHSA/CBHSQ) <
Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Mark,
>
> Thank you very much for further looking into this issue.  So, the "ugly"
> solution is better!  Would you like to bring to Hadley's attention that
> mutate does set the NA value for the new column?
>
> Regards,
>
> Pradip
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
>
> -----Original Message-----
> From: Mark Sharp [mailto:msharp at TxBiomed.org]
> Sent: Monday, November 10, 2014 12:23 PM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] range () does not remove NA's with complete.cases() for
> dates (dplyr/mutate)
>
> Pradip,
>
> For some reason mutate is not setting the is.NA value for the new column.
> Note the output below using your data structures.
>
> > ## It looks at first as if the second element of both columns are NA.
> > data2$mrjdate[2]
> [1] NA
> > data2$oiddate[2]
> [1] NA
> > ## for convenience
> > mrj <- data2$mrjdate[2]
> > oid <- data2$oiddate[2]
> > mode(mrj)
> [1] "numeric"
> > mode(oid)
> [1] "numeric"
> > str(mrj)
>  Date[1:1], format: NA
> > str(oid)
>  Date[1:1], format: NA
> > class(mrj)
> [1] "Date"
> > class(oid)
> [1] "Date"
> > ## But note:
> > identical(mrj, oid)
> [1] FALSE
> > all.equal(mrj, oid)
> [1] "'is.NA' value mismatch: 0 in current 1 in target"
> ## functioning code
> data2$mrjdate[2]
> data2$oiddate[2]
> mrj <- data2$mrjdate[2]
> oid <- data2$oiddate[2]
> mode(mrj)
> mode(oid)
> str(mrj)
> str(oid)
> class(mrj)
> class(oid)
> # But note:
> identical(mrj, oid)
> all.equal(mrj, oid)
>
> ## This ugly solution does not have the problem.
> > data3 <- data1
> > data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
> +   if (all(is.na(unlist(data1[row, -1])))) {
> +     max_d <- NA
> +   } else {
> +     max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
> +   }
> +   max_d}),
> +   origin = "1970-01-01")
> >
> > range(data3$mrjdate[complete.cases(data3$mrjdate)])
> [1] "2004-11-04" "2009-10-24"
> > range(data3$cocdate[complete.cases(data3$cocdate)])
> [1] "2005-08-10" "2011-10-05"
> > range(data3$inhdate[complete.cases(data3$inhdate)])
> [1] "2005-07-07" "2011-10-13"
> > range(data3$haldate[complete.cases(data3$haldate)])
> [1] "2007-11-07" "2011-11-04"
> > range(data3$oiddate[complete.cases(data3$oiddate)])
> [1] "2006-09-01" "2011-11-04"
> >
> Working code below.
>
> data3 <- data1
> data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
>   if (all(is.na(unlist(data1[row, -1])))) {
>     max_d <- NA
>   } else {
>     max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
>   }
>   max_d}),
>   origin = "1970-01-01")
>
> range(data3$mrjdate[complete.cases(data3$mrjdate)])
> range(data3$cocdate[complete.cases(data3$cocdate)])
> range(data3$inhdate[complete.cases(data3$inhdate)])
> range(data3$haldate[complete.cases(data3$haldate)])
> range(data3$oiddate[complete.cases(data3$oiddate)])
>
>
> On Nov 10, 2014, at 10:10 AM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
>
> > Hello,
> >
> > The range() with complete.cases() removes NA's for the date variables
> that are read from a data frame.  However, the issue is that the same
> function does not remove NA's for the other date variable that is created
> using the dplyr/mutate().  The console and the reproducible example are
> given below. Any advice how to resolve this issue would be appreciated.
> >
> > Thanks,
> >
> > Pradip Muhuri
> >
> >
> > #################  cut and pasted from the R console ####################
> >
> > id    mrjdate    cocdate    inhdate    haldate    oiddate
> > 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> > 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> > 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> > 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> > 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> > 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> > 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
> >>
> >> # range of dates
> >>
> >> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> > [1] "2004-11-04" "2009-10-24"
> >> range(data2$cocdate[complete.cases(data2$cocdate)])
> > [1] "2005-08-10" "2011-10-05"
> >> range(data2$inhdate[complete.cases(data2$inhdate)])
> > [1] "2005-07-07" "2011-10-13"
> >> range(data2$haldate[complete.cases(data2$haldate)])
> > [1] "2007-11-07" "2011-11-04"
> >> range(data2$oiddate[complete.cases(data2$oiddate)])
> > [1] NA           "2011-11-04"
> >
> >
> > ################  reproducible code #############################
> >
> > library(dplyr)
> > library(lubridate)
> > library(zoo)
> > # data object - description of the
> >
> > temp <- "id  mrjdate cocdate inhdate haldate
> > 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> > 2             NA         NA         NA         NA
> > 3     2009-10-24         NA 2011-10-13         NA
> > 4     2007-10-10         NA         NA         NA
> > 5     2006-09-01 2005-08-10         NA         NA
> > 6     2007-09-04 2011-10-05         NA         NA
> > 7     2005-10-25         NA         NA 2011-11-04"
> >
> > # read the data object
> >
> > data1 <- read.table(textConnection(temp),
> >                    colClasses=c("character", "Date", "Date", "Date",
> "Date"),
> >                    header=TRUE, as.is=TRUE
> >                    )
> >
> >
> > # create a new column
> >
> > data2 <- data1 %>%
> >     rowwise() %>%
> >      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
> >
>  na.rm=TRUE), origin='1970-01-01'))
> >
> > # print records
> >
> > print (data2)
> >
> > # range of dates
> >
> > range(data2$mrjdate[complete.cases(data2$mrjdate)])
> > range(data2$cocdate[complete.cases(data2$cocdate)])
> > range(data2$inhdate[complete.cases(data2$inhdate)])
> > range(data2$haldate[complete.cases(data2$haldate)])
> > range(data2$oiddate[complete.cases(data2$oiddate)])
> >
> >
> >
> >
> >
> > Pradip K. Muhuri, PhD
> > SAMHSA/CBHSQ
> > 1 Choke Cherry Road, Room 2-1071
> > Rockville, MD 20857
> > Tel: 240-276-1070
> > Fax: 240-276-1260
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
> NOTICE:  This E-Mail (including attachments) is confidential and may be
> legally privileged.  It is covered by the Electronic Communications Privacy
> Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are
> hereby notified that any retention, dissemination, distribution or copying
> of this communication is strictly prohibited.  Please reply to the sender
> that you have received this message in error, then delete it.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Pradip.Muhuri at samhsa.hhs.gov  Mon Nov 10 19:36:43 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Mon, 10 Nov 2014 18:36:43 +0000
Subject: [R] range () does not remove NA's with complete.cases() for
 dates (dplyr/mutate)
In-Reply-To: <CAF8bMcaFbPooet=LYwR-oadVTCQhbMvmCUXMqATYi32KbtwZeA@mail.gmail.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5EE75@pl-emsmb11>
	<4170D4A5-A345-4E31-958A-44FEC62A00FD@TxBiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5EEEC@pl-emsmb11>
	<CAF8bMcaFbPooet=LYwR-oadVTCQhbMvmCUXMqATYi32KbtwZeA@mail.gmail.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F5EF17@pl-emsmb11>

Hi Bill and mark,

I meant the mutate does NOT set the NA value ? sorry for the confusion.  Thank you for your clarifications that this may not be mutate()?s problem.  This thread is now closed from my end.

Thanks,

Pradip

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Monday, November 10, 2014 1:30 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: Mark Sharp; r-help at r-project.org
Subject: Re: [R] range () does not remove NA's with complete.cases() for dates (dplyr/mutate)

> Would you like to bring to Hadley's attention that mutate does
> set the NA value for the new column?

This may not be mutate()'s problem.

The Date class is messed up with regard to NA's and Inf's.  E.g., what gets printed as NA does not correspond to what is.na<http://is.na>() returns and its range() method does not appear to pass the finite=TRUE argument to range.default:
  > d <- as.Date(c("2014-10-31", c("2014-11-10")))
  > d1 <- range(d[0], finite=TRUE)
  Warning messages:
  1: In min.default(numeric(0), na.rm = FALSE) :
    no non-missing arguments to min; returning Inf
  2: In max.default(numeric(0), na.rm = FALSE) :
    no non-missing arguments to max; returning -Inf
  > d1
  [1] NA NA
  > is.na<http://is.na>(d1)
  [1] FALSE FALSE
  > dput(d1)
  structure(c(Inf, -Inf), class = "Date")
  > range(c(d1, d), finite=TRUE)
  [1] NA NA
  > range(c(d1, d), finite=TRUE, na.rm=TRUE)
  [1] NA NA



Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Mon, Nov 10, 2014 at 10:09 AM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov<mailto:Pradip.Muhuri at samhsa.hhs.gov>> wrote:
Mark,

Thank you very much for further looking into this issue.  So, the "ugly" solution is better!  Would you like to bring to Hadley's attention that mutate does set the NA value for the new column?

Regards,

Pradip

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070<tel:240-276-1070>
Fax: 240-276-1260<tel:240-276-1260>


-----Original Message-----
From: Mark Sharp [mailto:msharp at TxBiomed.org<mailto:msharp at TxBiomed.org>]
Sent: Monday, November 10, 2014 12:23 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] range () does not remove NA's with complete.cases() for dates (dplyr/mutate)
Pradip,

For some reason mutate is not setting the is.NA value for the new column. Note the output below using your data structures.

> ## It looks at first as if the second element of both columns are NA.
> data2$mrjdate[2]
[1] NA
> data2$oiddate[2]
[1] NA
> ## for convenience
> mrj <- data2$mrjdate[2]
> oid <- data2$oiddate[2]
> mode(mrj)
[1] "numeric"
> mode(oid)
[1] "numeric"
> str(mrj)
 Date[1:1], format: NA
> str(oid)
 Date[1:1], format: NA
> class(mrj)
[1] "Date"
> class(oid)
[1] "Date"
> ## But note:
> identical(mrj, oid)
[1] FALSE
> all.equal(mrj, oid)
[1] "'is.NA' value mismatch: 0 in current 1 in target"
## functioning code
data2$mrjdate[2]
data2$oiddate[2]
mrj <- data2$mrjdate[2]
oid <- data2$oiddate[2]
mode(mrj)
mode(oid)
str(mrj)
str(oid)
class(mrj)
class(oid)
# But note:
identical(mrj, oid)
all.equal(mrj, oid)

## This ugly solution does not have the problem.
> data3 <- data1
> data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
+   if (all(is.na<http://is.na>(unlist(data1[row, -1])))) {
+     max_d <- NA
+   } else {
+     max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
+   }
+   max_d}),
+   origin = "1970-01-01")
>
> range(data3$mrjdate[complete.cases(data3$mrjdate)])
[1] "2004-11-04" "2009-10-24"
> range(data3$cocdate[complete.cases(data3$cocdate)])
[1] "2005-08-10" "2011-10-05"
> range(data3$inhdate[complete.cases(data3$inhdate)])
[1] "2005-07-07" "2011-10-13"
> range(data3$haldate[complete.cases(data3$haldate)])
[1] "2007-11-07" "2011-11-04"
> range(data3$oiddate[complete.cases(data3$oiddate)])
[1] "2006-09-01" "2011-11-04"
>
Working code below.

data3 <- data1
data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
  if (all(is.na<http://is.na>(unlist(data1[row, -1])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

range(data3$mrjdate[complete.cases(data3$mrjdate)])
range(data3$cocdate[complete.cases(data3$cocdate)])
range(data3$inhdate[complete.cases(data3$inhdate)])
range(data3$haldate[complete.cases(data3$haldate)])
range(data3$oiddate[complete.cases(data3$oiddate)])


On Nov 10, 2014, at 10:10 AM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:

> Hello,
>
> The range() with complete.cases() removes NA's for the date variables that are read from a data frame.  However, the issue is that the same function does not remove NA's for the other date variable that is created using the dplyr/mutate().  The console and the reproducible example are given below. Any advice how to resolve this issue would be appreciated.
>
> Thanks,
>
> Pradip Muhuri
>
>
> #################  cut and pasted from the R console ####################
>
> id    mrjdate    cocdate    inhdate    haldate    oiddate
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>>
>> # range of dates
>>
>> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> [1] "2004-11-04" "2009-10-24"
>> range(data2$cocdate[complete.cases(data2$cocdate)])
> [1] "2005-08-10" "2011-10-05"
>> range(data2$inhdate[complete.cases(data2$inhdate)])
> [1] "2005-07-07" "2011-10-13"
>> range(data2$haldate[complete.cases(data2$haldate)])
> [1] "2007-11-07" "2011-11-04"
>> range(data2$oiddate[complete.cases(data2$oiddate)])
> [1] NA           "2011-11-04"
>
>
> ################  reproducible code #############################
>
> library(dplyr)
> library(lubridate)
> library(zoo)
> # data object - description of the
>
> temp <- "id  mrjdate cocdate inhdate haldate
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> 2             NA         NA         NA         NA
> 3     2009-10-24         NA 2011-10-13         NA
> 4     2007-10-10         NA         NA         NA
> 5     2006-09-01 2005-08-10         NA         NA
> 6     2007-09-04 2011-10-05         NA         NA
> 7     2005-10-25         NA         NA 2011-11-04"
>
> # read the data object
>
> data1 <- read.table(textConnection(temp),
>                    colClasses=c("character", "Date", "Date", "Date", "Date"),
>                    header=TRUE, as.is<http://as.is>=TRUE
>                    )
>
>
> # create a new column
>
> data2 <- data1 %>%
>     rowwise() %>%
>      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>                                                               na.rm=TRUE), origin='1970-01-01'))
>
> # print records
>
> print (data2)
>
> # range of dates
>
> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> range(data2$cocdate[complete.cases(data2$cocdate)])
> range(data2$inhdate[complete.cases(data2$inhdate)])
> range(data2$haldate[complete.cases(data2$haldate)])
> range(data2$oiddate[complete.cases(data2$oiddate)])
>
>
>
>
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From istazahn at gmail.com  Mon Nov 10 19:36:31 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 10 Nov 2014 13:36:31 -0500
Subject: [R] Remove from listserv
In-Reply-To: <CAHKoFnrPwVyjrNK708L-LnLxY1GUUikvhtQTXYMkDKrV3rGnpw@mail.gmail.com>
References: <CAHKoFnrPwVyjrNK708L-LnLxY1GUUikvhtQTXYMkDKrV3rGnpw@mail.gmail.com>
Message-ID: <CA+vqiLGom4SWC54j5QG47DZ1c81XJ-O0FY915Lz6urksQXGGiw@mail.gmail.com>

Hi Emma,

(Un)Subscription is self-service at the link in the bottom of this
(and every) message on R-help, i.e.,
https://stat.ethz.ch/mailman/listinfo/r-help

Best,
Ista

On Mon, Nov 10, 2014 at 1:18 PM, Emma Gerald Boyer
<emma.gerald at gmail.com> wrote:
> Hello
>
> Is there any way that I can be removed from the list-serv?  Let me know if
> I need to do anything.
>
> Thanks so much
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Mon Nov 10 19:37:45 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 10 Nov 2014 19:37:45 +0100
Subject: [R] Remove from listserv
In-Reply-To: <CAHKoFnrPwVyjrNK708L-LnLxY1GUUikvhtQTXYMkDKrV3rGnpw@mail.gmail.com>
References: <CAHKoFnrPwVyjrNK708L-LnLxY1GUUikvhtQTXYMkDKrV3rGnpw@mail.gmail.com>
Message-ID: <546105F9.30901@statistik.tu-dortmund.de>



On 10.11.2014 19:18, Emma Gerald Boyer wrote:
> Hello
>
> Is there any way that I can be removed from the list-serv?  Let me know if
> I need to do anything.
>
> Thanks so much
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


Read the message at the bottom ...

Best,
Uwe Ligges


From bhh at xs4all.nl  Mon Nov 10 19:43:05 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 10 Nov 2014 19:43:05 +0100
Subject: [R] Remove from listserv
In-Reply-To: <CAHKoFnrPwVyjrNK708L-LnLxY1GUUikvhtQTXYMkDKrV3rGnpw@mail.gmail.com>
References: <CAHKoFnrPwVyjrNK708L-LnLxY1GUUikvhtQTXYMkDKrV3rGnpw@mail.gmail.com>
Message-ID: <0AAB4290-6FC2-4497-B25C-8C428B9D916E@xs4all.nl>


On 10-11-2014, at 19:18, Emma Gerald Boyer <emma.gerald at gmail.com> wrote:

> Hello
> 
> Is there any way that I can be removed from the list-serv?  Let me know if
> I need to do anything.
> 

You can find this in the section Mailing Lists on the R project page.
Click on Mailing Lists and then select web interface in the section for R-help. You should be sent to:

http://stat.ethz.ch/mailman/listinfo/r-help

Goto the bottom of the page.

Berend

> Thanks so much
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.gang.peng at gmail.com  Mon Nov 10 20:35:44 2014
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Mon, 10 Nov 2014 13:35:44 -0600
Subject: [R] Error when install R package in Windows
Message-ID: <CAMjJGR3LE5zSLpkXwoLpohitN1j2dwkYw9bUr1D=W0XYLeRAAw@mail.gmail.com>

Dear all,

I am now writing a R library. After I build it in Windows *R CMD INSTALL
--build --compile-both foo.tar.gz*, I get a file foo.zip. foo.tar.gz is the
source file tarball. When I tried to install the package in R (
*install.packages("foo.zip")*, or choose the zip file from menu
package/install packages), an error occurred:

In read.dcf(file.path(pkgname, "DESCRIPTION"), c("Package", "Type")) :
cannot open compressed file ?/DESCRIPTION', probable reason 'No such
file or directory'

But if I install the package in the console: *R CMD INSTALL foo.zip*, there
is no such problem.

I am working on Windows 7 and R version is 3.1.2.

And there is no problem for Mac OS and Linux.

Thanks,
Gang

	[[alternative HTML version deleted]]


From a.mosnier at gmail.com  Mon Nov 10 21:26:43 2014
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Mon, 10 Nov 2014 15:26:43 -0500
Subject: [R] Submodel selection using dredge and gam (mgcv)
Message-ID: <CANkFkEftjMT1QNihMQsSFMpwdGTwY3gSFdO+4x9+WQbgK2QNig@mail.gmail.com>

Hi,

I want to use dredge to test several gam submodels including interactions.
I tried to find a way in order to keep models with interaction only if the
single variables occurring in the interaction are also included.

i.e.: for
 y~s(x0)+s(x1)+ti(x0, x1)

I want to keep
y ~ s(x0)
y ~ s(x1)
y ~ s(x0) + s(x1)
y ~ s(x0) + s(x1) + ti(x0,x1)

and I want to remove

y ~ s(x0) + ti(x0,x1)
y ~ s(x1) + ti(x0,x1)
y ~ ti(x0,x1)


I know that I should use the "subset" option of the dredge function.
However, I can not find the correct matrix / expression to obtain what I
need !


Here a small example.

################

# Create some data (use mgcv example)
library(mgcv)
set.seed(2)
dat <- gamSim(1,n=400,dist="normal",scale=2)

# Create the global gam model
# Here a model with interaction. Note the use of ti()
bt <- gam(y~s(x0)+s(x1)+s(x2)+s(x3)+ti(x1,x2), data=dat,method="ML")

# Use dredge to test sub-models
library(MuMIn)
print(modstab <- dredge(bt))

# Here the 11th model include the interaction but do not include the single
variables x1 and x2
# ... I want to avoid that kind of model.
get.models(modstab, subset = 11)

################


Any help would be appreciated !

Arnaud

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Mon Nov 10 22:15:29 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 10 Nov 2014 15:15:29 -0600
Subject: [R] 1. What function to use to read all the files in a
 directory to a vector in R code? 2. What function to use to coerce
 character string into numeric?
In-Reply-To: <666010385.273467.1415625130588.JavaMail.yahoo@jws10681.mail.bf1.yahoo.com>
References: <666010385.273467.1415625130588.JavaMail.yahoo@jws10681.mail.bf1.yahoo.com>
Message-ID: <CAAJSdjh+hu7NOJT2-Sh7GTS1GYSVAoyzom3Hqn-1xG_H7Ym7_w@mail.gmail.com>

On Mon, Nov 10, 2014 at 7:12 AM, Aditya Singh <aps6dl at yahoo.com> wrote:

> Hi,
> I have 2 queries:
> 1. What function to use to read all the files in a directory to a vector
> in R code?
> 2. What function to use to coerce character string into numeric?
> As a help to others, I figured out to use setwd("C:/....") to set working
> directory!
> Aditya
>

?First, please don't post in HTML. It is contrary to forum policy. Thanks.

Answer 1: you can get a list of the names of all the files using the
list.files() function. Do a ?list.files for more information.

Answer 2: If I understand your question correctly, then I'd use
as.numeric() .

Suggestion 1: Get & read a good book on R programming. These were very
basic questions. I'd strongly suggest "Advanced R" by Hadley Wickham. You
can order if Amazon.com, or read it (for free!) here:
http://adv-r.had.co.nz/
?

?Another good one is "The Art of R Programming" by Norman Matloff. This
later one is what I used, but that's mainly because Hadley's book hadn't
been written (or maybe published) when I was first learning R. ?

?Suggestion 2: If you haven't already, I would strongly recommend getting &
installing RStudio. It is free (as in beer, which is a curious phrase
because beer isn't usually free). http://www.rstudio.com ?

-- 
The temperature of the aqueous content of an unremittingly ogled
culinary vessel will not achieve 100 degrees on the Celsius scale.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From marco.scutari at gmail.com  Tue Nov 11 00:28:49 2014
From: marco.scutari at gmail.com (Marco Scutari)
Date: Mon, 10 Nov 2014 23:28:49 +0000
Subject: [R] Strange error while passing string as an argument to the
 function in bnlearn package
In-Reply-To: <CAJ4nbUq=jEWy6L3TWdS6vSO2WUJOCGj9pRRWJ=cPysU4FpCmvg@mail.gmail.com>
References: <CAJ4nbUq=jEWy6L3TWdS6vSO2WUJOCGj9pRRWJ=cPysU4FpCmvg@mail.gmail.com>
Message-ID: <CA+RJqXVCO3X4-ED78qYCwunEKQmfRuBOB9GH9++qPnuYYu4mcg@mail.gmail.com>

Hi Alexandr,

On 10 November 2014 17:46, Alexandr M <rus314 at gmail.com> wrote:
> I am working with the package bnlear, but, probably, error is caused not by
> the package itself.

Logic sampling in cpquery() relies on handling unevaluated
expressions, so it is a tad fragile in any complex setting (inside
loops and function calls, for example). On its own, the
eval(parse(...)) trick works if you do it in the global environment,
or in relatively simple scripts.

For the simple query you are trying to do, just use likelihood weighting:

prob.s = cpquery(fitted1,
                             event=eval(parse(text="(M=='s')")),
                             evidence=list(lag1.M1='s'),
                             method = "lw")

passing str2 as a list.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom


From rus314 at gmail.com  Tue Nov 11 01:10:01 2014
From: rus314 at gmail.com (Alexandr M)
Date: Tue, 11 Nov 2014 00:10:01 +0000
Subject: [R] Strange error while passing string as an argument to the
 function in bnlearn package
In-Reply-To: <CA+RJqXVCO3X4-ED78qYCwunEKQmfRuBOB9GH9++qPnuYYu4mcg@mail.gmail.com>
References: <CAJ4nbUq=jEWy6L3TWdS6vSO2WUJOCGj9pRRWJ=cPysU4FpCmvg@mail.gmail.com>
	<CA+RJqXVCO3X4-ED78qYCwunEKQmfRuBOB9GH9++qPnuYYu4mcg@mail.gmail.com>
Message-ID: <CAJ4nbUqrbo_e0VJWOGwh0C-bFcHzHRAr8u74CW+yK8DHQ3A=uA@mail.gmail.com>

Hi Marco,

Thanks for your reply!

Logic sampling in cpquery() relies on handling unevaluated
> expressions, so it is a tad fragile in any complex setting (inside
> loops and function calls, for example).


Actually I am doing it inside the loop.
Inside the loop I determine important features and form expressions
dynamically in the string format:

for( i in 1:N )
{
...

varnames = names(newrow) # new piece of data in a form of the row with
variables names

# like in the documentation: event parameter
str1 = paste("(", var[1] , "=='", as.character(newrow[1, 1]), "')", sep =
"")

# evidence parameter:
str2 = paste("(", var[-1], "=='", sapply(newrow[1,-1], as.character), "')",
sep = "", collapse = " & ")

# estimate conditional probability
cpquery(fitted.model,
    event       = eval(parse(text=str1)),
    evidence = eval(parse(text=str2)))
...
}

For the simple query you are trying to do, just use likelihood weighting


Sorry that I formulated my question not very accurately.
I form expressions/(logic conditions for parameters evidence and event)
dynamically inside the loop and they are sometimes quite long.


--
Best regards,
Alexandr

On 10 November 2014 23:28, Marco Scutari <marco.scutari at gmail.com> wrote:

> Hi Alexandr,
>
> On 10 November 2014 17:46, Alexandr M <rus314 at gmail.com> wrote:
> > I am working with the package bnlear, but, probably, error is caused not
> by
> > the package itself.
>
> Logic sampling in cpquery() relies on handling unevaluated
> expressions, so it is a tad fragile in any complex setting (inside
> loops and function calls, for example). On its own, the
> eval(parse(...)) trick works if you do it in the global environment,
> or in relatively simple scripts.
>
> For the simple query you are trying to do, just use likelihood weighting:
>
> prob.s = cpquery(fitted1,
>                              event=eval(parse(text="(M=='s')")),
>                              evidence=list(lag1.M1='s'),
>                              method = "lw")
>
> passing str2 as a list.
>
> Cheers,
>     Marco
>
> --
> Marco Scutari, Ph.D.
> Lecturer in Statistics, Department of Statistics
> University of Oxford, United Kingdom
>



-- 
Best regards,
Alexander Maslov

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Nov 11 02:26:16 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 10 Nov 2014 20:26:16 -0500
Subject: [R] 1. What function to use to read all the files in a
 directory to a vector in R code? 2. What function to use to coerce
 character string into numeric?
In-Reply-To: <CAAJSdjh+hu7NOJT2-Sh7GTS1GYSVAoyzom3Hqn-1xG_H7Ym7_w@mail.gmail.com>
References: <666010385.273467.1415625130588.JavaMail.yahoo@jws10681.mail.bf1.yahoo.com>
	<CAAJSdjh+hu7NOJT2-Sh7GTS1GYSVAoyzom3Hqn-1xG_H7Ym7_w@mail.gmail.com>
Message-ID: <CA+vqiLGdx39qUcXvLkdfnooq+Fk_0-ovg_0QRaA8C4OQpZz06w@mail.gmail.com>

On Mon, Nov 10, 2014 at 4:15 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Mon, Nov 10, 2014 at 7:12 AM, Aditya Singh <aps6dl at yahoo.com> wrote:

[snip]

> Suggestion 2: If you haven't already, I would strongly recommend getting &
> installing RStudio. It is free (as in beer, which is a curious phrase
> because beer isn't usually free). http://www.rstudio.com

Rstudio is free "as in free speech" as well, as far as I can tell.
Though there is a non-free (in both senses) version as well.

Best,
Ista

>
> --
> The temperature of the aqueous content of an unremittingly ogled
> culinary vessel will not achieve 100 degrees on the Celsius scale.
>
> Maranatha! <><
> John McKown
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmkarcich at msn.com  Tue Nov 11 01:10:39 2014
From: rmkarcich at msn.com (RICHARD M KARCICH)
Date: Tue, 11 Nov 2014 00:10:39 +0000
Subject: [R] upgrade from 3.1.1 > 3.1.2
Message-ID: <BLU168-W13655EF66F20C97286A2D49A3810@phx.gbl>

in 3.1.1, i had a few small scripts like the one attached -- 
installed 3.1.2, then from the R-console, i chg dir and can successfully source() the mycode.R --
however, 
> getwd()[1] "C:/RProgramming"> dir()[1] "forCondition.R"  "ifCondition.R"   "mycode.R"        "nestedForLoop.R"[5] "whileLoop.R"    > source ("mycode.R")> ls()[1] "myfunction" "second"    > second(4)Error in second(4) : unused argument (4)
why can't 'second' run...?  thx in advance...
-r

 		 	   		  

From dwinsemius at comcast.net  Tue Nov 11 05:45:31 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 10 Nov 2014 20:45:31 -0800
Subject: [R] upgrade from 3.1.1 > 3.1.2
In-Reply-To: <BLU168-W13655EF66F20C97286A2D49A3810@phx.gbl>
References: <BLU168-W13655EF66F20C97286A2D49A3810@phx.gbl>
Message-ID: <A876B0C8-C7FB-43C5-B37E-B662714967F4@comcast.net>


On Nov 10, 2014, at 4:10 PM, RICHARD M KARCICH wrote:

> in 3.1.1, i had a few small scripts like the one attached -- 
> installed 3.1.2, then from the R-console, i chg dir and can successfully source() the mycode.R --
> however, 
>> getwd()[1] "C:/RProgramming"> dir()[1] "forCondition.R"  "ifCondition.R"   "mycode.R"        "nestedForLoop.R"[5] "whileLoop.R"    > source ("mycode.R")> ls()[1] "myfunction" "second"    > second(4)Error in second(4) : unused argument (4)

I'm guessing this is supposed to appear as:

getwd()[1] "C:/RProgramming"
> dir()[1] "forCondition.R"  "ifCondition.R"   "mycode.R"        "nestedForLoop.R"
[5] "whileLoop.R"    
> source ("mycode.R")
> ls()
[1] "myfunction" "second"    
> second(4) 
Error in second(4) : unused argument (4)

R seems to be saying that the `second` function does not have any arguments in its formals. If you think this error message is not describing the reality of your code, then why did you not provide the code????

> why can't 'second' run...?  thx in advance...

R told you. You gave it too many arguments. I seriously doubt this has anything to do with the upgrade. This is not a behavior that changed in R 3.1.2

> -r


-- 
David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Tue Nov 11 06:01:19 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 10 Nov 2014 21:01:19 -0800
Subject: [R] upgrade from 3.1.1 > 3.1.2
In-Reply-To: <BLU168-W13655EF66F20C97286A2D49A3810@phx.gbl>
References: <BLU168-W13655EF66F20C97286A2D49A3810@phx.gbl>
Message-ID: <E89A6E69-29C2-4940-B00A-D0D831384630@dcn.davis.CA.us>

Mindreading option not enabled. Please make your example reproducible by including all code necessary for us to reproduce your problem starting from an empty R environment.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 10, 2014 4:10:39 PM PST, RICHARD M KARCICH <rmkarcich at msn.com> wrote:
>in 3.1.1, i had a few small scripts like the one attached -- 
>installed 3.1.2, then from the R-console, i chg dir and can
>successfully source() the mycode.R --
>however, 
>> getwd()[1] "C:/RProgramming"> dir()[1] "forCondition.R" 
>"ifCondition.R"   "mycode.R"        "nestedForLoop.R"[5] "whileLoop.R" 
>> source ("mycode.R")> ls()[1] "myfunction" "second"    >
>second(4)Error in second(4) : unused argument (4)
>why can't 'second' run...?  thx in advance...
>-r
>
> 		 	   		  
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kamil.barton at o2.pl  Tue Nov 11 10:11:50 2014
From: kamil.barton at o2.pl (=?UTF-8?B?S2FtaWwgQmFydG/FhA==?=)
Date: Tue, 11 Nov 2014 10:11:50 +0100
Subject: [R] Submodel selection using dredge and gam (mgcv)
In-Reply-To: <CANkFkEftjMT1QNihMQsSFMpwdGTwY3gSFdO+4x9+WQbgK2QNig@mail.gmail.com>
References: <CANkFkEftjMT1QNihMQsSFMpwdGTwY3gSFdO+4x9+WQbgK2QNig@mail.gmail.com>
Message-ID: <5461D2D6.80002@o2.pl>

Hi Arnaud,
your question has in fact nothing to do with gam or model selection. 
What you are asking is: what is the logical expression that yields True 
when AB is False or both A and B are True. Now replace the words with 
operators (!AB | (A & B)) and voil?.

See also:
help("Logic", "base")
fortunes::fortune(350)

best,
kamil


On 2014-11-10 21:26, Arnaud Mosnier wrote:
> Hi,
>
> I want to use dredge to test several gam submodels including interactions.
> I tried to find a way in order to keep models with interaction only if
> the single variables occurring in the interaction are also included.
>
> i.e.: for
>   y~s(x0)+s(x1)+ti(x0, x1)
>
> I want to keep
> y ~ s(x0)
> y ~ s(x1)
> y ~ s(x0) + s(x1)
> y ~ s(x0) + s(x1) + ti(x0,x1)
>
> and I want to remove
>
> y ~ s(x0) + ti(x0,x1)
> y ~ s(x1) + ti(x0,x1)
> y ~ ti(x0,x1)
>
>
> I know that I should use the "subset" option of the dredge function.
> However, I can not find the correct matrix / expression to obtain what I
> need !
>
>
> Here a small example.
>
> ################
>
> # Create some data (use mgcv example)
> library(mgcv)
> set.seed(2)
> dat <- gamSim(1,n=400,dist="normal",scale=2)
>
> # Create the global gam model
> # Here a model with interaction. Note the use of ti()
> bt <- gam(y~s(x0)+s(x1)+s(x2)+s(x3)+ti(x1,x2), data=dat,method="ML")
>
> # Use dredge to test sub-models
> library(MuMIn)
> print(modstab <- dredge(bt))
>
> # Here the 11th model include the interaction but do not include the
> single variables x1 and x2
> # ... I want to avoid that kind of model.
> get.models(modstab, subset = 11)
>
> ################
>
>
> Any help would be appreciated !
>
> Arnaud


From aps6dl at yahoo.com  Tue Nov 11 10:05:54 2014
From: aps6dl at yahoo.com (Aditya Singh)
Date: Tue, 11 Nov 2014 09:05:54 +0000 (UTC)
Subject: [R] Error: (list) object cannot be coerced to type double;
 on running the following code in R ver 3.1.2
Message-ID: <2117106709.487786.1415696754905.JavaMail.yahoo@jws10625.mail.bf1.yahoo.com>

setwd("C:/Documents and Settings/Administrator/Desktop/Coursera/specdata/specdata")temp=list.files(pattern="*.csv")myfiles=lapply(temp,read.delim)summk=0nummk=0for (i in 1:10) {? vb=data.frame(myfiles[i])? vbm=as.double(vb)? summk=sum(vbm[,2])? nummk=length(vbm[,2]) - sum(is.na(vbm[,2]))}
Aditya

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Tue Nov 11 10:36:09 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 11 Nov 2014 10:36:09 +0100
Subject: [R] 1. What function to use to read all the files in a directory to
 a vector in R code? 2. What function to use to coerce character string into
 numeric?
In-Reply-To: <CAAJSdjh+hu7NOJT2-Sh7GTS1GYSVAoyzom3Hqn-1xG_H7Ym7_w@mail.gmail.com>
References: <666010385.273467.1415625130588.JavaMail.yahoo@jws10681.mail.bf1.yahoo.com>
	<CAAJSdjh+hu7NOJT2-Sh7GTS1GYSVAoyzom3Hqn-1xG_H7Ym7_w@mail.gmail.com>
Message-ID: <5461D889.9010700@yahoo.fr>

Le 10/11/2014 22:15, John McKown a ?crit :
> On Mon, Nov 10, 2014 at 7:12 AM, Aditya Singh <aps6dl at yahoo.com> wrote:
>
>> Hi,
>> I have 2 queries:
>> 1. What function to use to read all the files in a directory to a vector
>> in R code?

In the package phenology, a function read_folder can be used to read all 
the files at one time into a list. After you can use unlist():

Description
To create a list, the syntax is

datalist<-read_folder(folder=".", read=read.delim, header=FALSE)

Return NULL with a warning if the folder does not exist or is empty. The 
names of the elements of the list are the filenames.

Usage
read_folder(folder = try(file.choose(), silent = TRUE), wildcard = 
"*.*", read = read.delim, ...)

Arguments
folder Where to search for files; can be or a file path or a folder path
wildcard Define which files are to be read (examples: "*.*", "*.xls", 
"essai*.txt")
read Function used to read file. Ex: read.delim or read.xls from gdata 
package
... Parameters send to the read function

Sincerely,

Marc Girondot


>> 2. What function to use to coerce character string into numeric?
>> As a help to others, I figured out to use setwd("C:/....") to set working
>> directory!
>> Aditya
>>
>
> ?First, please don't post in HTML. It is contrary to forum policy. Thanks.
>
> Answer 1: you can get a list of the names of all the files using the
> list.files() function. Do a ?list.files for more information.
>
> Answer 2: If I understand your question correctly, then I'd use
> as.numeric() .
>
> Suggestion 1: Get & read a good book on R programming. These were very
> basic questions. I'd strongly suggest "Advanced R" by Hadley Wickham. You
> can order if Amazon.com, or read it (for free!) here:
> http://adv-r.had.co.nz/
> ?
>
> ?Another good one is "The Art of R Programming" by Norman Matloff. This
> later one is what I used, but that's mainly because Hadley's book hadn't
> been written (or maybe published) when I was first learning R. ?
>
> ?Suggestion 2: If you haven't already, I would strongly recommend getting &
> installing RStudio. It is free (as in beer, which is a curious phrase
> because beer isn't usually free). http://www.rstudio.com ?
>


From ntfredo at gmail.com  Tue Nov 11 12:25:58 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 11 Nov 2014 14:25:58 +0300
Subject: [R] sweave package for R version 3.02
Message-ID: <CAGh51gQWV1TMUAks4mzC=kjsSHnqcDXw2LEdptTM6e-vrHpwiQ@mail.gmail.com>

Hi All,

I would like to install the package "sweave" but got the following warning:

> install.packages("sweave")
Installing package into ?/home/fredo/R/x86_64-pc-linux-gnu-library/3.0?
(as ?lib? is unspecified)
Warning in install.packages :
  package ?sweave? is not available (for R version 3.0.2)

I tryied to download it's zip file but not get it.

Anyone help me on how I can do it. Thanks

Regrads,
Frederic.



Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Nov 11 13:19:37 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 11 Nov 2014 06:19:37 -0600
Subject: [R] sweave package for R version 3.02
In-Reply-To: <CAGh51gQWV1TMUAks4mzC=kjsSHnqcDXw2LEdptTM6e-vrHpwiQ@mail.gmail.com>
References: <CAGh51gQWV1TMUAks4mzC=kjsSHnqcDXw2LEdptTM6e-vrHpwiQ@mail.gmail.com>
Message-ID: <CF256E33-F97A-495A-B221-144239E7B448@me.com>


> On Nov 11, 2014, at 5:25 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> 
> Hi All,
> 
> I would like to install the package "sweave" but got the following warning:
> 
>> install.packages("sweave")
> Installing package into ?/home/fredo/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> Warning in install.packages :
>  package ?sweave? is not available (for R version 3.0.2)
> 
> I tryied to download it's zip file but not get it.
> 
> Anyone help me on how I can do it. Thanks
> 
> Regrads,
> Frederic.


Sweave is part of the 'utils' package, which is a part of base R and does not need to be installed, it already is.

BTW, 3.1.2 is the current version of R. 3.0.2 is over a year old already.

Regards,

Marc Schwartz


From murdoch.duncan at gmail.com  Tue Nov 11 13:50:38 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 11 Nov 2014 07:50:38 -0500
Subject: [R] sweave package for R version 3.02
In-Reply-To: <CAGh51gQWV1TMUAks4mzC=kjsSHnqcDXw2LEdptTM6e-vrHpwiQ@mail.gmail.com>
References: <CAGh51gQWV1TMUAks4mzC=kjsSHnqcDXw2LEdptTM6e-vrHpwiQ@mail.gmail.com>
Message-ID: <5462061E.8010903@gmail.com>

On 11/11/2014, 6:25 AM, Frederic Ntirenganya wrote:
> Hi All,
> 
> I would like to install the package "sweave" but got the following warning:
> 
>> install.packages("sweave")
> Installing package into ?/home/fredo/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> Warning in install.packages :
>   package ?sweave? is not available (for R version 3.0.2)
> 
> I tryied to download it's zip file but not get it.
> 
> Anyone help me on how I can do it. Thanks

As far as I know, there is no "sweave" package.  "Sweave" is a function
in the utils package that comes with R.

Duncan Murdoch


From ntfredo at gmail.com  Tue Nov 11 14:08:05 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 11 Nov 2014 16:08:05 +0300
Subject: [R] sweave package for R version 3.02
In-Reply-To: <5462061E.8010903@gmail.com>
References: <CAGh51gQWV1TMUAks4mzC=kjsSHnqcDXw2LEdptTM6e-vrHpwiQ@mail.gmail.com>
	<5462061E.8010903@gmail.com>
Message-ID: <CAGh51gR7kXAc_fEUyy=+6gy6=CHaD01N=Xa+_rOesmQrAbjf2g@mail.gmail.com>

Thanks all for the help.

Now I want to use it and I am getting this error:

> \documentclass[9pt,a4paper]{article}
Error: unexpected input in "\"
> \usepackage{amsmath}
Error: unexpected input in "\"
> \usepackage{booktabs}
Error: unexpected input in "\"
> \usepackage{adjustbox}
Error: unexpected input in "\"
> \usepackage{listings}
Error: unexpected input in "\"

 I am using ubuntu 14.04.

I don't understand the input it is talking about.



Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Nov 11, 2014 at 3:50 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 11/11/2014, 6:25 AM, Frederic Ntirenganya wrote:
> > Hi All,
> >
> > I would like to install the package "sweave" but got the following
> warning:
> >
> >> install.packages("sweave")
> > Installing package into ?/home/fredo/R/x86_64-pc-linux-gnu-library/3.0?
> > (as ?lib? is unspecified)
> > Warning in install.packages :
> >   package ?sweave? is not available (for R version 3.0.2)
> >
> > I tryied to download it's zip file but not get it.
> >
> > Anyone help me on how I can do it. Thanks
>
> As far as I know, there is no "sweave" package.  "Sweave" is a function
> in the utils package that comes with R.
>
> Duncan Murdoch
>
>

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Tue Nov 11 14:41:44 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 11 Nov 2014 16:41:44 +0300
Subject: [R] sweave package for R version 3.02
In-Reply-To: <CAGh51gR7kXAc_fEUyy=+6gy6=CHaD01N=Xa+_rOesmQrAbjf2g@mail.gmail.com>
References: <CAGh51gQWV1TMUAks4mzC=kjsSHnqcDXw2LEdptTM6e-vrHpwiQ@mail.gmail.com>
	<5462061E.8010903@gmail.com>
	<CAGh51gR7kXAc_fEUyy=+6gy6=CHaD01N=Xa+_rOesmQrAbjf2g@mail.gmail.com>
Message-ID: <CAGh51gSJXjR11ErpZNg92LasKL4FJhv6uYmPt9QVBKKU4GMA4A@mail.gmail.com>

I got it. I should use compile not run option.

Thanks All.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Nov 11, 2014 at 4:08 PM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

> Thanks all for the help.
>
> Now I want to use it and I am getting this error:
>
> > \documentclass[9pt,a4paper]{article}
> Error: unexpected input in "\"
> > \usepackage{amsmath}
> Error: unexpected input in "\"
> > \usepackage{booktabs}
> Error: unexpected input in "\"
> > \usepackage{adjustbox}
> Error: unexpected input in "\"
> > \usepackage{listings}
> Error: unexpected input in "\"
>
>  I am using ubuntu 14.04.
>
> I don't understand the input it is talking about.
>
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Nov 11, 2014 at 3:50 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 11/11/2014, 6:25 AM, Frederic Ntirenganya wrote:
>> > Hi All,
>> >
>> > I would like to install the package "sweave" but got the following
>> warning:
>> >
>> >> install.packages("sweave")
>> > Installing package into ?/home/fredo/R/x86_64-pc-linux-gnu-library/3.0?
>> > (as ?lib? is unspecified)
>> > Warning in install.packages :
>> >   package ?sweave? is not available (for R version 3.0.2)
>> >
>> > I tryied to download it's zip file but not get it.
>> >
>> > Anyone help me on how I can do it. Thanks
>>
>> As far as I know, there is no "sweave" package.  "Sweave" is a function
>> in the utils package that comes with R.
>>
>> Duncan Murdoch
>>
>>
>

	[[alternative HTML version deleted]]


From llukas.kkohl at gmail.com  Tue Nov 11 15:58:41 2014
From: llukas.kkohl at gmail.com (Lukas Kohl)
Date: Tue, 11 Nov 2014 11:28:41 -0330
Subject: [R] problem with vegan function rda()
Message-ID: <CAP1mp3bjampC17M1NbWvaayJzYDQU5yyr+0mszR3856SkJ_8KQ@mail.gmail.com>

Hello R-list

Maybe someone knows what's going on here.

I'm trying to re-run a script I wrote earlier this year using the function
rda() in the vegan package. The script run fine back then, and I did not
change the dataset, so I was wandering whether there's some problem in a
updated version of the package (I re-installed R + all packages since then).

Thanks for any advice,
Lukas Kohl

--

So here's the output I get:

> rda(rel)
Call:
rda(X = rel)

Regularization parameters:
NULL

Prior probabilities of groups:
NULL

Misclassification rate:
       apparent:  %
Warning message:
In is.na(x$error.rate[1]) :
  is.na() applied to non-(list or vector) of type 'NULL'

There's no NA's in my dataset, which seems ok..

> sum(is.na(rel))
[1] 0
> nrow(rel)
[1] 59
> ncol(rel)
[1] 49
> head(rel)
      X14.0   i.15.0  ai.15.0    br.16.0      X15.1    n.15.0    i.16.0
br.17.0
1 0.8409636 2.758547 1.925111 0.00000000 0.03878272 0.8658653 1.2627433
0.00000000
2 0.8631263 2.999573 2.068838 0.00000000 0.04781487 0.9281469 1.2124018
0.01814870
3 1.1698988 4.017031 2.475490 0.00000000 0.06475970 0.8345328 1.8643781
0.04102243
4 1.1189279 3.543764 2.385878 0.00000000 0.04980440 0.7698666 1.7861071
0.03490974
5 1.2324211 2.017189 1.484382 0.02462469 0.03719938 0.8285019 1.1649025
0.00000000
6 1.1275200 1.984574 1.417046 0.00000000 0.02461027 0.7751023 0.7736307
0.01144489
     X16.0 X2.1.16.1a X10.Me.16.0 X2.3.16.1b     X2.4a X2.4.16.1w7
X2.5.i.17.0_
1 16.74626  0.4417955   1.0486484  0.3216925 0.4034028    4.357194
0.5073206
2 16.77015  0.4702506   1.1215379  0.3326751 0.3719471    4.753351
0.5005562
3 16.89350  0.7087030   2.5427811  0.3788973 0.4233197    4.578289
0.5389445
4 17.21581  0.6239133   2.5463528  0.3439109 0.4152840    4.537743
0.4928171
5 18.34007  0.2722663   0.8365801  0.1955707 0.4530307    3.462293
0.2493175
6 18.42559  0.2618034   0.8100510  0.1946894 0.4464420    3.396504
0.2508381
    X16.1c br.17.0.1    br17.1 X10.Me17.0   cy17.0    X18.0        X0
X18.1w9t._
1 1.342751  2.883930 0.5117392  0.3985677 2.214624 4.429970 0.1811544
0.1680561
2 1.456768  2.817626 0.7262325  0.3552404 2.370162 3.419123 0.4533272
0.1274811
3 1.819283  3.597939 0.7856195  0.6546772 2.029322 3.375979 0.3780399
0.1366054
4 1.748514  3.893054 0.7656742  0.5506949 2.114840 3.604125 0.3286007
0.2314595
5 1.041661  3.516501 0.3611086  0.2074937 1.722343 3.698022 0.1720278
0.1276793
6 1.008310  3.589629 0.3439892  0.2085050 1.788364 3.858083 0.0000000
0.1268165
   br19.0._ X18.1w9c   X18.1b    X18.1c    X18.2a X18.2w6.9 X18.3w6.9.12
cy.19.0
1 0.4214627 11.88366 7.042868 0.7785622 0.5296606  20.75001    0.3747013
0.1845085
2 0.3655930 12.00201 7.117161 0.7833297 0.2148572  21.92248    0.4152870
0.1879331
3 0.2086673 13.43202 6.233585 1.1172938 0.5660451  14.61465    0.4775747
0.2788579
4 0.2348959 13.74445 6.138005 1.0161645 0.2209565  15.53226    0.4344465
0.2116109
5 0.1659439 14.24557 5.240076 0.7881302 0.1541940  23.97948    0.5682993
0.1642502
6 0.1609455 14.29624 5.137798 0.7543159 0.2945796  24.54077    0.5711625
0.1318383
  cy.19.0.1      X0.1 X18.3w3.6.9     X20.0       X0.2     X18.2b
X21.0     X20.2
1  3.896800 0.1349484    3.392245 0.7221273 0.14947364 0.04188258 0.1495564
0.4198097
2  3.974945 0.1426084    3.216271 0.5750869 0.12714397 0.08999512 0.1339824
0.2883602
3  5.044190 0.3689036    2.116062 0.8468635 0.08036104 0.07226680 0.1390747
0.2504645
4  4.324061 0.3253495    2.270108 0.8674106 0.09904184 0.05582051 0.1436902
0.1901801
5  3.534329 0.1266162    3.941966 0.7320950 0.15424966 0.14193815 0.1310820
0.1926944
6  3.547334 0.1062227    4.118720 0.7581633 0.12410799 0.11998844 0.1402905
0.1977357
     X20.3a    X20.3b X20.4w6.9.12.15     X22.0 X20.5w3.6.9.12.15
X0.3    X23.0_
1 0.4094126 0.2474286       1.1500272 1.1227407         0.9296417 0.2243854
0.2339230
2 0.4186328 0.2084205       0.8633682 0.8924207         0.5396120 0.1732975
0.1987064
3 0.4683385 0.1670621       0.7293349 1.3617136         0.3184905 0.1806325
0.2426850
4 0.4419191 0.1784320       0.7967968 1.4136308         0.2825521 0.1660992
0.2709302
5 0.4628079 0.1882448       0.7705750 1.1223705         0.2243516 0.1713259
0.2452253
6 0.4212344 0.1971018       0.7522184 1.1690829         0.1822425 0.0000000
0.2481156
      X24.0      X25.0 X22.6w3.6.9.12.15.18
1 0.9094009 0.08456623           0.16707761
2 0.7546380 0.06352018           0.14586538
3 1.1081230 0.08133338           0.18639182
4 1.2978036 0.11136199           0.12997539
5 0.9084890 0.09101005           0.10949849
6 1.0261733 0.10038159           0.07969927

here are the package versions.

> version
               _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status

major          3
minor          0.2
year           2013
month          09
day            25
svn rev        63987
language       R
version.string R version 3.0.2 (2013-09-25)
nickname       Frisbee Sailing

> citation('vegan')

To cite package ?vegan? in publications use:

  Jari Oksanen, F. Guillaume Blanchet, Roeland Kindt, Pierre Legendre, Peter
  R. Minchin, R. B. O'Hara, Gavin L. Simpson, Peter Solymos, M. Henry H.
  Stevens and Helene Wagner (2013). vegan: Community Ecology Package. R
  package version 2.0-10. http://CRAN.R-project.org/package=vegan

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Tue Nov 11 16:42:35 2014
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 11 Nov 2014 09:42:35 -0600
Subject: [R] Error: (list) object cannot be coerced to type double;
 on running the following code in R ver 3.1.2
In-Reply-To: <2117106709.487786.1415696754905.JavaMail.yahoo@jws10625.mail.bf1.yahoo.com>
References: <2117106709.487786.1415696754905.JavaMail.yahoo@jws10625.mail.bf1.yahoo.com>
Message-ID: <BE650289-A12C-4498-A93D-1311863D9B5E@TxBiomed.org>

Aditya,

Please use plan text. HTML is not handled correctly.

Within your last statement it appears you are trying to find the sum of a logical vector - is.na(). This is what is causing the error.

My guess is that you want to count the number of elements in the second column that are not NA values. You probably want the following for your last line. (See ?sum).

nummk <- length(vbm[ !is.na(vbm[ , 2], 2])
## or
nummk <- nrow(vbm[!is.na(vbm[ , 2], ])

## The is.na(vbm[ ,2]) returns a logical vector (for example c(FALSE, TRUE, TRUE))

Mark

R. Mark Sharp, Ph.D.
Director Primate Records Database
Southwest National Primate Research Center
Director of Scientific Computing
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Office telephone: (210)258-9476 (is forwarded to mobile telephone; message are captured into e-mail.)
Mobile telephone: (210) 218-2868




On Nov 11, 2014, at 3:05 AM, Aditya Singh wrote:

setwd("C:/Documents and Settings/Administrator/Desktop/Coursera/specdata/specdata")temp=list.files(pattern="*.csv")myfiles=lapply(temp,read.delim)summk=0nummk=0for (i in 1:10) {  vb=data.frame(myfiles[i])  vbm=as.double(vb)  summk=sum(vbm[,2])  nummk=length(vbm[,2]) - sum(is.na(vbm[,2]))}
Aditya

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


________________________________
NOTICE: This E-Mail (including attachments) is confidential and may be legally privileged. It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited. Please reply to the sender that you have received this message in error, then delete it.

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Nov 11 16:50:20 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 11 Nov 2014 07:50:20 -0800
Subject: [R] Error: (list) object cannot be coerced to type double;
 on running the following code in R ver 3.1.2
In-Reply-To: <BE650289-A12C-4498-A93D-1311863D9B5E@TxBiomed.org>
References: <2117106709.487786.1415696754905.JavaMail.yahoo@jws10625.mail.bf1.yahoo.com>
	<BE650289-A12C-4498-A93D-1311863D9B5E@TxBiomed.org>
Message-ID: <CACk-te1vguFrdBTejPq429qbm=1ETj0K93vvx3PP5TYnW6xJig@mail.gmail.com>

1. No comment on original garbled HTML code.

2. Comment on: "... Within your last statement it appears you are
trying to find the sum of a logical vector - is.na(). This is what is
causing the error."

That is false:

> sum(rep(c(FALSE,TRUE),3))
[1] 3

Please do read basic R documents -- this is about automatic coercion
-- before dispensing false advice.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Nov 11, 2014 at 7:42 AM, Mark Sharp <msharp at txbiomed.org> wrote:
> Aditya,
>
> Please use plan text. HTML is not handled correctly.
>
> Within your last statement it appears you are trying to find the sum of a logical vector - is.na(). This is what is causing the error.
>
> My guess is that you want to count the number of elements in the second column that are not NA values. You probably want the following for your last line. (See ?sum).
>
> nummk <- length(vbm[ !is.na(vbm[ , 2], 2])
> ## or
> nummk <- nrow(vbm[!is.na(vbm[ , 2], ])
>
> ## The is.na(vbm[ ,2]) returns a logical vector (for example c(FALSE, TRUE, TRUE))
>
> Mark
>
> R. Mark Sharp, Ph.D.
> Director Primate Records Database
> Southwest National Primate Research Center
> Director of Scientific Computing
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Office telephone: (210)258-9476 (is forwarded to mobile telephone; message are captured into e-mail.)
> Mobile telephone: (210) 218-2868
>
>
>
>
> On Nov 11, 2014, at 3:05 AM, Aditya Singh wrote:
>
> setwd("C:/Documents and Settings/Administrator/Desktop/Coursera/specdata/specdata")temp=list.files(pattern="*.csv")myfiles=lapply(temp,read.delim)summk=0nummk=0for (i in 1:10) {  vb=data.frame(myfiles[i])  vbm=as.double(vb)  summk=sum(vbm[,2])  nummk=length(vbm[,2]) - sum(is.na(vbm[,2]))}
> Aditya
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ________________________________
> NOTICE: This E-Mail (including attachments) is confidential and may be legally privileged. It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521. If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited. Please reply to the sender that you have received this message in error, then delete it.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From colli.leandro at gmail.com  Tue Nov 11 16:48:51 2014
From: colli.leandro at gmail.com (Leandro Colli)
Date: Tue, 11 Nov 2014 10:48:51 -0500
Subject: [R] How to highlight a group on a dendrogram
Message-ID: <CAJUkyXHMoC-+7EBY2BY2A+kwD5kGsSoTY8Ex2m67oQLGuia-aw@mail.gmail.com>

Hi, everyone,

     I am trying to highlight a group of samples at a cluster (dendogram).
I would like to do it setting a group name in bold (the group "Para").

     It is a large series, but I have a sampler above:
# Library

library(cluster)
library(png)

# Generating table1:

table1 <- (cbind(rbind("Para", "Tumor", "Normal", "Para", "Tumor",
 "Normal"), rbind(0.2, 6.4,2.3, 0.5, 1.5, 4.4), rbind(2.1, 2.14,1.0, 5.5,
0.3, 3.5), rbind(0.2, 1.4,2.2, 0.1, 1.9, 1.0),rbind(3.2, 6.4,2.3, 3.5,
10.5, 4.4), rbind(1.27, 0.9,1.7,1.2,1.5, 2.4) ))
names = as.matrix(table1[,1])
rownames(table1) <- names
table1 <- (table1[,2:6])
table1 = apply(table1, 1,as.numeric)

# Cluster and Plot

cluster = agnes(t(table1), metric = "manhattan", stand = T, method = "ward")
plot(cluster, main="", xlab="")

      I would like that the group "Para" at this plot appears on bold. Is
it possible using plot?

      Thank you very much, Leandro

	[[alternative HTML version deleted]]


From vinhdizzo at gmail.com  Tue Nov 11 17:10:49 2014
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Tue, 11 Nov 2014 08:10:49 -0800
Subject: [R] segfault with readDCF on R 3.1.2 on AIX 6.1 when using
	install.packages
Message-ID: <CA+2Dmwipnm70YM8pfTyjrR=O8-e5Y4uE=sgR-n921OvVvTXt2g@mail.gmail.com>

Dear list,

I was able to successfully compile R on our AIX box at work using the
GNU compilers following the instructions on the R Administration
guide.  The output can be seen at here
(https://gist.github.com/nguyenvinh/504321ea9c89d8919bef) and yields
no errors .

However, I get a segfault whenever I try to use the install.packages
function to install packages.  Using debug, I was able to trace it to
the readDCF function:

Browse[2]>
debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
Browse[2]>
debug: return(.Internal(readDCF(file, fields, keep.white)))
Browse[2]>

 *** caught segfault ***
address 4, cause 'invalid permissions'

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:

Was curious if anyone has a clue on why such error exists or what I
could do to fix it?  I'm able to install packages via R CMD INSTALL,
but I would hate to have to manually determine dependencies, download
the source for each package, and install them "by hand" via R CMD
INSTALL.  Would be great to get this resolved.  Thank you for your
help.

-- Vinh


From vinhdizzo at gmail.com  Tue Nov 11 17:57:11 2014
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Tue, 11 Nov 2014 08:57:11 -0800
Subject: [R] segfault with readDCF on R 3.1.2 on AIX 6.1 when using
	install.packages
In-Reply-To: <CA+2Dmwipnm70YM8pfTyjrR=O8-e5Y4uE=sgR-n921OvVvTXt2g@mail.gmail.com>
References: <CA+2Dmwipnm70YM8pfTyjrR=O8-e5Y4uE=sgR-n921OvVvTXt2g@mail.gmail.com>
Message-ID: <CA+2DmwhT4r1zomtzpftGqYuK-8AXyU6VNasb2nXSsxbh6PEtvw@mail.gmail.com>

I went back and compiled older versions of R to see if this error
exists.  On R 3.0.3, I get:

debug(available.packages)
install.packages('ggplot2', dep=TRUE, repo='http://cran.stat.ucla.edu')
...
Browse[2]>
debug: z <- res0 <- tryCatch(read.dcf(file = tmpf), error = identity)
Browse[2]>
Error: segfault from C stack overflow

On R 2.15.3, I do not see the error.

Thanks!

-- Vinh


On Tue, Nov 11, 2014 at 8:10 AM, Vinh Nguyen <vinhdizzo at gmail.com> wrote:
> Dear list,
>
> I was able to successfully compile R on our AIX box at work using the
> GNU compilers following the instructions on the R Administration
> guide.  The output can be seen at here
> (https://gist.github.com/nguyenvinh/504321ea9c89d8919bef) and yields
> no errors .
>
> However, I get a segfault whenever I try to use the install.packages
> function to install packages.  Using debug, I was able to trace it to
> the readDCF function:
>
> Browse[2]>
> debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
> Browse[2]>
> debug: return(.Internal(readDCF(file, fields, keep.white)))
> Browse[2]>
>
>  *** caught segfault ***
> address 4, cause 'invalid permissions'
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
>
> Was curious if anyone has a clue on why such error exists or what I
> could do to fix it?  I'm able to install packages via R CMD INSTALL,
> but I would hate to have to manually determine dependencies, download
> the source for each package, and install them "by hand" via R CMD
> INSTALL.  Would be great to get this resolved.  Thank you for your
> help.
>
> -- Vinh


From sikiru.suleiman at hotmail.com  Tue Nov 11 12:40:27 2014
From: sikiru.suleiman at hotmail.com (sikiru suleiman)
Date: Tue, 11 Nov 2014 11:40:27 +0000
Subject: [R] (no subject)
Message-ID: <BAY405-EAS338C24D3B064213F1960494FA810@phx.gbl>

I want to build a package that can generates random replication of treatment for DOE in matrix form.please I need your assistance on how to use R to generate  nth row by jth col matrix with random replications of experiments.






Sent from Windows Mail
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Nov 11 18:11:57 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 11 Nov 2014 09:11:57 -0800
Subject: [R] (no subject)
In-Reply-To: <BAY405-EAS338C24D3B064213F1960494FA810@phx.gbl>
References: <BAY405-EAS338C24D3B064213F1960494FA810@phx.gbl>
Message-ID: <CACk-te1DLigmyi7113Mj-UQDTir0688_cNEaNVcTSZmz3KrxpA@mail.gmail.com>

Start reading:

http://cran.r-project.org/doc/manuals/R-intro.pdf

(or hire a consultant?)

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Nov 11, 2014 at 3:40 AM, sikiru suleiman
<sikiru.suleiman at hotmail.com> wrote:
> I want to build a package that can generates random replication of treatment for DOE in matrix form.please I need your assistance on how to use R to generate  nth row by jth col matrix with random replications of experiments.
>
>
>
>
>
>
> Sent from Windows Mail
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Nov 11 19:06:25 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 11 Nov 2014 10:06:25 -0800
Subject: [R] segfault with readDCF on R 3.1.2 on AIX 6.1 when
	using	install.packages
In-Reply-To: <CA+2Dmwipnm70YM8pfTyjrR=O8-e5Y4uE=sgR-n921OvVvTXt2g@mail.gmail.com>
References: <CA+2Dmwipnm70YM8pfTyjrR=O8-e5Y4uE=sgR-n921OvVvTXt2g@mail.gmail.com>
Message-ID: <C4CF8244-ED9C-480F-ABB1-3008362EE58A@dcn.davis.CA.us>

Perhaps you are not using a compatible compiler. I believe this is off-topic for this mailing list, though.. see the Posting Guide.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 11, 2014 8:10:49 AM PST, Vinh Nguyen <vinhdizzo at gmail.com> wrote:
>Dear list,
>
>I was able to successfully compile R on our AIX box at work using the
>GNU compilers following the instructions on the R Administration
>guide.  The output can be seen at here
>(https://gist.github.com/nguyenvinh/504321ea9c89d8919bef) and yields
>no errors .
>
>However, I get a segfault whenever I try to use the install.packages
>function to install packages.  Using debug, I was able to trace it to
>the readDCF function:
>
>Browse[2]>
>debug: if (!all) return(.Internal(readDCF(file, fields, keep.white)))
>Browse[2]>
>debug: return(.Internal(readDCF(file, fields, keep.white)))
>Browse[2]>
>
> *** caught segfault ***
>address 4, cause 'invalid permissions'
>
>Possible actions:
>1: abort (with core dump, if enabled)
>2: normal R exit
>3: exit R without saving workspace
>4: exit R saving workspace
>Selection:
>
>Was curious if anyone has a clue on why such error exists or what I
>could do to fix it?  I'm able to install packages via R CMD INSTALL,
>but I would hate to have to manually determine dependencies, download
>the source for each package, and install them "by hand" via R CMD
>INSTALL.  Would be great to get this resolved.  Thank you for your
>help.
>
>-- Vinh
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jenn1120 at naver.com  Tue Nov 11 18:58:44 2014
From: jenn1120 at naver.com (=?UTF-8?B?7KCV7J6s7Z2s?=)
Date: Wed, 12 Nov 2014 02:58:44 +0900 (KST)
Subject: [R] =?utf-8?q?How_are_the_standard_errors_of_the_estimates_in_glm?=
 =?utf-8?b?Lm5iKCkgY2FsY3VsYXRlZD8=?=
Message-ID: <b4dc60f8fa7e8c5cc38efa31e190767d@cweb12.nm.nhnsystem.com>

Hello, I am running a negative binomial model using the glm.nb function in MASS package. But the standard errors I get are slightly different from the same model I ran using Stata's nbreg command. Some of the standard errors are the same, but some are not. Those that are different differ in their decimals, particularly the third decimal. I am wondering how exactly glm.nb calculates standard errors. I could not find any documentation. The standard errors in Stata's nbreg command are calculated from the observed information matrix. I am thinking that maybe glm.nb uses the expected information instead of the observed information? But I could not figure out if that is the case. It may be because I don't have a very good grasp of the difference between expected and observed information. I also tried to look into the source code of glm.nb by typing glm.nb in the R console, but I could not find how the standard errors are calculated. Any help will be very much appreciated! As a side note, here is the output I get after running the glm.nb model: Deviance Residuals:     Min       1Q         Median       3Q      Max   -2.8076  -1.0216  -0.4800   0.3257   4.2359   Coefficients:                                 Estimate    Std. Error    z value   Pr(&gt;|z|)     (Intercept)             -1.4211390   0.2334931   -6.086   1.15e-09 *** x1                        -0.0633597    0.1825984   -0.347    0.728599     x2                         0.0240531    0.0327962    0.733     0.463308     x3                        -0.0223691    0.0318900   -0.701    0.483025     x4                        0.1004497     0.0348040    2.886     0.003900 ** x5                        -0.0110895    0.0254989   -0.435    0.663635     x6                        0.0098525     0.0174814    0.564     0.573029     x7                        -0.2574358    0.2375014   -1.084     0.278394     x8                        0.0319359     0.0250482   1.275      0.202318     x9                         0.9795687     0.0332084  29.498     &lt; 2e-16 *** x10                       -1.2697342   0.1684822   -7.536     4.83e-14 *** x11                       0.0021235    0.0003019   7.035     2.00e-12 *** x12                       0.5223974    0.2052481   2.545      0.010922 *   x13                      -0.0491496   0.1853978   -0.265     0.790930     x14                      -0.4071932    0.1087920  -3.743     0.000182 *** x15                      -0.2980707   0.2197779   -1.356     0.175024     x16                      -0.2374620   0.1885971    -1.259    0.207995     x17                      -0.1466253   0.1236171    -1.186    0.235573     --- Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 (Dispersion parameter for Negative Binomial(1.2214) family taken to be 1)      Null deviance: 3658.9  on 1108  degrees of freedom Residual deviance: 1186.1  on 1091  degrees of freedom   (34 observations deleted due to missingness) AIC: 5104.4 Number of Fisher Scoring iterations: 1               Theta:  1.2214           Std. Err.:  0.0855  2 x log-likelihood:  -5066.3860  

	[[alternative HTML version deleted]]


From vinhdizzo at gmail.com  Tue Nov 11 19:15:38 2014
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Tue, 11 Nov 2014 10:15:38 -0800
Subject: [R] segfault with readDCF on R 3.1.2 on AIX 6.1 when using
	install.packages
In-Reply-To: <C4CF8244-ED9C-480F-ABB1-3008362EE58A@dcn.davis.CA.us>
References: <CA+2Dmwipnm70YM8pfTyjrR=O8-e5Y4uE=sgR-n921OvVvTXt2g@mail.gmail.com>
	<C4CF8244-ED9C-480F-ABB1-3008362EE58A@dcn.davis.CA.us>
Message-ID: <CA+2DmwjDvP21Wb-N88a+gyDpg1OZiE-wQB5rCJqVMRDFNb2BeA@mail.gmail.com>

On Tue, Nov 11, 2014 at 10:06 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Perhaps you are not using a compatible compiler. I believe this is off-topic for this mailing list, though.. see the Posting Guide.

I'll move this question to r-devel.  Thanks.

-- Vinh


From gyanendra.pokharel at gmail.com  Tue Nov 11 20:17:13 2014
From: gyanendra.pokharel at gmail.com (Gyanendra Pokharel)
Date: Tue, 11 Nov 2014 14:17:13 -0500
Subject: [R] Two dimensional likelihood surface plot
Message-ID: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>

Hi R users,
I am trying to plot two dimensional posterior likelihood surface. I have a
data like

para1     para2     likehood
.......      ........      ...........
.......      ........      ...........



I looked at contour plot but it needs a shorted values of parameters and a
matrix of likelihood values. Is there any way to get the plot? or how can I
change my likelihood values to a matrix for the function "contour"?

Any suggestions are appreciated.


GP
University of Guelph
Guelph, ON

	[[alternative HTML version deleted]]


From eliza_botto at hotmail.com  Tue Nov 11 20:32:54 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 11 Nov 2014 19:32:54 +0000
Subject: [R] R memory issues
Message-ID: <BLU170-W30B78805187518568888B789810@phx.gbl>

Dear useRs,
I have this funny thing going on with me since morning. I am 32 bit window 7 system with 4 GB RAM(2.95 usable). I tried to run a code on it but when I tried to convert dataframe to matrix by using the following code
mat<-matrix(as.numeric(unlist(SFI)),nrow=nrow(SFI))
*where SFI is my dataframe.
an error came up, "Error: cannot allocate vector of size 237.3 Mb"
I tried to increase memory by using memory.limit(2500) but to no effect. 
Kindly help me out on it as you always do.
Thanks,
Eliza 		 	   		  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Nov 11 21:53:44 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 11 Nov 2014 12:53:44 -0800
Subject: [R] Two dimensional likelihood surface plot
In-Reply-To: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>
References: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>
Message-ID: <A94E447D-210B-43C6-A978-35C9F5AE1438@comcast.net>


On Nov 11, 2014, at 11:17 AM, Gyanendra Pokharel wrote:

> Hi R users,
> I am trying to plot two dimensional posterior likelihood surface. I have a
> data like
> 
> para1     para2     likehood
> .......      ........      ...........
> .......      ........      ...........
> 
> 
> 
> I looked at contour plot but it needs a shorted values of parameters and a
> matrix of likelihood values. Is there any way to get the plot? or how can I
> change my likelihood values to a matrix for the function "contour"?

If the data are organized in a regular manner, then this might succeed:

with( df, contour( x=unique(para1), y=unique(para2)
                   z= matrix( likehood, length(unique(para1), length(unique(para2) )
     )           )

> 
> Any suggestions are appreciated.
> 
> 
> GP
> University of Guelph
> Guelph, ON
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue Nov 11 21:56:58 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 11 Nov 2014 15:56:58 -0500
Subject: [R] Two dimensional likelihood surface plot
In-Reply-To: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>
References: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>
Message-ID: <5462781A.7050604@gmail.com>

On 11/11/2014, 2:17 PM, Gyanendra Pokharel wrote:
> Hi R users,
> I am trying to plot two dimensional posterior likelihood surface. I have a
> data like
> 
> para1     para2     likehood
> .......      ........      ...........
> .......      ........      ...........
> 
> 
> 
> I looked at contour plot but it needs a shorted values of parameters and a
> matrix of likelihood values. Is there any way to get the plot? or how can I
> change my likelihood values to a matrix for the function "contour"?

The interp() function in the akima package should be able to do what you
want.

Duncan Murdoch


From gunter.berton at gene.com  Tue Nov 11 22:31:23 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 11 Nov 2014 13:31:23 -0800
Subject: [R] Two dimensional likelihood surface plot
In-Reply-To: <5462781A.7050604@gmail.com>
References: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>
	<5462781A.7050604@gmail.com>
Message-ID: <CACk-te3evCZkjARBbrEgMOtfZtLxiwT_urAj=UCL4a1dbFMY5Q@mail.gmail.com>

... as would the loess predict() method do from a loess() fit in the
base package.

I have used loess() for this purpose primarily to take advantage of
its "robustness" capabilities. I hasten to add that the algorithm is
not infallible in this regard, as it may not recover from a
sufficiently bad set of (least squares)starting values, as ?loess
explicitly says. It can also be slow.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Nov 11, 2014 at 12:56 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 11/11/2014, 2:17 PM, Gyanendra Pokharel wrote:
>> Hi R users,
>> I am trying to plot two dimensional posterior likelihood surface. I have a
>> data like
>>
>> para1     para2     likehood
>> .......      ........      ...........
>> .......      ........      ...........
>>
>>
>>
>> I looked at contour plot but it needs a shorted values of parameters and a
>> matrix of likelihood values. Is there any way to get the plot? or how can I
>> change my likelihood values to a matrix for the function "contour"?
>
> The interp() function in the akima package should be able to do what you
> want.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.gang.peng at gmail.com  Tue Nov 11 23:05:46 2014
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Tue, 11 Nov 2014 16:05:46 -0600
Subject: [R] Cannot change R package name in Windows and cannot install an R
 package in Mac OS Yosemite
Message-ID: <CAMjJGR2U5TZwozoiWpVWXxFG=pY-2FGxXtpoNkaowYaznkeZEw@mail.gmail.com>

Hi,

I am now writing an R package LFSpro. I build it for both Mac OS and
Windows.

For Windows, the binary package name is LFSpro_1.0.3.zip. It can be
installed into R successfully. But when I changed the name to
LFSpro_1.0.3.Windows.zip, an error occurred:

Error in read.dcf(file.path(pkgname,"DESCRIPTION"), c("Package",
"TYPE")):cannot open the connection
In addition: Warning message:
In read.dcf(file.path(pkgname,"DESCRIPTION") c("Package", "TYPE")) cannot
open compressed file 'LFSpro_1.0.3.Windows/DESCRIPTION', probable reason
'No such file or directory'

Why we cannot change the package name in windows?

The R package is build on http://win-builder.r-project.org/. There is no
error when built it on http://win-builder.r-project.org/. We installed it
in Windows 7 and 8.1. The R version is 3.1.2.

For Mac OS, someone tested it on Yosemite, an error occurred:

R[1588:958444] plugin com.getdropbox.dropbox.garcon interrupted

I googled the error message, it seems that there is an incompatibility
between R and Yosemite. But when I tested it by myself on Yosemite, there
is no such an error. The user is in Brazil, and he is not very familiar
with R. I don't know why this error occurs.

Is anyone has any idea why there is this error message. The R package is
build in R 3.1.1 and Mac OS X 10.6.8.

If anyone want to test the R package, you can download it from
http://bioinformatics.mdanderson.org/main/LFSpro

Thanks a lot for your help.

Best,
Gang

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Nov 11 23:20:06 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 11 Nov 2014 23:20:06 +0100
Subject: [R] Cannot change R package name in Windows and cannot install
 an R package in Mac OS Yosemite
In-Reply-To: <CAMjJGR2U5TZwozoiWpVWXxFG=pY-2FGxXtpoNkaowYaznkeZEw@mail.gmail.com>
References: <CAMjJGR2U5TZwozoiWpVWXxFG=pY-2FGxXtpoNkaowYaznkeZEw@mail.gmail.com>
Message-ID: <54628B96.3070603@statistik.tu-dortmund.de>



On 11.11.2014 23:05, Michael Peng wrote:
> Hi,
>
> I am now writing an R package LFSpro. I build it for both Mac OS and
> Windows.
>
> For Windows, the binary package name is LFSpro_1.0.3.zip. It can be
> installed into R successfully. But when I changed the name to
> LFSpro_1.0.3.Windows.zip, an error occurred:
>
> Error in read.dcf(file.path(pkgname,"DESCRIPTION"), c("Package",
> "TYPE")):cannot open the connection
> In addition: Warning message:
> In read.dcf(file.path(pkgname,"DESCRIPTION") c("Package", "TYPE")) cannot
> open compressed file 'LFSpro_1.0.3.Windows/DESCRIPTION', probable reason
> 'No such file or directory'
>
> Why we cannot change the package name in windows?

Since the filename is an esential part of the package used by the tools.

Best,
Uwe Ligges


> The R package is build on http://win-builder.r-project.org/. There is no
> error when built it on http://win-builder.r-project.org/. We installed it
> in Windows 7 and 8.1. The R version is 3.1.2.
>
> For Mac OS, someone tested it on Yosemite, an error occurred:
>
> R[1588:958444] plugin com.getdropbox.dropbox.garcon interrupted
>
> I googled the error message, it seems that there is an incompatibility
> between R and Yosemite. But when I tested it by myself on Yosemite, there
> is no such an error. The user is in Brazil, and he is not very familiar
> with R. I don't know why this error occurs.
>
> Is anyone has any idea why there is this error message. The R package is
> build in R 3.1.1 and Mac OS X 10.6.8.
>
> If anyone want to test the R package, you can download it from
> http://bioinformatics.mdanderson.org/main/LFSpro
>
> Thanks a lot for your help.
>
> Best,
> Gang
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michael.gang.peng at gmail.com  Tue Nov 11 23:28:49 2014
From: michael.gang.peng at gmail.com (Michael Peng)
Date: Tue, 11 Nov 2014 16:28:49 -0600
Subject: [R] Cannot change R package name in Windows and cannot install
 an R package in Mac OS Yosemite
In-Reply-To: <54628B96.3070603@statistik.tu-dortmund.de>
References: <CAMjJGR2U5TZwozoiWpVWXxFG=pY-2FGxXtpoNkaowYaznkeZEw@mail.gmail.com>
	<54628B96.3070603@statistik.tu-dortmund.de>
Message-ID: <CAMjJGR29eBcumyAMCnsZTzE81L=fY4nmeGZLrhOTcKJmC1BTpw@mail.gmail.com>

I see. Thanks a lot.

Gang

On Tuesday, November 11, 2014, Uwe Ligges <ligges at statistik.tu-dortmund.de>
wrote:

>
>
> On 11.11.2014 23:05, Michael Peng wrote:
>
>> Hi,
>>
>> I am now writing an R package LFSpro. I build it for both Mac OS and
>> Windows.
>>
>> For Windows, the binary package name is LFSpro_1.0.3.zip. It can be
>> installed into R successfully. But when I changed the name to
>> LFSpro_1.0.3.Windows.zip, an error occurred:
>>
>> Error in read.dcf(file.path(pkgname,"DESCRIPTION"), c("Package",
>> "TYPE")):cannot open the connection
>> In addition: Warning message:
>> In read.dcf(file.path(pkgname,"DESCRIPTION") c("Package", "TYPE")) cannot
>> open compressed file 'LFSpro_1.0.3.Windows/DESCRIPTION', probable reason
>> 'No such file or directory'
>>
>> Why we cannot change the package name in windows?
>>
>
> Since the filename is an esential part of the package used by the tools.
>
> Best,
> Uwe Ligges
>
>
>  The R package is build on http://win-builder.r-project.org/. There is no
>> error when built it on http://win-builder.r-project.org/. We installed it
>> in Windows 7 and 8.1. The R version is 3.1.2.
>>
>> For Mac OS, someone tested it on Yosemite, an error occurred:
>>
>> R[1588:958444] plugin com.getdropbox.dropbox.garcon interrupted
>>
>> I googled the error message, it seems that there is an incompatibility
>> between R and Yosemite. But when I tested it by myself on Yosemite, there
>> is no such an error. The user is in Brazil, and he is not very familiar
>> with R. I don't know why this error occurs.
>>
>> Is anyone has any idea why there is this error message. The R package is
>> build in R 3.1.1 and Mac OS X 10.6.8.
>>
>> If anyone want to test the R package, you can download it from
>> http://bioinformatics.mdanderson.org/main/LFSpro
>>
>> Thanks a lot for your help.
>>
>> Best,
>> Gang
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Tue Nov 11 23:30:44 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 11 Nov 2014 23:30:44 +0100
Subject: [R] R memory issues
In-Reply-To: <BLU170-W30B78805187518568888B789810@phx.gbl>
References: <BLU170-W30B78805187518568888B789810@phx.gbl>
Message-ID: <54628E14.9070300@statistik.tu-dortmund.de>



On 11.11.2014 20:32, eliza botto wrote:
> Dear useRs,
> I have this funny thing going on with me since morning. I am 32 bit window 7 system with 4 GB RAM(2.95 usable). I tried to run a code on it but when I tried to convert dataframe to matrix by using the following code
> mat<-matrix(as.numeric(unlist(SFI)),nrow=nrow(SFI))
> *where SFI is my dataframe.
> an error came up, "Error: cannot allocate vector of size 237.3 Mb"
> I tried to increase memory by using memory.limit(2500) but to no effect.

So there is no memory left. Clean uo, use a 64-bit OS, ......

Best,
Uwe Ligges



> Kindly help me out on it as you always do.
> Thanks,
> Eliza 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From istazahn at gmail.com  Tue Nov 11 23:43:40 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 11 Nov 2014 17:43:40 -0500
Subject: [R] R memory issues
In-Reply-To: <BLU170-W30B78805187518568888B789810@phx.gbl>
References: <BLU170-W30B78805187518568888B789810@phx.gbl>
Message-ID: <CA+vqiLGEv2ECWbPF1EngzABxHhH5zbwW1jivaTMin1Betpe8SA@mail.gmail.com>

The short answer is "get a bigger computer or find a way to do the
computation using less memory".

Best,
Ists
On Nov 11, 2014 2:34 PM, "eliza botto" <eliza_botto at hotmail.com> wrote:

> Dear useRs,
> I have this funny thing going on with me since morning. I am 32 bit window
> 7 system with 4 GB RAM(2.95 usable). I tried to run a code on it but when I
> tried to convert dataframe to matrix by using the following code
> mat<-matrix(as.numeric(unlist(SFI)),nrow=nrow(SFI))
> *where SFI is my dataframe.
> an error came up, "Error: cannot allocate vector of size 237.3 Mb"
> I tried to increase memory by using memory.limit(2500) but to no effect.
> Kindly help me out on it as you always do.
> Thanks,
> Eliza
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gyanendra.pokharel at gmail.com  Tue Nov 11 23:53:23 2014
From: gyanendra.pokharel at gmail.com (Gyanendra Pokharel)
Date: Tue, 11 Nov 2014 17:53:23 -0500
Subject: [R] Two dimensional likelihood surface plot
In-Reply-To: <A94E447D-210B-43C6-A978-35C9F5AE1438@comcast.net>
References: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>
	<A94E447D-210B-43C6-A978-35C9F5AE1438@comcast.net>
Message-ID: <CAK=huh7cs=w4=rMSJZONDn6qT1iG3mee-=9JHKW5GY1FmOWRig@mail.gmail.com>

Thanks David, what do you mean by organized data in regular manner?

Gyanendra Pokharel
University of Guelph
Guelph, ON

On Tue, Nov 11, 2014 at 3:53 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Nov 11, 2014, at 11:17 AM, Gyanendra Pokharel wrote:
>
> > Hi R users,
> > I am trying to plot two dimensional posterior likelihood surface. I have
> a
> > data like
> >
> > para1     para2     likehood
> > .......      ........      ...........
> > .......      ........      ...........
> >
> >
> >
> > I looked at contour plot but it needs a shorted values of parameters and
> a
> > matrix of likelihood values. Is there any way to get the plot? or how
> can I
> > change my likelihood values to a matrix for the function "contour"?
>
> If the data are organized in a regular manner, then this might succeed:
>
> with( df, contour( x=unique(para1), y=unique(para2)
>                    z= matrix( likehood, length(unique(para1),
> length(unique(para2) )
>      )           )
>
> >
> > Any suggestions are appreciated.
> >
> >
> > GP
> > University of Guelph
> > Guelph, ON
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From marco.scutari at gmail.com  Wed Nov 12 00:33:38 2014
From: marco.scutari at gmail.com (Marco Scutari)
Date: Tue, 11 Nov 2014 23:33:38 +0000
Subject: [R] Strange error while passing string as an argument to the
 function in bnlearn package
In-Reply-To: <CAJ4nbUqrbo_e0VJWOGwh0C-bFcHzHRAr8u74CW+yK8DHQ3A=uA@mail.gmail.com>
References: <CAJ4nbUq=jEWy6L3TWdS6vSO2WUJOCGj9pRRWJ=cPysU4FpCmvg@mail.gmail.com>
	<CA+RJqXVCO3X4-ED78qYCwunEKQmfRuBOB9GH9++qPnuYYu4mcg@mail.gmail.com>
	<CAJ4nbUqrbo_e0VJWOGwh0C-bFcHzHRAr8u74CW+yK8DHQ3A=uA@mail.gmail.com>
Message-ID: <CA+RJqXUNBWY80Rvi6+W_mfY+6-_2WfXR5PsCBZVTUxKB9qPkdg@mail.gmail.com>

Hi Alexandr,

On 11 November 2014 00:10, Alexandr M <rus314 at gmail.com> wrote:
> Sorry that I formulated my question not very accurately.
> I form expressions/(logic conditions for parameters evidence and event)
> dynamically inside the loop and they are sometimes quite long.

By any chance, are using that for prediction? Because predict(...,
method = "bayes-lw") does posterior predictions from any set of
variables.

As an alternative, you can do cpdist(..., method = "lw") which also
generates from the posterior distribution:

> str(cpdist(fit, node = "A", evidence = list(B = "b"), method = "lw"))
Classes ?bn.cpdist? and 'data.frame':    10000 obs. of  1 variable:
 $ A: Factor w/ 3 levels "a","b","c": 1 2 2 3 1 1 1 2 1 1 ...
 - attr(*, "weights")= num  0.114 1 1 0.428 0.114 ...
 - attr(*, "method")= chr "lw"

To compute P(A = a | whatever you conditioned on), just sum the
corresponding weights over the total weight mass. Since no language
trickery is involved, this works reliably.

Cheers,
    Marco

-- 
Marco Scutari, Ph.D.
Lecturer in Statistics, Department of Statistics
University of Oxford, United Kingdom


From dwinsemius at comcast.net  Wed Nov 12 01:02:02 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 11 Nov 2014 16:02:02 -0800
Subject: [R] Two dimensional likelihood surface plot
In-Reply-To: <CAK=huh7cs=w4=rMSJZONDn6qT1iG3mee-=9JHKW5GY1FmOWRig@mail.gmail.com>
References: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>
	<A94E447D-210B-43C6-A978-35C9F5AE1438@comcast.net>
	<CAK=huh7cs=w4=rMSJZONDn6qT1iG3mee-=9JHKW5GY1FmOWRig@mail.gmail.com>
Message-ID: <6ADF46C8-ED97-4B46-AE1F-0DA57C65E0A3@comcast.net>


On Nov 11, 2014, at 2:53 PM, Gyanendra Pokharel wrote:

> Thanks David, what do you mean by organized data in regular manner?

This  is what I meant by a regular manner:

> matrix( c( rep( seq(0,1, by=.1), 11), rep( seq(0,1, by=.1),each=11) , runif(121) ), 121,3)
       [,1] [,2]        [,3]
  [1,]  0.0  0.0 0.048946906
  [2,]  0.1  0.0 0.332529489
  [3,]  0.2  0.0 0.967099462
  [4,]  0.3  0.0 0.565349269
  [5,]  0.4  0.0 0.024230243
  [6,]  0.5  0.0 0.421633329
  [7,]  0.6  0.0 0.965847357
  [8,]  0.7  0.0 0.719618276
  [9,]  0.8  0.0 0.948675911
 [10,]  0.9  0.0 0.180241643
 [11,]  1.0  0.0 0.804828468
 [12,]  0.0  0.1 0.713698501
 [13,]  0.1  0.1 0.991003966
 [14,]  0.2  0.1 0.936413540
 [15,]  0.3  0.1 0.941731063
 [16,]  0.4  0.1 0.373998953
 [17,]  0.5  0.1 0.988915380
 [18,]  0.6  0.1 0.500791201
 [19,]  0.7  0.1 0.070137099
 [20,]  0.8  0.1 0.968422057
 [21,]  0.9  0.1 0.827396746
snipped the remain 100 lines

with( df, contour( x=unique(V1), y=unique(V2),
                   z= matrix( V3, length(unique(V1)), length(unique(V2) )
     )           ))


df <- as.data.frame( matrix( c( rep( seq(0,1, by=.1), 11), rep( seq(0,1, by=.1),each=11) , runif(121) ), 121,3))
> str(df)
'data.frame':	121 obs. of  3 variables:
 $ V1: num  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 ...
 $ V2: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V3: num  0.628 0.661 0.163 0.57 0.527 ...

My original untested suggestion had some missing parentheses and a missing comma:

with( df, contour( x=unique(V1), y=unique(V2),
                   z= matrix( V3, length(unique(V1)), length(unique(V2) )
     )           ))


> Gyanendra Pokharel
> University of Guelph
> Guelph, ON
> 
> On Tue, Nov 11, 2014 at 3:53 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Nov 11, 2014, at 11:17 AM, Gyanendra Pokharel wrote:
> 
> > Hi R users,
> > I am trying to plot two dimensional posterior likelihood surface. I have a
> > data like
> >
> > para1     para2     likehood
> > .......      ........      ...........
> > .......      ........      ...........
> >
> >
> >
> > I looked at contour plot but it needs a shorted values of parameters and a
> > matrix of likelihood values. Is there any way to get the plot? or how can I
> > change my likelihood values to a matrix for the function "contour"?
> 
> If the data are organized in a regular manner, then this might succeed:
> 
> with( df, contour( x=unique(para1), y=unique(para2)
>                    z= matrix( likehood, length(unique(para1), length(unique(para2) )
>      )           )
> 
> >
> > Any suggestions are appreciated.
> >
> >
> > GP
> > University of Guelph
> > Guelph, ON
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From gyanendra.pokharel at gmail.com  Wed Nov 12 01:37:33 2014
From: gyanendra.pokharel at gmail.com (Gyanendra Pokharel)
Date: Tue, 11 Nov 2014 19:37:33 -0500
Subject: [R] Two dimensional likelihood surface plot
In-Reply-To: <6ADF46C8-ED97-4B46-AE1F-0DA57C65E0A3@comcast.net>
References: <CAK=huh5nKvARsPTkHew-DvY3HyCsGur1yizw-LkNLj=fyjjZPg@mail.gmail.com>
	<A94E447D-210B-43C6-A978-35C9F5AE1438@comcast.net>
	<CAK=huh7cs=w4=rMSJZONDn6qT1iG3mee-=9JHKW5GY1FmOWRig@mail.gmail.com>
	<6ADF46C8-ED97-4B46-AE1F-0DA57C65E0A3@comcast.net>
Message-ID: <CAK=huh74tbtREuvi802xVTKRCW=Hm=3=Xj3+o7wTKKUOZjvGGQ@mail.gmail.com>

Thanks a lot, David !

Thats what I wanted. it is greatly helpful.



GP
University of Guelph
Guelph, ON

On Tue, Nov 11, 2014 at 7:02 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Nov 11, 2014, at 2:53 PM, Gyanendra Pokharel wrote:
>
> > Thanks David, what do you mean by organized data in regular manner?
>
> This  is what I meant by a regular manner:
>
> > matrix( c( rep( seq(0,1, by=.1), 11), rep( seq(0,1, by=.1),each=11) ,
> runif(121) ), 121,3)
>        [,1] [,2]        [,3]
>   [1,]  0.0  0.0 0.048946906
>   [2,]  0.1  0.0 0.332529489
>   [3,]  0.2  0.0 0.967099462
>   [4,]  0.3  0.0 0.565349269
>   [5,]  0.4  0.0 0.024230243
>   [6,]  0.5  0.0 0.421633329
>   [7,]  0.6  0.0 0.965847357
>   [8,]  0.7  0.0 0.719618276
>   [9,]  0.8  0.0 0.948675911
>  [10,]  0.9  0.0 0.180241643
>  [11,]  1.0  0.0 0.804828468
>  [12,]  0.0  0.1 0.713698501
>  [13,]  0.1  0.1 0.991003966
>  [14,]  0.2  0.1 0.936413540
>  [15,]  0.3  0.1 0.941731063
>  [16,]  0.4  0.1 0.373998953
>  [17,]  0.5  0.1 0.988915380
>  [18,]  0.6  0.1 0.500791201
>  [19,]  0.7  0.1 0.070137099
>  [20,]  0.8  0.1 0.968422057
>  [21,]  0.9  0.1 0.827396746
> snipped the remain 100 lines
>
> with( df, contour( x=unique(V1), y=unique(V2),
>                    z= matrix( V3, length(unique(V1)), length(unique(V2) )
>      )           ))
>
>
> df <- as.data.frame( matrix( c( rep( seq(0,1, by=.1), 11), rep( seq(0,1,
> by=.1),each=11) , runif(121) ), 121,3))
> > str(df)
> 'data.frame':   121 obs. of  3 variables:
>  $ V1: num  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 ...
>  $ V2: num  0 0 0 0 0 0 0 0 0 0 ...
>  $ V3: num  0.628 0.661 0.163 0.57 0.527 ...
>
> My original untested suggestion had some missing parentheses and a missing
> comma:
>
> with( df, contour( x=unique(V1), y=unique(V2),
>                    z= matrix( V3, length(unique(V1)), length(unique(V2) )
>      )           ))
>
>
> > Gyanendra Pokharel
> > University of Guelph
> > Guelph, ON
> >
> > On Tue, Nov 11, 2014 at 3:53 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > On Nov 11, 2014, at 11:17 AM, Gyanendra Pokharel wrote:
> >
> > > Hi R users,
> > > I am trying to plot two dimensional posterior likelihood surface. I
> have a
> > > data like
> > >
> > > para1     para2     likehood
> > > .......      ........      ...........
> > > .......      ........      ...........
> > >
> > >
> > >
> > > I looked at contour plot but it needs a shorted values of parameters
> and a
> > > matrix of likelihood values. Is there any way to get the plot? or how
> can I
> > > change my likelihood values to a matrix for the function "contour"?
> >
> > If the data are organized in a regular manner, then this might succeed:
> >
> > with( df, contour( x=unique(para1), y=unique(para2)
> >                    z= matrix( likehood, length(unique(para1),
> length(unique(para2) )
> >      )           )
> >
> > >
> > > Any suggestions are appreciated.
> > >
> > >
> > > GP
> > > University of Guelph
> > > Guelph, ON
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From ron_michael70 at yahoo.com  Tue Nov 11 20:41:19 2014
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Tue, 11 Nov 2014 19:41:19 +0000 (UTC)
Subject: [R] qq-plot in R
Message-ID: <1046106110.415470.1415734879647.JavaMail.yahoo@jws10936.mail.sg3.yahoo.com>

Hi,

I am some questions on qq-plot offered by R. Let say I have following qq-plot:

?qqplot(rt(300, df = 5), rt(300, df = 5))
However I want to get more controls to define the range of x-axis as well as y-axis. For example I want to define that, x-axis range will be -10 to 10 and y-axis range will be 0-10 (just an example on what I am looking for). Additionally I want to get the entire list of (x,y) coordinates for all plotted points.
Basically one my goals is to draw multiple different qq-plots onto same plot-window, with my optimally chosen range of x & y axes. 
Can somebody here guide me how to achieve that?
Appreciate your pointers and help.
Thanks,
	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Wed Nov 12 04:47:34 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Wed, 12 Nov 2014 11:47:34 +0800 (CST)
Subject: [R]  how to use the rpart model to predict new data frame?
Message-ID: <62dcaa5c.1ba9e.149a21d1288.Coremail.rhelpmaillist@163.com>


Dear expeRts,
? ? Now i have a ?train ?dataset a ?and ?test dataset b , i ?using the following codes:
rp<-rpart(y~.,data=a,method="class")
plot(rp)
text(rp)
but how can i use the trained model to predict b?
TKS.






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From dwinsemius at comcast.net  Wed Nov 12 05:49:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 11 Nov 2014 20:49:23 -0800
Subject: [R] how to use the rpart model to predict new data frame?
In-Reply-To: <62dcaa5c.1ba9e.149a21d1288.Coremail.rhelpmaillist@163.com>
References: <62dcaa5c.1ba9e.149a21d1288.Coremail.rhelpmaillist@163.com>
Message-ID: <BDF5EE72-4433-4402-9FE9-C47BF96C9F4C@comcast.net>


> On Nov 11, 2014, at 7:47 PM, PO SU <rhelpmaillist at 163.com> wrote:
> 
> 
> Dear expeRts,
>     Now i have a  train  dataset a  and  test dataset b , i  using the following codes:
> rp<-rpart(y~.,data=a,method="class")
> plot(rp)
> text(rp)
> but how can i use the trained model to predict b?

?predict

> --
> 
> PO SU
> mail: desolator88 at 163.com 
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From bharatbargujar at gmail.com  Wed Nov 12 04:55:08 2014
From: bharatbargujar at gmail.com (Bharat Bargujar)
Date: Wed, 12 Nov 2014 09:25:08 +0530
Subject: [R] how to use the rpart model to predict new data frame?
In-Reply-To: <62dcaa5c.1ba9e.149a21d1288.Coremail.rhelpmaillist@163.com>
References: <62dcaa5c.1ba9e.149a21d1288.Coremail.rhelpmaillist@163.com>
Message-ID: <CAF3tJnGn4Uwyx_ZN=k1YWzWacJ0-pZ4eJSU-eFo17A1L+==Fgg@mail.gmail.com>

HI,

Try this:

results <- predict(rp,b,type = "vector")

Regards,
Bharat


On 12 November 2014 09:17, PO SU <rhelpmaillist at 163.com> wrote:

>
> Dear expeRts,
>     Now i have a  train  dataset a  and  test dataset b , i  using the
> following codes:
> rp<-rpart(y~.,data=a,method="class")
> plot(rp)
> text(rp)
> but how can i use the trained model to predict b?
> TKS.
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Wed Nov 12 06:06:37 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Wed, 12 Nov 2014 13:06:37 +0800 (CST)
Subject: [R] how to use the rpart model to predict new data frame?
In-Reply-To: <CAF3tJnGn4Uwyx_ZN=k1YWzWacJ0-pZ4eJSU-eFo17A1L+==Fgg@mail.gmail.com>
References: <62dcaa5c.1ba9e.149a21d1288.Coremail.rhelpmaillist@163.com>
	<CAF3tJnGn4Uwyx_ZN=k1YWzWacJ0-pZ4eJSU-eFo17A1L+==Fgg@mail.gmail.com>
Message-ID: <2359ac0f.1cda7.149a265701b.Coremail.rhelpmaillist@163.com>

OK , i tried predict(rp,b) but showed me a result which i can't understand, now it's the argument ?type="vector" worked.





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

At 2014-11-12 11:55:08, "Bharat Bargujar" <bharatbargujar at gmail.com> wrote:
 


HI,
?
Try this:
?
results <- predict(rp,b,type = "vector")
?
Regards,
Bharat
?


On 12 November 2014 09:17, PO SU <rhelpmaillist at 163.com> wrote:



Dear expeRts,

? ? Now i have a ?train ?dataset a ?and ?test dataset b , i ?using the following codes:

rp<-rpart(y~.,data=a,method="class")

plot(rp)

text(rp)

but how can i use the trained model to predict b?

TKS.













--



PO SU

mail: desolator88 at 163.com

Majored in Statistics from SJTU

______________________________________________

R-help at r-project.org mailing list

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.




From Gerrit.Eichner at math.uni-giessen.de  Wed Nov 12 08:45:02 2014
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 12 Nov 2014 08:45:02 +0100 (MET)
Subject: [R] qq-plot in R
In-Reply-To: <1046106110.415470.1415734879647.JavaMail.yahoo@jws10936.mail.sg3.yahoo.com>
References: <1046106110.415470.1415734879647.JavaMail.yahoo@jws10936.mail.sg3.yahoo.com>
Message-ID: <Pine.SOC.4.64.1411120842500.11907@solcom.hrz.uni-giessen.de>

Hello, ron,

have you looked at the help page of qqplot and consequently tried, e.g., 
the following?

xy <- qqplot( rt(300, df = 5), rt(300, df = 5),
               xlim = c(-10, 10), ylim = c(0, 10))
str( xy)



Hth  --  Gerrit


On Tue, 11 Nov 2014, Ron Michael wrote:

> Hi,
>
> I am some questions on qq-plot offered by R. Let say I have following qq-plot:
>
> ?qqplot(rt(300, df = 5), rt(300, df = 5))
> However I want to get more controls to define the range of x-axis as well as y-axis. For example I want to define that, x-axis range will be -10 to 10 and y-axis range will be 0-10 (just an example on what I am looking for). Additionally I want to get the entire list of (x,y) coordinates for all plotted points.
> Basically one my goals is to draw multiple different qq-plots onto same plot-window, with my optimally chosen range of x & y axes.
> Can somebody here guide me how to achieve that?
> Appreciate your pointers and help.
> Thanks,
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From petr.pikal at precheza.cz  Wed Nov 12 11:08:28 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 12 Nov 2014 10:08:28 +0000
Subject: [R] Compressing code help in a loop
In-Reply-To: <CABjzuv6QO5p=0H3njh1jLFVeJqGtzJ7FvqJfWTb+gOmba5N_GA@mail.gmail.com>
References: <CAKFaUKhjKkn2+0jVkTAQxsFT1fUgKzf9hSGh4niTRQTwQ_28Ug@mail.gmail.com>
	<CABjzuv6QO5p=0H3njh1jLFVeJqGtzJ7FvqJfWTb+gOmba5N_GA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEE264@SRVEXCHMBX.precheza.cz>

Hi

slightly more general if first number is quarter and last two are year

> index <- c(406, 107, 207, 307, 407, 108, 208, 308, 408, 109, 209, 309, 409,
+ 110, 210, 310, 410, 111, 211)

year<-substr(as.character(index), 2,3)
qrt<-substr(as.character(index), 1,1)
as.numeric(factor(paste(year, qrt, sep="-")))
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19

qyTOindex <- function(x) {

year <- substr(as.character(x), 2,3)
qrt <- substr(as.character(x), 1,1)
result <-as.numeric(factor(paste(year, qrt, sep="-")))
}

qyTOindex(p_int$p_made)

Regards

Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Wush Wu
> Sent: Monday, November 10, 2014 2:30 PM
> To: Francesca
> Cc: R help
> Subject: Re: [R] Compressing code help in a loop
>
> Dear Francesca,
>
> Is this what you want?
>
> ```r
> index <- c(406, 107, 207, 307, 407, 108, 208, 308, 408, 109, 209, 309,
> 409,
> 110, 210, 310, 410, 111, 211)
> p_m <- match( p_int$p_made, index)
> dim(p_m) <- c(dim(p_int)[1],1)
> ```
>
> Best,
> Wush
> PhD Student Graduate Institute of Electrical Engineering, National
> Taiwan
> University
>
>
>
> 2014-11-10 20:14 GMT+08:00 Francesca <francesca.pancotto at gmail.com>:
>
> > Dear Contributors
> >
> > I have a problem with a loop.
> >
> > I needed to create a variable that takes values 1,2.. to 19
> corresponding
> > to the value of a variable in a data.frame whose name is p_int$p_made
> and
> >
> > which takes values from 406  to 211.
> >
> > The problem is that this values come ordered in the wrong way when I
> try to
> > compress the loop as the system reads
> >
> >
> > 107,111,207,211,311,406,407,408,409,410,411,
> >
> >
> > while they correspond to quarters-years so they should be ordered as
> >
> >
> > 406-107-207-307-407?
> >
> > the only solution I found was really silly. It is the following.
> >
> >
> >
> >
> > p_m<-matrix(0,dim(p_int)[1],1)
> >
> > for (i in 1:length(p_int$p_made)){
> >
> >   if (p_int$p_made[i]==406) p_m[i]<-1 else
> >
> >     if (p_int$p_made[i]==107) p_m[i]<-2 else
> >
> >       if (p_int$p_made[i]==207) p_m[i]<-3 else
> >
> >         if (p_int$p_made[i]==307) p_m[i]<-4 else
> >
> >           if (p_int$p_made[i]==407) p_m[i]<-5 else
> >
> >             if (p_int$p_made[i]==108) p_m[i]<-6 else
> >
> >               if (p_int$p_made[i]==208) p_m[i]<-7 else
> >
> >                 if (p_int$p_made[i]==308) p_m[i]<-8 else
> >
> >                   if (p_int$p_made[i]==408) p_m[i]<-9 else
> >
> >                     if (p_int$p_made[i]==109) p_m[i]<-10 else
> >
> >                       if (p_int$p_made[i]==209) p_m[i]<-11 else
> >
> >                         if (p_int$p_made[i]==309) p_m[i]<-12 else
> >
> >                           if (p_int$p_made[i]==409) p_m[i]<-13 else
> >
> >                             if (p_int$p_made[i]==110) p_m[i]<-14 else
> >
> >                               if (p_int$p_made[i]==210) p_m[i]<-15
> else
> >
> >                                 if (p_int$p_made[i]==310) p_m[i]<-16
> else
> >
> >                                   if (p_int$p_made[i]==410) p_m[i]<-
> 17 else
> >
> >                                     if (p_int$p_made[i]==111)
> p_m[i]<-18
> > else
> >
> >                                       if (p_int$p_made[i]==211)
> p_m[i]<-19
> >
> > }
> >
> > Can anyone help to find something more efficient?
> >
> >
> > Thanks in advance.
> >
> >
> > Francesca
> >
> > --
> >
> > Francesca
> >
> > ----------------------------------
> > Francesca Pancotto
> > Associate Professor
> > University of Modena and Reggio Emilia
> > Viale A. Allegri, 9
> > 40121 Reggio Emilia
> > Office: +39 0522 523264
> > Web: https://sites.google.com/site/francescapancotto/
> > ----------------------------------
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From studerov at gmail.com  Wed Nov 12 14:34:10 2014
From: studerov at gmail.com (David Studer)
Date: Wed, 12 Nov 2014 14:34:10 +0100
Subject: [R] factor levels > numeric values
Message-ID: <CAA1twZRqtMM74_ZpSx+a0TdTivrfiVTd30FwcBN6Wg29BtiLRA@mail.gmail.com>

Hi everybody,

I have another question (to which I could not find an answer in my r-books.
I am sure, it's not a great issue, but I simply lack of a good idea how to
solve this:

One of my variables gets imported as a factor instead of a numeric variable.
Now I have a...
 Factor w/ 63 levels "0","0.02","0.03",..: 1 NA NA 1 NA NA 1 1 53 10 ...

How can I transform these factor levels into actual values?

Thank you very much for any help!
David

	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Wed Nov 12 15:06:01 2014
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 12 Nov 2014 15:06:01 +0100 (MET)
Subject: [R] factor levels > numeric values
In-Reply-To: <CAA1twZRqtMM74_ZpSx+a0TdTivrfiVTd30FwcBN6Wg29BtiLRA@mail.gmail.com>
References: <CAA1twZRqtMM74_ZpSx+a0TdTivrfiVTd30FwcBN6Wg29BtiLRA@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1411121504520.16032@solcom.hrz.uni-giessen.de>

Hello, David,

take a look at the beginning of the "Warning" section of ?factor.

  Hth  --  Gerrit

> Hi everybody,
>
> I have another question (to which I could not find an answer in my r-books.
> I am sure, it's not a great issue, but I simply lack of a good idea how to
> solve this:
>
> One of my variables gets imported as a factor instead of a numeric variable.
> Now I have a...
> Factor w/ 63 levels "0","0.02","0.03",..: 1 NA NA 1 NA NA 1 1 53 10 ...
>
> How can I transform these factor levels into actual values?
>
> Thank you very much for any help!
> David
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From a.mosnier at gmail.com  Wed Nov 12 15:19:39 2014
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Wed, 12 Nov 2014 09:19:39 -0500
Subject: [R] Submodel selection using dredge and gam (mgcv)
In-Reply-To: <5461D2D6.80002@o2.pl>
References: <CANkFkEftjMT1QNihMQsSFMpwdGTwY3gSFdO+4x9+WQbgK2QNig@mail.gmail.com>
	<5461D2D6.80002@o2.pl>
Message-ID: <CANkFkEfe+8nmxcFEN=yEjcuQ3n5Apdfftq2W7FdGZ77kSCKMgg@mail.gmail.com>

Hi Kamil,

Thanks for your answer. In fact, I already tried something with operators
in such a way you advise, but it seems more complicated due to the use of
the s() and ti() operators.

Can you provide a solution for the following example ?

library(mgcv)
set.seed(2)
dat <- gamSim(1,n=400,dist="normal",scale=2)

bt <- gam(y~s(x0)+s(x1)+ti(x0,x1), data=dat,method="ML")

library(MuMIn)

# this does not work
dredge(bt, subset = (!(x0,x1) | (x0 & x1)))
dredge(bt, subset = (!ti(x0,x1) | (s(x0) & s(x1))))

Cheers,

Arnaud


2014-11-11 4:11 GMT-05:00 Kamil Barto? <kamil.barton at o2.pl>:

> Hi Arnaud,
> your question has in fact nothing to do with gam or model selection. What
> you are asking is: what is the logical expression that yields True when AB
> is False or both A and B are True. Now replace the words with operators
> (!AB | (A & B)) and voil?.
>
> See also:
> help("Logic", "base")
> fortunes::fortune(350)
>
> best,
> kamil
>
>
>
> On 2014-11-10 21:26, Arnaud Mosnier wrote:
>
>> Hi,
>>
>> I want to use dredge to test several gam submodels including interactions.
>> I tried to find a way in order to keep models with interaction only if
>> the single variables occurring in the interaction are also included.
>>
>> i.e.: for
>>   y~s(x0)+s(x1)+ti(x0, x1)
>>
>> I want to keep
>> y ~ s(x0)
>> y ~ s(x1)
>> y ~ s(x0) + s(x1)
>> y ~ s(x0) + s(x1) + ti(x0,x1)
>>
>> and I want to remove
>>
>> y ~ s(x0) + ti(x0,x1)
>> y ~ s(x1) + ti(x0,x1)
>> y ~ ti(x0,x1)
>>
>>
>> I know that I should use the "subset" option of the dredge function.
>> However, I can not find the correct matrix / expression to obtain what I
>> need !
>>
>>
>> Here a small example.
>>
>> ################
>>
>> # Create some data (use mgcv example)
>> library(mgcv)
>> set.seed(2)
>> dat <- gamSim(1,n=400,dist="normal",scale=2)
>>
>> # Create the global gam model
>> # Here a model with interaction. Note the use of ti()
>> bt <- gam(y~s(x0)+s(x1)+s(x2)+s(x3)+ti(x1,x2), data=dat,method="ML")
>>
>> # Use dredge to test sub-models
>> library(MuMIn)
>> print(modstab <- dredge(bt))
>>
>> # Here the 11th model include the interaction but do not include the
>> single variables x1 and x2
>> # ... I want to avoid that kind of model.
>> get.models(modstab, subset = 11)
>>
>> ################
>>
>>
>> Any help would be appreciated !
>>
>> Arnaud
>>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Nov 12 15:56:11 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 12 Nov 2014 14:56:11 +0000
Subject: [R] factor levels > numeric values
In-Reply-To: <Pine.SOC.4.64.1411121504520.16032@solcom.hrz.uni-giessen.de>
References: <CAA1twZRqtMM74_ZpSx+a0TdTivrfiVTd30FwcBN6Wg29BtiLRA@mail.gmail.com>
	<Pine.SOC.4.64.1411121504520.16032@solcom.hrz.uni-giessen.de>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB1E51@mb02.ads.tamu.edu>

Also look at the Frequently Asked Questions document that comes with your R installation:

7.10 How do I convert factors to numeric?

It may happen that when reading numeric data into R (usually, when reading in a file), they come in as factors. If f is such a factor object, you can use

as.numeric(as.character(f))

to get the numbers back. More efficient, but harder to remember, is

as.numeric(levels(f))[as.integer(f)]

In any case, do not call as.numeric() or their likes directly for the task at hand (as as.numeric() or unclass() give the internal codes).

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Gerrit Eichner
Sent: Wednesday, November 12, 2014 8:06 AM
To: David Studer
Cc: r-help at r-project.org
Subject: Re: [R] factor levels > numeric values

Hello, David,

take a look at the beginning of the "Warning" section of ?factor.

  Hth  --  Gerrit

> Hi everybody,
>
> I have another question (to which I could not find an answer in my r-books.
> I am sure, it's not a great issue, but I simply lack of a good idea how to
> solve this:
>
> One of my variables gets imported as a factor instead of a numeric variable.
> Now I have a...
> Factor w/ 63 levels "0","0.02","0.03",..: 1 NA NA 1 NA NA 1 1 53 10 ...
>
> How can I transform these factor levels into actual values?
>
> Thank you very much for any help!
> David
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Wed Nov 12 16:18:21 2014
From: zadig_1 at excite.com (ce)
Date: Wed, 12 Nov 2014 10:18:21 -0500
Subject: [R] R memory issues
Message-ID: <20141112101821.31864@web001.roc2.bluetie.com>

you may try to increase virtual memory :

http://windows.microsoft.com/en-us/windows/change-virtual-memory-size#1TC=windows-7

-----Original Message-----
From: "eliza botto" [eliza_botto at hotmail.com]
Date: 11/11/2014 02:35 PM
To: "r-help at r-project.org" <r-help at r-project.org>
Subject: [R] R memory issues

Dear useRs,
I have this funny thing going on with me since morning. I am 32 bit window 7 system with 4 GB RAM(2.95 usable). I tried to run a code on it but when I tried to convert dataframe to matrix by using the following code
mat<-matrix(as.numeric(unlist(SFI)),nrow=nrow(SFI))
*where SFI is my dataframe.
an error came up, "Error: cannot allocate vector of size 237.3 Mb"
I tried to increase memory by using memory.limit(2500) but to no effect. 
Kindly help me out on it as you always do.
Thanks,
Eliza 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at univ-reims.fr  Wed Nov 12 16:20:12 2014
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 12 Nov 2014 16:20:12 +0100
Subject: [R] factor levels > numeric values
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FB1E51@mb02.ads.tamu.edu>
References: <CAA1twZRqtMM74_ZpSx+a0TdTivrfiVTd30FwcBN6Wg29BtiLRA@mail.gmail.com>	<Pine.SOC.4.64.1411121504520.16032@solcom.hrz.uni-giessen.de>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FB1E51@mb02.ads.tamu.edu>
Message-ID: <54637AAC.80406@univ-reims.fr>

I have not completely followed the discussion, so excuse me if it was 
already pointed out.
If numeric data are read as factors, this means that there are not only 
numeric data in the column. It could be an empty space somewhere, or 
some character that should be NA, or...
I think it is worth spending some time searching for the typo so that 
the file will be read correctly in R.

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENA? - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 12/11/14 15:56, David L Carlson a ?crit :
> Also look at the Frequently Asked Questions document that comes with your R installation:
>
> 7.10 How do I convert factors to numeric?
>
> It may happen that when reading numeric data into R (usually, when reading in a file), they come in as factors. If f is such a factor object, you can use
>
> as.numeric(as.character(f))
>
> to get the numbers back. More efficient, but harder to remember, is
>
> as.numeric(levels(f))[as.integer(f)]
>
> In any case, do not call as.numeric() or their likes directly for the task at hand (as as.numeric() or unclass() give the internal codes).
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Gerrit Eichner
> Sent: Wednesday, November 12, 2014 8:06 AM
> To: David Studer
> Cc: r-help at r-project.org
> Subject: Re: [R] factor levels > numeric values
>
> Hello, David,
>
> take a look at the beginning of the "Warning" section of ?factor.
>
>    Hth  --  Gerrit
>
>> Hi everybody,
>>
>> I have another question (to which I could not find an answer in my r-books.
>> I am sure, it's not a great issue, but I simply lack of a good idea how to
>> solve this:
>>
>> One of my variables gets imported as a factor instead of a numeric variable.
>> Now I have a...
>> Factor w/ 63 levels "0","0.02","0.03",..: 1 NA NA 1 NA NA 1 1 53 10 ...
>>
>> How can I transform these factor levels into actual values?
>>
>> Thank you very much for any help!
>> David
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From asimola78 at gmail.com  Wed Nov 12 16:20:40 2014
From: asimola78 at gmail.com (Antti Simola)
Date: Wed, 12 Nov 2014 17:20:40 +0200
Subject: [R] Compilation error: Rcpp and related packages -
	record-gcc-switches missing
Message-ID: <CAEeSNQ2ZKkeYGNdXVH40G98H11UV5oKoz_dhK2O3YkC+QSNarg@mail.gmail.com>

Hello,

I encountered problem with Linux machine (openSUSE, 3.1.1. version of R)
while I tried to update the packages with update.packages(). Rcpp,
RcppArmadillo and RcppEigen refused to compile because record-gcc-swtiches
was missing. I don't know much about compiling and such so I didn't get any
further with the problem. Enquiries to Rcpp and openSUSE experts have not
solved my problem. What I learned was that -frecord-gcc-switches might be
mispelled somewhere. That information did not help me to find solution. If
anyone could help with this problem I would we very thankful. See the log
and SessionInfo() below for more detail:

Rcpp :
Version 0.11.2 installed in /home/antti/R/x86_64-suse-linux-gnu-library/3.1
Version 0.11.3 available at http://ftp.eenet.ee/pub/cran
Update (y/N/c)? y
RcppArmadillo :
Version 0.4.320.0 installed in
/home/antti/R/x86_64-suse-linux-gnu-library/3.1
Version 0.4.450.1.0 available at http://ftp.eenet.ee/pub/cran
Update (y/N/c)? y
RcppEigen :
Version 0.3.2.1.2 installed in
/home/antti/R/x86_64-suse-linux-gnu-library/3.1
Version 0.3.2.2.0 available at http://ftp.eenet.ee/pub/cran
Update (y/N/c)? y
trying URL 'http://ftp.eenet.ee/pub/cran/src/con..._0.11.3.tar.gz
<http://ftp.eenet.ee/pub/cran/src/contrib/Rcpp_0.11.3.tar.gz>'
Content type 'application/x-tar' length 2169583 bytes (2.1 Mb)
opened URL
==================================================
downloaded 2.1 Mb

trying URL 'http://ftp.eenet.ee/pub/cran/src/con...450.1.0.tar.gz
<http://ftp.eenet.ee/pub/cran/src/contrib/RcppArmadillo_0.4.450.1.0.tar.gz>'
Content type 'application/x-tar' length 931597 bytes (909 Kb)
opened URL
==================================================
downloaded 909 Kb

trying URL 'http://ftp.eenet.ee/pub/cran/src/con...3.2.2.0.tar.gz
<http://ftp.eenet.ee/pub/cran/src/contrib/RcppEigen_0.3.2.2.0.tar.gz>'
Content type 'application/x-tar' length 1216536 bytes (1.2 Mb)
opened URL
==================================================
downloaded 1.2 Mb

* installing *source* package ?Rcpp? ...
** package ?Rcpp? successfully unpacked and MD5 sums checked
** libs
g++ -I/usr/lib64/R/include -I../inst/include/ -I/usr/local/include -fpic
-fmessage-length=0 record-gcc-switches -fstack-protector -O3 -Wall
-D_FORTIFY_SOURCE=2 -funwind-tables -fasynchronous-unwind-tables -c
Date.cpp -o Date.o
g++: error: record-gcc-switches: No such file or directory
make: *** [Date.o] Error 1
ERROR: compilation failed for package ?Rcpp?
* removing ?/home/antti/R/x86_64-suse-linux-gnu-library/3.1/Rcpp?
* restoring previous ?/home/antti/R/x86_64-suse-linux-gnu-library/3.1/Rcpp?
* installing *source* package ?RcppArmadillo? ...
** package ?RcppArmadillo? successfully unpacked and MD5 sums checked
* checking LAPACK_LIBS: divide-and-conquer complex SVD available via
R-supplied LAPACK
** libs
g++ -I/usr/lib64/R/include -I/usr/local/include
-I"/home/antti/R/x86_64-suse-linux-gnu-library/3.1/Rcpp/include"
-I../inst/include -fpic -fmessage-length=0 record-gcc-switches
-fstack-protector -O3 -Wall -D_FORTIFY_SOURCE=2 -funwind-tables
-fasynchronous-unwind-tables -c RcppArmadillo.cpp -o RcppArmadillo.o
g++: error: record-gcc-switches: No such file or directory
make: *** [RcppArmadillo.o] Error 1
ERROR: compilation failed for package ?RcppArmadillo?
* removing ?/home/antti/R/x86_64-suse-linux-gnu-library/3.1/RcppArmadillo?
* restoring previous
?/home/antti/R/x86_64-suse-linux-gnu-library/3.1/RcppArmadillo?
* installing *source* package ?RcppEigen? ...
** package ?RcppEigen? successfully unpacked and MD5 sums checked
** libs
g++ -I/usr/lib64/R/include -I/usr/local/include
-I"/home/antti/R/x86_64-suse-linux-gnu-library/3.1/Rcpp/include"
-I../inst/include -fpic -fmessage-length=0 record-gcc-switches
-fstack-protector -O3 -Wall -D_FORTIFY_SOURCE=2 -funwind-tables
-fasynchronous-unwind-tables -c RcppEigen.cpp -o RcppEigen.o
g++: error: record-gcc-switches: No such file or directory
make: *** [RcppEigen.o] Error 1
ERROR: compilation failed for package ?RcppEigen?
* removing ?/home/antti/R/x86_64-suse-linux-gnu-library/3.1/RcppEigen?
* restoring previous
?/home/antti/R/x86_64-suse-linux-gnu-library/3.1/RcppEigen?

The downloaded source packages are in
?/tmp/Rtmpnx5dfE/downloaded_packages?
Warning messages:
1: In install.packages(update[instlib == l, "Package"], l, contriburl =
contriburl, :
installation of package ?Rcpp? had non-zero exit status
2: In install.packages(update[instlib == l, "Package"], l, contriburl =
contriburl, :
installation of package ?RcppArmadillo? had non-zero exit status
3: In install.packages(update[instlib == l, "Package"], l, contriburl =
contriburl, :
installation of package ?RcppEigen? had non-zero exit status
> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-suse-linux-gnu (64-bit)

locale:
[1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
[5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=en_US.UTF-8 LC_NAME=C
[9] LC_ADDRESS=C LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats graphics grDevices utils datasets methods base

loaded via a namespace (and not attached):
[1] compiler_3.1.1 tcltk_3.1.1 tools_3.1.1

Cheer,

Antti

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Nov 12 16:39:05 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 12 Nov 2014 07:39:05 -0800
Subject: [R] factor levels > numeric values
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FB1E51@mb02.ads.tamu.edu>
References: <CAA1twZRqtMM74_ZpSx+a0TdTivrfiVTd30FwcBN6Wg29BtiLRA@mail.gmail.com>
	<Pine.SOC.4.64.1411121504520.16032@solcom.hrz.uni-giessen.de>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FB1E51@mb02.ads.tamu.edu>
Message-ID: <18648BDF-6F6A-4A06-B307-797836F84281@dcn.davis.CA.us>

Another approach is to re-import your data using options that do not put the data into a factor in the first place.  For example you can use the colClasses parameter in the read.table family of functions to specify "numeric" for that column. If you need to give special handling to that column anyway (using strong functions) then you can use the stringsAsFactors=FALSE or as.is=TRUE parameter settings and avoid the as.character() band-aid in your code.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 12, 2014 6:56:11 AM PST, David L Carlson <dcarlson at tamu.edu> wrote:
>Also look at the Frequently Asked Questions document that comes with
>your R installation:
>
>7.10 How do I convert factors to numeric?
>
>It may happen that when reading numeric data into R (usually, when
>reading in a file), they come in as factors. If f is such a factor
>object, you can use
>
>as.numeric(as.character(f))
>
>to get the numbers back. More efficient, but harder to remember, is
>
>as.numeric(levels(f))[as.integer(f)]
>
>In any case, do not call as.numeric() or their likes directly for the
>task at hand (as as.numeric() or unclass() give the internal codes).
>
>-------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77840-4352
>
>-----Original Message-----
>From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org] On Behalf Of Gerrit Eichner
>Sent: Wednesday, November 12, 2014 8:06 AM
>To: David Studer
>Cc: r-help at r-project.org
>Subject: Re: [R] factor levels > numeric values
>
>Hello, David,
>
>take a look at the beginning of the "Warning" section of ?factor.
>
>  Hth  --  Gerrit
>
>> Hi everybody,
>>
>> I have another question (to which I could not find an answer in my
>r-books.
>> I am sure, it's not a great issue, but I simply lack of a good idea
>how to
>> solve this:
>>
>> One of my variables gets imported as a factor instead of a numeric
>variable.
>> Now I have a...
>> Factor w/ 63 levels "0","0.02","0.03",..: 1 NA NA 1 NA NA 1 1 53 10
>...
>>
>> How can I transform these factor levels into actual values?
>>
>> Thank you very much for any help!
>> David
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Nov 12 16:47:00 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 12 Nov 2014 15:47:00 +0000
Subject: [R] R memory issues
In-Reply-To: <20141112101821.31864@web001.roc2.bluetie.com>
References: <20141112101821.31864@web001.roc2.bluetie.com>
Message-ID: <546380F4.40003@stats.ox.ac.uk>

On 12/11/2014 15:18, ce wrote:
> you may try to increase virtual memory :
>
> http://windows.microsoft.com/en-us/windows/change-virtual-memory-size#1TC=windows-7

That is a very low plausibility for the error.  See the discussion in 
the FAQ: 
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-uses_0021 
and the discussion of fragmentation in ?"Memory-limits" .

As others have said: get a 64-bit OS -- the only 32-bit one I have seen 
for several years now is on an old Windows sub-notebook with an Atom CPU.

>
> -----Original Message-----
> From: "eliza botto" [eliza_botto at hotmail.com]
> Date: 11/11/2014 02:35 PM
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] R memory issues
>
> Dear useRs,
> I have this funny thing going on with me since morning. I am 32 bit window 7 system with 4 GB RAM(2.95 usable). I tried to run a code on it but when I tried to convert dataframe to matrix by using the following code
> mat<-matrix(as.numeric(unlist(SFI)),nrow=nrow(SFI))
> *where SFI is my dataframe.
> an error came up, "Error: cannot allocate vector of size 237.3 Mb"
> I tried to increase memory by using memory.limit(2500) but to no effect.
> Kindly help me out on it as you always do.
> Thanks,
> Eliza 		 	   		
> 	[[alternative HTML version deleted]]
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From martin.canon at gmail.com  Wed Nov 12 13:59:17 2014
From: martin.canon at gmail.com (Martin Canon)
Date: Wed, 12 Nov 2014 07:59:17 -0500
Subject: [R] tapply error svyby function "survey" package
Message-ID: <CAD3qanCPiqGk_U7hcsa3VpHdfq449Z156BjS2Hvj8LkM+phXBQ@mail.gmail.com>

Hi.


I'm trying to calculate the weighted mean score of a quality of life
measure (ovt) in patients with irritable bowel syndrome by their
marital status (d7).

This is a summary of the structure of the dataset:

> str(sii.tesis)
'data.frame':    1063 obs. of  75 variables:
 $ id         : int  51 52 53 54 55 56 57 58 59 60 ...
 $ stratum    : Factor w/ 6 levels "MEst","MAcad",..: 1 4 NA 4 4 1 6 NA 4 4 ...
 $ expfc      : num  22.8 17.1 NA 17.1 17.1 ...
 $ d6         : Factor w/ 3 levels "Estudiante","Profesor",..: 1 1 NA
1 1 1 3 NA 1 1 ...
 $ d7         : Factor w/ 6 levels "Soltero","Casado",..: 1 1 NA 1 1 1
1 NA 1 1 ...
 $ d7c        : Factor w/ 2 levels "No estable","Estable": 1 1 NA 1 1
1 1 NA 1 1 ...
 $ s1cm       : Factor w/ 2 levels "No","Si": 1 2 NA 1 1 1 2 NA 1 1 ...
 $ ovt        : num  NA 93.4 NA NA NA ...

I declared the sampling design:

> sii.design <- svydesign(
  id = ~1,
  strata = ~stratum,
  weights = ~expfc,
  data = subset(sii.tesis, !is.na(stratum)))

Then I tried to get the result:

> svyby(~ovt, ~d7, sii.design, svymean, na.rm = TRUE, level = 0.95)

but i get the error:

Error in tapply(1:NROW(x), list(factor(strata)), function(index) { :
  arguments must have same length


The length of both variables is the same. If the variable ovt exists,
there is a d7 match in the data frame.

I try the same thing using another variable instead - "role" (d6) -
and it works.

> svyby(~ovt, ~d6, sii.design, svymean, na.rm = TRUE, level = 0.95)
                           d6      ovt       se
Estudiante         Estudiante 71.01805 1.370569
Profesor             Profesor 72.30923 6.518378
Administrativo Administrativo 75.69102 3.715050

If I use the recategorized d7 variable (d7c,  two levels only) it works too:

> svyby(~ovt, ~d7c, sii.design, svymean, na.rm = TRUE, level = 0.95)
                  d7c      ovt      se
No estable No estable 70.92344 1.37460
Estable       Estable 74.53719 4.16954


What could be the problem?


Regards.


Martin Canon
Colombia, South America


From ajdamico at gmail.com  Wed Nov 12 19:39:00 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Wed, 12 Nov 2014 13:39:00 -0500
Subject: [R] tapply error svyby function "survey" package
In-Reply-To: <CAD3qanCPiqGk_U7hcsa3VpHdfq449Z156BjS2Hvj8LkM+phXBQ@mail.gmail.com>
References: <CAD3qanCPiqGk_U7hcsa3VpHdfq449Z156BjS2Hvj8LkM+phXBQ@mail.gmail.com>
Message-ID: <CAOwvMDw13o4PMRbNfgEozdWXzsNL2HN=21ihh4tgbjhYPz4cVg@mail.gmail.com>

try resetting your levels?  if that doesn't work, please dput() an example
data set that we can test with :) thanks!

sii.design <- update( sii.design , d6 = factor( d6 ) )






On Wed, Nov 12, 2014 at 7:59 AM, Martin Canon <martin.canon at gmail.com>
wrote:

> Hi.
>
>
> I'm trying to calculate the weighted mean score of a quality of life
> measure (ovt) in patients with irritable bowel syndrome by their
> marital status (d7).
>
> This is a summary of the structure of the dataset:
>
> > str(sii.tesis)
> 'data.frame':    1063 obs. of  75 variables:
>  $ id         : int  51 52 53 54 55 56 57 58 59 60 ...
>  $ stratum    : Factor w/ 6 levels "MEst","MAcad",..: 1 4 NA 4 4 1 6 NA 4
> 4 ...
>  $ expfc      : num  22.8 17.1 NA 17.1 17.1 ...
>  $ d6         : Factor w/ 3 levels "Estudiante","Profesor",..: 1 1 NA
> 1 1 1 3 NA 1 1 ...
>  $ d7         : Factor w/ 6 levels "Soltero","Casado",..: 1 1 NA 1 1 1
> 1 NA 1 1 ...
>  $ d7c        : Factor w/ 2 levels "No estable","Estable": 1 1 NA 1 1
> 1 1 NA 1 1 ...
>  $ s1cm       : Factor w/ 2 levels "No","Si": 1 2 NA 1 1 1 2 NA 1 1 ...
>  $ ovt        : num  NA 93.4 NA NA NA ...
>
> I declared the sampling design:
>
> > sii.design <- svydesign(
>   id = ~1,
>   strata = ~stratum,
>   weights = ~expfc,
>   data = subset(sii.tesis, !is.na(stratum)))
>
> Then I tried to get the result:
>
> > svyby(~ovt, ~d7, sii.design, svymean, na.rm = TRUE, level = 0.95)
>
> but i get the error:
>
> Error in tapply(1:NROW(x), list(factor(strata)), function(index) { :
>   arguments must have same length
>
>
> The length of both variables is the same. If the variable ovt exists,
> there is a d7 match in the data frame.
>
> I try the same thing using another variable instead - "role" (d6) -
> and it works.
>
> > svyby(~ovt, ~d6, sii.design, svymean, na.rm = TRUE, level = 0.95)
>                            d6      ovt       se
> Estudiante         Estudiante 71.01805 1.370569
> Profesor             Profesor 72.30923 6.518378
> Administrativo Administrativo 75.69102 3.715050
>
> If I use the recategorized d7 variable (d7c,  two levels only) it works
> too:
>
> > svyby(~ovt, ~d7c, sii.design, svymean, na.rm = TRUE, level = 0.95)
>                   d7c      ovt      se
> No estable No estable 70.92344 1.37460
> Estable       Estable 74.53719 4.16954
>
>
> What could be the problem?
>
>
> Regards.
>
>
> Martin Canon
> Colombia, South America
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kamil.barton at o2.pl  Wed Nov 12 20:19:56 2014
From: kamil.barton at o2.pl (=?UTF-8?B?S2FtaWwgQmFydG/FhA==?=)
Date: Wed, 12 Nov 2014 20:19:56 +0100
Subject: [R] Submodel selection using dredge and gam (mgcv)
In-Reply-To: <CANkFkEfe+8nmxcFEN=yEjcuQ3n5Apdfftq2W7FdGZ77kSCKMgg@mail.gmail.com>
References: <CANkFkEftjMT1QNihMQsSFMpwdGTwY3gSFdO+4x9+WQbgK2QNig@mail.gmail.com>	<5461D2D6.80002@o2.pl>
	<CANkFkEfe+8nmxcFEN=yEjcuQ3n5Apdfftq2W7FdGZ77kSCKMgg@mail.gmail.com>
Message-ID: <5463B2DC.70905@o2.pl>

Hi Arnaud,
please read ?dredge -> "Details" -> "Subsetting", where this is explained.


On 2014-11-12 15:19, Arnaud Mosnier wrote:
> Hi Kamil,
>
> Thanks for your answer. In fact, I already tried something with
> operators in such a way you advise, but it seems more complicated due to
> the use of the s() and ti() operators.
>
> Can you provide a solution for the following example ?
>
> library(mgcv)
> set.seed(2)
> dat <- gamSim(1,n=400,dist="normal",scale=2)
>
> bt <- gam(y~s(x0)+s(x1)+ti(x0,x1), data=dat,method="ML")
>
> library(MuMIn)
>
> # this does not work
> dredge(bt, subset = (!(x0,x1) | (x0 & x1)))
> dredge(bt, subset = (!ti(x0,x1) | (s(x0) & s(x1))))
>
> Cheers,
>
> Arnaud
>
>
> 2014-11-11 4:11 GMT-05:00 Kamil Barto? <kamil.barton at o2.pl
> <mailto:kamil.barton at o2.pl>>:
>
>     Hi Arnaud,
>     your question has in fact nothing to do with gam or model selection.
>     What you are asking is: what is the logical expression that yields
>     True when AB is False or both A and B are True. Now replace the
>     words with operators (!AB | (A & B)) and voil?.
>
>     See also:
>     help("Logic", "base")
>     fortunes::fortune(350)
>
>     best,
>     kamil
>
>
>
>     On 2014-11-10 21:26, Arnaud Mosnier wrote:
>
>         Hi,
>
>         I want to use dredge to test several gam submodels including
>         interactions.
>         I tried to find a way in order to keep models with interaction
>         only if
>         the single variables occurring in the interaction are also included.
>
>         i.e.: for
>            y~s(x0)+s(x1)+ti(x0, x1)
>
>         I want to keep
>         y ~ s(x0)
>         y ~ s(x1)
>         y ~ s(x0) + s(x1)
>         y ~ s(x0) + s(x1) + ti(x0,x1)
>
>         and I want to remove
>
>         y ~ s(x0) + ti(x0,x1)
>         y ~ s(x1) + ti(x0,x1)
>         y ~ ti(x0,x1)
>
>
>         I know that I should use the "subset" option of the dredge function.
>         However, I can not find the correct matrix / expression to
>         obtain what I
>         need !
>
>
>         Here a small example.
>
>         ################
>
>         # Create some data (use mgcv example)
>         library(mgcv)
>         set.seed(2)
>         dat <- gamSim(1,n=400,dist="normal",__scale=2)
>
>         # Create the global gam model
>         # Here a model with interaction. Note the use of ti()
>         bt <- gam(y~s(x0)+s(x1)+s(x2)+s(x3)+__ti(x1,x2),
>         data=dat,method="ML")
>
>         # Use dredge to test sub-models
>         library(MuMIn)
>         print(modstab <- dredge(bt))
>
>         # Here the 11th model include the interaction but do not include the
>         single variables x1 and x2
>         # ... I want to avoid that kind of model.
>         get.models(modstab, subset = 11)
>
>         ################
>
>
>         Any help would be appreciated !
>
>         Arnaud
>
>
>


From ajdamico at gmail.com  Wed Nov 12 23:39:00 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Wed, 12 Nov 2014 17:39:00 -0500
Subject: [R] tapply error svyby function "survey" package
In-Reply-To: <CAD3qanCe55X6r4CZ70F2v=EQG3my_L+Rv9s5A-QSBnuu9d+h_g@mail.gmail.com>
References: <CAD3qanCPiqGk_U7hcsa3VpHdfq449Z156BjS2Hvj8LkM+phXBQ@mail.gmail.com>
	<CAOwvMDw13o4PMRbNfgEozdWXzsNL2HN=21ihh4tgbjhYPz4cVg@mail.gmail.com>
	<CAD3qanCe55X6r4CZ70F2v=EQG3my_L+Rv9s5A-QSBnuu9d+h_g@mail.gmail.com>
Message-ID: <CAOwvMDzg4gQyp+Kmsja5eHaC7naQoZNDhDR80YCY9UVK4CYppQ@mail.gmail.com>

hi martin, sending the first 25 rows does not help if it does not re-create
the problem..  when i run the data you have provided, i do not encounter
your problem (see below).  someone else may be able to guess the issue, but
this would be a lot easier to solve if you can create a minimal
reproducible example

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


sii.tesis <-
structure(list(id = c(51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L,
59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L,
73L, 74L, 75L, 76L), stratum = structure(c(1L, 4L, NA, 4L, 4L,
1L, 6L, NA, 4L, 4L, 1L, 1L, 1L, 6L, 6L, 3L, 3L, 6L, NA, 1L, 1L,
6L, 4L, 3L, 6L), .Label = c("MEst", "MAcad", "MAdm", "FEst",
"FAcad", "FAdm"), class = "factor"), expfc = c(22.8195266723633,
17.0644626617432, NA, 17.0644626617432, 17.0644626617432, 22.8195266723633,
5.1702127456665, NA, 17.0644626617432, 17.0644626617432, 22.8195266723633,
22.8195266723633, 22.8195266723633, 5.1702127456665, 5.1702127456665,
6.24137926101685, 6.24137926101685, 5.1702127456665, NA, 22.8195266723633,
22.8195266723633, 5.1702127456665, 17.0644626617432, 6.24137926101685,
5.1702127456665), d7 = structure(c(1L, 1L, NA, 1L, 1L, 1L, 1L,
NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, NA, 1L, 1L, 6L, 1L,
6L, 6L), .Label = c("Soltero", "Casado", "Separado", "Divorciado",
"Viudo", "Union libre"), class = "factor"), ovt = c(NA, 93.3823547363281,
NA, NA, NA, NA, 83.8235321044922, NA, NA, NA, NA, NA, NA, NA,
79.4117660522461, NA, NA, 19.1176471710205, NA, NA, NA, 85.2941207885742,
NA, NA, NA)), .Names = c("id", "stratum", "expfc", "d7", "ovt"
), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
"10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
"21", "22", "23", "24", "25"), class = "data.frame")

 sii.design <- svydesign(
  id = ~1,
  strata = ~stratum,
  weights = ~expfc,
  data = subset(sii.tesis, !is.na(stratum)))

svyby(~ovt, ~d7, sii.design, svymean, na.rm = TRUE, level = 0.95)


# works fine---
> svyby(~ovt, ~d7, sii.design, svymean, na.rm = TRUE, level = 0.95)
                     d7      ovt       se
Soltero         Soltero 88.94329 3.333485
Casado           Casado 19.11765 0.000000
Union libre Union libre 85.29412 0.000000






On Wed, Nov 12, 2014 at 5:25 PM, Martin Canon <martin.canon at gmail.com>
wrote:

> Anthony, thanks for your reply.
>
> Resetting the levels didn't work.
>
> These are the first 25 rows of the dataset:
>
> structure(list(id = c(51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L,
> 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L,
> 73L, 74L, 75L, 76L), stratum = structure(c(1L, 4L, NA, 4L, 4L,
> 1L, 6L, NA, 4L, 4L, 1L, 1L, 1L, 6L, 6L, 3L, 3L, 6L, NA, 1L, 1L,
> 6L, 4L, 3L, 6L), .Label = c("MEst", "MAcad", "MAdm", "FEst",
> "FAcad", "FAdm"), class = "factor"), expfc = c(22.8195266723633,
> 17.0644626617432, NA, 17.0644626617432, 17.0644626617432, 22.8195266723633,
> 5.1702127456665, NA, 17.0644626617432, 17.0644626617432, 22.8195266723633,
> 22.8195266723633, 22.8195266723633, 5.1702127456665, 5.1702127456665,
> 6.24137926101685, 6.24137926101685, 5.1702127456665, NA, 22.8195266723633,
> 22.8195266723633, 5.1702127456665, 17.0644626617432, 6.24137926101685,
> 5.1702127456665), d7 = structure(c(1L, 1L, NA, 1L, 1L, 1L, 1L,
> NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, NA, 1L, 1L, 6L, 1L,
> 6L, 6L), .Label = c("Soltero", "Casado", "Separado", "Divorciado",
> "Viudo", "Union libre"), class = "factor"), ovt = c(NA, 93.3823547363281,
> NA, NA, NA, NA, 83.8235321044922, NA, NA, NA, NA, NA, NA, NA,
> 79.4117660522461, NA, NA, 19.1176471710205, NA, NA, NA, 85.2941207885742,
> NA, NA, NA)), .Names = c("id", "stratum", "expfc", "d7", "ovt"
> ), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
> "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
> "21", "22", "23", "24", "25"), class = "data.frame")
>
> Regards.
>
> Martin
>
> On Wed, Nov 12, 2014 at 1:39 PM, Anthony Damico <ajdamico at gmail.com>
> wrote:
> > try resetting your levels?  if that doesn't work, please dput() an
> example
> > data set that we can test with :) thanks!
> >
> > sii.design <- update( sii.design , d6 = factor( d6 ) )
> >
> >
> >
> >
> >
> >
> > On Wed, Nov 12, 2014 at 7:59 AM, Martin Canon <martin.canon at gmail.com>
> > wrote:
> >>
> >> Hi.
> >>
> >>
> >> I'm trying to calculate the weighted mean score of a quality of life
> >> measure (ovt) in patients with irritable bowel syndrome by their
> >> marital status (d7).
> >>
> >> This is a summary of the structure of the dataset:
> >>
> >> > str(sii.tesis)
> >> 'data.frame':    1063 obs. of  75 variables:
> >>  $ id         : int  51 52 53 54 55 56 57 58 59 60 ...
> >>  $ stratum    : Factor w/ 6 levels "MEst","MAcad",..: 1 4 NA 4 4 1 6 NA
> 4
> >> 4 ...
> >>  $ expfc      : num  22.8 17.1 NA 17.1 17.1 ...
> >>  $ d6         : Factor w/ 3 levels "Estudiante","Profesor",..: 1 1 NA
> >> 1 1 1 3 NA 1 1 ...
> >>  $ d7         : Factor w/ 6 levels "Soltero","Casado",..: 1 1 NA 1 1 1
> >> 1 NA 1 1 ...
> >>  $ d7c        : Factor w/ 2 levels "No estable","Estable": 1 1 NA 1 1
> >> 1 1 NA 1 1 ...
> >>  $ s1cm       : Factor w/ 2 levels "No","Si": 1 2 NA 1 1 1 2 NA 1 1 ...
> >>  $ ovt        : num  NA 93.4 NA NA NA ...
> >>
> >> I declared the sampling design:
> >>
> >> > sii.design <- svydesign(
> >>   id = ~1,
> >>   strata = ~stratum,
> >>   weights = ~expfc,
> >>   data = subset(sii.tesis, !is.na(stratum)))
> >>
> >> Then I tried to get the result:
> >>
> >> > svyby(~ovt, ~d7, sii.design, svymean, na.rm = TRUE, level = 0.95)
> >>
> >> but i get the error:
> >>
> >> Error in tapply(1:NROW(x), list(factor(strata)), function(index) { :
> >>   arguments must have same length
> >>
> >>
> >> The length of both variables is the same. If the variable ovt exists,
> >> there is a d7 match in the data frame.
> >>
> >> I try the same thing using another variable instead - "role" (d6) -
> >> and it works.
> >>
> >> > svyby(~ovt, ~d6, sii.design, svymean, na.rm = TRUE, level = 0.95)
> >>                            d6      ovt       se
> >> Estudiante         Estudiante 71.01805 1.370569
> >> Profesor             Profesor 72.30923 6.518378
> >> Administrativo Administrativo 75.69102 3.715050
> >>
> >> If I use the recategorized d7 variable (d7c,  two levels only) it works
> >> too:
> >>
> >> > svyby(~ovt, ~d7c, sii.design, svymean, na.rm = TRUE, level = 0.95)
> >>                   d7c      ovt      se
> >> No estable No estable 70.92344 1.37460
> >> Estable       Estable 74.53719 4.16954
> >>
> >>
> >> What could be the problem?
> >>
> >>
> >> Regards.
> >>
> >>
> >> Martin Canon
> >> Colombia, South America
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Nov 13 01:26:49 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 13 Nov 2014 00:26:49 +0000
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <545FAD62.10101@yahoo.fr>
References: <545FAD62.10101@yahoo.fr>
Message-ID: <D08939DD.112043%macqueen1@llnl.gov>

Along the lines of what Bert Gunter said, the ideal way to represent <LDL
results depends on the functions used later to analyze them. I deal with
such data on a daily basis and have never found it necessary to
incorporate that information in the same variable as the results. What
would you do if data were censored at both ends, both low and high?

Anyway, the functions I use mostly incorporate that information in a
second variable, a ?detection indicator? variable, and that?s what I do.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/9/14, 10:07 AM, "Marc Girondot" <marc_grt at yahoo.fr> wrote:

>Dear member list,
>
>In many experimental sciences, there is a lower detection limit (LDL)
>when a dosage of a product is done. Then some samples are evaluated to
>be below this limit.
>I search for the best way to indicate in a data.frame that some values
>are such LDL. Ideally, an equivalent of NA would be the best.
>Until now I manage by indicating all the column in characters.
>So the question is: is it possible to define a value that could be named
>LDL and that could take place in vectors or data.frame such as:
>v <- c(0.2, 0.28, LDL, 0.9) is the same way that NA can be used.
>with of course a function is.ldl(v) that would return F F T F
>
>Thanks a lot for any direction to solve this
>
>Marc
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pmaclean2011 at yahoo.com  Thu Nov 13 04:01:26 2014
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Wed, 12 Nov 2014 19:01:26 -0800
Subject: [R] Synthestic Control Methods for Causal Inference
In-Reply-To: <mailman.23.1415790009.26085.r-help@r-project.org>
References: <mailman.23.1415790009.26085.r-help@r-project.org>
Message-ID: <1415847686.57405.YahooMailNeo@web122403.mail.ne1.yahoo.com>

I am interested in conducting causal inference using synthetic control method using R where there are multiple treated units/regions. The current synth package allows only one treated unit to be compared to other (several) synthetic units. In my case, I have 5 treated units and 35 untreated units. Is there any package I have missed? I am currently doing a sequential analysis comparing each treated unit to the 35 untreated units. I would like to get a composite result. Any help will be appreciated.
 
Sincerely,

Peter Maclean
Department of Economics
UDSM


From a.mosnier at gmail.com  Wed Nov 12 21:43:58 2014
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Wed, 12 Nov 2014 15:43:58 -0500
Subject: [R] Submodel selection using dredge and gam (mgcv)
In-Reply-To: <5463B2DC.70905@o2.pl>
References: <CANkFkEftjMT1QNihMQsSFMpwdGTwY3gSFdO+4x9+WQbgK2QNig@mail.gmail.com>
	<5461D2D6.80002@o2.pl>
	<CANkFkEfe+8nmxcFEN=yEjcuQ3n5Apdfftq2W7FdGZ77kSCKMgg@mail.gmail.com>
	<5463B2DC.70905@o2.pl>
Message-ID: <CANkFkEdgjBpA4xsZvO1CqbkV5_p9Qy8c9e1pYS2kcJbV3MYa4w@mail.gmail.com>

Argh ! Ok ... my fault ... the use of back-ticks was the solution !!!
Thanks,

Arnaud

2014-11-12 14:19 GMT-05:00 Kamil Barto? <kamil.barton at o2.pl>:

> Hi Arnaud,
> please read ?dredge -> "Details" -> "Subsetting", where this is explained.
>
>
> On 2014-11-12 15:19, Arnaud Mosnier wrote:
>
>> Hi Kamil,
>>
>> Thanks for your answer. In fact, I already tried something with
>> operators in such a way you advise, but it seems more complicated due to
>> the use of the s() and ti() operators.
>>
>> Can you provide a solution for the following example ?
>>
>> library(mgcv)
>> set.seed(2)
>> dat <- gamSim(1,n=400,dist="normal",scale=2)
>>
>> bt <- gam(y~s(x0)+s(x1)+ti(x0,x1), data=dat,method="ML")
>>
>> library(MuMIn)
>>
>> # this does not work
>> dredge(bt, subset = (!(x0,x1) | (x0 & x1)))
>> dredge(bt, subset = (!ti(x0,x1) | (s(x0) & s(x1))))
>>
>> Cheers,
>>
>> Arnaud
>>
>>
>> 2014-11-11 4:11 GMT-05:00 Kamil Barto? <kamil.barton at o2.pl
>> <mailto:kamil.barton at o2.pl>>:
>>
>>
>>     Hi Arnaud,
>>     your question has in fact nothing to do with gam or model selection.
>>     What you are asking is: what is the logical expression that yields
>>     True when AB is False or both A and B are True. Now replace the
>>     words with operators (!AB | (A & B)) and voil?.
>>
>>     See also:
>>     help("Logic", "base")
>>     fortunes::fortune(350)
>>
>>     best,
>>     kamil
>>
>>
>>
>>     On 2014-11-10 21:26, Arnaud Mosnier wrote:
>>
>>         Hi,
>>
>>         I want to use dredge to test several gam submodels including
>>         interactions.
>>         I tried to find a way in order to keep models with interaction
>>         only if
>>         the single variables occurring in the interaction are also
>> included.
>>
>>         i.e.: for
>>            y~s(x0)+s(x1)+ti(x0, x1)
>>
>>         I want to keep
>>         y ~ s(x0)
>>         y ~ s(x1)
>>         y ~ s(x0) + s(x1)
>>         y ~ s(x0) + s(x1) + ti(x0,x1)
>>
>>         and I want to remove
>>
>>         y ~ s(x0) + ti(x0,x1)
>>         y ~ s(x1) + ti(x0,x1)
>>         y ~ ti(x0,x1)
>>
>>
>>         I know that I should use the "subset" option of the dredge
>> function.
>>         However, I can not find the correct matrix / expression to
>>         obtain what I
>>         need !
>>
>>
>>         Here a small example.
>>
>>         ################
>>
>>         # Create some data (use mgcv example)
>>         library(mgcv)
>>         set.seed(2)
>>         dat <- gamSim(1,n=400,dist="normal",__scale=2)
>>
>>         # Create the global gam model
>>         # Here a model with interaction. Note the use of ti()
>>         bt <- gam(y~s(x0)+s(x1)+s(x2)+s(x3)+__ti(x1,x2),
>>         data=dat,method="ML")
>>
>>         # Use dredge to test sub-models
>>         library(MuMIn)
>>         print(modstab <- dredge(bt))
>>
>>         # Here the 11th model include the interaction but do not include
>> the
>>         single variables x1 and x2
>>         # ... I want to avoid that kind of model.
>>         get.models(modstab, subset = 11)
>>
>>         ################
>>
>>
>>         Any help would be appreciated !
>>
>>         Arnaud
>>
>>
>>
>>
>

	[[alternative HTML version deleted]]


From martin.canon at gmail.com  Wed Nov 12 23:25:51 2014
From: martin.canon at gmail.com (Martin Canon)
Date: Wed, 12 Nov 2014 17:25:51 -0500
Subject: [R] tapply error svyby function "survey" package
In-Reply-To: <CAOwvMDw13o4PMRbNfgEozdWXzsNL2HN=21ihh4tgbjhYPz4cVg@mail.gmail.com>
References: <CAD3qanCPiqGk_U7hcsa3VpHdfq449Z156BjS2Hvj8LkM+phXBQ@mail.gmail.com>
	<CAOwvMDw13o4PMRbNfgEozdWXzsNL2HN=21ihh4tgbjhYPz4cVg@mail.gmail.com>
Message-ID: <CAD3qanCe55X6r4CZ70F2v=EQG3my_L+Rv9s5A-QSBnuu9d+h_g@mail.gmail.com>

Anthony, thanks for your reply.

Resetting the levels didn't work.

These are the first 25 rows of the dataset:

structure(list(id = c(51L, 52L, 53L, 54L, 55L, 56L, 57L, 58L,
59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 71L,
73L, 74L, 75L, 76L), stratum = structure(c(1L, 4L, NA, 4L, 4L,
1L, 6L, NA, 4L, 4L, 1L, 1L, 1L, 6L, 6L, 3L, 3L, 6L, NA, 1L, 1L,
6L, 4L, 3L, 6L), .Label = c("MEst", "MAcad", "MAdm", "FEst",
"FAcad", "FAdm"), class = "factor"), expfc = c(22.8195266723633,
17.0644626617432, NA, 17.0644626617432, 17.0644626617432, 22.8195266723633,
5.1702127456665, NA, 17.0644626617432, 17.0644626617432, 22.8195266723633,
22.8195266723633, 22.8195266723633, 5.1702127456665, 5.1702127456665,
6.24137926101685, 6.24137926101685, 5.1702127456665, NA, 22.8195266723633,
22.8195266723633, 5.1702127456665, 17.0644626617432, 6.24137926101685,
5.1702127456665), d7 = structure(c(1L, 1L, NA, 1L, 1L, 1L, 1L,
NA, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, NA, 1L, 1L, 6L, 1L,
6L, 6L), .Label = c("Soltero", "Casado", "Separado", "Divorciado",
"Viudo", "Union libre"), class = "factor"), ovt = c(NA, 93.3823547363281,
NA, NA, NA, NA, 83.8235321044922, NA, NA, NA, NA, NA, NA, NA,
79.4117660522461, NA, NA, 19.1176471710205, NA, NA, NA, 85.2941207885742,
NA, NA, NA)), .Names = c("id", "stratum", "expfc", "d7", "ovt"
), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
"10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
"21", "22", "23", "24", "25"), class = "data.frame")

Regards.

Martin

On Wed, Nov 12, 2014 at 1:39 PM, Anthony Damico <ajdamico at gmail.com> wrote:
> try resetting your levels?  if that doesn't work, please dput() an example
> data set that we can test with :) thanks!
>
> sii.design <- update( sii.design , d6 = factor( d6 ) )
>
>
>
>
>
>
> On Wed, Nov 12, 2014 at 7:59 AM, Martin Canon <martin.canon at gmail.com>
> wrote:
>>
>> Hi.
>>
>>
>> I'm trying to calculate the weighted mean score of a quality of life
>> measure (ovt) in patients with irritable bowel syndrome by their
>> marital status (d7).
>>
>> This is a summary of the structure of the dataset:
>>
>> > str(sii.tesis)
>> 'data.frame':    1063 obs. of  75 variables:
>>  $ id         : int  51 52 53 54 55 56 57 58 59 60 ...
>>  $ stratum    : Factor w/ 6 levels "MEst","MAcad",..: 1 4 NA 4 4 1 6 NA 4
>> 4 ...
>>  $ expfc      : num  22.8 17.1 NA 17.1 17.1 ...
>>  $ d6         : Factor w/ 3 levels "Estudiante","Profesor",..: 1 1 NA
>> 1 1 1 3 NA 1 1 ...
>>  $ d7         : Factor w/ 6 levels "Soltero","Casado",..: 1 1 NA 1 1 1
>> 1 NA 1 1 ...
>>  $ d7c        : Factor w/ 2 levels "No estable","Estable": 1 1 NA 1 1
>> 1 1 NA 1 1 ...
>>  $ s1cm       : Factor w/ 2 levels "No","Si": 1 2 NA 1 1 1 2 NA 1 1 ...
>>  $ ovt        : num  NA 93.4 NA NA NA ...
>>
>> I declared the sampling design:
>>
>> > sii.design <- svydesign(
>>   id = ~1,
>>   strata = ~stratum,
>>   weights = ~expfc,
>>   data = subset(sii.tesis, !is.na(stratum)))
>>
>> Then I tried to get the result:
>>
>> > svyby(~ovt, ~d7, sii.design, svymean, na.rm = TRUE, level = 0.95)
>>
>> but i get the error:
>>
>> Error in tapply(1:NROW(x), list(factor(strata)), function(index) { :
>>   arguments must have same length
>>
>>
>> The length of both variables is the same. If the variable ovt exists,
>> there is a d7 match in the data frame.
>>
>> I try the same thing using another variable instead - "role" (d6) -
>> and it works.
>>
>> > svyby(~ovt, ~d6, sii.design, svymean, na.rm = TRUE, level = 0.95)
>>                            d6      ovt       se
>> Estudiante         Estudiante 71.01805 1.370569
>> Profesor             Profesor 72.30923 6.518378
>> Administrativo Administrativo 75.69102 3.715050
>>
>> If I use the recategorized d7 variable (d7c,  two levels only) it works
>> too:
>>
>> > svyby(~ovt, ~d7c, sii.design, svymean, na.rm = TRUE, level = 0.95)
>>                   d7c      ovt      se
>> No estable No estable 70.92344 1.37460
>> Estable       Estable 74.53719 4.16954
>>
>>
>> What could be the problem?
>>
>>
>> Regards.
>>
>>
>> Martin Canon
>> Colombia, South America
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From mmuurr at gmail.com  Thu Nov 13 06:02:18 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Wed, 12 Nov 2014 22:02:18 -0700
Subject: [R] subset drops S3 classes?
Message-ID: <CA+YV+Hy0JDnjyMTCZV2m1jZAzZWnbtzW16cckPzt-ejwi4jqaQ@mail.gmail.com>

Hi all --- I've stumbled upon some pretty annoying behavior, and I'm
curious how others may have gotten around it.
When using subset(...) on a data frame that contains a custom S3
field, the class is dropped in the result:

> MyClass <- function(x) structure(x, class = "MyClass")

> df <- data.frame(x = 1:10, y = 10:1)
> df$x <- MyClass(df$x)
> str(df)
 'data.frame':   10 obs. of  2 variables:
  $ x:Class 'MyClass'  int [1:10] 1 2 3 4 5 6 7 8 9 10
  $ y: int  10 9 8 7 6 5 4 3 2 1
> str(subset(df, x %% 2 == 0))
 'data.frame':   5 obs. of  2 variables:
  $ x: int  2 4 6 8 10
  $ y: int  9 7 5 3 1

And so, any generic functions hooked to MyClass suddenly don't work on
the subset results, but do work on the original data frame.
I think I could write a custom as.data.frame.MyClass for all such
classes, but this is annoying, indeed (and I don't know for sure if
that's a robust solution)
Wrapping in I(...) doesn't work, either:

> df <- data.frame(x = 1:10, y = 10:1)
> df$x <- I(MyClass(df$x))
> str(df)
 'data.frame':   10 obs. of  2 variables:
  $ x:Classes 'AsIs', 'MyClass'  int [1:10] 1 2 3 4 5 6 7 8 9 10
  $ y: int  10 9 8 7 6 5 4 3 2 1
> str(subset(df, x %% 2 == 0))
  'data.frame':   5 obs. of  2 variables:
  $ x:Class 'AsIs'  int [1:5] 2 4 6 8 10
  $ y: int  9 7 5 3 1

(note that while 'AsIs' is kept, 'MyClass' has been removed in $x)

Cheers!

-Murat


From mmuurr at gmail.com  Thu Nov 13 07:02:38 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Wed, 12 Nov 2014 23:02:38 -0700
Subject: [R] subset drops S3 classes?
In-Reply-To: <CA+YV+Hy0JDnjyMTCZV2m1jZAzZWnbtzW16cckPzt-ejwi4jqaQ@mail.gmail.com>
References: <CA+YV+Hy0JDnjyMTCZV2m1jZAzZWnbtzW16cckPzt-ejwi4jqaQ@mail.gmail.com>
Message-ID: <CA+YV+HyQpPy7JVFG-P_EraTbAuM8gXstTJAUdMzHz04Lu__zWA@mail.gmail.com>

And as a follow-up, I implemented a barebones as.data.frame.MyClass(...).
It works when dealing with non-subsetted data frames, but fails upon a
subset(...) call:

> as.data.frame.MyClass <- function(x, ...) as.data.frame.vector(x, ...)

This works for a single column, e.g.:

> str(data.frame(MyClass(1:10)))
 'data.frame':   10 obs. of  1 variable:
  $ MyClass.1.10.:Class 'MyClass'  int [1:10] 1 2 3 4 5 6 7 8 9 10

But not during a subset:

> str(subset(data.frame(x = MyClass(1:10)), x %% 2 == 0))
'data.frame':   5 obs. of  1 variable:
 $ x: int  2 4 6 8 10

-Murat


On Wed, Nov 12, 2014 at 10:02 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> Hi all --- I've stumbled upon some pretty annoying behavior, and I'm
> curious how others may have gotten around it.
> When using subset(...) on a data frame that contains a custom S3
> field, the class is dropped in the result:
>
>> MyClass <- function(x) structure(x, class = "MyClass")
>
>> df <- data.frame(x = 1:10, y = 10:1)
>> df$x <- MyClass(df$x)
>> str(df)
>  'data.frame':   10 obs. of  2 variables:
>   $ x:Class 'MyClass'  int [1:10] 1 2 3 4 5 6 7 8 9 10
>   $ y: int  10 9 8 7 6 5 4 3 2 1
>> str(subset(df, x %% 2 == 0))
>  'data.frame':   5 obs. of  2 variables:
>   $ x: int  2 4 6 8 10
>   $ y: int  9 7 5 3 1
>
> And so, any generic functions hooked to MyClass suddenly don't work on
> the subset results, but do work on the original data frame.
> I think I could write a custom as.data.frame.MyClass for all such
> classes, but this is annoying, indeed (and I don't know for sure if
> that's a robust solution)
> Wrapping in I(...) doesn't work, either:
>
>> df <- data.frame(x = 1:10, y = 10:1)
>> df$x <- I(MyClass(df$x))
>> str(df)
>  'data.frame':   10 obs. of  2 variables:
>   $ x:Classes 'AsIs', 'MyClass'  int [1:10] 1 2 3 4 5 6 7 8 9 10
>   $ y: int  10 9 8 7 6 5 4 3 2 1
>> str(subset(df, x %% 2 == 0))
>   'data.frame':   5 obs. of  2 variables:
>   $ x:Class 'AsIs'  int [1:5] 2 4 6 8 10
>   $ y: int  9 7 5 3 1
>
> (note that while 'AsIs' is kept, 'MyClass' has been removed in $x)
>
> Cheers!
>
> -Murat


From mmuurr at gmail.com  Thu Nov 13 07:21:17 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Wed, 12 Nov 2014 23:21:17 -0700
Subject: [R] subset drops S3 classes?
In-Reply-To: <CA+YV+HyQpPy7JVFG-P_EraTbAuM8gXstTJAUdMzHz04Lu__zWA@mail.gmail.com>
References: <CA+YV+Hy0JDnjyMTCZV2m1jZAzZWnbtzW16cckPzt-ejwi4jqaQ@mail.gmail.com>
	<CA+YV+HyQpPy7JVFG-P_EraTbAuM8gXstTJAUdMzHz04Lu__zWA@mail.gmail.com>
Message-ID: <CA+YV+HyN1BPp-XtNQYSJfeWoJ6v_AqxaQcviErpe6MVMuPZ1OQ@mail.gmail.com>

... aaaand nevermind, figured it out (from the final example on the
Extract.data.frame page):

`[.MyClass` <- function(x, i, ...) {
    NextMethod("[")
    mostattributes(RV) <- attribute(x)
    RV
}

cheers,

-m

On Wed, Nov 12, 2014 at 11:02 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> And as a follow-up, I implemented a barebones as.data.frame.MyClass(...).
> It works when dealing with non-subsetted data frames, but fails upon a
> subset(...) call:
>
>> as.data.frame.MyClass <- function(x, ...) as.data.frame.vector(x, ...)
>
> This works for a single column, e.g.:
>
>> str(data.frame(MyClass(1:10)))
>  'data.frame':   10 obs. of  1 variable:
>   $ MyClass.1.10.:Class 'MyClass'  int [1:10] 1 2 3 4 5 6 7 8 9 10
>
> But not during a subset:
>
>> str(subset(data.frame(x = MyClass(1:10)), x %% 2 == 0))
> 'data.frame':   5 obs. of  1 variable:
>  $ x: int  2 4 6 8 10
>
> -Murat
>
>
> On Wed, Nov 12, 2014 at 10:02 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>> Hi all --- I've stumbled upon some pretty annoying behavior, and I'm
>> curious how others may have gotten around it.
>> When using subset(...) on a data frame that contains a custom S3
>> field, the class is dropped in the result:
>>
>>> MyClass <- function(x) structure(x, class = "MyClass")
>>
>>> df <- data.frame(x = 1:10, y = 10:1)
>>> df$x <- MyClass(df$x)
>>> str(df)
>>  'data.frame':   10 obs. of  2 variables:
>>   $ x:Class 'MyClass'  int [1:10] 1 2 3 4 5 6 7 8 9 10
>>   $ y: int  10 9 8 7 6 5 4 3 2 1
>>> str(subset(df, x %% 2 == 0))
>>  'data.frame':   5 obs. of  2 variables:
>>   $ x: int  2 4 6 8 10
>>   $ y: int  9 7 5 3 1
>>
>> And so, any generic functions hooked to MyClass suddenly don't work on
>> the subset results, but do work on the original data frame.
>> I think I could write a custom as.data.frame.MyClass for all such
>> classes, but this is annoying, indeed (and I don't know for sure if
>> that's a robust solution)
>> Wrapping in I(...) doesn't work, either:
>>
>>> df <- data.frame(x = 1:10, y = 10:1)
>>> df$x <- I(MyClass(df$x))
>>> str(df)
>>  'data.frame':   10 obs. of  2 variables:
>>   $ x:Classes 'AsIs', 'MyClass'  int [1:10] 1 2 3 4 5 6 7 8 9 10
>>   $ y: int  10 9 8 7 6 5 4 3 2 1
>>> str(subset(df, x %% 2 == 0))
>>   'data.frame':   5 obs. of  2 variables:
>>   $ x:Class 'AsIs'  int [1:5] 2 4 6 8 10
>>   $ y: int  9 7 5 3 1
>>
>> (note that while 'AsIs' is kept, 'MyClass' has been removed in $x)
>>
>> Cheers!
>>
>> -Murat


From rhelpmaillist at 163.com  Thu Nov 13 07:49:10 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 13 Nov 2014 14:49:10 +0800 (CST)
Subject: [R]   problem when using gmailr
Message-ID: <635defb3.b50e.149a7e9b039.Coremail.rhelpmaillist@163.com>


Dear expeRts,
Hi, when i using gmailr through Rscript ?got the following error :
oauth_listener() needs an interactive environment
But when i using the Rstudio it worked.
Does the function?gmail_auth(filepath,"full") support the Rscript way ??
I need run it in a windows schdual task. TKS?







--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From ed.purssell at kcl.ac.uk  Thu Nov 13 12:00:46 2014
From: ed.purssell at kcl.ac.uk (Purssell, Ed)
Date: Thu, 13 Nov 2014 11:00:46 +0000
Subject: [R] metafor - code for analysing geometric means
Message-ID: <1415876433556.77087@kcl.ac.uk>

?Dear All


I have some data expressed in geometric means and 95% confidence intervals.  Can I code them in metafor as:


rma(m1i=geometric mean 1, m2i=geometric mean 2, sd1i=geometric mean 1 CI /3.92, sd2i=geometric mean 2 CI/3.92.......etc, measure="MD")

All of the studies use geometric means.


Thanks!


Edward

 ----------------------------


	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Thu Nov 13 12:08:03 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 13 Nov 2014 12:08:03 +0100
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <D08939DD.112043%macqueen1@llnl.gov>
References: <545FAD62.10101@yahoo.fr> <D08939DD.112043%macqueen1@llnl.gov>
Message-ID: <54649113.8060701@yahoo.fr>

Le 13/11/2014 01:26, MacQueen, Don a ?crit :
> Along the lines of what Bert Gunter said, the ideal way to represent <LDL
> results depends on the functions used later to analyze them. I deal with
> such data on a daily basis and have never found it necessary to
> incorporate that information in the same variable as the results. What
> would you do if data were censored at both ends, both low and high?
>
> Anyway, the functions I use mostly incorporate that information in a
> second variable, a ?detection indicator? variable, and that?s what I do.
>
> -Don
>
I agree that LDL is a special case of what could be named ODL (Out of 
detection limit).
To answer to Bert Gunter, indeed if LDL (or ODL) values are changed into 
NA, the results will be biased. That's why I would like to introduce 
another category. I don't plan to just transform them as NA.

But thinking again about this problem, a LDL must be always associated 
with one value (or two in the case of ODL) that indicates the detection 
limit. In a dataset, all values have not necessarily the same limit 
depending on the experimental conditions.
The best solution that I find is to use attributes to indicate the 
limits. A NA attribute for a NA value will be treated as a "true" NA.
For exemple:

 > values <- c(NA, 29, 30, NA, 3)
 > attributes(values) <- list(ODL=c(NA, "[10, 40]", "[0, 40]", "[0, 
40]", "[0, 40]"))
 > values
[1] NA 29 30 NA  3
attr(,"ODL")
[1] NA         "[10, 40]" "[0, 40]"  "[0, 40]"  "[0, 40]"
 > values[3]
[1] 30
 > attributes(values)$ODL[3]
[1] "[0, 40]"
 > values[1]
[1] NA
 > attributes(values)$ODL[1]
[1] NA

The attributes are retained in data.frame. So it seems to be a good 
solution.

 > essai <- data.frame(c1=values)
 > essai
   c1
1 NA
2 29
3 30
4 NA
5  3
 > essai$c1
[1] NA 29 30 NA  3
attr(,"ODL")
[1] NA         "[10, 40]" "[0, 40]"  "[0, 40]"  "[0, 40]"

Thanks to the list members,

Marc


From info at aghmed.fsnet.co.uk  Thu Nov 13 12:35:38 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 13 Nov 2014 11:35:38 +0000
Subject: [R] metafor - code for analysing geometric means
In-Reply-To: <1415876433556.77087@kcl.ac.uk>
References: <1415876433556.77087@kcl.ac.uk>
Message-ID: <5464978A.3060902@aghmed.fsnet.co.uk>



On 13/11/2014 11:00, Purssell, Ed wrote:
> ?Dear All
>
>
> I have some data expressed in geometric means and 95% confidence intervals.  Can I code them in metafor as:
>
>
> rma(m1i=geometric mean 1, m2i=geometric mean 2, sd1i=geometric mean 1 CI /3.92, sd2i=geometric mean 2 CI/3.92.......etc, measure="MD")
>
Would it not be better to work on the log scale?

> All of the studies use geometric means.
>
>
> Thanks!
>
>
> Edward
>
>   ----------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5557 / Virus Database: 4213/8565 - Release Date: 11/13/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From Keith.Jewell at campdenbri.co.uk  Thu Nov 13 16:17:19 2014
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Thu, 13 Nov 2014 15:17:19 +0000
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <54649113.8060701@yahoo.fr>
References: <545FAD62.10101@yahoo.fr> <D08939DD.112043%macqueen1@llnl.gov>
	<54649113.8060701@yahoo.fr>
Message-ID: <m42i1v$k6b$1@ger.gmane.org>

On 13/11/2014 11:08, Marc Girondot wrote:
> Le 13/11/2014 01:26, MacQueen, Don a ?crit :
>> Along the lines of what Bert Gunter said, the ideal way to represent <LDL
>> results depends on the functions used later to analyze them. I deal with
>> such data on a daily basis and have never found it necessary to
>> incorporate that information in the same variable as the results. What
>> would you do if data were censored at both ends, both low and high?
>>
>> Anyway, the functions I use mostly incorporate that information in a
>> second variable, a ?detection indicator? variable, and that?s what I do.
>>
>> -Don
>>
> I agree that LDL is a special case of what could be named ODL (Out of
> detection limit).
> To answer to Bert Gunter, indeed if LDL (or ODL) values are changed into
> NA, the results will be biased. That's why I would like to introduce
> another category. I don't plan to just transform them as NA.
>
> But thinking again about this problem, a LDL must be always associated
> with one value (or two in the case of ODL) that indicates the detection
> limit. In a dataset, all values have not necessarily the same limit
> depending on the experimental conditions.
> The best solution that I find is to use attributes to indicate the
> limits. A NA attribute for a NA value will be treated as a "true" NA.
> For exemple:
>
>  > values <- c(NA, 29, 30, NA, 3)
>  > attributes(values) <- list(ODL=c(NA, "[10, 40]", "[0, 40]", "[0,
> 40]", "[0, 40]"))
>  > values
> [1] NA 29 30 NA  3
> attr(,"ODL")
> [1] NA         "[10, 40]" "[0, 40]"  "[0, 40]"  "[0, 40]"
>  > values[3]
> [1] 30
>  > attributes(values)$ODL[3]
> [1] "[0, 40]"
>  > values[1]
> [1] NA
>  > attributes(values)$ODL[1]
> [1] NA
>
> The attributes are retained in data.frame. So it seems to be a good
> solution.
>
>  > essai <- data.frame(c1=values)
>  > essai
>    c1
> 1 NA
> 2 29
> 3 30
> 4 NA
> 5  3
>  > essai$c1
> [1] NA 29 30 NA  3
> attr(,"ODL")
> [1] NA         "[10, 40]" "[0, 40]"  "[0, 40]"  "[0, 40]"
>
> Thanks to the list members,
>
> Marc
>
I strongly recommend you re-read and take action on Bert Gunter's 
comment, quoted here for truth!
-----------------------------
Ouch!

The values are **NOT** missing -- they are (left) censored, and need
to be handled by appropriate censored data methods. I suggest you
(all!) either read up on this or consult someone locally who has
knowledge of such methods.

-- Bert
------------------------
You are re-inventing the wheel and yours will probably end up square!
R already has facilities for handling censored data, e.g. Surv in the 
survival package (which despite its name is applicable to applications 
other than survival analysis).


From pdalgd at gmail.com  Thu Nov 13 16:29:35 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 13 Nov 2014 16:29:35 +0100
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <m42i1v$k6b$1@ger.gmane.org>
References: <545FAD62.10101@yahoo.fr> <D08939DD.112043%macqueen1@llnl.gov>
	<54649113.8060701@yahoo.fr> <m42i1v$k6b$1@ger.gmane.org>
Message-ID: <AE8CB0F7-08B9-4EA7-A79D-680FCE7D3767@gmail.com>

As you may know already, that design can be considerably improved by making the wheel triangular, reducing the bump count per revolution by a full 25% 

-pd

On 13 Nov 2014, at 16:17 , Keith Jewell <Keith.Jewell at campdenbri.co.uk> wrote:

> You are re-inventing the wheel and yours will probably end up square!

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rshepard at appl-ecosys.com  Thu Nov 13 16:46:16 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 13 Nov 2014 07:46:16 -0800
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <m42i1v$k6b$1@ger.gmane.org>
References: <545FAD62.10101@yahoo.fr> <D08939DD.112043%macqueen1@llnl.gov>
	<54649113.8060701@yahoo.fr> <m42i1v$k6b$1@ger.gmane.org>
Message-ID: <alpine.LNX.2.11.1411130745210.30805@localhost>

On Thu, 13 Nov 2014, Keith Jewell wrote:

> You are re-inventing the wheel and yours will probably end up square!
> R already has facilities for handling censored data, e.g. Surv in the 
> survival package (which despite its name is applicable to applications other 
> than survival analysis).

   There is also the NADA package that provides several approaches for
handling left-censored data.

Rich


From rshepard at appl-ecosys.com  Thu Nov 13 16:47:24 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 13 Nov 2014 07:47:24 -0800
Subject: [R] Is it possible to define another kind of NA
In-Reply-To: <AE8CB0F7-08B9-4EA7-A79D-680FCE7D3767@gmail.com>
References: <545FAD62.10101@yahoo.fr> <D08939DD.112043%macqueen1@llnl.gov>
	<54649113.8060701@yahoo.fr> <m42i1v$k6b$1@ger.gmane.org>
	<AE8CB0F7-08B9-4EA7-A79D-680FCE7D3767@gmail.com>
Message-ID: <alpine.LNX.2.11.1411130746480.30805@localhost>

On Thu, 13 Nov 2014, peter dalgaard wrote:

> As you may know already, that design can be considerably improved by
> making the wheel triangular, reducing the bump count per revolution by a
> full 25%

   It has been written that those who go around in circles think of
themselves as big wheels.

Rich


From mikeumo at gmail.com  Thu Nov 13 16:59:51 2014
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Thu, 13 Nov 2014 09:59:51 -0600
Subject: [R] How to put inlined C code on a worker node?
Message-ID: <2A9F55B0-90D4-4826-9E32-5B80DF42DCF7@gmail.com>

Hello ?

I am using inline C functions within foreach %dopar% loop. On SMP (doParallel, doMP) it works but on MPI-based clusters (doMPI) it does?t. The reason, I think, is because the object code produced using the inline package, essentially an .so file, does not get copied onto the worker nodes when they are spawned using startMPIcluster().

Does anyone have any ideas on how I can send the object code to the workers and re-link it to the inline functions, or some other way? I know that I can define the inline functions within the foreach loop but it is very limiting and does not look pretty when you have a lot of functions to define. So, is there I way that follows a good programming style?

I would prefer to do it from within the R script and use the ?spawning? mode to paralellize.

Thank you for your time, 

Mikhail.

From clwaka at yahoo.com  Thu Nov 13 11:50:28 2014
From: clwaka at yahoo.com (Cox Lwaka)
Date: Thu, 13 Nov 2014 10:50:28 +0000 (UTC)
Subject: [R] hi
Message-ID: <1148352248.253403.1415875828989.JavaMail.yahoo@jws100139.mail.ne1.yahoo.com>

I have a bit of trouble here to program in r. I am anew user but i really enjoy working with it.I have a large number of variables in a matrix that are arranged sequentially on a line (chromosome). This order has to be maintained whatsoever. I am to develop an r algorithm that will develop groups as follows;i) Calculate the correlation between successive variables and correlation matrix for all the variables
ii) if r(i) is the maximum correlation coefficient in the successive variable correlation then my first group has variables [x(i-k ), ...x(i),... x(i+k )]. this gives me group one of size 2k+1. note that variables are picked on that line and order is maintained.iii) we check for remaining correlation btn successive variables relative to the bigger correlation matrix and select? other groups. these groups don't need to be of same size and they must not overlap.i will have divided in to disjoint groups but maintaining the order.kindly assist me see how i can get this done, thanks

	[[alternative HTML version deleted]]


From franck.vermet at univ-brest.fr  Thu Nov 13 12:54:49 2014
From: franck.vermet at univ-brest.fr (Franck Vermet)
Date: Thu, 13 Nov 2014 12:54:49 +0100
Subject: [R] number of weights in multinom
Message-ID: <94619031-9FD8-4450-B150-CAC1197929B4@univ-brest.fr>

Dear colleagues,

In the function multinom (package nnet), I get the following message after training for a model with 9 inputs and 6 classes (output) :

# weights:  66 (50 variable)

I understand that there are 50 variables in the model,
but I don't understand the number 66. 
How can we interpret this number ?

Thank you very much.

Yours sincerely,
Franck Vermet.


From Matthias.Weber at fntsoftware.com  Thu Nov 13 15:02:29 2014
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Thu, 13 Nov 2014 15:02:29 +0100
Subject: [R] merge 2 data.frames in dependence of 2 values
Message-ID: <7E39CF5278A2C948968C39502CF451020174CEADF37C@mail.ell.fnt.de>

Hello togehter,

i have a little problem. Maybe anyone can help me.

I have 2 data.frames, which look like as follows:
First:

        NAME    MONTH     BONUS
1      Andy     2014-10       100
2      Pete     2014-10        200
3      Marc    2014-10        300
4      Andy    2014-11        400

Second:

      NAME  MONTH    BONUS_2
1    Andy    2014-10       150
2    Pete     2014-11       180
3    Jason   2014-10       190
4    Paul     2014-10       210
5    Andy    2014-11       30

How can I merge this 2 data.frames, if I want the following result:

        NAME    MONTH     BONUS    BONUS_2
1     Andy     2014-10       100            150
2     Pete     2014-11                         180
3     Marc    2014-10        300
4     Andy    2014-11       400             30
5     Pete     2014-10       200
6     Jason  2014-10                         190
7     Paul     2014-10                         210

The important thing is, that for every accordance in the Columns "NAME" and "MONTH" I get a new line.

Thanks for your help.

Best regards.

Mat

________________________________
This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.

	[[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Thu Nov 13 18:24:35 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 13 Nov 2014 17:24:35 +0000
Subject: [R] merge 2 data.frames in dependence of 2 values
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF37C@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF37C@mail.ell.fnt.de>
Message-ID: <5464E953.3020202@aghmed.fsnet.co.uk>



On 13/11/2014 14:02, Matthias Weber wrote:
> Hello togehter,
>
> i have a little problem. Maybe anyone can help me.

I think you might find
?merge
enlightening

Indeed given that the word merge occurs in your subject line and your 
text it is surprising you have not already found it.

>
> I have 2 data.frames, which look like as follows:
> First:
>
>          NAME    MONTH     BONUS
> 1      Andy     2014-10       100
> 2      Pete     2014-10        200
> 3      Marc    2014-10        300
> 4      Andy    2014-11        400
>
> Second:
>
>        NAME  MONTH    BONUS_2
> 1    Andy    2014-10       150
> 2    Pete     2014-11       180
> 3    Jason   2014-10       190
> 4    Paul     2014-10       210
> 5    Andy    2014-11       30
>
> How can I merge this 2 data.frames, if I want the following result:
>
>          NAME    MONTH     BONUS    BONUS_2
> 1     Andy     2014-10       100            150
> 2     Pete     2014-11                         180
> 3     Marc    2014-10        300
> 4     Andy    2014-11       400             30
> 5     Pete     2014-10       200
> 6     Jason  2014-10                         190
> 7     Paul     2014-10                         210
>
> The important thing is, that for every accordance in the Columns "NAME" and "MONTH" I get a new line.
>
> Thanks for your help.
>
> Best regards.
>
> Mat
>
> ________________________________
> This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.
>
> Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5557 / Virus Database: 4213/8566 - Release Date: 11/13/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From ruipbarradas at sapo.pt  Thu Nov 13 18:45:58 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 13 Nov 2014 17:45:58 +0000
Subject: [R] merge 2 data.frames in dependence of 2 values
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF37C@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF37C@mail.ell.fnt.de>
Message-ID: <5464EE56.2080204@sapo.pt>

Hello,

See ?merge, in particular the argument 'all'.

dat1 <- read.table(text = "
         NAME    MONTH     BONUS
1      Andy     2014-10       100
2      Pete     2014-10        200
3      Marc    2014-10        300
4      Andy    2014-11        400
", header = TRUE, stringsAsFactors = FALSE)


dat2 <- read.table(text = "
       NAME  MONTH    BONUS_2
1    Andy    2014-10       150
2    Pete     2014-11       180
3    Jason   2014-10       190
4    Paul     2014-10       210
5    Andy    2014-11       30
", header = TRUE, stringsAsFactors = FALSE)

merge(dat1, dat2, all = TRUE)


Hope this helps,

Rui Barradas

Em 13-11-2014 14:02, Matthias Weber escreveu:
> Hello togehter,
>
> i have a little problem. Maybe anyone can help me.
>
> I have 2 data.frames, which look like as follows:
> First:
>
>          NAME    MONTH     BONUS
> 1      Andy     2014-10       100
> 2      Pete     2014-10        200
> 3      Marc    2014-10        300
> 4      Andy    2014-11        400
>
> Second:
>
>        NAME  MONTH    BONUS_2
> 1    Andy    2014-10       150
> 2    Pete     2014-11       180
> 3    Jason   2014-10       190
> 4    Paul     2014-10       210
> 5    Andy    2014-11       30
>
> How can I merge this 2 data.frames, if I want the following result:
>
>          NAME    MONTH     BONUS    BONUS_2
> 1     Andy     2014-10       100            150
> 2     Pete     2014-11                         180
> 3     Marc    2014-10        300
> 4     Andy    2014-11       400             30
> 5     Pete     2014-10       200
> 6     Jason  2014-10                         190
> 7     Paul     2014-10                         210
>
> The important thing is, that for every accordance in the Columns "NAME" and "MONTH" I get a new line.
>
> Thanks for your help.
>
> Best regards.
>
> Mat
>
> ________________________________
> This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.
>
> Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Thu Nov 13 18:59:57 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 13 Nov 2014 09:59:57 -0800
Subject: [R] merge 2 data.frames in dependence of 2 values
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF37C@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF37C@mail.ell.fnt.de>
Message-ID: <CAF8bMcaX1h3Rf7SPxvQ_GHYjbHR5F7XZn0TQ8rtQ2NwoQt6nnQ@mail.gmail.com>

merge(df1, df2, all=TRUE)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 13, 2014 at 6:02 AM, Matthias Weber <
Matthias.Weber at fntsoftware.com> wrote:

> Hello togehter,
>
> i have a little problem. Maybe anyone can help me.
>
> I have 2 data.frames, which look like as follows:
> First:
>
>         NAME    MONTH     BONUS
> 1      Andy     2014-10       100
> 2      Pete     2014-10        200
> 3      Marc    2014-10        300
> 4      Andy    2014-11        400
>
> Second:
>
>       NAME  MONTH    BONUS_2
> 1    Andy    2014-10       150
> 2    Pete     2014-11       180
> 3    Jason   2014-10       190
> 4    Paul     2014-10       210
> 5    Andy    2014-11       30
>
> How can I merge this 2 data.frames, if I want the following result:
>
>         NAME    MONTH     BONUS    BONUS_2
> 1     Andy     2014-10       100            150
> 2     Pete     2014-11                         180
> 3     Marc    2014-10        300
> 4     Andy    2014-11       400             30
> 5     Pete     2014-10       200
> 6     Jason  2014-10                         190
> 7     Paul     2014-10                         210
>
> The important thing is, that for every accordance in the Columns "NAME"
> and "MONTH" I get a new line.
>
> Thanks for your help.
>
> Best regards.
>
> Mat
>
> ________________________________
> This e-mail may contain trade secrets, privileged, undisclosed or
> otherwise confidential information. If you have received this e-mail in
> error, you are hereby notified that any review, copying or distribution of
> it is strictly prohibited. Please inform us immediately and destroy the
> original transmittal. Thank you for your cooperation.
>
> Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige
> vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich
> erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine
> Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte
> benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen
> Dank.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Thu Nov 13 21:35:56 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 13 Nov 2014 21:35:56 +0100
Subject: [R] rpart package: How can I save print(rpart)
Message-ID: <CALJKBv9pgKswuz4hPX9OFDxXZwsU2T5HxOSRM9aVZmm8qR9G=Q@mail.gmail.com>

Hi,

the print of rpart fitting gives the summary of tree
 I would like to save the console text of:
 fit <- rpart(formula, data)
 summary <- print(fit)

when I look in "summary" I did not find the same thing as in


 "print(rpart)"


[1] "Clinical Data exists"
[1] "merging samples from Clinical and Profile Data"
[1] "Selected formula:  DFS_STATUS~."
n= 236

node), split, n, loss, yval, (yprob)
      * denotes terminal node

 1) root 236 58 DiseaseFree (0.21610169 0.75423729 0.02966102)
   2) PIK3CA< 302.7615 105 42 DiseaseFree (0.39047619 0.60000000
0.00952381)
     4) FGFR1< 941.6309 41 16  (0.60975610 0.36585366 0.02439024)
       8) ANXA1>=2148.882 19  3  (0.84210526 0.10526316 0.05263158) *
       9) ANXA1< 2148.882 22  9 DiseaseFree (0.40909091 0.59090909
0.00000000)
        18) RAF1< 2315.279 13  4  (0.69230769 0.30769231 0.00000000) *
        19) RAF1>=2315.279 9  0 DiseaseFree (0.00000000 1.00000000
0.00000000) *
     5) FGFR1>=941.6309 64 16 DiseaseFree (0.25000000 0.75000000
0.00000000)
      10) CDH2>=153.6887 10  2  (0.80000000 0.20000000 0.00000000) *
      11) CDH2< 153.6887 54  8 DiseaseFree (0.14814815 0.85185185
0.00000000)
        22) PCNA< 696.389 7  3  (0.57142857 0.42857143 0.00000000) *
        23) PCNA>=696.389 47  4 DiseaseFree (0.08510638 0.91489362
0.00000000) *
   3) PIK3CA>=302.7615 131 16 DiseaseFree (0.07633588 0.87786260
0.04580153) *
>
class(summary)
#rpart

summary
{list(var = c(6, 3, 1, 4, 7, 4, 4, 2, 4, 5, 4, 4, 4), n = c(236, 105, 41,
19, 22, 13, 9, 64, 10, 54, 7, 47, 131), wt = c(236, 105, 41, 19, 22, 13, 9,
64, 10, 54, 7, 47, 131), dev = c(58, 42, 16, 3, 9, 4, 0, 16, 2, 8, 3, 4,
16), yval = c(2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2), complexity =
c(0.0862068965517241, 0.0862068965517241, 0.0775862068965517, 0.01,
0.0775862068965517, 0.01, 0.01, 0.0862068965517241, 0.01,
0.0172413793103448, 0.01, 0, 0), ncompete = c(4, 4, 4, 0, 4, 0, 0, 4, 0, 4,
0, 0, 0),
    nsurrogate = c(5, 5, 5, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0), yval2 = c(2, 2,
1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 51, 41, 25, 16, 9, 9, 0, 16, 8, 8, 4, 4,
10, 178, 63, 15, 2, 13, 4, 9, 48, 2, 46, 3, 43, 115, 7, 1, 1, 1, 0, 0, 0,
0, 0, 0, 0, 0, 6, 0.216101694915254, 0.39047619047619, 0.609756097560976,
0.842105263157895, 0.409090909090909, 0.692307692307692, 0, 0.25, 0.8,
0.148148148148148, 0.571428571428571, 0.0851063829787234,
0.0763358778625954, 0.754237288135593, 0.6, 0.365853658536585,
0.105263157894737,
    0.590909090909091, 0.307692307692308, 1, 0.75, 0.2, 0.851851851851852,
0.428571428571429, 0.914893617021277, 0.877862595419847,
0.0296610169491525, 0.00952380952380952, 0.024390243902439,
0.0526315789473684, 0, 0, 0, 0, 0, 0, 0, 0, 0.0458015267175573, 1,
0.444915254237288, 0.173728813559322, 0.0805084745762712,
0.0932203389830508, 0.0550847457627119, 0.038135593220339,
0.271186440677966, 0.0423728813559322, 0.228813559322034,
0.0296610169491525, 0.199152542372881, 0.555084745762712))} {c(13, 13, 13,
12, 7, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12,
13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13,
13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
13, 13, 13, 13, 13, 13, 13, 13, 13, 6, 12, 12, 12, 6, 6, 13, 6, 13, 4, 13,
13, 13, 7, 12, 6, 12, 12, 12, 9, 4, 12, 11, 12, 12, 12, 11, 12, 12, 13, 7,
4, 12, 12, 4, 9, 7, 13, 12, 7, 12,
12, 13, 12, 13, 12, 11, 12, 13, 12, 13, 13, 13, 12, 13, 12, 13, 7, 13, 13,
12, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13,
13, 7, 13, 11, 13, 4, 7, 4, 9, 9, 13, 4, 12, 13, 13, 13, 13, 4, 13, 7, 4,
6, 12, 12, 12, 12, 12, 13, 11, 13, 6, 13, 13, 4, 12, 12, 4, 11, 12, 12, 12,
13, 13, 13, 12, 9, 9, 9, 4, 9, 4, 4, 4, 11, 13, 4, 4, 9, 12, 6, 4, 9, 4, 6,
6, 6, 6, 6, 12)} {rpart(formula = frmla, data = ProfData, method =
"class")} {DFS_STATUS ~ A1CF + ACACA + ACKR2 + AGXT + AHCYL2 + AHSA1 +
AIMP2 + AKR1B1 + AKT1 + AKT1S1 + ANO3 + ANXA1 + APOBR + AQP7 + AR +
ARHGEF26 + ARID1A + ATM + BAK1 + BAX + BCL2 + BCL2L1 + BCL2L11 + BECN1 +
BID + BIRC2 + BRAF + CASP3 + CASP7 + CASP8 + CASP9 + CAT + CAV1 + CCL15 +
CCNB1 + CCND1 + CCNE1 + CCNE2 + CDH1 + CDH2 + CDHR2 + CDHR5 + CDK1 + CDKN1A
+ CHEK1 + CHEK2 + CHST5 + CLDN7 + CLIC6 + CNTN1 + COL6A2 + COX2 + CTNNB1 +
DDR2 + DEFA6 + DIABLO + DIRAS1 + DKK3 + DNAJC22 + DVL3 + EDAR + EEF2 +
EEF2K +
    EGFR + EIF4E + EIF4EBP1 + ENGASE + ERBB2 + ERBB3 + ERC2 + ERCC1 +
ERRFI1 + ESR1 + FA2H + FAM153A + FAM184A + FGFR1 + FGGY + FN1 + FOXO3 +
GAB2 + GARS + GATA3 + GRID1 + GSK3A + GSK3B + GUCY2C + H3F3AP6 + HOMER2 +
HPGDS + HSPA1A + HSPA1B + HSPB8 + IFI27 + IGF1R + IGFBP2 + INF2 + INPP4B +
IRS1 + ITGA2 + JUN + KCNJ5 + KDR + KIAA0226L + KIT + KLK1 + KRAS + LCK +
LPAR1 + LPAR3 + MAP2K1 + MAPK1 + MAPK14 + MAPK4 + MAPK6 + MAPK8 + MAPK9 +
MAPT + MET + MOGAT3 + MRE11A + MS4A1 + MS4A2 + MSH2 + MSH6 + MTOR +
    MYC + MYH7B + NANOS3 + NCOA3 + NDRG1 + NEURL1 + NF2 + NKX2.1 + NOTCH1 +
NOTCH3 + NPPC + PARK7 + PARP1 + PCDHB11 + PCNA + PDK1 + PDPK1 + PEA15 +
PECAM1 + PGR + PIK3CA + PIK3CB + PIK3CD + PNMAL1 + PRH2 + PRKAA1 + PRKAA2 +
PRKCA + PRKCD + PSMC4 + PSMD9 + PTCH1 + PTEN + PTK2 + PXN + RAB11A + RAB25
+ RAD50 + RAD51 + RAF1 + RB1 + REG1B + RORA + RPS6 + SETD2 + SHC1 + SLC18A1
+ SLC7A8 + SMAD1 + SMAD3 + SMAD4 + SNAI1 + SRC + SSSCA1 + SSUH2 + STAT3 +
STAT5A + STK11 + STMN4 + SYK + TAZ + TCEAL1 + TGM1 +
    TGM2 + TGM3 + TGM4 + TMEM37 + TNFRSF11A + TONSL + TP53 + TP53AIP1 +
TP53BP1 + TRIL + TSC2 + TSPO2 + VASP + WWTR1 + XBP1 + XBP1P1 + XIAP + XRCC1
+ XRCC5 + YBX1 + YWHAE + YY1AP1} {c(0.0862068965517241, 0.0775862068965517,
0.0172413793103448, 0.01, 0, 3, 5, 6, 1, 0.724137931034483,
0.568965517241379, 0.551724137931034, 1, 1.22413793103448, 1.3448275862069,
1.41379310344828, 0.114035482086724, 0.121475068159872, 0.124592485529312,
0.12611980528159)} class {list(prior = c(0.216101694915254,
0.754237288135593, 0.0296610169491525), loss = c(0, 1, 1, 1, 0, 1, 1, 1,
0), split = 1)} {list(minsplit = 20, minbucket = 7, cp = 0.01, maxcompete =
4, maxsurrogate = 5, usesurrogate = 2, surrogatestyle = 0, maxdepth = 30,
xval = 10)} {list(summary = function (yval, dev, wt, ylevel, digits)
{
    nclass <- (ncol(yval) - 2)/2
    group <- yval[, 1]
    counts <- yval[, 1 + (1:nclass)]
    yprob <- yval[, 1 + nclass + 1:nclass]
    nodeprob <- yval[, 2 * nclass + 2]
    if (!is.null(ylevel))
        group <- ylevel[group]
    temp1 <- formatg(counts, format = "%5g")
    temp2 <- formatg(yprob, format = "%5.3f")
    if (nclass > 1) {
        temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse = "
")
        temp2 <- apply(matrix(temp2, ncol = nclass), 1, paste, collapse = "
")
    }
    dev <- dev/(wt[1] * nodeprob)
    paste0("  predicted class=", format(group, justify = "left"), "
expected loss=", formatg(dev, digits), "  P(node) =", formatg(nodeprob,
digits), "\n", "    class counts: ", temp1, "\n", "   probabilities: ",
temp2)
}, print = function (yval, ylevel, digits)
{
    temp <- if (is.null(ylevel))
        as.character(yval[, 1])
    else ylevel[yval[, 1]]
    nclass <- (ncol(yval) - 2)/2
    yprob <- if (nclass < 5)
        format(yval[, 1 + nclass + 1:nclass], digits = digits, nsmall =
digits)
    else formatg(yval[, 1 + nclass + 1:nclass], digits = 2)
    if (!is.matrix(yprob))
        yprob <- matrix(yprob, nrow = 1)
    temp <- paste0(temp, " (", yprob[, 1])
    for (i in 2:ncol(yprob)) temp <- paste(temp, yprob[, i], sep = " ")
    temp <- paste0(temp, ")")
    temp
}, text = function (yval, dev, wt, ylevel, digits, n, use.n)
{
    nclass <- (ncol(yval) - 2)/2
    group <- yval[, 1]
    counts <- yval[, 1 + (1:nclass)]
    if (!is.null(ylevel))
        group <- ylevel[group]
    temp1 <- formatg(counts, digits)
    if (nclass > 1)
        temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse =
"/")

.......................

How can I save print(fit)?
Thank?

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Thu Nov 13 21:49:27 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 13 Nov 2014 21:49:27 +0100
Subject: [R] rpart package: prp does not work with RStudio and R console
Message-ID: <CALJKBv-i3t+F3dUd-CPqBNqS6vCQy2tM+KM1soK9qMSbZh=86Q@mail.gmail.com>

Hi,
All  right for rpart package but it seems there is a confusion in "text"
function.

prp is not found

Error in fun() : could not find function "prp"

Thanks


  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Nov 13 21:49:22 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 13 Nov 2014 12:49:22 -0800
Subject: [R] rpart package: How can I save print(rpart)
In-Reply-To: <CALJKBv9pgKswuz4hPX9OFDxXZwsU2T5HxOSRM9aVZmm8qR9G=Q@mail.gmail.com>
References: <CALJKBv9pgKswuz4hPX9OFDxXZwsU2T5HxOSRM9aVZmm8qR9G=Q@mail.gmail.com>
Message-ID: <CAF8bMcbDOS0CDvyLfGNhzJNqCQ4tN1G+_ZpTpcKXATSVxP2r=A@mail.gmail.com>

Use capture.output(), as in
  > junk <- capture.output(summary(1:10))
  > junk
  [1] "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. "
  [2] "   1.00    3.25    5.50    5.50    7.75   10.00 "
  > cat(junk, sep="\n")
     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
     1.00    3.25    5.50    5.50    7.75   10.00



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 13, 2014 at 12:35 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Hi,
>
> the print of rpart fitting gives the summary of tree
>  I would like to save the console text of:
>  fit <- rpart(formula, data)
>  summary <- print(fit)
>
> when I look in "summary" I did not find the same thing as in
>
>
>  "print(rpart)"
>
>
> [1] "Clinical Data exists"
> [1] "merging samples from Clinical and Profile Data"
> [1] "Selected formula:  DFS_STATUS~."
> n= 236
>
> node), split, n, loss, yval, (yprob)
>       * denotes terminal node
>
>  1) root 236 58 DiseaseFree (0.21610169 0.75423729 0.02966102)
>    2) PIK3CA< 302.7615 105 42 DiseaseFree (0.39047619 0.60000000
> 0.00952381)
>      4) FGFR1< 941.6309 41 16  (0.60975610 0.36585366 0.02439024)
>        8) ANXA1>=2148.882 19  3  (0.84210526 0.10526316 0.05263158) *
>        9) ANXA1< 2148.882 22  9 DiseaseFree (0.40909091 0.59090909
> 0.00000000)
>         18) RAF1< 2315.279 13  4  (0.69230769 0.30769231 0.00000000) *
>         19) RAF1>=2315.279 9  0 DiseaseFree (0.00000000 1.00000000
> 0.00000000) *
>      5) FGFR1>=941.6309 64 16 DiseaseFree (0.25000000 0.75000000
> 0.00000000)
>       10) CDH2>=153.6887 10  2  (0.80000000 0.20000000 0.00000000) *
>       11) CDH2< 153.6887 54  8 DiseaseFree (0.14814815 0.85185185
> 0.00000000)
>         22) PCNA< 696.389 7  3  (0.57142857 0.42857143 0.00000000) *
>         23) PCNA>=696.389 47  4 DiseaseFree (0.08510638 0.91489362
> 0.00000000) *
>    3) PIK3CA>=302.7615 131 16 DiseaseFree (0.07633588 0.87786260
> 0.04580153) *
> >
> class(summary)
> #rpart
>
> summary
> {list(var = c(6, 3, 1, 4, 7, 4, 4, 2, 4, 5, 4, 4, 4), n = c(236, 105, 41,
> 19, 22, 13, 9, 64, 10, 54, 7, 47, 131), wt = c(236, 105, 41, 19, 22, 13, 9,
> 64, 10, 54, 7, 47, 131), dev = c(58, 42, 16, 3, 9, 4, 0, 16, 2, 8, 3, 4,
> 16), yval = c(2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2), complexity =
> c(0.0862068965517241, 0.0862068965517241, 0.0775862068965517, 0.01,
> 0.0775862068965517, 0.01, 0.01, 0.0862068965517241, 0.01,
> 0.0172413793103448, 0.01, 0, 0), ncompete = c(4, 4, 4, 0, 4, 0, 0, 4, 0, 4,
> 0, 0, 0),
>     nsurrogate = c(5, 5, 5, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0), yval2 = c(2, 2,
> 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 51, 41, 25, 16, 9, 9, 0, 16, 8, 8, 4, 4,
> 10, 178, 63, 15, 2, 13, 4, 9, 48, 2, 46, 3, 43, 115, 7, 1, 1, 1, 0, 0, 0,
> 0, 0, 0, 0, 0, 6, 0.216101694915254, 0.39047619047619, 0.609756097560976,
> 0.842105263157895, 0.409090909090909, 0.692307692307692, 0, 0.25, 0.8,
> 0.148148148148148, 0.571428571428571, 0.0851063829787234,
> 0.0763358778625954, 0.754237288135593, 0.6, 0.365853658536585,
> 0.105263157894737,
>     0.590909090909091, 0.307692307692308, 1, 0.75, 0.2, 0.851851851851852,
> 0.428571428571429, 0.914893617021277, 0.877862595419847,
> 0.0296610169491525, 0.00952380952380952, 0.024390243902439,
> 0.0526315789473684, 0, 0, 0, 0, 0, 0, 0, 0, 0.0458015267175573, 1,
> 0.444915254237288, 0.173728813559322, 0.0805084745762712,
> 0.0932203389830508, 0.0550847457627119, 0.038135593220339,
> 0.271186440677966, 0.0423728813559322, 0.228813559322034,
> 0.0296610169491525, 0.199152542372881, 0.555084745762712))} {c(13, 13, 13,
> 12, 7, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12,
> 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 6, 12, 12, 12, 6, 6, 13, 6, 13, 4, 13,
> 13, 13, 7, 12, 6, 12, 12, 12, 9, 4, 12, 11, 12, 12, 12, 11, 12, 12, 13, 7,
> 4, 12, 12, 4, 9, 7, 13, 12, 7, 12,
> 12, 13, 12, 13, 12, 11, 12, 13, 12, 13, 13, 13, 12, 13, 12, 13, 7, 13, 13,
> 12, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13,
> 13, 7, 13, 11, 13, 4, 7, 4, 9, 9, 13, 4, 12, 13, 13, 13, 13, 4, 13, 7, 4,
> 6, 12, 12, 12, 12, 12, 13, 11, 13, 6, 13, 13, 4, 12, 12, 4, 11, 12, 12, 12,
> 13, 13, 13, 12, 9, 9, 9, 4, 9, 4, 4, 4, 11, 13, 4, 4, 9, 12, 6, 4, 9, 4, 6,
> 6, 6, 6, 6, 12)} {rpart(formula = frmla, data = ProfData, method =
> "class")} {DFS_STATUS ~ A1CF + ACACA + ACKR2 + AGXT + AHCYL2 + AHSA1 +
> AIMP2 + AKR1B1 + AKT1 + AKT1S1 + ANO3 + ANXA1 + APOBR + AQP7 + AR +
> ARHGEF26 + ARID1A + ATM + BAK1 + BAX + BCL2 + BCL2L1 + BCL2L11 + BECN1 +
> BID + BIRC2 + BRAF + CASP3 + CASP7 + CASP8 + CASP9 + CAT + CAV1 + CCL15 +
> CCNB1 + CCND1 + CCNE1 + CCNE2 + CDH1 + CDH2 + CDHR2 + CDHR5 + CDK1 + CDKN1A
> + CHEK1 + CHEK2 + CHST5 + CLDN7 + CLIC6 + CNTN1 + COL6A2 + COX2 + CTNNB1 +
> DDR2 + DEFA6 + DIABLO + DIRAS1 + DKK3 + DNAJC22 + DVL3 + EDAR + EEF2 +
> EEF2K +
>     EGFR + EIF4E + EIF4EBP1 + ENGASE + ERBB2 + ERBB3 + ERC2 + ERCC1 +
> ERRFI1 + ESR1 + FA2H + FAM153A + FAM184A + FGFR1 + FGGY + FN1 + FOXO3 +
> GAB2 + GARS + GATA3 + GRID1 + GSK3A + GSK3B + GUCY2C + H3F3AP6 + HOMER2 +
> HPGDS + HSPA1A + HSPA1B + HSPB8 + IFI27 + IGF1R + IGFBP2 + INF2 + INPP4B +
> IRS1 + ITGA2 + JUN + KCNJ5 + KDR + KIAA0226L + KIT + KLK1 + KRAS + LCK +
> LPAR1 + LPAR3 + MAP2K1 + MAPK1 + MAPK14 + MAPK4 + MAPK6 + MAPK8 + MAPK9 +
> MAPT + MET + MOGAT3 + MRE11A + MS4A1 + MS4A2 + MSH2 + MSH6 + MTOR +
>     MYC + MYH7B + NANOS3 + NCOA3 + NDRG1 + NEURL1 + NF2 + NKX2.1 + NOTCH1 +
> NOTCH3 + NPPC + PARK7 + PARP1 + PCDHB11 + PCNA + PDK1 + PDPK1 + PEA15 +
> PECAM1 + PGR + PIK3CA + PIK3CB + PIK3CD + PNMAL1 + PRH2 + PRKAA1 + PRKAA2 +
> PRKCA + PRKCD + PSMC4 + PSMD9 + PTCH1 + PTEN + PTK2 + PXN + RAB11A + RAB25
> + RAD50 + RAD51 + RAF1 + RB1 + REG1B + RORA + RPS6 + SETD2 + SHC1 + SLC18A1
> + SLC7A8 + SMAD1 + SMAD3 + SMAD4 + SNAI1 + SRC + SSSCA1 + SSUH2 + STAT3 +
> STAT5A + STK11 + STMN4 + SYK + TAZ + TCEAL1 + TGM1 +
>     TGM2 + TGM3 + TGM4 + TMEM37 + TNFRSF11A + TONSL + TP53 + TP53AIP1 +
> TP53BP1 + TRIL + TSC2 + TSPO2 + VASP + WWTR1 + XBP1 + XBP1P1 + XIAP + XRCC1
> + XRCC5 + YBX1 + YWHAE + YY1AP1} {c(0.0862068965517241, 0.0775862068965517,
> 0.0172413793103448, 0.01, 0, 3, 5, 6, 1, 0.724137931034483,
> 0.568965517241379, 0.551724137931034, 1, 1.22413793103448, 1.3448275862069,
> 1.41379310344828, 0.114035482086724, 0.121475068159872, 0.124592485529312,
> 0.12611980528159)} class {list(prior = c(0.216101694915254,
> 0.754237288135593, 0.0296610169491525), loss = c(0, 1, 1, 1, 0, 1, 1, 1,
> 0), split = 1)} {list(minsplit = 20, minbucket = 7, cp = 0.01, maxcompete =
> 4, maxsurrogate = 5, usesurrogate = 2, surrogatestyle = 0, maxdepth = 30,
> xval = 10)} {list(summary = function (yval, dev, wt, ylevel, digits)
> {
>     nclass <- (ncol(yval) - 2)/2
>     group <- yval[, 1]
>     counts <- yval[, 1 + (1:nclass)]
>     yprob <- yval[, 1 + nclass + 1:nclass]
>     nodeprob <- yval[, 2 * nclass + 2]
>     if (!is.null(ylevel))
>         group <- ylevel[group]
>     temp1 <- formatg(counts, format = "%5g")
>     temp2 <- formatg(yprob, format = "%5.3f")
>     if (nclass > 1) {
>         temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse = "
> ")
>         temp2 <- apply(matrix(temp2, ncol = nclass), 1, paste, collapse = "
> ")
>     }
>     dev <- dev/(wt[1] * nodeprob)
>     paste0("  predicted class=", format(group, justify = "left"), "
> expected loss=", formatg(dev, digits), "  P(node) =", formatg(nodeprob,
> digits), "\n", "    class counts: ", temp1, "\n", "   probabilities: ",
> temp2)
> }, print = function (yval, ylevel, digits)
> {
>     temp <- if (is.null(ylevel))
>         as.character(yval[, 1])
>     else ylevel[yval[, 1]]
>     nclass <- (ncol(yval) - 2)/2
>     yprob <- if (nclass < 5)
>         format(yval[, 1 + nclass + 1:nclass], digits = digits, nsmall =
> digits)
>     else formatg(yval[, 1 + nclass + 1:nclass], digits = 2)
>     if (!is.matrix(yprob))
>         yprob <- matrix(yprob, nrow = 1)
>     temp <- paste0(temp, " (", yprob[, 1])
>     for (i in 2:ncol(yprob)) temp <- paste(temp, yprob[, i], sep = " ")
>     temp <- paste0(temp, ")")
>     temp
> }, text = function (yval, dev, wt, ylevel, digits, n, use.n)
> {
>     nclass <- (ncol(yval) - 2)/2
>     group <- yval[, 1]
>     counts <- yval[, 1 + (1:nclass)]
>     if (!is.null(ylevel))
>         group <- ylevel[group]
>     temp1 <- formatg(counts, digits)
>     if (nclass > 1)
>         temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse =
> "/")
>
> .......................
>
> How can I save print(fit)?
> Thank?
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Thu Nov 13 22:13:25 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 13 Nov 2014 22:13:25 +0100
Subject: [R] rpart package: How can I save print(rpart)
In-Reply-To: <CAF8bMcbDOS0CDvyLfGNhzJNqCQ4tN1G+_ZpTpcKXATSVxP2r=A@mail.gmail.com>
References: <CALJKBv9pgKswuz4hPX9OFDxXZwsU2T5HxOSRM9aVZmm8qR9G=Q@mail.gmail.com>
	<CAF8bMcbDOS0CDvyLfGNhzJNqCQ4tN1G+_ZpTpcKXATSVxP2r=A@mail.gmail.com>
Message-ID: <CALJKBv8EeH6OsPLS2RYAiYY6_UfUA_=zH0WVJr0KjQAXf7caYA@mail.gmail.com>

Yes Thanks! that works,
but I loose the \n when I would like to save or edit it.

getTextInWindows is a function that edits any text in editor.

getTextInWindows(summary): without "\n"
save (file= "junk.txt", junk):without "\n"
getTextInWindow(capture.output(cat(junk, sep = "\n"))) :No works

Thanks








  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Thu, Nov 13, 2014 at 9:49 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Use capture.output(), as in
>   > junk <- capture.output(summary(1:10))
>   > junk
>   [1] "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. "
>   [2] "   1.00    3.25    5.50    5.50    7.75   10.00 "
>   > cat(junk, sep="\n")
>      Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>      1.00    3.25    5.50    5.50    7.75   10.00
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Nov 13, 2014 at 12:35 PM, Karim Mezhoud <kmezhoud at gmail.com>
> wrote:
>
>> Hi,
>>
>> the print of rpart fitting gives the summary of tree
>>  I would like to save the console text of:
>>  fit <- rpart(formula, data)
>>  summary <- print(fit)
>>
>> when I look in "summary" I did not find the same thing as in
>>
>>
>>  "print(rpart)"
>>
>>
>> [1] "Clinical Data exists"
>> [1] "merging samples from Clinical and Profile Data"
>> [1] "Selected formula:  DFS_STATUS~."
>> n= 236
>>
>> node), split, n, loss, yval, (yprob)
>>       * denotes terminal node
>>
>>  1) root 236 58 DiseaseFree (0.21610169 0.75423729 0.02966102)
>>    2) PIK3CA< 302.7615 105 42 DiseaseFree (0.39047619 0.60000000
>> 0.00952381)
>>      4) FGFR1< 941.6309 41 16  (0.60975610 0.36585366 0.02439024)
>>        8) ANXA1>=2148.882 19  3  (0.84210526 0.10526316 0.05263158) *
>>        9) ANXA1< 2148.882 22  9 DiseaseFree (0.40909091 0.59090909
>> 0.00000000)
>>         18) RAF1< 2315.279 13  4  (0.69230769 0.30769231 0.00000000) *
>>         19) RAF1>=2315.279 9  0 DiseaseFree (0.00000000 1.00000000
>> 0.00000000) *
>>      5) FGFR1>=941.6309 64 16 DiseaseFree (0.25000000 0.75000000
>> 0.00000000)
>>       10) CDH2>=153.6887 10  2  (0.80000000 0.20000000 0.00000000) *
>>       11) CDH2< 153.6887 54  8 DiseaseFree (0.14814815 0.85185185
>> 0.00000000)
>>         22) PCNA< 696.389 7  3  (0.57142857 0.42857143 0.00000000) *
>>         23) PCNA>=696.389 47  4 DiseaseFree (0.08510638 0.91489362
>> 0.00000000) *
>>    3) PIK3CA>=302.7615 131 16 DiseaseFree (0.07633588 0.87786260
>> 0.04580153) *
>> >
>> class(summary)
>> #rpart
>>
>> summary
>> {list(var = c(6, 3, 1, 4, 7, 4, 4, 2, 4, 5, 4, 4, 4), n = c(236, 105, 41,
>> 19, 22, 13, 9, 64, 10, 54, 7, 47, 131), wt = c(236, 105, 41, 19, 22, 13,
>> 9,
>> 64, 10, 54, 7, 47, 131), dev = c(58, 42, 16, 3, 9, 4, 0, 16, 2, 8, 3, 4,
>> 16), yval = c(2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2), complexity =
>> c(0.0862068965517241, 0.0862068965517241, 0.0775862068965517, 0.01,
>> 0.0775862068965517, 0.01, 0.01, 0.0862068965517241, 0.01,
>> 0.0172413793103448, 0.01, 0, 0), ncompete = c(4, 4, 4, 0, 4, 0, 0, 4, 0,
>> 4,
>> 0, 0, 0),
>>     nsurrogate = c(5, 5, 5, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0), yval2 = c(2, 2,
>> 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 51, 41, 25, 16, 9, 9, 0, 16, 8, 8, 4, 4,
>> 10, 178, 63, 15, 2, 13, 4, 9, 48, 2, 46, 3, 43, 115, 7, 1, 1, 1, 0, 0, 0,
>> 0, 0, 0, 0, 0, 6, 0.216101694915254, 0.39047619047619, 0.609756097560976,
>> 0.842105263157895, 0.409090909090909, 0.692307692307692, 0, 0.25, 0.8,
>> 0.148148148148148, 0.571428571428571, 0.0851063829787234,
>> 0.0763358778625954, 0.754237288135593, 0.6, 0.365853658536585,
>> 0.105263157894737,
>>     0.590909090909091, 0.307692307692308, 1, 0.75, 0.2, 0.851851851851852,
>> 0.428571428571429, 0.914893617021277, 0.877862595419847,
>> 0.0296610169491525, 0.00952380952380952, 0.024390243902439,
>> 0.0526315789473684, 0, 0, 0, 0, 0, 0, 0, 0, 0.0458015267175573, 1,
>> 0.444915254237288, 0.173728813559322, 0.0805084745762712,
>> 0.0932203389830508, 0.0550847457627119, 0.038135593220339,
>> 0.271186440677966, 0.0423728813559322, 0.228813559322034,
>> 0.0296610169491525, 0.199152542372881, 0.555084745762712))} {c(13, 13, 13,
>> 12, 7, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12,
>> 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
>> 13,
>> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13,
>> 13,
>> 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13,
>> 13,
>> 13, 13, 13, 13, 13, 13, 13, 13, 13, 6, 12, 12, 12, 6, 6, 13, 6, 13, 4, 13,
>> 13, 13, 7, 12, 6, 12, 12, 12, 9, 4, 12, 11, 12, 12, 12, 11, 12, 12, 13, 7,
>> 4, 12, 12, 4, 9, 7, 13, 12, 7, 12,
>> 12, 13, 12, 13, 12, 11, 12, 13, 12, 13, 13, 13, 12, 13, 12, 13, 7, 13, 13,
>> 12, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13,
>> 13,
>> 13, 7, 13, 11, 13, 4, 7, 4, 9, 9, 13, 4, 12, 13, 13, 13, 13, 4, 13, 7, 4,
>> 6, 12, 12, 12, 12, 12, 13, 11, 13, 6, 13, 13, 4, 12, 12, 4, 11, 12, 12,
>> 12,
>> 13, 13, 13, 12, 9, 9, 9, 4, 9, 4, 4, 4, 11, 13, 4, 4, 9, 12, 6, 4, 9, 4,
>> 6,
>> 6, 6, 6, 6, 12)} {rpart(formula = frmla, data = ProfData, method =
>> "class")} {DFS_STATUS ~ A1CF + ACACA + ACKR2 + AGXT + AHCYL2 + AHSA1 +
>> AIMP2 + AKR1B1 + AKT1 + AKT1S1 + ANO3 + ANXA1 + APOBR + AQP7 + AR +
>> ARHGEF26 + ARID1A + ATM + BAK1 + BAX + BCL2 + BCL2L1 + BCL2L11 + BECN1 +
>> BID + BIRC2 + BRAF + CASP3 + CASP7 + CASP8 + CASP9 + CAT + CAV1 + CCL15 +
>> CCNB1 + CCND1 + CCNE1 + CCNE2 + CDH1 + CDH2 + CDHR2 + CDHR5 + CDK1 +
>> CDKN1A
>> + CHEK1 + CHEK2 + CHST5 + CLDN7 + CLIC6 + CNTN1 + COL6A2 + COX2 + CTNNB1 +
>> DDR2 + DEFA6 + DIABLO + DIRAS1 + DKK3 + DNAJC22 + DVL3 + EDAR + EEF2 +
>> EEF2K +
>>     EGFR + EIF4E + EIF4EBP1 + ENGASE + ERBB2 + ERBB3 + ERC2 + ERCC1 +
>> ERRFI1 + ESR1 + FA2H + FAM153A + FAM184A + FGFR1 + FGGY + FN1 + FOXO3 +
>> GAB2 + GARS + GATA3 + GRID1 + GSK3A + GSK3B + GUCY2C + H3F3AP6 + HOMER2 +
>> HPGDS + HSPA1A + HSPA1B + HSPB8 + IFI27 + IGF1R + IGFBP2 + INF2 + INPP4B +
>> IRS1 + ITGA2 + JUN + KCNJ5 + KDR + KIAA0226L + KIT + KLK1 + KRAS + LCK +
>> LPAR1 + LPAR3 + MAP2K1 + MAPK1 + MAPK14 + MAPK4 + MAPK6 + MAPK8 + MAPK9 +
>> MAPT + MET + MOGAT3 + MRE11A + MS4A1 + MS4A2 + MSH2 + MSH6 + MTOR +
>>     MYC + MYH7B + NANOS3 + NCOA3 + NDRG1 + NEURL1 + NF2 + NKX2.1 + NOTCH1
>> +
>> NOTCH3 + NPPC + PARK7 + PARP1 + PCDHB11 + PCNA + PDK1 + PDPK1 + PEA15 +
>> PECAM1 + PGR + PIK3CA + PIK3CB + PIK3CD + PNMAL1 + PRH2 + PRKAA1 + PRKAA2
>> +
>> PRKCA + PRKCD + PSMC4 + PSMD9 + PTCH1 + PTEN + PTK2 + PXN + RAB11A + RAB25
>> + RAD50 + RAD51 + RAF1 + RB1 + REG1B + RORA + RPS6 + SETD2 + SHC1 +
>> SLC18A1
>> + SLC7A8 + SMAD1 + SMAD3 + SMAD4 + SNAI1 + SRC + SSSCA1 + SSUH2 + STAT3 +
>> STAT5A + STK11 + STMN4 + SYK + TAZ + TCEAL1 + TGM1 +
>>     TGM2 + TGM3 + TGM4 + TMEM37 + TNFRSF11A + TONSL + TP53 + TP53AIP1 +
>> TP53BP1 + TRIL + TSC2 + TSPO2 + VASP + WWTR1 + XBP1 + XBP1P1 + XIAP +
>> XRCC1
>> + XRCC5 + YBX1 + YWHAE + YY1AP1} {c(0.0862068965517241,
>> 0.0775862068965517,
>> 0.0172413793103448, 0.01, 0, 3, 5, 6, 1, 0.724137931034483,
>> 0.568965517241379, 0.551724137931034, 1, 1.22413793103448,
>> 1.3448275862069,
>> 1.41379310344828, 0.114035482086724, 0.121475068159872, 0.124592485529312,
>> 0.12611980528159)} class {list(prior = c(0.216101694915254,
>> 0.754237288135593, 0.0296610169491525), loss = c(0, 1, 1, 1, 0, 1, 1, 1,
>> 0), split = 1)} {list(minsplit = 20, minbucket = 7, cp = 0.01, maxcompete
>> =
>> 4, maxsurrogate = 5, usesurrogate = 2, surrogatestyle = 0, maxdepth = 30,
>> xval = 10)} {list(summary = function (yval, dev, wt, ylevel, digits)
>> {
>>     nclass <- (ncol(yval) - 2)/2
>>     group <- yval[, 1]
>>     counts <- yval[, 1 + (1:nclass)]
>>     yprob <- yval[, 1 + nclass + 1:nclass]
>>     nodeprob <- yval[, 2 * nclass + 2]
>>     if (!is.null(ylevel))
>>         group <- ylevel[group]
>>     temp1 <- formatg(counts, format = "%5g")
>>     temp2 <- formatg(yprob, format = "%5.3f")
>>     if (nclass > 1) {
>>         temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse =
>> "
>> ")
>>         temp2 <- apply(matrix(temp2, ncol = nclass), 1, paste, collapse =
>> "
>> ")
>>     }
>>     dev <- dev/(wt[1] * nodeprob)
>>     paste0("  predicted class=", format(group, justify = "left"), "
>> expected loss=", formatg(dev, digits), "  P(node) =", formatg(nodeprob,
>> digits), "\n", "    class counts: ", temp1, "\n", "   probabilities: ",
>> temp2)
>> }, print = function (yval, ylevel, digits)
>> {
>>     temp <- if (is.null(ylevel))
>>         as.character(yval[, 1])
>>     else ylevel[yval[, 1]]
>>     nclass <- (ncol(yval) - 2)/2
>>     yprob <- if (nclass < 5)
>>         format(yval[, 1 + nclass + 1:nclass], digits = digits, nsmall =
>> digits)
>>     else formatg(yval[, 1 + nclass + 1:nclass], digits = 2)
>>     if (!is.matrix(yprob))
>>         yprob <- matrix(yprob, nrow = 1)
>>     temp <- paste0(temp, " (", yprob[, 1])
>>     for (i in 2:ncol(yprob)) temp <- paste(temp, yprob[, i], sep = " ")
>>     temp <- paste0(temp, ")")
>>     temp
>> }, text = function (yval, dev, wt, ylevel, digits, n, use.n)
>> {
>>     nclass <- (ncol(yval) - 2)/2
>>     group <- yval[, 1]
>>     counts <- yval[, 1 + (1:nclass)]
>>     if (!is.null(ylevel))
>>         group <- ylevel[group]
>>     temp1 <- formatg(counts, digits)
>>     if (nclass > 1)
>>         temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse =
>> "/")
>>
>> .......................
>>
>> How can I save print(fit)?
>> Thank?
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Nov 13 22:41:28 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 13 Nov 2014 13:41:28 -0800
Subject: [R] rpart package: How can I save print(rpart)
In-Reply-To: <CALJKBv8EeH6OsPLS2RYAiYY6_UfUA_=zH0WVJr0KjQAXf7caYA@mail.gmail.com>
References: <CALJKBv9pgKswuz4hPX9OFDxXZwsU2T5HxOSRM9aVZmm8qR9G=Q@mail.gmail.com>
	<CAF8bMcbDOS0CDvyLfGNhzJNqCQ4tN1G+_ZpTpcKXATSVxP2r=A@mail.gmail.com>
	<CALJKBv8EeH6OsPLS2RYAiYY6_UfUA_=zH0WVJr0KjQAXf7caYA@mail.gmail.com>
Message-ID: <CAF8bMcZwWyJVqOi-qgFQ0hEChX1exnbDFCDF+T5_dqxcnPeRaQ@mail.gmail.com>

Use paste(collapse="\n", junk) if you want it as a single string with \n's
in it.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 13, 2014 at 1:13 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Yes Thanks! that works,
> but I loose the \n when I would like to save or edit it.
>
> getTextInWindows is a function that edits any text in editor.
>
> getTextInWindows(summary): without "\n"
> save (file= "junk.txt", junk):without "\n"
> getTextInWindow(capture.output(cat(junk, sep = "\n"))) :No works
>
> Thanks
>
>
>
>
>
>
>
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Thu, Nov 13, 2014 at 9:49 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> Use capture.output(), as in
>>   > junk <- capture.output(summary(1:10))
>>   > junk
>>   [1] "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. "
>>   [2] "   1.00    3.25    5.50    5.50    7.75   10.00 "
>>   > cat(junk, sep="\n")
>>      Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>      1.00    3.25    5.50    5.50    7.75   10.00
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Thu, Nov 13, 2014 at 12:35 PM, Karim Mezhoud <kmezhoud at gmail.com>
>> wrote:
>>
>>> Hi,
>>>
>>> the print of rpart fitting gives the summary of tree
>>>  I would like to save the console text of:
>>>  fit <- rpart(formula, data)
>>>  summary <- print(fit)
>>>
>>> when I look in "summary" I did not find the same thing as in
>>>
>>>
>>>  "print(rpart)"
>>>
>>>
>>> [1] "Clinical Data exists"
>>> [1] "merging samples from Clinical and Profile Data"
>>> [1] "Selected formula:  DFS_STATUS~."
>>> n= 236
>>>
>>> node), split, n, loss, yval, (yprob)
>>>       * denotes terminal node
>>>
>>>  1) root 236 58 DiseaseFree (0.21610169 0.75423729 0.02966102)
>>>    2) PIK3CA< 302.7615 105 42 DiseaseFree (0.39047619 0.60000000
>>> 0.00952381)
>>>      4) FGFR1< 941.6309 41 16  (0.60975610 0.36585366 0.02439024)
>>>        8) ANXA1>=2148.882 19  3  (0.84210526 0.10526316 0.05263158) *
>>>        9) ANXA1< 2148.882 22  9 DiseaseFree (0.40909091 0.59090909
>>> 0.00000000)
>>>         18) RAF1< 2315.279 13  4  (0.69230769 0.30769231 0.00000000) *
>>>         19) RAF1>=2315.279 9  0 DiseaseFree (0.00000000 1.00000000
>>> 0.00000000) *
>>>      5) FGFR1>=941.6309 64 16 DiseaseFree (0.25000000 0.75000000
>>> 0.00000000)
>>>       10) CDH2>=153.6887 10  2  (0.80000000 0.20000000 0.00000000) *
>>>       11) CDH2< 153.6887 54  8 DiseaseFree (0.14814815 0.85185185
>>> 0.00000000)
>>>         22) PCNA< 696.389 7  3  (0.57142857 0.42857143 0.00000000) *
>>>         23) PCNA>=696.389 47  4 DiseaseFree (0.08510638 0.91489362
>>> 0.00000000) *
>>>    3) PIK3CA>=302.7615 131 16 DiseaseFree (0.07633588 0.87786260
>>> 0.04580153) *
>>> >
>>> class(summary)
>>> #rpart
>>>
>>> summary
>>> {list(var = c(6, 3, 1, 4, 7, 4, 4, 2, 4, 5, 4, 4, 4), n = c(236, 105, 41,
>>> 19, 22, 13, 9, 64, 10, 54, 7, 47, 131), wt = c(236, 105, 41, 19, 22, 13,
>>> 9,
>>> 64, 10, 54, 7, 47, 131), dev = c(58, 42, 16, 3, 9, 4, 0, 16, 2, 8, 3, 4,
>>> 16), yval = c(2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2), complexity =
>>> c(0.0862068965517241, 0.0862068965517241, 0.0775862068965517, 0.01,
>>> 0.0775862068965517, 0.01, 0.01, 0.0862068965517241, 0.01,
>>> 0.0172413793103448, 0.01, 0, 0), ncompete = c(4, 4, 4, 0, 4, 0, 0, 4, 0,
>>> 4,
>>> 0, 0, 0),
>>>     nsurrogate = c(5, 5, 5, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0), yval2 = c(2,
>>> 2,
>>> 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 51, 41, 25, 16, 9, 9, 0, 16, 8, 8, 4, 4,
>>> 10, 178, 63, 15, 2, 13, 4, 9, 48, 2, 46, 3, 43, 115, 7, 1, 1, 1, 0, 0, 0,
>>> 0, 0, 0, 0, 0, 6, 0.216101694915254, 0.39047619047619, 0.609756097560976,
>>> 0.842105263157895, 0.409090909090909, 0.692307692307692, 0, 0.25, 0.8,
>>> 0.148148148148148, 0.571428571428571, 0.0851063829787234,
>>> 0.0763358778625954, 0.754237288135593, 0.6, 0.365853658536585,
>>> 0.105263157894737,
>>>     0.590909090909091, 0.307692307692308, 1, 0.75, 0.2,
>>> 0.851851851851852,
>>> 0.428571428571429, 0.914893617021277, 0.877862595419847,
>>> 0.0296610169491525, 0.00952380952380952, 0.024390243902439,
>>> 0.0526315789473684, 0, 0, 0, 0, 0, 0, 0, 0, 0.0458015267175573, 1,
>>> 0.444915254237288, 0.173728813559322, 0.0805084745762712,
>>> 0.0932203389830508, 0.0550847457627119, 0.038135593220339,
>>> 0.271186440677966, 0.0423728813559322, 0.228813559322034,
>>> 0.0296610169491525, 0.199152542372881, 0.555084745762712))} {c(13, 13,
>>> 13,
>>> 12, 7, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
>>> 12,
>>> 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
>>> 13,
>>> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13,
>>> 13,
>>> 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13,
>>> 13,
>>> 13, 13, 13, 13, 13, 13, 13, 13, 13, 6, 12, 12, 12, 6, 6, 13, 6, 13, 4,
>>> 13,
>>> 13, 13, 7, 12, 6, 12, 12, 12, 9, 4, 12, 11, 12, 12, 12, 11, 12, 12, 13,
>>> 7,
>>> 4, 12, 12, 4, 9, 7, 13, 12, 7, 12,
>>> 12, 13, 12, 13, 12, 11, 12, 13, 12, 13, 13, 13, 12, 13, 12, 13, 7, 13,
>>> 13,
>>> 12, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13,
>>> 13,
>>> 13, 7, 13, 11, 13, 4, 7, 4, 9, 9, 13, 4, 12, 13, 13, 13, 13, 4, 13, 7, 4,
>>> 6, 12, 12, 12, 12, 12, 13, 11, 13, 6, 13, 13, 4, 12, 12, 4, 11, 12, 12,
>>> 12,
>>> 13, 13, 13, 12, 9, 9, 9, 4, 9, 4, 4, 4, 11, 13, 4, 4, 9, 12, 6, 4, 9, 4,
>>> 6,
>>> 6, 6, 6, 6, 12)} {rpart(formula = frmla, data = ProfData, method =
>>> "class")} {DFS_STATUS ~ A1CF + ACACA + ACKR2 + AGXT + AHCYL2 + AHSA1 +
>>> AIMP2 + AKR1B1 + AKT1 + AKT1S1 + ANO3 + ANXA1 + APOBR + AQP7 + AR +
>>> ARHGEF26 + ARID1A + ATM + BAK1 + BAX + BCL2 + BCL2L1 + BCL2L11 + BECN1 +
>>> BID + BIRC2 + BRAF + CASP3 + CASP7 + CASP8 + CASP9 + CAT + CAV1 + CCL15 +
>>> CCNB1 + CCND1 + CCNE1 + CCNE2 + CDH1 + CDH2 + CDHR2 + CDHR5 + CDK1 +
>>> CDKN1A
>>> + CHEK1 + CHEK2 + CHST5 + CLDN7 + CLIC6 + CNTN1 + COL6A2 + COX2 + CTNNB1
>>> +
>>> DDR2 + DEFA6 + DIABLO + DIRAS1 + DKK3 + DNAJC22 + DVL3 + EDAR + EEF2 +
>>> EEF2K +
>>>     EGFR + EIF4E + EIF4EBP1 + ENGASE + ERBB2 + ERBB3 + ERC2 + ERCC1 +
>>> ERRFI1 + ESR1 + FA2H + FAM153A + FAM184A + FGFR1 + FGGY + FN1 + FOXO3 +
>>> GAB2 + GARS + GATA3 + GRID1 + GSK3A + GSK3B + GUCY2C + H3F3AP6 + HOMER2 +
>>> HPGDS + HSPA1A + HSPA1B + HSPB8 + IFI27 + IGF1R + IGFBP2 + INF2 + INPP4B
>>> +
>>> IRS1 + ITGA2 + JUN + KCNJ5 + KDR + KIAA0226L + KIT + KLK1 + KRAS + LCK +
>>> LPAR1 + LPAR3 + MAP2K1 + MAPK1 + MAPK14 + MAPK4 + MAPK6 + MAPK8 + MAPK9 +
>>> MAPT + MET + MOGAT3 + MRE11A + MS4A1 + MS4A2 + MSH2 + MSH6 + MTOR +
>>>     MYC + MYH7B + NANOS3 + NCOA3 + NDRG1 + NEURL1 + NF2 + NKX2.1 +
>>> NOTCH1 +
>>> NOTCH3 + NPPC + PARK7 + PARP1 + PCDHB11 + PCNA + PDK1 + PDPK1 + PEA15 +
>>> PECAM1 + PGR + PIK3CA + PIK3CB + PIK3CD + PNMAL1 + PRH2 + PRKAA1 +
>>> PRKAA2 +
>>> PRKCA + PRKCD + PSMC4 + PSMD9 + PTCH1 + PTEN + PTK2 + PXN + RAB11A +
>>> RAB25
>>> + RAD50 + RAD51 + RAF1 + RB1 + REG1B + RORA + RPS6 + SETD2 + SHC1 +
>>> SLC18A1
>>> + SLC7A8 + SMAD1 + SMAD3 + SMAD4 + SNAI1 + SRC + SSSCA1 + SSUH2 + STAT3 +
>>> STAT5A + STK11 + STMN4 + SYK + TAZ + TCEAL1 + TGM1 +
>>>     TGM2 + TGM3 + TGM4 + TMEM37 + TNFRSF11A + TONSL + TP53 + TP53AIP1 +
>>> TP53BP1 + TRIL + TSC2 + TSPO2 + VASP + WWTR1 + XBP1 + XBP1P1 + XIAP +
>>> XRCC1
>>> + XRCC5 + YBX1 + YWHAE + YY1AP1} {c(0.0862068965517241,
>>> 0.0775862068965517,
>>> 0.0172413793103448, 0.01, 0, 3, 5, 6, 1, 0.724137931034483,
>>> 0.568965517241379, 0.551724137931034, 1, 1.22413793103448,
>>> 1.3448275862069,
>>> 1.41379310344828, 0.114035482086724, 0.121475068159872,
>>> 0.124592485529312,
>>> 0.12611980528159)} class {list(prior = c(0.216101694915254,
>>> 0.754237288135593, 0.0296610169491525), loss = c(0, 1, 1, 1, 0, 1, 1, 1,
>>> 0), split = 1)} {list(minsplit = 20, minbucket = 7, cp = 0.01,
>>> maxcompete =
>>> 4, maxsurrogate = 5, usesurrogate = 2, surrogatestyle = 0, maxdepth = 30,
>>> xval = 10)} {list(summary = function (yval, dev, wt, ylevel, digits)
>>> {
>>>     nclass <- (ncol(yval) - 2)/2
>>>     group <- yval[, 1]
>>>     counts <- yval[, 1 + (1:nclass)]
>>>     yprob <- yval[, 1 + nclass + 1:nclass]
>>>     nodeprob <- yval[, 2 * nclass + 2]
>>>     if (!is.null(ylevel))
>>>         group <- ylevel[group]
>>>     temp1 <- formatg(counts, format = "%5g")
>>>     temp2 <- formatg(yprob, format = "%5.3f")
>>>     if (nclass > 1) {
>>>         temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse
>>> = "
>>> ")
>>>         temp2 <- apply(matrix(temp2, ncol = nclass), 1, paste, collapse
>>> = "
>>> ")
>>>     }
>>>     dev <- dev/(wt[1] * nodeprob)
>>>     paste0("  predicted class=", format(group, justify = "left"), "
>>> expected loss=", formatg(dev, digits), "  P(node) =", formatg(nodeprob,
>>> digits), "\n", "    class counts: ", temp1, "\n", "   probabilities: ",
>>> temp2)
>>> }, print = function (yval, ylevel, digits)
>>> {
>>>     temp <- if (is.null(ylevel))
>>>         as.character(yval[, 1])
>>>     else ylevel[yval[, 1]]
>>>     nclass <- (ncol(yval) - 2)/2
>>>     yprob <- if (nclass < 5)
>>>         format(yval[, 1 + nclass + 1:nclass], digits = digits, nsmall =
>>> digits)
>>>     else formatg(yval[, 1 + nclass + 1:nclass], digits = 2)
>>>     if (!is.matrix(yprob))
>>>         yprob <- matrix(yprob, nrow = 1)
>>>     temp <- paste0(temp, " (", yprob[, 1])
>>>     for (i in 2:ncol(yprob)) temp <- paste(temp, yprob[, i], sep = " ")
>>>     temp <- paste0(temp, ")")
>>>     temp
>>> }, text = function (yval, dev, wt, ylevel, digits, n, use.n)
>>> {
>>>     nclass <- (ncol(yval) - 2)/2
>>>     group <- yval[, 1]
>>>     counts <- yval[, 1 + (1:nclass)]
>>>     if (!is.null(ylevel))
>>>         group <- ylevel[group]
>>>     temp1 <- formatg(counts, digits)
>>>     if (nclass > 1)
>>>         temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse =
>>> "/")
>>>
>>> .......................
>>>
>>> How can I save print(fit)?
>>> Thank?
>>>
>>>   ?__
>>>  c/ /'_;~~~~kmezhoud
>>> (*) \(*)   ?????  ??????
>>> http://bioinformatics.tn/
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Thu Nov 13 22:44:09 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 13 Nov 2014 22:44:09 +0100
Subject: [R] rpart package: How can I save print(rpart)
In-Reply-To: <CAF8bMcZwWyJVqOi-qgFQ0hEChX1exnbDFCDF+T5_dqxcnPeRaQ@mail.gmail.com>
References: <CALJKBv9pgKswuz4hPX9OFDxXZwsU2T5HxOSRM9aVZmm8qR9G=Q@mail.gmail.com>
	<CAF8bMcbDOS0CDvyLfGNhzJNqCQ4tN1G+_ZpTpcKXATSVxP2r=A@mail.gmail.com>
	<CALJKBv8EeH6OsPLS2RYAiYY6_UfUA_=zH0WVJr0KjQAXf7caYA@mail.gmail.com>
	<CAF8bMcZwWyJVqOi-qgFQ0hEChX1exnbDFCDF+T5_dqxcnPeRaQ@mail.gmail.com>
Message-ID: <CALJKBv99BL2r9xVa+vT8b-enXymCnqZDnbNG3vHwG1LpZos8Ww@mail.gmail.com>

OK thanks
That works.
:)

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Thu, Nov 13, 2014 at 10:41 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Use paste(collapse="\n", junk) if you want it as a single string with \n's
> in it.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Nov 13, 2014 at 1:13 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> Yes Thanks! that works,
>> but I loose the \n when I would like to save or edit it.
>>
>> getTextInWindows is a function that edits any text in editor.
>>
>> getTextInWindows(summary): without "\n"
>> save (file= "junk.txt", junk):without "\n"
>> getTextInWindow(capture.output(cat(junk, sep = "\n"))) :No works
>>
>> Thanks
>>
>>
>>
>>
>>
>>
>>
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Thu, Nov 13, 2014 at 9:49 PM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>
>>> Use capture.output(), as in
>>>   > junk <- capture.output(summary(1:10))
>>>   > junk
>>>   [1] "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. "
>>>   [2] "   1.00    3.25    5.50    5.50    7.75   10.00 "
>>>   > cat(junk, sep="\n")
>>>      Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>>      1.00    3.25    5.50    5.50    7.75   10.00
>>>
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Thu, Nov 13, 2014 at 12:35 PM, Karim Mezhoud <kmezhoud at gmail.com>
>>> wrote:
>>>
>>>> Hi,
>>>>
>>>> the print of rpart fitting gives the summary of tree
>>>>  I would like to save the console text of:
>>>>  fit <- rpart(formula, data)
>>>>  summary <- print(fit)
>>>>
>>>> when I look in "summary" I did not find the same thing as in
>>>>
>>>>
>>>>  "print(rpart)"
>>>>
>>>>
>>>> [1] "Clinical Data exists"
>>>> [1] "merging samples from Clinical and Profile Data"
>>>> [1] "Selected formula:  DFS_STATUS~."
>>>> n= 236
>>>>
>>>> node), split, n, loss, yval, (yprob)
>>>>       * denotes terminal node
>>>>
>>>>  1) root 236 58 DiseaseFree (0.21610169 0.75423729 0.02966102)
>>>>    2) PIK3CA< 302.7615 105 42 DiseaseFree (0.39047619 0.60000000
>>>> 0.00952381)
>>>>      4) FGFR1< 941.6309 41 16  (0.60975610 0.36585366 0.02439024)
>>>>        8) ANXA1>=2148.882 19  3  (0.84210526 0.10526316 0.05263158) *
>>>>        9) ANXA1< 2148.882 22  9 DiseaseFree (0.40909091 0.59090909
>>>> 0.00000000)
>>>>         18) RAF1< 2315.279 13  4  (0.69230769 0.30769231 0.00000000) *
>>>>         19) RAF1>=2315.279 9  0 DiseaseFree (0.00000000 1.00000000
>>>> 0.00000000) *
>>>>      5) FGFR1>=941.6309 64 16 DiseaseFree (0.25000000 0.75000000
>>>> 0.00000000)
>>>>       10) CDH2>=153.6887 10  2  (0.80000000 0.20000000 0.00000000) *
>>>>       11) CDH2< 153.6887 54  8 DiseaseFree (0.14814815 0.85185185
>>>> 0.00000000)
>>>>         22) PCNA< 696.389 7  3  (0.57142857 0.42857143 0.00000000) *
>>>>         23) PCNA>=696.389 47  4 DiseaseFree (0.08510638 0.91489362
>>>> 0.00000000) *
>>>>    3) PIK3CA>=302.7615 131 16 DiseaseFree (0.07633588 0.87786260
>>>> 0.04580153) *
>>>> >
>>>> class(summary)
>>>> #rpart
>>>>
>>>> summary
>>>> {list(var = c(6, 3, 1, 4, 7, 4, 4, 2, 4, 5, 4, 4, 4), n = c(236, 105,
>>>> 41,
>>>> 19, 22, 13, 9, 64, 10, 54, 7, 47, 131), wt = c(236, 105, 41, 19, 22,
>>>> 13, 9,
>>>> 64, 10, 54, 7, 47, 131), dev = c(58, 42, 16, 3, 9, 4, 0, 16, 2, 8, 3, 4,
>>>> 16), yval = c(2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2), complexity =
>>>> c(0.0862068965517241, 0.0862068965517241, 0.0775862068965517, 0.01,
>>>> 0.0775862068965517, 0.01, 0.01, 0.0862068965517241, 0.01,
>>>> 0.0172413793103448, 0.01, 0, 0), ncompete = c(4, 4, 4, 0, 4, 0, 0, 4,
>>>> 0, 4,
>>>> 0, 0, 0),
>>>>     nsurrogate = c(5, 5, 5, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0), yval2 = c(2,
>>>> 2,
>>>> 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 51, 41, 25, 16, 9, 9, 0, 16, 8, 8, 4,
>>>> 4,
>>>> 10, 178, 63, 15, 2, 13, 4, 9, 48, 2, 46, 3, 43, 115, 7, 1, 1, 1, 0, 0,
>>>> 0,
>>>> 0, 0, 0, 0, 0, 6, 0.216101694915254, 0.39047619047619,
>>>> 0.609756097560976,
>>>> 0.842105263157895, 0.409090909090909, 0.692307692307692, 0, 0.25, 0.8,
>>>> 0.148148148148148, 0.571428571428571, 0.0851063829787234,
>>>> 0.0763358778625954, 0.754237288135593, 0.6, 0.365853658536585,
>>>> 0.105263157894737,
>>>>     0.590909090909091, 0.307692307692308, 1, 0.75, 0.2,
>>>> 0.851851851851852,
>>>> 0.428571428571429, 0.914893617021277, 0.877862595419847,
>>>> 0.0296610169491525, 0.00952380952380952, 0.024390243902439,
>>>> 0.0526315789473684, 0, 0, 0, 0, 0, 0, 0, 0, 0.0458015267175573, 1,
>>>> 0.444915254237288, 0.173728813559322, 0.0805084745762712,
>>>> 0.0932203389830508, 0.0550847457627119, 0.038135593220339,
>>>> 0.271186440677966, 0.0423728813559322, 0.228813559322034,
>>>> 0.0296610169491525, 0.199152542372881, 0.555084745762712))} {c(13, 13,
>>>> 13,
>>>> 12, 7, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
>>>> 12,
>>>> 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
>>>> 13,
>>>> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13,
>>>> 13,
>>>> 13, 13, 13, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13,
>>>> 13,
>>>> 13, 13, 13, 13, 13, 13, 13, 13, 13, 6, 12, 12, 12, 6, 6, 13, 6, 13, 4,
>>>> 13,
>>>> 13, 13, 7, 12, 6, 12, 12, 12, 9, 4, 12, 11, 12, 12, 12, 11, 12, 12, 13,
>>>> 7,
>>>> 4, 12, 12, 4, 9, 7, 13, 12, 7, 12,
>>>> 12, 13, 12, 13, 12, 11, 12, 13, 12, 13, 13, 13, 12, 13, 12, 13, 7, 13,
>>>> 13,
>>>> 12, 13, 13, 13, 13, 13, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 13,
>>>> 13,
>>>> 13, 7, 13, 11, 13, 4, 7, 4, 9, 9, 13, 4, 12, 13, 13, 13, 13, 4, 13, 7,
>>>> 4,
>>>> 6, 12, 12, 12, 12, 12, 13, 11, 13, 6, 13, 13, 4, 12, 12, 4, 11, 12, 12,
>>>> 12,
>>>> 13, 13, 13, 12, 9, 9, 9, 4, 9, 4, 4, 4, 11, 13, 4, 4, 9, 12, 6, 4, 9,
>>>> 4, 6,
>>>> 6, 6, 6, 6, 12)} {rpart(formula = frmla, data = ProfData, method =
>>>> "class")} {DFS_STATUS ~ A1CF + ACACA + ACKR2 + AGXT + AHCYL2 + AHSA1 +
>>>> AIMP2 + AKR1B1 + AKT1 + AKT1S1 + ANO3 + ANXA1 + APOBR + AQP7 + AR +
>>>> ARHGEF26 + ARID1A + ATM + BAK1 + BAX + BCL2 + BCL2L1 + BCL2L11 + BECN1 +
>>>> BID + BIRC2 + BRAF + CASP3 + CASP7 + CASP8 + CASP9 + CAT + CAV1 + CCL15
>>>> +
>>>> CCNB1 + CCND1 + CCNE1 + CCNE2 + CDH1 + CDH2 + CDHR2 + CDHR5 + CDK1 +
>>>> CDKN1A
>>>> + CHEK1 + CHEK2 + CHST5 + CLDN7 + CLIC6 + CNTN1 + COL6A2 + COX2 +
>>>> CTNNB1 +
>>>> DDR2 + DEFA6 + DIABLO + DIRAS1 + DKK3 + DNAJC22 + DVL3 + EDAR + EEF2 +
>>>> EEF2K +
>>>>     EGFR + EIF4E + EIF4EBP1 + ENGASE + ERBB2 + ERBB3 + ERC2 + ERCC1 +
>>>> ERRFI1 + ESR1 + FA2H + FAM153A + FAM184A + FGFR1 + FGGY + FN1 + FOXO3 +
>>>> GAB2 + GARS + GATA3 + GRID1 + GSK3A + GSK3B + GUCY2C + H3F3AP6 + HOMER2
>>>> +
>>>> HPGDS + HSPA1A + HSPA1B + HSPB8 + IFI27 + IGF1R + IGFBP2 + INF2 +
>>>> INPP4B +
>>>> IRS1 + ITGA2 + JUN + KCNJ5 + KDR + KIAA0226L + KIT + KLK1 + KRAS + LCK +
>>>> LPAR1 + LPAR3 + MAP2K1 + MAPK1 + MAPK14 + MAPK4 + MAPK6 + MAPK8 + MAPK9
>>>> +
>>>> MAPT + MET + MOGAT3 + MRE11A + MS4A1 + MS4A2 + MSH2 + MSH6 + MTOR +
>>>>     MYC + MYH7B + NANOS3 + NCOA3 + NDRG1 + NEURL1 + NF2 + NKX2.1 +
>>>> NOTCH1 +
>>>> NOTCH3 + NPPC + PARK7 + PARP1 + PCDHB11 + PCNA + PDK1 + PDPK1 + PEA15 +
>>>> PECAM1 + PGR + PIK3CA + PIK3CB + PIK3CD + PNMAL1 + PRH2 + PRKAA1 +
>>>> PRKAA2 +
>>>> PRKCA + PRKCD + PSMC4 + PSMD9 + PTCH1 + PTEN + PTK2 + PXN + RAB11A +
>>>> RAB25
>>>> + RAD50 + RAD51 + RAF1 + RB1 + REG1B + RORA + RPS6 + SETD2 + SHC1 +
>>>> SLC18A1
>>>> + SLC7A8 + SMAD1 + SMAD3 + SMAD4 + SNAI1 + SRC + SSSCA1 + SSUH2 + STAT3
>>>> +
>>>> STAT5A + STK11 + STMN4 + SYK + TAZ + TCEAL1 + TGM1 +
>>>>     TGM2 + TGM3 + TGM4 + TMEM37 + TNFRSF11A + TONSL + TP53 + TP53AIP1 +
>>>> TP53BP1 + TRIL + TSC2 + TSPO2 + VASP + WWTR1 + XBP1 + XBP1P1 + XIAP +
>>>> XRCC1
>>>> + XRCC5 + YBX1 + YWHAE + YY1AP1} {c(0.0862068965517241,
>>>> 0.0775862068965517,
>>>> 0.0172413793103448, 0.01, 0, 3, 5, 6, 1, 0.724137931034483,
>>>> 0.568965517241379, 0.551724137931034, 1, 1.22413793103448,
>>>> 1.3448275862069,
>>>> 1.41379310344828, 0.114035482086724, 0.121475068159872,
>>>> 0.124592485529312,
>>>> 0.12611980528159)} class {list(prior = c(0.216101694915254,
>>>> 0.754237288135593, 0.0296610169491525), loss = c(0, 1, 1, 1, 0, 1, 1, 1,
>>>> 0), split = 1)} {list(minsplit = 20, minbucket = 7, cp = 0.01,
>>>> maxcompete =
>>>> 4, maxsurrogate = 5, usesurrogate = 2, surrogatestyle = 0, maxdepth =
>>>> 30,
>>>> xval = 10)} {list(summary = function (yval, dev, wt, ylevel, digits)
>>>> {
>>>>     nclass <- (ncol(yval) - 2)/2
>>>>     group <- yval[, 1]
>>>>     counts <- yval[, 1 + (1:nclass)]
>>>>     yprob <- yval[, 1 + nclass + 1:nclass]
>>>>     nodeprob <- yval[, 2 * nclass + 2]
>>>>     if (!is.null(ylevel))
>>>>         group <- ylevel[group]
>>>>     temp1 <- formatg(counts, format = "%5g")
>>>>     temp2 <- formatg(yprob, format = "%5.3f")
>>>>     if (nclass > 1) {
>>>>         temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse
>>>> = "
>>>> ")
>>>>         temp2 <- apply(matrix(temp2, ncol = nclass), 1, paste, collapse
>>>> = "
>>>> ")
>>>>     }
>>>>     dev <- dev/(wt[1] * nodeprob)
>>>>     paste0("  predicted class=", format(group, justify = "left"), "
>>>> expected loss=", formatg(dev, digits), "  P(node) =", formatg(nodeprob,
>>>> digits), "\n", "    class counts: ", temp1, "\n", "   probabilities: ",
>>>> temp2)
>>>> }, print = function (yval, ylevel, digits)
>>>> {
>>>>     temp <- if (is.null(ylevel))
>>>>         as.character(yval[, 1])
>>>>     else ylevel[yval[, 1]]
>>>>     nclass <- (ncol(yval) - 2)/2
>>>>     yprob <- if (nclass < 5)
>>>>         format(yval[, 1 + nclass + 1:nclass], digits = digits, nsmall =
>>>> digits)
>>>>     else formatg(yval[, 1 + nclass + 1:nclass], digits = 2)
>>>>     if (!is.matrix(yprob))
>>>>         yprob <- matrix(yprob, nrow = 1)
>>>>     temp <- paste0(temp, " (", yprob[, 1])
>>>>     for (i in 2:ncol(yprob)) temp <- paste(temp, yprob[, i], sep = " ")
>>>>     temp <- paste0(temp, ")")
>>>>     temp
>>>> }, text = function (yval, dev, wt, ylevel, digits, n, use.n)
>>>> {
>>>>     nclass <- (ncol(yval) - 2)/2
>>>>     group <- yval[, 1]
>>>>     counts <- yval[, 1 + (1:nclass)]
>>>>     if (!is.null(ylevel))
>>>>         group <- ylevel[group]
>>>>     temp1 <- formatg(counts, digits)
>>>>     if (nclass > 1)
>>>>         temp1 <- apply(matrix(temp1, ncol = nclass), 1, paste, collapse
>>>> =
>>>> "/")
>>>>
>>>> .......................
>>>>
>>>> How can I save print(fit)?
>>>> Thank?
>>>>
>>>>   ?__
>>>>  c/ /'_;~~~~kmezhoud
>>>> (*) \(*)   ?????  ??????
>>>> http://bioinformatics.tn/
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From zhengda1936 at gmail.com  Thu Nov 13 20:51:41 2014
From: zhengda1936 at gmail.com (Zheng Da)
Date: Thu, 13 Nov 2014 14:51:41 -0500
Subject: [R] "R CMD Rd2txt" generate "_^H" for in all section titles
Message-ID: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>

Hello,

I'm trying to generate plain text from the .Rd files. I run "R CMD
Rd2txt xx.Rd -o xx.txt" to get the plain text file. When I open the
text file, I see "_^H" in front of each character in all section
titles. I can't figure out where the problem is. If I don't specify -o
argument, "R CMD Rd2txt" prints on the standard output correctly. What
should I do to output everything correctly to a file?

Thanks,
Da


From john.posner at MJBIOSTAT.COM  Fri Nov 14 00:31:53 2014
From: john.posner at MJBIOSTAT.COM (John Posner)
Date: Thu, 13 Nov 2014 23:31:53 +0000
Subject: [R] Help with ddply/summarize
Message-ID: <9E73F88F04AA25408DBB58FB730BA6531E0044F9@AUSP01DAG0503.collaborationhost.net>

I have a straightforward application of ddply() and summarize():

   ddply(MyFrame, .(Treatment, Week), summarize, MeanValue=mean(MyVar))

This works just fine:

   Treatment     Week MeanValue
1    MyDrug  BASELINE      5.91
2    MyDrug    WEEK 1      4.68
3    MyDrug    WEEK 2      4.08
4    MyDrug    WEEK 3      3.67
5    MyDrug    WEEK 4      2.96
6    MyDrug    WEEK 5      2.57
7    MyDrug    WEEK 6      2.50
8    Placebo BASELINE      8.58
9    Placebo   WEEK 1      8.25
...

But I want to specify the variable (MyVar) as a character string:

   ddply(MyFrame, .(Treatment, Week), summarize, MeanValue=mean("MyVar"))

(Actually, the character string "MyVar" will be selected from a vector of character strings.)

The code above produces no joy:

   Treatment     Week MeanValue
1    MyDrug  BASELINE        NA
2    MyDrug    WEEK 1        NA
3    MyDrug    WEEK 2        NA
4    MyDrug    WEEK 3        NA
...
I tried a few things, including:

  as.name("MyVar")
  as.quoted("MyVar")

... but they all produced the name results: NAs

I'm obviously thrashing around in the dark! Any advice would be greatly appreciated.

-John


	[[alternative HTML version deleted]]


From rskgautam at gmail.com  Fri Nov 14 01:28:02 2014
From: rskgautam at gmail.com (Ramesh Gautam)
Date: Thu, 13 Nov 2014 16:28:02 -0800
Subject: [R] Data Import to R
Message-ID: <CAKo12DaYFaQ+OVs9_swhuAPLKqPBPETCwwDi-A0Cp4F25Y7a9A@mail.gmail.com>

While importing .csv files into R, all data are converted to factor-by
default. But, how can I preserve the original format of the data like
numeric to numeric, integer to integer, character to character etc while
importing from csv to R environment.

I tried several ways, no thing helps. I used 'stringsAsFactor = FALSE'
command, it did convert all data to characters. But, I wanted to preserve
the numeric data to be in integer or double.

Any idea? examples?

Thanks

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Nov 14 01:42:50 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 13 Nov 2014 16:42:50 -0800
Subject: [R] Help with ddply/summarize
In-Reply-To: <9E73F88F04AA25408DBB58FB730BA6531E0044F9@AUSP01DAG0503.collaborationhost.net>
References: <9E73F88F04AA25408DBB58FB730BA6531E0044F9@AUSP01DAG0503.collaborationhost.net>
Message-ID: <E5ACE7E8-487A-4477-96D2-C6912D3118F1@comcast.net>


On Nov 13, 2014, at 3:31 PM, John Posner wrote:

> I have a straightforward application of ddply() and summarize():
> 
>   ddply(MyFrame, .(Treatment, Week), summarize, MeanValue=mean(MyVar))
> 
> This works just fine:
> 
>   Treatment     Week MeanValue
> 1    MyDrug  BASELINE      5.91
> 2    MyDrug    WEEK 1      4.68
> 3    MyDrug    WEEK 2      4.08
> 4    MyDrug    WEEK 3      3.67
> 5    MyDrug    WEEK 4      2.96
> 6    MyDrug    WEEK 5      2.57
> 7    MyDrug    WEEK 6      2.50
> 8    Placebo BASELINE      8.58
> 9    Placebo   WEEK 1      8.25
> ...
> 
> But I want to specify the variable (MyVar) as a character string:
> 
>   ddply(MyFrame, .(Treatment, Week), summarize, MeanValue=mean("MyVar"))
> 
> (Actually, the character string "MyVar" will be selected from a vector of character strings.)
> 
> The code above produces no joy:
> 
>   Treatment     Week MeanValue
> 1    MyDrug  BASELINE        NA
> 2    MyDrug    WEEK 1        NA
> 3    MyDrug    WEEK 2        NA
> 4    MyDrug    WEEK 3        NA
> ...
> I tried a few things, including:
> 
>  as.name("MyVar")
>  as.quoted("MyVar")
> 
> ... but they all produced the name results: NAs

The data example  from ddply's help page:

dfx <- data.frame(
  group = c(rep('A', 8), rep('B', 15), rep('C', 6)),
  sex = sample(c("M", "F"), size = 29, replace = TRUE),
  age = runif(n = 29, min = 18, max = 54)
                )

ddply(dfx, .(group, sex), summarize,
 mean = round(mean( get('age') ), 2))

  group sex  mean
1     A   F 34.81
2     A   M 33.38
3     B   F 35.89
4     B   M 33.67
5     C   F 33.38
6     C   M 35.36


Group - sex ... a very `60's sort of result.

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Nov 14 01:44:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 13 Nov 2014 16:44:13 -0800
Subject: [R] Data Import to R
In-Reply-To: <CAKo12DaYFaQ+OVs9_swhuAPLKqPBPETCwwDi-A0Cp4F25Y7a9A@mail.gmail.com>
References: <CAKo12DaYFaQ+OVs9_swhuAPLKqPBPETCwwDi-A0Cp4F25Y7a9A@mail.gmail.com>
Message-ID: <B70A1364-5A26-42EA-AC94-016706F89C29@comcast.net>


On Nov 13, 2014, at 4:28 PM, Ramesh Gautam wrote:

> While importing .csv files into R, all data are converted to factor-by
> default. But, how can I preserve the original format of the data like
> numeric to numeric, integer to integer, character to character etc while
> importing from csv to R environment.
> 
> I tried several ways, no thing helps. I used 'stringsAsFactor = FALSE'
> command, it did convert all data to characters. But, I wanted to preserve
> the numeric data to be in integer or double.

Use colClasses. And if that hint is not enough then post an example to work with.
> 
> Any idea? examples?
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Fri Nov 14 01:59:04 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Nov 2014 19:59:04 -0500
Subject: [R] "R CMD Rd2txt" generate "_^H" for in all section titles
In-Reply-To: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>
References: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>
Message-ID: <546553D8.4080304@gmail.com>

On 13/11/2014, 2:51 PM, Zheng Da wrote:
> Hello,
> 
> I'm trying to generate plain text from the .Rd files. I run "R CMD
> Rd2txt xx.Rd -o xx.txt" to get the plain text file. When I open the
> text file, I see "_^H" in front of each character in all section
> titles. I can't figure out where the problem is. If I don't specify -o
> argument, "R CMD Rd2txt" prints on the standard output correctly. What
> should I do to output everything correctly to a file?

That's the old-fashioned way to do underlining.  Set the
"underline_titles" option (see ?Rd2txt_options) to FALSE if you don't
want it.

Duncan Murdoch


From r.turner at auckland.ac.nz  Fri Nov 14 02:16:00 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 14 Nov 2014 14:16:00 +1300
Subject: [R] "R CMD Rd2txt" generate "_^H" for in all section titles
In-Reply-To: <546553D8.4080304@gmail.com>
References: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>
	<546553D8.4080304@gmail.com>
Message-ID: <546557D0.4080906@auckland.ac.nz>

On 14/11/14 13:59, Duncan Murdoch wrote:
> On 13/11/2014, 2:51 PM, Zheng Da wrote:
>> Hello,
>>
>> I'm trying to generate plain text from the .Rd files. I run "R CMD
>> Rd2txt xx.Rd -o xx.txt" to get the plain text file. When I open the
>> text file, I see "_^H" in front of each character in all section
>> titles. I can't figure out where the problem is. If I don't specify -o
>> argument, "R CMD Rd2txt" prints on the standard output correctly. What
>> should I do to output everything correctly to a file?
>
> That's the old-fashioned way to do underlining.  Set the
> "underline_titles" option (see ?Rd2txt_options) to FALSE if you don't
> want it.


Tried it; doesn't work. My hunch is that Rd2txt_options() only has 
impact on the R function Rd2txt() and has no impact on the output of
R CMD Rd2txt ....

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS


From dwinsemius at comcast.net  Fri Nov 14 02:29:45 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 13 Nov 2014 17:29:45 -0800
Subject: [R] "R CMD Rd2txt" generate "_^H" for in all section titles
In-Reply-To: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>
References: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>
Message-ID: <86B8E4A4-1A96-4E24-98E9-BE9F16E43478@comcast.net>


On Nov 13, 2014, at 11:51 AM, Zheng Da wrote:

> Hello,
> 
> I'm trying to generate plain text from the .Rd files. I run "R CMD
> Rd2txt xx.Rd -o xx.txt" to get the plain text file. When I open the
> text file, I see "_^H" in front of each character in all section
> titles. I can't figure out where the problem is. If I don't specify -o
> argument, "R CMD Rd2txt" prints on the standard output correctly. What
> should I do to output everything correctly to a file?

I think your (unstated) editor is displaying backspaces with ^H. The Section Header convention in Rd files is with interspersed underscores so they look like:

_D_e_s_c_r_i_p_t_i_o_n:

The ^H's are apparently being put in to "erase" or squeeze together the text separated by <underscores> and your editor is not handling it in the manner expected.

> 
> Thanks,
> Da
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From zhengda1936 at gmail.com  Fri Nov 14 03:41:05 2014
From: zhengda1936 at gmail.com (Zheng Da)
Date: Thu, 13 Nov 2014 21:41:05 -0500
Subject: [R] "R CMD Rd2txt" generate "_^H" for in all section titles
In-Reply-To: <86B8E4A4-1A96-4E24-98E9-BE9F16E43478@comcast.net>
References: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>
	<86B8E4A4-1A96-4E24-98E9-BE9F16E43478@comcast.net>
Message-ID: <CAFLer80OwVEW7fkuELoDr3Zm5vFwHs0TT0uG+jdkkLT5SPVYqA@mail.gmail.com>

Thank you. Great help!
Given your information, we can generate text files without _^H with
the following command:
echo "tools::Rd2txt(\"$input_file\", out=\"$output_file\",
options=list(underline_titles=FALSE))" | R --no-save
It's kind tedious though.

I'm just curious. Which text editor can actually display _^H correct?
I normally use vim. I also tried gedit. I even tried a web browser
(chrome).

Da

On Thu, Nov 13, 2014 at 8:29 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Nov 13, 2014, at 11:51 AM, Zheng Da wrote:
>
>> Hello,
>>
>> I'm trying to generate plain text from the .Rd files. I run "R CMD
>> Rd2txt xx.Rd -o xx.txt" to get the plain text file. When I open the
>> text file, I see "_^H" in front of each character in all section
>> titles. I can't figure out where the problem is. If I don't specify -o
>> argument, "R CMD Rd2txt" prints on the standard output correctly. What
>> should I do to output everything correctly to a file?
>
> I think your (unstated) editor is displaying backspaces with ^H. The Section Header convention in Rd files is with interspersed underscores so they look like:
>
> _ D_ e_ s_ c_ r_ i_ p_ t_ i_ o_ n:
>
> The ^H's are apparently being put in to "erase" or squeeze together the text separated by <underscores> and your editor is not handling it in the manner expected.
>
>>
>> Thanks,
>> Da
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From jdnewmil at dcn.davis.CA.us  Fri Nov 14 04:28:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 13 Nov 2014 19:28:48 -0800
Subject: [R] "R CMD Rd2txt" generate "_^H" for in all section titles
In-Reply-To: <CAFLer80OwVEW7fkuELoDr3Zm5vFwHs0TT0uG+jdkkLT5SPVYqA@mail.gmail.com>
References: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>
	<86B8E4A4-1A96-4E24-98E9-BE9F16E43478@comcast.net>
	<CAFLer80OwVEW7fkuELoDr3Zm5vFwHs0TT0uG+jdkkLT5SPVYqA@mail.gmail.com>
Message-ID: <154FEA68-E01B-4EE3-B635-D4B72CD7D576@dcn.davis.CA.us>

> Which text editor can actually display _^H correct?

Not aware of any. It is from very old line printer behavior, which most (all?) printers can still support even though few computers are set up to utilize it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 13, 2014 6:41:05 PM PST, Zheng Da <zhengda1936 at gmail.com> wrote:
>Thank you. Great help!
>Given your information, we can generate text files without _^H with
>the following command:
>echo "tools::Rd2txt(\"$input_file\", out=\"$output_file\",
>options=list(underline_titles=FALSE))" | R --no-save
>It's kind tedious though.
>
>I'm just curious. Which text editor can actually display _^H correct?
>I normally use vim. I also tried gedit. I even tried a web browser
>(chrome).
>
>Da
>
>On Thu, Nov 13, 2014 at 8:29 PM, David Winsemius
><dwinsemius at comcast.net> wrote:
>>
>> On Nov 13, 2014, at 11:51 AM, Zheng Da wrote:
>>
>>> Hello,
>>>
>>> I'm trying to generate plain text from the .Rd files. I run "R CMD
>>> Rd2txt xx.Rd -o xx.txt" to get the plain text file. When I open the
>>> text file, I see "_^H" in front of each character in all section
>>> titles. I can't figure out where the problem is. If I don't specify
>-o
>>> argument, "R CMD Rd2txt" prints on the standard output correctly.
>What
>>> should I do to output everything correctly to a file?
>>
>> I think your (unstated) editor is displaying backspaces with ^H. The
>Section Header convention in Rd files is with interspersed underscores
>so they look like:
>>
>> _ D_ e_ s_ c_ r_ i_ p_ t_ i_ o_ n:
>>
>> The ^H's are apparently being put in to "erase" or squeeze together
>the text separated by <underscores> and your editor is not handling it
>in the manner expected.
>>
>>>
>>> Thanks,
>>> Da
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From danielpopoola at yahoo.com  Fri Nov 14 06:29:21 2014
From: danielpopoola at yahoo.com (Popoola Daniel)
Date: Thu, 13 Nov 2014 21:29:21 -0800
Subject: [R] HELP ON NON-LINEAR MIXED MODEL
Message-ID: <1415942961.97300.YahooMailBasic@web141701.mail.bf1.yahoo.com>

Good Morning Sir/Ma,
I am POPOOLA DANIEL a Forest Biometrician in making from the University of Ibadan, Ibadan Nigeria. Please Sir/Ma I am having issues on performing Non-linear mixed model on R (using maximum likelihood approach). I am trying to input four different measured variables which are basal area, diameter at breast height, Dominant height,quadratic mean diameter as a function for height prediction on equation. But I have not been able to get through with the model.

Please I need your  candid options on how to go about this. Other useful tips on Codes entering for data analysis in R environment will also be appreciated . 

Thanks in anticipation to your reply.


From petr.pikal at precheza.cz  Fri Nov 14 07:01:16 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 14 Nov 2014 06:01:16 +0000
Subject: [R] Data Import to R
In-Reply-To: <CAKo12DaYFaQ+OVs9_swhuAPLKqPBPETCwwDi-A0Cp4F25Y7a9A@mail.gmail.com>
References: <CAKo12DaYFaQ+OVs9_swhuAPLKqPBPETCwwDi-A0Cp4F25Y7a9A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEE82D@SRVEXCHMBX.precheza.cz>

Hi

Your original numeric data probably contain something which prevents read.* to accept them as numeric (decimal point, white space)

what is result of

str(imported.data)

Petr Pikal

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ramesh Gautam
> Sent: Friday, November 14, 2014 1:28 AM
> To: r-help at r-project.org
> Subject: [R] Data Import to R
>
> While importing .csv files into R, all data are converted to factor-by
> default. But, how can I preserve the original format of the data like
> numeric to numeric, integer to integer, character to character etc
> while importing from csv to R environment.
>
> I tried several ways, no thing helps. I used 'stringsAsFactor = FALSE'
> command, it did convert all data to characters. But, I wanted to
> preserve the numeric data to be in integer or double.
>
> Any idea? examples?

Your original numeric data probably contain something which prevents read.* to accept them as numeric (decimal point, white space)

What is result of str(imported.data)

Example of data is up to you, we do not have them.

Cheers
Petr


>
> Thanks
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Nov 14 07:07:33 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 14 Nov 2014 06:07:33 +0000
Subject: [R] hi
In-Reply-To: <1148352248.253403.1415875828989.JavaMail.yahoo@jws100139.mail.ne1.yahoo.com>
References: <1148352248.253403.1415875828989.JavaMail.yahoo@jws100139.mail.ne1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEE874@SRVEXCHMBX.precheza.cz>

Hi

1.      Do not post in html
2.      Post example of data, preferably by dput function
3.      Based on posted data explain what do you want to achieve
4.      As it seems to be biological issue did you look at Bioconductor?

Cheers
Petr




> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Cox Lwaka
> Sent: Thursday, November 13, 2014 11:50 AM
> To: r-help at r-project.org
> Subject: [R] hi
>
> I have a bit of trouble here to program in r. I am anew user but i
> really enjoy working with it.I have a large number of variables in a
> matrix that are arranged sequentially on a line (chromosome). This
> order has to be maintained whatsoever. I am to develop an r algorithm
> that will develop groups as follows;i) Calculate the correlation
> between successive variables and correlation matrix for all the
> variables
> ii) if r(i) is the maximum correlation coefficient in the successive
> variable correlation then my first group has variables [x(i-k ),
> ...x(i),... x(i+k )]. this gives me group one of size 2k+1. note that
> variables are picked on that line and order is maintained.iii) we check
> for remaining correlation btn successive variables relative to the
> bigger correlation matrix and select  other groups. these groups don't
> need to be of same size and they must not overlap.i will have divided
> in to disjoint groups but maintaining the order.kindly assist me see
> how i can get this done, thanks
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From clwaka at yahoo.com  Fri Nov 14 10:19:49 2014
From: clwaka at yahoo.com (Cox Lwaka)
Date: Fri, 14 Nov 2014 09:19:49 +0000 (UTC)
Subject: [R] hi
In-Reply-To: <1148352248.253403.1415875828989.JavaMail.yahoo@jws100139.mail.ne1.yahoo.com>
References: <1148352248.253403.1415875828989.JavaMail.yahoo@jws100139.mail.ne1.yahoo.com>
Message-ID: <514887654.446566.1415956789490.JavaMail.yahoo@jws10034.mail.ne1.yahoo.com>

Thanks,Following your explanation i have through bi conductor but still unable to figure out how to group. for the data, my data takes values 0,1,2? hence simulating from a multinomial distribution such as (rmultinom(10, size = 3, prob = c(0.1,0.2,0.8))) gives 10 variables from three individuals assume this variables are ordered.I am to develop an r algorithm that will develop groups as follows;
i) Calculate the correlation between successive variables and correlation matrix for all the variables
ii) if r(i) is the maximum correlation coefficient in the successive variable correlation then my first group has variables [x(i-k ), ...x(i),... x(i+k )]. this gives me group one of size 2k+1. note that variables are picked on that line and order is maintained.iii) the max r is removed from the list of successive correlation between variables, but we don't recalculate the correlation since this will destroy the array. 
iv)check for remaining correlation btn successive variables relative to the bigger correlation matrix and select? other groups. these groups don't need to be of same size and they must not overlap.
e.g,if for instance? x1, x2,......x10?? are my 10 variables. i calculate correlation btn successive variable. Say the max correlation is? Cor(x4,x5) i take group one to have values (x2,x3,x4,x5),?? my data remains, ? x1,-,-,-,-,x6,x7,x8,x9,x10. Clearly x1 will form a group and the algorithm has to check for other groups form x6,x7,x8,x9,x10 based on max r and also the correlation matrix. 

Note that i have large number of variables. i don't need the groups to overlap 
i will have divided in to disjoint groups but maintaining the order.
kindly assist me see how i can get this done, thanks 

     On Thursday, November 13, 2014 1:50 PM, Cox Lwaka <clwaka at yahoo.com> wrote:
   

 I have a bit of trouble here to program in r. I am anew user but i really enjoy working with it.I have a large number of variables in a matrix that are arranged sequentially on a line (chromosome). This order has to be maintained whatsoever. I am to develop an r algorithm that will develop groups as follows;i) Calculate the correlation between successive variables and correlation matrix for all the variables
ii) if r(i) is the maximum correlation coefficient in the successive variable correlation then my first group has variables [x(i-k ), ...x(i),... x(i+k )]. this gives me group one of size 2k+1. note that variables are picked on that line and order is maintained.iii) we check for remaining correlation btn successive variables relative to the bigger correlation matrix and select? other groups. these groups don't need to be of same size and they must not overlap.i will have divided in to disjoint groups but maintaining the order.kindly assist me see how i can get this done, thanks


   
	[[alternative HTML version deleted]]


From rus314 at gmail.com  Fri Nov 14 10:26:48 2014
From: rus314 at gmail.com (Alexandr M)
Date: Fri, 14 Nov 2014 09:26:48 +0000
Subject: [R] Strange error while passing string as an argument to the
 function in bnlearn package
In-Reply-To: <CA+RJqXUNBWY80Rvi6+W_mfY+6-_2WfXR5PsCBZVTUxKB9qPkdg@mail.gmail.com>
References: <CAJ4nbUq=jEWy6L3TWdS6vSO2WUJOCGj9pRRWJ=cPysU4FpCmvg@mail.gmail.com>
	<CA+RJqXVCO3X4-ED78qYCwunEKQmfRuBOB9GH9++qPnuYYu4mcg@mail.gmail.com>
	<CAJ4nbUqrbo_e0VJWOGwh0C-bFcHzHRAr8u74CW+yK8DHQ3A=uA@mail.gmail.com>
	<CA+RJqXUNBWY80Rvi6+W_mfY+6-_2WfXR5PsCBZVTUxKB9qPkdg@mail.gmail.com>
Message-ID: <CAJ4nbUqJ-LCc4XRkGx92QMOOqdicucmaE_vz+Uykv7v6oKt3dw@mail.gmail.com>

Hello Marco,

> By any chance, are using that for prediction?

Yes, I am using it for prediction.

> To compute P(A = a | whatever you conditioned on), just sum the
> corresponding weights over the total weight mass. Since no language
> trickery is involved, this works reliably.

Thank you! It's exactly what I needed.

---
BR,
Alexandr

On 11 November 2014 23:33, Marco Scutari <marco.scutari at gmail.com> wrote:

> Hi Alexandr,
>
> On 11 November 2014 00:10, Alexandr M <rus314 at gmail.com> wrote:
> > Sorry that I formulated my question not very accurately.
> > I form expressions/(logic conditions for parameters evidence and event)
> > dynamically inside the loop and they are sometimes quite long.
>
> By any chance, are using that for prediction? Because predict(...,
> method = "bayes-lw") does posterior predictions from any set of
> variables.
>
> As an alternative, you can do cpdist(..., method = "lw") which also
> generates from the posterior distribution:
>
> > str(cpdist(fit, node = "A", evidence = list(B = "b"), method = "lw"))
> Classes ?bn.cpdist? and 'data.frame':    10000 obs. of  1 variable:
>  $ A: Factor w/ 3 levels "a","b","c": 1 2 2 3 1 1 1 2 1 1 ...
>  - attr(*, "weights")= num  0.114 1 1 0.428 0.114 ...
>  - attr(*, "method")= chr "lw"
>
> To compute P(A = a | whatever you conditioned on), just sum the
> corresponding weights over the total weight mass. Since no language
> trickery is involved, this works reliably.
>
> Cheers,
>     Marco
>
> --
> Marco Scutari, Ph.D.
> Lecturer in Statistics, Department of Statistics
> University of Oxford, United Kingdom
>



-- 
Best regards,
Alexander Maslov

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Nov 14 11:38:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 14 Nov 2014 05:38:12 -0500
Subject: [R] "R CMD Rd2txt" generate "_^H" for in all section titles
In-Reply-To: <546557D0.4080906@auckland.ac.nz>
References: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>
	<546553D8.4080304@gmail.com> <546557D0.4080906@auckland.ac.nz>
Message-ID: <5465DB94.3050304@gmail.com>

On 13/11/2014, 8:16 PM, Rolf Turner wrote:
> On 14/11/14 13:59, Duncan Murdoch wrote:
>> On 13/11/2014, 2:51 PM, Zheng Da wrote:
>>> Hello,
>>>
>>> I'm trying to generate plain text from the .Rd files. I run "R CMD
>>> Rd2txt xx.Rd -o xx.txt" to get the plain text file. When I open the
>>> text file, I see "_^H" in front of each character in all section
>>> titles. I can't figure out where the problem is. If I don't specify -o
>>> argument, "R CMD Rd2txt" prints on the standard output correctly. What
>>> should I do to output everything correctly to a file?
>>
>> That's the old-fashioned way to do underlining.  Set the
>> "underline_titles" option (see ?Rd2txt_options) to FALSE if you don't
>> want it.
> 
> 
> Tried it; doesn't work. My hunch is that Rd2txt_options() only has 
> impact on the R function Rd2txt() and has no impact on the output of
> R CMD Rd2txt ....
> 

Yes, you're right.  R CMD Rd2txt is effectively an abbreviation of a
call to Rd2txt() that doesn't set the options.  I didn't pay attention
to the fact that Zheng was using "R CMD Rd2txt".

Duncan Murdoch


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Nov 14 11:40:10 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 14 Nov 2014 11:40:10 +0100
Subject: [R] metafor - code for analysing geometric means
In-Reply-To: <5464978A.3060902@aghmed.fsnet.co.uk>
References: <1415876433556.77087@kcl.ac.uk>
	<5464978A.3060902@aghmed.fsnet.co.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730EF7D57BBB@UM-MAIL4112.unimaas.nl>

With "geometric mean 1 CI /3.92", I assume you mean "(upper bound - lower bound) / 3.92". Two things:

1) That will give you the SE of the mean, not the SD of the observations (which is what you need as input).

2) Probably the CI for the geometric mean was calculated on the log-scale (as Michael hinted at). Check if log(upper bound) and log(lower bound) is (within rounding error) symmetric around log(geometric mean). Then (log(upper bound) - log(lower bound)) / 3.96 * sqrt(n) will give you the SD of the log of the values used to compute the geometric mean. Then you could use log(geometric mean) and that SD as input. But this would give you the difference of the log-transformed geometric means. Not sure if this is what you want to analyze.

Two more articles that may be helpful here:

Friedrich, J. O., Adhikari, N. K., & Beyene, J. (2012). Ratio of geometric means to analyze continuous outcomes in meta-analysis: Comparison to mean differences and ratio of arithmetic means using empiric data and simulation. Statistics in Medicine, 31(17), 1857-1886.

Souverein, O. W., Dullemeijer, C., van 't Veer, P., & van der Voet, H. (2012). Transformations of summary statistics as input in meta-analysis for linear dose-response models on a logarithmic scale: A methodology developed within EURRECA. BMC Medical Research Methodology, 12(57).

Best,
Wolfgang

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Michael Dewey
> Sent: Thursday, November 13, 2014 12:36
> To: Purssell, Ed; r-help at r-project.org
> Subject: Re: [R] metafor - code for analysing geometric means
> 
> On 13/11/2014 11:00, Purssell, Ed wrote:
> > ?Dear All
> >
> > I have some data expressed in geometric means and 95% confidence
> intervals.  Can I code them in metafor as:
> >
> > rma(m1i=geometric mean 1, m2i=geometric mean 2, sd1i=geometric mean 1
> CI /3.92, sd2i=geometric mean 2 CI/3.92.......etc, measure="MD")
> 
> Would it not be better to work on the log scale?
> 
> > All of the studies use geometric means.
> >
> > Thanks!
> >
> > Edward
> 
> --
> Michael
> http://www.dewey.myzen.co.uk


From murdoch.duncan at gmail.com  Fri Nov 14 11:47:43 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 14 Nov 2014 05:47:43 -0500
Subject: [R] "R CMD Rd2txt" generate "_^H" for in all section titles
In-Reply-To: <154FEA68-E01B-4EE3-B635-D4B72CD7D576@dcn.davis.CA.us>
References: <CAFLer82grEysMAQDOdo8x4F9iGHfekYBXiW8NZfDRDr0c22s0g@mail.gmail.com>	<86B8E4A4-1A96-4E24-98E9-BE9F16E43478@comcast.net>	<CAFLer80OwVEW7fkuELoDr3Zm5vFwHs0TT0uG+jdkkLT5SPVYqA@mail.gmail.com>
	<154FEA68-E01B-4EE3-B635-D4B72CD7D576@dcn.davis.CA.us>
Message-ID: <5465DDCF.4010405@gmail.com>

On 13/11/2014, 10:28 PM, Jeff Newmiller wrote:
>> Which text editor can actually display _^H correct?
> 
> Not aware of any. It is from very old line printer behavior, which most (all?) printers can still support even though few computers are set up to utilize it.

The "less" command in Unix-alikes generally supports it for display.

Duncan Murdoch

> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On November 13, 2014 6:41:05 PM PST, Zheng Da <zhengda1936 at gmail.com> wrote:
>> Thank you. Great help!
>> Given your information, we can generate text files without _^H with
>> the following command:
>> echo "tools::Rd2txt(\"$input_file\", out=\"$output_file\",
>> options=list(underline_titles=FALSE))" | R --no-save
>> It's kind tedious though.
>>
>> I'm just curious. Which text editor can actually display _^H correct?
>> I normally use vim. I also tried gedit. I even tried a web browser
>> (chrome).
>>
>> Da
>>
>> On Thu, Nov 13, 2014 at 8:29 PM, David Winsemius
>> <dwinsemius at comcast.net> wrote:
>>>
>>> On Nov 13, 2014, at 11:51 AM, Zheng Da wrote:
>>>
>>>> Hello,
>>>>
>>>> I'm trying to generate plain text from the .Rd files. I run "R CMD
>>>> Rd2txt xx.Rd -o xx.txt" to get the plain text file. When I open the
>>>> text file, I see "_^H" in front of each character in all section
>>>> titles. I can't figure out where the problem is. If I don't specify
>> -o
>>>> argument, "R CMD Rd2txt" prints on the standard output correctly.
>> What
>>>> should I do to output everything correctly to a file?
>>>
>>> I think your (unstated) editor is displaying backspaces with ^H. The
>> Section Header convention in Rd files is with interspersed underscores
>> so they look like:
>>>
>>> _ D_ e_ s_ c_ r_ i_ p_ t_ i_ o_ n:
>>>
>>> The ^H's are apparently being put in to "erase" or squeeze together
>> the text separated by <underscores> and your editor is not handling it
>> in the manner expected.
>>>
>>>>
>>>> Thanks,
>>>> Da
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Pradip.Muhuri at samhsa.hhs.gov  Fri Nov 14 13:07:27 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Fri, 14 Nov 2014 12:07:27 +0000
Subject: [R] file.copy
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F639C5@pl-emsmb11>

Hello,

Here is something (file.copy) trivial but does not seem to work.  I could not figure out what I am doing wrong.  

The R script below creates folders (fromFolder and toFolder) and finds the list of files (list.of.files) to be copied to the toFolder, which I have verified using the print ()  command. But, the issue is that the file.copy() command does not work.  

Both the R.script and the console are shown below.

Any help/hints will be appreciated.

Thanks,

Pradip Muhuri

#########################  R script  #####################################################
#file.copy.R

#identify the folders
fromFolder <- "H:/R/cis_study"
toFolder <- "F:/cis_study_backup"

# find the list of files to copy 
list.of.files <- list.files(fromFolder, ".R$")

# print objects
print(c(fromFolder, toFolder, list.of.files))
options(warn=1)

# copy the files to the toFolder  - THIS DOES NOT WORK WHILE EVERYTHING PRIOR HAS WORKED
file.copy(list.of.files, toFolder)



#####################  Below is from console ###################
#file.copy.R
> 
> #identify the folders
> fromFolder <- "H:/R/cis_study"
> toFolder <- "F:/cis_study_backup"
> 
> # find the list of files to copy 
> list.of.files <- list.files(fromFolder, ".R$")
> 
> # print objects
> print(c(fromFolder, toFolder, list.of.files))
 [1] "H:/R/cis_study"          "F:/cis_study_backup"    
 [3] "anl.in.scope_111114.R"   "create.oid.data.frame.R"
 [5] "create_xd2012.R"         "file.copy.R"            
 [7] "further.data.R"          "mrj.in.scope_111214.R"  
 [9] "oid.in.scope_111114.R"   "oid_cohort.R"           
[11] "warning.max.R"           "xdate.R"                
[13] "years.before.anl.init.R" "years.before.mrj.init.R"
[15] "years.before.oid.init.R"
> options(warn=1)
> 
> # copy the files to the toFolder  - THIS DOES NOT WORK WHILE EVERYTHING PRIOR HAS WORKED
> file.copy(list.of.files, toFolder)
Warning in file.copy(list.of.files, toFolder) :
  problem copying .\anl.in.scope_111114.R to F:\cis_study_backup\anl.in.scope_111114.R: No such file or directory
(other similar warning messages are not shown)



Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


From ashenkin at ufl.edu  Fri Nov 14 13:18:26 2014
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Fri, 14 Nov 2014 12:18:26 +0000
Subject: [R] expected arguments for rgl.triangles
Message-ID: <5465F312.3000807@ufl.edu>

Hello all,

I have a set of points in 3D space that represent vertices of a 
non-convex polyhedron.  I would like to plot this polyhedron, and have 
been trying to do so with rgl.triangles, but to no avail.  I imagine I 
don't understand what rgl.triangles expects for arguments.  I have 
constructed the triangles myself, and have the three vertices of each 
triangle.  I am then passing these to rgl.triangles in the x,y & z 
arguments.

I end up with unexpected results (see http://i.imgur.com/BaKfzn7.png). 
Might someone advise me about the structure of arguments that 
rgl.triangles expects (or perhaps a better way to go about this)? 
?rgl.triangles doesn't help much with this particular issue...

Thanks,
Allie


The code, where rows 2,3,4 are one triangle, 5,6,7 the next, etc 
(apologies - don't know how to serialize a dataframe to make it easy to 
suck into one's environment):

rgl.triangles(tri_df[,1],tri_df[,2],tri_df[,3],col=heat.colors(nrow(tri_df)),alpha=.2)

 > tri_df
             x          y   z
2  -2.9970624 -0.1327280 8.0
3  -1.3358202  3.8762849 4.9
4   3.5380065  0.6652143 9.1
5  -1.3358202  3.8762849 4.9
6   1.4644874  3.6145922 5.3
7   3.5380065  0.6652143 9.1
8   1.4644874  3.6145922 5.3
9   1.9606671 -3.8269811 4.5
10  3.5380065  0.6652143 9.1
11  1.9606671 -3.8269811 4.5
12 -3.5337687  3.6772923 3.9
13  3.5380065  0.6652143 9.1
14 -3.5337687  3.6772923 3.9
15 -5.6586500  1.2726665 3.5
16  3.5380065  0.6652143 9.1
17 -5.6586500  1.2726665 3.5
18  3.8327817 -2.8895994 3.4
19  3.5380065  0.6652143 9.1
20  3.8327817 -2.8895994 3.4
21  6.0806691 -0.4852461 2.2
22  3.5380065  0.6652143 9.1
23  6.0806691 -0.4852461 2.2
24 -0.5109254 -6.7807784 0.5
25  3.5380065  0.6652143 9.1
26 -0.5109254 -6.7807784 0.5
27  2.3503422 -6.2742244 1.8
28  3.5380065  0.6652143 9.1
29  2.3503422 -6.2742244 1.8
30  5.4741865 -1.1803740 0.3
31  3.5380065  0.6652143 9.1
32  5.4741865 -1.1803740 0.3
33  5.7888812 -0.3589635 2.7
34  3.5380065  0.6652143 9.1
35  5.7888812 -0.3589635 2.7
36 -3.1939122 -2.4080958 5.4
37  3.5380065  0.6652143 9.1
38 -3.1939122 -2.4080958 5.4
39 -1.4732303 -3.9331403 4.9
40  3.5380065  0.6652143 9.1
41 -1.4732303 -3.9331403 4.9
42 -3.4863074  0.3092904 6.8
43  3.5380065  0.6652143 9.1
44 -3.4863074  0.3092904 6.8
45  0.8019969 -2.2620347 7.2
46  3.5380065  0.6652143 9.1
47  0.8019969 -2.2620347 7.2
48 -2.9970624 -0.1327280 8.0
49  3.5380065  0.6652143 9.1
50 -1.3358202  3.8762849 4.9
51 -2.9970624 -0.1327280 8.0
52  6.4508128 -2.4488802 0.3
53  1.4644874  3.6145922 5.3
54 -1.3358202  3.8762849 4.9
55  6.4508128 -2.4488802 0.3
56  1.9606671 -3.8269811 4.5
57  1.4644874  3.6145922 5.3
58  6.4508128 -2.4488802 0.3
59 -3.5337687  3.6772923 3.9
60  1.9606671 -3.8269811 4.5
61  6.4508128 -2.4488802 0.3
62 -5.6586500  1.2726665 3.5
63 -3.5337687  3.6772923 3.9
64  6.4508128 -2.4488802 0.3
65  3.8327817 -2.8895994 3.4
66 -5.6586500  1.2726665 3.5
67  6.4508128 -2.4488802 0.3
68  6.0806691 -0.4852461 2.2
69  3.8327817 -2.8895994 3.4
70  6.4508128 -2.4488802 0.3
71 -0.5109254 -6.7807784 0.5
72  6.0806691 -0.4852461 2.2
73  6.4508128 -2.4488802 0.3
74  2.3503422 -6.2742244 1.8
75 -0.5109254 -6.7807784 0.5
76  6.4508128 -2.4488802 0.3
77  5.4741865 -1.1803740 0.3
78  2.3503422 -6.2742244 1.8
79  6.4508128 -2.4488802 0.3
80  5.7888812 -0.3589635 2.7
81  5.4741865 -1.1803740 0.3
82  6.4508128 -2.4488802 0.3
83 -3.1939122 -2.4080958 5.4
84  5.7888812 -0.3589635 2.7
85  6.4508128 -2.4488802 0.3
86 -1.4732303 -3.9331403 4.9
87 -3.1939122 -2.4080958 5.4
88  6.4508128 -2.4488802 0.3
89 -3.4863074  0.3092904 6.8
90 -1.4732303 -3.9331403 4.9
91  6.4508128 -2.4488802 0.3
92  0.8019969 -2.2620347 7.2
93 -3.4863074  0.3092904 6.8
94  6.4508128 -2.4488802 0.3
95 -2.9970624 -0.1327280 8.0
96  0.8019969 -2.2620347 7.2
97  6.4508128 -2.4488802 0.3


From jdnewmil at dcn.davis.CA.us  Fri Nov 14 13:36:12 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 14 Nov 2014 04:36:12 -0800
Subject: [R] file.copy
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F639C5@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F639C5@pl-emsmb11>
Message-ID: <BB4F81F6-6ACE-4639-B650-15C24A5E140F@dcn.davis.CA.us>

Your list.of.files variable just has filenames without the fromFolder path. Try

file.copy(file.path,fromFolder,list.of.files), toFolder)

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 14, 2014 4:07:27 AM PST, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>Hello,
>
>Here is something (file.copy) trivial but does not seem to work.  I
>could not figure out what I am doing wrong.  
>
>The R script below creates folders (fromFolder and toFolder) and finds
>the list of files (list.of.files) to be copied to the toFolder, which I
>have verified using the print ()  command. But, the issue is that the
>file.copy() command does not work.  
>
>Both the R.script and the console are shown below.
>
>Any help/hints will be appreciated.
>
>Thanks,
>
>Pradip Muhuri
>
>#########################  R script 
>#####################################################
>#file.copy.R
>
>#identify the folders
>fromFolder <- "H:/R/cis_study"
>toFolder <- "F:/cis_study_backup"
>
># find the list of files to copy 
>list.of.files <- list.files(fromFolder, ".R$")
>
># print objects
>print(c(fromFolder, toFolder, list.of.files))
>options(warn=1)
>
># copy the files to the toFolder  - THIS DOES NOT WORK WHILE EVERYTHING
>PRIOR HAS WORKED
>file.copy(list.of.files, toFolder)
>
>
>
>#####################  Below is from console ###################
>#file.copy.R
>> 
>> #identify the folders
>> fromFolder <- "H:/R/cis_study"
>> toFolder <- "F:/cis_study_backup"
>> 
>> # find the list of files to copy 
>> list.of.files <- list.files(fromFolder, ".R$")
>> 
>> # print objects
>> print(c(fromFolder, toFolder, list.of.files))
> [1] "H:/R/cis_study"          "F:/cis_study_backup"    
> [3] "anl.in.scope_111114.R"   "create.oid.data.frame.R"
> [5] "create_xd2012.R"         "file.copy.R"            
> [7] "further.data.R"          "mrj.in.scope_111214.R"  
> [9] "oid.in.scope_111114.R"   "oid_cohort.R"           
>[11] "warning.max.R"           "xdate.R"                
>[13] "years.before.anl.init.R" "years.before.mrj.init.R"
>[15] "years.before.oid.init.R"
>> options(warn=1)
>> 
>> # copy the files to the toFolder  - THIS DOES NOT WORK WHILE
>EVERYTHING PRIOR HAS WORKED
>> file.copy(list.of.files, toFolder)
>Warning in file.copy(list.of.files, toFolder) :
>problem copying .\anl.in.scope_111114.R to
>F:\cis_study_backup\anl.in.scope_111114.R: No such file or directory
>(other similar warning messages are not shown)
>
>
>
>Pradip K. Muhuri, PhD
>SAMHSA/CBHSQ
>1 Choke Cherry Road, Room 2-1071
>Rockville, MD 20857
>Tel: 240-276-1070
>Fax: 240-276-1260
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Nov 14 13:59:34 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 14 Nov 2014 12:59:34 +0000
Subject: [R] hi
In-Reply-To: <514887654.446566.1415956789490.JavaMail.yahoo@jws10034.mail.ne1.yahoo.com>
References: <1148352248.253403.1415875828989.JavaMail.yahoo@jws100139.mail.ne1.yahoo.com>
	<514887654.446566.1415956789490.JavaMail.yahoo@jws10034.mail.ne1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEE962@SRVEXCHMBX.precheza.cz>

It seems rather complicated. AFAIK cor gives you correlation matrix, you can check items in this matrix but I do not understand your rules.
?
Cheers
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Cox Lwaka
> Sent: Friday, November 14, 2014 10:20 AM
> To: r-help at r-project.org
> Subject: Re: [R] hi
>
> Thanks,Following your explanation i have through bi conductor but still
> unable to figure out how to group. for the data, my data takes values
> 0,1,2  hence simulating from a multinomial distribution such as
> (rmultinom(10, size = 3, prob = c(0.1,0.2,0.8))) gives 10 variables
> from three individuals assume this variables are ordered.I am to
> develop an r algorithm that will develop groups as follows;
> i) Calculate the correlation between successive variables and
> correlation matrix for all the variables
> ii) if r(i) is the maximum correlation coefficient in the successive
> variable correlation then my first group has variables [x(i-k ),
> ...x(i),... x(i+k )]. this gives me group one of size 2k+1. note that
> variables are picked on that line and order is maintained.iii) the max
> r is removed from the list of successive correlation between variables,
> but we don't recalculate the correlation since this will destroy the
> array.
> iv)check for remaining correlation btn successive variables relative to
> the bigger correlation matrix and select  other groups. these groups
> don't need to be of same size and they must not overlap.
> e.g,if for instance  x1, x2,......x10   are my 10 variables. i
> calculate correlation btn successive variable. Say the max correlation
> is  Cor(x4,x5) i take group one to have values (x2,x3,x4,x5),   my data
> remains,   x1,-,-,-,-,x6,x7,x8,x9,x10. Clearly x1 will form a group and
> the algorithm has to check for other groups form x6,x7,x8,x9,x10 based
> on max r and also the correlation matrix.
>
> Note that i have large number of variables. i don't need the groups to
> overlap i will have divided in to disjoint groups but maintaining the
> order.
> kindly assist me see how i can get this done, thanks
>
>      On Thursday, November 13, 2014 1:50 PM, Cox Lwaka
> <clwaka at yahoo.com> wrote:
>
>
>  I have a bit of trouble here to program in r. I am anew user but i
> really enjoy working with it.I have a large number of variables in a
> matrix that are arranged sequentially on a line (chromosome). This
> order has to be maintained whatsoever. I am to develop an r algorithm
> that will develop groups as follows;i) Calculate the correlation
> between successive variables and correlation matrix for all the
> variables
> ii) if r(i) is the maximum correlation coefficient in the successive
> variable correlation then my first group has variables [x(i-k ),
> ...x(i),... x(i+k )]. this gives me group one of size 2k+1. note that
> variables are picked on that line and order is maintained.iii) we check
> for remaining correlation btn successive variables relative to the
> bigger correlation matrix and select  other groups. these groups don't
> need to be of same size and they must not overlap.i will have divided
> in to disjoint groups but maintaining the order.kindly assist me see
> how i can get this done, thanks
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.CA.us  Fri Nov 14 14:21:01 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 14 Nov 2014 05:21:01 -0800
Subject: [R] file.copy
In-Reply-To: <BB4F81F6-6ACE-4639-B650-15C24A5E140F@dcn.davis.CA.us>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F639C5@pl-emsmb11>
	<BB4F81F6-6ACE-4639-B650-15C24A5E140F@dcn.davis.CA.us>
Message-ID: <14829488-C8A5-49CE-B4B9-8DE79C208AF8@dcn.davis.CA.us>

Sorry.. typo...

file.copy(file.path(fromFolder,list.of.files), toFolder)

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 14, 2014 4:36:12 AM PST, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>Your list.of.files variable just has filenames without the fromFolder
>path. Try
>
>file.copy(file.path,fromFolder,list.of.files), toFolder)
>
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>On November 14, 2014 4:07:27 AM PST, "Muhuri, Pradip (SAMHSA/CBHSQ)"
><Pradip.Muhuri at samhsa.hhs.gov> wrote:
>>Hello,
>>
>>Here is something (file.copy) trivial but does not seem to work.  I
>>could not figure out what I am doing wrong.  
>>
>>The R script below creates folders (fromFolder and toFolder) and finds
>>the list of files (list.of.files) to be copied to the toFolder, which
>I
>>have verified using the print ()  command. But, the issue is that the
>>file.copy() command does not work.  
>>
>>Both the R.script and the console are shown below.
>>
>>Any help/hints will be appreciated.
>>
>>Thanks,
>>
>>Pradip Muhuri
>>
>>#########################  R script 
>>#####################################################
>>#file.copy.R
>>
>>#identify the folders
>>fromFolder <- "H:/R/cis_study"
>>toFolder <- "F:/cis_study_backup"
>>
>># find the list of files to copy 
>>list.of.files <- list.files(fromFolder, ".R$")
>>
>># print objects
>>print(c(fromFolder, toFolder, list.of.files))
>>options(warn=1)
>>
>># copy the files to the toFolder  - THIS DOES NOT WORK WHILE
>EVERYTHING
>>PRIOR HAS WORKED
>>file.copy(list.of.files, toFolder)
>>
>>
>>
>>#####################  Below is from console ###################
>>#file.copy.R
>>> 
>>> #identify the folders
>>> fromFolder <- "H:/R/cis_study"
>>> toFolder <- "F:/cis_study_backup"
>>> 
>>> # find the list of files to copy 
>>> list.of.files <- list.files(fromFolder, ".R$")
>>> 
>>> # print objects
>>> print(c(fromFolder, toFolder, list.of.files))
>> [1] "H:/R/cis_study"          "F:/cis_study_backup"    
>> [3] "anl.in.scope_111114.R"   "create.oid.data.frame.R"
>> [5] "create_xd2012.R"         "file.copy.R"            
>> [7] "further.data.R"          "mrj.in.scope_111214.R"  
>> [9] "oid.in.scope_111114.R"   "oid_cohort.R"           
>>[11] "warning.max.R"           "xdate.R"                
>>[13] "years.before.anl.init.R" "years.before.mrj.init.R"
>>[15] "years.before.oid.init.R"
>>> options(warn=1)
>>> 
>>> # copy the files to the toFolder  - THIS DOES NOT WORK WHILE
>>EVERYTHING PRIOR HAS WORKED
>>> file.copy(list.of.files, toFolder)
>>Warning in file.copy(list.of.files, toFolder) :
>>problem copying .\anl.in.scope_111114.R to
>>F:\cis_study_backup\anl.in.scope_111114.R: No such file or directory
>>(other similar warning messages are not shown)
>>
>>
>>
>>Pradip K. Muhuri, PhD
>>SAMHSA/CBHSQ
>>1 Choke Cherry Road, Room 2-1071
>>Rockville, MD 20857
>>Tel: 240-276-1070
>>Fax: 240-276-1260
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Nov 14 14:27:00 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 14 Nov 2014 08:27:00 -0500
Subject: [R] expected arguments for rgl.triangles
In-Reply-To: <5465F312.3000807@ufl.edu>
References: <5465F312.3000807@ufl.edu>
Message-ID: <54660324.2050109@gmail.com>

On 14/11/2014 7:18 AM, Alexander Shenkin wrote:
> Hello all,
>
> I have a set of points in 3D space that represent vertices of a
> non-convex polyhedron.  I would like to plot this polyhedron, and have
> been trying to do so with rgl.triangles, but to no avail.  I imagine I
> don't understand what rgl.triangles expects for arguments.  I have
> constructed the triangles myself, and have the three vertices of each
> triangle.  I am then passing these to rgl.triangles in the x,y & z
> arguments.
>
> I end up with unexpected results (see http://i.imgur.com/BaKfzn7.png).
> Might someone advise me about the structure of arguments that
> rgl.triangles expects (or perhaps a better way to go about this)?
> ?rgl.triangles doesn't help much with this particular issue...

I can't tell what you think is wrong.   Your arguments look right. 
Here's some general advice:

1.  Don't use rgl.triangles().  Use triangles3d().  This won't affect 
the geometry, but it handles colours and other attributes more rationally.

2.  Think about using a triangle mesh instead of triangles3d().  You 
only need to specify each vertex once, instead of
many times as your current code does.

3.  Put together a simpler example, e.g. two triangles, and see if that 
works.  Then build up from there.

Duncan Murdoch

>
> Thanks,
> Allie
>
>
> The code, where rows 2,3,4 are one triangle, 5,6,7 the next, etc
> (apologies - don't know how to serialize a dataframe to make it easy to
> suck into one's environment):
>
> rgl.triangles(tri_df[,1],tri_df[,2],tri_df[,3],col=heat.colors(nrow(tri_df)),alpha=.2)
>
>   > tri_df
>               x          y   z
> 2  -2.9970624 -0.1327280 8.0
> 3  -1.3358202  3.8762849 4.9
> 4   3.5380065  0.6652143 9.1
> 5  -1.3358202  3.8762849 4.9
> 6   1.4644874  3.6145922 5.3
> 7   3.5380065  0.6652143 9.1
> 8   1.4644874  3.6145922 5.3
> 9   1.9606671 -3.8269811 4.5
> 10  3.5380065  0.6652143 9.1
> 11  1.9606671 -3.8269811 4.5
> 12 -3.5337687  3.6772923 3.9
> 13  3.5380065  0.6652143 9.1
> 14 -3.5337687  3.6772923 3.9
> 15 -5.6586500  1.2726665 3.5
> 16  3.5380065  0.6652143 9.1
> 17 -5.6586500  1.2726665 3.5
> 18  3.8327817 -2.8895994 3.4
> 19  3.5380065  0.6652143 9.1
> 20  3.8327817 -2.8895994 3.4
> 21  6.0806691 -0.4852461 2.2
> 22  3.5380065  0.6652143 9.1
> 23  6.0806691 -0.4852461 2.2
> 24 -0.5109254 -6.7807784 0.5
> 25  3.5380065  0.6652143 9.1
> 26 -0.5109254 -6.7807784 0.5
> 27  2.3503422 -6.2742244 1.8
> 28  3.5380065  0.6652143 9.1
> 29  2.3503422 -6.2742244 1.8
> 30  5.4741865 -1.1803740 0.3
> 31  3.5380065  0.6652143 9.1
> 32  5.4741865 -1.1803740 0.3
> 33  5.7888812 -0.3589635 2.7
> 34  3.5380065  0.6652143 9.1
> 35  5.7888812 -0.3589635 2.7
> 36 -3.1939122 -2.4080958 5.4
> 37  3.5380065  0.6652143 9.1
> 38 -3.1939122 -2.4080958 5.4
> 39 -1.4732303 -3.9331403 4.9
> 40  3.5380065  0.6652143 9.1
> 41 -1.4732303 -3.9331403 4.9
> 42 -3.4863074  0.3092904 6.8
> 43  3.5380065  0.6652143 9.1
> 44 -3.4863074  0.3092904 6.8
> 45  0.8019969 -2.2620347 7.2
> 46  3.5380065  0.6652143 9.1
> 47  0.8019969 -2.2620347 7.2
> 48 -2.9970624 -0.1327280 8.0
> 49  3.5380065  0.6652143 9.1
> 50 -1.3358202  3.8762849 4.9
> 51 -2.9970624 -0.1327280 8.0
> 52  6.4508128 -2.4488802 0.3
> 53  1.4644874  3.6145922 5.3
> 54 -1.3358202  3.8762849 4.9
> 55  6.4508128 -2.4488802 0.3
> 56  1.9606671 -3.8269811 4.5
> 57  1.4644874  3.6145922 5.3
> 58  6.4508128 -2.4488802 0.3
> 59 -3.5337687  3.6772923 3.9
> 60  1.9606671 -3.8269811 4.5
> 61  6.4508128 -2.4488802 0.3
> 62 -5.6586500  1.2726665 3.5
> 63 -3.5337687  3.6772923 3.9
> 64  6.4508128 -2.4488802 0.3
> 65  3.8327817 -2.8895994 3.4
> 66 -5.6586500  1.2726665 3.5
> 67  6.4508128 -2.4488802 0.3
> 68  6.0806691 -0.4852461 2.2
> 69  3.8327817 -2.8895994 3.4
> 70  6.4508128 -2.4488802 0.3
> 71 -0.5109254 -6.7807784 0.5
> 72  6.0806691 -0.4852461 2.2
> 73  6.4508128 -2.4488802 0.3
> 74  2.3503422 -6.2742244 1.8
> 75 -0.5109254 -6.7807784 0.5
> 76  6.4508128 -2.4488802 0.3
> 77  5.4741865 -1.1803740 0.3
> 78  2.3503422 -6.2742244 1.8
> 79  6.4508128 -2.4488802 0.3
> 80  5.7888812 -0.3589635 2.7
> 81  5.4741865 -1.1803740 0.3
> 82  6.4508128 -2.4488802 0.3
> 83 -3.1939122 -2.4080958 5.4
> 84  5.7888812 -0.3589635 2.7
> 85  6.4508128 -2.4488802 0.3
> 86 -1.4732303 -3.9331403 4.9
> 87 -3.1939122 -2.4080958 5.4
> 88  6.4508128 -2.4488802 0.3
> 89 -3.4863074  0.3092904 6.8
> 90 -1.4732303 -3.9331403 4.9
> 91  6.4508128 -2.4488802 0.3
> 92  0.8019969 -2.2620347 7.2
> 93 -3.4863074  0.3092904 6.8
> 94  6.4508128 -2.4488802 0.3
> 95 -2.9970624 -0.1327280 8.0
> 96  0.8019969 -2.2620347 7.2
> 97  6.4508128 -2.4488802 0.3
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Nov 14 14:28:59 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 14 Nov 2014 08:28:59 -0500
Subject: [R] file.copy
In-Reply-To: <14829488-C8A5-49CE-B4B9-8DE79C208AF8@dcn.davis.CA.us>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F639C5@pl-emsmb11>	<BB4F81F6-6ACE-4639-B650-15C24A5E140F@dcn.davis.CA.us>
	<14829488-C8A5-49CE-B4B9-8DE79C208AF8@dcn.davis.CA.us>
Message-ID: <5466039B.80007@gmail.com>

On 14/11/2014 8:21 AM, Jeff Newmiller wrote:
> Sorry.. typo...
>
> file.copy(file.path(fromFolder,list.of.files), toFolder)

Or construct the list of files containing full paths.  See ?list.files.

Duncan Murdoch
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 14, 2014 4:36:12 AM PST, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> >Your list.of.files variable just has filenames without the fromFolder
> >path. Try
> >
> >file.copy(file.path,fromFolder,list.of.files), toFolder)
> >
> >---------------------------------------------------------------------------
> >Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >Go...
> >                                     Live:   OO#.. Dead: OO#..  Playing
> >Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >/Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >---------------------------------------------------------------------------
> >
> >Sent from my phone. Please excuse my brevity.
> >
> >On November 14, 2014 4:07:27 AM PST, "Muhuri, Pradip (SAMHSA/CBHSQ)"
> ><Pradip.Muhuri at samhsa.hhs.gov> wrote:
> >>Hello,
> >>
> >>Here is something (file.copy) trivial but does not seem to work.  I
> >>could not figure out what I am doing wrong.
> >>
> >>The R script below creates folders (fromFolder and toFolder) and finds
> >>the list of files (list.of.files) to be copied to the toFolder, which
> >I
> >>have verified using the print ()  command. But, the issue is that the
> >>file.copy() command does not work.
> >>
> >>Both the R.script and the console are shown below.
> >>
> >>Any help/hints will be appreciated.
> >>
> >>Thanks,
> >>
> >>Pradip Muhuri
> >>
> >>#########################  R script
> >>#####################################################
> >>#file.copy.R
> >>
> >>#identify the folders
> >>fromFolder <- "H:/R/cis_study"
> >>toFolder <- "F:/cis_study_backup"
> >>
> >># find the list of files to copy
> >>list.of.files <- list.files(fromFolder, ".R$")
> >>
> >># print objects
> >>print(c(fromFolder, toFolder, list.of.files))
> >>options(warn=1)
> >>
> >># copy the files to the toFolder  - THIS DOES NOT WORK WHILE
> >EVERYTHING
> >>PRIOR HAS WORKED
> >>file.copy(list.of.files, toFolder)
> >>
> >>
> >>
> >>#####################  Below is from console ###################
> >>#file.copy.R
> >>>
> >>> #identify the folders
> >>> fromFolder <- "H:/R/cis_study"
> >>> toFolder <- "F:/cis_study_backup"
> >>>
> >>> # find the list of files to copy
> >>> list.of.files <- list.files(fromFolder, ".R$")
> >>>
> >>> # print objects
> >>> print(c(fromFolder, toFolder, list.of.files))
> >> [1] "H:/R/cis_study"          "F:/cis_study_backup"
> >> [3] "anl.in.scope_111114.R"   "create.oid.data.frame.R"
> >> [5] "create_xd2012.R"         "file.copy.R"
> >> [7] "further.data.R"          "mrj.in.scope_111214.R"
> >> [9] "oid.in.scope_111114.R"   "oid_cohort.R"
> >>[11] "warning.max.R"           "xdate.R"
> >>[13] "years.before.anl.init.R" "years.before.mrj.init.R"
> >>[15] "years.before.oid.init.R"
> >>> options(warn=1)
> >>>
> >>> # copy the files to the toFolder  - THIS DOES NOT WORK WHILE
> >>EVERYTHING PRIOR HAS WORKED
> >>> file.copy(list.of.files, toFolder)
> >>Warning in file.copy(list.of.files, toFolder) :
> >>problem copying .\anl.in.scope_111114.R to
> >>F:\cis_study_backup\anl.in.scope_111114.R: No such file or directory
> >>(other similar warning messages are not shown)
> >>
> >>
> >>
> >>Pradip K. Muhuri, PhD
> >>SAMHSA/CBHSQ
> >>1 Choke Cherry Road, Room 2-1071
> >>Rockville, MD 20857
> >>Tel: 240-276-1070
> >>Fax: 240-276-1260
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Pradip.Muhuri at samhsa.hhs.gov  Fri Nov 14 14:59:03 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Fri, 14 Nov 2014 13:59:03 +0000
Subject: [R] file.copy
In-Reply-To: <14829488-C8A5-49CE-B4B9-8DE79C208AF8@dcn.davis.CA.us>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F639C5@pl-emsmb11>
	<BB4F81F6-6ACE-4639-B650-15C24A5E140F@dcn.davis.CA.us>
	<14829488-C8A5-49CE-B4B9-8DE79C208AF8@dcn.davis.CA.us>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F63A04@pl-emsmb11>

Jeff,
Thank you so much for your help.

Below are the revised code (done with your hints) that has worked and the console. I have just added - overwrite=TRUE) to file.copy().

Pradip

###############################################
#file.copy.jn.way.R

#identify the folders
fromFolder <- "H:/R/cis_study"
toFolder <- "F:/cis_study_backup"

# find the list of files to copy
list.of.files <- list.files(fromFolder, ".R$")

# print objects
print(c(fromFolder, toFolder, list.of.files))
options(warn=1)

# copy the files to the toFolder  - THIS DOES NOT WORK WHILE EVERYTHING PRIOR HAS WORKED

file.copy(file.path(fromFolder,list.of.files), toFolder, overwrite=TRUE)

###################  revised console ########################
> #file.copy.jn.way.R
> 
> #identify the folders
> fromFolder <- "H:/R/cis_study"
> toFolder <- "F:/cis_study_backup"
> 
> # find the list of files to copy
> list.of.files <- list.files(fromFolder, ".R$")
> 
> # print objects
> print(c(fromFolder, toFolder, list.of.files))
 [1] "H:/R/cis_study"          "F:/cis_study_backup"    
 [3] "anl.in.scope_111114.R"   "create.oid.data.frame.R"
 [5] "create_xd2012.R"         "file.copy.R"            
 [7] "file.copy_Duncan_way.R"  "further.data.R"         
 [9] "mrj.in.scope_111214.R"   "oid.in.scope_111114.R"  
[11] "oid_cohort.R"            "warning.max.R"          
[13] "xdate.R"                 "years.before.anl.init.R"
[15] "years.before.mrj.init.R" "years.before.oid.init.R"
> options(warn=1)
> 
> # copy the files to the toFolder  - THIS DOES NOT WORK WHILE EVERYTHING PRIOR HAS WORKED
> 
> file.copy(file.path(fromFolder,list.of.files), toFolder, overwrite=TRUE)
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
>

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

From Pradip.Muhuri at samhsa.hhs.gov  Fri Nov 14 15:13:59 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Fri, 14 Nov 2014 14:13:59 +0000
Subject: [R] file.copy
In-Reply-To: <5466039B.80007@gmail.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F639C5@pl-emsmb11>
	<BB4F81F6-6ACE-4639-B650-15C24A5E140F@dcn.davis.CA.us>
	<14829488-C8A5-49CE-B4B9-8DE79C208AF8@dcn.davis.CA.us>
	<5466039B.80007@gmail.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F63A2B@pl-emsmb11>

Hello Duncan,

Jeff's tweaks to my code has worked.   Now I am trying your way. Below are the R script and console.   The issue is that the object (list.of.files) has not been created.  Any thoughts?

Thanks,

###############  R script ##########################

#file.copy.dm.way.R

#identify the folders

fromFolder <- file.path("H:", "cis_study")

toFolder <- file.path("F:", "cis_study")

# find the list of files to copied
list.of.files <- list.files(fromFolder, ".R$")

# print objects
print(fromFolder, list.of.files, toFolder)

# copy the files
file.copy(list.of.files, toFiles)

###############  console ###############
> #file.copy.dm.way.R
> 
> #identify the folders
> 
> fromFolder <- file.path("H:", "cis_study")
> 
> toFolder <- file.path("F:", "cis_study")
> 
> # find the list of files to copied
> list.of.files <- list.files(fromFolder, ".R$")
> 
> # print objects
> print(fromFolder, list.of.files, toFolder)
Error in print.default(fromFolder, list.of.files, toFolder) : 
  invalid 'digits' argument
> 
> # copy the files
> file.copy(list.of.files, toFiles)
logical(0)


From francesca.pancotto at unimore.it  Fri Nov 14 15:48:57 2014
From: francesca.pancotto at unimore.it (Francesca Pancotto)
Date: Fri, 14 Nov 2014 15:48:57 +0100
Subject: [R] Small vector into large data frame
Message-ID: <A6CE05E4-6D92-4401-BA28-41009D057820@unimore.it>

Dear Contributors
I seem not to get the general rule applying to the use of loops.
I need some help. I have a database in which i need to generate a variable according to the following rule.


This is the database head

      bank_name       date px_last       Q_Y p_made p_for p_m p_f
aba.1       ABA 2006-10-24    1.28 p406-q406    406   406   1   1
aba.2       ABA 2006-11-30    1.31 p406-q406    406   406   1   1
aba.3       ABA 2006-10-24    1.29 p406-q107    406   107   1   2
aba.4       ABA 2006-11-30    1.33 p406-q107    406   107   1   2
aba.5       ABA 2006-10-24    1.31 p406-q207    406   207   1   3
aba.6       ABA 2006-11-30    1.35 p406-q207    406   207   1   3


the variable p_f takes values from 1 to 19 in a non regular way.

then I have a vector of 19 elements

> spot$pxlast
 [1] 1.32 1.34 1.35 1.43 1.46 1.58 1.58 1.41 1.40 1.33 1.40 1.46 1.43 1.35 1.22 1.36 1.34 1.42 1.42

I need to create a variable to attach to the data frame which is composed of 11500 rows that takes values
1.32 when p_f==1
1.34 when p_f==2

It seems so easy but I cannot find a way to do it in an efficient way.
Thanks in advance for any help.



Francesca



	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Fri Nov 14 15:56:56 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 14 Nov 2014 08:56:56 -0600
Subject: [R] Small vector into large data frame
In-Reply-To: <A6CE05E4-6D92-4401-BA28-41009D057820@unimore.it>
References: <A6CE05E4-6D92-4401-BA28-41009D057820@unimore.it>
Message-ID: <CAN5YmCFvWMbgb1Y6f3c-RqB8Ltdf+MKowGgdg5Hqk13h_1ix0Q@mail.gmail.com>

Use the p_f numbers as an "index" of spot$pxlast.  Suppose your data frame
is called mydata,

mydata$newvar <- spot$pxlast[mydata$p_f]

Jean

On Fri, Nov 14, 2014 at 8:48 AM, Francesca Pancotto <
francesca.pancotto at unimore.it> wrote:

> Dear Contributors
> I seem not to get the general rule applying to the use of loops.
> I need some help. I have a database in which i need to generate a variable
> according to the following rule.
>
>
> This is the database head
>
>       bank_name       date px_last       Q_Y p_made p_for p_m p_f
> aba.1       ABA 2006-10-24    1.28 p406-q406    406   406   1   1
> aba.2       ABA 2006-11-30    1.31 p406-q406    406   406   1   1
> aba.3       ABA 2006-10-24    1.29 p406-q107    406   107   1   2
> aba.4       ABA 2006-11-30    1.33 p406-q107    406   107   1   2
> aba.5       ABA 2006-10-24    1.31 p406-q207    406   207   1   3
> aba.6       ABA 2006-11-30    1.35 p406-q207    406   207   1   3
>
>
> the variable p_f takes values from 1 to 19 in a non regular way.
>
> then I have a vector of 19 elements
>
> > spot$pxlast
>  [1] 1.32 1.34 1.35 1.43 1.46 1.58 1.58 1.41 1.40 1.33 1.40 1.46 1.43 1.35
> 1.22 1.36 1.34 1.42 1.42
>
> I need to create a variable to attach to the data frame which is composed
> of 11500 rows that takes values
> 1.32 when p_f==1
> 1.34 when p_f==2
>
> It seems so easy but I cannot find a way to do it in an efficient way.
> Thanks in advance for any help.
>
>
>
> Francesca
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From eliza_botto at hotmail.com  Fri Nov 14 16:04:33 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 14 Nov 2014 15:04:33 +0000
Subject: [R] replacing columns with same names
Message-ID: <BLU170-W108490845AEFC8C6AEE4596898C0@phx.gbl>

Dear useRs,
I have two matrices
> dput(EB)
structure(1:15, .Dim = c(3L, 5L), .Dimnames = list(NULL, c("A", "B", "C", "D", "E")))

> dput(EA)
structure(31:36, .Dim = c(3L, 2L), .Dimnames = list(NULL, c("D", "E")))
I have two question
1-Generally speaking, How can I replace the columns of matrix with the other columns having same names?
2-Precisely, how can I replace column "D" and "E" of "EB" with "D" and "E" of "EA"?
Thankyou very very much in advance.
Eliza 		 	   		  
	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Fri Nov 14 16:24:03 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 14 Nov 2014 16:24:03 +0100
Subject: [R] replacing columns with same names
In-Reply-To: <BLU170-W108490845AEFC8C6AEE4596898C0@phx.gbl>
References: <BLU170-W108490845AEFC8C6AEE4596898C0@phx.gbl>
Message-ID: <426CCCD0-6032-41F9-A8F5-155033227317@xs4all.nl>


On 14-11-2014, at 16:04, eliza botto <eliza_botto at hotmail.com> wrote:

> Dear useRs,
> I have two matrices
>> dput(EB)
> structure(1:15, .Dim = c(3L, 5L), .Dimnames = list(NULL, c("A", "B", "C", "D", "E")))
> 
>> dput(EA)
> structure(31:36, .Dim = c(3L, 2L), .Dimnames = list(NULL, c("D", "E")))
> I have two question
> 1-Generally speaking, How can I replace the columns of matrix with the other columns having same names?
> 2-Precisely, how can I replace column "D" and "E" of "EB" with "D" and "E" of "EA"?
> Thankyou very very much in advance.


How about

colnms <- c("D","E")
EB[,colnms] <-  EA[,colnms]

Berend


From dcarlson at tamu.edu  Fri Nov 14 16:25:23 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 14 Nov 2014 15:25:23 +0000
Subject: [R] Help with ddply/summarize
In-Reply-To: <9E73F88F04AA25408DBB58FB730BA6531E0044F9@AUSP01DAG0503.collaborationhost.net>
References: <9E73F88F04AA25408DBB58FB730BA6531E0044F9@AUSP01DAG0503.collaborationhost.net>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB2667@mb02.ads.tamu.edu>

I think this is what you want:

> MyVar <- 1:10
> MyVar
 [1]  1  2  3  4  5  6  7  8  9 10
> mean(MyVar)
[1] 5.5
> txt <- "MyVar"
> mean(txt)
[1] NA
Warning message:
In mean.default(txt) : argument is not numeric or logical: returning NA
> mean(get(txt))
[1] 5.5


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of John Posner
Sent: Thursday, November 13, 2014 5:32 PM
To: 'r-help at r-project.org'
Subject: [R] Help with ddply/summarize

I have a straightforward application of ddply() and summarize():

   ddply(MyFrame, .(Treatment, Week), summarize, MeanValue=mean(MyVar))

This works just fine:

   Treatment     Week MeanValue
1    MyDrug  BASELINE      5.91
2    MyDrug    WEEK 1      4.68
3    MyDrug    WEEK 2      4.08
4    MyDrug    WEEK 3      3.67
5    MyDrug    WEEK 4      2.96
6    MyDrug    WEEK 5      2.57
7    MyDrug    WEEK 6      2.50
8    Placebo BASELINE      8.58
9    Placebo   WEEK 1      8.25
...

But I want to specify the variable (MyVar) as a character string:

   ddply(MyFrame, .(Treatment, Week), summarize, MeanValue=mean("MyVar"))

(Actually, the character string "MyVar" will be selected from a vector of character strings.)

The code above produces no joy:

   Treatment     Week MeanValue
1    MyDrug  BASELINE        NA
2    MyDrug    WEEK 1        NA
3    MyDrug    WEEK 2        NA
4    MyDrug    WEEK 3        NA
...
I tried a few things, including:

  as.name("MyVar")
  as.quoted("MyVar")

... but they all produced the name results: NAs

I'm obviously thrashing around in the dark! Any advice would be greatly appreciated.

-John


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mikeumo at gmail.com  Fri Nov 14 16:42:01 2014
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Fri, 14 Nov 2014 09:42:01 -0600
Subject: [R] How to put inlined C code on a worker node?
Message-ID: <A1C5E1D2-CE13-4BDC-AF19-8EA7071C1C43@gmail.com>

Hello ?

I am using inline C functions within foreach %dopar% loop. On SMP (doParallel, doMP) it works but on MPI-based clusters (doMPI) it does?t. The reason, I think, is because the object code produced using the inline package, essentially an .so file, does not get copied onto the worker nodes when they are spawned using startMPIcluster().

Does anyone have any ideas on how I can send the object code to the workers and re-link it to the inline functions, or some other way? I know that I can define the inline functions within the foreach loop but it is very limiting and does not look pretty when you have a lot of functions to define. So, is there I way that follows a good programming style?

I would prefer to do it from within the R script and use the ?spawning? mode to paralellize.

Thank you for your time, 

Mikhail.

From eliza_botto at hotmail.com  Fri Nov 14 16:57:10 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 14 Nov 2014 15:57:10 +0000
Subject: [R] replacing columns with same names
In-Reply-To: <426CCCD0-6032-41F9-A8F5-155033227317@xs4all.nl>
References: <BLU170-W108490845AEFC8C6AEE4596898C0@phx.gbl>,
	<426CCCD0-6032-41F9-A8F5-155033227317@xs4all.nl>
Message-ID: <BLU170-W119FD63B602DBEE1080769898C0@phx.gbl>

Thankyou very much Berend. It worked!!!
Have a great weekend!!
:)
Eliza

> Subject: Re: [R] replacing columns with same names
> From: bhh at xs4all.nl
> Date: Fri, 14 Nov 2014 16:24:03 +0100
> CC: r-help at r-project.org
> To: eliza_botto at hotmail.com
> 
> 
> On 14-11-2014, at 16:04, eliza botto <eliza_botto at hotmail.com> wrote:
> 
> > Dear useRs,
> > I have two matrices
> >> dput(EB)
> > structure(1:15, .Dim = c(3L, 5L), .Dimnames = list(NULL, c("A", "B", "C", "D", "E")))
> > 
> >> dput(EA)
> > structure(31:36, .Dim = c(3L, 2L), .Dimnames = list(NULL, c("D", "E")))
> > I have two question
> > 1-Generally speaking, How can I replace the columns of matrix with the other columns having same names?
> > 2-Precisely, how can I replace column "D" and "E" of "EB" with "D" and "E" of "EA"?
> > Thankyou very very much in advance.
> 
> 
> How about
> 
> colnms <- c("D","E")
> EB[,colnms] <-  EA[,colnms]
> 
> Berend
> 
 		 	   		  
	[[alternative HTML version deleted]]


From john.posner at MJBIOSTAT.COM  Fri Nov 14 17:19:45 2014
From: john.posner at MJBIOSTAT.COM (John Posner)
Date: Fri, 14 Nov 2014 16:19:45 +0000
Subject: [R] Help with ddply/summarize
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FB2667@mb02.ads.tamu.edu>
References: <9E73F88F04AA25408DBB58FB730BA6531E0044F9@AUSP01DAG0503.collaborationhost.net>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FB2667@mb02.ads.tamu.edu>
Message-ID: <9E73F88F04AA25408DBB58FB730BA6531E004790@AUSP01DAG0503.collaborationhost.net>

> -----Original Message-----
> From: David L Carlson [mailto:dcarlson at tamu.edu]
> Sent: Friday, November 14, 2014 10:25 AM
> To: John Posner; 'r-help at r-project.org'
> Subject: RE: Help with ddply/summarize
> 
> I think this is what you want:
> 
> > MyVar <- 1:10
> > MyVar
>  [1]  1  2  3  4  5  6  7  8  9 10
> > mean(MyVar)
> [1] 5.5
> > txt <- "MyVar"
> > mean(txt)
> [1] NA
> Warning message:
> In mean.default(txt) : argument is not numeric or logical: returning NA
> > mean(get(txt))
> [1] 5.5
> 

Got it.  I was also pointed to get() by David Winsemius. Thanks to both Davids!

-John


> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of John Posner
> Sent: Thursday, November 13, 2014 5:32 PM
> To: 'r-help at r-project.org'
> Subject: [R] Help with ddply/summarize
> 
> I have a straightforward application of ddply() and summarize():
> 
>    ddply(MyFrame, .(Treatment, Week), summarize,
> MeanValue=mean(MyVar))
> 
> This works just fine:
> 
>    Treatment     Week MeanValue
> 1    MyDrug  BASELINE      5.91
> 2    MyDrug    WEEK 1      4.68
> 3    MyDrug    WEEK 2      4.08
> 4    MyDrug    WEEK 3      3.67
> 5    MyDrug    WEEK 4      2.96
> 6    MyDrug    WEEK 5      2.57
> 7    MyDrug    WEEK 6      2.50
> 8    Placebo BASELINE      8.58
> 9    Placebo   WEEK 1      8.25
> ...
> 
> But I want to specify the variable (MyVar) as a character string:
> 
>    ddply(MyFrame, .(Treatment, Week), summarize,
> MeanValue=mean("MyVar"))
> 
> (Actually, the character string "MyVar" will be selected from a vector of
> character strings.)
> 
> The code above produces no joy:
> 
>    Treatment     Week MeanValue
> 1    MyDrug  BASELINE        NA
> 2    MyDrug    WEEK 1        NA
> 3    MyDrug    WEEK 2        NA
> 4    MyDrug    WEEK 3        NA
> ...
> I tried a few things, including:
> 
>   as.name("MyVar")
>   as.quoted("MyVar")
> 
> ... but they all produced the name results: NAs
> 
> I'm obviously thrashing around in the dark! Any advice would be greatly
> appreciated.
> 
> -John
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bsmith030465 at gmail.com  Fri Nov 14 17:37:43 2014
From: bsmith030465 at gmail.com (Brian Smith)
Date: Fri, 14 Nov 2014 11:37:43 -0500
Subject: [R] package multicore: check progress?
Message-ID: <CAEQKoCFgUJ60jKj2gnxGcoRRsyVMbyFkh=hXQJv7MEVefyxprg@mail.gmail.com>

Hi,

I use multicore package quite a lot. However, I want to find a way to check
on the progress of my job. For example:

ftest <- function(x){
if(x %% 100 == 0) print(x)
y <- 2x

return(y)
}

res <- mclapply(1:1000,ftest)


This would print the value of x in a for loop, but doesn't produce anything
when using the mclapply function.

Is there a way to check on the progress of the job?

thanks!

	[[alternative HTML version deleted]]


From theosjp at gmail.com  Fri Nov 14 14:12:59 2014
From: theosjp at gmail.com (theo)
Date: Fri, 14 Nov 2014 22:12:59 +0900
Subject: [R] Data Import to R
In-Reply-To: <B70A1364-5A26-42EA-AC94-016706F89C29@comcast.net>
References: <CAKo12DaYFaQ+OVs9_swhuAPLKqPBPETCwwDi-A0Cp4F25Y7a9A@mail.gmail.com>
	<B70A1364-5A26-42EA-AC94-016706F89C29@comcast.net>
Message-ID: <5465FFDB.6040502@gmail.com>

i think you can set: options(stringsAsFactor=FALSE)  which will apply
globally or use read.csv(..., stringsAsFactor=FALSE) when imporing.
have a look at the documentation ?read.csv
good luck.

On 11/14/2014 09:44 AM, David Winsemius wrote:
> 
> On Nov 13, 2014, at 4:28 PM, Ramesh Gautam wrote:
> 
>> While importing .csv files into R, all data are converted to factor-by
>> default. But, how can I preserve the original format of the data like
>> numeric to numeric, integer to integer, character to character etc while
>> importing from csv to R environment.
>>
>> I tried several ways, no thing helps. I used 'stringsAsFactor = FALSE'
>> command, it did convert all data to characters. But, I wanted to preserve
>> the numeric data to be in integer or double.
> 
> Use colClasses. And if that hint is not enough then post an example to work with.
>>
>> Any idea? examples?
>>
>> Thanks
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chidambaramselvakumar at gmail.com  Fri Nov 14 18:34:07 2014
From: chidambaramselvakumar at gmail.com (Chidambaram Selvakumar)
Date: Fri, 14 Nov 2014 23:04:07 +0530
Subject: [R] Urgent Help - Editing XML through R
In-Reply-To: <CA+WmytSNO-_dEjNp-Jabo-eLcEwdLeNui9-3VgNF09AAmODziw@mail.gmail.com>
References: <CA+WmytSNO-_dEjNp-Jabo-eLcEwdLeNui9-3VgNF09AAmODziw@mail.gmail.com>
Message-ID: <CA+WmytTx5QKjOcNdB_-jXUGMC6u8S2KMzWTPcNYemRMov-==cA@mail.gmail.com>

Hi Team,

Can you please help me on the below?

1) Is it possible to achieve the below requirement through or not?
       Open XMl; find and remove the all the string tag;add new string tag
based on the email count; save it in the same XML.
2) If yes can you please share the script

As I am new to R script, I am expecting your help to achieve this.

Thanks in advance.

Regards
Chidambaram
On Nov 8, 2014 1:10 PM, "Chidambaram Selvakumar" <
chidambaramselvakumar at gmail.com> wrote:
>
> Hi Team,
>
> I have the below xml file where i have to find and remove all the email
address in <string> tag and need to append the new email address using R
script.May be string tag needs to be added or decreased based on the email
list.
>
> XM File
>
> <?xml version="1.0" encoding="utf-8"?>
> <as:Job xmlns:as="urn:tibco:spotfire.dxp.automation">
>   <as:Tasks>
>     <OpenAnalysisFromLibrary
xmlns="urn:tibco:spotfire.dxp.automation.tasks">
>       <as:Title>Open Analysis from Library</as:Title>
>       <AnalysisPath>/Z- Archive - TO BE
purged/ConditionEmailTest</AnalysisPath>
>     </OpenAnalysisFromLibrary>
>     <SendEmail xmlns="urn:tibco:spotfire.dxp.automation.tasks">
>       <as:Title>Send Email</as:Title>
>       <Recipients>
>         <string>chidambaramselvakumar at gmail.com</string>
> <string>chidambaramselvakumar at gmail.com</string>
>       </Recipients>
>       <Subject>Sales Report</Subject>
>       <Message>Hi,
>
> Good Day!
>
> Thanks for achieving your sales target.
>
> Regards,
> Chidambaram</Message>
>       <Links />
>       <Attachments />
>     </SendEmail>
>   </as:Tasks>
> </as:Job>
>
> Kindly help me. It is little urgent.
>
> Thanks in advance for your effort and support.
>
> Regards,
> Chidambaram

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Nov 14 19:04:09 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 14 Nov 2014 10:04:09 -0800
Subject: [R] How to put inlined C code on a worker node?
In-Reply-To: <A1C5E1D2-CE13-4BDC-AF19-8EA7071C1C43@gmail.com>
References: <A1C5E1D2-CE13-4BDC-AF19-8EA7071C1C43@gmail.com>
Message-ID: <68B1A1AA-B4B4-4190-8CDC-BAFDA485F436@dcn.davis.CA.us>

Repeating yourself verbatim is poor form. At least quote your previous message and indicate that this is a reprise.

While I doubt that my opinion is universal, I think that mixing C and R in the same file is already living on the edge of good practice. You are assuming that all of your nodes have the infrastructure to compile your code on the fly, which is something you have to insure for each node in your facilities. A less convenient but more conventional approach is to create your own support package(s) that contain the compiled portions of your code and distribute them prior to running your application.

However, this conversation might be more productive if conducted between you and the maintainer of the inline package (see ?maintainer) or on the R-devel list because it is outside the R language.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 14, 2014 7:42:01 AM PST, Mikhail Umorin <mikeumo at gmail.com> wrote:
>Hello ?
>
>I am using inline C functions within foreach %dopar% loop. On SMP
>(doParallel, doMP) it works but on MPI-based clusters (doMPI) it
>does?t. The reason, I think, is because the object code produced using
>the inline package, essentially an .so file, does not get copied onto
>the worker nodes when they are spawned using startMPIcluster().
>
>Does anyone have any ideas on how I can send the object code to the
>workers and re-link it to the inline functions, or some other way? I
>know that I can define the inline functions within the foreach loop but
>it is very limiting and does not look pretty when you have a lot of
>functions to define. So, is there I way that follows a good programming
>style?
>
>I would prefer to do it from within the R script and use the ?spawning?
>mode to paralellize.
>
>Thank you for your time, 
>
>Mikhail.
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mikeumo at gmail.com  Fri Nov 14 19:10:12 2014
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Fri, 14 Nov 2014 12:10:12 -0600
Subject: [R] How to put inlined C code on a worker node?
In-Reply-To: <68B1A1AA-B4B4-4190-8CDC-BAFDA485F436@dcn.davis.CA.us>
References: <A1C5E1D2-CE13-4BDC-AF19-8EA7071C1C43@gmail.com>
	<68B1A1AA-B4B4-4190-8CDC-BAFDA485F436@dcn.davis.CA.us>
Message-ID: <7624AF07-BB3F-4CD8-A7FD-DC659D53B802@gmail.com>

Sorry for the trouble with double posting: I never received my original message through the mailing list so I assumed that it did not go through.

I?ll try your suggestions, thank you.

Mikhail.

> On Nov 14, 2014, at 12:04, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:
> 
> Repeating yourself verbatim is poor form. At least quote your previous message and indicate that this is a reprise.
> 
> While I doubt that my opinion is universal, I think that mixing C and R in the same file is already living on the edge of good practice. You are assuming that all of your nodes have the infrastructure to compile your code on the fly, which is something you have to insure for each node in your facilities. A less convenient but more conventional approach is to create your own support package(s) that contain the compiled portions of your code and distribute them prior to running your application.
> 
> However, this conversation might be more productive if conducted between you and the maintainer of the inline package (see ?maintainer) or on the R-devel list because it is outside the R language.
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On November 14, 2014 7:42:01 AM PST, Mikhail Umorin <mikeumo at gmail.com> wrote:
>> Hello ?
>> 
>> I am using inline C functions within foreach %dopar% loop. On SMP
>> (doParallel, doMP) it works but on MPI-based clusters (doMPI) it
>> does?t. The reason, I think, is because the object code produced using
>> the inline package, essentially an .so file, does not get copied onto
>> the worker nodes when they are spawned using startMPIcluster().
>> 
>> Does anyone have any ideas on how I can send the object code to the
>> workers and re-link it to the inline functions, or some other way? I
>> know that I can define the inline functions within the foreach loop but
>> it is very limiting and does not look pretty when you have a lot of
>> functions to define. So, is there I way that follows a good programming
>> style?
>> 
>> I would prefer to do it from within the R script and use the ?spawning?
>> mode to paralellize.
>> 
>> Thank you for your time, 
>> 
>> Mikhail.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From edd at debian.org  Fri Nov 14 19:49:00 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 14 Nov 2014 12:49:00 -0600
Subject: [R] How to put inlined C code on a worker node?
In-Reply-To: <7624AF07-BB3F-4CD8-A7FD-DC659D53B802@gmail.com>
References: <A1C5E1D2-CE13-4BDC-AF19-8EA7071C1C43@gmail.com>
	<68B1A1AA-B4B4-4190-8CDC-BAFDA485F436@dcn.davis.CA.us>
	<7624AF07-BB3F-4CD8-A7FD-DC659D53B802@gmail.com>
Message-ID: <21606.20124.681198.430299@max.nulle.part>


Mikhail,

The canonical recommendation is to wrap you code in a package -- either
source or even binary -- and to install it on the nodes.

Writing a package is the correct answer to many questions, and is
particularly true here.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From macqueen1 at llnl.gov  Fri Nov 14 20:11:20 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 14 Nov 2014 19:11:20 +0000
Subject: [R] Data Import to R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEE82D@SRVEXCHMBX.precheza.cz>
References: <CAKo12DaYFaQ+OVs9_swhuAPLKqPBPETCwwDi-A0Cp4F25Y7a9A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEE82D@SRVEXCHMBX.precheza.cz>
Message-ID: <D08B92C2.112485%macqueen1@llnl.gov>

Petr is almost certainly correct. A further suggestion:

Continue to import using stringsAsFactors = FALSE

On one of the columns that should be numeric, use as.numeric(), find the
NA's in the result of that, and then look at those rows of the data. There
will be something there that is non-numeric. By any chance, does your data
use a comma instead of a decimal point (see the "dec" argument to
read.table)?

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/13/14, 10:01 PM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:

>Hi
>
>Your original numeric data probably contain something which prevents
>read.* to accept them as numeric (decimal point, white space)
>
>what is result of
>
>str(imported.data)
>
>Petr Pikal
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Ramesh Gautam
>> Sent: Friday, November 14, 2014 1:28 AM
>> To: r-help at r-project.org
>> Subject: [R] Data Import to R
>>
>> While importing .csv files into R, all data are converted to factor-by
>> default. But, how can I preserve the original format of the data like
>> numeric to numeric, integer to integer, character to character etc
>> while importing from csv to R environment.
>>
>> I tried several ways, no thing helps. I used 'stringsAsFactor = FALSE'
>> command, it did convert all data to characters. But, I wanted to
>> preserve the numeric data to be in integer or double.
>>
>> Any idea? examples?
>
>Your original numeric data probably contain something which prevents
>read.* to accept them as numeric (decimal point, white space)
>
>What is result of str(imported.data)
>
>Example of data is up to you, we do not have them.
>
>Cheers
>Petr
>
>
>>
>> Thanks
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and are
>intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into a
>contract in any time, for any reason, and without stating any reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer) excludes
>any acceptance of the offer on the part of the recipient containing any
>amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by the
>recipient.
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Nov 14 20:27:22 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 14 Nov 2014 14:27:22 -0500
Subject: [R] Urgent Help - Editing XML through R
In-Reply-To: <CA+WmytTx5QKjOcNdB_-jXUGMC6u8S2KMzWTPcNYemRMov-==cA@mail.gmail.com>
References: <CA+WmytSNO-_dEjNp-Jabo-eLcEwdLeNui9-3VgNF09AAmODziw@mail.gmail.com>
	<CA+WmytTx5QKjOcNdB_-jXUGMC6u8S2KMzWTPcNYemRMov-==cA@mail.gmail.com>
Message-ID: <5466579A.6060700@gmail.com>

On 14/11/2014 12:34 PM, Chidambaram Selvakumar wrote:
> Hi Team,
>
> Can you please help me on the below?
>
> 1) Is it possible to achieve the below requirement through or not?
>         Open XMl; find and remove the all the string tag;add new string tag
> based on the email count; save it in the same XML.
> 2) If yes can you please share the script
>
> As I am new to R script, I am expecting your help to achieve this.

As you are new to R scripts, I'll assume you are also new to R Help, so 
I'll explain the etiquette.

You are asking for help to work with a commercial product, for which you 
should have paid a license fee.  But you are asking us to help you for 
free.  You should have a Spotfire license, and you should be asking 
Tibco for help to work with it.

Duncan Murdoch
>
> Thanks in advance.
>
> Regards
> Chidambaram
> On Nov 8, 2014 1:10 PM, "Chidambaram Selvakumar" <
> chidambaramselvakumar at gmail.com> wrote:
> >
> > Hi Team,
> >
> > I have the below xml file where i have to find and remove all the email
> address in <string> tag and need to append the new email address using R
> script.May be string tag needs to be added or decreased based on the email
> list.
> >
> > XM File
> >
> > <?xml version="1.0" encoding="utf-8"?>
> > <as:Job xmlns:as="urn:tibco:spotfire.dxp.automation">
> >   <as:Tasks>
> >     <OpenAnalysisFromLibrary
> xmlns="urn:tibco:spotfire.dxp.automation.tasks">
> >       <as:Title>Open Analysis from Library</as:Title>
> >       <AnalysisPath>/Z- Archive - TO BE
> purged/ConditionEmailTest</AnalysisPath>
> >     </OpenAnalysisFromLibrary>
> >     <SendEmail xmlns="urn:tibco:spotfire.dxp.automation.tasks">
> >       <as:Title>Send Email</as:Title>
> >       <Recipients>
> >         <string>chidambaramselvakumar at gmail.com</string>
> > <string>chidambaramselvakumar at gmail.com</string>
> >       </Recipients>
> >       <Subject>Sales Report</Subject>
> >       <Message>Hi,
> >
> > Good Day!
> >
> > Thanks for achieving your sales target.
> >
> > Regards,
> > Chidambaram</Message>
> >       <Links />
> >       <Attachments />
> >     </SendEmail>
> >   </as:Tasks>
> > </as:Job>
> >
> > Kindly help me. It is little urgent.
> >
> > Thanks in advance for your effort and support.
> >
> > Regards,
> > Chidambaram
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From i.petzev at gmail.com  Fri Nov 14 21:15:44 2014
From: i.petzev at gmail.com (ivan)
Date: Fri, 14 Nov 2014 21:15:44 +0100
Subject: [R] Bootstrap CIs for weighted means of paired differences
Message-ID: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>

Hi,

I am trying to compute bootstrap confidence intervals for weighted means of
paired differences with the boot package. Unfortunately, the weighted mean
estimate lies out of the confidence bounds and hence I am obviously doing
something wrong.

Appreciate any help. Thanks. Here is a reproducible example:


library(boot)
set.seed(1111)
x <- rnorm(50)
y <- rnorm(50)
weights <- runif(50)
weights <- weights / sum(weights)
dataset <- cbind(x,y,weights)
vw_m_diff <- function(dataset,w, d) {
    differences <- dataset[d,1]-dataset[d,2]
    weights <- w[d]
    return(weighted.mean(x=differences, w=weights))
}
res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
boot.ci(res_boot)

*BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS*
*Based on 1000 bootstrap replicates*

*CALL : *
*boot.ci <http://boot.ci>(boot.out = res_boot)*

*Intervals : *
*Level      Normal              Basic         *
*95%   (-0.8365, -0.3463 )   (-0.8311, -0.3441 )  *

*Level     Percentile            BCa          *
*95%   (-0.3276,  0.1594 )   (-0.4781, -0.3477 )  *

weighted.mean(x=dataset[,1]-dataset[,2], w=dataset[,3])

*[1] -0.07321734*

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Fri Nov 14 21:33:27 2014
From: jholtman at gmail.com (jim holtman)
Date: Fri, 14 Nov 2014 15:33:27 -0500
Subject: [R] Urgent Help - Editing XML through R
In-Reply-To: <CA+WmytTx5QKjOcNdB_-jXUGMC6u8S2KMzWTPcNYemRMov-==cA@mail.gmail.com>
References: <CA+WmytSNO-_dEjNp-Jabo-eLcEwdLeNui9-3VgNF09AAmODziw@mail.gmail.com>
	<CA+WmytTx5QKjOcNdB_-jXUGMC6u8S2KMzWTPcNYemRMov-==cA@mail.gmail.com>
Message-ID: <CAAxdm-7hXahExp81icF7b+DeHRmdcziGbpBykgTLd4g4Q_5hAg@mail.gmail.com>

Here is one way using the XML package:


> x <- '<?xml version="1.0" encoding="utf-8"?>
+ <as:Job xmlns:as="urn:tibco:spotfire.dxp.automation">
+   <as:Tasks>
+     <OpenAnalysisFromLibrary
+ xmlns="urn:tibco:spotfire.dxp.automation.tasks">
+       <as:Title>Open Analysis from Library</as:Title>
+       <AnalysisPath>/Z- Archive - TO BE
+ purged/ConditionEmailTest</AnalysisPath>
+     </OpenAnalysisFromLibrary>
+     <SendEmail xmlns="urn:tibco:spotfire.dxp.automation.tasks">
+       <as:Title>Send Email</as:Title>
+       <Recipients>
+         <string>chidambaramselvakumar at gmail.com</string>
+ <string>chidambaramselvakumar at gmail.com</string>
+       </Recipients>
+       <Subject>Sales Report</Subject>
+       <Message>Hi,
+
+ Good Day!
+
+ Thanks for achieving your sales target.
+
+ Regards,
+ Chidambaram</Message>
+       <Links />
+       <Attachments />
+     </SendEmail>
+   </as:Tasks>
+ </as:Job>'
> require(XML)
>
> doc <- xmlParse(x)
> docRoot <- xmlRoot(doc)
>



> # change the second email and then output
> docRoot[["Tasks"]][["SendEmail"]][["Recipients"]][[2]][['text']] <- "
name at domain.tv"
> print(docRoot)



<as:Job xmlns:as="urn:tibco:spotfire.dxp.automation">
  <as:Tasks>
    <OpenAnalysisFromLibrary
xmlns="urn:tibco:spotfire.dxp.automation.tasks">
      <as:Title>Open Analysis from Library</as:Title>
      <AnalysisPath>/Z- Archive - TO BE
purged/ConditionEmailTest</AnalysisPath>
    </OpenAnalysisFromLibrary>
    <SendEmail xmlns="urn:tibco:spotfire.dxp.automation.tasks">
      <as:Title>Send Email</as:Title>
      <Recipients>
        <string>chidambaramselvakumar at gmail.com</string>
        <string>name at domain.tv</string>
      </Recipients>
      <Subject>Sales Report</Subject>
      <Message>Hi,

Good Day!

Thanks for achieving your sales target.

Regards,
Chidambaram</Message>
      <Links/>
      <Attachments/>
    </SendEmail>
  </as:Tasks>
</as:Job>



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Nov 14, 2014 at 12:34 PM, Chidambaram Selvakumar <
chidambaramselvakumar at gmail.com> wrote:

> Hi Team,
>
> Can you please help me on the below?
>
> 1) Is it possible to achieve the below requirement through or not?
>        Open XMl; find and remove the all the string tag;add new string tag
> based on the email count; save it in the same XML.
> 2) If yes can you please share the script
>
> As I am new to R script, I am expecting your help to achieve this.
>
> Thanks in advance.
>
> Regards
> Chidambaram
> On Nov 8, 2014 1:10 PM, "Chidambaram Selvakumar" <
> chidambaramselvakumar at gmail.com> wrote:
> >
> > Hi Team,
> >
> > I have the below xml file where i have to find and remove all the email
> address in <string> tag and need to append the new email address using R
> script.May be string tag needs to be added or decreased based on the email
> list.
> >
> > XM File
> >
> > <?xml version="1.0" encoding="utf-8"?>
> > <as:Job xmlns:as="urn:tibco:spotfire.dxp.automation">
> >   <as:Tasks>
> >     <OpenAnalysisFromLibrary
> xmlns="urn:tibco:spotfire.dxp.automation.tasks">
> >       <as:Title>Open Analysis from Library</as:Title>
> >       <AnalysisPath>/Z- Archive - TO BE
> purged/ConditionEmailTest</AnalysisPath>
> >     </OpenAnalysisFromLibrary>
> >     <SendEmail xmlns="urn:tibco:spotfire.dxp.automation.tasks">
> >       <as:Title>Send Email</as:Title>
> >       <Recipients>
> >         <string>chidambaramselvakumar at gmail.com</string>
> > <string>chidambaramselvakumar at gmail.com</string>
> >       </Recipients>
> >       <Subject>Sales Report</Subject>
> >       <Message>Hi,
> >
> > Good Day!
> >
> > Thanks for achieving your sales target.
> >
> > Regards,
> > Chidambaram</Message>
> >       <Links />
> >       <Attachments />
> >     </SendEmail>
> >   </as:Tasks>
> > </as:Job>
> >
> > Kindly help me. It is little urgent.
> >
> > Thanks in advance for your effort and support.
> >
> > Regards,
> > Chidambaram
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mardones.p at gmail.com  Fri Nov 14 22:45:40 2014
From: mardones.p at gmail.com (Pedro Mardones)
Date: Fri, 14 Nov 2014 18:45:40 -0300
Subject: [R] select same row in a data frame several times
Message-ID: <CAEd7G2eJDQMeJihHgsyv0ECCDFEMJDENHhh3Uwekot1gYwzeOw@mail.gmail.com>

Dear R user;

Consider the following toy example

A <- data.frame(ID1 = c(1,2,3,1,2,3,1,2,3), ID2 =
c("a","b","c","d","e","f","g","h","i"), stringsAsFactors = FALSE)
B <- sample(a$ID2, 6, replace = TRUE)

Lets say B is = "a", "a", "a", "h", "b", "e"

I want to extract from A the rows where ID2 == B. If I use
AA <- A[A$ID2 %in% B == TRUE,], I get only 1 row with ID2="a" instead of
the 3 rows I want.

Is it possible to easily implement this selection? (same row several times)

Thanks
Pedro

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Nov 14 22:58:47 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 15 Nov 2014 10:58:47 +1300
Subject: [R] HELP ON NON-LINEAR MIXED MODEL
In-Reply-To: <1415942961.97300.YahooMailBasic@web141701.mail.bf1.yahoo.com>
References: <1415942961.97300.YahooMailBasic@web141701.mail.bf1.yahoo.com>
Message-ID: <54667B17.9000104@auckland.ac.nz>

On 14/11/14 18:29, Popoola Daniel wrote:
> Good Morning Sir/Ma, I am POPOOLA DANIEL a Forest Biometrician in
> making from the University of Ibadan, Ibadan Nigeria. Please Sir/Ma I
> am having issues on performing Non-linear mixed model on R (using
> maximum likelihood approach). I am trying to input four different
> measured variables which are basal area, diameter at breast height,
> Dominant height,quadratic mean diameter as a function for height
> prediction on equation. But I have not been able to get through with
> the model.
>
> Please I need your  candid options on how to go about this. Other
> useful tips on Codes entering for data analysis in R environment will
> also be appreciated .

(1) Your question is far too vague for anyone to be able to give you a 
useful response.  You should provide a small reproducible example of 
what you are trying to do and a clear explanation of what problems you 
are having in trying to do it.

(2) Questions about mixed models are better addressed to the "special 
interest group" R-sig-ME.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From macqueen1 at llnl.gov  Fri Nov 14 23:15:11 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 14 Nov 2014 22:15:11 +0000
Subject: [R] select same row in a data frame several times
In-Reply-To: <CAEd7G2eJDQMeJihHgsyv0ECCDFEMJDENHhh3Uwekot1gYwzeOw@mail.gmail.com>
References: <CAEd7G2eJDQMeJihHgsyv0ECCDFEMJDENHhh3Uwekot1gYwzeOw@mail.gmail.com>
Message-ID: <D08BBE96.1124B6%macqueen1@llnl.gov>

Try

B <- c("a", "a", "a", "h", "b", "e")
subset(A, ID2 %in% B)

or
  subset(A, ID2 %in% unique(B))
will do as well


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/14/14, 1:45 PM, "Pedro Mardones" <mardones.p at gmail.com> wrote:

>Dear R user;
>
>Consider the following toy example
>
>A <- data.frame(ID1 = c(1,2,3,1,2,3,1,2,3), ID2 =
>c("a","b","c","d","e","f","g","h","i"), stringsAsFactors = FALSE)
>B <- sample(a$ID2, 6, replace = TRUE)
>
>Lets say B is = "a", "a", "a", "h", "b", "e"
>
>I want to extract from A the rows where ID2 == B. If I use
>AA <- A[A$ID2 %in% B == TRUE,], I get only 1 row with ID2="a" instead of
>the 3 rows I want.
>
>Is it possible to easily implement this selection? (same row several
>times)
>
>Thanks
>Pedro
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Fri Nov 14 23:18:50 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 14 Nov 2014 22:18:50 +0000
Subject: [R] select same row in a data frame several times
In-Reply-To: <CAEd7G2eJDQMeJihHgsyv0ECCDFEMJDENHhh3Uwekot1gYwzeOw@mail.gmail.com>
References: <CAEd7G2eJDQMeJihHgsyv0ECCDFEMJDENHhh3Uwekot1gYwzeOw@mail.gmail.com>
Message-ID: <D08BBFAD.1124BB%macqueen1@llnl.gov>

Sorry, I was too quick.

Try
  A[ match(B, A$ID2) ,]

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/14/14, 1:45 PM, "Pedro Mardones" <mardones.p at gmail.com> wrote:

>Dear R user;
>
>Consider the following toy example
>
>A <- data.frame(ID1 = c(1,2,3,1,2,3,1,2,3), ID2 =
>c("a","b","c","d","e","f","g","h","i"), stringsAsFactors = FALSE)
>B <- sample(a$ID2, 6, replace = TRUE)
>
>Lets say B is = "a", "a", "a", "h", "b", "e"
>
>I want to extract from A the rows where ID2 == B. If I use
>AA <- A[A$ID2 %in% B == TRUE,], I get only 1 row with ID2="a" instead of
>the 3 rows I want.
>
>Is it possible to easily implement this selection? (same row several
>times)
>
>Thanks
>Pedro
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Fri Nov 14 23:20:09 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 15 Nov 2014 11:20:09 +1300
Subject: [R] select same row in a data frame several times
In-Reply-To: <CAEd7G2eJDQMeJihHgsyv0ECCDFEMJDENHhh3Uwekot1gYwzeOw@mail.gmail.com>
References: <CAEd7G2eJDQMeJihHgsyv0ECCDFEMJDENHhh3Uwekot1gYwzeOw@mail.gmail.com>
Message-ID: <54668019.8070405@auckland.ac.nz>

On 15/11/14 10:45, Pedro Mardones wrote:
> Dear R user;
>
> Consider the following toy example
>
> A <- data.frame(ID1 = c(1,2,3,1,2,3,1,2,3), ID2 =
> c("a","b","c","d","e","f","g","h","i"), stringsAsFactors = FALSE)
> B <- sample(a$ID2, 6, replace = TRUE)
>
> Lets say B is = "a", "a", "a", "h", "b", "e"
>
> I want to extract from A the rows where ID2 == B. If I use
> AA <- A[A$ID2 %in% B == TRUE,], I get only 1 row with ID2="a" instead of
> the 3 rows I want.
>
> Is it possible to easily implement this selection? (same row several times)

AA <- A[match(B,A$ID2),]

cheers,

Rolf Turner

P.S. The syntax "A$ID2 %in% B == TRUE" is a message brought to you by 
the Department of Redundancy Department, and it drives me _crazy_!  Just 
use "A$ID2%in%B,".

If "v" is a logical vector then "v==TRUE" is identical to v.

See fortune(69).

R. T.

-- 
Rolf Turner
Technical Editor ANZJS


From dwinsemius at comcast.net  Sat Nov 15 00:18:05 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Nov 2014 15:18:05 -0800
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
Message-ID: <C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>


On Nov 14, 2014, at 12:15 PM, ivan wrote:

> Hi,
> 
> I am trying to compute bootstrap confidence intervals for weighted means of
> paired differences with the boot package. Unfortunately, the weighted mean
> estimate lies out of the confidence bounds and hence I am obviously doing
> something wrong.
> 
> Appreciate any help. Thanks. Here is a reproducible example:
> 
> 
> library(boot)
> set.seed(1111)
> x <- rnorm(50)
> y <- rnorm(50)
> weights <- runif(50)
> weights <- weights / sum(weights)
> dataset <- cbind(x,y,weights)
> vw_m_diff <- function(dataset,w, d) {

My understanding of the principle underlying the design of the bootstrapped function was that the data was the first argument and the index vector was the second. (I admit to not knowing what it would do with a third argument. So I would have guessed that you wanted:

 vw_m_diff <- function(dataset,w) {
     differences <- dataset[d,1]-dataset[d,2]
    weights <- dataset[w, "weights"]
    return(weighted.mean(x=differences, w=weights))
  } 

I get what appears to me as a sensible set of estimates (since they seem centered on zero) although I further admit I do not know what the theoretic CI _should_ be for this problem:

> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
> boot.ci(res_boot)
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 1000 bootstrap replicates

CALL : 
boot.ci(boot.out = res_boot)

Intervals : 
Level      Normal              Basic         
95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )  

Level     Percentile            BCa          
95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )  
Calculations and Intervals on Original Scale


>    differences <- dataset[d,1]-dataset[d,2]
>    weights <- w[d]
>    return(weighted.mean(x=differences, w=weights))
> }
> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
> boot.ci(res_boot)
> 
> *BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS*
> *Based on 1000 bootstrap replicates*
> 
> *CALL : *
> *boot.ci <http://boot.ci>(boot.out = res_boot)*
> 
> *Intervals : *
> *Level      Normal              Basic         *
> *95%   (-0.8365, -0.3463 )   (-0.8311, -0.3441 )  *
> 
> *Level     Percentile            BCa          *
> *95%   (-0.3276,  0.1594 )   (-0.4781, -0.3477 )  *
> 
> weighted.mean(x=dataset[,1]-dataset[,2], w=dataset[,3])
> 
> *[1] -0.07321734*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From janko.thyson at gmail.com  Sat Nov 15 00:51:16 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Sat, 15 Nov 2014 00:51:16 +0100
Subject: [R] Lexical scoping/calling stack issue: R fails to recognize an
 argument's default value
Message-ID: <CAGmpueggerHVJd0fOdWuw7xPM33pYrPgHjB7XDMhA0j3+JdBPQ@mail.gmail.com>

Dear list,

I just encountered a behavior that I've never seen before:

Is it possible, that certain argument names (lazy in my case) are
special/reserved and thus would lead to unexpected behavior when a calling
stack is involved that spreads across functions of three different
packages: optionr::setAnywhereOptions() calls nestr::setNested() calls
reactr::setShinyReactive()?

Or is there something I'm generally missing with respect the combination of
lexical scoping/the frame stack, S4 and default values of function
arguments.

Running the following code leads to a situation where the default value of
`lazy` in `reactr::setShinyReactive()` is not properly recognized while
others (e.g. `push`) are recognized just fine:

require("devtools")
devtools::install_github("Rappster/conditionr")
devtools::install_github("Rappster/nestr")
devtools::install_github("Rappster/optionr")
require("optionr")

container <- initializeOptionContainer(overwrite = TRUE)
expect_true(setAnywhereOption(id = "x_1", value = TRUE, reactive = TRUE))
expect_equal(getAnywhereOption(id = "x_1"), TRUE)
expect_true(res <- setAnywhereOption(id = "x_2",
  value = reactr::reactiveExpression(
    !getAnywhereOption(id = "x_1")
  ),
  reactive = TRUE))

The current version of `setShinyReactive()` contains a debugging section
that prints these status messages (the actual code:
https://github.com/Rappster/reactr/blob/bug-28/R/setShinyReactive.r#L196)

DEBUG/push/before[1] FALSE
DEBUG/lazy/before
Error in print(lazy) : argument is missing, with no default
DEBUG/is_lazy/before[1] FALSE
DEBUG/lazy/after[1] FALSE

It also contains my current workaround: also include an argument with
name `is_lazy` (whose default)
value is recognized again) and then run `lazy <- is_lazy`.

You can also find this information in this Stackoverflow post:
http://stackoverflow.com/questions/26940474/lexical-scoping-issue-r-fails-to-recognize-an-arguments-default-value

Thanks a lot for everyone that can shed some light on this!


Best regards,
Janko

	[[alternative HTML version deleted]]


From janko.thyson at gmail.com  Sat Nov 15 01:39:37 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Sat, 15 Nov 2014 01:39:37 +0100
Subject: [R] Lexical scoping/calling stack issue: R fails to recognize
 an argument's default value
In-Reply-To: <54669A93.8010906@gmail.com>
References: <CAGmpueggerHVJd0fOdWuw7xPM33pYrPgHjB7XDMhA0j3+JdBPQ@mail.gmail.com>
	<54669A93.8010906@gmail.com>
Message-ID: <CAGmpuegBpwjxzVdGupAPGQ2kavdXAHCDy6x03beE7f+QfiAU9w@mail.gmail.com>

Hi Duncan,

thanks for answering and I'm very sorry: I was a bit too quick with letting
the example go.

This should be self-contained now:

require("devtools")

## Dependencies //
devtools::install_github("Rappster/conditionr")
devtools::install_github("Rappster/typr")
devtools::install_github("Rappster/nestr")
devtools::install_github("Rappster/reactr", ref = "bug-28")
## Actual package //
devtools::install_github("Rappster/optionr")
require("optionr")

path <- file.path(tempdir(), "test")
create(path, description = getOption("devtools.desc"), check = FALSE,
  rstudio = TRUE)
setwd(path)

container <- initializeOptionContainer(overwrite = TRUE)
setAnywhereOption(id = "x_1", value = TRUE, reactive = TRUE)
getAnywhereOption(id = "x_1")
setAnywhereOption(id = "x_2",
  value = reactr::reactiveExpression(
    !getAnywhereOption(id = "x_1")
  ),
  reactive = TRUE)

getAnywhereOption(id = "x_1")
getAnywhereOption(id = "x_2")

Thanks a lot should you take the time to look into this,
Janko

On Sat, Nov 15, 2014 at 1:13 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 14/11/2014, 6:51 PM, Janko Thyson wrote:
> > Dear list,
> >
> > I just encountered a behavior that I've never seen before:
> >
> > Is it possible, that certain argument names (lazy in my case) are
> > special/reserved and thus would lead to unexpected behavior when a
> calling
> > stack is involved that spreads across functions of three different
> > packages: optionr::setAnywhereOptions() calls nestr::setNested() calls
> > reactr::setShinyReactive()?
>
> No.
>
> >
> > Or is there something I'm generally missing with respect the combination
> of
> > lexical scoping/the frame stack, S4 and default values of function
> > arguments.
> >
> > Running the following code leads to a situation where the default value
> of
> > `lazy` in `reactr::setShinyReactive()` is not properly recognized while
> > others (e.g. `push`) are recognized just fine:
> >
> > require("devtools")
> > devtools::install_github("Rappster/conditionr")
> > devtools::install_github("Rappster/nestr")
> > devtools::install_github("Rappster/optionr")
> > require("optionr")
> >
> > container <- initializeOptionContainer(overwrite = TRUE)
> > expect_true(setAnywhereOption(id = "x_1", value = TRUE, reactive = TRUE))
> > expect_equal(getAnywhereOption(id = "x_1"), TRUE)
> > expect_true(res <- setAnywhereOption(id = "x_2",
> >   value = reactr::reactiveExpression(
> >     !getAnywhereOption(id = "x_1")
> >   ),
> >   reactive = TRUE))
> >
> > The current version of `setShinyReactive()` contains a debugging section
> > that prints these status messages (the actual code:
> > https://github.com/Rappster/reactr/blob/bug-28/R/setShinyReactive.r#L196
> )
> >
> > DEBUG/push/before[1] FALSE
> > DEBUG/lazy/before
> > Error in print(lazy) : argument is missing, with no default
> > DEBUG/is_lazy/before[1] FALSE
> > DEBUG/lazy/after[1] FALSE
> >
> > It also contains my current workaround: also include an argument with
> > name `is_lazy` (whose default)
> > value is recognized again) and then run `lazy <- is_lazy`.
> >
> > You can also find this information in this Stackoverflow post:
> >
> http://stackoverflow.com/questions/26940474/lexical-scoping-issue-r-fails-to-recognize-an-arguments-default-value
> >
> > Thanks a lot for everyone that can shed some light on this!
>
> Sorry, I don't use Stackoverflow.  If you don't get a more useful answer
> from someone else, please simplify the question and post a
> self-contained version to R-help.
>
> Duncan Murdoch
>
> >
> >
> > Best regards,
> > Janko
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Nov 15 02:01:09 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 14 Nov 2014 17:01:09 -0800
Subject: [R] Lexical scoping/calling stack issue: R fails to recognize
	an argument's default value
In-Reply-To: <CAGmpueggerHVJd0fOdWuw7xPM33pYrPgHjB7XDMhA0j3+JdBPQ@mail.gmail.com>
References: <CAGmpueggerHVJd0fOdWuw7xPM33pYrPgHjB7XDMhA0j3+JdBPQ@mail.gmail.com>
Message-ID: <348D4843-C34F-41C4-8592-F51142195580@dcn.davis.CA.us>

While you appear to have been thorough in providing access to your code, I don't think I will install a bunch of your dev code to debug it for you. The Posting Guide does say your example should be minimal, and IMO this doesn't fit that description. You should extract enough generic functions to replicate the structure of the call tree in a single short example.

I suppose there could be a bug in the parameter handling, but are you sure every calling point is including the "..." argument that should be?

My second blind point is that visibility of package variables does follow a complicated path, but there are good descriptions available, such as [1] or [2].

If you do think you have found a bug, the R Core team will want a minimal reproducible example, and you should read the Posting Guide on bug reporting to make sure your issue gets addressed.

[1] http://obeautifulcode.com/R/How-R-Searches-And-Finds-Stuff/
[2] http://adv-r.had.co.nz/Environments.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 14, 2014 3:51:16 PM PST, Janko Thyson <janko.thyson at gmail.com> wrote:
>Dear list,
>
>I just encountered a behavior that I've never seen before:
>
>Is it possible, that certain argument names (lazy in my case) are
>special/reserved and thus would lead to unexpected behavior when a
>calling
>stack is involved that spreads across functions of three different
>packages: optionr::setAnywhereOptions() calls nestr::setNested() calls
>reactr::setShinyReactive()?
>
>Or is there something I'm generally missing with respect the
>combination of
>lexical scoping/the frame stack, S4 and default values of function
>arguments.
>
>Running the following code leads to a situation where the default value
>of
>`lazy` in `reactr::setShinyReactive()` is not properly recognized while
>others (e.g. `push`) are recognized just fine:
>
>require("devtools")
>devtools::install_github("Rappster/conditionr")
>devtools::install_github("Rappster/nestr")
>devtools::install_github("Rappster/optionr")
>require("optionr")
>
>container <- initializeOptionContainer(overwrite = TRUE)
>expect_true(setAnywhereOption(id = "x_1", value = TRUE, reactive =
>TRUE))
>expect_equal(getAnywhereOption(id = "x_1"), TRUE)
>expect_true(res <- setAnywhereOption(id = "x_2",
>  value = reactr::reactiveExpression(
>    !getAnywhereOption(id = "x_1")
>  ),
>  reactive = TRUE))
>
>The current version of `setShinyReactive()` contains a debugging
>section
>that prints these status messages (the actual code:
>https://github.com/Rappster/reactr/blob/bug-28/R/setShinyReactive.r#L196)
>
>DEBUG/push/before[1] FALSE
>DEBUG/lazy/before
>Error in print(lazy) : argument is missing, with no default
>DEBUG/is_lazy/before[1] FALSE
>DEBUG/lazy/after[1] FALSE
>
>It also contains my current workaround: also include an argument with
>name `is_lazy` (whose default)
>value is recognized again) and then run `lazy <- is_lazy`.
>
>You can also find this information in this Stackoverflow post:
>http://stackoverflow.com/questions/26940474/lexical-scoping-issue-r-fails-to-recognize-an-arguments-default-value
>
>Thanks a lot for everyone that can shed some light on this!
>
>
>Best regards,
>Janko
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From janko.thyson at gmail.com  Sat Nov 15 02:06:19 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Sat, 15 Nov 2014 02:06:19 +0100
Subject: [R] Lexical scoping/calling stack issue: R fails to recognize
 an argument's default value
In-Reply-To: <348D4843-C34F-41C4-8592-F51142195580@dcn.davis.CA.us>
References: <CAGmpueggerHVJd0fOdWuw7xPM33pYrPgHjB7XDMhA0j3+JdBPQ@mail.gmail.com>
	<348D4843-C34F-41C4-8592-F51142195580@dcn.davis.CA.us>
Message-ID: <CAGmpuegRmu2xDJg5OLrXhiK1Br7KUS+iP1Z9cEdoF8pcMZnMgA@mail.gmail.com>

Thanks. I will try to further simplify the example.

On Sat, Nov 15, 2014 at 2:01 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> While you appear to have been thorough in providing access to your code, I
> don't think I will install a bunch of your dev code to debug it for you.
> The Posting Guide does say your example should be minimal, and IMO this
> doesn't fit that description. You should extract enough generic functions
> to replicate the structure of the call tree in a single short example.
>
> I suppose there could be a bug in the parameter handling, but are you sure
> every calling point is including the "..." argument that should be?
>
> My second blind point is that visibility of package variables does follow
> a complicated path, but there are good descriptions available, such as [1]
> or [2].
>
> If you do think you have found a bug, the R Core team will want a minimal
> reproducible example, and you should read the Posting Guide on bug
> reporting to make sure your issue gets addressed.
>
> [1] http://obeautifulcode.com/R/How-R-Searches-And-Finds-Stuff/
> [2] http://adv-r.had.co.nz/Environments.html
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 14, 2014 3:51:16 PM PST, Janko Thyson <janko.thyson at gmail.com>
> wrote:
> >Dear list,
> >
> >I just encountered a behavior that I've never seen before:
> >
> >Is it possible, that certain argument names (lazy in my case) are
> >special/reserved and thus would lead to unexpected behavior when a
> >calling
> >stack is involved that spreads across functions of three different
> >packages: optionr::setAnywhereOptions() calls nestr::setNested() calls
> >reactr::setShinyReactive()?
> >
> >Or is there something I'm generally missing with respect the
> >combination of
> >lexical scoping/the frame stack, S4 and default values of function
> >arguments.
> >
> >Running the following code leads to a situation where the default value
> >of
> >`lazy` in `reactr::setShinyReactive()` is not properly recognized while
> >others (e.g. `push`) are recognized just fine:
> >
> >require("devtools")
> >devtools::install_github("Rappster/conditionr")
> >devtools::install_github("Rappster/nestr")
> >devtools::install_github("Rappster/optionr")
> >require("optionr")
> >
> >container <- initializeOptionContainer(overwrite = TRUE)
> >expect_true(setAnywhereOption(id = "x_1", value = TRUE, reactive =
> >TRUE))
> >expect_equal(getAnywhereOption(id = "x_1"), TRUE)
> >expect_true(res <- setAnywhereOption(id = "x_2",
> >  value = reactr::reactiveExpression(
> >    !getAnywhereOption(id = "x_1")
> >  ),
> >  reactive = TRUE))
> >
> >The current version of `setShinyReactive()` contains a debugging
> >section
> >that prints these status messages (the actual code:
> >https://github.com/Rappster/reactr/blob/bug-28/R/setShinyReactive.r#L196)
> >
> >DEBUG/push/before[1] FALSE
> >DEBUG/lazy/before
> >Error in print(lazy) : argument is missing, with no default
> >DEBUG/is_lazy/before[1] FALSE
> >DEBUG/lazy/after[1] FALSE
> >
> >It also contains my current workaround: also include an argument with
> >name `is_lazy` (whose default)
> >value is recognized again) and then run `lazy <- is_lazy`.
> >
> >You can also find this information in this Stackoverflow post:
> >
> http://stackoverflow.com/questions/26940474/lexical-scoping-issue-r-fails-to-recognize-an-arguments-default-value
> >
> >Thanks a lot for everyone that can shed some light on this!
> >
> >
> >Best regards,
> >Janko
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Nov 15 03:03:36 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 14 Nov 2014 18:03:36 -0800
Subject: [R] Data Import to R
In-Reply-To: <D08B92C2.112485%macqueen1@llnl.gov>
References: <CAKo12DaYFaQ+OVs9_swhuAPLKqPBPETCwwDi-A0Cp4F25Y7a9A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEE82D@SRVEXCHMBX.precheza.cz>
	<D08B92C2.112485%macqueen1@llnl.gov>
Message-ID: <558DA631-E363-45D2-8C21-ED533A43A9A0@dcn.davis.CA.us>

If your data uses a special marker such as "--" or "n/a" to indicate not available then once you have identified those markers (using any method, though Don's procedure below is what I use) then you can specify them with the na.strings parameter to read.csv. (See the help for read.table for many other parameters you can also give to read.csv.) Once those special values are specified, then you should get numeric columns just fine.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 14, 2014 11:11:20 AM PST, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>Petr is almost certainly correct. A further suggestion:
>
>Continue to import using stringsAsFactors = FALSE
>
>On one of the columns that should be numeric, use as.numeric(), find
>the
>NA's in the result of that, and then look at those rows of the data.
>There
>will be something there that is non-numeric. By any chance, does your
>data
>use a comma instead of a decimal point (see the "dec" argument to
>read.table)?


From k-aravindhan1 at ti.com  Sat Nov 15 02:48:55 2014
From: k-aravindhan1 at ti.com (Aravindhan, K)
Date: Sat, 15 Nov 2014 01:48:55 +0000
Subject: [R] how to compure R-squared in glm
Message-ID: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E8745057BD@DBDE04.ent.ti.com>

Team,
Can some one help me in computing the R-squared value in glm.

Thanks
Aravindhan

	[[alternative HTML version deleted]]


From k-aravindhan1 at ti.com  Sat Nov 15 03:28:42 2014
From: k-aravindhan1 at ti.com (Aravindhan, K)
Date: Sat, 15 Nov 2014 02:28:42 +0000
Subject: [R] boot strapping poisson getting warnings and negative values
In-Reply-To: <1407507124.21368.YahooMailBasic@web190104.mail.sg3.yahoo.com>
References: <1407507124.21368.YahooMailBasic@web190104.mail.sg3.yahoo.com>
Message-ID: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E874509959@DBDE04.ent.ti.com>

Team,
Has anyone looked at this question from me ?  it will help me immensely if someone can provide an answer to this.

Thanks
Aravindhan

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of K Aravindhan
Sent: Friday, August 08, 2014 7:42 PM
To: r-help at r-project.org
Subject: [R] boot strapping poisson getting warnings and negative values

Dear Team,
I am getting this error while running the boot-strapping functions. 

==================================================
mod.db.hub<-glm(TOTAL~1+IPD,family="poisson",data=db)
fit<-fitted(mod.db.hub)
e<-residuals(mod.db.hub)
X<-model.matrix(mod.db.hub)
boot.huber.fixed<-function(data,indices,maxit=20) { Y<-fit+e[indices]
mod<-glm(Y~X-1,family="poisson",maxit=maxit)
coefficients(mod)
}
library(boot)
db.fix.boot<-boot(db,boot.huber.fixed,2000,maxit=20)
db.fix.boot
boot.ci(db.fix.boot,index=1,type=c("bca","perc","poisson"))
boot.ci(db.fix.boot,index=2,type=c("bca","perc","poisson"))
==================================================

Error in eval(expr, envir, enclos) : 
negative values not allowed for the 'Poisson' family In addition: Warning messages:
1: In dpois(y, mu, log = TRUE) : non-integer x = 25.006412
2: In dpois(y, mu, log = TRUE) : non-integer x = 26.969411
3: In dpois(y, mu, log = TRUE) : non-integer x = 66.352323
4: In dpois(y, mu, log = TRUE) : non-integer x = 61.083519
5: In dpois(y, mu, log = TRUE) : non-integer x = 20.596770
6: In dpois(y, mu, log = TRUE) : non-integer x = 43.428258
7: In dpois(y, mu, log = TRUE) : non-integer x = 1108.263554
8: In dpois(y, mu, log = TRUE) : non-integer x = 61.937982
9: In dpois(y, mu, log = TRUE) : non-integer x = 419.991213
10: In dpois(y, mu, log = TRUE) : non-integer x = 47.369133

Can you explain to me how to get rid of these ?

Thanks
Aravindhan

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Nov 15 08:44:24 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Nov 2014 23:44:24 -0800
Subject: [R] boot strapping poisson getting warnings and negative values
In-Reply-To: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E874509959@DBDE04.ent.ti.com>
References: <1407507124.21368.YahooMailBasic@web190104.mail.sg3.yahoo.com>
	<EF1CB4B85C8C3D41B75FB3A4E4EEA4E874509959@DBDE04.ent.ti.com>
Message-ID: <8AD0D6D1-AFBA-4D03-A607-1F397232DCA3@comcast.net>


> On Nov 14, 2014, at 6:28 PM, Aravindhan, K <k-aravindhan1 at ti.com> wrote:
> 
> Team,
> Has anyone looked at this question from me ?  it will help me immensely if someone can provide an answer to this.
> 
> Thanks
> Aravindhan
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of K Aravindhan
> Sent: Friday, August 08, 2014 7:42 PM
> To: r-help at r-project.org
> Subject: [R] boot strapping poisson getting warnings and negative values
> 
> Dear Team,
> I am getting this error while running the boot-strapping functions. 
> 
> ==================================================
> mod.db.hub<-glm(TOTAL~1+IPD,family="poisson",data=db)
> fit<-fitted(mod.db.hub)
> e<-residuals(mod.db.hub)
> X<-model.matrix(mod.db.hub)
> boot.huber.fixed<-function(data,indices,maxit=20) { Y<-fit+e[indices]

I would imagine that the length of fit and of e[indices] would be different. Won?t generate an error that stops execute, but may create an error in evaluation.

> mod<-glm(Y~X-1,family="poisson",maxit=maxit)

And if you are pulling X from ?outside? the bootstrapped function (and not adjusting it to reflect the indices), I cannot imagine good things should be expected.

> coefficients(mod)
> }
> library(boot)
> db.fix.boot<-boot(db,boot.huber.fixed,2000,maxit=20)

And then there is the question of what ?db? really is. Furthermore, it doesn't seem that you are using any of that data-object in your bootstrapped function.

> db.fix.boot
> boot.ci(db.fix.boot,index=1,type=c("bca","perc","poisson"))
> boot.ci(db.fix.boot,index=2,type=c("bca","perc","poisson"))
> ==================================================
> 
> Error in eval(expr, envir, enclos) : 
> negative values not allowed for the 'Poisson' family In addition: Warning messages:

If you wnat to construct a Y variable that is not integer then you need to use quasipoisson.


> 1: In dpois(y, mu, log = TRUE) : non-integer x = 25.006412
> 2: In dpois(y, mu, log = TRUE) : non-integer x = 26.969411
> 3: In dpois(y, mu, log = TRUE) : non-integer x = 66.352323
> 4: In dpois(y, mu, log = TRUE) : non-integer x = 61.083519
> 5: In dpois(y, mu, log = TRUE) : non-integer x = 20.596770
> 6: In dpois(y, mu, log = TRUE) : non-integer x = 43.428258
> 7: In dpois(y, mu, log = TRUE) : non-integer x = 1108.263554
> 8: In dpois(y, mu, log = TRUE) : non-integer x = 61.937982
> 9: In dpois(y, mu, log = TRUE) : non-integer x = 419.991213
> 10: In dpois(y, mu, log = TRUE) : non-integer x = 47.369133
> 
> Can you explain to me how to get rid of these ?
> 
> Thanks
> Aravindhan
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Nov 15 08:46:20 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Nov 2014 23:46:20 -0800
Subject: [R] how to compure R-squared in glm
In-Reply-To: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E8745057BD@DBDE04.ent.ti.com>
References: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E8745057BD@DBDE04.ent.ti.com>
Message-ID: <886C65F9-5246-4E7D-87CC-D73FDD9262AC@comcast.net>


> On Nov 14, 2014, at 5:48 PM, Aravindhan, K <k-aravindhan1 at ti.com> wrote:
> 
> Team,
> Can some one help me in computing the R-squared value in glm.
> 

Which version of a pseudo-R^2? What?s the model?


> Thanks
> Aravindhan
> 
> 	[[alternative HTML version deleted]]

This is a plain text mailing list

> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help

Please: 

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From lordpreetam at gmail.com  Sat Nov 15 11:23:22 2014
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sat, 15 Nov 2014 15:53:22 +0530
Subject: [R] Prediction using ARCH
Message-ID: <CAHVFrXEpJGTC-nqbeXj3nuUZ3cWk3M2-OJ_L29oUFsOrWqF_gA@mail.gmail.com>

Hi,

I have two variables, FTSE100 and CPI . Call them Y and X respectively.
I want to fit an ARCH(1) to model Y on X. I also intend to predict the
values of Y for future (given) values of X. How can I use R for such
prediction?

Another question is: is there a way I can call an R function which would
return me the optimal p for the ARCH(p)  model?

I have attached the Excel data in case it is required.

Thanks,
Preetam

From pburns at pburns.seanet.com  Sat Nov 15 12:41:49 2014
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 15 Nov 2014 11:41:49 +0000
Subject: [R] Prediction using ARCH
In-Reply-To: <CAHVFrXEpJGTC-nqbeXj3nuUZ3cWk3M2-OJ_L29oUFsOrWqF_gA@mail.gmail.com>
References: <CAHVFrXEpJGTC-nqbeXj3nuUZ3cWk3M2-OJ_L29oUFsOrWqF_gA@mail.gmail.com>
Message-ID: <54673BFD.6060701@pburns.seanet.com>

Preetam,

You are more likely to want garch than
arch.

These models are data-hungry, so I'm
sceptical that a model with CPI is going
to be very good.  See for instance:

www.portfolioprobe.com/2012/09/20/garch-estimation-on-impossibly-long-series/

This question is really more appropriate
for r-sig-finance (you need to subscribe
before you can post).

Pat

On 15/11/2014 10:23, Preetam Pal wrote:
> Hi,
>
> I have two variables, FTSE100 and CPI . Call them Y and X respectively.
> I want to fit an ARCH(1) to model Y on X. I also intend to predict the
> values of Y for future (given) values of X. How can I use R for such
> prediction?
>
> Another question is: is there a way I can call an R function which would
> return me the optimal p for the ARCH(p)  model?
>
> I have attached the Excel data in case it is required.
>
> Thanks,
> Preetam
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From janko.thyson at gmail.com  Sat Nov 15 14:37:03 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Sat, 15 Nov 2014 14:37:03 +0100
Subject: [R] Lexical scoping/calling stack issue: R fails to recognize
 an argument's default value
In-Reply-To: <CAGmpuegRmu2xDJg5OLrXhiK1Br7KUS+iP1Z9cEdoF8pcMZnMgA@mail.gmail.com>
References: <CAGmpueggerHVJd0fOdWuw7xPM33pYrPgHjB7XDMhA0j3+JdBPQ@mail.gmail.com>
	<348D4843-C34F-41C4-8592-F51142195580@dcn.davis.CA.us>
	<CAGmpuegRmu2xDJg5OLrXhiK1Br7KUS+iP1Z9cEdoF8pcMZnMgA@mail.gmail.com>
Message-ID: <CAGmpuej4xMJHpK2weG-WV+3GN00jdK9zFOmAZ_rb19Sh=P9F8A@mail.gmail.com>

Ok, I have to admit: that was a really stupid mistake :-/

I unintentionally had a trailing `,` in the call to `nestr::setNested()`
inside `optionr::setAnywhereOption()`

Here's a much simpler illustration:

*Definitions* //

    setGeneric(
      name = "setAnywhereOption",
      signature = "id",
      def = function(id, ...) standardGeneric("setAnywhereOption")
    )
    setMethod(
      f = "setAnywhereOption",
      signature = signature(id = "character"),
    #  definition = function(id, ...) setNested(id = id)
      ## --> works
    #  definition = function(id, ...) setNested(id = id, ...)
      ## --> works
      definition = function(id, ...) setNested(id = id,)
      ## --> this leads to things get messed up with argument's default
values
      ## --> so the trailing `,` was causing the problem!
    )
    setGeneric(
      name = "setNested",
      signature = "id",
      def = function(id, ...) standardGeneric("setNested")
    )
    setMethod(
      f = "setNested",
      signature = signature(id = "character"),
      definition = function(id, ...) {

      if (FALSE) {
        ## Omitted
      } else {
        setShinyReactive(id = basename(id), ...)
      }

    })
    setShinyReactive <- function(
      id,
      lazy = FALSE,
      is_lazy = FALSE,
      push = FALSE,
      typed = FALSE,
      strict_set = c(0, 1, 2),
      ...
      ) {

      ###########
      ## DEBUG ##
      ###########
      message("DEBUG/setShinyReactive/threedots")
      print(list(...))
      message("DEBUG/setShinyReactive/push")
      print(push)
      message("DEBUG/setShinyReactive/lazy")
      try(print(lazy))
      ## --> strangely, R does not seem to like the name `lazy`
      message("DEBUG/setShinyReactive/is_lazy")
      print(is_lazy)
      ## --> this works
      lazy <- is_lazy
      message("DEBUG/setShinyReactive/lazy")
      print(lazy)

      TRUE

    }

*Apply //*

    setAnywhereOption(id = "test")
    # DEBUG/setShinyReactive/threedots
    # list()
    # DEBUG/setShinyReactive/push
    # [1] FALSE
    # DEBUG/setShinyReactive/lazy
    # Error in print(lazy) : argument is missing, with no default
    # DEBUG/setShinyReactive/is_lazy
    # [1] FALSE
    # DEBUG/setShinyReactive/lazy
    # [1] FALSE
    # [1] TRUE
    setAnywhereOption(id = "test", push = TRUE)
    setAnywhereOption(id = "test", lazy = TRUE)

*Actual cause / solution //*

Removing the trailing `,` in the method definition of `setAnywhereOption()`:

    setMethod(
      f = "setAnywhereOption",
      signature = signature(id = "character"),
      definition = function(id, ...) setNested(id = id)
      ## --> works
    #  definition = function(id, ...) setNested(id = id,)
      ## --> this leads to things get messed up with argument's default
values
      ## --> so the trailing `,` was causing the problem!
    )

    setAnywhereOption(id = "test")
    # DEBUG/setShinyReactive/threedots
    # list()
    # DEBUG/setShinyReactive/push
    # [1] FALSE
    # DEBUG/setShinyReactive/lazy
    # [1] FALSE
    # DEBUG/setShinyReactive/is_lazy
    # [1] FALSE
    # DEBUG/setShinyReactive/lazy
    # [1] FALSE
    # [1] TRUE

Now it works just fine. Also stated this as an answer as potential
reference for others that might run into similar problems:
http://stackoverflow.com/questions/26940474/lexical-scoping-calling-stack-issue-r-fails-to-recognize-an-arguments-defaul

Thanks for everyone that answered/took the time to have a look at the code
- and sorry for having thrown a complicated example at you!
It was just that at first I didn't see the wood for the trees and I thought
that the problem was caused by this very calling stack structure (spread
across three different packages).

Best regards and happy coding,
Janko

On Sat, Nov 15, 2014 at 2:06 AM, Janko Thyson <janko.thyson at gmail.com>
wrote:

> Thanks. I will try to further simplify the example.
>
> On Sat, Nov 15, 2014 at 2:01 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> While you appear to have been thorough in providing access to your code,
>> I don't think I will install a bunch of your dev code to debug it for you.
>> The Posting Guide does say your example should be minimal, and IMO this
>> doesn't fit that description. You should extract enough generic functions
>> to replicate the structure of the call tree in a single short example.
>>
>> I suppose there could be a bug in the parameter handling, but are you
>> sure every calling point is including the "..." argument that should be?
>>
>> My second blind point is that visibility of package variables does follow
>> a complicated path, but there are good descriptions available, such as [1]
>> or [2].
>>
>> If you do think you have found a bug, the R Core team will want a minimal
>> reproducible example, and you should read the Posting Guide on bug
>> reporting to make sure your issue gets addressed.
>>
>> [1] http://obeautifulcode.com/R/How-R-Searches-And-Finds-Stuff/
>> [2] http://adv-r.had.co.nz/Environments.html
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 14, 2014 3:51:16 PM PST, Janko Thyson <janko.thyson at gmail.com>
>> wrote:
>> >Dear list,
>> >
>> >I just encountered a behavior that I've never seen before:
>> >
>> >Is it possible, that certain argument names (lazy in my case) are
>> >special/reserved and thus would lead to unexpected behavior when a
>> >calling
>> >stack is involved that spreads across functions of three different
>> >packages: optionr::setAnywhereOptions() calls nestr::setNested() calls
>> >reactr::setShinyReactive()?
>> >
>> >Or is there something I'm generally missing with respect the
>> >combination of
>> >lexical scoping/the frame stack, S4 and default values of function
>> >arguments.
>> >
>> >Running the following code leads to a situation where the default value
>> >of
>> >`lazy` in `reactr::setShinyReactive()` is not properly recognized while
>> >others (e.g. `push`) are recognized just fine:
>> >
>> >require("devtools")
>> >devtools::install_github("Rappster/conditionr")
>> >devtools::install_github("Rappster/nestr")
>> >devtools::install_github("Rappster/optionr")
>> >require("optionr")
>> >
>> >container <- initializeOptionContainer(overwrite = TRUE)
>> >expect_true(setAnywhereOption(id = "x_1", value = TRUE, reactive =
>> >TRUE))
>> >expect_equal(getAnywhereOption(id = "x_1"), TRUE)
>> >expect_true(res <- setAnywhereOption(id = "x_2",
>> >  value = reactr::reactiveExpression(
>> >    !getAnywhereOption(id = "x_1")
>> >  ),
>> >  reactive = TRUE))
>> >
>> >The current version of `setShinyReactive()` contains a debugging
>> >section
>> >that prints these status messages (the actual code:
>> >https://github.com/Rappster/reactr/blob/bug-28/R/setShinyReactive.r#L196
>> )
>> >
>> >DEBUG/push/before[1] FALSE
>> >DEBUG/lazy/before
>> >Error in print(lazy) : argument is missing, with no default
>> >DEBUG/is_lazy/before[1] FALSE
>> >DEBUG/lazy/after[1] FALSE
>> >
>> >It also contains my current workaround: also include an argument with
>> >name `is_lazy` (whose default)
>> >value is recognized again) and then run `lazy <- is_lazy`.
>> >
>> >You can also find this information in this Stackoverflow post:
>> >
>> http://stackoverflow.com/questions/26940474/lexical-scoping-issue-r-fails-to-recognize-an-arguments-default-value
>> >
>> >Thanks a lot for everyone that can shed some light on this!
>> >
>> >
>> >Best regards,
>> >Janko
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From janko.thyson at gmail.com  Sat Nov 15 15:49:41 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Sat, 15 Nov 2014 15:49:41 +0100
Subject: [R] Fine controlling "three dots" argument dispatch to functions
 with identical argument names
Message-ID: <CAGmpuegNtZFAqCUZbQKscwOhKu+RibtgCRmS--39M4G4+tzjog@mail.gmail.com>

Dear list,

I wonder if there's a clever way to fine control the exact way arguments
are dispatched via R's "three dots" argument ....

Consider the following use case:

   - you have a function foobar() that calls foo() which in turn calls bar()
   - *both* foo() and bar() have an argument that's called y, but they each
   have a *different meaning*
   - in the call to foobar(), you would like to say "here's the y for foo()
   and here's the y for bar()". *That's what I would like to accomplish*.

If you simply call foobar(x = "John Doe", y = "hello world"), y only get's
dispatched to foo() as in the call to bar() things would have to be
explicit in order to be dispatched (i.e. the call would have to be bar(x =
x, y = y) instead of bar(x = x, ...):

foo <- function(x, y = "some character", ...) {
  message("foo ----------")
  message("foo/threedots")
  try(print(list(...)))
  message("foo/y")
  try(print(y))
  bar(x = x, ...)}
bar <- function(x, y = TRUE, ...) {
  message("bar ----------")
  message("bar/threedots")
  try(print(list(...)))
  message("bar/y")
  try(print(y))
  return(paste0("hello: ", x))}
foobar <- function(x, ...) {
  message("foobar ----------")
  message("foobar/threedots")
  try(print(list(...)))
  foo(x = x, ...)}

foobar(x = "John Doe", y = "hi there")# foobar ----------#
foobar/threedots# $y# [1] "hi there"# # foo ----------# foo/threedots#
list()# foo/y# [1] "hi there"# bar ----------# bar/threedots# list()#
bar/y# [1] TRUE# [1] "hello: John Doe"

What I conceptionally would like to be able to do is something like this:

foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)

Here's an approach that works but that also feels very odd:

foo <- function(x, y = "some character", ...) {
  message("foo ----------")
  message("foo/threedots")
  try(print(list(...)))
  message("foo/y")
  arg <- paste0("y_", sys.call()[[1]])
  if (arg %in% names(list(...))) {
    y <- list(...)[[arg]]
  }
  try(print(y))
  bar(x = x, ...)}
bar <- function(x, y = TRUE, ...) {
  message("bar ----------")
  message("bar/threedots")
  try(print(list(...)))
  message("bar/y")
  arg <- paste0("y_", sys.call()[[1]])
  if (arg %in% names(list(...))) {
    y <- list(...)[[arg]]
  }
  try(print(y))
  return(paste0("hello: ", x))}

foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)# foobar
----------# foobar/threedots# $y_foo# [1] "hello world!"# # $y_bar#
[1] FALSE# # foo ----------# foo/threedots# $y_foo# [1] "hello
world!"# # $y_bar# [1] FALSE# # foo/y# [1] "hello world!"# bar
----------# bar/threedots# $y_foo# [1] "hello world!"# # $y_bar# [1]
FALSE# # bar/y# [1] FALSE# [1] "hello: John Doe"

How would you go about implementing something like this?

I also played around with S4 method dispatch to see if I could define
methods for a signature argument ..., but that didn't go too well (and it's
probably a very bad idea anyway):

setGeneric(
  name = "foo",
  signature = c("x", "..."),
  def = function(x, ...) standardGeneric("foo")      )
setMethod(
  f = "foo",
  signature = signature(x = "character", "..." = "MyThreeDotsForBar"),
 definition = function(x, ...) bar(x = x))## --> does not work

	[[alternative HTML version deleted]]


From alamdirvi10 at yahoo.com  Sat Nov 15 12:30:16 2014
From: alamdirvi10 at yahoo.com (Muhammad Alam)
Date: Sat, 15 Nov 2014 11:30:16 +0000 (UTC)
Subject: [R] request
Message-ID: <672087155.613660.1416051016141.JavaMail.yahoo@jws10095.mail.ne1.yahoo.com>

Respected sir i am a student of Mphil statistics from pakistan, please i have a great problem and i try my best but can not solve, ?sir the problem is that i want to estimate the parameters of ? LN3 ? for a set of data having name ?x ? ?by MLE method, in ?R, ?i also apply the VGAM ?package but can not solve because it give us the two parameters, please send me the command and package in detail, i will be always pray for you, i spend my one month but not solve it, please ?once again


	[[alternative HTML version deleted]]


From k-aravindhan1 at ti.com  Sat Nov 15 16:19:46 2014
From: k-aravindhan1 at ti.com (Aravindhan, K)
Date: Sat, 15 Nov 2014 15:19:46 +0000
Subject: [R] how to compure R-squared in glm
In-Reply-To: <886C65F9-5246-4E7D-87CC-D73FDD9262AC@comcast.net>
References: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E8745057BD@DBDE04.ent.ti.com>
	<886C65F9-5246-4E7D-87CC-D73FDD9262AC@comcast.net>
Message-ID: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E87450B7B2@DBDE04.ent.ti.com>

Hi David,
I am using generalized linear models (glm command with family="poisson"). 

Thanks
Aravindhan

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Saturday, November 15, 2014 1:16 PM
To: Aravindhan, K
Cc: R-help at r-project.org
Subject: Re: [R] how to compure R-squared in glm


> On Nov 14, 2014, at 5:48 PM, Aravindhan, K <k-aravindhan1 at ti.com> wrote:
> 
> Team,
> Can some one help me in computing the R-squared value in glm.
> 

Which version of a pseudo-R^2? What?s the model?


> Thanks
> Aravindhan
> 
> 	[[alternative HTML version deleted]]

This is a plain text mailing list

> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help

Please: 

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From chandratr at gmail.com  Sat Nov 15 17:14:17 2014
From: chandratr at gmail.com (Chandrasekhar Rudrappa)
Date: Sat, 15 Nov 2014 21:44:17 +0530
Subject: [R] Help in code for fitting a growth model
Message-ID: <CAMSabZQV3Njazq5oh9405-EoJjTvweBs+nRwgrcS398sC8BQqw@mail.gmail.com>

I have to fit a model to growth data of Hevea (rubber) trees. The details
are outlined in the attached docx file.  Kind help is solicited.
-- 
Dr. TR Chandrasekhar, M.Sc., M. Tech., Ph. D.,
Sr. Scientist
Rubber Research Institute of India
Hevea Breeding Sub Station
Kadaba - 574 221
DK Dt., Karnataka
Phone-Land: 08251-214336
Mobile: 9448780118

From jdnewmil at dcn.davis.CA.us  Sat Nov 15 17:26:29 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 15 Nov 2014 08:26:29 -0800
Subject: [R] Fine controlling "three dots" argument dispatch to
	functions with identical argument names
In-Reply-To: <CAGmpuegNtZFAqCUZbQKscwOhKu+RibtgCRmS--39M4G4+tzjog@mail.gmail.com>
References: <CAGmpuegNtZFAqCUZbQKscwOhKu+RibtgCRmS--39M4G4+tzjog@mail.gmail.com>
Message-ID: <335D892B-BDE7-4D1D-A77A-6796889201F6@dcn.davis.CA.us>

AFAIK You have to alter the name of at least one of the y arguments as used by foobar, and anyone calling foobar has to read about that in the help file. That is only one y can be in "...". e.g.

foobar <- function( x, y_foo, ... ) {
  foo( x, y=y_foo, ... )
  bar( x, ... )
}


---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 15, 2014 6:49:41 AM PST, Janko Thyson <janko.thyson at gmail.com> wrote:
>Dear list,
>
>I wonder if there's a clever way to fine control the exact way
>arguments
>are dispatched via R's "three dots" argument ....
>
>Consider the following use case:
>
>- you have a function foobar() that calls foo() which in turn calls
>bar()
>- *both* foo() and bar() have an argument that's called y, but they
>each
>   have a *different meaning*
>- in the call to foobar(), you would like to say "here's the y for
>foo()
> and here's the y for bar()". *That's what I would like to accomplish*.
>
>If you simply call foobar(x = "John Doe", y = "hello world"), y only
>get's
>dispatched to foo() as in the call to bar() things would have to be
>explicit in order to be dispatched (i.e. the call would have to be
>bar(x =
>x, y = y) instead of bar(x = x, ...):
>
>foo <- function(x, y = "some character", ...) {
>  message("foo ----------")
>  message("foo/threedots")
>  try(print(list(...)))
>  message("foo/y")
>  try(print(y))
>  bar(x = x, ...)}
>bar <- function(x, y = TRUE, ...) {
>  message("bar ----------")
>  message("bar/threedots")
>  try(print(list(...)))
>  message("bar/y")
>  try(print(y))
>  return(paste0("hello: ", x))}
>foobar <- function(x, ...) {
>  message("foobar ----------")
>  message("foobar/threedots")
>  try(print(list(...)))
>  foo(x = x, ...)}
>
>foobar(x = "John Doe", y = "hi there")# foobar ----------#
>foobar/threedots# $y# [1] "hi there"# # foo ----------# foo/threedots#
>list()# foo/y# [1] "hi there"# bar ----------# bar/threedots# list()#
>bar/y# [1] TRUE# [1] "hello: John Doe"
>
>What I conceptionally would like to be able to do is something like
>this:
>
>foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)
>
>Here's an approach that works but that also feels very odd:
>
>foo <- function(x, y = "some character", ...) {
>  message("foo ----------")
>  message("foo/threedots")
>  try(print(list(...)))
>  message("foo/y")
>  arg <- paste0("y_", sys.call()[[1]])
>  if (arg %in% names(list(...))) {
>    y <- list(...)[[arg]]
>  }
>  try(print(y))
>  bar(x = x, ...)}
>bar <- function(x, y = TRUE, ...) {
>  message("bar ----------")
>  message("bar/threedots")
>  try(print(list(...)))
>  message("bar/y")
>  arg <- paste0("y_", sys.call()[[1]])
>  if (arg %in% names(list(...))) {
>    y <- list(...)[[arg]]
>  }
>  try(print(y))
>  return(paste0("hello: ", x))}
>
>foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)# foobar
>----------# foobar/threedots# $y_foo# [1] "hello world!"# # $y_bar#
>[1] FALSE# # foo ----------# foo/threedots# $y_foo# [1] "hello
>world!"# # $y_bar# [1] FALSE# # foo/y# [1] "hello world!"# bar
>----------# bar/threedots# $y_foo# [1] "hello world!"# # $y_bar# [1]
>FALSE# # bar/y# [1] FALSE# [1] "hello: John Doe"
>
>How would you go about implementing something like this?
>
>I also played around with S4 method dispatch to see if I could define
>methods for a signature argument ..., but that didn't go too well (and
>it's
>probably a very bad idea anyway):
>
>setGeneric(
>  name = "foo",
>  signature = c("x", "..."),
>  def = function(x, ...) standardGeneric("foo")      )
>setMethod(
>  f = "foo",
>  signature = signature(x = "character", "..." = "MyThreeDotsForBar"),
> definition = function(x, ...) bar(x = x))## --> does not work
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Nov 15 17:27:04 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Nov 2014 08:27:04 -0800
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
Message-ID: <B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>


On Nov 14, 2014, at 3:18 PM, David Winsemius wrote:

> 
> On Nov 14, 2014, at 12:15 PM, ivan wrote:
> 
>> Hi,
>> 
>> I am trying to compute bootstrap confidence intervals for weighted means of
>> paired differences with the boot package. Unfortunately, the weighted mean
>> estimate lies out of the confidence bounds and hence I am obviously doing
>> something wrong.
>> 
>> Appreciate any help. Thanks. Here is a reproducible example:
>> 
>> 
>> library(boot)
>> set.seed(1111)
>> x <- rnorm(50)
>> y <- rnorm(50)
>> weights <- runif(50)
>> weights <- weights / sum(weights)
>> dataset <- cbind(x,y,weights)
>> vw_m_diff <- function(dataset,w, d) {
> 
> My understanding of the principle underlying the design of the bootstrapped function was that the data was the first argument and the index vector was the second. (I admit to not knowing what it would do with a third argument. So I would have guessed that you wanted:
> 
> vw_m_diff <- function(dataset,w) {
>     differences <- dataset[d,1]-dataset[d,2]
>    weights <- dataset[w, "weights"]
>    return(weighted.mean(x=differences, w=weights))
>  } 

I'm sorry. That was the code I first editted. This is the code that produced that output:

 vw_m_diff <- function(dataset,w) {
      differences <- dataset[w,1]-dataset[w,2]
     weights <- dataset[w, "weights"]
     return(weighted.mean(x=differences, w=weights))
   }

> 
> I get what appears to me as a sensible set of estimates (since they seem centered on zero) although I further admit I do not know what the theoretic CI _should_ be for this problem:
> 
>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
>> boot.ci(res_boot)
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 1000 bootstrap replicates
> 
> CALL : 
> boot.ci(boot.out = res_boot)
> 
> Intervals : 
> Level      Normal              Basic         
> 95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )  
> 
> Level     Percentile            BCa          
> 95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )  
> Calculations and Intervals on Original Scale
> 
> 
>>   differences <- dataset[d,1]-dataset[d,2]
>>   weights <- w[d]
>>   return(weighted.mean(x=differences, w=weights))
>> }
>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
>> boot.ci(res_boot)
>> 
>> *BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS*
>> *Based on 1000 bootstrap replicates*
>> 
>> *CALL : *
>> *boot.ci <http://boot.ci>(boot.out = res_boot)*
>> 
>> *Intervals : *
>> *Level      Normal              Basic         *
>> *95%   (-0.8365, -0.3463 )   (-0.8311, -0.3441 )  *
>> 
>> *Level     Percentile            BCa          *
>> *95%   (-0.3276,  0.1594 )   (-0.4781, -0.3477 )  *
>> 
>> weighted.mean(x=dataset[,1]-dataset[,2], w=dataset[,3])
>> 
>> *[1] -0.07321734*
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Sat Nov 15 18:10:10 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 15 Nov 2014 12:10:10 -0500
Subject: [R] Fine controlling "three dots" argument dispatch to
 functions with identical argument names
In-Reply-To: <335D892B-BDE7-4D1D-A77A-6796889201F6@dcn.davis.CA.us>
References: <CAGmpuegNtZFAqCUZbQKscwOhKu+RibtgCRmS--39M4G4+tzjog@mail.gmail.com>
	<335D892B-BDE7-4D1D-A77A-6796889201F6@dcn.davis.CA.us>
Message-ID: <546788F2.4040802@gmail.com>

On 15/11/2014, 11:26 AM, Jeff Newmiller wrote:
> AFAIK You have to alter the name of at least one of the y arguments as used by foobar, and anyone calling foobar has to read about that in the help file. That is only one y can be in "...". e.g.
> 
> foobar <- function( x, y_foo, ... ) {
>   foo( x, y=y_foo, ... )
>   bar( x, ... )
> }
> 

That's the best solution.  There is another one:  you can put

args <- list(...)

into foobar(), and then do whatever you like to the args vector, and put
together calls to foo() and bar() using do.call().  But this is hard to
read and easy to get wrong, so I recommend Jeff's simple solution.

Duncan Murdoch

> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On November 15, 2014 6:49:41 AM PST, Janko Thyson <janko.thyson at gmail.com> wrote:
>> Dear list,
>>
>> I wonder if there's a clever way to fine control the exact way
>> arguments
>> are dispatched via R's "three dots" argument ....
>>
>> Consider the following use case:
>>
>> - you have a function foobar() that calls foo() which in turn calls
>> bar()
>> - *both* foo() and bar() have an argument that's called y, but they
>> each
>>   have a *different meaning*
>> - in the call to foobar(), you would like to say "here's the y for
>> foo()
>> and here's the y for bar()". *That's what I would like to accomplish*.
>>
>> If you simply call foobar(x = "John Doe", y = "hello world"), y only
>> get's
>> dispatched to foo() as in the call to bar() things would have to be
>> explicit in order to be dispatched (i.e. the call would have to be
>> bar(x =
>> x, y = y) instead of bar(x = x, ...):
>>
>> foo <- function(x, y = "some character", ...) {
>>  message("foo ----------")
>>  message("foo/threedots")
>>  try(print(list(...)))
>>  message("foo/y")
>>  try(print(y))
>>  bar(x = x, ...)}
>> bar <- function(x, y = TRUE, ...) {
>>  message("bar ----------")
>>  message("bar/threedots")
>>  try(print(list(...)))
>>  message("bar/y")
>>  try(print(y))
>>  return(paste0("hello: ", x))}
>> foobar <- function(x, ...) {
>>  message("foobar ----------")
>>  message("foobar/threedots")
>>  try(print(list(...)))
>>  foo(x = x, ...)}
>>
>> foobar(x = "John Doe", y = "hi there")# foobar ----------#
>> foobar/threedots# $y# [1] "hi there"# # foo ----------# foo/threedots#
>> list()# foo/y# [1] "hi there"# bar ----------# bar/threedots# list()#
>> bar/y# [1] TRUE# [1] "hello: John Doe"
>>
>> What I conceptionally would like to be able to do is something like
>> this:
>>
>> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)
>>
>> Here's an approach that works but that also feels very odd:
>>
>> foo <- function(x, y = "some character", ...) {
>>  message("foo ----------")
>>  message("foo/threedots")
>>  try(print(list(...)))
>>  message("foo/y")
>>  arg <- paste0("y_", sys.call()[[1]])
>>  if (arg %in% names(list(...))) {
>>    y <- list(...)[[arg]]
>>  }
>>  try(print(y))
>>  bar(x = x, ...)}
>> bar <- function(x, y = TRUE, ...) {
>>  message("bar ----------")
>>  message("bar/threedots")
>>  try(print(list(...)))
>>  message("bar/y")
>>  arg <- paste0("y_", sys.call()[[1]])
>>  if (arg %in% names(list(...))) {
>>    y <- list(...)[[arg]]
>>  }
>>  try(print(y))
>>  return(paste0("hello: ", x))}
>>
>> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)# foobar
>> ----------# foobar/threedots# $y_foo# [1] "hello world!"# # $y_bar#
>> [1] FALSE# # foo ----------# foo/threedots# $y_foo# [1] "hello
>> world!"# # $y_bar# [1] FALSE# # foo/y# [1] "hello world!"# bar
>> ----------# bar/threedots# $y_foo# [1] "hello world!"# # $y_bar# [1]
>> FALSE# # bar/y# [1] FALSE# [1] "hello: John Doe"
>>
>> How would you go about implementing something like this?
>>
>> I also played around with S4 method dispatch to see if I could define
>> methods for a signature argument ..., but that didn't go too well (and
>> it's
>> probably a very bad idea anyway):
>>
>> setGeneric(
>>  name = "foo",
>>  signature = c("x", "..."),
>>  def = function(x, ...) standardGeneric("foo")      )
>> setMethod(
>>  f = "foo",
>>  signature = signature(x = "character", "..." = "MyThreeDotsForBar"),
>> definition = function(x, ...) bar(x = x))## --> does not work
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Sat Nov 15 19:58:56 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 15 Nov 2014 10:58:56 -0800
Subject: [R] Help in code for fitting a growth model
In-Reply-To: <CAMSabZQV3Njazq5oh9405-EoJjTvweBs+nRwgrcS398sC8BQqw@mail.gmail.com>
References: <CAMSabZQV3Njazq5oh9405-EoJjTvweBs+nRwgrcS398sC8BQqw@mail.gmail.com>
Message-ID: <87E7FC9A-5D37-480F-9C2D-B46E56842476@dcn.davis.CA.us>

Please read the Posting Guide... this question is too vague.

a) There are plenty of online references as to how to use R to fit various kinds of models. If you understand which algorithms you want to use, you should be able to find an example or even just a relevant R package using appropriate search terms in Google. If you don't understand the theory well enough to do this, then this may not be the right forum for you to be in yet. (Perhaps [1]?) Please demonstrate some initiative and make an attempt to compose your question using a small reproducible example [2]. What is and is not working for you?

b) This list has a very restricted set of allowed attachment types, and docx is not one of them. Please compose your question in your email.

[1] stats.stackexchange.com
[2] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 15, 2014 8:14:17 AM PST, Chandrasekhar Rudrappa <chandratr at gmail.com> wrote:
>I have to fit a model to growth data of Hevea (rubber) trees. The
>details
>are outlined in the attached docx file.  Kind help is solicited.


From tbowlo at gmail.com  Sat Nov 15 21:08:30 2014
From: tbowlo at gmail.com (Henry Chen)
Date: Sat, 15 Nov 2014 15:08:30 -0500
Subject: [R] Could you remove me from the mailing list please?
Message-ID: <CALe_F6mMpfpBLnT0_mgtYqNGv_SdVfg5aYXwCyN6MjNt1i-+Tw@mail.gmail.com>

I do not have my login information anymore but I do not want to receive any
R help emails again.

Thank you.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sat Nov 15 21:15:24 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 15 Nov 2014 15:15:24 -0500
Subject: [R] Could you remove me from the mailing list please?
In-Reply-To: <CALe_F6mMpfpBLnT0_mgtYqNGv_SdVfg5aYXwCyN6MjNt1i-+Tw@mail.gmail.com>
References: <CALe_F6mMpfpBLnT0_mgtYqNGv_SdVfg5aYXwCyN6MjNt1i-+Tw@mail.gmail.com>
Message-ID: <CAM_vju=2fQDQry_atdYCNpPFaD=U_pxobOAGqvzSMTKWit+16g@mail.gmail.com>

If you go to:
https://stat.ethz.ch/mailman/listinfo/r-help
as given in the footer of all list messages, the only thing you
require to unsubscribe is the email address you used to subscribe to
the list, which you obviously know since you sent this message from
it.

Sarah

On Sat, Nov 15, 2014 at 3:08 PM, Henry Chen <tbowlo at gmail.com> wrote:
> I do not have my login information anymore but I do not want to receive any
> R help emails again.
>
> Thank you.
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From jdnewmil at dcn.davis.CA.us  Sat Nov 15 21:59:36 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 15 Nov 2014 12:59:36 -0800
Subject: [R] request
In-Reply-To: <672087155.613660.1416051016141.JavaMail.yahoo@jws10095.mail.ne1.yahoo.com>
References: <672087155.613660.1416051016141.JavaMail.yahoo@jws10095.mail.ne1.yahoo.com>
Message-ID: <90FB5988-1E4A-490D-B6BA-CEDB30A8B9C1@dcn.davis.CA.us>

The data you are working with us at least as important as the algorithms you work with. You need to learn what information to give us in order for our response to help you. You can start by reading the Posting Guide mentioned in the footer of any message on this list. One important item mentioned there is that you should post using only plain text on this list, since we won't be able to see what you see if you post using HTML. You may also find [1] helpful.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 15, 2014 3:30:16 AM PST, Muhammad Alam <alamdirvi10 at yahoo.com> wrote:
>Respected sir i am a student of Mphil statistics from pakistan, please
>i have a great problem and i try my best but can not solve, ?sir the
>problem is that i want to estimate the parameters of ? LN3 ? for a set
>of data having name ?x ? ?by MLE method, in ?R, ?i also apply the VGAM
>?package but can not solve because it give us the two parameters,
>please send me the command and package in detail, i will be always pray
>for you, i spend my one month but not solve it, please ?once again
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Sun Nov 16 01:11:25 2014
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Sat, 15 Nov 2014 16:11:25 -0800
Subject: [R] Using OpenBLAS with R
Message-ID: <CACdH2Zb++5Qd1gdteaeaepx4YrcHrPy163hnk05k1J7q5e1OmQ@mail.gmail.com>

Greetings.  I'd like to get some advice about using OpenBLAS with R, rather
than using the BLAS that comes built in to R.

I've tried this on my Fedora 20 system (see the appended for details).  I ran
a simple test -- multiplying two large matrices -- and the results were very
impressive, i.e., in favor of OpenBLAS, which is consistent with discussions
I've seen on the web.

My concern is that maybe this is too good to be true.  I.e., the standard R
configuration is vetted by thousands of people every day.  Can I have the same
degree of confidence with OpenBLAS that I have in the built-in version?

And/or are there other caveats to using OpenBLAS of which I should be aware?

Thanks.

-- Mike

#### Here's the version of R, compiled locally with configuration options:
#### ./configure --enable-R-shlib --enable-BLAS-shlib

$ R

R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)
.
.
.

#### Here's the R source code for this little test:

library(microbenchmark)

mSize <- 10000
set.seed(42)

aMat <- matrix(rnorm(mSize * mSize), nrow=mSize)
bMat <- matrix(rnorm(mSize * mSize), nrow=mSize)

cMat <- aMat %*% bMat  ## do the calculation once to see that it works

traceCMat <- sum(diag(cMat))  ## a mild sanity check on the calculation
traceCMat

microbenchmark(aMat %*% bMat, times=5L)  ## repeat a few more times

-----

#### Here is the output from code, running under various conditions:

> traceCMat ###### Using the built-in BLAS from R
[1] -11367.55
> microbenchmark(aMat %*% bMat, times=5L)
Unit: seconds
          expr      min       lq     mean   median       uq     max neval
 aMat %*% bMat 675.0064 675.5325 675.4897 675.5857 675.6618 675.662     5

----------

> traceCMat  ###### Using libopenblas.so from Fedora
[1] -11367.55
> microbenchmark(aMat %*% bMat, times=5L)
Unit: seconds
          expr      min       lq     mean   median       uq      max neval
 aMat %*% bMat 70.67843 70.70545 70.76365 70.73026 70.83935 70.86475     5
>

----------

> traceCMat <- sum(diag(cMat))  ###### libopenblas.so from Fedora with
> traceCMat                     ###### export OMP_NUM_THREADS=6
[1] -11367.55
> microbenchmark(aMat %*% bMat, times=5L)
Unit: seconds
          expr      min       lq    mean   median       uq      max neval
 aMat %*% bMat 69.99146 70.02426 70.3466 70.08327 70.39537 71.23866     5
>

###### Fedora libopenblas.so appears to be single-threaded

----------

> traceCMat <- sum(diag(cMat))  ###### libopenblas.so compiled locally
> traceCMat                     ###### from source w/OMP_NUM_THREADS=6
[1] -11367.55
> microbenchmark(aMat %*% bMat, times=5L)
Unit: seconds
          expr      min       lq     mean   median       uq      max neval
 aMat %*% bMat 26.77385 27.10434 27.17862 27.12485 27.16301 27.72705     5
>

###### Locally-compiled openblas appears to be multi-threaded
###### The microbenchmark appeared to use all 8 processors, even
###### though I asked for only 6.


From yqzhang at ucsd.edu  Sat Nov 15 21:12:14 2014
From: yqzhang at ucsd.edu (Yunqi Zhang)
Date: Sat, 15 Nov 2014 15:12:14 -0500
Subject: [R] quantreg speed
Message-ID: <CA+56VKJKkOYskFXFtfiou5uRJCRdqpWhYAFWCXMBqr6wY=6bdg@mail.gmail.com>

Hi all,

I'm using quantreg rq() to perform quantile regression on a large data set.
Each record has 4 fields and there are about 18 million records in total. I
wonder if anyone has tried rq() on a large dataset and how long I should
expect it to finish. Or it is simply too large and I should subsample the
data. I would like to have an idea before I start to run and wait forever.

In addition, I will appreciate if anyone could give me an idea how long it
takes for rq() to run approximately for certain dataset size.

Yunqi

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Nov 16 02:19:57 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 15 Nov 2014 17:19:57 -0800
Subject: [R] quantreg speed
In-Reply-To: <CA+56VKJKkOYskFXFtfiou5uRJCRdqpWhYAFWCXMBqr6wY=6bdg@mail.gmail.com>
References: <CA+56VKJKkOYskFXFtfiou5uRJCRdqpWhYAFWCXMBqr6wY=6bdg@mail.gmail.com>
Message-ID: <CAF8bMcbjkPb7Q9ph3mioSv4N-OvGOCTYA0dV-UA6-w-VZjcASg@mail.gmail.com>

You can time it yourself on increasingly large subsets of your data.  E.g.,

> dat <- data.frame(x1=rnorm(1e6), x2=rnorm(1e6),
x3=sample(c("A","B","C"),size=1e6,replace=TRUE))
> dat$y <- with(dat, x1 + 2*(x3=="B")*x2 + rnorm(1e6))
> t <- vapply(n<-4^(3:10),FUN=function(n){d<-dat[seq_len(n),];
print(system.time(rq(data=d, y ~ x1 + x2*x3,
tau=0.9)))},FUN.VALUE=numeric(5))
   user  system elapsed
      0       0       0
   user  system elapsed
      0       0       0
   user  system elapsed
   0.02    0.00    0.01
   user  system elapsed
   0.01    0.00    0.02
   user  system elapsed
   0.10    0.00    0.11
   user  system elapsed
   1.09    0.00    1.10
   user  system elapsed
  13.05    0.02   13.07
   user  system elapsed
 273.30    0.11  273.74
> t
           [,1] [,2] [,3] [,4] [,5] [,6]  [,7]   [,8]
user.self     0    0 0.02 0.01 0.10 1.09 13.05 273.30
sys.self      0    0 0.00 0.00 0.00 0.00  0.02   0.11
elapsed       0    0 0.01 0.02 0.11 1.10 13.07 273.74
user.child   NA   NA   NA   NA   NA   NA    NA     NA
sys.child    NA   NA   NA   NA   NA   NA    NA     NA

Do some regressions on t["elapsed",] as a function of n and predict up to
n=10^7.  E.g.,
> summary(lm(t["elapsed",] ~ poly(n,4)))

Call:
lm(formula = t["elapsed", ] ~ poly(n, 4))

Residuals:
         1          2          3          4          5          6
 7          8
-2.375e-03 -2.970e-03  4.484e-03  1.674e-03 -8.723e-04  6.096e-05
-9.199e-07  2.715e-09

Coefficients:
             Estimate Std. Error  t value Pr(>|t|)
(Intercept) 3.601e+01  1.261e-03 28564.33 9.46e-14 ***
poly(n, 4)1 2.493e+02  3.565e-03 69917.04 6.45e-15 ***
poly(n, 4)2 5.093e+01  3.565e-03 14284.61 7.57e-13 ***
poly(n, 4)3 1.158e+00  3.565e-03   324.83 6.43e-08 ***
poly(n, 4)4 4.392e-02  3.565e-03    12.32  0.00115 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.003565 on 3 degrees of freedom
Multiple R-squared:      1,     Adjusted R-squared:      1
F-statistic: 1.273e+09 on 4 and 3 DF,  p-value: 3.575e-14


It does not look good for n=10^7.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Nov 15, 2014 at 12:12 PM, Yunqi Zhang <yqzhang at ucsd.edu> wrote:

> Hi all,
>
> I'm using quantreg rq() to perform quantile regression on a large data set.
> Each record has 4 fields and there are about 18 million records in total. I
> wonder if anyone has tried rq() on a large dataset and how long I should
> expect it to finish. Or it is simply too large and I should subsample the
> data. I would like to have an idea before I start to run and wait forever.
>
> In addition, I will appreciate if anyone could give me an idea how long it
> takes for rq() to run approximately for certain dataset size.
>
> Yunqi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From yqzhang at ucsd.edu  Sun Nov 16 02:40:48 2014
From: yqzhang at ucsd.edu (Yunqi Zhang)
Date: Sat, 15 Nov 2014 20:40:48 -0500
Subject: [R] quantreg speed
In-Reply-To: <CAF8bMcbjkPb7Q9ph3mioSv4N-OvGOCTYA0dV-UA6-w-VZjcASg@mail.gmail.com>
References: <CA+56VKJKkOYskFXFtfiou5uRJCRdqpWhYAFWCXMBqr6wY=6bdg@mail.gmail.com>
	<CAF8bMcbjkPb7Q9ph3mioSv4N-OvGOCTYA0dV-UA6-w-VZjcASg@mail.gmail.com>
Message-ID: <CA+56VKJg5M7SRV7rTyRqJ3jcrKBe0h7aM9hftuiCfCivzmy-OA@mail.gmail.com>

Hi William,

Thank you very much for your reply.

I did a subsampling to reduce the number of samples to ~1.8 million. It
seems to work fine except for 99th percentile (p-values for all the
features are 1.0). Does this mean I?m subsampling too much? How should I
interpret the result?

tau: [1] 0.25



Coefficients:

               Value      Std. Error t value    Pr(>|t|)

(Intercept)      72.15700    0.03651 1976.10513    0.00000

f1            -0.51000    0.04906  -10.39508    0.00000

f2            -20.44200    0.03933 -519.78766    0.00000

f3              -2.37000    0.04871  -48.65117    0.00000

f1:f2       -2.52500    0.05315  -47.50361    0.00000

f1:f3         1.03600    0.06573   15.76193    0.00000

f2:f3          3.41300    0.05247   65.05075    0.00000

f1:f2:f3   -0.83800    0.07120  -11.77002    0.00000



Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *

    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,

    0.75, 0.9, 0.95, 0.99), data = data_stats)



tau: [1] 0.5



Coefficients:

               Value      Std. Error t value    Pr(>|t|)

(Intercept)      83.80900    0.05626 1489.61222    0.00000

f1            -0.92200    0.07528  -12.24692    0.00000

f2            -27.90700    0.05937 -470.07189    0.00000

f3              -6.45000    0.07204  -89.53909    0.00000

f1:f2       -2.66500    0.07933  -33.59275    0.00000

f1:f3         1.99000    0.09869   20.16440    0.00000

f2:f3          7.09600    0.07611   93.23813    0.00000

f1:f2:f3   -1.71200    0.10390  -16.47660    0.00000



Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *

    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,

    0.75, 0.9, 0.95, 0.99), data = data_stats)



tau: [1] 0.75



Coefficients:

               Value      Std. Error t value    Pr(>|t|)

(Intercept)     102.71700    0.10175 1009.45946    0.00000

f1            -1.59300    0.13241  -12.03125    0.00000

f2            -40.64200    0.10623 -382.58456    0.00000

f3             -14.40900    0.12096 -119.11988    0.00000

f1:f2       -2.97600    0.13867  -21.46071    0.00000

f1:f3         3.74600    0.16335   22.93165    0.00000

f2:f3         14.14800    0.12692  111.47217    0.00000

f1:f2:f3   -3.16400    0.17159  -18.43899    0.00000



Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *

    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,

    0.75, 0.9, 0.95, 0.99), data = data_stats)



tau: [1] 0.9



Coefficients:

               Value      Std. Error t value    Pr(>|t|)

(Intercept)     130.89400    0.20609  635.12464    0.00000

f1            -2.55500    0.28139   -9.07995    0.00000

f2            -60.90500    0.21322 -285.64558    0.00000

f3             -29.42300    0.23409 -125.69092    0.00000

f1:f2       -2.77700    0.29052   -9.55870    0.00000

f1:f3         7.89700    0.33308   23.70870    0.00000

f2:f3         27.78100    0.24338  114.14722    0.00000

f1:f2:f3   -6.95800    0.34491  -20.17327    0.00000



Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *

    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,

    0.75, 0.9, 0.95, 0.99), data = data_stats)



tau: [1] 0.95



Coefficients:

               Value      Std. Error t value    Pr(>|t|)

(Intercept)     157.45900    0.42733  368.47413    0.00000

f1            -4.10200    0.55834   -7.34678    0.00000

f2            -81.24000    0.44012 -184.58697    0.00000

f3             -46.17500    0.46235  -99.87033    0.00000

f1:f2       -2.01700    0.57651   -3.49866    0.00047

f1:f3        15.67000    0.67409   23.24600    0.00000

f2:f3         43.00100    0.47973   89.63500    0.00000

f1:f2:f3  -14.05100    0.69737  -20.14843    0.00000



Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *

    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,

    0.75, 0.9, 0.95, 0.99), data = data_stats)



tau: [1] 0.99



Coefficients:

               Value         Std. Error    t value       Pr(>|t|)

(Intercept)     2.544860e+02  3.878303e+07  1.000000e-05  9.999900e-01

f1          -1.420000e+01  5.917548e+11  0.000000e+00  1.000000e+00

f2           -1.582920e+02  3.450261e+07  0.000000e+00  1.000000e+00

f3            -1.139210e+02  4.763057e+07  0.000000e+00  1.000000e+00

f1:f2      5.725000e+00  1.324283e+12  0.000000e+00  1.000000e+00

f1:f3       6.811780e+02  1.153645e+13  0.000000e+00  1.000000e+00

f2:f3        1.042510e+02  2.299953e+24  0.000000e+00  1.000000e+00

f1:f2:f3 -6.763210e+02  2.299953e+24  0.000000e+00  1.000000e+00

Warning message:

In summary.rq(xi, ...) : 288000 non-positive fis

On Sat, Nov 15, 2014 at 8:19 PM, William Dunlap <wdunlap at tibco.com> wrote:

> You can time it yourself on increasingly large subsets of your data.  E.g.,
>
> > dat <- data.frame(x1=rnorm(1e6), x2=rnorm(1e6),
> x3=sample(c("A","B","C"),size=1e6,replace=TRUE))
> > dat$y <- with(dat, x1 + 2*(x3=="B")*x2 + rnorm(1e6))
> > t <- vapply(n<-4^(3:10),FUN=function(n){d<-dat[seq_len(n),];
> print(system.time(rq(data=d, y ~ x1 + x2*x3,
> tau=0.9)))},FUN.VALUE=numeric(5))
>    user  system elapsed
>       0       0       0
>    user  system elapsed
>       0       0       0
>    user  system elapsed
>    0.02    0.00    0.01
>    user  system elapsed
>    0.01    0.00    0.02
>    user  system elapsed
>    0.10    0.00    0.11
>    user  system elapsed
>    1.09    0.00    1.10
>    user  system elapsed
>   13.05    0.02   13.07
>    user  system elapsed
>  273.30    0.11  273.74
> > t
>            [,1] [,2] [,3] [,4] [,5] [,6]  [,7]   [,8]
> user.self     0    0 0.02 0.01 0.10 1.09 13.05 273.30
> sys.self      0    0 0.00 0.00 0.00 0.00  0.02   0.11
> elapsed       0    0 0.01 0.02 0.11 1.10 13.07 273.74
> user.child   NA   NA   NA   NA   NA   NA    NA     NA
> sys.child    NA   NA   NA   NA   NA   NA    NA     NA
>
> Do some regressions on t["elapsed",] as a function of n and predict up to
> n=10^7.  E.g.,
> > summary(lm(t["elapsed",] ~ poly(n,4)))
>
> Call:
> lm(formula = t["elapsed", ] ~ poly(n, 4))
>
> Residuals:
>          1          2          3          4          5          6
>  7          8
> -2.375e-03 -2.970e-03  4.484e-03  1.674e-03 -8.723e-04  6.096e-05
> -9.199e-07  2.715e-09
>
> Coefficients:
>              Estimate Std. Error  t value Pr(>|t|)
> (Intercept) 3.601e+01  1.261e-03 28564.33 9.46e-14 ***
> poly(n, 4)1 2.493e+02  3.565e-03 69917.04 6.45e-15 ***
> poly(n, 4)2 5.093e+01  3.565e-03 14284.61 7.57e-13 ***
> poly(n, 4)3 1.158e+00  3.565e-03   324.83 6.43e-08 ***
> poly(n, 4)4 4.392e-02  3.565e-03    12.32  0.00115 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.003565 on 3 degrees of freedom
> Multiple R-squared:      1,     Adjusted R-squared:      1
> F-statistic: 1.273e+09 on 4 and 3 DF,  p-value: 3.575e-14
>
>
> It does not look good for n=10^7.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Sat, Nov 15, 2014 at 12:12 PM, Yunqi Zhang <yqzhang at ucsd.edu> wrote:
>
>> Hi all,
>>
>> I'm using quantreg rq() to perform quantile regression on a large data
>> set.
>> Each record has 4 fields and there are about 18 million records in total.
>> I
>> wonder if anyone has tried rq() on a large dataset and how long I should
>> expect it to finish. Or it is simply too large and I should subsample the
>> data. I would like to have an idea before I start to run and wait forever.
>>
>> In addition, I will appreciate if anyone could give me an idea how long it
>> takes for rq() to run approximately for certain dataset size.
>>
>> Yunqi
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Nov 16 06:00:42 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Nov 2014 21:00:42 -0800
Subject: [R] how to compure R-squared in glm
In-Reply-To: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E87450B7B2@DBDE04.ent.ti.com>
References: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E8745057BD@DBDE04.ent.ti.com>
	<886C65F9-5246-4E7D-87CC-D73FDD9262AC@comcast.net>
	<EF1CB4B85C8C3D41B75FB3A4E4EEA4E87450B7B2@DBDE04.ent.ti.com>
Message-ID: <6B566C5B-4C80-40E2-AB84-037125B27893@comcast.net>


> On Nov 15, 2014, at 7:19 AM, Aravindhan, K <k-aravindhan1 at ti.com> wrote:
> 
> Hi David,
> I am using generalized linear models (glm command with family="poisson"). 

You still have not answered what sort of pseudo-R^2 measure you expected.

http://www.econ.ucdavis.edu/faculty/cameron/research/jbes96preprint.pdf

? 
David.
> 
> Thanks
> Aravindhan
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: Saturday, November 15, 2014 1:16 PM
> To: Aravindhan, K
> Cc: R-help at r-project.org
> Subject: Re: [R] how to compure R-squared in glm
> 
> 
>> On Nov 14, 2014, at 5:48 PM, Aravindhan, K <k-aravindhan1 at ti.com> wrote:
>> 
>> Team,
>> Can some one help me in computing the R-squared value in glm.
>> 
> 
> Which version of a pseudo-R^2? What?s the model?
> 
> 
>> Thanks
>> Aravindhan
>> 
>> 	[[alternative HTML version deleted]]
> 
> This is a plain text mailing list
> 
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
> 
> Please: 
> 
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius, MD
> Alameda, CA, USA
> 

David Winsemius, MD
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Sun Nov 16 11:29:04 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 16 Nov 2014 10:29:04 +0000
Subject: [R] Using OpenBLAS with R
In-Reply-To: <CACdH2Zb++5Qd1gdteaeaepx4YrcHrPy163hnk05k1J7q5e1OmQ@mail.gmail.com>
References: <CACdH2Zb++5Qd1gdteaeaepx4YrcHrPy163hnk05k1J7q5e1OmQ@mail.gmail.com>
Message-ID: <54687C70.6090700@stats.ox.ac.uk>

On 16/11/2014 00:11, Michael Hannon wrote:
> Greetings.  I'd like to get some advice about using OpenBLAS with R, rather
> than using the BLAS that comes built in to R.

That was really a topic for the R-devel list: see the posting guide.

> I've tried this on my Fedora 20 system (see the appended for details).  I ran
> a simple test -- multiplying two large matrices -- and the results were very
> impressive, i.e., in favor of OpenBLAS, which is consistent with discussions
> I've seen on the web.

If that is all you do, then you should be using an optimized BLAS, and 
choose the one(s) best for your (unstated) machine(s).

> My concern is that maybe this is too good to be true.  I.e., the standard R
> configuration is vetted by thousands of people every day.  Can I have the same
> degree of confidence with OpenBLAS that I have in the built-in version?

No.  And it is 'too good to be true' for most users of R, for whom BLAS 
operations take a negligible proportion of their CPU time.

> And/or are there other caveats to using OpenBLAS of which I should be aware?

Yes: see the 'R Installation and Administration Manual'.  Known issues 
include:

1) Optimized BLAS trade accuracy for speed.   Surprisingly much 
published R code relies on using extended-precision FPU registers for 
intermediate results, which optimized BLAS do much less than the 
reference BLAS.

Some packages rely on a particular sign of the solution to svd or eigen 
problems: people then report as bugs that optimized BLAS give a 
different sign from the reference BLAS.

2) Fast BLAS normally use multi-threading: that usually helps elapsed 
time for a single R task at the expense of increased total CPU time. 
Fine if you have unused CPU cores, but not advantageous in a fully-used 
multi-core machine, e.g. one that is doing many R sessions in parallel.

3) Many BLAS optimize their use of CPU caches.  This works best if the 
BLAS-using process is the only task running on a particular core (or CPU 
where CPU cores share cache).  (It also means that optimizing on one CPU 
model and running on another can be disastrous.)


>
> Thanks.
>
> -- Mike
>
> #### Here's the version of R, compiled locally with configuration options:
> #### ./configure --enable-R-shlib --enable-BLAS-shlib
>
> $ R
>
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
> .
> .
> .
>
> #### Here's the R source code for this little test:
>
> library(microbenchmark)
>
> mSize <- 10000
> set.seed(42)
>
> aMat <- matrix(rnorm(mSize * mSize), nrow=mSize)
> bMat <- matrix(rnorm(mSize * mSize), nrow=mSize)
>
> cMat <- aMat %*% bMat  ## do the calculation once to see that it works
>
> traceCMat <- sum(diag(cMat))  ## a mild sanity check on the calculation
> traceCMat
>
> microbenchmark(aMat %*% bMat, times=5L)  ## repeat a few more times
>
> -----
>
> #### Here is the output from code, running under various conditions:
>
>> traceCMat ###### Using the built-in BLAS from R
> [1] -11367.55
>> microbenchmark(aMat %*% bMat, times=5L)
> Unit: seconds
>            expr      min       lq     mean   median       uq     max neval
>   aMat %*% bMat 675.0064 675.5325 675.4897 675.5857 675.6618 675.662     5
>
> ----------
>
>> traceCMat  ###### Using libopenblas.so from Fedora
> [1] -11367.55
>> microbenchmark(aMat %*% bMat, times=5L)
> Unit: seconds
>            expr      min       lq     mean   median       uq      max neval
>   aMat %*% bMat 70.67843 70.70545 70.76365 70.73026 70.83935 70.86475     5
>>
>
> ----------
>
>> traceCMat <- sum(diag(cMat))  ###### libopenblas.so from Fedora with
>> traceCMat                     ###### export OMP_NUM_THREADS=6
> [1] -11367.55
>> microbenchmark(aMat %*% bMat, times=5L)
> Unit: seconds
>            expr      min       lq    mean   median       uq      max neval
>   aMat %*% bMat 69.99146 70.02426 70.3466 70.08327 70.39537 71.23866     5
>>
>
> ###### Fedora libopenblas.so appears to be single-threaded
>
> ----------
>
>> traceCMat <- sum(diag(cMat))  ###### libopenblas.so compiled locally
>> traceCMat                     ###### from source w/OMP_NUM_THREADS=6
> [1] -11367.55
>> microbenchmark(aMat %*% bMat, times=5L)
> Unit: seconds
>            expr      min       lq     mean   median       uq      max neval
>   aMat %*% bMat 26.77385 27.10434 27.17862 27.12485 27.16301 27.72705     5
>>
>
> ###### Locally-compiled openblas appears to be multi-threaded
> ###### The microbenchmark appeared to use all 8 processors, even
> ###### though I asked for only 6.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From rkoenker at illinois.edu  Sun Nov 16 14:42:52 2014
From: rkoenker at illinois.edu (Roger)
Date: Sun, 16 Nov 2014 13:42:52 +0000
Subject: [R] quantreg speed
In-Reply-To: <b007ded0a18e4bdab01a4f090d0e7b7e@CITESHT2.ad.uillinois.edu>
References: <CA+56VKJKkOYskFXFtfiou5uRJCRdqpWhYAFWCXMBqr6wY=6bdg@mail.gmail.com>
	<CAF8bMcbjkPb7Q9ph3mioSv4N-OvGOCTYA0dV-UA6-w-VZjcASg@mail.gmail.com>
	<b007ded0a18e4bdab01a4f090d0e7b7e@CITESHT2.ad.uillinois.edu>
Message-ID: <00364B96-682B-477E-931D-EEDC6EBB09EF@illinois.edu>

You could try method = "pin".  

Sent from my iPhone

> On Nov 16, 2014, at 1:40 AM, Yunqi Zhang <yqzhang at ucsd.edu> wrote:
> 
> Hi William,
> 
> Thank you very much for your reply.
> 
> I did a subsampling to reduce the number of samples to ~1.8 million. It
> seems to work fine except for 99th percentile (p-values for all the
> features are 1.0). Does this mean I?m subsampling too much? How should I
> interpret the result?
> 
> tau: [1] 0.25
> 
> 
> 
> Coefficients:
> 
>               Value      Std. Error t value    Pr(>|t|)
> 
> (Intercept)      72.15700    0.03651 1976.10513    0.00000
> 
> f1            -0.51000    0.04906  -10.39508    0.00000
> 
> f2            -20.44200    0.03933 -519.78766    0.00000
> 
> f3              -2.37000    0.04871  -48.65117    0.00000
> 
> f1:f2       -2.52500    0.05315  -47.50361    0.00000
> 
> f1:f3         1.03600    0.06573   15.76193    0.00000
> 
> f2:f3          3.41300    0.05247   65.05075    0.00000
> 
> f1:f2:f3   -0.83800    0.07120  -11.77002    0.00000
> 
> 
> 
> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
> 
>    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
> 
>    0.75, 0.9, 0.95, 0.99), data = data_stats)
> 
> 
> 
> tau: [1] 0.5
> 
> 
> 
> Coefficients:
> 
>               Value      Std. Error t value    Pr(>|t|)
> 
> (Intercept)      83.80900    0.05626 1489.61222    0.00000
> 
> f1            -0.92200    0.07528  -12.24692    0.00000
> 
> f2            -27.90700    0.05937 -470.07189    0.00000
> 
> f3              -6.45000    0.07204  -89.53909    0.00000
> 
> f1:f2       -2.66500    0.07933  -33.59275    0.00000
> 
> f1:f3         1.99000    0.09869   20.16440    0.00000
> 
> f2:f3          7.09600    0.07611   93.23813    0.00000
> 
> f1:f2:f3   -1.71200    0.10390  -16.47660    0.00000
> 
> 
> 
> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
> 
>    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
> 
>    0.75, 0.9, 0.95, 0.99), data = data_stats)
> 
> 
> 
> tau: [1] 0.75
> 
> 
> 
> Coefficients:
> 
>               Value      Std. Error t value    Pr(>|t|)
> 
> (Intercept)     102.71700    0.10175 1009.45946    0.00000
> 
> f1            -1.59300    0.13241  -12.03125    0.00000
> 
> f2            -40.64200    0.10623 -382.58456    0.00000
> 
> f3             -14.40900    0.12096 -119.11988    0.00000
> 
> f1:f2       -2.97600    0.13867  -21.46071    0.00000
> 
> f1:f3         3.74600    0.16335   22.93165    0.00000
> 
> f2:f3         14.14800    0.12692  111.47217    0.00000
> 
> f1:f2:f3   -3.16400    0.17159  -18.43899    0.00000
> 
> 
> 
> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
> 
>    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
> 
>    0.75, 0.9, 0.95, 0.99), data = data_stats)
> 
> 
> 
> tau: [1] 0.9
> 
> 
> 
> Coefficients:
> 
>               Value      Std. Error t value    Pr(>|t|)
> 
> (Intercept)     130.89400    0.20609  635.12464    0.00000
> 
> f1            -2.55500    0.28139   -9.07995    0.00000
> 
> f2            -60.90500    0.21322 -285.64558    0.00000
> 
> f3             -29.42300    0.23409 -125.69092    0.00000
> 
> f1:f2       -2.77700    0.29052   -9.55870    0.00000
> 
> f1:f3         7.89700    0.33308   23.70870    0.00000
> 
> f2:f3         27.78100    0.24338  114.14722    0.00000
> 
> f1:f2:f3   -6.95800    0.34491  -20.17327    0.00000
> 
> 
> 
> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
> 
>    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
> 
>    0.75, 0.9, 0.95, 0.99), data = data_stats)
> 
> 
> 
> tau: [1] 0.95
> 
> 
> 
> Coefficients:
> 
>               Value      Std. Error t value    Pr(>|t|)
> 
> (Intercept)     157.45900    0.42733  368.47413    0.00000
> 
> f1            -4.10200    0.55834   -7.34678    0.00000
> 
> f2            -81.24000    0.44012 -184.58697    0.00000
> 
> f3             -46.17500    0.46235  -99.87033    0.00000
> 
> f1:f2       -2.01700    0.57651   -3.49866    0.00047
> 
> f1:f3        15.67000    0.67409   23.24600    0.00000
> 
> f2:f3         43.00100    0.47973   89.63500    0.00000
> 
> f1:f2:f3  -14.05100    0.69737  -20.14843    0.00000
> 
> 
> 
> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
> 
>    f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
> 
>    0.75, 0.9, 0.95, 0.99), data = data_stats)
> 
> 
> 
> tau: [1] 0.99
> 
> 
> 
> Coefficients:
> 
>               Value         Std. Error    t value       Pr(>|t|)
> 
> (Intercept)     2.544860e+02  3.878303e+07  1.000000e-05  9.999900e-01
> 
> f1          -1.420000e+01  5.917548e+11  0.000000e+00  1.000000e+00
> 
> f2           -1.582920e+02  3.450261e+07  0.000000e+00  1.000000e+00
> 
> f3            -1.139210e+02  4.763057e+07  0.000000e+00  1.000000e+00
> 
> f1:f2      5.725000e+00  1.324283e+12  0.000000e+00  1.000000e+00
> 
> f1:f3       6.811780e+02  1.153645e+13  0.000000e+00  1.000000e+00
> 
> f2:f3        1.042510e+02  2.299953e+24  0.000000e+00  1.000000e+00
> 
> f1:f2:f3 -6.763210e+02  2.299953e+24  0.000000e+00  1.000000e+00
> 
> Warning message:
> 
> In summary.rq(xi, ...) : 288000 non-positive fis
> 
>> On Sat, Nov 15, 2014 at 8:19 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> 
>> You can time it yourself on increasingly large subsets of your data.  E.g.,
>> 
>>> dat <- data.frame(x1=rnorm(1e6), x2=rnorm(1e6),
>> x3=sample(c("A","B","C"),size=1e6,replace=TRUE))
>>> dat$y <- with(dat, x1 + 2*(x3=="B")*x2 + rnorm(1e6))
>>> t <- vapply(n<-4^(3:10),FUN=function(n){d<-dat[seq_len(n),];
>> print(system.time(rq(data=d, y ~ x1 + x2*x3,
>> tau=0.9)))},FUN.VALUE=numeric(5))
>>   user  system elapsed
>>      0       0       0
>>   user  system elapsed
>>      0       0       0
>>   user  system elapsed
>>   0.02    0.00    0.01
>>   user  system elapsed
>>   0.01    0.00    0.02
>>   user  system elapsed
>>   0.10    0.00    0.11
>>   user  system elapsed
>>   1.09    0.00    1.10
>>   user  system elapsed
>>  13.05    0.02   13.07
>>   user  system elapsed
>> 273.30    0.11  273.74
>>> t
>>           [,1] [,2] [,3] [,4] [,5] [,6]  [,7]   [,8]
>> user.self     0    0 0.02 0.01 0.10 1.09 13.05 273.30
>> sys.self      0    0 0.00 0.00 0.00 0.00  0.02   0.11
>> elapsed       0    0 0.01 0.02 0.11 1.10 13.07 273.74
>> user.child   NA   NA   NA   NA   NA   NA    NA     NA
>> sys.child    NA   NA   NA   NA   NA   NA    NA     NA
>> 
>> Do some regressions on t["elapsed",] as a function of n and predict up to
>> n=10^7.  E.g.,
>>> summary(lm(t["elapsed",] ~ poly(n,4)))
>> 
>> Call:
>> lm(formula = t["elapsed", ] ~ poly(n, 4))
>> 
>> Residuals:
>>         1          2          3          4          5          6
>> 7          8
>> -2.375e-03 -2.970e-03  4.484e-03  1.674e-03 -8.723e-04  6.096e-05
>> -9.199e-07  2.715e-09
>> 
>> Coefficients:
>>             Estimate Std. Error  t value Pr(>|t|)
>> (Intercept) 3.601e+01  1.261e-03 28564.33 9.46e-14 ***
>> poly(n, 4)1 2.493e+02  3.565e-03 69917.04 6.45e-15 ***
>> poly(n, 4)2 5.093e+01  3.565e-03 14284.61 7.57e-13 ***
>> poly(n, 4)3 1.158e+00  3.565e-03   324.83 6.43e-08 ***
>> poly(n, 4)4 4.392e-02  3.565e-03    12.32  0.00115 **
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> Residual standard error: 0.003565 on 3 degrees of freedom
>> Multiple R-squared:      1,     Adjusted R-squared:      1
>> F-statistic: 1.273e+09 on 4 and 3 DF,  p-value: 3.575e-14
>> 
>> 
>> It does not look good for n=10^7.
>> 
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>>> On Sat, Nov 15, 2014 at 12:12 PM, Yunqi Zhang <yqzhang at ucsd.edu> wrote:
>>> 
>>> Hi all,
>>> 
>>> I'm using quantreg rq() to perform quantile regression on a large data
>>> set.
>>> Each record has 4 fields and there are about 18 million records in total.
>>> I
>>> wonder if anyone has tried rq() on a large dataset and how long I should
>>> expect it to finish. Or it is simply too large and I should subsample the
>>> data. I would like to have an idea before I start to run and wait forever.
>>> 
>>> In addition, I will appreciate if anyone could give me an idea how long it
>>> takes for rq() to run approximately for certain dataset size.
>>> 
>>> Yunqi
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sun Nov 16 15:43:45 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 16 Nov 2014 06:43:45 -0800
Subject: [R] how to compure R-squared in glm
In-Reply-To: <6B566C5B-4C80-40E2-AB84-037125B27893@comcast.net>
References: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E8745057BD@DBDE04.ent.ti.com>
	<886C65F9-5246-4E7D-87CC-D73FDD9262AC@comcast.net>
	<EF1CB4B85C8C3D41B75FB3A4E4EEA4E87450B7B2@DBDE04.ent.ti.com>
	<6B566C5B-4C80-40E2-AB84-037125B27893@comcast.net>
Message-ID: <CACk-te2ieBbf2e_QjYSqT5DPHFuzrN+EUnjytAc6ZW-A2VgifQ@mail.gmail.com>

... and I would further add to David's comments that R^2 is basically
nonsense for glm's (and mostly for lm's also --  but not a topic for
further discussion here). Likelihood ratio tests are what should be
used to judge model fits for glm's -- also not a topic for further
discussion here. Consult a local statistician, do your glm homework,
or post on stats.stackexchange.com for statistical follow-ups.

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Nov 15, 2014 at 9:00 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Nov 15, 2014, at 7:19 AM, Aravindhan, K <k-aravindhan1 at ti.com> wrote:
>>
>> Hi David,
>> I am using generalized linear models (glm command with family="poisson").
>
> You still have not answered what sort of pseudo-R^2 measure you expected.
>
> http://www.econ.ucdavis.edu/faculty/cameron/research/jbes96preprint.pdf
>
> ?
> David.
>>
>> Thanks
>> Aravindhan
>>
>> -----Original Message-----
>> From: David Winsemius [mailto:dwinsemius at comcast.net]
>> Sent: Saturday, November 15, 2014 1:16 PM
>> To: Aravindhan, K
>> Cc: R-help at r-project.org
>> Subject: Re: [R] how to compure R-squared in glm
>>
>>
>>> On Nov 14, 2014, at 5:48 PM, Aravindhan, K <k-aravindhan1 at ti.com> wrote:
>>>
>>> Team,
>>> Can some one help me in computing the R-squared value in glm.
>>>
>>
>> Which version of a pseudo-R^2? What?s the model?
>>
>>
>>> Thanks
>>> Aravindhan
>>>
>>>      [[alternative HTML version deleted]]
>>
>> This is a plain text mailing list
>>
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>
>> Please:
>>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>
> David Winsemius, MD
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From janko.thyson at gmail.com  Sun Nov 16 17:42:20 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Sun, 16 Nov 2014 17:42:20 +0100
Subject: [R] Fine controlling "three dots" argument dispatch to
 functions with identical argument names
In-Reply-To: <546788F2.4040802@gmail.com>
References: <CAGmpuegNtZFAqCUZbQKscwOhKu+RibtgCRmS--39M4G4+tzjog@mail.gmail.com>
	<335D892B-BDE7-4D1D-A77A-6796889201F6@dcn.davis.CA.us>
	<546788F2.4040802@gmail.com>
Message-ID: <CAGmpuejeu3=2qsqvqcwscHNgVX9icd_GStdPaLLTJF6+ZMx-_w@mail.gmail.com>

Thanks for the info/suggestions!

But note that it's not just a one-step, but a two step dispatching process
with respect to `...`. That is, `foo()` and `bar()` are *not* both called
directly inside `foobar()`: `foobar()` only calls `foo()` which then calls
`bar()`.

I now came up with something along the lines of what Duncan suggested. The
reason I wouldn't want to go with Jeff's approach is that I would want
`foobar()` to remain as generic an interface as possible (the same goes for
`foo()` calling `bar()`).

I.e., I don't want it to have any explicit arguments of subsequently called
functions (e.g. `y_foo`). It should just be able to take any inputs that
subsequently called functions can process (i.e. `foo()` and then in turn
`bar()`) and pass them along accordingly. Of course this would need to be
clearly and well documented for the respective functions.

So here's my current approach. It would be nice to just be able to dispatch
`...` for calls of `do.call()` like so: `do.call("foo", c(x = x, ...))` but
that way a nested structure of `...` gets flattened out (see respective
lines in `foobar()`). That's why I need to resort to `do.call("foo", c(x =
x, threedots$args_foo, threedots[-idx]))`. What do you think of it?

foobar <- function(x, ...) {
  message("foobar ----------")
  message("foobar/threedots")
  threedots <- list(...)
  try(print(threedots))
  message("foobar/combined args")
  try(print(c(x, threedots)))
  ## --> list gets flattened (i.e. `args_foo.y` instead of nested structure)
  ## --> that's why subsequent functions will not recognize "their"
arguments
  ## from it
  if (any(idx <- names(threedots) %in% "args_foo")) {
    do.call("foo", c(x = x, threedots$args_foo, threedots[-idx]))
  } else {
    foo(x = x, ...)
  }
}
foo <- function(x, y = "some character", ...) {
  message("foo ----------")
  message("foo/threedots")
  threedots <- list(...)
  try(print(threedots))
  message("foo/y")
  try(print(y))
  if (any(idx <- names(threedots) %in% "args_bar")) {
    do.call("bar", c(x = x, threedots$args_bar, threedots[-idx]))
  } else {
    bar(x = x, ...)
  }
}
bar <- function(x, y = TRUE, ...) {
  message("bar ----------")
  message("bar/threedots")
  try(print(list(...)))
  message("bar/y")
  try(print(y))
  return(paste0("hello: ", x))
}

foobar(x = "John Doe", args_foo = list(y = "hello world!"))
foobar(x = "John Doe", args_bar = list(y = FALSE))
foobar(x = "John Doe",
       args_foo = list(y = "hello world!"),
       args_bar = list(y = FALSE)
)

Best regards and thanks,
Janko

On Sat, Nov 15, 2014 at 6:10 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 15/11/2014, 11:26 AM, Jeff Newmiller wrote:
> > AFAIK You have to alter the name of at least one of the y arguments as
> used by foobar, and anyone calling foobar has to read about that in the
> help file. That is only one y can be in "...". e.g.
> >
> > foobar <- function( x, y_foo, ... ) {
> >   foo( x, y=y_foo, ... )
> >   bar( x, ... )
> > }
> >
>
> That's the best solution.  There is another one:  you can put
>
> args <- list(...)
>
> into foobar(), and then do whatever you like to the args vector, and put
> together calls to foo() and bar() using do.call().  But this is hard to
> read and easy to get wrong, so I recommend Jeff's simple solution.
>
> Duncan Murdoch
>
> >
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On November 15, 2014 6:49:41 AM PST, Janko Thyson <
> janko.thyson at gmail.com> wrote:
> >> Dear list,
> >>
> >> I wonder if there's a clever way to fine control the exact way
> >> arguments
> >> are dispatched via R's "three dots" argument ....
> >>
> >> Consider the following use case:
> >>
> >> - you have a function foobar() that calls foo() which in turn calls
> >> bar()
> >> - *both* foo() and bar() have an argument that's called y, but they
> >> each
> >>   have a *different meaning*
> >> - in the call to foobar(), you would like to say "here's the y for
> >> foo()
> >> and here's the y for bar()". *That's what I would like to accomplish*.
> >>
> >> If you simply call foobar(x = "John Doe", y = "hello world"), y only
> >> get's
> >> dispatched to foo() as in the call to bar() things would have to be
> >> explicit in order to be dispatched (i.e. the call would have to be
> >> bar(x =
> >> x, y = y) instead of bar(x = x, ...):
> >>
> >> foo <- function(x, y = "some character", ...) {
> >>  message("foo ----------")
> >>  message("foo/threedots")
> >>  try(print(list(...)))
> >>  message("foo/y")
> >>  try(print(y))
> >>  bar(x = x, ...)}
> >> bar <- function(x, y = TRUE, ...) {
> >>  message("bar ----------")
> >>  message("bar/threedots")
> >>  try(print(list(...)))
> >>  message("bar/y")
> >>  try(print(y))
> >>  return(paste0("hello: ", x))}
> >> foobar <- function(x, ...) {
> >>  message("foobar ----------")
> >>  message("foobar/threedots")
> >>  try(print(list(...)))
> >>  foo(x = x, ...)}
> >>
> >> foobar(x = "John Doe", y = "hi there")# foobar ----------#
> >> foobar/threedots# $y# [1] "hi there"# # foo ----------# foo/threedots#
> >> list()# foo/y# [1] "hi there"# bar ----------# bar/threedots# list()#
> >> bar/y# [1] TRUE# [1] "hello: John Doe"
> >>
> >> What I conceptionally would like to be able to do is something like
> >> this:
> >>
> >> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)
> >>
> >> Here's an approach that works but that also feels very odd:
> >>
> >> foo <- function(x, y = "some character", ...) {
> >>  message("foo ----------")
> >>  message("foo/threedots")
> >>  try(print(list(...)))
> >>  message("foo/y")
> >>  arg <- paste0("y_", sys.call()[[1]])
> >>  if (arg %in% names(list(...))) {
> >>    y <- list(...)[[arg]]
> >>  }
> >>  try(print(y))
> >>  bar(x = x, ...)}
> >> bar <- function(x, y = TRUE, ...) {
> >>  message("bar ----------")
> >>  message("bar/threedots")
> >>  try(print(list(...)))
> >>  message("bar/y")
> >>  arg <- paste0("y_", sys.call()[[1]])
> >>  if (arg %in% names(list(...))) {
> >>    y <- list(...)[[arg]]
> >>  }
> >>  try(print(y))
> >>  return(paste0("hello: ", x))}
> >>
> >> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)# foobar
> >> ----------# foobar/threedots# $y_foo# [1] "hello world!"# # $y_bar#
> >> [1] FALSE# # foo ----------# foo/threedots# $y_foo# [1] "hello
> >> world!"# # $y_bar# [1] FALSE# # foo/y# [1] "hello world!"# bar
> >> ----------# bar/threedots# $y_foo# [1] "hello world!"# # $y_bar# [1]
> >> FALSE# # bar/y# [1] FALSE# [1] "hello: John Doe"
> >>
> >> How would you go about implementing something like this?
> >>
> >> I also played around with S4 method dispatch to see if I could define
> >> methods for a signature argument ..., but that didn't go too well (and
> >> it's
> >> probably a very bad idea anyway):
> >>
> >> setGeneric(
> >>  name = "foo",
> >>  signature = c("x", "..."),
> >>  def = function(x, ...) standardGeneric("foo")      )
> >> setMethod(
> >>  f = "foo",
> >>  signature = signature(x = "character", "..." = "MyThreeDotsForBar"),
> >> definition = function(x, ...) bar(x = x))## --> does not work
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Nov 16 18:14:04 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 16 Nov 2014 12:14:04 -0500
Subject: [R] Fine controlling "three dots" argument dispatch to
 functions with identical argument names
In-Reply-To: <CAGmpuejeu3=2qsqvqcwscHNgVX9icd_GStdPaLLTJF6+ZMx-_w@mail.gmail.com>
References: <CAGmpuegNtZFAqCUZbQKscwOhKu+RibtgCRmS--39M4G4+tzjog@mail.gmail.com>	<335D892B-BDE7-4D1D-A77A-6796889201F6@dcn.davis.CA.us>	<546788F2.4040802@gmail.com>
	<CAGmpuejeu3=2qsqvqcwscHNgVX9icd_GStdPaLLTJF6+ZMx-_w@mail.gmail.com>
Message-ID: <5468DB5C.5010608@gmail.com>

On 16/11/2014, 11:42 AM, Janko Thyson wrote:
> Thanks for the info/suggestions!
> 
> But note that it's not just a one-step, but a two step dispatching
> process with respect to `...`. That is, `foo()` and `bar()` are *not*
> both called directly inside `foobar()`: `foobar()` only calls `foo()`
> which then calls `bar()`.
> 
> I now came up with something along the lines of what Duncan suggested.
> The reason I wouldn't want to go with Jeff's approach is that I would
> want `foobar()` to remain as generic an interface as possible (the same
> goes for `foo()` calling `bar()`).
> 
> I.e., I don't want it to have any explicit arguments of subsequently
> called functions (e.g. `y_foo`). It should just be able to take any
> inputs that subsequently called functions can process (i.e. `foo()` and
> then in turn `bar()`) and pass them along accordingly. Of course this
> would need to be clearly and well documented for the respective functions.
> 
> So here's my current approach. It would be nice to just be able to
> dispatch `...` for calls of `do.call()` like so: `do.call("foo", c(x =
> x, ...))` but that way a nested structure of `...` gets flattened out
> (see respective lines in `foobar()`). That's why I need to resort to
> `do.call("foo", c(x = x, threedots$args_foo, threedots[-idx]))`. What do
> you think of it?

I haven't analyzed your implementation, so I don't know if it has any
bugs.

But the other thing that's hard when you do this is to document it.  How
do you describe the ... argument of foobar?  Where do you document the
args_foo and args_bar names?  If users can't figure this out, then it's
not a good design.  And if it ties you to a particular implementation of
foobar it might not be.

For example, I'd rather read "cex.axis is the character size on the
axis", rather than "args_axis is a named list of arguments to pass to
the axis function".

Duncan Murdoch



> foobar <- function(x, ...) {
>   message("foobar ----------")
>   message("foobar/threedots")
>   threedots <- list(...)
>   try(print(threedots))
>   message("foobar/combined args")
>   try(print(c(x, threedots)))
>   ## --> list gets flattened (i.e. `args_foo.y` instead of nested structure)
>   ## --> that's why subsequent functions will not recognize "their"
> arguments
>   ## from it
>   if (any(idx <- names(threedots) %in% "args_foo")) {
>     do.call("foo", c(x = x, threedots$args_foo, threedots[-idx])) 
>   } else {
>     foo(x = x, ...)
>   }
> }
> foo <- function(x, y = "some character", ...) {
>   message("foo ----------")
>   message("foo/threedots")
>   threedots <- list(...)
>   try(print(threedots))
>   message("foo/y")
>   try(print(y))
>   if (any(idx <- names(threedots) %in% "args_bar")) {
>     do.call("bar", c(x = x, threedots$args_bar, threedots[-idx]))
>   } else {
>     bar(x = x, ...)
>   }
> }
> bar <- function(x, y = TRUE, ...) {
>   message("bar ----------")
>   message("bar/threedots")
>   try(print(list(...)))
>   message("bar/y")
>   try(print(y))
>   return(paste0("hello: ", x))
> }
> 
> foobar(x = "John Doe", args_foo = list(y = "hello world!"))
> foobar(x = "John Doe", args_bar = list(y = FALSE))
> foobar(x = "John Doe",
>        args_foo = list(y = "hello world!"),
>        args_bar = list(y = FALSE)
> )
> 
> Best regards and thanks,
> Janko
> 
> On Sat, Nov 15, 2014 at 6:10 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 15/11/2014, 11:26 AM, Jeff Newmiller wrote:
>     > AFAIK You have to alter the name of at least one of the y arguments as used by foobar, and anyone calling foobar has to read about that in the help file. That is only one y can be in "...". e.g.
>     >
>     > foobar <- function( x, y_foo, ... ) {
>     >   foo( x, y=y_foo, ... )
>     >   bar( x, ... )
>     > }
>     >
> 
>     That's the best solution.  There is another one:  you can put
> 
>     args <- list(...)
> 
>     into foobar(), and then do whatever you like to the args vector, and put
>     together calls to foo() and bar() using do.call().  But this is hard to
>     read and easy to get wrong, so I recommend Jeff's simple solution.
> 
>     Duncan Murdoch
> 
>     >
>     >
>     ---------------------------------------------------------------------------
>     > Jeff Newmiller                        The     .....       ..... 
>     Go Live...
>     > DCN:<jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>> 
>           Basics: ##.#.       ##.#.  Live Go...
>     >                                       Live:   OO#.. Dead: OO#.. 
>     Playing
>     > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>     > /Software/Embedded Controllers)               .OO#.       .OO#. 
>     rocks...1k
>     >
>     ---------------------------------------------------------------------------
>     > Sent from my phone. Please excuse my brevity.
>     >
>     > On November 15, 2014 6:49:41 AM PST, Janko Thyson
>     <janko.thyson at gmail.com <mailto:janko.thyson at gmail.com>> wrote:
>     >> Dear list,
>     >>
>     >> I wonder if there's a clever way to fine control the exact way
>     >> arguments
>     >> are dispatched via R's "three dots" argument ....
>     >>
>     >> Consider the following use case:
>     >>
>     >> - you have a function foobar() that calls foo() which in turn calls
>     >> bar()
>     >> - *both* foo() and bar() have an argument that's called y, but they
>     >> each
>     >>   have a *different meaning*
>     >> - in the call to foobar(), you would like to say "here's the y for
>     >> foo()
>     >> and here's the y for bar()". *That's what I would like to
>     accomplish*.
>     >>
>     >> If you simply call foobar(x = "John Doe", y = "hello world"), y only
>     >> get's
>     >> dispatched to foo() as in the call to bar() things would have to be
>     >> explicit in order to be dispatched (i.e. the call would have to be
>     >> bar(x =
>     >> x, y = y) instead of bar(x = x, ...):
>     >>
>     >> foo <- function(x, y = "some character", ...) {
>     >>  message("foo ----------")
>     >>  message("foo/threedots")
>     >>  try(print(list(...)))
>     >>  message("foo/y")
>     >>  try(print(y))
>     >>  bar(x = x, ...)}
>     >> bar <- function(x, y = TRUE, ...) {
>     >>  message("bar ----------")
>     >>  message("bar/threedots")
>     >>  try(print(list(...)))
>     >>  message("bar/y")
>     >>  try(print(y))
>     >>  return(paste0("hello: ", x))}
>     >> foobar <- function(x, ...) {
>     >>  message("foobar ----------")
>     >>  message("foobar/threedots")
>     >>  try(print(list(...)))
>     >>  foo(x = x, ...)}
>     >>
>     >> foobar(x = "John Doe", y = "hi there")# foobar ----------#
>     >> foobar/threedots# $y# [1] "hi there"# # foo ----------#
>     foo/threedots#
>     >> list()# foo/y# [1] "hi there"# bar ----------# bar/threedots# list()#
>     >> bar/y# [1] TRUE# [1] "hello: John Doe"
>     >>
>     >> What I conceptionally would like to be able to do is something like
>     >> this:
>     >>
>     >> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)
>     >>
>     >> Here's an approach that works but that also feels very odd:
>     >>
>     >> foo <- function(x, y = "some character", ...) {
>     >>  message("foo ----------")
>     >>  message("foo/threedots")
>     >>  try(print(list(...)))
>     >>  message("foo/y")
>     >>  arg <- paste0("y_", sys.call()[[1]])
>     >>  if (arg %in% names(list(...))) {
>     >>    y <- list(...)[[arg]]
>     >>  }
>     >>  try(print(y))
>     >>  bar(x = x, ...)}
>     >> bar <- function(x, y = TRUE, ...) {
>     >>  message("bar ----------")
>     >>  message("bar/threedots")
>     >>  try(print(list(...)))
>     >>  message("bar/y")
>     >>  arg <- paste0("y_", sys.call()[[1]])
>     >>  if (arg %in% names(list(...))) {
>     >>    y <- list(...)[[arg]]
>     >>  }
>     >>  try(print(y))
>     >>  return(paste0("hello: ", x))}
>     >>
>     >> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)# foobar
>     >> ----------# foobar/threedots# $y_foo# [1] "hello world!"# # $y_bar#
>     >> [1] FALSE# # foo ----------# foo/threedots# $y_foo# [1] "hello
>     >> world!"# # $y_bar# [1] FALSE# # foo/y# [1] "hello world!"# bar
>     >> ----------# bar/threedots# $y_foo# [1] "hello world!"# # $y_bar# [1]
>     >> FALSE# # bar/y# [1] FALSE# [1] "hello: John Doe"
>     >>
>     >> How would you go about implementing something like this?
>     >>
>     >> I also played around with S4 method dispatch to see if I could define
>     >> methods for a signature argument ..., but that didn't go too well
>     (and
>     >> it's
>     >> probably a very bad idea anyway):
>     >>
>     >> setGeneric(
>     >>  name = "foo",
>     >>  signature = c("x", "..."),
>     >>  def = function(x, ...) standardGeneric("foo")      )
>     >> setMethod(
>     >>  f = "foo",
>     >>  signature = signature(x = "character", "..." = "MyThreeDotsForBar"),
>     >> definition = function(x, ...) bar(x = x))## --> does not work
>     >>
>     >>      [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     >> http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
> 
>


From jarod_v6 at libero.it  Sun Nov 16 19:25:32 2014
From: jarod_v6 at libero.it (jarod_v6 at libero.it)
Date: Sun, 16 Nov 2014 19:25:32 +0100 (CET)
Subject: [R] Problem on annotation of Deseq2 on reportingtools
Message-ID: <2041049126.5672141416162332341.JavaMail.httpd@webmail-51.iol.local>

Dear all!,

I use this code:


dds <- DESeq(ddHTSeq)
res <-results(dds)
#reporting
library(ReportingTools)
library("org.Hs.eg.db")
des2Report <- HTMLReport(shortName ='RNAseq_analysis_DESeq2.html',title ='RNA-seq analysis of differential expression using DESeq2 ',reportDirectory = "./Reports")
#publish(dds,des2Report,pvalueCutoff=0.05,annotation.db="org,Hs.eg.db")
publish(dds,des2Report,pvalueCutoff=0.01,annotation.db="org.Hs.egENSEMBL2EG",factor=colData(dds)$condition,categorySize=5)
finish(des2Report) 

and I have this error:
Error in results(object, resultName) : 
  'contrast', as a character vector of length 3, should have the form:
contrast = c('factorName','numeratorLevel','denominatorLevel'),
see the manual page of ?results for more information


is.factor(colData(dds)$condition)
[1] TRUE
> 
What can I do?


 sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] pvclust_1.2-2             gplots_2.13.0             genefilter_1.44.0        
 [4] ReportingTools_2.2.0      knitr_1.6                 org.Hs.eg.db_2.10.1      
 [7] RSQLite_0.11.4            DBI_0.2-7                 annotate_1.40.1          
[10] AnnotationDbi_1.24.0      Biobase_2.22.0            biomaRt_2.18.0           
[13] DESeq2_1.4.5              RcppArmadillo_0.4.300.8.0 Rcpp_0.11.2              
[16] GenomicRanges_1.14.4      XVector_0.2.0             IRanges_1.20.7           
[19] BiocGenerics_0.8.0       

loaded via a namespace (and not attached):
 [1] AnnotationForge_1.4.4    Biostrings_2.30.1        biovizBase_1.10.8       
 [4] bitops_1.0-6             BSgenome_1.30.0          Category_2.28.0         
 [7] caTools_1.17             cluster_1.15.3           colorspace_1.2-4        
[10] dichromat_2.0-0          digest_0.6.4             edgeR_3.4.2             
[13] evaluate_0.5.5           formatR_0.10             Formula_1.1-1           
[16] gdata_2.13.3             geneplotter_1.40.0       GenomicFeatures_1.14.5  
[19] ggbio_1.10.16            ggplot2_1.0.0            GO.db_2.10.1            
[22] GOstats_2.28.0           graph_1.40.1             grid_3.1.1              
[25] gridExtra_0.9.1          GSEABase_1.24.0          gtable_0.1.2            
[28] gtools_3.4.1             Hmisc_3.14-4             hwriter_1.3             
[31] KernSmooth_2.23-13       lattice_0.20-29          latticeExtra_0.6-26     
[34] limma_3.18.13            locfit_1.5-9.1           MASS_7.3-34             
[37] Matrix_1.1-4             munsell_0.4.2            PFAM.db_2.10.1          
[40] plyr_1.8.1               proto_0.3-10             RBGL_1.38.0             
[43] RColorBrewer_1.0-5       RCurl_1.95-4.1           reshape2_1.4            
[46] R.methodsS3_1.6.1        R.oo_1.18.0              Rsamtools_1.14.3        
[49] rtracklayer_1.22.7       R.utils_1.32.4           scales_0.2.4            
[52] splines_3.1.1            stats4_3.1.1             stringr_0.6.2           
[55] survival_2.37-7          tools_3.1.1              VariantAnnotation_1.8.13
[58] XML_3.98-1.1             xtable_1.7-3             zlibbioc_1.8.0

	[[alternative HTML version deleted]]


From predeus at gmail.com  Sun Nov 16 08:53:28 2014
From: predeus at gmail.com (Alexander Predeus)
Date: Sun, 16 Nov 2014 02:53:28 -0500
Subject: [R] Using factors to analyze table by quantiles
Message-ID: <CADvsxOmffYqfv9ipipXvco7zBDJ5PJ9EKk1SQaM4Gu_XUNTOqQ@mail.gmail.com>

Hello all,

I've been trying to do the following analysis. I have a table (T1) that
defines sizes of my datasets (~80k rows):

       size
X1   1000
X2   8323
X3   58

And then I have a table (T2) of ~ 5 million significant overlaps between
datasets:

X234   X443
X323   X1
X998   X12

What I want to do, is split table T1 into 10 quantiles by "size", which I
seem to successfully achieve using these commands:

qq <- factor(cut(T1$size,quantile(T1$size,
probs=seq(0.0,1.0,by=0.1)),include.lowest = TRUE),labels = LETTERS[1:10])
table(qq)

  A    B    C    D    E    F    G    H    I    J
8204 7643 7941 7878 7867 7773 7913 7856 7894 7869


Now I need to count how many of all 100 possible combinations
(AA,AB,AC,etc) are present in table T2 using these factors.

How can I do that? Thank you in advance,

-- Alex

	[[alternative HTML version deleted]]


From junluke at gmail.com  Sun Nov 16 17:27:59 2014
From: junluke at gmail.com (jun wang)
Date: Sun, 16 Nov 2014 11:27:59 -0500
Subject: [R] heston model simulation
Message-ID: <CAPD4hGCBqz+LSGJGrh8zoiJj06FN35kZjfoTmvDomVQtwt2xeQ@mail.gmail.com>

Dear all,

I am using the following code for simulating Heston model. I am trying to
compare skewness with respect to different Rhos, but it doesn't seem to
work. Any body can tell me what is happening? I am using Euler-Maruyama
Monte Carlo. Here is my sample code. Any hints would be really appreciated.



theta=0.04
alpha=1.5
#delta=0.5
#rho=-0.9
n=100
m=1000

heston_sim<-function(rho,delta,m,mu){
s<-matrix(NA,n,m)
v<-matrix(NA,n,m)
for (j in 1:m){
for (i in 2:n) {
s[1,j]=2
v[1,j]=0.4
dt=1/100
zv<-rnorm(1)
zs<-rnorm(1)
zx<-rho*zv+sqrt(1-rho^2)*zs
w1<-zv*sqrt(dt)
w2<-zx*sqrt(dt)
s[i,j]=s[i-1,j]+(mu-0.5*max(v[i-1,j],0))*dt+sqrt(max(v[i-1,j],0))*w2
v[i,j]=v[i-1,j]+alpha*(theta-v[i-1,j])*dt+sqrt(max(v[i-1,j],0))*delta*w1
}
}
return(s)
}
s1<-heston_sim(-1,0.1,1000,0)
s2<-heston_sim(0,0.1,1000,0)
s3<-heston_sim(0.7,0.1,1000,0)

a1<-c(diff(s1,lag=1)*100)
a2<-c(diff(s2,lag=1)*100)
a3<-c(diff(s3,lag=1)*100)



plot(density(na.omit(a1),bw=0.5),main="",ylim=c(0,0.2))
lines(density(na.omit(a2),bw=0.5),col=2)
lines(density(na.omit(a3),,bw=0.5),col=3)
legend('topright',legend=c(expression(paste(rho,
"=--0.3")),expression(paste(rho, "=0")),expression(paste(rho,
"=0.5"))),col=1:3,lty=1)

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Nov 16 19:54:54 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 16 Nov 2014 10:54:54 -0800
Subject: [R] Fine controlling "three dots" argument dispatch to
	functions with identical argument names
In-Reply-To: <CAGmpuejeu3=2qsqvqcwscHNgVX9icd_GStdPaLLTJF6+ZMx-_w@mail.gmail.com>
References: <CAGmpuegNtZFAqCUZbQKscwOhKu+RibtgCRmS--39M4G4+tzjog@mail.gmail.com>
	<335D892B-BDE7-4D1D-A77A-6796889201F6@dcn.davis.CA.us>
	<546788F2.4040802@gmail.com>
	<CAGmpuejeu3=2qsqvqcwscHNgVX9icd_GStdPaLLTJF6+ZMx-_w@mail.gmail.com>
Message-ID: <32152484-1B61-414C-8A9C-C14B4184355B@dcn.davis.CA.us>

You have some interesting ideas about what makes for improvements in parameter interfaces. Wrapping the arguments into a list is like creating an object to represent all of them, except that you don't have the benefits of a class to go with that cognitive shift. And if making classes to hold parameters were appropriate wouldn't you have already done so in the foo and bar interfaces? That is a heavyweight approach that doesn't always make sense.

I agree with Duncan that each time you define a function you are defining an interface that should stand on its own... the user should be able to associate unique names with unique behaviors. From this perspective, your reluctance to define a unified set of uniquely-named parameters for each of foobar and (and apparently foo) seems illogical.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 16, 2014 8:42:20 AM PST, Janko Thyson <janko.thyson at gmail.com> wrote:
>Thanks for the info/suggestions!
>
>But note that it's not just a one-step, but a two step dispatching
>process
>with respect to `...`. That is, `foo()` and `bar()` are *not* both
>called
>directly inside `foobar()`: `foobar()` only calls `foo()` which then
>calls
>`bar()`.
>
>I now came up with something along the lines of what Duncan suggested.
>The
>reason I wouldn't want to go with Jeff's approach is that I would want
>`foobar()` to remain as generic an interface as possible (the same goes
>for
>`foo()` calling `bar()`).
>
>I.e., I don't want it to have any explicit arguments of subsequently
>called
>functions (e.g. `y_foo`). It should just be able to take any inputs
>that
>subsequently called functions can process (i.e. `foo()` and then in
>turn
>`bar()`) and pass them along accordingly. Of course this would need to
>be
>clearly and well documented for the respective functions.
>
>So here's my current approach. It would be nice to just be able to
>dispatch
>`...` for calls of `do.call()` like so: `do.call("foo", c(x = x, ...))`
>but
>that way a nested structure of `...` gets flattened out (see respective
>lines in `foobar()`). That's why I need to resort to `do.call("foo",
>c(x =
>x, threedots$args_foo, threedots[-idx]))`. What do you think of it?
>
>foobar <- function(x, ...) {
>  message("foobar ----------")
>  message("foobar/threedots")
>  threedots <- list(...)
>  try(print(threedots))
>  message("foobar/combined args")
>  try(print(c(x, threedots)))
>## --> list gets flattened (i.e. `args_foo.y` instead of nested
>structure)
>  ## --> that's why subsequent functions will not recognize "their"
>arguments
>  ## from it
>  if (any(idx <- names(threedots) %in% "args_foo")) {
>    do.call("foo", c(x = x, threedots$args_foo, threedots[-idx]))
>  } else {
>    foo(x = x, ...)
>  }
>}
>foo <- function(x, y = "some character", ...) {
>  message("foo ----------")
>  message("foo/threedots")
>  threedots <- list(...)
>  try(print(threedots))
>  message("foo/y")
>  try(print(y))
>  if (any(idx <- names(threedots) %in% "args_bar")) {
>    do.call("bar", c(x = x, threedots$args_bar, threedots[-idx]))
>  } else {
>    bar(x = x, ...)
>  }
>}
>bar <- function(x, y = TRUE, ...) {
>  message("bar ----------")
>  message("bar/threedots")
>  try(print(list(...)))
>  message("bar/y")
>  try(print(y))
>  return(paste0("hello: ", x))
>}
>
>foobar(x = "John Doe", args_foo = list(y = "hello world!"))
>foobar(x = "John Doe", args_bar = list(y = FALSE))
>foobar(x = "John Doe",
>       args_foo = list(y = "hello world!"),
>       args_bar = list(y = FALSE)
>)
>
>Best regards and thanks,
>Janko
>
>On Sat, Nov 15, 2014 at 6:10 PM, Duncan Murdoch
><murdoch.duncan at gmail.com>
>wrote:
>
>> On 15/11/2014, 11:26 AM, Jeff Newmiller wrote:
>> > AFAIK You have to alter the name of at least one of the y arguments
>as
>> used by foobar, and anyone calling foobar has to read about that in
>the
>> help file. That is only one y can be in "...". e.g.
>> >
>> > foobar <- function( x, y_foo, ... ) {
>> >   foo( x, y=y_foo, ... )
>> >   bar( x, ... )
>> > }
>> >
>>
>> That's the best solution.  There is another one:  you can put
>>
>> args <- list(...)
>>
>> into foobar(), and then do whatever you like to the args vector, and
>put
>> together calls to foo() and bar() using do.call().  But this is hard
>to
>> read and easy to get wrong, so I recommend Jeff's simple solution.
>>
>> Duncan Murdoch
>>
>> >
>> >
>>
>---------------------------------------------------------------------------
>> > Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>> Go...
>> >                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> > Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> >
>>
>---------------------------------------------------------------------------
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On November 15, 2014 6:49:41 AM PST, Janko Thyson <
>> janko.thyson at gmail.com> wrote:
>> >> Dear list,
>> >>
>> >> I wonder if there's a clever way to fine control the exact way
>> >> arguments
>> >> are dispatched via R's "three dots" argument ....
>> >>
>> >> Consider the following use case:
>> >>
>> >> - you have a function foobar() that calls foo() which in turn
>calls
>> >> bar()
>> >> - *both* foo() and bar() have an argument that's called y, but
>they
>> >> each
>> >>   have a *different meaning*
>> >> - in the call to foobar(), you would like to say "here's the y for
>> >> foo()
>> >> and here's the y for bar()". *That's what I would like to
>accomplish*.
>> >>
>> >> If you simply call foobar(x = "John Doe", y = "hello world"), y
>only
>> >> get's
>> >> dispatched to foo() as in the call to bar() things would have to
>be
>> >> explicit in order to be dispatched (i.e. the call would have to be
>> >> bar(x =
>> >> x, y = y) instead of bar(x = x, ...):
>> >>
>> >> foo <- function(x, y = "some character", ...) {
>> >>  message("foo ----------")
>> >>  message("foo/threedots")
>> >>  try(print(list(...)))
>> >>  message("foo/y")
>> >>  try(print(y))
>> >>  bar(x = x, ...)}
>> >> bar <- function(x, y = TRUE, ...) {
>> >>  message("bar ----------")
>> >>  message("bar/threedots")
>> >>  try(print(list(...)))
>> >>  message("bar/y")
>> >>  try(print(y))
>> >>  return(paste0("hello: ", x))}
>> >> foobar <- function(x, ...) {
>> >>  message("foobar ----------")
>> >>  message("foobar/threedots")
>> >>  try(print(list(...)))
>> >>  foo(x = x, ...)}
>> >>
>> >> foobar(x = "John Doe", y = "hi there")# foobar ----------#
>> >> foobar/threedots# $y# [1] "hi there"# # foo ----------#
>foo/threedots#
>> >> list()# foo/y# [1] "hi there"# bar ----------# bar/threedots#
>list()#
>> >> bar/y# [1] TRUE# [1] "hello: John Doe"
>> >>
>> >> What I conceptionally would like to be able to do is something
>like
>> >> this:
>> >>
>> >> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)
>> >>
>> >> Here's an approach that works but that also feels very odd:
>> >>
>> >> foo <- function(x, y = "some character", ...) {
>> >>  message("foo ----------")
>> >>  message("foo/threedots")
>> >>  try(print(list(...)))
>> >>  message("foo/y")
>> >>  arg <- paste0("y_", sys.call()[[1]])
>> >>  if (arg %in% names(list(...))) {
>> >>    y <- list(...)[[arg]]
>> >>  }
>> >>  try(print(y))
>> >>  bar(x = x, ...)}
>> >> bar <- function(x, y = TRUE, ...) {
>> >>  message("bar ----------")
>> >>  message("bar/threedots")
>> >>  try(print(list(...)))
>> >>  message("bar/y")
>> >>  arg <- paste0("y_", sys.call()[[1]])
>> >>  if (arg %in% names(list(...))) {
>> >>    y <- list(...)[[arg]]
>> >>  }
>> >>  try(print(y))
>> >>  return(paste0("hello: ", x))}
>> >>
>> >> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)#
>foobar
>> >> ----------# foobar/threedots# $y_foo# [1] "hello world!"# #
>$y_bar#
>> >> [1] FALSE# # foo ----------# foo/threedots# $y_foo# [1] "hello
>> >> world!"# # $y_bar# [1] FALSE# # foo/y# [1] "hello world!"# bar
>> >> ----------# bar/threedots# $y_foo# [1] "hello world!"# # $y_bar#
>[1]
>> >> FALSE# # bar/y# [1] FALSE# [1] "hello: John Doe"
>> >>
>> >> How would you go about implementing something like this?
>> >>
>> >> I also played around with S4 method dispatch to see if I could
>define
>> >> methods for a signature argument ..., but that didn't go too well
>(and
>> >> it's
>> >> probably a very bad idea anyway):
>> >>
>> >> setGeneric(
>> >>  name = "foo",
>> >>  signature = c("x", "..."),
>> >>  def = function(x, ...) standardGeneric("foo")      )
>> >> setMethod(
>> >>  f = "foo",
>> >>  signature = signature(x = "character", "..." =
>"MyThreeDotsForBar"),
>> >> definition = function(x, ...) bar(x = x))## --> does not work
>> >>
>> >>      [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>


From mtmorgan at fredhutch.org  Sun Nov 16 20:00:12 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sun, 16 Nov 2014 11:00:12 -0800
Subject: [R] Problem on annotation of Deseq2 on reportingtools
In-Reply-To: <2041049126.5672141416162332341.JavaMail.httpd@webmail-51.iol.local>
References: <2041049126.5672141416162332341.JavaMail.httpd@webmail-51.iol.local>
Message-ID: <5468F43C.10603@fredhutch.org>

On 11/16/2014 10:25 AM, jarod_v6 at libero.it wrote:
> Dear all!,
>
> I use this code:
>
>
> dds <- DESeq(ddHTSeq)
> res <-results(dds)
> #reporting
> library(ReportingTools)
> library("org.Hs.eg.db")
> des2Report <- HTMLReport(shortName ='RNAseq_analysis_DESeq2.html',title ='RNA-seq analysis of differential expression using DESeq2 ',reportDirectory = "./Reports")
> #publish(dds,des2Report,pvalueCutoff=0.05,annotation.db="org,Hs.eg.db")
> publish(dds,des2Report,pvalueCutoff=0.01,annotation.db="org.Hs.egENSEMBL2EG",factor=colData(dds)$condition,categorySize=5)
> finish(des2Report)
>
> and I have this error:
> Error in results(object, resultName) :
>    'contrast', as a character vector of length 3, should have the form:
> contrast = c('factorName','numeratorLevel','denominatorLevel'),
> see the manual page of ?results for more information
>
>
> is.factor(colData(dds)$condition)
> [1] TRUE
>>
> What can I do?
>

Please ask questions about Bioconductor packages on the Bioconductor support site

   https://support.bioconductor.org

Martin
>
>   sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8
>   [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] parallel  stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>   [1] pvclust_1.2-2             gplots_2.13.0             genefilter_1.44.0
>   [4] ReportingTools_2.2.0      knitr_1.6                 org.Hs.eg.db_2.10.1
>   [7] RSQLite_0.11.4            DBI_0.2-7                 annotate_1.40.1
> [10] AnnotationDbi_1.24.0      Biobase_2.22.0            biomaRt_2.18.0
> [13] DESeq2_1.4.5              RcppArmadillo_0.4.300.8.0 Rcpp_0.11.2
> [16] GenomicRanges_1.14.4      XVector_0.2.0             IRanges_1.20.7
> [19] BiocGenerics_0.8.0
>
> loaded via a namespace (and not attached):
>   [1] AnnotationForge_1.4.4    Biostrings_2.30.1        biovizBase_1.10.8
>   [4] bitops_1.0-6             BSgenome_1.30.0          Category_2.28.0
>   [7] caTools_1.17             cluster_1.15.3           colorspace_1.2-4
> [10] dichromat_2.0-0          digest_0.6.4             edgeR_3.4.2
> [13] evaluate_0.5.5           formatR_0.10             Formula_1.1-1
> [16] gdata_2.13.3             geneplotter_1.40.0       GenomicFeatures_1.14.5
> [19] ggbio_1.10.16            ggplot2_1.0.0            GO.db_2.10.1
> [22] GOstats_2.28.0           graph_1.40.1             grid_3.1.1
> [25] gridExtra_0.9.1          GSEABase_1.24.0          gtable_0.1.2
> [28] gtools_3.4.1             Hmisc_3.14-4             hwriter_1.3
> [31] KernSmooth_2.23-13       lattice_0.20-29          latticeExtra_0.6-26
> [34] limma_3.18.13            locfit_1.5-9.1           MASS_7.3-34
> [37] Matrix_1.1-4             munsell_0.4.2            PFAM.db_2.10.1
> [40] plyr_1.8.1               proto_0.3-10             RBGL_1.38.0
> [43] RColorBrewer_1.0-5       RCurl_1.95-4.1           reshape2_1.4
> [46] R.methodsS3_1.6.1        R.oo_1.18.0              Rsamtools_1.14.3
> [49] rtracklayer_1.22.7       R.utils_1.32.4           scales_0.2.4
> [52] splines_3.1.1            stats4_3.1.1             stringr_0.6.2
> [55] survival_2.37-7          tools_3.1.1              VariantAnnotation_1.8.13
> [58] XML_3.98-1.1             xtable_1.7-3             zlibbioc_1.8.0
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From yqzhang at eng.ucsd.edu  Sun Nov 16 19:49:16 2014
From: yqzhang at eng.ucsd.edu (Yunqi Zhang)
Date: Sun, 16 Nov 2014 13:49:16 -0500
Subject: [R] quantreg speed
In-Reply-To: <00364B96-682B-477E-931D-EEDC6EBB09EF@illinois.edu>
References: <CA+56VKJKkOYskFXFtfiou5uRJCRdqpWhYAFWCXMBqr6wY=6bdg@mail.gmail.com>
	<CAF8bMcbjkPb7Q9ph3mioSv4N-OvGOCTYA0dV-UA6-w-VZjcASg@mail.gmail.com>
	<b007ded0a18e4bdab01a4f090d0e7b7e@CITESHT2.ad.uillinois.edu>
	<00364B96-682B-477E-931D-EEDC6EBB09EF@illinois.edu>
Message-ID: <E8B2ACC7-0A3E-4F75-8142-D3EA62B8C06C@eng.ucsd.edu>

Hi Roger,

Thank you for your reply. To my understanding, changing the regression method only helps to speed up the computation, but not necessarily solve the problem with 99th percentile that p-values for all the factors are 1.0. I wonder how I should interpret the result for 99th percentile, while the results for other percentiles seem to work fine.

Correct me if I?m wrong.

Thank you!

Yunqi
On Nov 16, 2014, at 8:42 AM, Roger <rkoenker at illinois.edu> wrote:

> You could try method = "pin".  
> 
> Sent from my iPhone
> 
>> On Nov 16, 2014, at 1:40 AM, Yunqi Zhang <yqzhang at ucsd.edu> wrote:
>> 
>> Hi William,
>> 
>> Thank you very much for your reply.
>> 
>> I did a subsampling to reduce the number of samples to ~1.8 million. It
>> seems to work fine except for 99th percentile (p-values for all the
>> features are 1.0). Does this mean I?m subsampling too much? How should I
>> interpret the result?
>> 
>> tau: [1] 0.25
>> 
>> 
>> 
>> Coefficients:
>> 
>>              Value      Std. Error t value    Pr(>|t|)
>> 
>> (Intercept)      72.15700    0.03651 1976.10513    0.00000
>> 
>> f1            -0.51000    0.04906  -10.39508    0.00000
>> 
>> f2            -20.44200    0.03933 -519.78766    0.00000
>> 
>> f3              -2.37000    0.04871  -48.65117    0.00000
>> 
>> f1:f2       -2.52500    0.05315  -47.50361    0.00000
>> 
>> f1:f3         1.03600    0.06573   15.76193    0.00000
>> 
>> f2:f3          3.41300    0.05247   65.05075    0.00000
>> 
>> f1:f2:f3   -0.83800    0.07120  -11.77002    0.00000
>> 
>> 
>> 
>> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
>> 
>>   f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
>> 
>>   0.75, 0.9, 0.95, 0.99), data = data_stats)
>> 
>> 
>> 
>> tau: [1] 0.5
>> 
>> 
>> 
>> Coefficients:
>> 
>>              Value      Std. Error t value    Pr(>|t|)
>> 
>> (Intercept)      83.80900    0.05626 1489.61222    0.00000
>> 
>> f1            -0.92200    0.07528  -12.24692    0.00000
>> 
>> f2            -27.90700    0.05937 -470.07189    0.00000
>> 
>> f3              -6.45000    0.07204  -89.53909    0.00000
>> 
>> f1:f2       -2.66500    0.07933  -33.59275    0.00000
>> 
>> f1:f3         1.99000    0.09869   20.16440    0.00000
>> 
>> f2:f3          7.09600    0.07611   93.23813    0.00000
>> 
>> f1:f2:f3   -1.71200    0.10390  -16.47660    0.00000
>> 
>> 
>> 
>> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
>> 
>>   f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
>> 
>>   0.75, 0.9, 0.95, 0.99), data = data_stats)
>> 
>> 
>> 
>> tau: [1] 0.75
>> 
>> 
>> 
>> Coefficients:
>> 
>>              Value      Std. Error t value    Pr(>|t|)
>> 
>> (Intercept)     102.71700    0.10175 1009.45946    0.00000
>> 
>> f1            -1.59300    0.13241  -12.03125    0.00000
>> 
>> f2            -40.64200    0.10623 -382.58456    0.00000
>> 
>> f3             -14.40900    0.12096 -119.11988    0.00000
>> 
>> f1:f2       -2.97600    0.13867  -21.46071    0.00000
>> 
>> f1:f3         3.74600    0.16335   22.93165    0.00000
>> 
>> f2:f3         14.14800    0.12692  111.47217    0.00000
>> 
>> f1:f2:f3   -3.16400    0.17159  -18.43899    0.00000
>> 
>> 
>> 
>> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
>> 
>>   f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
>> 
>>   0.75, 0.9, 0.95, 0.99), data = data_stats)
>> 
>> 
>> 
>> tau: [1] 0.9
>> 
>> 
>> 
>> Coefficients:
>> 
>>              Value      Std. Error t value    Pr(>|t|)
>> 
>> (Intercept)     130.89400    0.20609  635.12464    0.00000
>> 
>> f1            -2.55500    0.28139   -9.07995    0.00000
>> 
>> f2            -60.90500    0.21322 -285.64558    0.00000
>> 
>> f3             -29.42300    0.23409 -125.69092    0.00000
>> 
>> f1:f2       -2.77700    0.29052   -9.55870    0.00000
>> 
>> f1:f3         7.89700    0.33308   23.70870    0.00000
>> 
>> f2:f3         27.78100    0.24338  114.14722    0.00000
>> 
>> f1:f2:f3   -6.95800    0.34491  -20.17327    0.00000
>> 
>> 
>> 
>> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
>> 
>>   f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
>> 
>>   0.75, 0.9, 0.95, 0.99), data = data_stats)
>> 
>> 
>> 
>> tau: [1] 0.95
>> 
>> 
>> 
>> Coefficients:
>> 
>>              Value      Std. Error t value    Pr(>|t|)
>> 
>> (Intercept)     157.45900    0.42733  368.47413    0.00000
>> 
>> f1            -4.10200    0.55834   -7.34678    0.00000
>> 
>> f2            -81.24000    0.44012 -184.58697    0.00000
>> 
>> f3             -46.17500    0.46235  -99.87033    0.00000
>> 
>> f1:f2       -2.01700    0.57651   -3.49866    0.00047
>> 
>> f1:f3        15.67000    0.67409   23.24600    0.00000
>> 
>> f2:f3         43.00100    0.47973   89.63500    0.00000
>> 
>> f1:f2:f3  -14.05100    0.69737  -20.14843    0.00000
>> 
>> 
>> 
>> Call: rq(formula = output ~ f1 + f2 + f3 + f1 * f2 + f1 *
>> 
>>   f3 + f2 * f3 + f1 * f2 * f3, tau = c(0.25, 0.5,
>> 
>>   0.75, 0.9, 0.95, 0.99), data = data_stats)
>> 
>> 
>> 
>> tau: [1] 0.99
>> 
>> 
>> 
>> Coefficients:
>> 
>>              Value         Std. Error    t value       Pr(>|t|)
>> 
>> (Intercept)     2.544860e+02  3.878303e+07  1.000000e-05  9.999900e-01
>> 
>> f1          -1.420000e+01  5.917548e+11  0.000000e+00  1.000000e+00
>> 
>> f2           -1.582920e+02  3.450261e+07  0.000000e+00  1.000000e+00
>> 
>> f3            -1.139210e+02  4.763057e+07  0.000000e+00  1.000000e+00
>> 
>> f1:f2      5.725000e+00  1.324283e+12  0.000000e+00  1.000000e+00
>> 
>> f1:f3       6.811780e+02  1.153645e+13  0.000000e+00  1.000000e+00
>> 
>> f2:f3        1.042510e+02  2.299953e+24  0.000000e+00  1.000000e+00
>> 
>> f1:f2:f3 -6.763210e+02  2.299953e+24  0.000000e+00  1.000000e+00
>> 
>> Warning message:
>> 
>> In summary.rq(xi, ...) : 288000 non-positive fis
>> 
>>> On Sat, Nov 15, 2014 at 8:19 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> 
>>> You can time it yourself on increasingly large subsets of your data.  E.g.,
>>> 
>>>> dat <- data.frame(x1=rnorm(1e6), x2=rnorm(1e6),
>>> x3=sample(c("A","B","C"),size=1e6,replace=TRUE))
>>>> dat$y <- with(dat, x1 + 2*(x3=="B")*x2 + rnorm(1e6))
>>>> t <- vapply(n<-4^(3:10),FUN=function(n){d<-dat[seq_len(n),];
>>> print(system.time(rq(data=d, y ~ x1 + x2*x3,
>>> tau=0.9)))},FUN.VALUE=numeric(5))
>>>  user  system elapsed
>>>     0       0       0
>>>  user  system elapsed
>>>     0       0       0
>>>  user  system elapsed
>>>  0.02    0.00    0.01
>>>  user  system elapsed
>>>  0.01    0.00    0.02
>>>  user  system elapsed
>>>  0.10    0.00    0.11
>>>  user  system elapsed
>>>  1.09    0.00    1.10
>>>  user  system elapsed
>>> 13.05    0.02   13.07
>>>  user  system elapsed
>>> 273.30    0.11  273.74
>>>> t
>>>          [,1] [,2] [,3] [,4] [,5] [,6]  [,7]   [,8]
>>> user.self     0    0 0.02 0.01 0.10 1.09 13.05 273.30
>>> sys.self      0    0 0.00 0.00 0.00 0.00  0.02   0.11
>>> elapsed       0    0 0.01 0.02 0.11 1.10 13.07 273.74
>>> user.child   NA   NA   NA   NA   NA   NA    NA     NA
>>> sys.child    NA   NA   NA   NA   NA   NA    NA     NA
>>> 
>>> Do some regressions on t["elapsed",] as a function of n and predict up to
>>> n=10^7.  E.g.,
>>>> summary(lm(t["elapsed",] ~ poly(n,4)))
>>> 
>>> Call:
>>> lm(formula = t["elapsed", ] ~ poly(n, 4))
>>> 
>>> Residuals:
>>>        1          2          3          4          5          6
>>> 7          8
>>> -2.375e-03 -2.970e-03  4.484e-03  1.674e-03 -8.723e-04  6.096e-05
>>> -9.199e-07  2.715e-09
>>> 
>>> Coefficients:
>>>            Estimate Std. Error  t value Pr(>|t|)
>>> (Intercept) 3.601e+01  1.261e-03 28564.33 9.46e-14 ***
>>> poly(n, 4)1 2.493e+02  3.565e-03 69917.04 6.45e-15 ***
>>> poly(n, 4)2 5.093e+01  3.565e-03 14284.61 7.57e-13 ***
>>> poly(n, 4)3 1.158e+00  3.565e-03   324.83 6.43e-08 ***
>>> poly(n, 4)4 4.392e-02  3.565e-03    12.32  0.00115 **
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Residual standard error: 0.003565 on 3 degrees of freedom
>>> Multiple R-squared:      1,     Adjusted R-squared:      1
>>> F-statistic: 1.273e+09 on 4 and 3 DF,  p-value: 3.575e-14
>>> 
>>> 
>>> It does not look good for n=10^7.
>>> 
>>> 
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>>> On Sat, Nov 15, 2014 at 12:12 PM, Yunqi Zhang <yqzhang at ucsd.edu> wrote:
>>>> 
>>>> Hi all,
>>>> 
>>>> I'm using quantreg rq() to perform quantile regression on a large data
>>>> set.
>>>> Each record has 4 fields and there are about 18 million records in total.
>>>> I
>>>> wonder if anyone has tried rq() on a large dataset and how long I should
>>>> expect it to finish. Or it is simply too large and I should subsample the
>>>> data. I would like to have an idea before I start to run and wait forever.
>>>> 
>>>> In addition, I will appreciate if anyone could give me an idea how long it
>>>> takes for rq() to run approximately for certain dataset size.
>>>> 
>>>> Yunqi
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>   [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rdsfield at gmail.com  Sun Nov 16 19:56:37 2014
From: rdsfield at gmail.com (Rachel Field)
Date: Sun, 16 Nov 2014 11:56:37 -0700
Subject: [R] package unmarked: distsamp vs gdistsamp vs pcount vs gpcount
Message-ID: <CA+n-Sxps5BOhRtNDatd4erdGroHewCZGDRyHCwsRogS6=K2VYA@mail.gmail.com>

Hello All,

I have been struggling with the following analysis in package 'unmarked':

I conducted repeated 10 min point counts over one season. I have 50 sites
(100 m radius) replicated over 3 surveys, and each individual observation
(n = 1108) is recorded at discrete distance intervals (i.e., the number of
observations for each site during each survey is not always equal). Habitat
variables were measured once for each site (n = 50), and detection
covariates were measured for each site on each survey (n = 150).

I wish to test the effect(s) of various habitat metrics on songbird
abundance/density, to include detection covariate(s) in my models, and to
account for repeated measures in my design. I think that 'distsamp' is most
appropriate for this, but am not sure (especially when it comes to how to
deal with repeated measures).

I have followed Chandler's 'Distance sampling analysis in unmarked (2011)'
and everything seems to work until I add detection covariates (using
distsamp; prior to adding abundance/density habitat predictors), when
running my models produce the warning: "*In lambda * A : longer object
length is not a multiple of shorter object length*".

(a) Am I using the appropriate fitting function (i.e., distsamp vs.
gdistsamp vs. pcount vs. ???)
(b) Why am I getting this warning message?

Here is my code:

dists <-read.csv("file/path.csv")

#sub-set of variables (to be used as detection covariates)
jdate<-(dists$day.julian)
daytime<-(dists$time.hour.num)

head(dists, 1108)

#'point' contains character+numerical site names (e.g., 'sweco03')
levels(dists$point) <- c(levels(dists$point), "sweco03")
levels(dists$point)

#individual observations were recorded at 10 m distance intervals to 100 m
umf <-unmarkedFrameDS(y = as.matrix(yDat), survey = "point", dist.breaks =
  c(0,10,20,30,40,50,60,70,80,90,100), unitsIn = "m")
summary(umf)

#to determine the best detection function
`hn_Null <- distsamp (~1 ~1, umf, keyfun = "halfnorm", output = "density",
unitsOut = "ha")
haz_Null <-distsamp (~1 ~1, umf, keyfun = "hazard")                #lowest
AIC
uni_Null <- distsamp (~1 ~1, umf, keyfun = "uniform")
exp_Null <- distsamp (~1 ~1, umf, keyfun = "exp") `

#to test the fit of detection covariates
model1 <-distsamp (~1 ~jdate, umf, keyfun = "hazard")
model2 <-distsamp (~1 ~daytime, umf, keyfun = "hazard")

#etc... When I attempt to run these models, I get the warning message.

Thank-you in advance,
Rachel

	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Sun Nov 16 21:58:35 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 16 Nov 2014 20:58:35 +0000 (UTC)
Subject: [R] Display two polygons in same map axes R
Message-ID: <1783220081.1180761.1416171515375.JavaMail.yahoo@jws10610.mail.bf1.yahoo.com>

Hello,
I have two spatial map objects (reproducible example further down) which I would like to overlay in R. The ESRI shapefiles were read using:

library(rgdal)
Prairie.Boundaries <-  readOGR(".", "boundaries") 
watersheds<-readOGR(".","watersheds")

The two objects have same projection:
print(proj4string(watersheds)) 
[1] "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"

print(proj4string(Prairie.Boundaries)) 
[1] "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"

However, the spatial limits are different:
summary(watersheds) 
Object of class SpatialPolygonsDataFrame 
Coordinates: 
min       max 
x -127.73835 -88.98395 
y   45.44628  61.38249 
Is projected: FALSE 
proj4string : 
[+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0]


summary(Prairie.Boundaries) 
Object of class SpatialPolygonsDataFrame 
Coordinates: 
min       max 
x -120.00138 -88.99081 
y   48.99668  60.00042 
Is projected: FALSE 
proj4string : 
[+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0]

Problem:
How can I overlay "watersheds" on "Prairie.Boundaries"?

For example:

plot(Prairie.Boundaries, axes=TRUE, border="black")
plot(watersheds,border="gray8",col="white",axes=TRUE)

I tried to extend the ylim and xlim of "Prairie.Boundaries" to match those of "watersheds" but could not display the shapefiles on same plot.

Please help.
Thanks, Asong.

#------------------------------------------------------------------------------------------------------------------------

dput(watersheds) 
new("SpatialPolygonsDataFrame" 
, data = structure(list(SUB_PF = structure(c(1L, 12L, 23L, 34L, 43L, 44L, 
45L, 46L, 47L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L, 32L, 33L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 
42L), .Label = c("1", "10", "11", "12", "13", "14", "15", "16", 
"17", "18", "19", "2", "20", "21", "22", "23", "24", "25", "26", 
"27", "28", "29", "3", "30", "31", "32", "33", "34", "35", "36", 
"37", "38", "39", "4", "40", "41", "42", "43", "44", "45", "46", 
"47", "5", "6", "7", "8", "9"), class = "factor")), .Names = "SUB_PF", row.names = 0:46, class = "data.frame") 
, polygons = list(<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>) 
, plotOrder = c(29L, 9L, 2L, 47L, 35L, 16L, 21L, 25L, 26L, 40L, 38L, 37L, 17L, 
15L, 42L, 34L, 32L, 45L, 22L, 43L, 1L, 3L, 30L, 20L, 28L, 19L, 
7L, 24L, 18L, 8L, 5L, 27L, 12L, 41L, 13L, 33L, 11L, 31L, 6L, 
23L, 46L, 10L, 14L, 39L, 44L, 36L, 4L) 
, bbox = structure(c(-127.738346938252, 45.4462802950586, -88.9839497612937, 
61.3824920693942), .Dim = c(2L, 2L), .Dimnames = list(c("x", 
"y"), c("min", "max"))) 
, proj4string = new("CRS" 
, projargs = "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0" 
) 
)

#-------------------------------------------------------------------------------------------------
dput(Prairie.Boundaries) 
new("SpatialPolygonsDataFrame" 
, data = structure(list(UUID = structure(c(2L, 3L, 1L), .Label = c("37", 
"496", "79"), class = "factor"), TYPE_E = structure(c(1L, 1L, 
1L), .Label = "PROV", class = "factor"), NAME = structure(c(2L, 
3L, 1L), .Label = c("ALBERTA", "MANITOBA", "SASKATCHEWAN"), class = "factor"), 
SRC_AGENCY = structure(c(1L, 1L, 1L), .Label = "NRCAN", class = "factor"), 
L_UPD_DATE = structure(c(1L, 1L, 2L), .Label = c("2007/05/17", 
"2011/04/15"), class = "factor"), L_UPD_TYPE = structure(c(1L, 
1L, 1L), .Label = "G", class = "factor"), P_UPD_DATE = structure(c(1L, 
1L, 1L), .Label = "2004/06/03", class = "factor")), .Names = c("UUID", 
"TYPE_E", "NAME", "SRC_AGENCY", "L_UPD_DATE", "L_UPD_TYPE", "P_UPD_DATE" 
), row.names = 0:2, class = "data.frame") 
, polygons = list(<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>) 
, plotOrder = c(3L, 1L, 2L) 
, bbox = structure(c(-120.001383519, 48.99667665, -88.990814136, 60.000421584 
), .Dim = c(2L, 2L), .Dimnames = list(c("x", "y"), c("min", "max" 
))) 
, proj4string = new("CRS" 
, projargs = "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0" 
) 
)#------------------------------------------------------------------------------------------------------


From janko.thyson at gmail.com  Mon Nov 17 01:25:34 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Mon, 17 Nov 2014 01:25:34 +0100
Subject: [R] Fine controlling "three dots" argument dispatch to
 functions with identical argument names
In-Reply-To: <32152484-1B61-414C-8A9C-C14B4184355B@dcn.davis.CA.us>
References: <CAGmpuegNtZFAqCUZbQKscwOhKu+RibtgCRmS--39M4G4+tzjog@mail.gmail.com>
	<335D892B-BDE7-4D1D-A77A-6796889201F6@dcn.davis.CA.us>
	<546788F2.4040802@gmail.com>
	<CAGmpuejeu3=2qsqvqcwscHNgVX9icd_GStdPaLLTJF6+ZMx-_w@mail.gmail.com>
	<32152484-1B61-414C-8A9C-C14B4184355B@dcn.davis.CA.us>
Message-ID: <CAGmpuehLiwjYfd1f=GRBG6qwxWsxLfsk7mzh6bjR8E88OyGXiQ@mail.gmail.com>

@Duncan, @Jeff: thanks for giving me your opinions, I really appreciate
that! I'm not saying that this is something that should *generally* be used
and I perfectly understand your concerns. However: correct me if I'm wrong,
but actually I'm not doing much more than generalizing the idea behind
`...` from the case where only *one *more function is called further down
the calling stack to the the general case where *n* more functions get
called.

*@Duncan*:  consider the `plot()` function: following your argumentation,
you would also want to see all of the paramters controlled via `par()` as
explicit paramters of `plot()` - if I understand you correctly. Of course
I'm exagerating to get my point accross and I do see your point. I think
the guys behind `roygen` have put it quite perfectly (
http://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html):
*Do repeat yourself*

*There is a tension between the DRY (do not repeat yourself) principle of
programming and the need for documentation to be self-contained. It's
frustrating to have to navigate through multiple help files in order to
pull together all the pieces you need. *

But I think it's a *trade-off* that needs to be decided on on a
*case-by-case* basis. For example, IMO for `plot()` and other functions
using `par()` it makes perfect sense to use `...` quite extensively: while
users might very well argue that they would prefer to see all the args
`plot()` can take in its help file I'm sure that developers/maintainers of
all the functions depending on `par()` would see that from quite a
different perspective. It would take quite some effort to propagate changes
in `par()` to all dependent functions.

As foryour question about how to document it: I don't see why that should
be a problem (see roxygen code below for `foobar()`). You can link to the
help pages of functions across packages just as is the case in for `plot()`
with respect to `par()`. The same documentation structure could also be
used for `foo()` and `bar()`.
*@Jeff*: well, if the mechanism is well documented, I don't see what you
are really loosing by wrapping things to a list first instead of passing
them directly as `...`: the only crucial part is that in a call to a
specific function, a dispatching mechanism would need to make sure that the
correct list is selected - or to be more precise that everything that came
via `...` is split up in a part that's used as explicit arguments for the
actual function call and a part that is passed along as the new/updated
`...` to subsequent functions.

>From there on, from the perspective of the function being called, it's just
as if `y` had been passed as such from the beginning (instead of via list
construct `args_<func>$y`).

As for the concern that functions would be tied to a certain
implementation: sure, that's true - but if you wrap everything in something
like `withThreedots()`, it's actually not much different (structure-wise)
from a call to `sapply()` and the like. What would really be neat is if one
could definde S4 methods for `...` and have the built-in dispatcher do the
job that `withThreedots()` currently does. Instead of a list
`args_<function>` one would use class instances along the line of
`Threedots$new(<args-list>, <function-name>)`.

Best regards and thanks for your opinions again!

Here's the `withThreedots()` implementation

*Definitions //*

withThreedots <- function(fun, ...) {
  threedots <- list(...)
  idx <- which(names(threedots) %in% sprintf("args_%s", fun))
  eval(substitute(
    do.call(FUN, c(THREE_THIS, THREE_REST)),
    list(
      FUN = as.name(fun),
      THREE_THIS = if (length(idx)) threedots[[idx]],
      THREE_REST = if (length(idx)) threedots[-idx] else threedots
    )
  ))
}

#' @title
#' Does something foobar
#'
#' @description
#' Calls \code{\link[foo.package]{foo}}.
#'
#' @section Argument dispatch via ...:
#'
#' Calling subsequent functions is handled by function
#' \code{\link{withThreedots}}. In order for it to dispatch the correct
#' arguments to the various functions further down the calling stack,
#' you need to wrap them in a individual lists and name them according to
#' the following convention: \code{args_<function-name>}.
#'
#' For example, arguments that should be passed to
#' \code{\link[foo.package]{foo} would need to be stated as follows:
#' \code{args_foo = list(y = "hello world!")}. The same goes for arguments
#' that \code{\link[foo.package]{foo} passes to its subsequent functions.
#'
#' @param x \code{\link{character}}. Some argument.
#' @param ... Further arguments to be passed to subsequent functions.
#'    In particular:
#'    \itemize{
#'      \item{\code{\link[foo.package]{foo}}. Make sure to also check if
#'        this function in turn can pass along arguments via \code{...}.
#'        In this case, you can also include those arguments.}
#'    }
#'    See section \strong{Argument dispatch via ...} for details about the
#'    expected object structure of things to pass via \code{...}.
#' @example inst/examples/existsNested.r
#' @seealso \code{\link[foo.package]{foo}}
#' @export
foobar <- function(x, ...) {
  withThreedots("foo", x = x, ...)
}

foo <- function(x = x, y = "some text", ...) {
  message("foo/y")
  print(y)
  withThreedots("bar", x = x, ...)
}
bar <- function(x = x, y = 1, ...) {
  message("bar/y")
  print(y)
  withThreedots("downTheLine", x = x, ...)
}
downTheLine <- function(x = x, y = list(), ...) {
  message("downTheLine/y")
  print(y)
}

*Apply  //*

foobar(x = 10)
foobar(x = 10, args_foo = list(y = "hello world!"))
foobar(x = 10, args_bar = list(y = 10))
foobar(x = 10, args_downTheLine = list(y = list(a = TRUE)))

foobar(x = 10,
       args_foo = list(y = "hello world!"),
       args_bar = list(y = 10),
       args_downTheLine = list(y = list(a = TRUE))
)

On Sun, Nov 16, 2014 at 7:54 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You have some interesting ideas about what makes for improvements in
> parameter interfaces. Wrapping the arguments into a list is like creating
> an object to represent all of them, except that you don't have the benefits
> of a class to go with that cognitive shift. And if making classes to hold
> parameters were appropriate wouldn't you have already done so in the foo
> and bar interfaces? That is a heavyweight approach that doesn't always make
> sense.
>
> I agree with Duncan that each time you define a function you are defining
> an interface that should stand on its own... the user should be able to
> associate unique names with unique behaviors. From this perspective, your
> reluctance to define a unified set of uniquely-named parameters for each of
> foobar and (and apparently foo) seems illogical.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 16, 2014 8:42:20 AM PST, Janko Thyson <janko.thyson at gmail.com>
> wrote:
> >Thanks for the info/suggestions!
> >
> >But note that it's not just a one-step, but a two step dispatching
> >process
> >with respect to `...`. That is, `foo()` and `bar()` are *not* both
> >called
> >directly inside `foobar()`: `foobar()` only calls `foo()` which then
> >calls
> >`bar()`.
> >
> >I now came up with something along the lines of what Duncan suggested.
> >The
> >reason I wouldn't want to go with Jeff's approach is that I would want
> >`foobar()` to remain as generic an interface as possible (the same goes
> >for
> >`foo()` calling `bar()`).
> >
> >I.e., I don't want it to have any explicit arguments of subsequently
> >called
> >functions (e.g. `y_foo`). It should just be able to take any inputs
> >that
> >subsequently called functions can process (i.e. `foo()` and then in
> >turn
> >`bar()`) and pass them along accordingly. Of course this would need to
> >be
> >clearly and well documented for the respective functions.
> >
> >So here's my current approach. It would be nice to just be able to
> >dispatch
> >`...` for calls of `do.call()` like so: `do.call("foo", c(x = x, ...))`
> >but
> >that way a nested structure of `...` gets flattened out (see respective
> >lines in `foobar()`). That's why I need to resort to `do.call("foo",
> >c(x =
> >x, threedots$args_foo, threedots[-idx]))`. What do you think of it?
> >
> >foobar <- function(x, ...) {
> >  message("foobar ----------")
> >  message("foobar/threedots")
> >  threedots <- list(...)
> >  try(print(threedots))
> >  message("foobar/combined args")
> >  try(print(c(x, threedots)))
> >## --> list gets flattened (i.e. `args_foo.y` instead of nested
> >structure)
> >  ## --> that's why subsequent functions will not recognize "their"
> >arguments
> >  ## from it
> >  if (any(idx <- names(threedots) %in% "args_foo")) {
> >    do.call("foo", c(x = x, threedots$args_foo, threedots[-idx]))
> >  } else {
> >    foo(x = x, ...)
> >  }
> >}
> >foo <- function(x, y = "some character", ...) {
> >  message("foo ----------")
> >  message("foo/threedots")
> >  threedots <- list(...)
> >  try(print(threedots))
> >  message("foo/y")
> >  try(print(y))
> >  if (any(idx <- names(threedots) %in% "args_bar")) {
> >    do.call("bar", c(x = x, threedots$args_bar, threedots[-idx]))
> >  } else {
> >    bar(x = x, ...)
> >  }
> >}
> >bar <- function(x, y = TRUE, ...) {
> >  message("bar ----------")
> >  message("bar/threedots")
> >  try(print(list(...)))
> >  message("bar/y")
> >  try(print(y))
> >  return(paste0("hello: ", x))
> >}
> >
> >foobar(x = "John Doe", args_foo = list(y = "hello world!"))
> >foobar(x = "John Doe", args_bar = list(y = FALSE))
> >foobar(x = "John Doe",
> >       args_foo = list(y = "hello world!"),
> >       args_bar = list(y = FALSE)
> >)
> >
> >Best regards and thanks,
> >Janko
> >
> >On Sat, Nov 15, 2014 at 6:10 PM, Duncan Murdoch
> ><murdoch.duncan at gmail.com>
> >wrote:
> >
> >> On 15/11/2014, 11:26 AM, Jeff Newmiller wrote:
> >> > AFAIK You have to alter the name of at least one of the y arguments
> >as
> >> used by foobar, and anyone calling foobar has to read about that in
> >the
> >> help file. That is only one y can be in "...". e.g.
> >> >
> >> > foobar <- function( x, y_foo, ... ) {
> >> >   foo( x, y=y_foo, ... )
> >> >   bar( x, ... )
> >> > }
> >> >
> >>
> >> That's the best solution.  There is another one:  you can put
> >>
> >> args <- list(...)
> >>
> >> into foobar(), and then do whatever you like to the args vector, and
> >put
> >> together calls to foo() and bar() using do.call().  But this is hard
> >to
> >> read and easy to get wrong, so I recommend Jeff's simple solution.
> >>
> >> Duncan Murdoch
> >>
> >> >
> >> >
> >>
>
> >---------------------------------------------------------------------------
> >> > Jeff Newmiller                        The     .....       .....  Go
> >> Live...
> >> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.
> >Live
> >> Go...
> >> >                                       Live:   OO#.. Dead: OO#..
> >Playing
> >> > Research Engineer (Solar/Batteries            O.O#.       #.O#.
> >with
> >> > /Software/Embedded Controllers)               .OO#.       .OO#.
> >> rocks...1k
> >> >
> >>
>
> >---------------------------------------------------------------------------
> >> > Sent from my phone. Please excuse my brevity.
> >> >
> >> > On November 15, 2014 6:49:41 AM PST, Janko Thyson <
> >> janko.thyson at gmail.com> wrote:
> >> >> Dear list,
> >> >>
> >> >> I wonder if there's a clever way to fine control the exact way
> >> >> arguments
> >> >> are dispatched via R's "three dots" argument ....
> >> >>
> >> >> Consider the following use case:
> >> >>
> >> >> - you have a function foobar() that calls foo() which in turn
> >calls
> >> >> bar()
> >> >> - *both* foo() and bar() have an argument that's called y, but
> >they
> >> >> each
> >> >>   have a *different meaning*
> >> >> - in the call to foobar(), you would like to say "here's the y for
> >> >> foo()
> >> >> and here's the y for bar()". *That's what I would like to
> >accomplish*.
> >> >>
> >> >> If you simply call foobar(x = "John Doe", y = "hello world"), y
> >only
> >> >> get's
> >> >> dispatched to foo() as in the call to bar() things would have to
> >be
> >> >> explicit in order to be dispatched (i.e. the call would have to be
> >> >> bar(x =
> >> >> x, y = y) instead of bar(x = x, ...):
> >> >>
> >> >> foo <- function(x, y = "some character", ...) {
> >> >>  message("foo ----------")
> >> >>  message("foo/threedots")
> >> >>  try(print(list(...)))
> >> >>  message("foo/y")
> >> >>  try(print(y))
> >> >>  bar(x = x, ...)}
> >> >> bar <- function(x, y = TRUE, ...) {
> >> >>  message("bar ----------")
> >> >>  message("bar/threedots")
> >> >>  try(print(list(...)))
> >> >>  message("bar/y")
> >> >>  try(print(y))
> >> >>  return(paste0("hello: ", x))}
> >> >> foobar <- function(x, ...) {
> >> >>  message("foobar ----------")
> >> >>  message("foobar/threedots")
> >> >>  try(print(list(...)))
> >> >>  foo(x = x, ...)}
> >> >>
> >> >> foobar(x = "John Doe", y = "hi there")# foobar ----------#
> >> >> foobar/threedots# $y# [1] "hi there"# # foo ----------#
> >foo/threedots#
> >> >> list()# foo/y# [1] "hi there"# bar ----------# bar/threedots#
> >list()#
> >> >> bar/y# [1] TRUE# [1] "hello: John Doe"
> >> >>
> >> >> What I conceptionally would like to be able to do is something
> >like
> >> >> this:
> >> >>
> >> >> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)
> >> >>
> >> >> Here's an approach that works but that also feels very odd:
> >> >>
> >> >> foo <- function(x, y = "some character", ...) {
> >> >>  message("foo ----------")
> >> >>  message("foo/threedots")
> >> >>  try(print(list(...)))
> >> >>  message("foo/y")
> >> >>  arg <- paste0("y_", sys.call()[[1]])
> >> >>  if (arg %in% names(list(...))) {
> >> >>    y <- list(...)[[arg]]
> >> >>  }
> >> >>  try(print(y))
> >> >>  bar(x = x, ...)}
> >> >> bar <- function(x, y = TRUE, ...) {
> >> >>  message("bar ----------")
> >> >>  message("bar/threedots")
> >> >>  try(print(list(...)))
> >> >>  message("bar/y")
> >> >>  arg <- paste0("y_", sys.call()[[1]])
> >> >>  if (arg %in% names(list(...))) {
> >> >>    y <- list(...)[[arg]]
> >> >>  }
> >> >>  try(print(y))
> >> >>  return(paste0("hello: ", x))}
> >> >>
> >> >> foobar(x = "John Doe", y_foo = "hello world!", y_bar = FALSE)#
> >foobar
> >> >> ----------# foobar/threedots# $y_foo# [1] "hello world!"# #
> >$y_bar#
> >> >> [1] FALSE# # foo ----------# foo/threedots# $y_foo# [1] "hello
> >> >> world!"# # $y_bar# [1] FALSE# # foo/y# [1] "hello world!"# bar
> >> >> ----------# bar/threedots# $y_foo# [1] "hello world!"# # $y_bar#
> >[1]
> >> >> FALSE# # bar/y# [1] FALSE# [1] "hello: John Doe"
> >> >>
> >> >> How would you go about implementing something like this?
> >> >>
> >> >> I also played around with S4 method dispatch to see if I could
> >define
> >> >> methods for a signature argument ..., but that didn't go too well
> >(and
> >> >> it's
> >> >> probably a very bad idea anyway):
> >> >>
> >> >> setGeneric(
> >> >>  name = "foo",
> >> >>  signature = c("x", "..."),
> >> >>  def = function(x, ...) standardGeneric("foo")      )
> >> >> setMethod(
> >> >>  f = "foo",
> >> >>  signature = signature(x = "character", "..." =
> >"MyThreeDotsForBar"),
> >> >> definition = function(x, ...) bar(x = x))## --> does not work
> >> >>
> >> >>      [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >>
>
>

	[[alternative HTML version deleted]]


From wizardchef at gmail.com  Mon Nov 17 02:54:41 2014
From: wizardchef at gmail.com (Ernie Stokely)
Date: Sun, 16 Nov 2014 19:54:41 -0600
Subject: [R] Newbie question: ROC function in TTR package
Message-ID: <54695561.2010701@gmail.com>

One of the great frustrations for a newbie to R is the documentation 
uses the same syntax in its description as the items it is trying to 
describe, a general no-no when giving language definitions. Why does the 
documentation not include the equation being represented by the 
function, thereby clarifying what the function is doing??

That gripe aside, can anyone explain to me what the rate of change (ROC) 
function in the TTR package is doing? I have run it on a set of returns 
and I cannot reverse engineer what it is calculating. Also, what is the 
difference between the discrete and the continuous types?? Thanks.

wizardchef


From dwinsemius at comcast.net  Mon Nov 17 03:15:24 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Nov 2014 18:15:24 -0800
Subject: [R] Newbie question: ROC function in TTR package
In-Reply-To: <54695561.2010701@gmail.com>
References: <54695561.2010701@gmail.com>
Message-ID: <6CA675ED-BBC2-4CCD-BCD7-297E30729F28@comcast.net>


On Nov 16, 2014, at 5:54 PM, Ernie Stokely wrote:

> One of the great frustrations for a newbie to R is the documentation uses the same syntax in its description as the items it is trying to describe, a general no-no when giving language definitions. Why does the documentation not include the equation being represented by the function, thereby clarifying what the function is doing??
> 

If you have issues with the documentation of non-recommended packages, you should address them to the maintainer. There is a maintainer function:

> maintainer("TTR")
[1] "Joshua Ulrich <josh.m.ulrich at gmail.com>"


> That gripe aside, can anyone explain to me what the rate of change (ROC) function in the TTR package is doing? I have run it on a set of returns and I cannot reverse engineer what it is calculating. Also, what is the difference between the discrete and the continuous types?? Thanks.

It's rather simple to look at the code. Just type:

TTR::ROC

> wizardchef

Reading the code is considered an important first step in answering such questions.

-- 

David Winsemius
Alameda, CA, USA


From josh.m.ulrich at gmail.com  Mon Nov 17 03:26:58 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 16 Nov 2014 20:26:58 -0600
Subject: [R] Newbie question: ROC function in TTR package
In-Reply-To: <54695561.2010701@gmail.com>
References: <54695561.2010701@gmail.com>
Message-ID: <CAPPM_gSdtU4WAsLjBePZAT8F3bik=nHRnmOb4MTdZjS9mKtxJQ@mail.gmail.com>

On Nov 16, 2014 8:10 PM, "Ernie Stokely" <wizardchef at gmail.com> wrote:
>
> One of the great frustrations for a newbie to R is the documentation uses
the same syntax in its description as the items it is trying to describe, a
general no-no when giving language definitions. Why does the documentation
not include the equation being represented by the function, thereby
clarifying what the function is doing??
>
A great frustration for those who took time to attempt to provide useful
documentation is when people criticize it instead of providing patches to
improve it.  The documentation is often written by the authors of the code
and it's extremely difficult to view it through the eyes of a neophyte when
it's something you know so intimately.

> That gripe aside, can anyone explain to me what the rate of change (ROC)
function in the TTR package is doing? I have run it on a set of returns and
I cannot reverse engineer what it is calculating. Also, what is the
difference between the discrete and the continuous types?? Thanks.
>
It's calculating log first differences, or continuously compounded returns.
The discrete type is p(t)/p(t-1)-1.  You also have the source code and
could have referenced it in your attempt to reverse engineer the
calculations.

> wizardchef
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Mon Nov 17 03:31:25 2014
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 16 Nov 2014 21:31:25 -0500
Subject: [R] Removing rows in a data frame containing string in rownames
In-Reply-To: <7.1.0.9.2.20141029115750.050c3948@gmail.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<54510abb.46dfec0a.3c7b.70ed@mx.google.com>
	<54510D5A.60800@utoronto.ca>
	<7.1.0.9.2.20141029115750.050c3948@gmail.com>
Message-ID: <54695e00.8807ec0a.2299.ffffeaa1@mx.google.com>

I like to remove from a data frame rows with labels containing 
certain string, e.g., "sex" and "rating". Below is a list of the data 
frame and my failed attempt to the rows. Any clues? Thanks.

 > out
                  est     se     t     p disc
p.(Intercept) 26.430 13.605 1.943 0.053
p.sex          3.502  3.930 0.891 0.373 *
p.children     3.693  4.521 0.817 0.414 *
p.occu         0.740  1.116 0.663 0.508
p.rating      -7.897  1.331 5.933 0.000
c.(Intercept)  1.861  0.965 1.929 0.054
c.sex          0.221  0.249 0.889 0.374 *
c.children     0.234  0.289 0.810 0.418 *
c.occu         0.052  0.079 0.663 0.508
c.rating      -0.556  0.102 5.451 0.000
u.(Intercept)  1.943  1.017 1.910 0.057
u.sex          0.221  0.248 0.888 0.375 *
u.children     0.229  0.276 0.827 0.409 *
u.occu         0.054  0.082 0.663 0.508
u.rating      -0.581  0.109 5.331 0.000

 > out<-subset(out,!(names(out) %in% c("sex","rating")))
 > out
                  est     se     t     p disc
p.(Intercept) 26.430 13.605 1.943 0.053
p.sex          3.502  3.930 0.891 0.373 *
p.children     3.693  4.521 0.817 0.414 *
p.occu         0.740  1.116 0.663 0.508
p.rating      -7.897  1.331 5.933 0.000
c.(Intercept)  1.861  0.965 1.929 0.054
c.sex          0.221  0.249 0.889 0.374 *
c.children     0.234  0.289 0.810 0.418 *
c.occu         0.052  0.079 0.663 0.508
c.rating      -0.556  0.102 5.451 0.000
u.(Intercept)  1.943  1.017 1.910 0.057
u.sex          0.221  0.248 0.888 0.375 *
u.children     0.229  0.276 0.827 0.409 *
u.occu         0.054  0.082 0.663 0.508
u.rating      -0.581  0.109 5.331 0.000


From wdunlap at tibco.com  Mon Nov 17 04:22:48 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 16 Nov 2014 19:22:48 -0800
Subject: [R] Removing rows in a data frame containing string in rownames
In-Reply-To: <54695e00.8807ec0a.2299.ffffeaa1@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<54510abb.46dfec0a.3c7b.70ed@mx.google.com>
	<54510D5A.60800@utoronto.ca>
	<7.1.0.9.2.20141029115750.050c3948@gmail.com>
	<54695e00.8807ec0a.2299.ffffeaa1@mx.google.com>
Message-ID: <CAF8bMcY2ZFo2dov4JXykBKvawWQkG-GonGTA7-Dqub8RAjSdHA@mail.gmail.com>

Try grepl() to do pattern matching in strings.  ("%in%" checks for
equality.)  E.g., using your original 'out' do
   out[ !grepl("sex|rating", rownames(out), ]
to get all but the rows whose names contain the character sequences
"sex" or "rating".

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Nov 16, 2014 at 6:31 PM, Steven Yen <syen04 at gmail.com> wrote:

> I like to remove from a data frame rows with labels containing certain
> string, e.g., "sex" and "rating". Below is a list of the data frame and my
> failed attempt to the rows. Any clues? Thanks.
>
> > out
>                  est     se     t     p disc
> p.(Intercept) 26.430 13.605 1.943 0.053
> p.sex          3.502  3.930 0.891 0.373 *
> p.children     3.693  4.521 0.817 0.414 *
> p.occu         0.740  1.116 0.663 0.508
> p.rating      -7.897  1.331 5.933 0.000
> c.(Intercept)  1.861  0.965 1.929 0.054
> c.sex          0.221  0.249 0.889 0.374 *
> c.children     0.234  0.289 0.810 0.418 *
> c.occu         0.052  0.079 0.663 0.508
> c.rating      -0.556  0.102 5.451 0.000
> u.(Intercept)  1.943  1.017 1.910 0.057
> u.sex          0.221  0.248 0.888 0.375 *
> u.children     0.229  0.276 0.827 0.409 *
> u.occu         0.054  0.082 0.663 0.508
> u.rating      -0.581  0.109 5.331 0.000
>
> > out<-subset(out,!(names(out) %in% c("sex","rating")))
> > out
>                  est     se     t     p disc
> p.(Intercept) 26.430 13.605 1.943 0.053
> p.sex          3.502  3.930 0.891 0.373 *
> p.children     3.693  4.521 0.817 0.414 *
> p.occu         0.740  1.116 0.663 0.508
> p.rating      -7.897  1.331 5.933 0.000
> c.(Intercept)  1.861  0.965 1.929 0.054
> c.sex          0.221  0.249 0.889 0.374 *
> c.children     0.234  0.289 0.810 0.418 *
> c.occu         0.052  0.079 0.663 0.508
> c.rating      -0.556  0.102 5.451 0.000
> u.(Intercept)  1.943  1.017 1.910 0.057
> u.sex          0.221  0.248 0.888 0.375 *
> u.children     0.229  0.276 0.827 0.409 *
> u.occu         0.054  0.082 0.663 0.508
> u.rating      -0.581  0.109 5.331 0.000
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Mon Nov 17 04:47:44 2014
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 16 Nov 2014 22:47:44 -0500
Subject: [R] Removing rows in a data frame containing string in rownames
In-Reply-To: <CAF8bMcY2ZFo2dov4JXykBKvawWQkG-GonGTA7-Dqub8RAjSdHA@mail.g
	mail.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<54510abb.46dfec0a.3c7b.70ed@mx.google.com>
	<54510D5A.60800@utoronto.ca>
	<7.1.0.9.2.20141029115750.050c3948@gmail.com>
	<54695e00.8807ec0a.2299.ffffeaa1@mx.google.com>
	<CAF8bMcY2ZFo2dov4JXykBKvawWQkG-GonGTA7-Dqub8RAjSdHA@mail.gmail.com>
Message-ID: <54696fe3.886eec0a.27ee.ffffe935@mx.google.com>

Thank you Bill and Dennis. grepl worked great. 
However, for reason I am not figuring out, the 
code worked as I included the procedure 
(subroutine) with a source command, viz.,

   source("z:\\R\\mylib\\me.R")

Compiling the routine into a library/package, as 
I always do, then the command got ignored. Hmm...

Steven

At 10:22 PM 11/16/2014, William Dunlap wrote:
>Try grepl() to do pattern matching in strings. ? ("%in%" checks for
>equality.) ? E.g., using your original 'out' do
>?  ? out[ !grepl("sex|rating", rownames(out), ]
>to get all but the rows whose names contain the character sequences
>"sex" or "rating".
>
>Bill Dunlap
>TIBCO Software
>wdunlap <http://tibco.com>tibco.com
>
>On Sun, Nov 16, 2014 at 6:31 PM, Steven Yen 
><<mailto:syen04 at gmail.com>syen04 at gmail.com> wrote:
>I like to remove from a data frame rows with 
>labels containing certain string, e.g., "sex" 
>and "rating". Below is a list of the data frame 
>and my failed attempt to the rows. Any clues? Thanks.
>
> > out
>?  ?  ?  ?  ?  ?  ?  ?  ? est?  ?  ? se?  ?  ? t?  ?  ? p disc
>p.(Intercept) 26.430 13.605 1.943 0.053
>p.sex?  ?  ?  ?  ?  3.502?  3.930 0.891 0.373 *
>p.children?  ?  ? 3.693?  4.521 0.817 0.414 *
>p.occu?  ?  ?  ?  ? 0.740?  1.116 0.663 0.508
>p.rating?  ?  ?  -7.897?  1.331 5.933 0.000
>c.(Intercept)?  1.861?  0.965 1.929 0.054
>c.sex?  ?  ?  ?  ?  0.221?  0.249 0.889 0.374 *
>c.children?  ?  ? 0.234?  0.289 0.810 0.418 *
>c.occu?  ?  ?  ?  ? 0.052?  0.079 0.663 0.508
>c.rating?  ?  ?  -0.556?  0.102 5.451 0.000
>u.(Intercept)?  1.943?  1.017 1.910 0.057
>u.sex?  ?  ?  ?  ?  0.221?  0.248 0.888 0.375 *
>u.children?  ?  ? 0.229?  0.276 0.827 0.409 *
>u.occu?  ?  ?  ?  ? 0.054?  0.082 0.663 0.508
>u.rating?  ?  ?  -0.581?  0.109 5.331 0.000
>
> > out<-subset(out,!(names(out) %in% c("sex","rating")))
> > out
>?  ?  ?  ?  ?  ?  ?  ?  ? est?  ?  ? se?  ?  ? t?  ?  ? p disc
>p.(Intercept) 26.430 13.605 1.943 0.053
>p.sex?  ?  ?  ?  ?  3.502?  3.930 0.891 0.373 *
>p.children?  ?  ? 3.693?  4.521 0.817 0.414 *
>p.occu?  ?  ?  ?  ? 0.740?  1.116 0.663 0.508
>p.rating?  ?  ?  -7.897?  1.331 5.933 0.000
>c.(Intercept)?  1.861?  0.965 1.929 0.054
>c.sex?  ?  ?  ?  ?  0.221?  0.249 0.889 0.374 *
>c.children?  ?  ? 0.234?  0.289 0.810 0.418 *
>c.occu?  ?  ?  ?  ? 0.052?  0.079 0.663 0.508
>c.rating?  ?  ?  -0.556?  0.102 5.451 0.000
>u.(Intercept)?  1.943?  1.017 1.910 0.057
>u.sex?  ?  ?  ?  ?  0.221?  0.248 0.888 0.375 *
>u.children?  ?  ? 0.229?  0.276 0.827 0.409 *
>u.occu?  ?  ?  ?  ? 0.054?  0.082 0.663 0.508
>u.rating?  ?  ?  -0.581?  0.109 5.331 0.000
>
>______________________________________________
><mailto:R-help at r-project.org>R-help at r-project.org mailing list
><https://stat.ethz.ch/mailman/listinfo/r-help>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
><http://www.R-project.org/posting-guide.html>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Nov 17 05:52:00 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 16 Nov 2014 20:52:00 -0800
Subject: [R] Removing rows in a data frame containing string in rownames
In-Reply-To: <54696fe3.886eec0a.27ee.ffffe935@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<54510abb.46dfec0a.3c7b.70ed@mx.google.com>
	<54510D5A.60800@utoronto.ca>
	<7.1.0.9.2.20141029115750.050c3948@gmail.com>
	<54695e00.8807ec0a.2299.ffffeaa1@mx.google.com>
	<CAF8bMcY2ZFo2dov4JXykBKvawWQkG-GonGTA7-Dqub8RAjSdHA@mail.gmail.com>
	<54696fe3.886eec0a.27ee.ffffe935@mx.google.com>
Message-ID: <205FED6C-3B69-40BE-B753-23AE693AAF29@dcn.davis.CA.us>

Not clear what you did. Is this an example of FAQ 7.16?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 16, 2014 7:47:44 PM PST, Steven Yen <syen04 at gmail.com> wrote:
>Thank you Bill and Dennis. grepl worked great. 
>However, for reason I am not figuring out, the 
>code worked as I included the procedure 
>(subroutine) with a source command, viz.,
>
>   source("z:\\R\\mylib\\me.R")
>
>Compiling the routine into a library/package, as 
>I always do, then the command got ignored. Hmm...
>
>Steven
>
>At 10:22 PM 11/16/2014, William Dunlap wrote:
>>Try grepl() to do pattern matching in strings. ? ("%in%" checks for
>>equality.) ? E.g., using your original 'out' do
>>?  ? out[ !grepl("sex|rating", rownames(out), ]
>>to get all but the rows whose names contain the character sequences
>>"sex" or "rating".
>>
>>Bill Dunlap
>>TIBCO Software
>>wdunlap <http://tibco.com>tibco.com
>>
>>On Sun, Nov 16, 2014 at 6:31 PM, Steven Yen 
>><<mailto:syen04 at gmail.com>syen04 at gmail.com> wrote:
>>I like to remove from a data frame rows with 
>>labels containing certain string, e.g., "sex" 
>>and "rating". Below is a list of the data frame 
>>and my failed attempt to the rows. Any clues? Thanks.
>>
>> > out
>>?  ?  ?  ?  ?  ?  ?  ?  ? est?  ?  ? se?  ?  ? t?  ?  ? p disc
>>p.(Intercept) 26.430 13.605 1.943 0.053
>>p.sex?  ?  ?  ?  ?  3.502?  3.930 0.891 0.373 *
>>p.children?  ?  ? 3.693?  4.521 0.817 0.414 *
>>p.occu?  ?  ?  ?  ? 0.740?  1.116 0.663 0.508
>>p.rating?  ?  ?  -7.897?  1.331 5.933 0.000
>>c.(Intercept)?  1.861?  0.965 1.929 0.054
>>c.sex?  ?  ?  ?  ?  0.221?  0.249 0.889 0.374 *
>>c.children?  ?  ? 0.234?  0.289 0.810 0.418 *
>>c.occu?  ?  ?  ?  ? 0.052?  0.079 0.663 0.508
>>c.rating?  ?  ?  -0.556?  0.102 5.451 0.000
>>u.(Intercept)?  1.943?  1.017 1.910 0.057
>>u.sex?  ?  ?  ?  ?  0.221?  0.248 0.888 0.375 *
>>u.children?  ?  ? 0.229?  0.276 0.827 0.409 *
>>u.occu?  ?  ?  ?  ? 0.054?  0.082 0.663 0.508
>>u.rating?  ?  ?  -0.581?  0.109 5.331 0.000
>>
>> > out<-subset(out,!(names(out) %in% c("sex","rating")))
>> > out
>>?  ?  ?  ?  ?  ?  ?  ?  ? est?  ?  ? se?  ?  ? t?  ?  ? p disc
>>p.(Intercept) 26.430 13.605 1.943 0.053
>>p.sex?  ?  ?  ?  ?  3.502?  3.930 0.891 0.373 *
>>p.children?  ?  ? 3.693?  4.521 0.817 0.414 *
>>p.occu?  ?  ?  ?  ? 0.740?  1.116 0.663 0.508
>>p.rating?  ?  ?  -7.897?  1.331 5.933 0.000
>>c.(Intercept)?  1.861?  0.965 1.929 0.054
>>c.sex?  ?  ?  ?  ?  0.221?  0.249 0.889 0.374 *
>>c.children?  ?  ? 0.234?  0.289 0.810 0.418 *
>>c.occu?  ?  ?  ?  ? 0.052?  0.079 0.663 0.508
>>c.rating?  ?  ?  -0.556?  0.102 5.451 0.000
>>u.(Intercept)?  1.943?  1.017 1.910 0.057
>>u.sex?  ?  ?  ?  ?  0.221?  0.248 0.888 0.375 *
>>u.children?  ?  ? 0.229?  0.276 0.827 0.409 *
>>u.occu?  ?  ?  ?  ? 0.054?  0.082 0.663 0.508
>>u.rating?  ?  ?  -0.581?  0.109 5.331 0.000
>>
>>______________________________________________
>><mailto:R-help at r-project.org>R-help at r-project.org mailing list
>><https://stat.ethz.ch/mailman/listinfo/r-help>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide 
>><http://www.R-project.org/posting-guide.html>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Mon Nov 17 09:37:58 2014
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 17 Nov 2014 00:37:58 -0800
Subject: [R] Using OpenBLAS with R
In-Reply-To: <54687C70.6090700@stats.ox.ac.uk>
References: <CACdH2Zb++5Qd1gdteaeaepx4YrcHrPy163hnk05k1J7q5e1OmQ@mail.gmail.com>
	<54687C70.6090700@stats.ox.ac.uk>
Message-ID: <CACdH2ZZ1JB5oGdhJh5ibXj72QFzoGUY+A+iCYJ9q_g1VcmAigQ@mail.gmail.com>

Useful and interesting.  Thanks for your prompt reply.

-- Mike

On Sun, Nov 16, 2014 at 2:29 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 16/11/2014 00:11, Michael Hannon wrote:
>>
>> Greetings.  I'd like to get some advice about using OpenBLAS with R,
>> rather
>> than using the BLAS that comes built in to R.
>
>
> That was really a topic for the R-devel list: see the posting guide.
>
>> I've tried this on my Fedora 20 system (see the appended for details).  I
>> ran
>> a simple test -- multiplying two large matrices -- and the results were
>> very
>> impressive, i.e., in favor of OpenBLAS, which is consistent with
>> discussions
>> I've seen on the web.
>
>
> If that is all you do, then you should be using an optimized BLAS, and
> choose the one(s) best for your (unstated) machine(s).
>
>> My concern is that maybe this is too good to be true.  I.e., the standard
>> R
>> configuration is vetted by thousands of people every day.  Can I have the
>> same
>> degree of confidence with OpenBLAS that I have in the built-in version?
>
>
> No.  And it is 'too good to be true' for most users of R, for whom BLAS
> operations take a negligible proportion of their CPU time.
>
>> And/or are there other caveats to using OpenBLAS of which I should be
>> aware?
>
>
> Yes: see the 'R Installation and Administration Manual'.  Known issues
> include:
>
> 1) Optimized BLAS trade accuracy for speed.   Surprisingly much published R
> code relies on using extended-precision FPU registers for intermediate
> results, which optimized BLAS do much less than the reference BLAS.
>
> Some packages rely on a particular sign of the solution to svd or eigen
> problems: people then report as bugs that optimized BLAS give a different
> sign from the reference BLAS.
>
> 2) Fast BLAS normally use multi-threading: that usually helps elapsed time
> for a single R task at the expense of increased total CPU time. Fine if you
> have unused CPU cores, but not advantageous in a fully-used multi-core
> machine, e.g. one that is doing many R sessions in parallel.
>
> 3) Many BLAS optimize their use of CPU caches.  This works best if the
> BLAS-using process is the only task running on a particular core (or CPU
> where CPU cores share cache).  (It also means that optimizing on one CPU
> model and running on another can be disastrous.)
>
>
>>
>> Thanks.
>>
>> -- Mike
>>
>> #### Here's the version of R, compiled locally with configuration options:
>> #### ./configure --enable-R-shlib --enable-BLAS-shlib
>>
>> $ R
>>
>> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
>> Copyright (C) 2014 The R Foundation for Statistical Computing
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> .
>> .
>> .
>>
>> #### Here's the R source code for this little test:
>>
>> library(microbenchmark)
>>
>> mSize <- 10000
>> set.seed(42)
>>
>> aMat <- matrix(rnorm(mSize * mSize), nrow=mSize)
>> bMat <- matrix(rnorm(mSize * mSize), nrow=mSize)
>>
>> cMat <- aMat %*% bMat  ## do the calculation once to see that it works
>>
>> traceCMat <- sum(diag(cMat))  ## a mild sanity check on the calculation
>> traceCMat
>>
>> microbenchmark(aMat %*% bMat, times=5L)  ## repeat a few more times
>>
>> -----
>>
>> #### Here is the output from code, running under various conditions:
>>
>>> traceCMat ###### Using the built-in BLAS from R
>>
>> [1] -11367.55
>>>
>>> microbenchmark(aMat %*% bMat, times=5L)
>>
>> Unit: seconds
>>            expr      min       lq     mean   median       uq     max neval
>>   aMat %*% bMat 675.0064 675.5325 675.4897 675.5857 675.6618 675.662     5
>>
>> ----------
>>
>>> traceCMat  ###### Using libopenblas.so from Fedora
>>
>> [1] -11367.55
>>>
>>> microbenchmark(aMat %*% bMat, times=5L)
>>
>> Unit: seconds
>>            expr      min       lq     mean   median       uq      max
>> neval
>>   aMat %*% bMat 70.67843 70.70545 70.76365 70.73026 70.83935 70.86475
>> 5
>>>
>>>
>>
>> ----------
>>
>>> traceCMat <- sum(diag(cMat))  ###### libopenblas.so from Fedora with
>>> traceCMat                     ###### export OMP_NUM_THREADS=6
>>
>> [1] -11367.55
>>>
>>> microbenchmark(aMat %*% bMat, times=5L)
>>
>> Unit: seconds
>>            expr      min       lq    mean   median       uq      max neval
>>   aMat %*% bMat 69.99146 70.02426 70.3466 70.08327 70.39537 71.23866     5
>>>
>>>
>>
>> ###### Fedora libopenblas.so appears to be single-threaded
>>
>> ----------
>>
>>> traceCMat <- sum(diag(cMat))  ###### libopenblas.so compiled locally
>>> traceCMat                     ###### from source w/OMP_NUM_THREADS=6
>>
>> [1] -11367.55
>>>
>>> microbenchmark(aMat %*% bMat, times=5L)
>>
>> Unit: seconds
>>            expr      min       lq     mean   median       uq      max
>> neval
>>   aMat %*% bMat 26.77385 27.10434 27.17862 27.12485 27.16301 27.72705
>> 5
>>>
>>>
>>
>> ###### Locally-compiled openblas appears to be multi-threaded
>> ###### The microbenchmark appeared to use all 8 processors, even
>> ###### though I asked for only 6.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK


From zilefacelvis at yahoo.com  Mon Nov 17 16:17:38 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Mon, 17 Nov 2014 15:17:38 +0000 (UTC)
Subject: [R] Overlay two shapefiles in same map axes rgdal/maptools
In-Reply-To: <1783220081.1180761.1416171515375.JavaMail.yahoo@jws10610.mail.bf1.yahoo.com>
References: <1783220081.1180761.1416171515375.JavaMail.yahoo@jws10610.mail.bf1.yahoo.com>
Message-ID: <2134668099.1494648.1416237458659.JavaMail.yahoo@jws106136.mail.bf1.yahoo.com>

Hello,

I have two spatial map objects (reproducible example further down) which I would like to overlay in R. The ESRI shapefiles were read using:

library(rgdal)
Prairie.Boundaries <-  readOGR(".", "boundaries") 
watersheds<-readOGR(".","watersheds")

The two objects have same projection:
print(proj4string(watersheds)) 
[1] "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"

print(proj4string(Prairie.Boundaries)) 
[1] "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"

However, the spatial limits are different:
summary(watersheds) 
Object of class SpatialPolygonsDataFrame 
Coordinates: 
min       max 
x -127.73835 -88.98395 
y   45.44628  61.38249 
Is projected: FALSE 
proj4string : 
[+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0]


summary(Prairie.Boundaries) 
Object of class SpatialPolygonsDataFrame 
Coordinates: 
min       max 
x -120.00138 -88.99081 
y   48.99668  60.00042 
Is projected: FALSE 
proj4string : 
[+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0]

Problem:
How can I overlay "watersheds" on "Prairie.Boundaries"?

For example:

plot(Prairie.Boundaries, axes=TRUE, border="black")
plot(watersheds,border="gray8",col="white",axes=TRUE)

I tried to extend the ylim and xlim of "Prairie.Boundaries" to match those of "watersheds" but could not display the shapefiles on same plot.

Please help.
Thanks, Asong.

#------------------------------------------------------------------------------------------------------------------------

dput(watersheds) 
new("SpatialPolygonsDataFrame" 
, data = structure(list(SUB_PF = structure(c(1L, 12L, 23L, 34L, 43L, 44L, 
45L, 46L, 47L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L, 32L, 33L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 
42L), .Label = c("1", "10", "11", "12", "13", "14", "15", "16", 
"17", "18", "19", "2", "20", "21", "22", "23", "24", "25", "26", 
"27", "28", "29", "3", "30", "31", "32", "33", "34", "35", "36", 
"37", "38", "39", "4", "40", "41", "42", "43", "44", "45", "46", 
"47", "5", "6", "7", "8", "9"), class = "factor")), .Names = "SUB_PF", row.names = 0:46, class = "data.frame") 
, polygons = list(<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>) 
, plotOrder = c(29L, 9L, 2L, 47L, 35L, 16L, 21L, 25L, 26L, 40L, 38L, 37L, 17L, 
15L, 42L, 34L, 32L, 45L, 22L, 43L, 1L, 3L, 30L, 20L, 28L, 19L, 
7L, 24L, 18L, 8L, 5L, 27L, 12L, 41L, 13L, 33L, 11L, 31L, 6L, 
23L, 46L, 10L, 14L, 39L, 44L, 36L, 4L) 
, bbox = structure(c(-127.738346938252, 45.4462802950586, -88.9839497612937, 
61.3824920693942), .Dim = c(2L, 2L), .Dimnames = list(c("x", 
"y"), c("min", "max"))) 
, proj4string = new("CRS" 
, projargs = "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0" 
) 
)

#-------------------------------------------------------------------------------------------------
dput(Prairie.Boundaries) 
new("SpatialPolygonsDataFrame" 
, data = structure(list(UUID = structure(c(2L, 3L, 1L), .Label = c("37", 
"496", "79"), class = "factor"), TYPE_E = structure(c(1L, 1L, 
1L), .Label = "PROV", class = "factor"), NAME = structure(c(2L, 
3L, 1L), .Label = c("ALBERTA", "MANITOBA", "SASKATCHEWAN"), class = "factor"), 
SRC_AGENCY = structure(c(1L, 1L, 1L), .Label = "NRCAN", class = "factor"), 
L_UPD_DATE = structure(c(1L, 1L, 2L), .Label = c("2007/05/17", 
"2011/04/15"), class = "factor"), L_UPD_TYPE = structure(c(1L, 
1L, 1L), .Label = "G", class = "factor"), P_UPD_DATE = structure(c(1L, 
1L, 1L), .Label = "2004/06/03", class = "factor")), .Names = c("UUID", 
"TYPE_E", "NAME", "SRC_AGENCY", "L_UPD_DATE", "L_UPD_TYPE", "P_UPD_DATE" 
), row.names = 0:2, class = "data.frame") 
, polygons = list(<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>, 
<S4 object of class structure("Polygons", package = "sp")>) 
, plotOrder = c(3L, 1L, 2L) 
, bbox = structure(c(-120.001383519, 48.99667665, -88.990814136, 60.000421584 
), .Dim = c(2L, 2L), .Dimnames = list(c("x", "y"), c("min", "max" 
))) 
, proj4string = new("CRS" 
, projargs = "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0" 
) 
)#------------------------------------------------------------------------------------------------------


From ruimaximo at gmail.com  Mon Nov 17 17:30:39 2014
From: ruimaximo at gmail.com (Ruima E.)
Date: Mon, 17 Nov 2014 17:30:39 +0100
Subject: [R] Preprocessing with Caret package
Message-ID: <CAJYLPFeVougfn2AxCNRESjL-Baq0yH9axusBpM40YFVEJezbWw@mail.gmail.com>

Hi,

Please consider the following code

library (caret)
x=matrix(c(12:131),2)
p=preProcess(x, method=c("center","scale"));
x.prep=predict(p,x)

y.prep=x.prep[60,60]

How can I get the value of y (the value from y.pre not centered and not
scaled ) using p and y.prep?

Thank you!
Rui

	[[alternative HTML version deleted]]


From aiyelabeganadijat45 at gmail.com  Mon Nov 17 12:42:02 2014
From: aiyelabeganadijat45 at gmail.com (aiyelabegan adijat)
Date: Mon, 17 Nov 2014 12:42:02 +0100
Subject: [R] I need help
Message-ID: <CAKbqaaLrwN=DrqXkYGxfBBByYTAkkhKCy1MFzZk=7HzKxU__9g@mail.gmail.com>

I need your assistance on how to generate random replication of treatments
for nth row by jth col matrix for design of experiments.
thank you.

	[[alternative HTML version deleted]]


From rees at reesmorrison.com  Mon Nov 17 13:03:25 2014
From: rees at reesmorrison.com (Rees Morrison)
Date: Mon, 17 Nov 2014 07:03:25 -0500
Subject: [R] Implements XPath 2.0 in R
Message-ID: <CAJ_hwm8v+w8uKPp9LFdoz6edXNBFc8sAKWYgC-rO5fupCqz7WA@mail.gmail.com>

Many users of R would like the enhanced extraction capabilities of XPath
2.0, but only XPath 1.0 is available..

What would the best approach be to find someone to implement XPath 2.0 for
R (assuming that is a good idea)?  What might the cost be and how would one
set this package development in motion?

Thanks

-- 
Rees Morrison
General Counsel Metrics, LLC (management consulting and *data analytics*)
4 Hawthorne Ave.
Princeton, NJ 08540-3840 USA
(973) 568-9110
Hosts www.lawdepartmentmanagementblog.com

	[[alternative HTML version deleted]]


From Christoph.Hanck at vwl.uni-due.de  Mon Nov 17 11:49:29 2014
From: Christoph.Hanck at vwl.uni-due.de (Hanck, Christoph)
Date: Mon, 17 Nov 2014 10:49:29 +0000
Subject: [R] glmnet estimates and Tibshirani JRSSB 1996
Message-ID: <2669DFACA6C93848AED7306DE9F3CA82133F1452@WIWINF-EXDAG01.wiwinf.uni-due.de>

Dear all,

I have a question that hopefully is an R question and does not simply arise from my lack of understanding of the LASSO.

The code below generates two different sets of relationships between y and X, one in which both variables matter (coefficients .5 each, line 14) and one in which one of the two will be shrunk to zero (coefficients .9 and .01, line 13). Lines 15-18 normalize by demeaning y and creating an orthonormal X matrix. I assign a "budget" of 0.5 to the coefficients (line 21). Line 31 translates this budget to the implied lambda in the Lagrangian form of the Lasso (one potential source of error, but I hope I read JRSSB equation 6 correctly here).

In the scenario in which both variables matter, everything works fine: the sum of the coefficients is 0.5 as intended, and the expressions from Tibshirani, eq 6 (lines 24,25), and those from glmnet agree. If, however, line 13 is switched on, so that the second coefficient gets shrunk to 0, the sum of the coefficients no longer equals the budget of 0.5 for either expression (which still agree). Any thoughts on why I only seem to do it right in the case in which there is no shrinkage to 0?

Best,
Christoph

rm(list=ls())
library(glmnet)
library(mvtnorm)
set.seed(38)

N = 50
K = 2
SigCorr=.0
Sigma = matrix(c(1,SigCorr,SigCorr,1),ncol=2)
X = rmvnorm(N, mean=rnorm(K), sigma=Sigma, method="chol")

u = rnorm(N)
y = .9*X[,1]+.01*X[,2]+u
#y = .5*X[,1]+.5*X[,2]+u
y = y-mean(y)
X = scale(X)
vX = var(X)
X = sqrt(N/(N-1))*X%*%solve(chol(vX)) # generates orthonormal matrix

reg = lm(y~X-1)
budget = .5

# where LASSO estimates should be according to Tibshirani (JRSSB 1996), eq (6)
beta_1_LASSO = max(c(0,budget/2+(reg$coefficients[1]-reg$coefficients[2])/2))
beta_2_LASSO = max(c(0,budget/2-(reg$coefficients[1]-reg$coefficients[2])/2))
beta_1_LASSO
beta_2_LASSO
beta_1_LASSO+beta_2_LASSO

# using glmnet. notice it minimizes 1/2*RSS+penalty, unlike in JRSSB, with implications for relationship betahat and lambda
lambda = (reg$coefficients[1]+reg$coefficients[2]-budget)/2
lasso.mod=glmnet(X,y,alpha=1,lambda=lambda)
coef(lasso.mod)
sum(coef(lasso.mod))


--
Prof. Dr. Christoph Hanck
Lehrstuhl f?r ?konometrie
Universit?t Duisburg-Essen

+49 201 183 2263
christoph.hanck at vwl.uni-due.de<mailto:christoph.hanck at vwl.uni-due.de>
www.oek.wiwi.uni-due.de<http://www.oek.wiwi.uni-due.de/>


	[[alternative HTML version deleted]]


From francesca.pancotto at gmail.com  Mon Nov 17 12:49:47 2014
From: francesca.pancotto at gmail.com (Francesca)
Date: Mon, 17 Nov 2014 12:49:47 +0100
Subject: [R] Dates in a data.frame
Message-ID: <CAKFaUKh5Yh5nty7frDLN6brxZd6v1MWCjgoShOda8Ff=C9hAEA@mail.gmail.com>

>

Dear Contributors

I have a problem concerning the replication of a variable with

the date structure.

I have the following database of 12000 observations

bank.list.m:

        name       date

aba.1        ABA 2006-10-24

aba.2        ABA 2006-11-30

aba.3        ABA 2006-10-24

aba.4        ABA 2006-11-30

aba.5        ABA 2006-10-24

aba.6        ABA 2006-11-30

aba.7        ABA 2006-10-24

aba.8        ABA 2006-11-30

aba.9        ABA 2006-10-24

aba.10       ABA 2006-11-30


and the following with 960 obs.


day.spot

        date   spot

1 2006-01-02 1.1826

2 2006-01-03 1.1875

3 2006-01-04 1.2083

4 2006-01-05 1.2088

5 2006-01-06 1.2093

6 2006-01-09 1.2078


the date in the second database are a subset of the dates of the first
database.

What I need to do is to associate the value of the variable spot

reported in the second database, at the exact place of the corresponding

date in the first database.

I tried the following



dates<-table(bank.list.m$date)


test<-as.data.frame(dates)

dates.v<-as.Date(test$Var1)

x<-as.data.frame(dates.v)

x$index<-c(1:960)

x$spot.v<-day.spot$spot[x$index]


but I do not seem to go anywhere.

I think I only replicated the values of the day.spot variable.

Any help?

Thanks for your time and patience!

Francescaa

-- 

Francesca

----------------------------------
Francesca Pancotto, PhD
Universit? di Modena e Reggio Emilia
Viale A. Allegri, 9
40121 Reggio Emilia
Office: +39 0522 523264
Web: https://sites.google.com/site/francescapancotto/
----------------------------------

	[[alternative HTML version deleted]]


From olivier.lerouzic at ymail.com  Mon Nov 17 16:24:03 2014
From: olivier.lerouzic at ymail.com (Olivier)
Date: Mon, 17 Nov 2014 10:24:03 -0500
Subject: [R] Help for x axis
Message-ID: <546A1313.4040508@ymail.com>

Hi,
I want to customize x axis to scientific data. I do experiments with 
different triggers. As others publications, I want that there is one 
line for each trigger with the sign "-" or "+" to show if the trigger is 
used or no. You will find attached an exemple.
Please find below a data.frame you could use to explain me.
Thank you for your response,
Olivier



set.seed(3)
sampleData <- data.frame(id = 1:100,gender = sample(c("0", "1"), 100, 
replace = TRUE), smoke = sample (c("0","1"), 100, replace=TRUE), age = 
rnorm(100, 40, 10))
summary(sampleData)

-> I want to give results with histograms or box.plot (age according to 
sex and smoking status)
-> x axis may be like something like this :

Gender        -          -         +        +
Smoke         -          +        -         +

-------------- next part --------------
A non-text attachment was scrubbed...
Name: ex.png
Type: image/png
Size: 22715 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141117/cd4d72e8/attachment.png>

From petr.pikal at precheza.cz  Tue Nov 18 11:48:28 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 18 Nov 2014 10:48:28 +0000
Subject: [R] problems with mail message
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEEE18@SRVEXCHMBX.precheza.cz>

Dear maintainers

I experienced problems with undeliverable messages to R-help

Here is header, which basically says that mail to r-help at r-project.org was undelivered and that phil2.ethz.ch refused to accept it.

*************************************
Doru?en? t?mto p??jemc?m nebo skupin?m se nezda?ilo:

r-help at r-project.org
P?i doru?ov?n? t?to zpr?vy na tuto e-mailovou adresu do?lo k chyb?. Pokuste se zpr?vu odeslat znovu. Pokud pot??e potrvaj?, obra?te se na helpdesk.

N?sleduj?c? organizace odm?tla zpr?vu: phil2.ethz.ch.
**********************************

I asked our IT people but they do not know reason.

If necessary I can send whole returned message with all diagnostic info.


Regards
Petr

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From maechler at stat.math.ethz.ch  Tue Nov 18 12:16:47 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 Nov 2014 12:16:47 +0100
Subject: [R] problems with mail message
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEEE18@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEEE18@SRVEXCHMBX.precheza.cz>
Message-ID: <21611.10911.125962.303019@stat.math.ethz.ch>

>>>>> PIKAL Petr <petr.pikal at precheza.cz>
>>>>>     on Tue, 18 Nov 2014 10:48:28 +0000 writes:

    > Dear maintainers

Hi Petr,
You sent this to the mailing list, not just the maintainers..

    > I experienced problems with undeliverable messages to R-help

Yes, and many others probably did too.

    > Here is header, which basically says that mail to r-help at r-project.org was undelivered and that phil2.ethz.ch refused to accept it.

Indeed, that's how we also read the message but our reading was
actually slightly misleading.. and so it took considerably
longer than in an ideal case to solve the situation.

Indeed, all the e-mails sent to <something>@r-project.org have
to be resent by the original senders.

We are very sorry for this grave mishap.

Martin Maechler,
Statistics (subset) Mathematics (subset) ETH Zurich

    > Regards
    > Petr


From petr.pikal at precheza.cz  Tue Nov 18 12:22:36 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 18 Nov 2014 11:22:36 +0000
Subject: [R] problems with mail message
In-Reply-To: <21611.10911.125962.303019@stat.math.ethz.ch>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEEE18@SRVEXCHMBX.precheza.cz>
	<21611.10911.125962.303019@stat.math.ethz.ch>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEEE77@SRVEXCHMBX.precheza.cz>

Hi Martin

No problem. I hope OP obtained my responses and so I do not see need for resending them to r-help.

You are doing great job and such minor problems do not change my opinon about it.

Regards
Petr


> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Tuesday, November 18, 2014 12:17 PM
> To: PIKAL Petr
> Cc: r-help
> Subject: Re: [R] problems with mail message
>
> >>>>> PIKAL Petr <petr.pikal at precheza.cz>
> >>>>>     on Tue, 18 Nov 2014 10:48:28 +0000 writes:
>
>     > Dear maintainers
>
> Hi Petr,
> You sent this to the mailing list, not just the maintainers..
>
>     > I experienced problems with undeliverable messages to R-help
>
> Yes, and many others probably did too.
>
>     > Here is header, which basically says that mail to r-help at r-
> project.org was undelivered and that phil2.ethz.ch refused to accept
> it.
>
> Indeed, that's how we also read the message but our reading was
> actually slightly misleading.. and so it took considerably longer than
> in an ideal case to solve the situation.
>
> Indeed, all the e-mails sent to <something>@r-project.org have to be
> resent by the original senders.
>
> We are very sorry for this grave mishap.
>
> Martin Maechler,
> Statistics (subset) Mathematics (subset) ETH Zurich
>
>     > Regards
>     > Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From franck.vermet at univ-brest.fr  Tue Nov 18 12:35:49 2014
From: franck.vermet at univ-brest.fr (Franck Vermet)
Date: Tue, 18 Nov 2014 12:35:49 +0100
Subject: [R] number of weights in multinom ?
Message-ID: <1B8B8B89-729C-4C22-A2BB-AE7BC3FF9E28@univ-brest.fr>

Hello,

In the function multinom (package nnet), I get the following message after training for a model with 9 inputs and 6 classes (output) :

# weights:  66 (50 variable)

I understand that there are 50 variables in the model,
but I don't understand the number 66. 
How can we interpret this number ?

Thanks,
Franck Vermet.


From ripley at stats.ox.ac.uk  Tue Nov 18 12:48:05 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 18 Nov 2014 11:48:05 +0000
Subject: [R] number of weights in multinom ?
In-Reply-To: <1B8B8B89-729C-4C22-A2BB-AE7BC3FF9E28@univ-brest.fr>
References: <1B8B8B89-729C-4C22-A2BB-AE7BC3FF9E28@univ-brest.fr>
Message-ID: <546B31F5.5090002@stats.ox.ac.uk>

On 18/11/2014 11:35, Franck Vermet wrote:
> Hello,
>
> In the function multinom (package nnet), I get the following message after training for a model with 9 inputs and 6 classes (output) :
>
> # weights:  66 (50 variable)
>
> I understand that there are 50 variables in the model,
> but I don't understand the number 66.
> How can we interpret this number ?

That is not what the message says: 'variable' is not a plural noun but 
an adjective, the antonym of 'fixed'.

Package nnet is support software for a book: you need to do your own 
homework by reading it.

>
> Thanks,
> Franck Vermet.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

That does mean you: in the absence for a reproducible example no one can 
help you.

Also, repeated posting is very strongly discouraged: you sent this on 
Nov 13 (and also spammed CRAN with it).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From franck.vermet at univ-brest.fr  Tue Nov 18 13:08:33 2014
From: franck.vermet at univ-brest.fr (Franck Vermet)
Date: Tue, 18 Nov 2014 13:08:33 +0100
Subject: [R] number of weights in multinom ?
In-Reply-To: <546B31F5.5090002@stats.ox.ac.uk>
References: <1B8B8B89-729C-4C22-A2BB-AE7BC3FF9E28@univ-brest.fr>
	<546B31F5.5090002@stats.ox.ac.uk>
Message-ID: <2D2063BF-41A8-441E-8C59-FAEEFE9F71C5@univ-brest.fr>

I have the book by W. Venables and B. Ripley, but I didn't find the answer.

Here is an explicit example : 

library(nnet)
data(fgl)
ir.glm <- multinom(type ~., data=fgl)

# weights:  66 (50 variable)
initial  value 383.436526 
iter  10 value 259.867465
iter  20 value 184.185706
iter  30 value 146.240801
iter  40 value 139.340485
iter  50 value 136.405273
iter  60 value 132.523057
iter  70 value 131.095461
iter  80 value 130.303792
iter  90 value 128.402012
iter 100 value 127.396942
final  value 127.396942 
stopped after 100 iterations

I understand that there are 50 variable weights, but I still not understand the sense of the value '66' in this model.

I'm sorry to spam the system; 
I'm using R-help for the first time.

Franck Vermet.


Le 18 nov. 2014 ? 12:48, Prof Brian Ripley a ?crit :

> On 18/11/2014 11:35, Franck Vermet wrote:
>> Hello,
>> 
>> In the function multinom (package nnet), I get the following message after training for a model with 9 inputs and 6 classes (output) :
>> 
>> # weights:  66 (50 variable)
>> 
>> I understand that there are 50 variables in the model,
>> but I don't understand the number 66.
>> How can we interpret this number ?
> 
> That is not what the message says: 'variable' is not a plural noun but an adjective, the antonym of 'fixed'.
> 
> Package nnet is support software for a book: you need to do your own homework by reading it.
> 
>> 
>> Thanks,
>> Franck Vermet.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> That does mean you: in the absence for a reproducible example no one can help you.
> 
> Also, repeated posting is very strongly discouraged: you sent this on Nov 13 (and also spammed CRAN with it).
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
> 


	[[alternative HTML version deleted]]


From therneau at mayo.edu  Tue Nov 18 14:07:12 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 18 Nov 2014 07:07:12 -0600
Subject: [R] CMD check error
Message-ID: <58e5f6$jmrm78@ironport9.mayo.edu>

I have a new package (local use only).  R CMD check fails with a messge I haven't seen before, and I haven't been able to guess the cause.
There are two vignettes, both of which have %\VignetteIndexEntry lines.

Same failure both under R-3.1.1 and R-devel, so it's me and not R.  Linux OS.

Hints anyone?

Terry Therneau

=================================================

tmt% R CMD build dart
* preparing 'dart':
* checking DESCRIPTION meta-information ... OK
* installing the package to build vignettes
* creating vignettes ... OK
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* looking to see if a 'data/datalist' file should be added
* building 'dart_1.0-2.tar.gz'

tmt% R CMD check dart*gz
...
Installation failed.
See '/people/biostat2/therneau/consult/bsi/dart.Rcheck ...

tmt% more dart.Rcheck/00install.out
...
** installing vignettes
Warning in file(con, "w") :
   cannot open file '/people/biostat2/therneau/consult/bsi/dart.Rcheck/dart/doc/
index.html': No such file or directory
Error in file(con, "w") : cannot open the connection
ERROR: installing vignettes failed
* removing '/people/biostat2/therneau/consult/bsi/dart.Rcheck/dart'


	[[alternative HTML version deleted]]


From roger.bivand at nhh.no  Tue Nov 18 14:13:32 2014
From: roger.bivand at nhh.no (Roger Bivand)
Date: Tue, 18 Nov 2014 13:13:32 +0000
Subject: [R] Overlay two shapefiles in same map axes rgdal/maptools
References: <1783220081.1180761.1416171515375.JavaMail.yahoo@jws10610.mail.bf1.yahoo.com>
	<2134668099.1494648.1416237458659.JavaMail.yahoo@jws106136.mail.bf1.yahoo.com>
Message-ID: <loom.20141118T122334-171@post.gmane.org>

Zilefac Elvis <zilefacelvis <at> yahoo.com> writes:

> 
> Hello,
> 
> I have two spatial map objects (reproducible example further down) 
> which I would like to overlay in R. The
> ESRI shapefiles were read using:
> 

The reproduction of the data didn't work with dput().

> library(rgdal)
> Prairie.Boundaries <-  readOGR(".", "boundaries") 
> watersheds<-readOGR(".","watersheds")
> 
> The two objects have same projection:
> print(proj4string(watersheds)) 
> [1] "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"
> 
> print(proj4string(Prairie.Boundaries)) 
> [1] "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"
> 
> However, the spatial limits are different:

This is not an intrinsic problem.

> Problem:
> How can I overlay "watersheds" on "Prairie.Boundaries"?
> 
> For example:
> 
> plot(Prairie.Boundaries, axes=TRUE, border="black")
> plot(watersheds,border="gray8",col="white",axes=TRUE)

I do not see add=TRUE here, so the second plot() erases the first. If you
are trying to overplot Prairie.Boundaries with filled watersheds polygons,
the Prairie.Boundaries will be covered anyway with col="white". 
What happens with:

plot(watersheds, border="gray8", col="white", axes=TRUE)
plot(Prairie.Boundaries, add=TRUE)

Consider posting questions of this kind on R-sig-geo, this list is for
general R help.

Do try to grasp what you are trying to do first, before asking for help.
Also check that reproducible examples actually reproduce.


> 
> I tried to extend the ylim and xlim of "Prairie.Boundaries" to match 
> those of "watersheds" but could not
> display the shapefiles on same plot.
> 
> Please help.
> Thanks, Asong.
> 
>
#--------------------------------------------------------------
> 
> dput(watersheds) 
> new("SpatialPolygonsDataFrame" 

>


From dcarlson at tamu.edu  Tue Nov 18 15:04:59 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 18 Nov 2014 14:04:59 +0000
Subject: [R] Help for x axis
References: <546A1313.4040508@ymail.com> 
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB30C5@mb02.ads.tamu.edu>

This should get you started:

> aggData <- aggregate(age~smoke+gender, sampleData, mean)
> aggData
  smoke gender      age
1     0      0 39.47231
2     1      0 40.09020
3     0      1 39.59814
4     1      1 42.04092
> plotInfo <- barplot(aggData$age)
> axis(1, c(0, plotInfo), c("Gender", "-", "-", "+", "+"), line=.75, 
+ lwd=0, cex.axis=1.25, xpd=TRUE)
> axis(1, c(0, plotInfo), c("Smoke", "-", "+", "-", "+"), line=2, 
+ lwd=0, cex.axis=1.25, xpd=TRUE)

To adapt it you will need to read the manual pages for barplot() and axis() and the page on graphical parameters par(). In particular, you will have to allocate more space at the bottom of the plot if you want to add more lines.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Olivier
Sent: Monday, November 17, 2014 9:24 AM
To: r-help at r-project.org
Subject: [R] Help for x axis

Hi,
I want to customize x axis to scientific data. I do experiments with 
different triggers. As others publications, I want that there is one 
line for each trigger with the sign "-" or "+" to show if the trigger is 
used or no. You will find attached an exemple.
Please find below a data.frame you could use to explain me.
Thank you for your response,
Olivier



set.seed(3)
sampleData <- data.frame(id = 1:100,gender = sample(c("0", "1"), 100, 
replace = TRUE), smoke = sample (c("0","1"), 100, replace=TRUE), age = 
rnorm(100, 40, 10))
summary(sampleData)

-> I want to give results with histograms or box.plot (age according to 
sex and smoking status)
-> x axis may be like something like this :

Gender        -          -         +        +
Smoke         -          +        -         +


From dcarlson at tamu.edu  Tue Nov 18 15:05:00 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 18 Nov 2014 14:05:00 +0000
Subject: [R] Help for x axis
References: <546A1313.4040508@ymail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FB2E37@mb02.ads.tamu.edu>
	<546A7909.4080200@ymail.com> 
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB30CA@mb02.ads.tamu.edu>

Try these:

aggData <- aggregate(age~smoke+gender, sampleData, function(x) c(mean=mean(x), 
	stderr=sd(x)/sqrt(length(x))))
aggData
plotInfo <- barplot(aggData$age[,1], ylim=c(0, max(rowSums(aggData$age))))
axis(1, c(0, plotInfo), c("Gender", "-", "-", "+", "+"), line=.75, 
	lwd=0, cex.axis=1.25, xpd=TRUE)
axis(1, c(0, plotInfo), c("Smoke", "-", "+", "-", "+"), line=2, 
	lwd=0, cex.axis=1.25, xpd=TRUE)
top <- aggData$age[,1]+aggData$age[,2]
bottom <- aggData$age[,1]-aggData$age[,2]
arrows(plotInfo, bottom, plotInfo, top, length=.15, angle=90, code=3)


boxplot(age~smoke+gender, sampleData, xaxt="n")
axis(1, 0:4, c("Gender", "-", "-", "+", "+"), line=.75, 
	lwd=0, cex.axis=1.25, xpd=TRUE)
axis(1, 0:4, c("Smoke", "-", "+", "-", "+"), line=2, 
	lwd=0, cex.axis=1.25, xpd=TRUE)


David

-----Original Message-----
From: Olivier [mailto:olivier.lerouzic at ymail.com] 
Sent: Monday, November 17, 2014 4:39 PM
To: David L Carlson
Subject: Re: [R] Help for x axis

Thank you very much, it is all I want to do. Is it possible with showing 
the error-bars or in a boxplot?
Best regards,

Olivier Le Rouzic

On 2014-11-17, 4:07 PM, David L Carlson wrote:
> This should get you started:
>
>> aggData <- aggregate(age~smoke+gender, sampleData, mean)
>> aggData
>    smoke gender      age
> 1     0      0 39.47231
> 2     1      0 40.09020
> 3     0      1 39.59814
> 4     1      1 42.04092
>> plotInfo <- barplot(aggData$age)
>> axis(1, c(0, plotInfo), c("Gender", "-", "-", "+", "+"), line=.75,
> + lwd=0, cex.axis=1.25, xpd=TRUE)
>> axis(1, c(0, plotInfo), c("Smoke", "-", "+", "-", "+"), line=2,
> + lwd=0, cex.axis=1.25, xpd=TRUE)
>
> To adapt it you will need to read the manual pages for barplot() and axis() and the page on graphical parameters par(). In particular, you will have to allocate more space at the bottom of the plot if you want to add more lines.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Olivier
> Sent: Monday, November 17, 2014 9:24 AM
> To: r-help at r-project.org
> Subject: [R] Help for x axis
>
> Hi,
> I want to customize x axis to scientific data. I do experiments with
> different triggers. As others publications, I want that there is one
> line for each trigger with the sign "-" or "+" to show if the trigger is
> used or no. You will find attached an exemple.
> Please find below a data.frame you could use to explain me.
> Thank you for your response,
> Olivier
>
>
>
> set.seed(3)
> sampleData <- data.frame(id = 1:100,gender = sample(c("0", "1"), 100,
> replace = TRUE), smoke = sample (c("0","1"), 100, replace=TRUE), age =
> rnorm(100, 40, 10))
> summary(sampleData)
>
> -> I want to give results with histograms or box.plot (age according to
> sex and smoking status)
> -> x axis may be like something like this :
>
> Gender        -          -         +        +
> Smoke         -          +        -         +
>
>


From h.wickham at gmail.com  Tue Nov 18 15:47:31 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 18 Nov 2014 08:47:31 -0600
Subject: [R] CMD check error
In-Reply-To: <58e5f6$jmrm78@ironport9.mayo.edu>
References: <58e5f6$jmrm78@ironport9.mayo.edu>
Message-ID: <CABdHhvFHMZk=aR_aE30a7M0bz1xrQMmK06Tyit7td9oKvUQpOQ@mail.gmail.com>

Do you have a .Rbuildignore? If so, what's in it?
Hadley

On Tue, Nov 18, 2014 at 7:07 AM, Therneau, Terry M., Ph.D.
<therneau at mayo.edu> wrote:
> I have a new package (local use only).  R CMD check fails with a messge I haven't seen before, and I haven't been able to guess the cause.
> There are two vignettes, both of which have %\VignetteIndexEntry lines.
>
> Same failure both under R-3.1.1 and R-devel, so it's me and not R.  Linux OS.
>
> Hints anyone?
>
> Terry Therneau
>
> =================================================
>
> tmt% R CMD build dart
> * preparing 'dart':
> * checking DESCRIPTION meta-information ... OK
> * installing the package to build vignettes
> * creating vignettes ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * looking to see if a 'data/datalist' file should be added
> * building 'dart_1.0-2.tar.gz'
>
> tmt% R CMD check dart*gz
> ...
> Installation failed.
> See '/people/biostat2/therneau/consult/bsi/dart.Rcheck ...
>
> tmt% more dart.Rcheck/00install.out
> ...
> ** installing vignettes
> Warning in file(con, "w") :
>    cannot open file '/people/biostat2/therneau/consult/bsi/dart.Rcheck/dart/doc/
> index.html': No such file or directory
> Error in file(con, "w") : cannot open the connection
> ERROR: installing vignettes failed
> * removing '/people/biostat2/therneau/consult/bsi/dart.Rcheck/dart'
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From h.wickham at gmail.com  Tue Nov 18 16:18:46 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 18 Nov 2014 09:18:46 -0600
Subject: [R] Implements XPath 2.0 in R
In-Reply-To: <CAJ_hwm8v+w8uKPp9LFdoz6edXNBFc8sAKWYgC-rO5fupCqz7WA@mail.gmail.com>
References: <CAJ_hwm8v+w8uKPp9LFdoz6edXNBFc8sAKWYgC-rO5fupCqz7WA@mail.gmail.com>
Message-ID: <CABdHhvHVoHPHxweprUdWjdAK8sYKpiwYq8a9FyK9k48GaYkpbQ@mail.gmail.com>

Why do you need from xpath 2.0?  It will almost certainly be easier to
implement similar functionality using a little R code than adding
xpath 2.0 support.

Hadley

On Mon, Nov 17, 2014 at 6:03 AM, Rees Morrison <rees at reesmorrison.com> wrote:
> Many users of R would like the enhanced extraction capabilities of XPath
> 2.0, but only XPath 1.0 is available..
>
> What would the best approach be to find someone to implement XPath 2.0 for
> R (assuming that is a good idea)?  What might the cost be and how would one
> set this package development in motion?
>
> Thanks
>
> --
> Rees Morrison
> General Counsel Metrics, LLC (management consulting and *data analytics*)
> 4 Hawthorne Ave.
> Princeton, NJ 08540-3840 USA
> (973) 568-9110
> Hosts www.lawdepartmentmanagementblog.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From fisher at plessthan.com  Tue Nov 18 16:23:41 2014
From: fisher at plessthan.com (Dennis Fisher)
Date: Tue, 18 Nov 2014 07:23:41 -0800
Subject: [R] duplicated function
Message-ID: <FC7C20DD-3754-4D9D-A5AF-04D4DFE7A4F4@plessthan.com>

R 3.1.1
OS X

Colleagues

When I use the duplicated function, I often need to find both the duplicates and the original element that was duplicated.  This can be accomplished with:
	duplicated(OBJECT) | duplicated(OBJECT, fromLast=TRUE)

>From my perspective, an improvement in the duplicated function would be an option that accomplishes this with a single call to the function.  This could either be:
	1.  a new option: all=TRUE (pick whatever name makes sense)
	2.  allowing fromLast to take a new value (e.g., NA, in the spirit of the xpd option in par())

If my suggestion would yield unintended consequences, it can certainly be ignored.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com




	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Nov 18 16:40:16 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Nov 2014 10:40:16 -0500
Subject: [R] duplicated function
In-Reply-To: <FC7C20DD-3754-4D9D-A5AF-04D4DFE7A4F4@plessthan.com>
References: <FC7C20DD-3754-4D9D-A5AF-04D4DFE7A4F4@plessthan.com>
Message-ID: <546B6860.40507@gmail.com>

On 18/11/2014 10:23 AM, Dennis Fisher wrote:
> R 3.1.1
> OS X
>
> Colleagues
>
> When I use the duplicated function, I often need to find both the duplicates and the original element that was duplicated.  This can be accomplished with:
> 	duplicated(OBJECT) | duplicated(OBJECT, fromLast=TRUE)
>
>  From my perspective, an improvement in the duplicated function would be an option that accomplishes this with a single call to the function.  This could either be:
> 	1.  a new option: all=TRUE (pick whatever name makes sense)
> 	2.  allowing fromLast to take a new value (e.g., NA, in the spirit of the xpd option in par())
>
> If my suggestion would yield unintended consequences, it can certainly be ignored.

The duplicated() function is pretty fast, so what's wrong with your 
original version?  If you find it to be too much typing, wouldn't it be 
simplest to write your own function, e.g.

nonunique <- function(x) duplicated(x) | duplicated(x, fromLast=TRUE)

?

Something I've wanted more than once is a variation on duplicated that 
returns the index of the duplicated element, so for example

dupindex(c(7,7,7,2,3,2))

would return

0 1 1 0 0 4

or possibly

1 1 1 4 5 4

Duncan Murdoch


From therneau at mayo.edu  Tue Nov 18 16:49:08 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 18 Nov 2014 09:49:08 -0600
Subject: [R] CMD check error
In-Reply-To: <CABdHhvFHMZk=aR_aE30a7M0bz1xrQMmK06Tyit7td9oKvUQpOQ@mail.gmail.com>
References: <58e5f6$jmrm78@ironport9.mayo.edu>
	<CABdHhvFHMZk=aR_aE30a7M0bz1xrQMmK06Tyit7td9oKvUQpOQ@mail.gmail.com>
Message-ID: <31062c$9cl5dj@ironport10.mayo.edu>

[Picture of a hand slapping forehead]
I suspected it to be something either dumb or obvious, and managed both.

This library plugs into the tail of a long developement project for a web API, which had 
prior documentation, which I stuck in "doc".  And then added to .Rbuildignore.

Thanks Hadley

Terry T.


On 11/18/2014 08:47 AM, Hadley Wickham wrote:
> Do you have a .Rbuildignore? If so, what's in it?
> Hadley
>
> On Tue, Nov 18, 2014 at 7:07 AM, Therneau, Terry M., Ph.D.
> <therneau at mayo.edu> wrote:
>> I have a new package (local use only).  R CMD check fails with a messge I haven't seen before, and I haven't been able to guess the cause.
>> There are two vignettes, both of which have %\VignetteIndexEntry lines.
>>
>> Same failure both under R-3.1.1 and R-devel, so it's me and not R.  Linux OS.
>>
>> Hints anyone?
>>
>> Terry Therneau
>>
>> =================================================
>>
>> tmt% R CMD build dart
>> * preparing 'dart':
>> * checking DESCRIPTION meta-information ... OK
>> * installing the package to build vignettes
>> * creating vignettes ... OK
>> * checking for LF line-endings in source and make files
>> * checking for empty or unneeded directories
>> * looking to see if a 'data/datalist' file should be added
>> * building 'dart_1.0-2.tar.gz'
>>
>> tmt% R CMD check dart*gz
>> ...
>> Installation failed.
>> See '/people/biostat2/therneau/consult/bsi/dart.Rcheck ...
>>
>> tmt% more dart.Rcheck/00install.out
>> ...
>> ** installing vignettes
>> Warning in file(con, "w") :
>>     cannot open file '/people/biostat2/therneau/consult/bsi/dart.Rcheck/dart/doc/
>> index.html': No such file or directory
>> Error in file(con, "w") : cannot open the connection
>> ERROR: installing vignettes failed
>> * removing '/people/biostat2/therneau/consult/bsi/dart.Rcheck/dart'
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From zilefacelvis at yahoo.com  Tue Nov 18 17:20:05 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 18 Nov 2014 16:20:05 +0000 (UTC)
Subject: [R] LAT/LON to UTM in R
Message-ID: <939705898.2064766.1416327605067.JavaMail.yahoo@jws106125.mail.bf1.yahoo.com>

Hi,
I am trying to convert lat/lon to UTM but my results are extremely flawed.
Is it because of wrong UTM zone or my lon points are negative?

I read a shapefile from ESRI using:
library(rgdal)
stations <- readOGR(".","stations")
print(proj4string(stations)) 
## +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
 How to convert to UTM the following lat/lon points? Reproducible example at the end.


library(sp) 

coordinates(xy) <- c("X", "Y") 
proj4string(xy) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")  ## for example 
res <- spTransform(xy, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")) 
res 
as(res, "SpatialPoints") 
x<-as(res, "SpatialPoints") 
xx<-as.data.frame(x) 

#OR

project(as.matrix(xy[,c("X","Y")]), "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
Everything goes wrong with the values.

Please help.



 

Zilefac.


From john.laing at gmail.com  Tue Nov 18 17:22:58 2014
From: john.laing at gmail.com (John Laing)
Date: Tue, 18 Nov 2014 11:22:58 -0500
Subject: [R] duplicated function
In-Reply-To: <546B6860.40507@gmail.com>
References: <FC7C20DD-3754-4D9D-A5AF-04D4DFE7A4F4@plessthan.com>
	<546B6860.40507@gmail.com>
Message-ID: <CAA3Wa=v=a2iu+S=9hQDFv6dehGx_y=12PiiU9caDWywGu-LW+A@mail.gmail.com>

That seems straightforward enough:
> x <- c(7, 7, 7, 2, 3, 2)
> match(x, x)
[1] 1 1 1 4 5 4
> ifelse(duplicated(x), match(x, x), 0)
[1] 0 1 1 0 0 4

On Tue, Nov 18, 2014 at 10:40 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 18/11/2014 10:23 AM, Dennis Fisher wrote:
>>
>> R 3.1.1
>> OS X
>>
>> Colleagues
>>
>> When I use the duplicated function, I often need to find both the
>> duplicates and the original element that was duplicated.  This can be
>> accomplished with:
>>         duplicated(OBJECT) | duplicated(OBJECT, fromLast=TRUE)
>>
>>  From my perspective, an improvement in the duplicated function would be
>> an option that accomplishes this with a single call to the function.  This
>> could either be:
>>         1.  a new option: all=TRUE (pick whatever name makes sense)
>>         2.  allowing fromLast to take a new value (e.g., NA, in the spirit
>> of the xpd option in par())
>>
>> If my suggestion would yield unintended consequences, it can certainly be
>> ignored.
>
>
> The duplicated() function is pretty fast, so what's wrong with your original
> version?  If you find it to be too much typing, wouldn't it be simplest to
> write your own function, e.g.
>
> nonunique <- function(x) duplicated(x) | duplicated(x, fromLast=TRUE)
>
> ?
>
> Something I've wanted more than once is a variation on duplicated that
> returns the index of the duplicated element, so for example
>
> dupindex(c(7,7,7,2,3,2))
>
> would return
>
> 0 1 1 0 0 4
>
> or possibly
>
> 1 1 1 4 5 4
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Nov 18 17:25:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Nov 2014 11:25:12 -0500
Subject: [R] duplicated function
In-Reply-To: <CAA3Wa=v=a2iu+S=9hQDFv6dehGx_y=12PiiU9caDWywGu-LW+A@mail.gmail.com>
References: <FC7C20DD-3754-4D9D-A5AF-04D4DFE7A4F4@plessthan.com>
	<546B6860.40507@gmail.com>
	<CAA3Wa=v=a2iu+S=9hQDFv6dehGx_y=12PiiU9caDWywGu-LW+A@mail.gmail.com>
Message-ID: <546B72E8.6070301@gmail.com>

On 18/11/2014 11:22 AM, John Laing wrote:
> That seems straightforward enough:
> > x <- c(7, 7, 7, 2, 3, 2)
> > match(x, x)
> [1] 1 1 1 4 5 4
> > ifelse(duplicated(x), match(x, x), 0)
> [1] 0 1 1 0 0 4

Nice solution!  Thanks.

Duncan Murdoch

> On Tue, Nov 18, 2014 at 10:40 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 18/11/2014 10:23 AM, Dennis Fisher wrote:
> >>
> >> R 3.1.1
> >> OS X
> >>
> >> Colleagues
> >>
> >> When I use the duplicated function, I often need to find both the
> >> duplicates and the original element that was duplicated.  This can be
> >> accomplished with:
> >>         duplicated(OBJECT) | duplicated(OBJECT, fromLast=TRUE)
> >>
> >>  From my perspective, an improvement in the duplicated function would be
> >> an option that accomplishes this with a single call to the function.  This
> >> could either be:
> >>         1.  a new option: all=TRUE (pick whatever name makes sense)
> >>         2.  allowing fromLast to take a new value (e.g., NA, in the spirit
> >> of the xpd option in par())
> >>
> >> If my suggestion would yield unintended consequences, it can certainly be
> >> ignored.
> >
> >
> > The duplicated() function is pretty fast, so what's wrong with your original
> > version?  If you find it to be too much typing, wouldn't it be simplest to
> > write your own function, e.g.
> >
> > nonunique <- function(x) duplicated(x) | duplicated(x, fromLast=TRUE)
> >
> > ?
> >
> > Something I've wanted more than once is a variation on duplicated that
> > returns the index of the duplicated element, so for example
> >
> > dupindex(c(7,7,7,2,3,2))
> >
> > would return
> >
> > 0 1 1 0 0 4
> >
> > or possibly
> >
> > 1 1 1 4 5 4
> >
> > Duncan Murdoch
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From lopez235 at llnl.gov  Tue Nov 18 17:32:32 2014
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 18 Nov 2014 16:32:32 +0000
Subject: [R] FW: Random Forest - Strata and sampsize and replace
Message-ID: <56180B40A4F72A4083C75B30DA8629733A8D3244@PRDEXMBX-05.the-lab.llnl.gov>

Hello R Experts,

I want to make sure I understand how the strata, sampsize and replace parameters work so I can confidently perform downsampling on a dataset I'm working with.

My main question is when the documentation talks about how each of these parameters (strata, sampsize, replace) works it is all per tree?  Below is my understanding...can you tell me if I have this correct?


table(iris$Species)



#    setosa versicolor  virginica

#        50         50         50

#default of replace is TRUE


#EACH tree uses a sample of 150. For a given tree since sampling w/ replacement is used it is possible that only one class is represented such as setosa i.e. each setosa observation is represented 3x.

randomForest(Species~.,data=iris)


# EACH tree uses a sample of 30 -- 10 from each class. Observations from each class may be repeated.
randomForest(Species~.,data=iris,sampsize=c(setosa=10,versicolor=10,virginica=10), strata=iris$Species)

# EACH tree uses a sample of 60 -- 10 from the 1st classs, 20 from the 2nd and 30 from the 3rd. Observations from each class may be repeated.
randomForest(Species~.,data=iris,sampsize=c(setosa=10,versicolor=20,virginica=30), strata=iris$Species)

Dan


	[[alternative HTML version deleted]]


From lopez235 at llnl.gov  Tue Nov 18 17:42:23 2014
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 18 Nov 2014 16:42:23 +0000
Subject: [R] Random Forest - Strata and sampsize and replace
Message-ID: <56180B40A4F72A4083C75B30DA8629733A8D3267@PRDEXMBX-05.the-lab.llnl.gov>

Hello R Experts,

I want to make sure I understand how the strata, sampsize and replace parameters work so I can confidently perform downsampling on a dataset I'm working with.

My main question is when the documentation talks about how each of these parameters (strata, sampsize, replace) works it is all per tree?  Below is my understanding...can you tell me if I have this correct?


table(iris$Species)



#    setosa versicolor  virginica

#        50         50         50

#default of replace is TRUE


#EACH tree uses a sample of 150. For a given tree since sampling w/ replacement is used it is possible that only one class is represented such as setosa i.e. each setosa observation is represented 3x.

randomForest(Species~.,data=iris)


# EACH tree uses a sample of 30 -- 10 from each class. Observations from each class may be repeated.
randomForest(Species~.,data=iris,sampsize=c(setosa=10,versicolor=10,virginica=10), strata=iris$Species)

# EACH tree uses a sample of 60 -- 10 from the 1st classs, 20 from the 2nd and 30 from the 3rd. Observations from each class may be repeated.
randomForest(Species~.,data=iris,sampsize=c(setosa=10,versicolor=20,virginica=30), strata=iris$Species)

Dan


	[[alternative HTML version deleted]]


From eshema4real at yahoo.com  Tue Nov 18 16:19:58 2014
From: eshema4real at yahoo.com (Eshema Imaledo)
Date: Tue, 18 Nov 2014 07:19:58 -0800
Subject: [R] HELP OUT
Message-ID: <1416323998.49870.YahooMailBasic@web161001.mail.bf1.yahoo.com>

Dear Sir/Ma,
I am a young  forest biometrician that adopted the method that consider how correlation within plot and between stand can be handled.
Actually i am working on modelling height-diameter relationship under different canopy layer using mixed model approach.
METHODOLOGY:
> Height and diameter measurement of tree under different canopy layer was taken at stand level.
>stand attributes such as quadratic mean diameter(Dq),mean height(Hm),dominant height(Ho),dominant diameter(Do),Basal area of the largest tree(BAL) were included in the selected models.
>I considered Dq,Hm,Ho,Do and BAL as the fixed component,and canopy layers as the random component.The canopy layer are tagged suppressed(4),intermediate(3),Co-dominant(2) and dominant(4)
>How do i analyse the fixed and random effect of this models.The models and example of data to be analysed are attached.
I will be grateful for  any suggestions and the command to run this analysis on R.

From maechler at stat.math.ethz.ch  Tue Nov 18 18:39:18 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 18 Nov 2014 18:39:18 +0100
Subject: [R] duplicated function
In-Reply-To: <546B6860.40507@gmail.com>
References: <FC7C20DD-3754-4D9D-A5AF-04D4DFE7A4F4@plessthan.com>
	<546B6860.40507@gmail.com>
Message-ID: <21611.33862.117345.106494@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Tue, 18 Nov 2014 10:40:16 -0500 writes:

    > On 18/11/2014 10:23 AM, Dennis Fisher wrote:
    >> R 3.1.1
    >> OS X
    >> 
    >> Colleagues
    >> 
    >> When I use the duplicated function, I often need to find both the duplicates and the original element that was duplicated.  This can be accomplished with:
    >> duplicated(OBJECT) | duplicated(OBJECT, fromLast=TRUE)
    >> 
    >> From my perspective, an improvement in the duplicated function would be an option that accomplishes this with a single call to the function.  This could either be:
    >> 1.  a new option: all=TRUE (pick whatever name makes sense)
    >> 2.  allowing fromLast to take a new value (e.g., NA, in the spirit of the xpd option in par())
    >> 
    >> If my suggestion would yield unintended consequences, it can certainly be ignored.

    > The duplicated() function is pretty fast, so what's wrong with your 
    > original version?  If you find it to be too much typing, wouldn't it be 
    > simplest to write your own function, e.g.

    > nonunique <- function(x) duplicated(x) | duplicated(x, fromLast=TRUE)

    > ?

    > Something I've wanted more than once is a variation on duplicated that 
    > returns the index of the duplicated element, so for example

    > dupindex(c(7,7,7,2,3,2))

    > would return

    > 0 1 1 0 0 4

    > or possibly

    > 1 1 1 4 5 4

    > Duncan Murdoch

In our CRAN package  'sfsmisc' (http://cran.r-project.org/web/packages/sfsmisc)
we have had a function Duplicated()
for a while now with the following "feature":

>      x <- c(9:12, 1:4, 3:6, 0:7)
>      data.frame(x, dup = duplicated(x),
+                    dupL= duplicated(x, fromLast=TRUE),
+                    Dup = Duplicated(x),
+                    DupL= Duplicated(x, fromLast=TRUE))

    x   dup  dupL Dup DupL
1   9 FALSE FALSE  NA   NA
2  10 FALSE FALSE  NA   NA
3  11 FALSE FALSE  NA   NA
4  12 FALSE FALSE  NA   NA
5   1 FALSE  TRUE   3    1
6   2 FALSE  TRUE   4    2
7   3 FALSE  TRUE   1    3
8   4 FALSE  TRUE   2    4
9   3  TRUE  TRUE   1    3
10  4  TRUE  TRUE   2    4
11  5 FALSE  TRUE   7    7
12  6 FALSE  TRUE   8    8
13  0 FALSE FALSE  NA   NA
14  1  TRUE FALSE   3    1
15  2  TRUE FALSE   4    2
16  3  TRUE FALSE   1    3
17  4  TRUE FALSE   2    4
18  5  TRUE FALSE   7    7
19  6  TRUE FALSE   8    8
20  7 FALSE FALSE  NA   NA
> 

---- help page --------------------------------------------------------

Duplicated               package:sfsmisc               R Documentation

Counting-Generalization of duplicated()

Description:

     Duplicated() generalizes the ?duplicated? method for vectors, by
     returning indices of ?equivalence classes? for duplicated entries
     and returning ?nomatch? (?NA? by default) for unique entries.

     Note that ?duplicated()? is not ?TRUE? for the first time a
     duplicate appears, whereas ?Duplicated()? only marks unique
     entries with ?nomatch? (?NA?).

Usage:

     Duplicated(v, incomparables = FALSE, fromLast = FALSE, nomatch = NA_integer_)
     
Arguments:

       v: a vector, often character, factor, or numeric.

incomparables: a vector of values that cannot be compared, passed to
          both ?duplicated()? and ?match()?.  ?FALSE? is a special
          value, meaning that all values can be compared, and may be
          the only value accepted for methods other than the default.
          It will be coerced internally to the same type as ?x?.

fromLast: logical indicating if duplication should be considered from
          the reverse side, i.e., the last (or rightmost) of identical
          elements would correspond to ?duplicated=FALSE?.

 nomatch: passed to ?match()?: the value to be returned in the case
          when no match is found.  Note that it is coerced to
          ?integer?.

Value:

     an integer vector of the same length as ?v?.  Can be used as a
     ?factor?, e.g., in ?split?, ?tapply?, etc.

Author(s):

     Christoph Buser and Martin Maechler, Seminar fuer Statistik, ETH
     Zurich, Sep.2007

See Also:

     ?uniqueL? (also in ?sfsmisc?); ?duplicated?, ?match?.

Examples:

     x <- c(9:12, 1:4, 3:6, 0:7)
     data.frame(x, dup = duplicated(x),
                   dupL= duplicated(x, fromLast=TRUE),
                   Dup = Duplicated(x),
                   DupL= Duplicated(x, fromLast=TRUE))


From kydaviddoyle at gmail.com  Tue Nov 18 22:42:22 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Tue, 18 Nov 2014 15:42:22 -0600
Subject: [R] Rose Diagrams for Geology
Message-ID: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>

Hello everyone,

In geology we often do rose diagrams showing the number of features along a
certain compass direction within a given range (bin) of angle (0-180
degrees).  I was wondering if anybody has had experience with this in R and
if they could recommend a package.

I looked at the circular package but it seems to deal only in radian and we
normally use degrees.

I've also looked a little at openair being rose diagrams are often used for
wind directions.

Any suggestions / guidance would be greatly appreciated.

Thank you for your time.
David Doyle

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Nov 18 22:55:38 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 18 Nov 2014 21:55:38 +0000
Subject: [R] Rose Diagrams for Geology
In-Reply-To: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>
References: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB329A@mb02.ads.tamu.edu>

Look at circular more carefully. It accepts both degrees and radians, but you have to create a circular object with circular() to specify what kind of circular data you have. Then you can plot and get circular statistics on your data.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David Doyle
Sent: Tuesday, November 18, 2014 3:42 PM
To: r-help at r-project.org
Subject: [R] Rose Diagrams for Geology

Hello everyone,

In geology we often do rose diagrams showing the number of features along a
certain compass direction within a given range (bin) of angle (0-180
degrees).  I was wondering if anybody has had experience with this in R and
if they could recommend a package.

I looked at the circular package but it seems to deal only in radian and we
normally use degrees.

I've also looked a little at openair being rose diagrams are often used for
wind directions.

Any suggestions / guidance would be greatly appreciated.

Thank you for your time.
David Doyle

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Nov 19 00:16:15 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 18 Nov 2014 15:16:15 -0800
Subject: [R] Rose Diagrams for Geology
In-Reply-To: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>
References: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>
Message-ID: <BABF13FF-F9ED-4DAF-9E53-A71FB5BE58E3@comcast.net>


On Nov 18, 2014, at 1:42 PM, David Doyle wrote:

> Hello everyone,
> 
> In geology we often do rose diagrams showing the number of features along a
> certain compass direction within a given range (bin) of angle (0-180
> degrees).  I was wondering if anybody has had experience with this in R and
> if they could recommend a package.
> 
> I looked at the circular package but it seems to deal only in radian and we
> normally use degrees.
> 
> I've also looked a little at openair being rose diagrams are often used for
> wind directions.
> 
> Any suggestions / guidance would be greatly appreciated.

Learn to search, Grasshopper.

Choose one of:
-----------------
install.packages("sos")
library(sos)
> findFn("rose diagram")
found 19 matches;  retrieving 1 page

Downloaded 14 links in 9 packages.

> unique( findFn("rose diagram")$Package )
found 19 matches;  retrieving 1 page

Downloaded 14 links in 9 packages.
[1] "circular"  "GEOmap"    "oce"       "CircStats" "plotrix"   "HistData" 
[7] "climatol"  "openair"   "xergm"  
--------------
OR use Rseek.org
------------
OR  http://stackoverflow.com/search?q=[r]+rose+diagram

-- 

> 
> Thank you for your time.
> David Doyle
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From evlizashel at gmail.com  Tue Nov 18 22:33:24 2014
From: evlizashel at gmail.com (=?UTF-8?B?0JXQstCz0LXQvdC40Y8t0JvQuNC30LAg0KjQtdC70Y7RhdC40L3QsA==?=)
Date: Wed, 19 Nov 2014 00:33:24 +0300
Subject: [R] R 3.1.2 (x64) Programming Assignment 1: Air Pollution(corr) do
 not understand the task
Message-ID: <CAGBsjjWhasPL4Y33xUZbAC9VavRMpDdps717Dn=Sc9_ZwzC7aA@mail.gmail.com>

Dear R experts,

I've submited  correctly "pollutionmean" and "complete" tasks, but "corr"
returns error, despite the beginning of the result is the same as example
output. (screenshot attached)

May be I understood the task wrongly; file of my function is attached, and
it does following:
1) sets directory
2) puts all files from the directory into one dataframe
3) removes NA values
4) creates zero vector "cr"
5) does the cycle:
         for each monitor location (id) counts number of cases "nmb"
         If "nmb" is more than threshold, calculates cor()
         puts cor() result into numeric vector "cr"
6) prints result as numeric vector

I have tried to change cor() function to the complex one with "method" etc,
tried to change "complete.cases" conditions, cycle structure, but it
doesn't help.
I think the reason is I understand task wrongly....
Please, tell me where Im wrong.

Thank you,
Eva

Best Regards,
Evgeniia-Liza Sheliukhina

From dwinsemius at comcast.net  Wed Nov 19 00:25:56 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 18 Nov 2014 15:25:56 -0800
Subject: [R] R 3.1.2 (x64) Programming Assignment 1: Air Pollution(corr)
	do not understand the task
In-Reply-To: <CAGBsjjWhasPL4Y33xUZbAC9VavRMpDdps717Dn=Sc9_ZwzC7aA@mail.gmail.com>
References: <CAGBsjjWhasPL4Y33xUZbAC9VavRMpDdps717Dn=Sc9_ZwzC7aA@mail.gmail.com>
Message-ID: <2456A204-9404-42DE-A688-AA85F141FD2C@comcast.net>

This is not the help forum for Coursera classes.

-- 
David.


On Nov 18, 2014, at 1:33 PM, ???????-???? ???????? wrote:

> Dear R experts,
> 
> I've submited  correctly "pollutionmean" and "complete" tasks, but "corr"
> returns error, despite the beginning of the result is the same as example
> output. (screenshot attached)
> 
> May be I understood the task wrongly; file of my function is attached, and
> it does following:
> 1) sets directory
> 2) puts all files from the directory into one dataframe
> 3) removes NA values
> 4) creates zero vector "cr"
> 5) does the cycle:
>         for each monitor location (id) counts number of cases "nmb"
>         If "nmb" is more than threshold, calculates cor()
>         puts cor() result into numeric vector "cr"
> 6) prints result as numeric vector
> 
> I have tried to change cor() function to the complex one with "method" etc,
> tried to change "complete.cases" conditions, cycle structure, but it
> doesn't help.
> I think the reason is I understand task wrongly....
> Please, tell me where Im wrong.
> 
> Thank you,
> Eva
> 
> Best Regards,
> Evgeniia-Liza Sheliukhina
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From upananda.pani at gmail.com  Wed Nov 19 04:42:29 2014
From: upananda.pani at gmail.com (Upananda Pani)
Date: Wed, 19 Nov 2014 09:12:29 +0530
Subject: [R] reading data using XTS package
Message-ID: <CAEezrQT5F4OS_XKZ6DC6iCMPHdHcMq99ba9-AC_RwUQz5Ae9Mg@mail.gmail.com>

Dear All,

I want to read the my time series data using XTS package and then to
calculate return using PeformanceAnalytics Package  but i am getting the
following error. Please help me to solve the problem. The error follows:

# Required Libraries
> library(xts)
> library(PerformanceAnalytics)
>
> #Reading Data
> x<-read.csv('crude.csv')
> y<-xts(x[,1:2],as.numeric(x[,2:2]),order.by
=as.Date(x[,1],format='%d-%b-%y'))
> close <- y$close
>
> #Calculating Return
> rspot = Return.calculate(close, method = c ("discrete"))
Error in `/.default`(pr, lag(pr)) :
  non-numeric argument to binary operator


I am not getting where i am committing the mistake.

With sincere regards,
Upananda

-- 


You may delay, but time will not.


Research Scholar
alternative mail id: upani at iitkgp.ac.in
Department of HSS, IIT KGP
KGP

From kydaviddoyle at gmail.com  Wed Nov 19 05:06:03 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Tue, 18 Nov 2014 22:06:03 -0600
Subject: [R] Rose Diagrams for Geology
In-Reply-To: <BABF13FF-F9ED-4DAF-9E53-A71FB5BE58E3@comcast.net>
References: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>
	<BABF13FF-F9ED-4DAF-9E53-A71FB5BE58E3@comcast.net>
Message-ID: <CACftpvqYVCVLU4bn0oA607SQLw7mVTO1ZW0hxaH0AHx-pKQk3Q@mail.gmail.com>

Thank you to David and David for their help.  The code below generated what
I needed.


library(circular)
mydata <- read.table("http://doylesdartden.com/R/Joints.csv", header=TRUE,
sep=",",)
x <- circular(mydata$JointsRad)
rose.diag(x,

          #Set point character to use
          pch = 20,
          #sets font size
          cex = 1,
          #parameter that controls the size of the circle.
          #1= default <1 makes it larger > makes it smaller
          shrink = 1,
          #the color for filling the rose diagram.
          col=2,
          prop = 2,
          # number of bins.  36 = 10 degrees each.  18 = 20 degree each
          bins=36,
          # Ticks showing bins
          ticks=TRUE,
          # Unites.
          units="degrees",
          # list main title
          main="Rose Diagram of XXX")
# for more info see
http://www.inside-r.org/packages/cran/circular/docs/rose.diag

Example of my data
JointsDegrees JointsRad
30 0.523598776
34 0.593411946
35 0.610865238
35 0.610865238
37 0.645771823
37 0.645771823


On Tue, Nov 18, 2014 at 5:16 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Nov 18, 2014, at 1:42 PM, David Doyle wrote:
>
> > Hello everyone,
> >
> > In geology we often do rose diagrams showing the number of features
> along a
> > certain compass direction within a given range (bin) of angle (0-180
> > degrees).  I was wondering if anybody has had experience with this in R
> and
> > if they could recommend a package.
> >
> > I looked at the circular package but it seems to deal only in radian and
> we
> > normally use degrees.
> >
> > I've also looked a little at openair being rose diagrams are often used
> for
> > wind directions.
> >
> > Any suggestions / guidance would be greatly appreciated.
>
> Learn to search, Grasshopper.
>
> Choose one of:
> -----------------
> install.packages("sos")
> library(sos)
> > findFn("rose diagram")
> found 19 matches;  retrieving 1 page
>
> Downloaded 14 links in 9 packages.
>
> > unique( findFn("rose diagram")$Package )
> found 19 matches;  retrieving 1 page
>
> Downloaded 14 links in 9 packages.
> [1] "circular"  "GEOmap"    "oce"       "CircStats" "plotrix"   "HistData"
> [7] "climatol"  "openair"   "xergm"
> --------------
> OR use Rseek.org
> ------------
> OR  http://stackoverflow.com/search?q=[r]+rose+diagram
>
> --
>
> >
> > Thank you for your time.
> > David Doyle
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From aps6dl at yahoo.com  Wed Nov 19 04:35:57 2014
From: aps6dl at yahoo.com (Aditya Singh)
Date: Wed, 19 Nov 2014 03:35:57 +0000 (UTC)
Subject: [R] R 3.1.2 (x64) Programming Assignment 1: Air Pollution(corr)
 do not understand the task
In-Reply-To: <CAGBsjjWhasPL4Y33xUZbAC9VavRMpDdps717Dn=Sc9_ZwzC7aA@mail.gmail.com>
References: <CAGBsjjWhasPL4Y33xUZbAC9VavRMpDdps717Dn=Sc9_ZwzC7aA@mail.gmail.com>
Message-ID: <91495342.2360461.1416368157352.JavaMail.yahoo@jws10653.mail.bf1.yahoo.com>

Eva and Professor Peng,

I spent many hours on Programming Assignment 1, however I was unable to get it right. I found it most useful and think others should work at it too!

Please do send me your work now that the deadline is over. Or you could tell me your Github account so that I could fork it? I will send you my work if you want!

Thanking you in advance,
Dr. Aditya P. Singh
8133/5 Stadium Road,
Patiala 147001 India.



On Wednesday, November 19, 2014 4:52 AM, ???????-???? ???????? <evlizashel at gmail.com> wrote:
Dear R experts,

I've submited  correctly "pollutionmean" and "complete" tasks, but "corr"
returns error, despite the beginning of the result is the same as example
output. (screenshot attached)

May be I understood the task wrongly; file of my function is attached, and
it does following:
1) sets directory
2) puts all files from the directory into one dataframe
3) removes NA values
4) creates zero vector "cr"
5) does the cycle:
         for each monitor location (id) counts number of cases "nmb"
         If "nmb" is more than threshold, calculates cor()
         puts cor() result into numeric vector "cr"
6) prints result as numeric vector

I have tried to change cor() function to the complex one with "method" etc,
tried to change "complete.cases" conditions, cycle structure, but it
doesn't help.
I think the reason is I understand task wrongly....
Please, tell me where Im wrong.

Thank you,
Eva

Best Regards,
Evgeniia-Liza Sheliukhina

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From amitmt at techmahindra.com  Wed Nov 19 10:47:48 2014
From: amitmt at techmahindra.com (Amit Thombre)
Date: Wed, 19 Nov 2014 15:17:48 +0530
Subject: [R] Using sapply instead of for loop
Message-ID: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>

I am trying to replace a for loop by using sapply, The code is for forecasting using arima. The code is as follows:-
-------------------------------------------------------
far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.

st=2013   # start year value for getting the time series
month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size

for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}
------------------------------------------------------------------
The sapply replaces the for loop
for (p in 1:Permax)
{
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima model
A[i,j,k,l,m,n,p]<-AIC(air.model)
f<- forecast(air.model,h=testsize1) # for getting the error
er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
}, error=function(e)
{

return(NA)
}
)
 cat("Value of error", er[i,j,k,l,m,n,p])
 cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
}
--------------------------------------------------------------------------
Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call to the function far() the array loses the previous value and gets replaced with NA and gets the newly calculated error value. Finally the array A gets populated with only the latest value and does not hold the old values. Please help


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From c.montgomery at sheffield.ac.uk  Wed Nov 19 12:38:47 2014
From: c.montgomery at sheffield.ac.uk (Chris Montgomery)
Date: Wed, 19 Nov 2014 11:38:47 +0000
Subject: [R] Mapping code not working
Message-ID: <CAAT4fzL+EzqCj-AwuyR3-vag=NqDp8qinrj7TFa+v2UM05DA5Q@mail.gmail.com>

I have a data frame of data I want to map. I've already created a base map
called 'England'. The data frame is as follows:

'data.frame':   2303 obs. of  13 variables:
 $ Response.ID: int  1 2 3 4 5 6 7 8 9 10 ...
 $ Year       : int  2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ...
 $ Sex        : Factor w/ 2 levels "f","m": 1 2 1 1 1 1 2 2 2 2 ...
 $ Ethnicity  : Factor w/ 6 levels "","Black","East Asian",..: 6 6 6 6 6 6
6 6 6 6 ...
 $ Age        : int  24 22 16 22 49 21 62 36 21 75 ...
 $ Age.Group  : Factor w/ 5 levels "> 80","16-20",..: 3 3 2 3 4 3 5 3 3 5
...
 $ Town       : Factor w/ 885 levels "Abbey Hey","Aberdare, Conwy",..: 781
259 421 259 229 92 836 276 594 276 ...
 $ Postcode   : Factor w/ 987 levels "AB10","AB16",..: 888 888 886 888 884
685 270 301 78 300 ...
 $ Region     : Factor w/ 11 levels "East Midlands",..: 9 9 9 9 9 9 9 9 9 9
...
 $ Latitude   : num  50.3 50.3 50.3 50.4 50.5 ...
 $ Longitude  : num  -3.66 -3.8 -3.61 -3.65 -3.52 ...
 $ Bread      : Factor w/ 8 levels "Bap","Barm","Batch",..: 7 7 1 7 7 7 7 7
7 6 ...
 $ Icon       : Factor w/ 8 levels "measle_brown",..: 2 2 1 2 2 2 2 2 2 8
...

The following command works on another similar data frame, but not on this
one.

>England+stat_bin2d(aes(x=Longitude,y=Latitude,color=factor(Bread$Bread),fill=factor(Bread$Bread)),size=.5,bins=200,alpha=.5,data=Bread)

It returns the following error:

Error in Bread$Sex : $ operator is invalid for atomic vectors

What am I doing wrong here? I'm new to R, so I'm not sure if this is easy
or difficult to solve.

Thanks in advance!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Nov 19 14:27:10 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 19 Nov 2014 05:27:10 -0800
Subject: [R] Mapping code not working
In-Reply-To: <CAAT4fzL+EzqCj-AwuyR3-vag=NqDp8qinrj7TFa+v2UM05DA5Q@mail.gmail.com>
References: <CAAT4fzL+EzqCj-AwuyR3-vag=NqDp8qinrj7TFa+v2UM05DA5Q@mail.gmail.com>
Message-ID: <B7836E48-D064-493D-9A0B-56CC76ECC122@dcn.davis.CA.us>

Your error references a column that is not mentioned in your sample line of code. . suggesting that something else is going on.

The usual advice applies, as the footer always says:

>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

One thing mentioned in the Posting Guide is that you should post in plain text, since HTML format can lead to confusion on our end (what you see is not necessarily what we see). You may also find [1] helpful in clarifying what reproducible means.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 19, 2014 3:38:47 AM PST, Chris Montgomery <c.montgomery at sheffield.ac.uk> wrote:
>I have a data frame of data I want to map. I've already created a base
>map
>called 'England'. The data frame is as follows:
>
>'data.frame':   2303 obs. of  13 variables:
> $ Response.ID: int  1 2 3 4 5 6 7 8 9 10 ...
>$ Year       : int  2013 2013 2013 2013 2013 2013 2013 2013 2013 2013
>...
> $ Sex        : Factor w/ 2 levels "f","m": 1 2 1 1 1 1 2 2 2 2 ...
>$ Ethnicity  : Factor w/ 6 levels "","Black","East Asian",..: 6 6 6 6 6
>6
>6 6 6 6 ...
> $ Age        : int  24 22 16 22 49 21 62 36 21 75 ...
>$ Age.Group  : Factor w/ 5 levels "> 80","16-20",..: 3 3 2 3 4 3 5 3 3
>5
>...
>$ Town       : Factor w/ 885 levels "Abbey Hey","Aberdare, Conwy",..:
>781
>259 421 259 229 92 836 276 594 276 ...
>$ Postcode   : Factor w/ 987 levels "AB10","AB16",..: 888 888 886 888
>884
>685 270 301 78 300 ...
>$ Region     : Factor w/ 11 levels "East Midlands",..: 9 9 9 9 9 9 9 9
>9 9
>...
> $ Latitude   : num  50.3 50.3 50.3 50.4 50.5 ...
> $ Longitude  : num  -3.66 -3.8 -3.61 -3.65 -3.52 ...
>$ Bread      : Factor w/ 8 levels "Bap","Barm","Batch",..: 7 7 1 7 7 7
>7 7
>7 6 ...
>$ Icon       : Factor w/ 8 levels "measle_brown",..: 2 2 1 2 2 2 2 2 2
>8
>...
>
>The following command works on another similar data frame, but not on
>this
>one.
>
>>England+stat_bin2d(aes(x=Longitude,y=Latitude,color=factor(Bread$Bread),fill=factor(Bread$Bread)),size=.5,bins=200,alpha=.5,data=Bread)
>
>It returns the following error:
>
>Error in Bread$Sex : $ operator is invalid for atomic vectors
>
>What am I doing wrong here? I'm new to R, so I'm not sure if this is
>easy
>or difficult to solve.
>
>Thanks in advance!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From deter088 at umn.edu  Wed Nov 19 14:35:52 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 19 Nov 2014 07:35:52 -0600
Subject: [R] Using sapply instead of for loop
In-Reply-To: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>
Message-ID: <CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>

Amit,

Your question isn't necessarily complete.  You haven't provided a
reproducible example of your data or an error message.  At first glance you
aren't passing anything to your 'far' function except for 'p' and yet it
uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid
global variables as they can lead to broken code.  You should redefine your
function with all the needed parameters and try again.

Regards,

On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com>
wrote:

> I am trying to replace a for loop by using sapply, The code is for
> forecasting using arima. The code is as follows:-
> -------------------------------------------------------
> far<-function(p)
> {
>
> cat("does it come here value of p", p)
> tryCatch({
> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima
> model
>
> f<- forecast(air.model,h=testsize1) # for getting the error
>
> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>
> }, error=function(e)
> {
>
> return(NA)
> }
> )
> cat("Value of error", ervalue[i,j,k,l,m,n,p])
> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
> print(ervalue)
> return(ervalue)
> }
> ---------------------------
> maxval=2  # set the array size as well as the maximum parameter value here.
> pmax=maxval  # set max p value of the ARIMA model
> dmax=maxval  # set max d value of the ARIMA model
> qmax=maxval  # set max q value of the ARIMA model
> Pmax=maxval  # set max P value of the ARIMA model
> Dmax=maxval  # set max D value of the ARIMA model
> Qmax=maxval  # set max Q value of the ARIMA model
> Permax=2     # maximum value of period.
>
> st=2013   # start year value for getting the time series
> month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23,
> 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as
> the time
>
> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
> on the max value set the , also it stores the AIC valuearray size
> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
> depdending on the max value set the , stores the error value.array size
>
> for (i in 1:pmax)
> {
> for (j in 1:dmax)
> {
> for (k in 1:qmax)
> {
> for (l in 1:Pmax)
> {
> for (m in 1:Dmax)
> {
> for (n in 1:Qmax)
> {
> A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>
> }
> }
> }
> }
> }  #for looping through period value
> }
> ------------------------------------------------------------------
> The sapply replaces the for loop
> for (p in 1:Permax)
> {
> cat("does it come here value of p", p)
> tryCatch({
> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
> seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima
> model
> A[i,j,k,l,m,n,p]<-AIC(air.model)
> f<- forecast(air.model,h=testsize1) # for getting the error
> er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
> }, error=function(e)
> {
>
> return(NA)
> }
> )
>  cat("Value of error", er[i,j,k,l,m,n,p])
>  cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
> }
> --------------------------------------------------------------------------
> Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call to
> the function far() the array loses the previous value and gets replaced
> with NA and gets the newly calculated error value. Finally the array A gets
> populated with only the latest value and does not hold the old values.
> Please help
>
>
>
> ============================================================================================================================
> Disclaimer:  This message and the information contained herein is
> proprietary and confidential and subject to the Tech Mahindra policy
> statement, you may review the policy at
> http://www.techmahindra.com/Disclaimer.html externally
> http://tim.techmahindra.com/tim/disclaimer.html internally within
> TechMahindra.
>
> ============================================================================================================================
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From i.petzev at gmail.com  Wed Nov 19 15:08:09 2014
From: i.petzev at gmail.com (i.petzev)
Date: Wed, 19 Nov 2014 15:08:09 +0100
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
	<B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
Message-ID: <79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>

Hi David,

thanks a lot for the response. I see that this works. I am not sure, however, what the appropriate way to do this is. It also works if you do not define weights in the boot() function (weighted bootstrap) but rather in the vw_m_diff function (ordinary bootstrap), i.e., 


vw_m_diff <- function(dataset,d) {
  differences <- dataset[d,1]-dataset[d,2]
  weights <- dataset[d, "weights"]
  return(weighted.mean(x=differences, w=weights))
}

with 

boot(dataset, statistic=vw_m_diff, R = 1000)

I guess this is rather a statistical question and hence I will have to look further into it. 

In any case, thanks a lot for your help.

Best



On 15 Nov 2014, at 17:27, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Nov 14, 2014, at 3:18 PM, David Winsemius wrote:
> 
>> 
>> On Nov 14, 2014, at 12:15 PM, ivan wrote:
>> 
>>> Hi,
>>> 
>>> I am trying to compute bootstrap confidence intervals for weighted means of
>>> paired differences with the boot package. Unfortunately, the weighted mean
>>> estimate lies out of the confidence bounds and hence I am obviously doing
>>> something wrong.
>>> 
>>> Appreciate any help. Thanks. Here is a reproducible example:
>>> 
>>> 
>>> library(boot)
>>> set.seed(1111)
>>> x <- rnorm(50)
>>> y <- rnorm(50)
>>> weights <- runif(50)
>>> weights <- weights / sum(weights)
>>> dataset <- cbind(x,y,weights)
>>> vw_m_diff <- function(dataset,w, d) {
>> 
>> My understanding of the principle underlying the design of the bootstrapped function was that the data was the first argument and the index vector was the second. (I admit to not knowing what it would do with a third argument. So I would have guessed that you wanted:
>> 
>> vw_m_diff <- function(dataset,w) {
>>    differences <- dataset[d,1]-dataset[d,2]
>>   weights <- dataset[w, "weights"]
>>   return(weighted.mean(x=differences, w=weights))
>> } 
> 
> I'm sorry. That was the code I first editted. This is the code that produced that output:
> 
> vw_m_diff <- function(dataset,w) {
>      differences <- dataset[w,1]-dataset[w,2]
>     weights <- dataset[w, "weights"]
>     return(weighted.mean(x=differences, w=weights))
>   }
> 
>> 
>> I get what appears to me as a sensible set of estimates (since they seem centered on zero) although I further admit I do not know what the theoretic CI _should_ be for this problem:
>> 
>>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
>>> boot.ci(res_boot)
>> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
>> Based on 1000 bootstrap replicates
>> 
>> CALL : 
>> boot.ci(boot.out = res_boot)
>> 
>> Intervals : 
>> Level      Normal              Basic         
>> 95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )  
>> 
>> Level     Percentile            BCa          
>> 95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )  
>> Calculations and Intervals on Original Scale
>> 
>> 
>>>  differences <- dataset[d,1]-dataset[d,2]
>>>  weights <- w[d]
>>>  return(weighted.mean(x=differences, w=weights))
>>> }
>>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
>>> boot.ci(res_boot)
>>> 
>>> *BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS*
>>> *Based on 1000 bootstrap replicates*
>>> 
>>> *CALL : *
>>> *boot.ci <http://boot.ci>(boot.out = res_boot)*
>>> 
>>> *Intervals : *
>>> *Level      Normal              Basic         *
>>> *95%   (-0.8365, -0.3463 )   (-0.8311, -0.3441 )  *
>>> 
>>> *Level     Percentile            BCa          *
>>> *95%   (-0.3276,  0.1594 )   (-0.4781, -0.3477 )  *
>>> 
>>> weighted.mean(x=dataset[,1]-dataset[,2], w=dataset[,3])
>>> 
>>> *[1] -0.07321734*
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA


	[[alternative HTML version deleted]]


From amitmt at techmahindra.com  Wed Nov 19 15:16:38 2014
From: amitmt at techmahindra.com (Amit Thombre)
Date: Wed, 19 Nov 2014 19:46:38 +0530
Subject: [R] Using sapply instead of for loop
In-Reply-To: <CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>,
	<CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
Message-ID: <4A753D3F0C227041AB666DA6283A81F313C5C3716C@SINPUNMBX002.TechMahindra.com>

Charles ,

I am not getting an error . The final array A does not have the values in it. Here is the reproducible code.  I have even tried using paasing ervalue as a parameter to the function far.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

errf<-function(act, res, testsize, flag)
{
j=1
if(flag==1)
{
j<-nrow(d)-testsize
}

print(act)
print(res)
print(flag)
diff<-0
s<-0
# loop for iterating to each value of the actual value and finding the difference with thepredicted value
for (mn in 1:length(act))
{
cat("Value of mn in err", mn)
cat("Value of j in err", j)
cat("Value of res[j] in err", res[j])
diff<-(act[mn]-res[j])
print(act[mn])
print(res[j])
print(diff)
s<-s+(diff*diff)

j<-j+1
}

er1<-sqrt(s/length(act)) #forecasting error
print(er1)
return(er1)
}



far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}





________________________________
From: Charles Determan Jr [deter088 at umn.edu]
Sent: Wednesday, November 19, 2014 7:05 PM
To: Amit Thombre
Cc: r-help at r-project.org
Subject: Re: [R] Using sapply instead of for loop

Amit,

Your question isn't necessarily complete.  You haven't provided a reproducible example of your data or an error message.  At first glance you aren't passing anything to your 'far' function except for 'p' and yet it uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid global variables as they can lead to broken code.  You should redefine your function with all the needed parameters and try again.

Regards,

On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
I am trying to replace a for loop by using sapply, The code is for forecasting using arima. The code is as follows:-
-------------------------------------------------------
far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.

st=2013   # start year value for getting the time series
month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size

for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}
------------------------------------------------------------------
The sapply replaces the for loop
for (p in 1:Permax)
{
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima model
A[i,j,k,l,m,n,p]<-AIC(air.model)
f<- forecast(air.model,h=testsize1) # for getting the error
er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
}, error=function(e)
{

return(NA)
}
)
 cat("Value of error", er[i,j,k,l,m,n,p])
 cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
}
--------------------------------------------------------------------------
Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call to the function far() the array loses the previous value and gets replaced with NA and gets the newly calculated error value. Finally the array A gets populated with only the latest value and does not hold the old values. Please help


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Dr. Charles Determan, PhD
Integrated Biosciences


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From ruimaximo at gmail.com  Wed Nov 19 15:22:24 2014
From: ruimaximo at gmail.com (Ruima E.)
Date: Wed, 19 Nov 2014 15:22:24 +0100
Subject: [R] Equivalent to matlab ".*" operator in R
Message-ID: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>

Hi,

I have this:

y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
z = matrix(c(12, -6),ncol=2)

In matlab I would do this

> y .* x

I would get this in matlab

> ans
0    -0
6    -3
12   -6

What is the equivalent in R?

Thanks

	[[alternative HTML version deleted]]


From amitmt at techmahindra.com  Wed Nov 19 15:23:12 2014
From: amitmt at techmahindra.com (Amit Thombre)
Date: Wed, 19 Nov 2014 19:53:12 +0530
Subject: [R] Using sapply instead of for loop
In-Reply-To: <CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>,
	<CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
Message-ID: <4A753D3F0C227041AB666DA6283A81F313C5C3716D@SINPUNMBX002.TechMahindra.com>

If I pass all the variables to the function in the following way then I get the following error "Error in cat("Value of error", ervalue[i, j, k, l, m, n, p]) :
  argument "ervalue" is missing, with no default. Finally the A array should have all the root mean square value calculated for each run which is missing even using global variables and even using the variables paaed to t afunction( I get the error so the code does not fill A)



----------------------------------------------------------------

errf<-function(act, res, testsize, flag)
{

j=1
if(flag==1)
{
j<-nrow(d)-testsize
}

print(act)
print(res)
print(flag)

diff<-0
s<-0

# loop for iterating to each value of the actual value and finding the difference with thepredicted value
for (mn in 1:length(act))
{

cat("Value of mn in err", mn)
cat("Value of j in err", j)
cat("Value of res[j] in err", res[j])

diff<-(act[mn]-res[j])
print(act[mn])
print(res[j])
print(diff)
s<-s+(diff*diff)

j<-j+1

}

er1<-sqrt(s/length(act)) #forecasting error
print(er1)
return(er1)

}

far<-function(p, i, j, k, l, m, n, ervalue)
{

cat("does it come here value of p", p)

tryCatch({

air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error



ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)

{

return(NA)

}

)

cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}

---------------------------
library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')





maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.

freq=12
d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time



A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{

A<-sapply((1:Permax),function(p, i, j, k, l, m, n, ervalue) far(p, i, j, k, l, m,n, ervalue),simplify=FALSE)



}

}

}

}

}  #for looping through period value

}
------------------------------------------------------------------
The sapply replaces the for loop
for (p in 1:Permax)
{

cat("does it come here value of p", p)

tryCatch({

air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima model

A[i,j,k,l,m,n,p]<-AIC(air.model)

f<- forecast(air.model,h=testsize1) # for getting the error

er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)

{

return(NA)

}

)
 cat("Value of error", er[i,j,k,l,m,n,p])
 cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)

}








________________________________
From: Charles Determan Jr [deter088 at umn.edu]
Sent: Wednesday, November 19, 2014 7:05 PM
To: Amit Thombre
Cc: r-help at r-project.org
Subject: Re: [R] Using sapply instead of for loop

Amit,

Your question isn't necessarily complete.  You haven't provided a reproducible example of your data or an error message.  At first glance you aren't passing anything to your 'far' function except for 'p' and yet it uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid global variables as they can lead to broken code.  You should redefine your function with all the needed parameters and try again.

Regards,

On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
I am trying to replace a for loop by using sapply, The code is for forecasting using arima. The code is as follows:-
-------------------------------------------------------
far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.

st=2013   # start year value for getting the time series
month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size

for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}
------------------------------------------------------------------
The sapply replaces the for loop
for (p in 1:Permax)
{
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima model
A[i,j,k,l,m,n,p]<-AIC(air.model)
f<- forecast(air.model,h=testsize1) # for getting the error
er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
}, error=function(e)
{

return(NA)
}
)
 cat("Value of error", er[i,j,k,l,m,n,p])
 cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
}
--------------------------------------------------------------------------
Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call to the function far() the array loses the previous value and gets replaced with NA and gets the newly calculated error value. Finally the array A gets populated with only the latest value and does not hold the old values. Please help


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Dr. Charles Determan, PhD
Integrated Biosciences


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From ruimaximo at gmail.com  Wed Nov 19 15:43:55 2014
From: ruimaximo at gmail.com (Ruima E.)
Date: Wed, 19 Nov 2014 15:43:55 +0100
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <546CAA9D.3010909@mail.usask.ca>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<546CAA9D.3010909@mail.usask.ca>
Message-ID: <CAJYLPFdTPRYUH4e=fdmYAM6=OMuzWm62CKQmef4tpHaTmV-EGw@mail.gmail.com>

Thank you Chel Hee.

Isn't there a simpler way to do so?


On Wed, Nov 19, 2014 at 3:35 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>> z = matrix(c(12, -6),ncol=2)
>> t(apply(y, 1, function(x) x*z))
>      [,1] [,2]
> [1,]    0    0
> [2,]    6   -3
> [3,]   12   -6
>
> I hope this helps.
>
> Chel Hee Lee
>
> On 14-11-19 08:22 AM, Ruima E. wrote:
>> Hi,
>>
>> I have this:
>>
>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>> z = matrix(c(12, -6),ncol=2)
>>
>> In matlab I would do this
>>
>>> y .* x
>> I would get this in matlab
>>
>>> ans
>> 0    -0
>> 6    -3
>> 12   -6
>>
>> What is the equivalent in R?
>>
>> Thanks
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From bhh at xs4all.nl  Wed Nov 19 15:50:03 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 19 Nov 2014 15:50:03 +0100
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
Message-ID: <2257487D-EFDD-4F13-BF12-A03A9B1AEC47@xs4all.nl>


On 19-11-2014, at 15:22, Ruima E. <ruimaximo at gmail.com> wrote:

> Hi,
> 
> I have this:
> 
> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
> z = matrix(c(12, -6),ncol=2)
> 
> In matlab I would do this
> 
>> y .* x
> 
> I would get this in matlab
> 
>> ans
> 0    -0
> 6    -3
> 12   -6
> 
> What is the equivalent in R?
> 

One way of doing this could be:

y * rep(z,1,each=nrow(y))

Berend

> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From josh.m.ulrich at gmail.com  Wed Nov 19 15:52:29 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 19 Nov 2014 08:52:29 -0600
Subject: [R] reading data using XTS package
In-Reply-To: <CAEezrQT5F4OS_XKZ6DC6iCMPHdHcMq99ba9-AC_RwUQz5Ae9Mg@mail.gmail.com>
References: <CAEezrQT5F4OS_XKZ6DC6iCMPHdHcMq99ba9-AC_RwUQz5Ae9Mg@mail.gmail.com>
Message-ID: <CAPPM_gS=EszX3ocOkFNREUraEeG+DsQ0=nQ+b+HXc4Nk4S6fZg@mail.gmail.com>

On Tue, Nov 18, 2014 at 9:42 PM, Upananda Pani <upananda.pani at gmail.com> wrote:
> Dear All,
>
> I want to read the my time series data using XTS package and then to
> calculate return using PeformanceAnalytics Package  but i am getting the
> following error. Please help me to solve the problem. The error follows:
>
> # Required Libraries
>> library(xts)
>> library(PerformanceAnalytics)
>>
>> #Reading Data
>> x<-read.csv('crude.csv')
>> y<-xts(x[,1:2],as.numeric(x[,2:2]),order.by
> =as.Date(x[,1],format='%d-%b-%y'))
>> close <- y$close
>>
>> #Calculating Return
>> rspot = Return.calculate(close, method = c ("discrete"))
> Error in `/.default`(pr, lag(pr)) :
>   non-numeric argument to binary operator
>
>
> I am not getting where i am committing the mistake.
>
I'm not sure what you were trying to do, because:
1) You didn't provide a reproducible example (I don't have 'crude.csv'), and
2) it doesn't make sense to use unnamed arguments for the first two
arguments, and then use a named argument to re-specify the second
argument (order.by).

You probably wanted something like:
close <- xts(x[,2], as.Date(x[,1], format='%d-%b-%y'))

> With sincere regards,
> Upananda
>
> --
>
>
> You may delay, but time will not.
>
>
> Research Scholar
> alternative mail id: upani at iitkgp.ac.in
> Department of HSS, IIT KGP
> KGP
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From jvadams at usgs.gov  Wed Nov 19 15:53:18 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 19 Nov 2014 08:53:18 -0600
Subject: [R] LAT/LON to UTM in R
In-Reply-To: <939705898.2064766.1416327605067.JavaMail.yahoo@jws106125.mail.bf1.yahoo.com>
References: <939705898.2064766.1416327605067.JavaMail.yahoo@jws106125.mail.bf1.yahoo.com>
Message-ID: <CAN5YmCHOnYabMGf4e1uPiJt5Mf1wgthw=Fsv_E7PirUZOz4hDw@mail.gmail.com>

Zilefac,

I tried to run your "reproducible" code, but you didn't provide an object
"xy".

Jean

On Tue, Nov 18, 2014 at 10:20 AM, Zilefac Elvis <zilefacelvis at yahoo.com>
wrote:

> Hi,
> I am trying to convert lat/lon to UTM but my results are extremely flawed.
> Is it because of wrong UTM zone or my lon points are negative?
>
> I read a shapefile from ESRI using:
> library(rgdal)
> stations <- readOGR(".","stations")
> print(proj4string(stations))
> ## +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
>  How to convert to UTM the following lat/lon points? Reproducible example
> at the end.
>
>
> library(sp)
>
> coordinates(xy) <- c("X", "Y")
> proj4string(xy) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
> +no_defs")  ## for example
> res <- spTransform(xy, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
> +no_defs"))
> res
> as(res, "SpatialPoints")
> x<-as(res, "SpatialPoints")
> xx<-as.data.frame(x)
>
> #OR
>
> project(as.matrix(xy[,c("X","Y")]), "+proj=longlat +ellps=WGS84
> +datum=WGS84 +no_defs")
> Everything goes wrong with the values.
>
> Please help.
>
>
>
>
>
> Zilefac.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Nov 19 15:58:55 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 19 Nov 2014 09:58:55 -0500
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <2257487D-EFDD-4F13-BF12-A03A9B1AEC47@xs4all.nl>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<2257487D-EFDD-4F13-BF12-A03A9B1AEC47@xs4all.nl>
Message-ID: <CA+vqiLGqnLRdW1aBLcOj_wJ_61xEBkXw5T04nfDq=K5HP=cXwA@mail.gmail.com>

On Wed, Nov 19, 2014 at 9:50 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
> On 19-11-2014, at 15:22, Ruima E. <ruimaximo at gmail.com> wrote:
>
>> Hi,
>>
>> I have this:
>>
>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>> z = matrix(c(12, -6),ncol=2)
>>
>> In matlab I would do this
>>
>>> y .* x
>>
>> I would get this in matlab
>>
>>> ans
>> 0    -0
>> 6    -3
>> 12   -6
>>
>> What is the equivalent in R?
>>
>
> One way of doing this could be:
>
> y * rep(z,1,each=nrow(y))

another is

t(t(y) * as.vector(z))

--Ista

>
> Berend
>
>> Thanks
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zilefacelvis at yahoo.com  Wed Nov 19 16:05:28 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 19 Nov 2014 15:05:28 +0000 (UTC)
Subject: [R] LAT/LON to UTM in R
In-Reply-To: <CAN5YmCHOnYabMGf4e1uPiJt5Mf1wgthw=Fsv_E7PirUZOz4hDw@mail.gmail.com>
References: <CAN5YmCHOnYabMGf4e1uPiJt5Mf1wgthw=Fsv_E7PirUZOz4hDw@mail.gmail.com>
Message-ID: <729646660.2587209.1416409528371.JavaMail.yahoo@jws10657.mail.bf1.yahoo.com>

Hi Admas,Sorry I missed out the reproducible example.Here it is:
dput(xy)structure(list(ID = 1:120, X = c(-102.6, -101.9, -97.1, -97,?-95.7, -99.1, -100.1, -97.2, -97, -99.3, -96, -95.2, -98.8, -98.1,?-99.6, -97.8, -96.1, -98.3, -95.6, -96.8, -101.2, -101.1, -97.2,?-111.1, -111.2, -116, -117.6, -103.7, -107.1, -102.3, -105.6,?-105.3, -108.5, -103.2, -94.1, -101.9, -94.7, -101.1, -97.9,?-111.4, -111.2, -110.5, -111.3, -107.3, -102.3, -104.7, -106.7,?-101.8, -106, -103, -107.9, -103.7, -103.8, -109.2, -108.9, -109.5,?-102.1, -104.6, -105.6, -101.7, -104, -108.3, -107.1, -103.9,?-105.2, -105.7, -104.7, -106.7, -108.8, -107.7, -102.2, -107.8,?-109.4, -106.1, -106.4, -104.2, -101.1, -99.9, -99.7, -101.3,?-113.3, -119.4, -113.8, -114.7, -112.8, -110.3, -113.6, -111.1,?-116.3, -118.5, -118.9, -117.4, -111.7, -114.1, -114.8, -113.8,?-115.8, -108.4, -109.1, -115.6, -114.2, -114, -113.4, -113.7,?-114.5, -112.9, -116.4, -113.1, -114.4, -117.5, -118, -113.8,?-112.8, -110.7, -113.6, -114.1, -114, -114.9, -112.7, -112.1),?? ? Y = c(52.88, 52.08, 50.93, 52.35, 51.03, 49.55, 51.1, 49,?? ? 50.63, 53.15, 50.47, 49.62, 50.42, 49.18, 50.15, 53.97, 50.18,?? ? 49.95, 49.02, 49.53, 52.12, 53.97, 49.92, 58.77, 56.65, 58.38,?? ? 57.75, 58.18, 57.35, 55.53, 57.25, 55.15, 59.57, 56.23, 58.73,?? ? 54.77, 56.35, 56.87, 55.8, 52.07, 50.72, 49.12, 51.58, 49.72,?? ? 50.9, 49.38, 50.47, 51.52, 51.27, 49.22, 50.98, 50.55, 51.25,?? ? 51.52, 49.68, 50.9, 49.62, 52.82, 50.33, 50.13, 53.33, 52.77,?? ? 51.48, 51.98, 52.42, 53.22, 50.43, 52.17, 52.37, 50.27, 51.2,?? ? 49.37, 53.13, 53.92, 49, 49.82, 50.43, 49.92, 49.42, 49.18,?? ? 54.72, 55.2, 53.28, 54.13, 53.03, 54.42, 53.32, 53.88, 55.42,?? ? 56.08, 55.18, 56.23, 53.42, 53.88, 55.28, 55.97, 54.15, 55.83,?? ? 54.05, 51.2, 49.47, 51.12, 49, 49.93, 49.63, 51.47, 53.58,?? ? 50.88, 50.55, 53.4, 52.93, 52.45, 49.63, 50.02, 49.13, 51.78,?? ? 49.52, 52.42, 52.33, 50.05)), .Names = c("ID", "X", "Y"), row.names = c(NA,?-120L), class = "data.frame")

	[[alternative HTML version deleted]]


From deter088 at umn.edu  Wed Nov 19 16:10:31 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 19 Nov 2014 09:10:31 -0600
Subject: [R] Using sapply instead of for loop
In-Reply-To: <4A753D3F0C227041AB666DA6283A81F313C5C3716C@SINPUNMBX002.TechMahindra.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>
	<CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716C@SINPUNMBX002.TechMahindra.com>
Message-ID: <CAOLJphmJO4vPZbcHadarSWdrXjgxtKvgBb_508df5tp4RaGgjQ@mail.gmail.com>

Amit,

Even if you aren't getting an error with your original global variables it
is far better practice to avoid global variables to make you code much more
stable.  Of course you ultimately get to decide how your code is written.

That said, your error from the modified far function to include the
variables is because you added too much to the sapply statement.  Here is
what it should look like:

            A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n,
ervalue),simplify=FALSE)

You can think apply statements as nothing more than a for loop that has
been made 'pretty'.  You wanted to iterate from 1:Permax and use the other
variables, therefore you only have the anonymous function (i.e.
function(p)) only include the iterator and supply the other values from
your nested for loops to the function.  When I run this with you code,
making sure the function accepts the extra parameters, the A array appears
to fill appropriately whereby most are 'NA' as specified by your 'far'
function.  Is this what you expect?


On Wed, Nov 19, 2014 at 8:16 AM, Amit Thombre <amitmt at techmahindra.com>
wrote:

>  Charles ,
>
> I am not getting an error . The final array A does not have the values in
> it. Here is the reproducible code.  I have even tried using paasing ervalue
> as a parameter to the function far.
>
>
> -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> errf<-function(act, res, testsize, flag)
> {
> j=1
> if(flag==1)
> {
> j<-nrow(d)-testsize
> }
>
> print(act)
> print(res)
> print(flag)
> diff<-0
> s<-0
> # loop for iterating to each value of the actual value and finding the
> difference with thepredicted value
> for (mn in 1:length(act))
> {
> cat("Value of mn in err", mn)
> cat("Value of j in err", j)
> cat("Value of res[j] in err", res[j])
> diff<-(act[mn]-res[j])
> print(act[mn])
> print(res[j])
> print(diff)
> s<-s+(diff*diff)
>
> j<-j+1
> }
>
> er1<-sqrt(s/length(act)) #forecasting error
> print(er1)
> return(er1)
> }
>
>
>
> far<-function(p)
> {
>
> cat("does it come here value of p", p)
> tryCatch({
> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima
> model
>
> f<- forecast(air.model,h=testsize1) # for getting the error
>
> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>
> }, error=function(e)
> {
>
> return(NA)
> }
> )
> cat("Value of error", ervalue[i,j,k,l,m,n,p])
> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
> print(ervalue)
> return(ervalue)
> }
> ---------------------------
> library('TTR')
> library('forecast')
> library('timeSeries')
> library('xts')
> library('RODBC')
>
>
> maxval=2  # set the array size as well as the maximum parameter value here.
> pmax=maxval  # set max p value of the ARIMA model
> dmax=maxval  # set max d value of the ARIMA model
> qmax=maxval  # set max q value of the ARIMA model
> Pmax=maxval  # set max P value of the ARIMA model
> Dmax=maxval  # set max D value of the ARIMA model
> Qmax=maxval  # set max Q value of the ARIMA model
> Permax=2     # maximum value of period.
> freq=12
> d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18,
> 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
> st=2013   # start year value for getting the time series
> month=4
> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as
> the time
>
> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
> on the max value set the , also it stores the AIC valuearray size
> er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending
> on the max value set the , stores the error value.array size
> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
> depdending on the max value set the , stores the error value.array size
> erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
> depdending on the max value set the , stores the error value.array size
> for (i in 1:pmax)
> {
> for (j in 1:dmax)
> {
> for (k in 1:qmax)
> {
> for (l in 1:Pmax)
> {
> for (m in 1:Dmax)
> {
> for (n in 1:Qmax)
> {
> A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>
> }
> }
> }
> }
> }  #for looping through period value
> }
>
>
>
>
>
>  ------------------------------
> *From:* Charles Determan Jr [deter088 at umn.edu]
> *Sent:* Wednesday, November 19, 2014 7:05 PM
> *To:* Amit Thombre
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] Using sapply instead of for loop
>
>   Amit,
>
>  Your question isn't necessarily complete.  You haven't provided a
> reproducible example of your data or an error message.  At first glance you
> aren't passing anything to your 'far' function except for 'p' and yet it
> uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid
> global variables as they can lead to broken code.  You should redefine your
> function with all the needed parameters and try again.
>
>  Regards,
>
> On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com>
> wrote:
>
>> I am trying to replace a for loop by using sapply, The code is for
>> forecasting using arima. The code is as follows:-
>> -------------------------------------------------------
>> far<-function(p)
>> {
>>
>> cat("does it come here value of p", p)
>> tryCatch({
>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima
>> model
>>
>> f<- forecast(air.model,h=testsize1) # for getting the error
>>
>> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>>
>> }, error=function(e)
>> {
>>
>> return(NA)
>> }
>> )
>> cat("Value of error", ervalue[i,j,k,l,m,n,p])
>> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>> print(ervalue)
>> return(ervalue)
>> }
>> ---------------------------
>> maxval=2  # set the array size as well as the maximum parameter value
>> here.
>> pmax=maxval  # set max p value of the ARIMA model
>> dmax=maxval  # set max d value of the ARIMA model
>> qmax=maxval  # set max q value of the ARIMA model
>> Pmax=maxval  # set max P value of the ARIMA model
>> Dmax=maxval  # set max D value of the ARIMA model
>> Qmax=maxval  # set max Q value of the ARIMA model
>> Permax=2     # maximum value of period.
>>
>> st=2013   # start year value for getting the time series
>> month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23,
>> 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
>> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa
>> as  the time
>>
>> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
>> on the max value set the , also it stores the AIC valuearray size
>> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>> depdending on the max value set the , stores the error value.array size
>>
>> for (i in 1:pmax)
>> {
>> for (j in 1:dmax)
>> {
>> for (k in 1:qmax)
>> {
>> for (l in 1:Pmax)
>> {
>> for (m in 1:Dmax)
>> {
>> for (n in 1:Qmax)
>> {
>> A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>>
>> }
>> }
>> }
>> }
>> }  #for looping through period value
>> }
>> ------------------------------------------------------------------
>> The sapply replaces the for loop
>> for (p in 1:Permax)
>> {
>> cat("does it come here value of p", p)
>> tryCatch({
>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>> seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima
>> model
>> A[i,j,k,l,m,n,p]<-AIC(air.model)
>> f<- forecast(air.model,h=testsize1) # for getting the error
>> er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>> }, error=function(e)
>> {
>>
>> return(NA)
>> }
>> )
>>  cat("Value of error", er[i,j,k,l,m,n,p])
>>  cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>> }
>> --------------------------------------------------------------------------
>> Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call
>> to the function far() the array loses the previous value and gets replaced
>> with NA and gets the newly calculated error value. Finally the array A gets
>> populated with only the latest value and does not hold the old values.
>> Please help
>>
>>
>>
>> ============================================================================================================================
>> Disclaimer:  This message and the information contained herein is
>> proprietary and confidential and subject to the Tech Mahindra policy
>> statement, you may review the policy at
>> http://www.techmahindra.com/Disclaimer.html externally
>> http://tim.techmahindra.com/tim/disclaimer.html internally within
>> TechMahindra.
>>
>> ============================================================================================================================
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>  --
>  Dr. Charles Determan, PhD
> Integrated Biosciences
>
> ------------------------------
>
> ============================================================================================================================
> Disclaimer: This message and the information contained herein is
> proprietary and confidential and subject to the Tech Mahindra policy
> statement, you may review the policy at
> http://www.techmahindra.com/Disclaimer.html externally
> http://tim.techmahindra.com/tim/disclaimer.html internally within
> TechMahindra.
>
> ============================================================================================================================
>
>


-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Nov 19 16:24:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 19 Nov 2014 07:24:48 -0800
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <CAJYLPFdTPRYUH4e=fdmYAM6=OMuzWm62CKQmef4tpHaTmV-EGw@mail.gmail.com>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<546CAA9D.3010909@mail.usask.ca>
	<CAJYLPFdTPRYUH4e=fdmYAM6=OMuzWm62CKQmef4tpHaTmV-EGw@mail.gmail.com>
Message-ID: <428BE3D9-9041-4383-9061-03B593002787@dcn.davis.CA.us>

When your matrices are the same size, the "*" operator does what you want. The problem is that you have to make a conforming version of z before you can use that operator.

y*matrix(rep(z,3),ncol=2,byrow=TRUE)

or

y*matrix(rep(z,each=3),ncol=2)

To interpret this, just keep in mind that matrices are folded vectors in R... every matrix can be thought of as a linear vector of columnwise data with dimension attributes.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 19, 2014 6:43:55 AM PST, "Ruima E." <ruimaximo at gmail.com> wrote:
>Thank you Chel Hee.
>
>Isn't there a simpler way to do so?
>
>
>On Wed, Nov 19, 2014 at 3:35 PM, Chel Hee Lee <chl948 at mail.usask.ca>
>wrote:
>>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>>> z = matrix(c(12, -6),ncol=2)
>>> t(apply(y, 1, function(x) x*z))
>>      [,1] [,2]
>> [1,]    0    0
>> [2,]    6   -3
>> [3,]   12   -6
>>
>> I hope this helps.
>>
>> Chel Hee Lee
>>
>> On 14-11-19 08:22 AM, Ruima E. wrote:
>>> Hi,
>>>
>>> I have this:
>>>
>>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>>> z = matrix(c(12, -6),ncol=2)
>>>
>>> In matlab I would do this
>>>
>>>> y .* x
>>> I would get this in matlab
>>>
>>>> ans
>>> 0    -0
>>> 6    -3
>>> 12   -6
>>>
>>> What is the equivalent in R?
>>>
>>> Thanks
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From amitmt at techmahindra.com  Wed Nov 19 16:46:01 2014
From: amitmt at techmahindra.com (Amit Thombre)
Date: Wed, 19 Nov 2014 21:16:01 +0530
Subject: [R] Using sapply instead of for loop
In-Reply-To: <CAOLJphmJO4vPZbcHadarSWdrXjgxtKvgBb_508df5tp4RaGgjQ@mail.gmail.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>
	<CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716C@SINPUNMBX002.TechMahindra.com>,
	<CAOLJphmJO4vPZbcHadarSWdrXjgxtKvgBb_508df5tp4RaGgjQ@mail.gmail.com>
Message-ID: <4A753D3F0C227041AB666DA6283A81F313C5C3716E@SINPUNMBX002.TechMahindra.com>

Charles,

Some variables were missing in the code. I have put them in this code. Now what happens is the value of cat("Value of error", ervalue[i,j,k,l,m,n,p]) gives error value for various runs but they are not in the final Array A. You will have to go through the runs carefully. The array ervalue which is printed shows the value only for that run with previous values as NA. It is like with every new value of p the previous values of ervalue are lost. Just for confirmation the A and ervalue array has the last value as 3.212016. This si just for information so that you can confirm if you are getting this value.
----------------------------------------------------------------------------------------------

errf<-function(act, res, testsize, flag)
{
j=1
if(flag==1)
{
j<-nrow(d)-testsize
}

print(act)
print(res)
print(flag)
diff<-0
s<-0
# loop for iterating to each value of the actual value and finding the difference with thepredicted value
for (mn in 1:length(act))
{
cat("Value of mn in err", mn)
cat("Value of j in err", j)
cat("Value of res[j] in err", res[j])
diff<-(act[mn]-res[j])
print(act[mn])
print(res[j])
print(diff)
s<-s+(diff*diff)

j<-j+1
}

er1<-sqrt(s/length(act)) #forecasting error
print(er1)
return(er1)
}



far<-function(p)
{
flagarima=0
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima model

f<- forecast(air.model,h=5) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time
testsize1=5
act1<-d[16:20] # the array of actual values, the forecasted values will be compared against these values



A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}






















________________________________
From: Charles Determan Jr [deter088 at umn.edu]
Sent: Wednesday, November 19, 2014 8:40 PM
To: Amit Thombre
Cc: r-help at r-project.org
Subject: Re: [R] Using sapply instead of for loop

Amit,

Even if you aren't getting an error with your original global variables it is far better practice to avoid global variables to make you code much more stable.  Of course you ultimately get to decide how your code is written.

That said, your error from the modified far function to include the variables is because you added too much to the sapply statement.  Here is what it should look like:

            A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n, ervalue),simplify=FALSE)

You can think apply statements as nothing more than a for loop that has been made 'pretty'.  You wanted to iterate from 1:Permax and use the other variables, therefore you only have the anonymous function (i.e. function(p)) only include the iterator and supply the other values from your nested for loops to the function.  When I run this with you code, making sure the function accepts the extra parameters, the A array appears to fill appropriately whereby most are 'NA' as specified by your 'far' function.  Is this what you expect?


On Wed, Nov 19, 2014 at 8:16 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
Charles ,

I am not getting an error . The final array A does not have the values in it. Here is the reproducible code.  I have even tried using paasing ervalue as a parameter to the function far.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

errf<-function(act, res, testsize, flag)
{
j=1
if(flag==1)
{
j<-nrow(d)-testsize
}

print(act)
print(res)
print(flag)
diff<-0
s<-0
# loop for iterating to each value of the actual value and finding the difference with thepredicted value
for (mn in 1:length(act))
{
cat("Value of mn in err", mn)
cat("Value of j in err", j)
cat("Value of res[j] in err", res[j])
diff<-(act[mn]-res[j])
print(act[mn])
print(res[j])
print(diff)
s<-s+(diff*diff)

j<-j+1
}

er1<-sqrt(s/length(act)) #forecasting error
print(er1)
return(er1)
}



far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}





________________________________
From: Charles Determan Jr [deter088 at umn.edu<mailto:deter088 at umn.edu>]
Sent: Wednesday, November 19, 2014 7:05 PM
To: Amit Thombre
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Using sapply instead of for loop

Amit,

Your question isn't necessarily complete.  You haven't provided a reproducible example of your data or an error message.  At first glance you aren't passing anything to your 'far' function except for 'p' and yet it uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid global variables as they can lead to broken code.  You should redefine your function with all the needed parameters and try again.

Regards,

On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
I am trying to replace a for loop by using sapply, The code is for forecasting using arima. The code is as follows:-
-------------------------------------------------------
far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.

st=2013   # start year value for getting the time series
month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size

for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}
------------------------------------------------------------------
The sapply replaces the for loop
for (p in 1:Permax)
{
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima model
A[i,j,k,l,m,n,p]<-AIC(air.model)
f<- forecast(air.model,h=testsize1) # for getting the error
er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
}, error=function(e)
{

return(NA)
}
)
 cat("Value of error", er[i,j,k,l,m,n,p])
 cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
}
--------------------------------------------------------------------------
Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call to the function far() the array loses the previous value and gets replaced with NA and gets the newly calculated error value. Finally the array A gets populated with only the latest value and does not hold the old values. Please help


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Dr. Charles Determan, PhD
Integrated Biosciences

________________________________
============================================================================================================================
Disclaimer: This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================



--
Dr. Charles Determan, PhD
Integrated Biosciences


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From bayat194 at yahoo.com  Wed Nov 19 13:29:09 2014
From: bayat194 at yahoo.com (Javad Bayat)
Date: Wed, 19 Nov 2014 12:29:09 +0000 (UTC)
Subject: [R] N.network help
Message-ID: <2104505658.2518770.1416400149550.JavaMail.yahoo@jws106135.mail.bf1.yahoo.com>

Dear all;I want to do N.network for pH and predict its future.but when I run the code and plot them (the measured data and the predicted), the predicted data in all station are same.i do not know what is wrong with this. Here are the codes that I used:"fit ?<- neuralnet(pH ~ station.2 + Day,data = bayat2)## create new data into the futurefuturedata <- expand.grid(station.2 = 1:5, Day = 511:1000)
## do predictionspredictions <- compute(fit, futuredata)predictions2 <- data.frame(predictions[["neurons"]][[1]][,2:3], pH = predictions$net.result)head(predictions2)## plot the results together with original datalibrary(lattice)library(latticeExtra)xyplot(pH ~ Day|factor(station.2), data = bayat2, type = "b", layout = c(3,2), xlim = c(0:1000))+xyplot(pH ~ Day|factor(station.2), data = predictions2, type = "b", layout = c(4,2), col = "red")"

Many thanks.
?Best Regards
Javad Bayat
Alternative Mail: j.bayat194 at gmail.com
	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Wed Nov 19 15:35:09 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 19 Nov 2014 08:35:09 -0600
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
Message-ID: <546CAA9D.3010909@mail.usask.ca>

> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
> z = matrix(c(12, -6),ncol=2)
> t(apply(y, 1, function(x) x*z))
     [,1] [,2]
[1,]    0    0
[2,]    6   -3
[3,]   12   -6

I hope this helps.

Chel Hee Lee

On 14-11-19 08:22 AM, Ruima E. wrote:
> Hi,
>
> I have this:
>
> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
> z = matrix(c(12, -6),ncol=2)
>
> In matlab I would do this
>
>> y .* x
> I would get this in matlab
>
>> ans
> 0    -0
> 6    -3
> 12   -6
>
> What is the equivalent in R?
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chl948 at mail.usask.ca  Wed Nov 19 15:55:27 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 19 Nov 2014 08:55:27 -0600
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <CAJYLPFdTPRYUH4e=fdmYAM6=OMuzWm62CKQmef4tpHaTmV-EGw@mail.gmail.com>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<546CAA9D.3010909@mail.usask.ca>
	<CAJYLPFdTPRYUH4e=fdmYAM6=OMuzWm62CKQmef4tpHaTmV-EGw@mail.gmail.com>
Message-ID: <546CAF5F.8020905@mail.usask.ca>

Another (simpler) way that I can think is that

> y * matrix(rep(z,3), ncol=ncol(y), byrow=TRUE)
     [,1] [,2]
[1,]    0    0
[2,]    6   -3
[3,]   12   -6

I hope this helps.

Chel Hee Lee


On 14-11-19 08:43 AM, Ruima E. wrote:
> Thank you Chel Hee.
>
> Isn't there a simpler way to do so?
>
>
> On Wed, Nov 19, 2014 at 3:35 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>>> z = matrix(c(12, -6),ncol=2)
>>> t(apply(y, 1, function(x) x*z))
>>      [,1] [,2]
>> [1,]    0    0
>> [2,]    6   -3
>> [3,]   12   -6
>>
>> I hope this helps.
>>
>> Chel Hee Lee
>>
>> On 14-11-19 08:22 AM, Ruima E. wrote:
>>> Hi,
>>>
>>> I have this:
>>>
>>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>>> z = matrix(c(12, -6),ncol=2)
>>>
>>> In matlab I would do this
>>>
>>>> y .* x
>>> I would get this in matlab
>>>
>>>> ans
>>> 0    -0
>>> 6    -3
>>> 12   -6
>>>
>>> What is the equivalent in R?
>>>
>>> Thanks
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From toth.denes at ttk.mta.hu  Wed Nov 19 16:00:49 2014
From: toth.denes at ttk.mta.hu (=?ISO-8859-1?Q?D=E9nes_T=F3th?=)
Date: Wed, 19 Nov 2014 16:00:49 +0100
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <2257487D-EFDD-4F13-BF12-A03A9B1AEC47@xs4all.nl>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<2257487D-EFDD-4F13-BF12-A03A9B1AEC47@xs4all.nl>
Message-ID: <546CB0A1.2010503@ttk.mta.hu>

Hi,

It is better to use sweep() for these kinds of problems, see ?sweep

y <- matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
z <- matrix(c(12, -6),ncol=2)
sweep(y, 2, z, "*")


Best,
   Denes



On 11/19/2014 03:50 PM, Berend Hasselman wrote:
> On 19-11-2014, at 15:22, Ruima E. <ruimaximo at gmail.com> wrote:
>
>> Hi,
>>
>> I have this:
>>
>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>> z = matrix(c(12, -6),ncol=2)
>>
>> In matlab I would do this
>>
>>> y .* x
>> I would get this in matlab
>>
>>> ans
>> 0    -0
>> 6    -3
>> 12   -6
>>
>> What is the equivalent in R?
>>
> One way of doing this could be:
>
> y * rep(z,1,each=nrow(y))
>
> Berend
>
>> Thanks
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From statup.r at gmail.com  Wed Nov 19 16:13:23 2014
From: statup.r at gmail.com (statup r)
Date: Wed, 19 Nov 2014 20:43:23 +0530
Subject: [R] R - PLOT - X-AXIS - DECIMALS
Message-ID: <CAPZdAj2iks3Pk=-bjRe4N5X1nnO4C8E=BhAJtj5_jX+S-ffUmA@mail.gmail.com>

I have a test.csv with two fields "year" and "sale", with below values:

year   sale
2001    1002002    200

This is what I did in R.

>aaa<-read.csv("test.csv")

>plot(aaa)


But when I call the above plot function why I'm getting decimals in x-axis
(year) ex: 2001.0, 2002.05

Please help.

	[[alternative HTML version deleted]]


From toth.denes at ttk.mta.hu  Wed Nov 19 16:34:51 2014
From: toth.denes at ttk.mta.hu (=?ISO-8859-1?Q?D=E9nes_T=F3th?=)
Date: Wed, 19 Nov 2014 16:34:51 +0100
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
Message-ID: <546CB89B.4040002@ttk.mta.hu>

Hi,

just for the records, your original code seems incorrect, see inline.

On 11/19/2014 03:22 PM, Ruima E. wrote:
> Hi,
>
> I have this:
>
> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
> z = matrix(c(12, -6),ncol=2)
>
> In matlab I would do this
>
>> y .* x
Here you wrote 'x' which I guess refers to 'z', and should be repmat(z, 
size(y, 1), 1) in matlab (assuming 'z' is a row vector)

> I would get this in matlab
>
>> ans
> 0    -0
> 6    -3
> 12   -6
>
> What is the equivalent in R?
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From benno at bapuetz.de  Wed Nov 19 16:35:19 2014
From: benno at bapuetz.de (=?iso-8859-1?Q?Benno_P=FCtz?=)
Date: Wed, 19 Nov 2014 16:35:19 +0100
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <428BE3D9-9041-4383-9061-03B593002787@dcn.davis.CA.us>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<546CAA9D.3010909@mail.usask.ca>
	<CAJYLPFdTPRYUH4e=fdmYAM6=OMuzWm62CKQmef4tpHaTmV-EGw@mail.gmail.com>
	<428BE3D9-9041-4383-9061-03B593002787@dcn.davis.CA.us>
Message-ID: <81AFDFF0-6D68-4CF4-90A9-91575CE476C6@bapuetz.de>

It can be simplified a bit, though, as the second operand in the multiplication does not need to be a matrix:

		y * rep(z,each=3)
 
On 19 Nov 2014, at 16:24 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> When your matrices are the same size, the "*" operator does what you want. The problem is that you have to make a conforming version of z before you can use that operator.
> 
> y*matrix(rep(z,3),ncol=2,byrow=TRUE)
> 
> or
> 
> y*matrix(rep(z,each=3),ncol=2)
> 
> To interpret this, just keep in mind that matrices are folded vectors in R... every matrix can be thought of as a linear vector of columnwise data with dimension attributes.
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On November 19, 2014 6:43:55 AM PST, "Ruima E." <ruimaximo at gmail.com> wrote:
>> Thank you Chel Hee.
>> 
>> Isn't there a simpler way to do so?
>> 
>> 
>> On Wed, Nov 19, 2014 at 3:35 PM, Chel Hee Lee <chl948 at mail.usask.ca>
>> wrote:
>>>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>>>> z = matrix(c(12, -6),ncol=2)
>>>> t(apply(y, 1, function(x) x*z))
>>>     [,1] [,2]
>>> [1,]    0    0
>>> [2,]    6   -3
>>> [3,]   12   -6
>>> 
>>> I hope this helps.
>>> 
>>> Chel Hee Lee
>>> 
>>> On 14-11-19 08:22 AM, Ruima E. wrote:
>>>> Hi,
>>>> 
>>>> I have this:
>>>> 
>>>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>>>> z = matrix(c(12, -6),ncol=2)
>>>> 
>>>> In matlab I would do this
>>>> 
>>>>> y .* x
>>>> I would get this in matlab
>>>> 
>>>>> ans
>>>> 0    -0
>>>> 6    -3
>>>> 12   -6
>>>> 
>>>> What is the equivalent in R?
>>>> 
>>>> Thanks
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From sarah.goslee at gmail.com  Wed Nov 19 17:26:32 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 19 Nov 2014 11:26:32 -0500
Subject: [R] R - PLOT - X-AXIS - DECIMALS
In-Reply-To: <CAPZdAj2iks3Pk=-bjRe4N5X1nnO4C8E=BhAJtj5_jX+S-ffUmA@mail.gmail.com>
References: <CAPZdAj2iks3Pk=-bjRe4N5X1nnO4C8E=BhAJtj5_jX+S-ffUmA@mail.gmail.com>
Message-ID: <CAM_vjun+aL3c0CtjZG7quc9KwijCv265brMcU0KXs5SjYG2RDw@mail.gmail.com>

Hi,

Since you didn't provide a reproducible example, we have no way of knowing.
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

But if I were you, I'd start with
str(aaa)
because my first guess is that your data import did not work as you expected.



On Wed, Nov 19, 2014 at 10:13 AM, statup r <statup.r at gmail.com> wrote:
> I have a test.csv with two fields "year" and "sale", with below values:
>
> year   sale
> 2001    1002002    200

That looks like three fields to me.
This may be an example of why you SHOULDN'T post to the list in HTML.


> This is what I did in R.
>
>>aaa<-read.csv("test.csv")
>
>>plot(aaa)
>
>
> But when I call the above plot function why I'm getting decimals in x-axis
> (year) ex: 2001.0, 2002.05
>
> Please help.
>
>         [[alternative HTML version deleted]]
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From deter088 at umn.edu  Wed Nov 19 17:34:42 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 19 Nov 2014 10:34:42 -0600
Subject: [R] Using sapply instead of for loop
In-Reply-To: <4A753D3F0C227041AB666DA6283A81F313C5C3716E@SINPUNMBX002.TechMahindra.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>
	<CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716C@SINPUNMBX002.TechMahindra.com>
	<CAOLJphmJO4vPZbcHadarSWdrXjgxtKvgBb_508df5tp4RaGgjQ@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716E@SINPUNMBX002.TechMahindra.com>
Message-ID: <CAOLJph=ZP4D5wYx-THEN5G63VcAtPzj3o0h4+B3gjTudpJZ=Bg@mail.gmail.com>

The following provides array A with 3.212016 as the last value.  The error
values are indeed in the array here.  There is also another with 6.281757
that I noticed at first glance.

errf<-function(act, res, testsize, flag)
{
  j=1
  if(flag==1)
  {
    j<-nrow(d)-testsize
  }

  print(act)
  print(res)
  print(flag)
  diff<-0
  s<-0
  # loop for iterating to each value of the actual value and finding the
difference with thepredicted value
  for (mn in 1:length(act))
  {
    cat("Value of mn in err", mn)
    cat("Value of j in err", j)
    cat("Value of res[j] in err", res[j])
    diff<-(act[mn]-res[j])
    print(act[mn])
    print(res[j])
    print(diff)
    s<-s+(diff*diff)

    j<-j+1
  }

  er1<-sqrt(s/length(act)) #forecasting error
  print(er1)
  return(er1)
}



far<-function(p, i, j, k, l, m, n, ervalue)
{
  flagarima=0
  testsize1 = 5
  cat("does it come here value of p", p)
  tryCatch({
    air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima
model  # the arima model

    f<- forecast(air.model,h=testsize1) # for getting the error

    ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

  }, error=function(e)
  {

    return(NA)
  }
  )
  cat("Value of error", ervalue[i,j,k,l,m,n,p])
  cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
  print(ervalue)
  return(ervalue)
}
---------------------------

  library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as
 the time
testsize1=5
act1<-d[16:20] # the array of actual values, the forecasted values will be
compared against these values

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on
the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on
the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
  for (j in 1:dmax)
  {
    for (k in 1:qmax)
    {
      for (l in 1:Pmax)
      {
        for (m in 1:Dmax)
        {
          for (n in 1:Qmax)
          {
            A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n,
ervalue),simplify=FALSE)

          }
        }
      }
    }
  }  #for looping through period value
}

A


On Wed, Nov 19, 2014 at 9:46 AM, Amit Thombre <amitmt at techmahindra.com>
wrote:

>  Charles,
>
> Some variables were missing in the code. I have put them in this code. Now
> what happens is the value of cat("Value of error", ervalue[i,j,k,l,m,n,p])
> gives error value for various runs but they are not in the final Array A.
> You will have to go through the runs carefully. The array ervalue which is
> printed shows the value only for that run with previous values as NA. It is
> like with every new value of p the previous values of ervalue are lost.
> Just for confirmation the A and ervalue array has the last value as
> 3.212016. This si just for information so that you can confirm if you are
> getting this value.
>
> ----------------------------------------------------------------------------------------------
>
> errf<-function(act, res, testsize, flag)
> {
> j=1
> if(flag==1)
> {
> j<-nrow(d)-testsize
> }
>
> print(act)
> print(res)
> print(flag)
> diff<-0
> s<-0
> # loop for iterating to each value of the actual value and finding the
> difference with thepredicted value
> for (mn in 1:length(act))
> {
> cat("Value of mn in err", mn)
> cat("Value of j in err", j)
> cat("Value of res[j] in err", res[j])
> diff<-(act[mn]-res[j])
> print(act[mn])
> print(res[j])
> print(diff)
> s<-s+(diff*diff)
>
> j<-j+1
> }
>
> er1<-sqrt(s/length(act)) #forecasting error
> print(er1)
> return(er1)
> }
>
>
>
> far<-function(p)
> {
> flagarima=0
> cat("does it come here value of p", p)
> tryCatch({
> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima
> model
>
> f<- forecast(air.model,h=5) # for getting the error
>
> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>
> }, error=function(e)
> {
>
> return(NA)
> }
> )
> cat("Value of error", ervalue[i,j,k,l,m,n,p])
> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
> print(ervalue)
> return(ervalue)
> }
> ---------------------------
> library('TTR')
> library('forecast')
> library('timeSeries')
> library('xts')
> library('RODBC')
>
>
> maxval=2  # set the array size as well as the maximum parameter value here.
> pmax=maxval  # set max p value of the ARIMA model
> dmax=maxval  # set max d value of the ARIMA model
> qmax=maxval  # set max q value of the ARIMA model
> Pmax=maxval  # set max P value of the ARIMA model
> Dmax=maxval  # set max D value of the ARIMA model
> Qmax=maxval  # set max Q value of the ARIMA model
> Permax=2     # maximum value of period.
> freq=12
> d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
> st=2013   # start year value for getting the time series
> month=4
> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as
> the time
> testsize1=5
> act1<-d[16:20] # the array of actual values, the forecasted values will be
> compared against these values
>
>
>
> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
> on the max value set the , also it stores the AIC valuearray size
> er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending
> on the max value set the , stores the error value.array size
> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
> depdending on the max value set the , stores the error value.array size
> erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
> depdending on the max value set the , stores the error value.array size
> for (i in 1:pmax)
> {
> for (j in 1:dmax)
> {
> for (k in 1:qmax)
> {
> for (l in 1:Pmax)
> {
> for (m in 1:Dmax)
> {
> for (n in 1:Qmax)
> {
> A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>
> }
> }
> }
> }
> }  #for looping through period value
> }
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>  ------------------------------
> *From:* Charles Determan Jr [deter088 at umn.edu]
> *Sent:* Wednesday, November 19, 2014 8:40 PM
>
> *To:* Amit Thombre
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] Using sapply instead of for loop
>
>   Amit,
>
>  Even if you aren't getting an error with your original global variables
> it is far better practice to avoid global variables to make you code much
> more stable.  Of course you ultimately get to decide how your code is
> written.
>
>  That said, your error from the modified far function to include the
> variables is because you added too much to the sapply statement.  Here is
> what it should look like:
>
>              A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n,
> ervalue),simplify=FALSE)
>
>  You can think apply statements as nothing more than a for loop that has
> been made 'pretty'.  You wanted to iterate from 1:Permax and use the other
> variables, therefore you only have the anonymous function (i.e.
> function(p)) only include the iterator and supply the other values from
> your nested for loops to the function.  When I run this with you code,
> making sure the function accepts the extra parameters, the A array appears
> to fill appropriately whereby most are 'NA' as specified by your 'far'
> function.  Is this what you expect?
>
>
> On Wed, Nov 19, 2014 at 8:16 AM, Amit Thombre <amitmt at techmahindra.com>
> wrote:
>
>>  Charles ,
>>
>> I am not getting an error . The final array A does not have the values in
>> it. Here is the reproducible code.  I have even tried using paasing ervalue
>> as a parameter to the function far.
>>
>>
>> -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>
>> errf<-function(act, res, testsize, flag)
>> {
>> j=1
>> if(flag==1)
>> {
>> j<-nrow(d)-testsize
>> }
>>
>> print(act)
>> print(res)
>> print(flag)
>> diff<-0
>> s<-0
>> # loop for iterating to each value of the actual value and finding the
>> difference with thepredicted value
>> for (mn in 1:length(act))
>> {
>> cat("Value of mn in err", mn)
>> cat("Value of j in err", j)
>> cat("Value of res[j] in err", res[j])
>> diff<-(act[mn]-res[j])
>> print(act[mn])
>> print(res[j])
>> print(diff)
>> s<-s+(diff*diff)
>>
>> j<-j+1
>> }
>>
>> er1<-sqrt(s/length(act)) #forecasting error
>> print(er1)
>> return(er1)
>> }
>>
>>
>>
>> far<-function(p)
>> {
>>
>> cat("does it come here value of p", p)
>> tryCatch({
>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima
>> model
>>
>> f<- forecast(air.model,h=testsize1) # for getting the error
>>
>> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>>
>> }, error=function(e)
>> {
>>
>> return(NA)
>> }
>> )
>> cat("Value of error", ervalue[i,j,k,l,m,n,p])
>> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>> print(ervalue)
>> return(ervalue)
>> }
>>  ---------------------------
>> library('TTR')
>> library('forecast')
>> library('timeSeries')
>> library('xts')
>> library('RODBC')
>>
>>
>>  maxval=2  # set the array size as well as the maximum parameter value
>> here.
>> pmax=maxval  # set max p value of the ARIMA model
>> dmax=maxval  # set max d value of the ARIMA model
>> qmax=maxval  # set max q value of the ARIMA model
>> Pmax=maxval  # set max P value of the ARIMA model
>> Dmax=maxval  # set max D value of the ARIMA model
>> Qmax=maxval  # set max Q value of the ARIMA model
>> Permax=2     # maximum value of period.
>>  freq=12
>> d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18,
>> 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
>> st=2013   # start year value for getting the time series
>> month=4
>> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa
>> as  the time
>>
>> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
>> on the max value set the , also it stores the AIC valuearray size
>> er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending
>> on the max value set the , stores the error value.array size
>> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>> depdending on the max value set the , stores the error value.array size
>> erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>> depdending on the max value set the , stores the error value.array size
>> for (i in 1:pmax)
>> {
>> for (j in 1:dmax)
>> {
>> for (k in 1:qmax)
>> {
>> for (l in 1:Pmax)
>> {
>> for (m in 1:Dmax)
>> {
>> for (n in 1:Qmax)
>> {
>>  A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>>
>> }
>> }
>> }
>> }
>> }  #for looping through period value
>> }
>>
>>
>>
>>
>>
>>  ------------------------------
>> *From:* Charles Determan Jr [deter088 at umn.edu]
>> *Sent:* Wednesday, November 19, 2014 7:05 PM
>> *To:* Amit Thombre
>> *Cc:* r-help at r-project.org
>> *Subject:* Re: [R] Using sapply instead of for loop
>>
>>    Amit,
>>
>>  Your question isn't necessarily complete.  You haven't provided a
>> reproducible example of your data or an error message.  At first glance you
>> aren't passing anything to your 'far' function except for 'p' and yet it
>> uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid
>> global variables as they can lead to broken code.  You should redefine your
>> function with all the needed parameters and try again.
>>
>>  Regards,
>>
>> On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com>
>> wrote:
>>
>>> I am trying to replace a for loop by using sapply, The code is for
>>> forecasting using arima. The code is as follows:-
>>> -------------------------------------------------------
>>> far<-function(p)
>>> {
>>>
>>> cat("does it come here value of p", p)
>>> tryCatch({
>>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>>> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima
>>> model
>>>
>>> f<- forecast(air.model,h=testsize1) # for getting the error
>>>
>>> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>>>
>>> }, error=function(e)
>>> {
>>>
>>> return(NA)
>>> }
>>> )
>>> cat("Value of error", ervalue[i,j,k,l,m,n,p])
>>> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>>> print(ervalue)
>>> return(ervalue)
>>> }
>>> ---------------------------
>>> maxval=2  # set the array size as well as the maximum parameter value
>>> here.
>>> pmax=maxval  # set max p value of the ARIMA model
>>> dmax=maxval  # set max d value of the ARIMA model
>>> qmax=maxval  # set max q value of the ARIMA model
>>> Pmax=maxval  # set max P value of the ARIMA model
>>> Dmax=maxval  # set max D value of the ARIMA model
>>> Qmax=maxval  # set max Q value of the ARIMA model
>>> Permax=2     # maximum value of period.
>>>
>>> st=2013   # start year value for getting the time series
>>> month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19,
>>> 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
>>> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa
>>> as  the time
>>>
>>> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
>>> on the max value set the , also it stores the AIC valuearray size
>>> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>>> depdending on the max value set the , stores the error value.array size
>>>
>>> for (i in 1:pmax)
>>> {
>>> for (j in 1:dmax)
>>> {
>>> for (k in 1:qmax)
>>> {
>>> for (l in 1:Pmax)
>>> {
>>> for (m in 1:Dmax)
>>> {
>>> for (n in 1:Qmax)
>>> {
>>> A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>>>
>>> }
>>> }
>>> }
>>> }
>>> }  #for looping through period value
>>> }
>>> ------------------------------------------------------------------
>>> The sapply replaces the for loop
>>> for (p in 1:Permax)
>>> {
>>> cat("does it come here value of p", p)
>>> tryCatch({
>>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>>> seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima
>>> model
>>> A[i,j,k,l,m,n,p]<-AIC(air.model)
>>> f<- forecast(air.model,h=testsize1) # for getting the error
>>> er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>>> }, error=function(e)
>>> {
>>>
>>> return(NA)
>>> }
>>> )
>>>  cat("Value of error", er[i,j,k,l,m,n,p])
>>>  cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>>> }
>>>
>>> --------------------------------------------------------------------------
>>> Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call
>>> to the function far() the array loses the previous value and gets replaced
>>> with NA and gets the newly calculated error value. Finally the array A gets
>>> populated with only the latest value and does not hold the old values.
>>> Please help
>>>
>>>
>>>
>>> ============================================================================================================================
>>> Disclaimer:  This message and the information contained herein is
>>> proprietary and confidential and subject to the Tech Mahindra policy
>>> statement, you may review the policy at
>>> http://www.techmahindra.com/Disclaimer.html externally
>>> http://tim.techmahindra.com/tim/disclaimer.html internally within
>>> TechMahindra.
>>>
>>> ============================================================================================================================
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>>  --
>>  Dr. Charles Determan, PhD
>> Integrated Biosciences
>>
>> ------------------------------
>>
>> ============================================================================================================================
>> Disclaimer: This message and the information contained herein is
>> proprietary and confidential and subject to the Tech Mahindra policy
>> statement, you may review the policy at
>> http://www.techmahindra.com/Disclaimer.html externally
>> http://tim.techmahindra.com/tim/disclaimer.html internally within
>> TechMahindra.
>>
>> ============================================================================================================================
>>
>>
>
>
>  --
>  Dr. Charles Determan, PhD
> Integrated Biosciences
>
> ------------------------------
>
> ============================================================================================================================
> Disclaimer: This message and the information contained herein is
> proprietary and confidential and subject to the Tech Mahindra policy
> statement, you may review the policy at
> http://www.techmahindra.com/Disclaimer.html externally
> http://tim.techmahindra.com/tim/disclaimer.html internally within
> TechMahindra.
>
> ============================================================================================================================
>
>


-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From mdayan.research at gmail.com  Wed Nov 19 17:18:14 2014
From: mdayan.research at gmail.com (Michael)
Date: Wed, 19 Nov 2014 11:18:14 -0500
Subject: [R] MANCOVA in R
Message-ID: <CAK8FaMNE95+Kr3cDUC9gqvBAhr8EdWgzTmwropw3NouX-=FSgA@mail.gmail.com>

Hi,

I have two groups of persons, GRP0 and GRP1, on which I measured three
continuous variables: VAR1, VAR2 and VAR3.

I would like to use Mancova in R with:
- VAR1, VAR2 and VAR3 as outcome variables
- GRP={0,1} as predictor variable
- age and gender = {F,M} as covariates

What would be the correct way to formulate this model in R?

Also, since the VAR1, VAR2 and VAR3 measures were carried out on the
same persons at N=100 instances which were serially correlated, I
would like to apply permutation-based multiple-comparison correction
on the N=100 MANCOVA results I would obtain. Any help on this matter
as well would be fantastic.

Best wishes,

Michael

	[[alternative HTML version deleted]]


From nanh.vothi at gmail.com  Wed Nov 19 17:36:32 2014
From: nanh.vothi at gmail.com (Anh Vo)
Date: Wed, 19 Nov 2014 17:36:32 +0100
Subject: [R] R and R Studio - Problem with the package xlsx
Message-ID: <546cc713.84b1c20a.4456.fffff175@mx.google.com>

Dear list,

 

I'm running windows 7 with R i386 3.1.2. I'm trying to load a excel
spreadsheet into R using the xlsx package. I posted my code below with the
error I got.

 

[R Studio]

> library(xlsx)
> quiz1q3data <- read.xlsx("quiz1q3.xlsx",sheetIndex=1,header=FALSE)
Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  : 
  java.util.zip.ZipException: invalid code -- missing end-of-block

 

With [R], it was even worse as I could not load the rJava package which the
xlsx library depends on.

 

Has anyone an idea what's going wrong?

 

Thanks in advance,

Anh


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Nov 19 17:48:42 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 19 Nov 2014 11:48:42 -0500
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <81AFDFF0-6D68-4CF4-90A9-91575CE476C6@bapuetz.de>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<546CAA9D.3010909@mail.usask.ca>
	<CAJYLPFdTPRYUH4e=fdmYAM6=OMuzWm62CKQmef4tpHaTmV-EGw@mail.gmail.com>
	<428BE3D9-9041-4383-9061-03B593002787@dcn.davis.CA.us>
	<81AFDFF0-6D68-4CF4-90A9-91575CE476C6@bapuetz.de>
Message-ID: <E79F740C-23BC-4D89-B1B4-B2A2F2519F10@utoronto.ca>

Or ... if you mean "simpler" as in "less to type", you can define your own binary operator by enclosing it in "%" signs, and the assign any of the previously proposed solutions, e.g.

y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
z = matrix(c(12, -6),ncol=2)
'%.*%' <- function(a,b) {a * rep(b, each=3)}


y %.*% z


     [,1] [,2]
[1,]    0    0
[2,]    6   -3
[3,]   12   -6


From dwinsemius at comcast.net  Wed Nov 19 17:49:45 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Nov 2014 08:49:45 -0800
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
	<B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
	<79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>
Message-ID: <8780E3CE-13F9-43B3-A6D3-5034BBE6304C@comcast.net>


On Nov 19, 2014, at 6:08 AM, i.petzev wrote:

> Hi David,
> 
> thanks a lot for the response. I see that this works. I am not sure, however, what the appropriate way to do this is. It also works if you do not define weights in the boot() function (weighted bootstrap) but rather in the vw_m_diff function (ordinary bootstrap), i.e., 
> 
> 
> vw_m_diff <- function(dataset,d) {
>   differences <- dataset[d,1]-dataset[d,2]
>   weights <- dataset[d, "weights"]
>   return(weighted.mean(x=differences, w=weights))
> }
> 
> with 
> 
> boot(dataset, statistic=vw_m_diff, R = 1000)

I don't undertand how that is in the slightest way different than what I suggested. You've only substituted 'd' for 'w' as a formal parameter in the function. That should not change the processed results at all.

-- 
David.

> 
> I guess this is rather a statistical question and hence I will have to look further into it. 
> 
> In any case, thanks a lot for your help.
> 
> Best
> 
> 
> 
> On 15 Nov 2014, at 17:27, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Nov 14, 2014, at 3:18 PM, David Winsemius wrote:
>> 
>>> 
>>> On Nov 14, 2014, at 12:15 PM, ivan wrote:
>>> 
>>>> Hi,
>>>> 
>>>> I am trying to compute bootstrap confidence intervals for weighted means of
>>>> paired differences with the boot package. Unfortunately, the weighted mean
>>>> estimate lies out of the confidence bounds and hence I am obviously doing
>>>> something wrong.
>>>> 
>>>> Appreciate any help. Thanks. Here is a reproducible example:
>>>> 
>>>> 
>>>> library(boot)
>>>> set.seed(1111)
>>>> x <- rnorm(50)
>>>> y <- rnorm(50)
>>>> weights <- runif(50)
>>>> weights <- weights / sum(weights)
>>>> dataset <- cbind(x,y,weights)
>>>> vw_m_diff <- function(dataset,w, d) {
>>> 
>>> My understanding of the principle underlying the design of the bootstrapped function was that the data was the first argument and the index vector was the second. (I admit to not knowing what it would do with a third argument. So I would have guessed that you wanted:
>>> 
>>> vw_m_diff <- function(dataset,w) {
>>>    differences <- dataset[d,1]-dataset[d,2]
>>>   weights <- dataset[w, "weights"]
>>>   return(weighted.mean(x=differences, w=weights))
>>> } 
>> 
>> I'm sorry. That was the code I first editted. This is the code that produced that output:
>> 
>> vw_m_diff <- function(dataset,w) {
>>      differences <- dataset[w,1]-dataset[w,2]
>>     weights <- dataset[w, "weights"]
>>     return(weighted.mean(x=differences, w=weights))
>>   }
>> 
>>> 
>>> I get what appears to me as a sensible set of estimates (since they seem centered on zero) although I further admit I do not know what the theoretic CI _should_ be for this problem:
>>> 
>>>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
>>>> boot.ci(res_boot)
>>> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
>>> Based on 1000 bootstrap replicates
>>> 
>>> CALL : 
>>> boot.ci(boot.out = res_boot)
>>> 
>>> Intervals : 
>>> Level      Normal              Basic         
>>> 95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )  
>>> 
>>> Level     Percentile            BCa          
>>> 95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )  
>>> Calculations and Intervals on Original Scale
>>> 
>>> 
>>>>  differences <- dataset[d,1]-dataset[d,2]
>>>>  weights <- w[d]
>>>>  return(weighted.mean(x=differences, w=weights))
>>>> }
>>>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
>>>> boot.ci(res_boot)
>>>> 
>>>> *BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS*
>>>> *Based on 1000 bootstrap replicates*
>>>> 
>>>> *CALL : *
>>>> *boot.ci <http://boot.ci>(boot.out = res_boot)*
>>>> 
>>>> *Intervals : *
>>>> *Level      Normal              Basic         *
>>>> *95%   (-0.8365, -0.3463 )   (-0.8311, -0.3441 )  *
>>>> 
>>>> *Level     Percentile            BCa          *
>>>> *95%   (-0.3276,  0.1594 )   (-0.4781, -0.3477 )  *
>>>> 
>>>> weighted.mean(x=dataset[,1]-dataset[,2], w=dataset[,3])
>>>> 
>>>> *[1] -0.07321734*
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From jvadams at usgs.gov  Wed Nov 19 17:52:06 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 19 Nov 2014 10:52:06 -0600
Subject: [R] LAT/LON to UTM in R
In-Reply-To: <729646660.2587209.1416409528371.JavaMail.yahoo@jws10657.mail.bf1.yahoo.com>
References: <CAN5YmCHOnYabMGf4e1uPiJt5Mf1wgthw=Fsv_E7PirUZOz4hDw@mail.gmail.com>
	<729646660.2587209.1416409528371.JavaMail.yahoo@jws10657.mail.bf1.yahoo.com>
Message-ID: <CAN5YmCHAfviTX-ABrXn0=uzxzkE9gmSHGirEOe=drjAp7zpLoQ@mail.gmail.com>

Zilefac,

When I try

library(rgdal)
utm <- project(as.matrix(xy[,c("X","Y")]), "+proj=longlat +ellps=WGS84
+datum=WGS84 +no_defs")
plot(utm)

the points look fine.  Similar to

map("world", xlim=range(xy$X), ylim=range(xy$Y))
points(xy[, c("X", "Y")])

What's wrong with them?

Jean

On Wed, Nov 19, 2014 at 9:05 AM, Zilefac Elvis <zilefacelvis at yahoo.com>
wrote:

> Hi Admas,
> Sorry I missed out the reproducible example.
> Here it is:
>
> dput(xy)
> structure(list(ID = 1:120, X = c(-102.6, -101.9, -97.1, -97,
> -95.7, -99.1, -100.1, -97.2, -97, -99.3, -96, -95.2, -98.8, -98.1,
> -99.6, -97.8, -96.1, -98.3, -95.6, -96.8, -101.2, -101.1, -97.2,
> -111.1, -111.2, -116, -117.6, -103.7, -107.1, -102.3, -105.6,
> -105.3, -108.5, -103.2, -94.1, -101.9, -94.7, -101.1, -97.9,
> -111.4, -111.2, -110.5, -111.3, -107.3, -102.3, -104.7, -106.7,
> -101.8, -106, -103, -107.9, -103.7, -103.8, -109.2, -108.9, -109.5,
> -102.1, -104.6, -105.6, -101.7, -104, -108.3, -107.1, -103.9,
> -105.2, -105.7, -104.7, -106.7, -108.8, -107.7, -102.2, -107.8,
> -109.4, -106.1, -106.4, -104.2, -101.1, -99.9, -99.7, -101.3,
> -113.3, -119.4, -113.8, -114.7, -112.8, -110.3, -113.6, -111.1,
> -116.3, -118.5, -118.9, -117.4, -111.7, -114.1, -114.8, -113.8,
> -115.8, -108.4, -109.1, -115.6, -114.2, -114, -113.4, -113.7,
> -114.5, -112.9, -116.4, -113.1, -114.4, -117.5, -118, -113.8,
> -112.8, -110.7, -113.6, -114.1, -114, -114.9, -112.7, -112.1),
>     Y = c(52.88, 52.08, 50.93, 52.35, 51.03, 49.55, 51.1, 49,
>     50.63, 53.15, 50.47, 49.62, 50.42, 49.18, 50.15, 53.97, 50.18,
>     49.95, 49.02, 49.53, 52.12, 53.97, 49.92, 58.77, 56.65, 58.38,
>     57.75, 58.18, 57.35, 55.53, 57.25, 55.15, 59.57, 56.23, 58.73,
>     54.77, 56.35, 56.87, 55.8, 52.07, 50.72, 49.12, 51.58, 49.72,
>     50.9, 49.38, 50.47, 51.52, 51.27, 49.22, 50.98, 50.55, 51.25,
>     51.52, 49.68, 50.9, 49.62, 52.82, 50.33, 50.13, 53.33, 52.77,
>     51.48, 51.98, 52.42, 53.22, 50.43, 52.17, 52.37, 50.27, 51.2,
>     49.37, 53.13, 53.92, 49, 49.82, 50.43, 49.92, 49.42, 49.18,
>     54.72, 55.2, 53.28, 54.13, 53.03, 54.42, 53.32, 53.88, 55.42,
>     56.08, 55.18, 56.23, 53.42, 53.88, 55.28, 55.97, 54.15, 55.83,
>     54.05, 51.2, 49.47, 51.12, 49, 49.93, 49.63, 51.47, 53.58,
>     50.88, 50.55, 53.4, 52.93, 52.45, 49.63, 50.02, 49.13, 51.78,
>     49.52, 52.42, 52.33, 50.05)), .Names = c("ID", "X", "Y"), row.names =
> c(NA,
> -120L), class = "data.frame")
>
>

	[[alternative HTML version deleted]]


From arturaugusto at gmail.com  Wed Nov 19 18:26:12 2014
From: arturaugusto at gmail.com (Artur Augusto)
Date: Wed, 19 Nov 2014 15:26:12 -0200
Subject: [R] Using Rmpfr to round with precision in R
Message-ID: <CAGP33S4k2qfwzA0txNBHh_xndxnWr=HiP4FjRmyrZ_cL9Auauw@mail.gmail.com>

I'm trying to use the Rmpfr library with the round() function to apply
the round half to even rule and achieve correct results, without
errors due the finite precision of float point values.

Example of problem:

round(1.225,2)
#[1] 1.23

So far, this is what I've achieved:

library(Rmpfr)
x <- c(1.225, 1.2225, 1.22225, 1.222225)
n <- c(2, 3, 4, 5)
round2 <- function(x, n){
  sprintf(paste("%#.", n, "f", sep=""), round(mpfr(as.character(x), 200), n))
}
mapply(round2, x, n)
#[1] "1.22"    "1.222"   "1.2222"  "1.22222"

But in some cases I don't get the desired results:

round2(1.152, 2)# Should be 1.15
#[1] "1.16"

Reading the Rmpfr docs, at the roundMpfr() function, it says:

The mpfr class group method Math2 implements a method for round(x,
digits) which rounds to decimal digits.

But I can't figure how to use it.

How can I achieve desired rounded results?

Artur


From sarifkin at ucsd.edu  Wed Nov 19 18:17:23 2014
From: sarifkin at ucsd.edu (Scott Rifkin)
Date: Wed, 19 Nov 2014 09:17:23 -0800
Subject: [R] Symbolic equations to R code?
Message-ID: <546CD0A3.30201@ucsd.edu>

I'm looking for a package that would take a mathematical function 
written in symbolic notation and convert it into R code.

What I have in mind would be something like the following:

1) Have a GUI (e.g. something like Microsoft Word equation editor, but 
computer readable) to produce an equation so that it would look just 
like it would if you were writing it on paper

2) Have some way to translate the GUI into some markup language (perhaps 
this would be in a non-R application)

3) Have code that translates the markup into an R function.

My motivation is that I teach an intro stats class that uses 
randomization techniques. I would like for the students to be able to 
make up their own statistics and then simulate null distributions or 
estimate bootstrap confidence intervals using them. I'd prefer to make 
it as easy as possible for them to enter the formula for their 
statistics into the computer, and I think that will be easier if it 
looks from their end just like it would if they were writing it on 
paper.  After they submit the equation, I would have an RStudio shiny 
applet take care of the rest.

Any suggestions for R packages that could do this or pieces of it would 
be very much appreciated.

Thanks,
Scott


From dscheffy at gmail.com  Wed Nov 19 17:48:34 2014
From: dscheffy at gmail.com (Jeff Hansen)
Date: Wed, 19 Nov 2014 10:48:34 -0600
Subject: [R] Why would something work in R but not Rscript?
Message-ID: <CAA77SLsYwWgHH4OFom86mB2cbQKSktbSJ0hBjCPUeSjwO+zBHA@mail.gmail.com>

I have a script that uses RWeka (and consequently rJava).  When I run
it in Rstudio everything works fine. When I run it with `R CMD BATCH`,
everything also works fine. However, when I run it with Rscript, I get
the following error:

Error in FUN(X[[1L]], ...) :
  object is not a Java object reference (jobjRef/jarrayRef).
Calls: evaluate_Weka_classifier -> t -> sapply -> lapply -> FUN
Execution halted

The following is a very simple toy script that you can run to produce
the results:

library("RWeka")
result <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
observation <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
df <- data.frame(result,observation)
j48 <- J48(result ~ .,data=df)
evaluate_Weka_classifier(j48)

Save that to a file called help.R and run

R CMD BATCH help.R

Check the output file help.Rout and you should see no errors. Now try
running it from:

Rscript help.R

And you should see the error I've pasted above.

I have consulted (and will continue to consult) the literature, but
the manuals tend to answer how usage differs between the two commands
rather than going into implementation details. I imagine there's a
difference in how environments get loaded and I just need to adjust
something on the Rscript side.

I'm working on a Mac (OSX) running R 3.1.0, but I get the same results
when I run everything from a Centos 6.4 virtual machine (headless)
with R 3.1.1 installed.

Thanks for any help!


From amitmt at techmahindra.com  Wed Nov 19 18:46:13 2014
From: amitmt at techmahindra.com (Amit Thombre)
Date: Wed, 19 Nov 2014 23:16:13 +0530
Subject: [R] Using sapply instead of for loop
In-Reply-To: <CAOLJph=ZP4D5wYx-THEN5G63VcAtPzj3o0h4+B3gjTudpJZ=Bg@mail.gmail.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>
	<CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716C@SINPUNMBX002.TechMahindra.com>
	<CAOLJphmJO4vPZbcHadarSWdrXjgxtKvgBb_508df5tp4RaGgjQ@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716E@SINPUNMBX002.TechMahindra.com>,
	<CAOLJph=ZP4D5wYx-THEN5G63VcAtPzj3o0h4+B3gjTudpJZ=Bg@mail.gmail.com>
Message-ID: <4A753D3F0C227041AB666DA6283A81F313C5C3716F@SINPUNMBX002.TechMahindra.com>

The following is printed for  i,j,k,l,m,n,p 2 2 2 2 2 1 2

"Value of error 6.281757Value of i,j,k,l,m,n,p 2 2 2 2 2 1 2, , 1, 1, 1, 1, 1"
Thus ervalue[2,2,2,2,2,1,2] should be 6.28175, But after all the runs if you try to get this array value it is NA. Also I think A is a list so not sure how to extract the same but the following is displayed for the same array as ervalue for A when I type A after all the runs .
, , 2, 2, 2, 1, 2
     [,1] [,2]
[1,]   NA   NA
[2,]   NA   NA
The ervalue itself loses the values , I think and hence A does not have it.

________________________________
From: Charles Determan Jr [deter088 at umn.edu]
Sent: Wednesday, November 19, 2014 10:04 PM
To: Amit Thombre
Cc: r-help at r-project.org
Subject: Re: [R] Using sapply instead of for loop

The following provides array A with 3.212016 as the last value.  The error values are indeed in the array here.  There is also another with 6.281757 that I noticed at first glance.

errf<-function(act, res, testsize, flag)
{
  j=1
  if(flag==1)
  {
    j<-nrow(d)-testsize
  }

  print(act)
  print(res)
  print(flag)
  diff<-0
  s<-0
  # loop for iterating to each value of the actual value and finding the difference with thepredicted value
  for (mn in 1:length(act))
  {
    cat("Value of mn in err", mn)
    cat("Value of j in err", j)
    cat("Value of res[j] in err", res[j])
    diff<-(act[mn]-res[j])
    print(act[mn])
    print(res[j])
    print(diff)
    s<-s+(diff*diff)

    j<-j+1
  }

  er1<-sqrt(s/length(act)) #forecasting error
  print(er1)
  return(er1)
}



far<-function(p, i, j, k, l, m, n, ervalue)
{
  flagarima=0
  testsize1 = 5
  cat("does it come here value of p", p)
  tryCatch({
    air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima model  # the arima model

    f<- forecast(air.model,h=testsize1) # for getting the error

    ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

  }, error=function(e)
  {

    return(NA)
  }
  )
  cat("Value of error", ervalue[i,j,k,l,m,n,p])
  cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
  print(ervalue)
  return(ervalue)
}
---------------------------

  library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time
testsize1=5
act1<-d[16:20] # the array of actual values, the forecasted values will be compared against these values

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
  for (j in 1:dmax)
  {
    for (k in 1:qmax)
    {
      for (l in 1:Pmax)
      {
        for (m in 1:Dmax)
        {
          for (n in 1:Qmax)
          {
            A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n, ervalue),simplify=FALSE)

          }
        }
      }
    }
  }  #for looping through period value
}

A


On Wed, Nov 19, 2014 at 9:46 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
Charles,

Some variables were missing in the code. I have put them in this code. Now what happens is the value of cat("Value of error", ervalue[i,j,k,l,m,n,p]) gives error value for various runs but they are not in the final Array A. You will have to go through the runs carefully. The array ervalue which is printed shows the value only for that run with previous values as NA. It is like with every new value of p the previous values of ervalue are lost. Just for confirmation the A and ervalue array has the last value as 3.212016. This si just for information so that you can confirm if you are getting this value.
----------------------------------------------------------------------------------------------

errf<-function(act, res, testsize, flag)
{
j=1
if(flag==1)
{
j<-nrow(d)-testsize
}

print(act)
print(res)
print(flag)
diff<-0
s<-0
# loop for iterating to each value of the actual value and finding the difference with thepredicted value
for (mn in 1:length(act))
{
cat("Value of mn in err", mn)
cat("Value of j in err", j)
cat("Value of res[j] in err", res[j])
diff<-(act[mn]-res[j])
print(act[mn])
print(res[j])
print(diff)
s<-s+(diff*diff)

j<-j+1
}

er1<-sqrt(s/length(act)) #forecasting error
print(er1)
return(er1)
}



far<-function(p)
{
flagarima=0
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima model

f<- forecast(air.model,h=5) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time
testsize1=5
act1<-d[16:20] # the array of actual values, the forecasted values will be compared against these values



A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}






















________________________________
From: Charles Determan Jr [deter088 at umn.edu<mailto:deter088 at umn.edu>]
Sent: Wednesday, November 19, 2014 8:40 PM

To: Amit Thombre
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Using sapply instead of for loop

Amit,

Even if you aren't getting an error with your original global variables it is far better practice to avoid global variables to make you code much more stable.  Of course you ultimately get to decide how your code is written.

That said, your error from the modified far function to include the variables is because you added too much to the sapply statement.  Here is what it should look like:

            A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n, ervalue),simplify=FALSE)

You can think apply statements as nothing more than a for loop that has been made 'pretty'.  You wanted to iterate from 1:Permax and use the other variables, therefore you only have the anonymous function (i.e. function(p)) only include the iterator and supply the other values from your nested for loops to the function.  When I run this with you code, making sure the function accepts the extra parameters, the A array appears to fill appropriately whereby most are 'NA' as specified by your 'far' function.  Is this what you expect?


On Wed, Nov 19, 2014 at 8:16 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
Charles ,

I am not getting an error . The final array A does not have the values in it. Here is the reproducible code.  I have even tried using paasing ervalue as a parameter to the function far.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

errf<-function(act, res, testsize, flag)
{
j=1
if(flag==1)
{
j<-nrow(d)-testsize
}

print(act)
print(res)
print(flag)
diff<-0
s<-0
# loop for iterating to each value of the actual value and finding the difference with thepredicted value
for (mn in 1:length(act))
{
cat("Value of mn in err", mn)
cat("Value of j in err", j)
cat("Value of res[j] in err", res[j])
diff<-(act[mn]-res[j])
print(act[mn])
print(res[j])
print(diff)
s<-s+(diff*diff)

j<-j+1
}

er1<-sqrt(s/length(act)) #forecasting error
print(er1)
return(er1)
}



far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}





________________________________
From: Charles Determan Jr [deter088 at umn.edu<mailto:deter088 at umn.edu>]
Sent: Wednesday, November 19, 2014 7:05 PM
To: Amit Thombre
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Using sapply instead of for loop

Amit,

Your question isn't necessarily complete.  You haven't provided a reproducible example of your data or an error message.  At first glance you aren't passing anything to your 'far' function except for 'p' and yet it uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid global variables as they can lead to broken code.  You should redefine your function with all the needed parameters and try again.

Regards,

On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
I am trying to replace a for loop by using sapply, The code is for forecasting using arima. The code is as follows:-
-------------------------------------------------------
far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.

st=2013   # start year value for getting the time series
month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size

for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}
------------------------------------------------------------------
The sapply replaces the for loop
for (p in 1:Permax)
{
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima model
A[i,j,k,l,m,n,p]<-AIC(air.model)
f<- forecast(air.model,h=testsize1) # for getting the error
er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
}, error=function(e)
{

return(NA)
}
)
 cat("Value of error", er[i,j,k,l,m,n,p])
 cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
}
--------------------------------------------------------------------------
Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call to the function far() the array loses the previous value and gets replaced with NA and gets the newly calculated error value. Finally the array A gets populated with only the latest value and does not hold the old values. Please help


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Dr. Charles Determan, PhD
Integrated Biosciences

________________________________
============================================================================================================================
Disclaimer: This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================



--
Dr. Charles Determan, PhD
Integrated Biosciences

________________________________
============================================================================================================================
Disclaimer: This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================



--
Dr. Charles Determan, PhD
Integrated Biosciences


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From deter088 at umn.edu  Wed Nov 19 19:18:03 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Wed, 19 Nov 2014 12:18:03 -0600
Subject: [R] Using sapply instead of for loop
In-Reply-To: <4A753D3F0C227041AB666DA6283A81F313C5C3716F@SINPUNMBX002.TechMahindra.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>
	<CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716C@SINPUNMBX002.TechMahindra.com>
	<CAOLJphmJO4vPZbcHadarSWdrXjgxtKvgBb_508df5tp4RaGgjQ@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716E@SINPUNMBX002.TechMahindra.com>
	<CAOLJph=ZP4D5wYx-THEN5G63VcAtPzj3o0h4+B3gjTudpJZ=Bg@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716F@SINPUNMBX002.TechMahindra.com>
Message-ID: <CAOLJphkWysgmoCbVCh3dPgczYTv7Q9AePko8+5dAkstkpsZpTg@mail.gmail.com>

Ah, this is because you are overwriting your 'A' with each loop.  As a
simple way to demonstrate this I changed:

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2))

to

A <- list()

and then I changed
A <- sapply((1:Permax),function(p) far(p, i, j, k, l, m,n,
ervalue),simplify=FALSE)

to

A<-append(A, sapply((1:Permax),function(p) far(p, i, j, k, l, m,n,
ervalue),simplify=FALSE))

Once the run is complete you can find the 6.28757 in A[126].  You can
easily create another index so you can find it easily in the list but the
ervalue is indeed , , 2,2,2,1,2 as you show above.


On Wed, Nov 19, 2014 at 11:46 AM, Amit Thombre <amitmt at techmahindra.com>
wrote:

>  The following is printed for  i,j,k,l,m,n,p 2 2 2 2 2 1 2
>
> "Value of error 6.281757Value of i,j,k,l,m,n,p 2 2 2 2 2 1 2, , 1, 1, 1,
> 1, 1"
>  Thus ervalue[2,2,2,2,2,1,2] should be 6.28175, But after all the runs if
> you try to get this array value it is NA. Also I think A is a list so not
> sure how to extract the same but the following is displayed for the same
> array as ervalue for A when I type A after all the runs .
> , , 2, 2, 2, 1, 2
>      [,1] [,2]
> [1,]   NA   NA
> [2,]   NA   NA
>  The ervalue itself loses the values , I think and hence A does not have
> it.
>
>  ------------------------------
> *From:* Charles Determan Jr [deter088 at umn.edu]
> *Sent:* Wednesday, November 19, 2014 10:04 PM
>
> *To:* Amit Thombre
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] Using sapply instead of for loop
>
>   The following provides array A with 3.212016 as the last value.  The
> error values are indeed in the array here.  There is also another with
> 6.281757 that I noticed at first glance.
>
>  errf<-function(act, res, testsize, flag)
> {
>   j=1
>   if(flag==1)
>   {
>     j<-nrow(d)-testsize
>   }
>
>   print(act)
>   print(res)
>   print(flag)
>   diff<-0
>   s<-0
>   # loop for iterating to each value of the actual value and finding the
> difference with thepredicted value
>   for (mn in 1:length(act))
>   {
>     cat("Value of mn in err", mn)
>     cat("Value of j in err", j)
>     cat("Value of res[j] in err", res[j])
>     diff<-(act[mn]-res[j])
>     print(act[mn])
>     print(res[j])
>     print(diff)
>     s<-s+(diff*diff)
>
>     j<-j+1
>   }
>
>   er1<-sqrt(s/length(act)) #forecasting error
>   print(er1)
>   return(er1)
> }
>
>
>
>  far<-function(p, i, j, k, l, m, n, ervalue)
> {
>   flagarima=0
>   testsize1 = 5
>   cat("does it come here value of p", p)
>   tryCatch({
>     air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima
> model  # the arima model
>
>     f<- forecast(air.model,h=testsize1) # for getting the error
>
>     ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>
>   }, error=function(e)
>   {
>
>     return(NA)
>   }
>   )
>   cat("Value of error", ervalue[i,j,k,l,m,n,p])
>   cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>   print(ervalue)
>   return(ervalue)
> }
> ---------------------------
>
>    library('TTR')
> library('forecast')
> library('timeSeries')
> library('xts')
> library('RODBC')
>
>
>  maxval=2  # set the array size as well as the maximum parameter value
> here.
> pmax=maxval  # set max p value of the ARIMA model
> dmax=maxval  # set max d value of the ARIMA model
> qmax=maxval  # set max q value of the ARIMA model
> Pmax=maxval  # set max P value of the ARIMA model
> Dmax=maxval  # set max D value of the ARIMA model
> Qmax=maxval  # set max Q value of the ARIMA model
> Permax=2     # maximum value of period.
> freq=12
> d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
> st=2013   # start year value for getting the time series
> month=4
> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as
>  the time
> testsize1=5
> act1<-d[16:20] # the array of actual values, the forecasted values will be
> compared against these values
>
>  A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
> on the max value set the , also it stores the AIC valuearray size
> er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending
> on the max value set the , stores the error value.array size
> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
> depdending on the max value set the , stores the error value.array size
> erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
> depdending on the max value set the , stores the error value.array size
> for (i in 1:pmax)
> {
>   for (j in 1:dmax)
>   {
>     for (k in 1:qmax)
>     {
>       for (l in 1:Pmax)
>       {
>         for (m in 1:Dmax)
>         {
>           for (n in 1:Qmax)
>           {
>             A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n,
> ervalue),simplify=FALSE)
>
>           }
>         }
>       }
>     }
>   }  #for looping through period value
> }
>
>  A
>
>
> On Wed, Nov 19, 2014 at 9:46 AM, Amit Thombre <amitmt at techmahindra.com>
> wrote:
>
>>  Charles,
>>
>> Some variables were missing in the code. I have put them in this code.
>> Now what happens is the value of cat("Value of error",
>> ervalue[i,j,k,l,m,n,p]) gives error value for various runs but they are not
>> in the final Array A. You will have to go through the runs carefully. The
>> array ervalue which is printed shows the value only for that run with
>> previous values as NA. It is like with every new value of p the previous
>> values of ervalue are lost. Just for confirmation the A and ervalue array
>> has the last value as 3.212016. This si just for information so that you
>> can confirm if you are getting this value.
>>
>> ----------------------------------------------------------------------------------------------
>>
>> errf<-function(act, res, testsize, flag)
>> {
>> j=1
>> if(flag==1)
>> {
>> j<-nrow(d)-testsize
>> }
>>
>> print(act)
>> print(res)
>> print(flag)
>> diff<-0
>> s<-0
>> # loop for iterating to each value of the actual value and finding the
>> difference with thepredicted value
>> for (mn in 1:length(act))
>> {
>> cat("Value of mn in err", mn)
>> cat("Value of j in err", j)
>> cat("Value of res[j] in err", res[j])
>> diff<-(act[mn]-res[j])
>> print(act[mn])
>> print(res[j])
>> print(diff)
>> s<-s+(diff*diff)
>>
>> j<-j+1
>> }
>>
>> er1<-sqrt(s/length(act)) #forecasting error
>> print(er1)
>> return(er1)
>> }
>>
>>
>>
>> far<-function(p)
>> {
>>  flagarima=0
>> cat("does it come here value of p", p)
>> tryCatch({
>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima
>> model
>>
>> f<- forecast(air.model,h=5) # for getting the error
>>
>> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>>
>> }, error=function(e)
>> {
>>
>> return(NA)
>> }
>> )
>> cat("Value of error", ervalue[i,j,k,l,m,n,p])
>> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>> print(ervalue)
>> return(ervalue)
>> }
>> ---------------------------
>> library('TTR')
>> library('forecast')
>> library('timeSeries')
>> library('xts')
>> library('RODBC')
>>
>>
>> maxval=2  # set the array size as well as the maximum parameter value
>> here.
>> pmax=maxval  # set max p value of the ARIMA model
>> dmax=maxval  # set max d value of the ARIMA model
>> qmax=maxval  # set max q value of the ARIMA model
>> Pmax=maxval  # set max P value of the ARIMA model
>> Dmax=maxval  # set max D value of the ARIMA model
>> Qmax=maxval  # set max Q value of the ARIMA model
>> Permax=2     # maximum value of period.
>>  freq=12
>> d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
>> st=2013   # start year value for getting the time series
>> month=4
>> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa
>> as  the time
>> testsize1=5
>> act1<-d[16:20] # the array of actual values, the forecasted values will
>> be compared against these values
>>
>>
>>
>> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
>> on the max value set the , also it stores the AIC valuearray size
>> er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending
>> on the max value set the , stores the error value.array size
>> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>> depdending on the max value set the , stores the error value.array size
>> erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>> depdending on the max value set the , stores the error value.array size
>> for (i in 1:pmax)
>> {
>> for (j in 1:dmax)
>> {
>> for (k in 1:qmax)
>> {
>> for (l in 1:Pmax)
>> {
>> for (m in 1:Dmax)
>> {
>> for (n in 1:Qmax)
>> {
>> A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>>
>> }
>> }
>> }
>> }
>> }  #for looping through period value
>> }
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>  ------------------------------
>> *From:* Charles Determan Jr [deter088 at umn.edu]
>> *Sent:* Wednesday, November 19, 2014 8:40 PM
>>
>> *To:* Amit Thombre
>> *Cc:* r-help at r-project.org
>> *Subject:* Re: [R] Using sapply instead of for loop
>>
>>    Amit,
>>
>>  Even if you aren't getting an error with your original global variables
>> it is far better practice to avoid global variables to make you code much
>> more stable.  Of course you ultimately get to decide how your code is
>> written.
>>
>>  That said, your error from the modified far function to include the
>> variables is because you added too much to the sapply statement.  Here is
>> what it should look like:
>>
>>              A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n,
>> ervalue),simplify=FALSE)
>>
>>  You can think apply statements as nothing more than a for loop that has
>> been made 'pretty'.  You wanted to iterate from 1:Permax and use the other
>> variables, therefore you only have the anonymous function (i.e.
>> function(p)) only include the iterator and supply the other values from
>> your nested for loops to the function.  When I run this with you code,
>> making sure the function accepts the extra parameters, the A array appears
>> to fill appropriately whereby most are 'NA' as specified by your 'far'
>> function.  Is this what you expect?
>>
>>
>> On Wed, Nov 19, 2014 at 8:16 AM, Amit Thombre <amitmt at techmahindra.com>
>> wrote:
>>
>>>  Charles ,
>>>
>>> I am not getting an error . The final array A does not have the values
>>> in it. Here is the reproducible code.  I have even tried using paasing
>>> ervalue as a parameter to the function far.
>>>
>>>
>>> -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>
>>> errf<-function(act, res, testsize, flag)
>>> {
>>> j=1
>>> if(flag==1)
>>> {
>>> j<-nrow(d)-testsize
>>> }
>>>
>>> print(act)
>>> print(res)
>>> print(flag)
>>> diff<-0
>>> s<-0
>>> # loop for iterating to each value of the actual value and finding the
>>> difference with thepredicted value
>>> for (mn in 1:length(act))
>>> {
>>> cat("Value of mn in err", mn)
>>> cat("Value of j in err", j)
>>> cat("Value of res[j] in err", res[j])
>>> diff<-(act[mn]-res[j])
>>> print(act[mn])
>>> print(res[j])
>>> print(diff)
>>> s<-s+(diff*diff)
>>>
>>> j<-j+1
>>> }
>>>
>>> er1<-sqrt(s/length(act)) #forecasting error
>>> print(er1)
>>> return(er1)
>>> }
>>>
>>>
>>>
>>> far<-function(p)
>>> {
>>>
>>> cat("does it come here value of p", p)
>>> tryCatch({
>>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>>> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima
>>> model
>>>
>>> f<- forecast(air.model,h=testsize1) # for getting the error
>>>
>>> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>>>
>>> }, error=function(e)
>>> {
>>>
>>> return(NA)
>>> }
>>> )
>>> cat("Value of error", ervalue[i,j,k,l,m,n,p])
>>> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>>> print(ervalue)
>>> return(ervalue)
>>> }
>>>  ---------------------------
>>> library('TTR')
>>> library('forecast')
>>> library('timeSeries')
>>> library('xts')
>>> library('RODBC')
>>>
>>>
>>>  maxval=2  # set the array size as well as the maximum parameter value
>>> here.
>>> pmax=maxval  # set max p value of the ARIMA model
>>> dmax=maxval  # set max d value of the ARIMA model
>>> qmax=maxval  # set max q value of the ARIMA model
>>> Pmax=maxval  # set max P value of the ARIMA model
>>> Dmax=maxval  # set max D value of the ARIMA model
>>> Qmax=maxval  # set max Q value of the ARIMA model
>>> Permax=2     # maximum value of period.
>>>  freq=12
>>> d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21,
>>> 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
>>> st=2013   # start year value for getting the time series
>>> month=4
>>> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa
>>> as  the time
>>>
>>> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending
>>> on the max value set the , also it stores the AIC valuearray size
>>> er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending
>>> on the max value set the , stores the error value.array size
>>> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>>> depdending on the max value set the , stores the error value.array size
>>> erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>>> depdending on the max value set the , stores the error value.array size
>>> for (i in 1:pmax)
>>> {
>>> for (j in 1:dmax)
>>> {
>>> for (k in 1:qmax)
>>> {
>>> for (l in 1:Pmax)
>>> {
>>> for (m in 1:Dmax)
>>> {
>>> for (n in 1:Qmax)
>>> {
>>>  A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>>>
>>> }
>>> }
>>> }
>>> }
>>> }  #for looping through period value
>>> }
>>>
>>>
>>>
>>>
>>>
>>>  ------------------------------
>>> *From:* Charles Determan Jr [deter088 at umn.edu]
>>> *Sent:* Wednesday, November 19, 2014 7:05 PM
>>> *To:* Amit Thombre
>>> *Cc:* r-help at r-project.org
>>> *Subject:* Re: [R] Using sapply instead of for loop
>>>
>>>    Amit,
>>>
>>>  Your question isn't necessarily complete.  You haven't provided a
>>> reproducible example of your data or an error message.  At first glance you
>>> aren't passing anything to your 'far' function except for 'p' and yet it
>>> uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid
>>> global variables as they can lead to broken code.  You should redefine your
>>> function with all the needed parameters and try again.
>>>
>>>  Regards,
>>>
>>> On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com>
>>> wrote:
>>>
>>>> I am trying to replace a for loop by using sapply, The code is for
>>>> forecasting using arima. The code is as follows:-
>>>> -------------------------------------------------------
>>>> far<-function(p)
>>>> {
>>>>
>>>> cat("does it come here value of p", p)
>>>> tryCatch({
>>>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>>>> seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima
>>>> model
>>>>
>>>> f<- forecast(air.model,h=testsize1) # for getting the error
>>>>
>>>> ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>>>>
>>>> }, error=function(e)
>>>> {
>>>>
>>>> return(NA)
>>>> }
>>>> )
>>>> cat("Value of error", ervalue[i,j,k,l,m,n,p])
>>>> cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>>>> print(ervalue)
>>>> return(ervalue)
>>>> }
>>>> ---------------------------
>>>> maxval=2  # set the array size as well as the maximum parameter value
>>>> here.
>>>> pmax=maxval  # set max p value of the ARIMA model
>>>> dmax=maxval  # set max d value of the ARIMA model
>>>> qmax=maxval  # set max q value of the ARIMA model
>>>> Pmax=maxval  # set max P value of the ARIMA model
>>>> Dmax=maxval  # set max D value of the ARIMA model
>>>> Qmax=maxval  # set max Q value of the ARIMA model
>>>> Permax=2     # maximum value of period.
>>>>
>>>> st=2013   # start year value for getting the time series
>>>> month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19,
>>>> 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
>>>> tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa
>>>> as  the time
>>>>
>>>> A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>>>> depdending on the max value set the , also it stores the AIC valuearray size
>>>> ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) #
>>>> depdending on the max value set the , stores the error value.array size
>>>>
>>>> for (i in 1:pmax)
>>>> {
>>>> for (j in 1:dmax)
>>>> {
>>>> for (k in 1:qmax)
>>>> {
>>>> for (l in 1:Pmax)
>>>> {
>>>> for (m in 1:Dmax)
>>>> {
>>>> for (n in 1:Qmax)
>>>> {
>>>> A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)
>>>>
>>>> }
>>>> }
>>>> }
>>>> }
>>>> }  #for looping through period value
>>>> }
>>>> ------------------------------------------------------------------
>>>> The sapply replaces the for loop
>>>> for (p in 1:Permax)
>>>> {
>>>> cat("does it come here value of p", p)
>>>> tryCatch({
>>>> air.model <-Arima(tsa,order=c(i-1,j-1,k-1),
>>>> seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima
>>>> model
>>>> A[i,j,k,l,m,n,p]<-AIC(air.model)
>>>> f<- forecast(air.model,h=testsize1) # for getting the error
>>>> er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
>>>> }, error=function(e)
>>>> {
>>>>
>>>> return(NA)
>>>> }
>>>> )
>>>>  cat("Value of error", er[i,j,k,l,m,n,p])
>>>>  cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
>>>> }
>>>>
>>>> --------------------------------------------------------------------------
>>>> Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call
>>>> to the function far() the array loses the previous value and gets replaced
>>>> with NA and gets the newly calculated error value. Finally the array A gets
>>>> populated with only the latest value and does not hold the old values.
>>>> Please help
>>>>
>>>>
>>>>
>>>> ============================================================================================================================
>>>> Disclaimer:  This message and the information contained herein is
>>>> proprietary and confidential and subject to the Tech Mahindra policy
>>>> statement, you may review the policy at
>>>> http://www.techmahindra.com/Disclaimer.html externally
>>>> http://tim.techmahindra.com/tim/disclaimer.html internally within
>>>> TechMahindra.
>>>>
>>>> ============================================================================================================================
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>>  --
>>>  Dr. Charles Determan, PhD
>>> Integrated Biosciences
>>>
>>> ------------------------------
>>>
>>> ============================================================================================================================
>>> Disclaimer: This message and the information contained herein is
>>> proprietary and confidential and subject to the Tech Mahindra policy
>>> statement, you may review the policy at
>>> http://www.techmahindra.com/Disclaimer.html externally
>>> http://tim.techmahindra.com/tim/disclaimer.html internally within
>>> TechMahindra.
>>>
>>> ============================================================================================================================
>>>
>>>
>>
>>
>>  --
>>  Dr. Charles Determan, PhD
>> Integrated Biosciences
>>
>> ------------------------------
>>
>> ============================================================================================================================
>> Disclaimer: This message and the information contained herein is
>> proprietary and confidential and subject to the Tech Mahindra policy
>> statement, you may review the policy at
>> http://www.techmahindra.com/Disclaimer.html externally
>> http://tim.techmahindra.com/tim/disclaimer.html internally within
>> TechMahindra.
>>
>> ============================================================================================================================
>>
>>
>
>
>  --
>  Dr. Charles Determan, PhD
> Integrated Biosciences
>
> ------------------------------
>
> ============================================================================================================================
> Disclaimer: This message and the information contained herein is
> proprietary and confidential and subject to the Tech Mahindra policy
> statement, you may review the policy at
> http://www.techmahindra.com/Disclaimer.html externally
> http://tim.techmahindra.com/tim/disclaimer.html internally within
> TechMahindra.
>
> ============================================================================================================================
>
>


-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Wed Nov 19 19:20:20 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 19 Nov 2014 18:20:20 +0000 (UTC)
Subject: [R] LAT/LON to UTM in R
In-Reply-To: <CAN5YmCHAfviTX-ABrXn0=uzxzkE9gmSHGirEOe=drjAp7zpLoQ@mail.gmail.com>
References: <CAN5YmCHAfviTX-ABrXn0=uzxzkE9gmSHGirEOe=drjAp7zpLoQ@mail.gmail.com>
Message-ID: <70731515.2706205.1416421220649.JavaMail.yahoo@jws106100.mail.bf1.yahoo.com>

Hi Adam,I was not sure if my solution was correct.This is what I got using ArcGIS to convert the same coordinates:
+proj=lcc +lat_1=49 +lat_2=77 +lat_0=49 +lon_0=-95 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"

structure(list(Long = c(662843L, 303344L, 634922L, 634177L, 310679L,?494213L, 426481L, 629459L, 640032L, 481274L, 712879L, 341099L,?514207L, 567047L, 459277L, 575434L, 709183L, 552371L, 309914L,?661364L, 347328L, 362256L, 627057L, 493059L, 486510L, 556726L,?463097L, 576453L, 371836L, 667253L, 462589L, 482793L, 642357L,?614686L, 438047L, 314744L, 393704L, 373215L, 570837L, 469155L,?485882L, 538672L, 475748L, 334217L, 691256L, 525404L, 382909L,?307134L, 431634L, 647819L, 294333L, 595640L, 587238L, 626271L,?650049L, 605478L, 709453L, 526955L, 460853L, 309177L, 566596L,?685513L, 357648L, 574174L, 489798L, 455265L, 523438L, 382373L,?647731L, 305459L, 693516L, 293105L, 607049L, 429728L, 399064L,?558985L, 354402L, 431804L, 452858L, 334572L, 353150L, 347255L,?309997L, 651587L, 377949L, 546719L, 328154L, 495398L, 544308L,?404778L, 380285L, 472101L, 451486L, 689300L, 641007L, 323389L,?579680L, 660968L, 624387L, 601305L, 704301L, 708545L, 325927L,?304077L, 681973L, 370117L, 536414L, 355787L, 686312L, 464761L,?430765L, 313128L, 370015L, 520058L, 308146L, 700041L, 284328L,?641445L, 382795L, 419101L), Lat = c(5861664L, 5773823L, 5643796L,?5801793L, 5656630L, 5488602L, 5661469L, 5428965L, 5610551L, 5888993L,?5595190L, 5498706L, 5585348L, 5447873L, 5555464L, 5980796L, 5562753L,?5533326L, 5432936L, 5488765L, 5776730L, 5982225L, 5531237L, 6514448L,?6278448L, 6471427L, 6401046L, 6449487L, 6358353L, 6156961L, 6345385L,?6111516L, 6606224L, 6233217L, 6510482L, 6073002L, 6246362L, 6304842L,?6184398L, 5768919L, 5618707L, 5440930L, 5714384L, 5510039L, 5642229L,?5469758L, 5592190L, 5711317L, 5680306L, 5453896L, 5651687L, 5600655L,?5678368L, 5709223L, 5505129L, 5639776L, 5500421L, 5852322L, 5575467L,?5556498L, 5909447L, 5850231L, 5705197L, 5759364L, 5807763L, 5896953L,?5586493L, 5781340L, 5804407L, 5572216L, 5675712L, 5472494L, 5887928L,?5975151L, 5428373L, 5518940L, 5588450L, 5530168L, 5474349L, 5449946L,?6066019L, 6119675L, 5907208L, 6000473L, 5877156L, 6030491L, 5910972L,?5970172L, 6141752L, 6216038L, 6116434L, 6231769L, 5919241L, 5974015L,?6128195L, 6206356L, 6000898L, 6190147L, 5990754L, 5673065L, 5483528L,?5667392L, 5430185L, 5534421L, 5500543L, 5703751L, 5936934L, 5638482L,?5603087L, 5916899L, 5864980L, 5814647L, 5499049L, 5540892L, 5445238L,?5740548L, 5489532L, 5809788L, 5799135L, 5544801L)), .Names = c("Long",?"Lat"), class = "data.frame", row.names = c(NA, -120L))

Is there any difference between these points and those converted in R?
Tahnks,Zilefac

	[[alternative HTML version deleted]]


From ben.bighair at gmail.com  Wed Nov 19 19:03:57 2014
From: ben.bighair at gmail.com (Ben Tupper)
Date: Wed, 19 Nov 2014 13:03:57 -0500
Subject: [R] Why would something work in R but not Rscript?
In-Reply-To: <CAA77SLsYwWgHH4OFom86mB2cbQKSktbSJ0hBjCPUeSjwO+zBHA@mail.gmail.com>
References: <CAA77SLsYwWgHH4OFom86mB2cbQKSktbSJ0hBjCPUeSjwO+zBHA@mail.gmail.com>
Message-ID: <92E225E3-F038-4F18-AF69-AA284019A469@gmail.com>

Hi,

On Nov 19, 2014, at 11:48 AM, Jeff Hansen <dscheffy at gmail.com> wrote:

> I have a script that uses RWeka (and consequently rJava).  When I run
> it in Rstudio everything works fine. When I run it with `R CMD BATCH`,
> everything also works fine. However, when I run it with Rscript, I get
> the following error:
> 
> Error in FUN(X[[1L]], ...) :
>  object is not a Java object reference (jobjRef/jarrayRef).
> Calls: evaluate_Weka_classifier -> t -> sapply -> lapply -> FUN
> Execution halted
> 
> The following is a very simple toy script that you can run to produce
> the results:
> 
> library("RWeka")
> result <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
> observation <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
> df <- data.frame(result,observation)
> j48 <- J48(result ~ .,data=df)
> evaluate_Weka_classifier(j48)
> 
> Save that to a file called help.R and run
> 
> R CMD BATCH help.R
> 
> Check the output file help.Rout and you should see no errors. Now try
> running it from:
> 
> Rscript help.R
> 

You might try using the the --vanilla option for each.  At least then you can rule out that something is being restored in the session of one but not the other. 

R --vanilla CMD BATCH help.R
Rscript --vanilla help.R

Cheers,
Ben


> And you should see the error I've pasted above.
> 
> I have consulted (and will continue to consult) the literature, but
> the manuals tend to answer how usage differs between the two commands
> rather than going into implementation details. I imagine there's a
> difference in how environments get loaded and I just need to adjust
> something on the Rscript side.
> 
> I'm working on a Mac (OSX) running R 3.1.0, but I get the same results
> when I run everything from a Centos 6.4 virtual machine (headless)
> with R 3.1.1 installed.
> 
> Thanks for any help!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jah23 at st-andrews.ac.uk  Wed Nov 19 19:48:24 2014
From: jah23 at st-andrews.ac.uk (Julie Hope)
Date: Wed, 19 Nov 2014 18:48:24 +0000
Subject: [R] Question on R lattice graphics
Message-ID: <CADAXPkbGW3PXkNnCKmHDHcMc40o7LCzVagm8GfYZQRW+cGuzeA@mail.gmail.com>

Hi,

I am currently using the lattice library and trellis graphs to explore my
data.  Without going into too much detail of the data I just have a
question about how dot plot in the lattice library scales things...

I have normalised data that I am exploring as a function of time
partitioned by Date

*dotplot(NormCarbs ~ time | date)*

I also wanted to look at this Normalised data as a function of a conc,
again partitioned by Date

*dotplot(NormCarbs ~ ugml1 | date)*

For the first plot above - the Normcarbs on Y axis is the scale of my
original data (0 - 0.1) - (I have very low values)

However when the second plot above is run in R, my scale jumps to 1-100 on
the Y axis for NormCarbs?

I have no idea if the fact that the ugml1 on the X axis is in the region 0
- 350 ugml1 has anything to do with this?  Is R correcting to keep both
variables in the same order of magnitude?

The NormCarbs data for each plot are both draw from the same column of data
in my csv file  in which the values are between 0 - 0.1.

The second plot looks great actually, I'm just wondering what R is doing.
The code above is all I have specified?

Is it scaling it to allow me to see the data better?  I can't really
decipher the first plots data as everything is so close together so it
would be good to be able to control this to allow me to explore the data
better before I start to

If so, is there a way for me to control this (i.e. by controlling the
scaling)

What is R doing mathematically to my data to get this?

*Any help on this would be very much appreciated.  *

*Thank you!*

*Julie*



Julie Hope (NERC PhD Student)
Sediment Ecology Research Group, University of St Andrews
& School of Geoscience, Bangor University
Scottish Oceans Institute
University of St Andrews, East Sands
St Andrews, Fife
KY16 8LB
Tel No:  01334 463469 / Email: jah23 at st-andrews.ac.uk
Web: http://synergy.st-andrews.ac.uk/serg

	[[alternative HTML version deleted]]


From jah23 at st-andrews.ac.uk  Wed Nov 19 20:06:13 2014
From: jah23 at st-andrews.ac.uk (Julie Hope)
Date: Wed, 19 Nov 2014 19:06:13 +0000
Subject: [R] Question on R lattice graphics
In-Reply-To: <CADAXPkbGW3PXkNnCKmHDHcMc40o7LCzVagm8GfYZQRW+cGuzeA@mail.gmail.com>
References: <CADAXPkbGW3PXkNnCKmHDHcMc40o7LCzVagm8GfYZQRW+cGuzeA@mail.gmail.com>
Message-ID: <CADAXPkZW9Wb+Svs0xz2LxyJ88ftQTWVL96ZZ=cBxSiGDCyvFeg@mail.gmail.com>

Hi,

Ignore the last email - R has plotted the number of data points (100) I
have and using that as a scale rather than the normalised data values

Sorry to be a pest!!

Julie

Julie Hope (NERC PhD Student)
Sediment Ecology Research Group, University of St Andrews
& School of Geoscience, Bangor University
Scottish Oceans Institute
University of St Andrews, East Sands
St Andrews, Fife
KY16 8LB
Tel No:  01334 463469 / Email: jah23 at st-andrews.ac.uk
Web: http://synergy.st-andrews.ac.uk/serg

On 19 November 2014 18:48, Julie Hope <jah23 at st-andrews.ac.uk> wrote:

> Hi,
>
> I am currently using the lattice library and trellis graphs to explore my
> data.  Without going into too much detail of the data I just have a
> question about how dot plot in the lattice library scales things...
>
> I have normalised data that I am exploring as a function of time
> partitioned by Date
>
> *dotplot(NormCarbs ~ time | date)*
>
> I also wanted to look at this Normalised data as a function of a conc,
> again partitioned by Date
>
> *dotplot(NormCarbs ~ ugml1 | date)*
>
> For the first plot above - the Normcarbs on Y axis is the scale of my
> original data (0 - 0.1) - (I have very low values)
>
> However when the second plot above is run in R, my scale jumps to 1-100 on
> the Y axis for NormCarbs?
>
> I have no idea if the fact that the ugml1 on the X axis is in the region 0
> - 350 ugml1 has anything to do with this?  Is R correcting to keep both
> variables in the same order of magnitude?
>
> The NormCarbs data for each plot are both draw from the same column of
> data in my csv file  in which the values are between 0 - 0.1.
>
> The second plot looks great actually, I'm just wondering what R is doing.
> The code above is all I have specified?
>
> Is it scaling it to allow me to see the data better?  I can't really
> decipher the first plots data as everything is so close together so it
> would be good to be able to control this to allow me to explore the data
> better before I start to
>
> If so, is there a way for me to control this (i.e. by controlling the
> scaling)
>
> What is R doing mathematically to my data to get this?
>
> *Any help on this would be very much appreciated.  *
>
> *Thank you!*
>
> *Julie*
>
>
>
> Julie Hope (NERC PhD Student)
> Sediment Ecology Research Group, University of St Andrews
> & School of Geoscience, Bangor University
> Scottish Oceans Institute
> University of St Andrews, East Sands
> St Andrews, Fife
> KY16 8LB
> Tel No:  01334 463469 / Email: jah23 at st-andrews.ac.uk
> Web: http://synergy.st-andrews.ac.uk/serg
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Nov 19 21:12:06 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Nov 2014 12:12:06 -0800
Subject: [R] Symbolic equations to R code?
In-Reply-To: <546CD0A3.30201@ucsd.edu>
References: <546CD0A3.30201@ucsd.edu>
Message-ID: <7E8D730B-BBB1-4A5A-B3CA-CAB52E1A0B0E@comcast.net>


On Nov 19, 2014, at 9:17 AM, Scott Rifkin wrote:

> I'm looking for a package that would take a mathematical function written in symbolic notation and convert it into R code.
> 
> What I have in mind would be something like the following:
> 
> 1) Have a GUI (e.g. something like Microsoft Word equation editor, but computer readable) to produce an equation so that it would look just like it would if you were writing it on paper
> 
> 2) Have some way to translate the GUI into some markup language (perhaps this would be in a non-R application)

There is a web-based equation editor that emits LateX code: http://www.codecogs.com/latex/eqneditor.php

> 
> 3) Have code that translates the markup into an R function.
> 
> My motivation is that I teach an intro stats class that uses randomization techniques. I would like for the students to be able to make up their own statistics and then simulate null distributions or estimate bootstrap confidence intervals using them. I'd prefer to make it as easy as possible for them to enter the formula for their statistics into the computer, and I think that will be easier if it looks from their end just like it would if they were writing it on paper.  After they submit the equation, I would have an RStudio shiny applet take care of the rest.
> 
> Any suggestions for R packages that could do this or pieces of it would be very much appreciated.

There are a couple of dropdown interfaces for R newbies with R Commander being the most famous. You appear not to have investigated what has already been attempted:

http://www.sciviews.org/_rgui/  # Admittedly a very out of date page, lots of dead links.

There are a large number of Rcmdr.plugins.

library(sos)
> unique(findFn("RcmdrPlugin")$Package)
found 667 matches;  retrieving 20 pages, 400 matches.
2 3 4 5 6 7 8 9 10 
11 12 13 14 15 16 17 18 19 20 

Downloaded 383 links in 50 packages.
 [1] "RcmdrPlugin.DoE"            "RcmdrPlugin.MA"            
 [3] "RcmdrPlugin.temis"          "RcmdrPlugin.HH"            
 [5] "RcmdrPlugin.FactoMineR"     "RcmdrPlugin.KMggplot2"     
 [7] "RcmdrPlugin.EACSPIR"        "RcmdrPlugin.survival"      
 [9] "RcmdrPlugin.depthTools"     "RcmdrPlugin.IPSUR"         
[11] "RcmdrPlugin.EZR"            "RcmdrPlugin.MPAStats"      
[13] "RcmdrPlugin.sampling"       "RcmdrPlugin.StatisticalURV"
[15] "RcmdrPlugin.plotByGroup"    "RcmdrPlugin.BCA"           
[17] "RcmdrPlugin.UCA"            "RcmdrPlugin.orloca"        
[19] "RcmdrPlugin.doBy"           "RcmdrPlugin.EBM"           
[21] "RcmdrPlugin.lfstat"         "RcmdrPlugin.EHESsampling"  
[23] "RcmdrPlugin.SLC"            "RcmdrPlugin.steepness"     
[25] "RcmdrPlugin.TextMining"     "RcmdrPlugin.doex"          
[27] "RcmdrPlugin.qual"           "RcmdrPlugin.ROC"           
[29] "RcmdrPlugin.SensoMineR"     "RcmdrPlugin.seeg"          
[31] "RcmdrPlugin.qcc"            "RcmdrPlugin.SM"            
[33] "RcmdrPlugin.TeachingDemos"  "RcmdrPlugin.EcoVirtual"    
[35] "RcmdrPlugin.sos"            "RcmdrPlugin.coin"          
[37] "RcmdrPlugin.epack"          "RcmdrPlugin.SCDA"          
[39] "RcmdrPlugin.SurvivalT"      "RcmdrPlugin.NMBU"          
[41] "RcmdrPlugin.pointG"         "RcmdrPlugin.MAc"           
[43] "RcmdrPlugin.MAd"            "RcmdrPlugin.mosaic"        
[45] "RcmdrPlugin.Export"         "MAc"                       
[47] "RcmdrPlugin.PT"             "compute.es"       

  
> 
> Thanks,
> Scott
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sarifkin at ucsd.edu  Wed Nov 19 21:48:19 2014
From: sarifkin at ucsd.edu (Scott Rifkin)
Date: Wed, 19 Nov 2014 12:48:19 -0800
Subject: [R] Symbolic equations to R code?
In-Reply-To: <7E8D730B-BBB1-4A5A-B3CA-CAB52E1A0B0E@comcast.net>
References: <546CD0A3.30201@ucsd.edu>
	<7E8D730B-BBB1-4A5A-B3CA-CAB52E1A0B0E@comcast.net>
Message-ID: <546D0213.3030108@ucsd.edu>

David, Thanks for your reply and suggestions of packages - let me 
clarify what I am looking for:

The web editor you pointed out is the sort of equation editor I'm 
looking for and I had seen others like this.    Let's say I use that one 
(step 1) and then have Latex code (step 2).  Step (3) would be 
converting the Latex into an R function automatically.  That's the key 
package. In searching for Latex and R there seem to be lots of ways to 
embed R code into Latex but not to translate Latex into R.

As far as R commander, I do indeed know about that and am not looking 
for an R GUI for my students. They are not going be learning R in the 
class.  As far as I know, R commander can't do steps 1-3, but please let 
me know if I am wrong.  After students use the interface in step (1), 
the software in steps (2) and (3) would be for my benefit, to 
programmatically translate the equations of 150+ students into R code.

Thanks,
Scott


From hb at biostat.ucsf.edu  Wed Nov 19 21:57:41 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 19 Nov 2014 12:57:41 -0800
Subject: [R] Why would something work in R but not Rscript?
In-Reply-To: <92E225E3-F038-4F18-AF69-AA284019A469@gmail.com>
References: <CAA77SLsYwWgHH4OFom86mB2cbQKSktbSJ0hBjCPUeSjwO+zBHA@mail.gmail.com>
	<92E225E3-F038-4F18-AF69-AA284019A469@gmail.com>
Message-ID: <CAFDcVCSjJw7r1h9wy7dsq8jK3f6rmc6=NnYeHvELHqY7cDgUGg@mail.gmail.com>

When using Rscript, the 'methods' package is not loaded/attached by
default, which it is when you use R.  See ?Rscript for details.  For
any scripts intended for batch usage, the safest is to only assume
that 'base' is attached, but nothing else.

/Henrik

On Wed, Nov 19, 2014 at 10:03 AM, Ben Tupper <ben.bighair at gmail.com> wrote:
> Hi,
>
> On Nov 19, 2014, at 11:48 AM, Jeff Hansen <dscheffy at gmail.com> wrote:
>
>> I have a script that uses RWeka (and consequently rJava).  When I run
>> it in Rstudio everything works fine. When I run it with `R CMD BATCH`,
>> everything also works fine. However, when I run it with Rscript, I get
>> the following error:
>>
>> Error in FUN(X[[1L]], ...) :
>>  object is not a Java object reference (jobjRef/jarrayRef).
>> Calls: evaluate_Weka_classifier -> t -> sapply -> lapply -> FUN
>> Execution halted
>>
>> The following is a very simple toy script that you can run to produce
>> the results:
>>
>> library("RWeka")
>> result <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
>> observation <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
>> df <- data.frame(result,observation)
>> j48 <- J48(result ~ .,data=df)
>> evaluate_Weka_classifier(j48)
>>
>> Save that to a file called help.R and run
>>
>> R CMD BATCH help.R
>>
>> Check the output file help.Rout and you should see no errors. Now try
>> running it from:
>>
>> Rscript help.R
>>
>
> You might try using the the --vanilla option for each.  At least then you can rule out that something is being restored in the session of one but not the other.
>
> R --vanilla CMD BATCH help.R
> Rscript --vanilla help.R
>
> Cheers,
> Ben
>
>
>> And you should see the error I've pasted above.
>>
>> I have consulted (and will continue to consult) the literature, but
>> the manuals tend to answer how usage differs between the two commands
>> rather than going into implementation details. I imagine there's a
>> difference in how environments get loaded and I just need to adjust
>> something on the Rscript side.
>>
>> I'm working on a Mac (OSX) running R 3.1.0, but I get the same results
>> when I run everything from a Centos 6.4 virtual machine (headless)
>> with R 3.1.1 installed.
>>
>> Thanks for any help!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Wed Nov 19 22:25:15 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 19 Nov 2014 21:25:15 +0000
Subject: [R] R - PLOT - X-AXIS - DECIMALS
In-Reply-To: <CAM_vjun+aL3c0CtjZG7quc9KwijCv265brMcU0KXs5SjYG2RDw@mail.gmail.com>
References: <CAPZdAj2iks3Pk=-bjRe4N5X1nnO4C8E=BhAJtj5_jX+S-ffUmA@mail.gmail.com>
	<CAM_vjun+aL3c0CtjZG7quc9KwijCv265brMcU0KXs5SjYG2RDw@mail.gmail.com>
Message-ID: <D0924A37.112BEE%macqueen1@llnl.gov>

My guess is that perhaps
  plot(aaa$year, aaa$sale)
will produce something closer to what was expected.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/19/14, 8:26 AM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:

>Hi,
>
>Since you didn't provide a reproducible example, we have no way of
>knowing.
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproduci
>ble-example
>
>But if I were you, I'd start with
>str(aaa)
>because my first guess is that your data import did not work as you
>expected.
>
>
>
>On Wed, Nov 19, 2014 at 10:13 AM, statup r <statup.r at gmail.com> wrote:
>> I have a test.csv with two fields "year" and "sale", with below values:
>>
>> year   sale
>> 2001    1002002    200
>
>That looks like three fields to me.
>This may be an example of why you SHOULDN'T post to the list in HTML.
>
>
>> This is what I did in R.
>>
>>>aaa<-read.csv("test.csv")
>>
>>>plot(aaa)
>>
>>
>> But when I call the above plot function why I'm getting decimals in
>>x-axis
>> (year) ex: 2001.0, 2002.05
>>
>> Please help.
>>
>>         [[alternative HTML version deleted]]
>>
>
>-- 
>Sarah Goslee
>http://www.functionaldiversity.org
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Wed Nov 19 22:28:52 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 19 Nov 2014 21:28:52 +0000
Subject: [R] LAT/LON to UTM in R
In-Reply-To: <939705898.2064766.1416327605067.JavaMail.yahoo@jws106125.mail.bf1.yahoo.com>
References: <939705898.2064766.1416327605067.JavaMail.yahoo@jws106125.mail.bf1.yahoo.com>
Message-ID: <D0924B67.112BF6%macqueen1@llnl.gov>

By the way, this question is more appropriate for R-sig-geo.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/18/14, 8:20 AM, "Zilefac Elvis" <zilefacelvis at yahoo.com> wrote:

>Hi,
>I am trying to convert lat/lon to UTM but my results are extremely flawed.
>Is it because of wrong UTM zone or my lon points are negative?
>
>I read a shapefile from ESRI using:
>library(rgdal)
>stations <- readOGR(".","stations")
>print(proj4string(stations))
>## +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
> How to convert to UTM the following lat/lon points? Reproducible example
>at the end.
>
>
>library(sp) 
>
>coordinates(xy) <- c("X", "Y")
>proj4string(xy) <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
>+no_defs")  ## for example
>res <- spTransform(xy, CRS("+proj=longlat +ellps=WGS84 +datum=WGS84
>+no_defs")) 
>res 
>as(res, "SpatialPoints")
>x<-as(res, "SpatialPoints")
>xx<-as.data.frame(x)
>
>#OR
>
>project(as.matrix(xy[,c("X","Y")]), "+proj=longlat +ellps=WGS84
>+datum=WGS84 +no_defs")
>Everything goes wrong with the values.
>
>Please help.
>
>
>
> 
>
>Zilefac.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From frainj at gmail.com  Wed Nov 19 22:48:13 2014
From: frainj at gmail.com (John C Frain)
Date: Wed, 19 Nov 2014 21:48:13 +0000
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <E79F740C-23BC-4D89-B1B4-B2A2F2519F10@utoronto.ca>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<546CAA9D.3010909@mail.usask.ca>
	<CAJYLPFdTPRYUH4e=fdmYAM6=OMuzWm62CKQmef4tpHaTmV-EGw@mail.gmail.com>
	<428BE3D9-9041-4383-9061-03B593002787@dcn.davis.CA.us>
	<81AFDFF0-6D68-4CF4-90A9-91575CE476C6@bapuetz.de>
	<E79F740C-23BC-4D89-B1B4-B2A2F2519F10@utoronto.ca>
Message-ID: <CAHrK515utVsi463W9hRBrFELuYOfzPcP6LnexMYre43KHTVD8A@mail.gmail.com>

What you have written does not work in Matlab -

>> y = [0 0;0.5 0.5;1 1]

y =

         0         0
    0.5000    0.5000
    1.0000    1.0000

>> z = [12, -6]

z =

    12    -6

.

>> y .* z
Error using  .*
Matrix dimensions must agree.

When dimensions agree it you get the same result in R as in Matlab by using
the * operator

> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
> y
     [,1] [,2]
[1,]  0.0  0.0
[2,]  0.5  0.5
[3,]  1.0  1.0
> z = matrix(1:6, ncol=2)
> z
     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6

> prod <- matrix(y*z,2)
> prod
     [,1] [,2] [,3]
[1,]    0    3  2.5
[2,]    1    0  6.0
> prod <- matrix(y*z)
> prod
     [,1] [,2]
[1,]    0  0.0
[2,]    1  2.5
[3,]    3  6.0
>

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 19 November 2014 16:48, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> Or ... if you mean "simpler" as in "less to type", you can define your own
> binary operator by enclosing it in "%" signs, and the assign any of the
> previously proposed solutions, e.g.
>
> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
> z = matrix(c(12, -6),ncol=2)
> '%.*%' <- function(a,b) {a * rep(b, each=3)}
>
>
> y %.*% z
>
>
>      [,1] [,2]
> [1,]    0    0
> [2,]    6   -3
> [3,]   12   -6
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Wed Nov 19 23:47:23 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 19 Nov 2014 16:47:23 -0600
Subject: [R] LAT/LON to UTM in R
In-Reply-To: <70731515.2706205.1416421220649.JavaMail.yahoo@jws106100.mail.bf1.yahoo.com>
References: <CAN5YmCHAfviTX-ABrXn0=uzxzkE9gmSHGirEOe=drjAp7zpLoQ@mail.gmail.com>
	<70731515.2706205.1416421220649.JavaMail.yahoo@jws106100.mail.bf1.yahoo.com>
Message-ID: <CAN5YmCH0ek0f645D5Jj_HLsy7rUaxkWN3V0BF48eox=hD52sCw@mail.gmail.com>

Zilefac,

Those do look different.  I called that data frame "arc", and ran this code
to look at all three versions of the coordinates.

par(mfrow=c(2, 2))
map("world", type="n", xlim=range(xy$X), ylim=range(xy$Y), mar=c(1, 1, 2,
1))
points(xy[, c("X", "Y")])
mtext("xy lat long", side=3, font=2, line=1)
plot(utm, xlab="", ylab="", main="xy utm", axes=FALSE)
plot(arc, xlab="", ylab="", main="arc utm", axes=FALSE)

Jean

On Wed, Nov 19, 2014 at 12:20 PM, Zilefac Elvis <zilefacelvis at yahoo.com>
wrote:

> Hi Adam,
> I was not sure if my solution was correct.
> This is what I got using ArcGIS to convert the same coordinates:
>
> +proj=lcc +lat_1=49 +lat_2=77 +lat_0=49 +lon_0=-95 +x_0=0 +y_0=0
> +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
>
> structure(list(Long = c(662843L, 303344L, 634922L, 634177L, 310679L,
> 494213L, 426481L, 629459L, 640032L, 481274L, 712879L, 341099L,
> 514207L, 567047L, 459277L, 575434L, 709183L, 552371L, 309914L,
> 661364L, 347328L, 362256L, 627057L, 493059L, 486510L, 556726L,
> 463097L, 576453L, 371836L, 667253L, 462589L, 482793L, 642357L,
> 614686L, 438047L, 314744L, 393704L, 373215L, 570837L, 469155L,
> 485882L, 538672L, 475748L, 334217L, 691256L, 525404L, 382909L,
> 307134L, 431634L, 647819L, 294333L, 595640L, 587238L, 626271L,
> 650049L, 605478L, 709453L, 526955L, 460853L, 309177L, 566596L,
> 685513L, 357648L, 574174L, 489798L, 455265L, 523438L, 382373L,
> 647731L, 305459L, 693516L, 293105L, 607049L, 429728L, 399064L,
> 558985L, 354402L, 431804L, 452858L, 334572L, 353150L, 347255L,
> 309997L, 651587L, 377949L, 546719L, 328154L, 495398L, 544308L,
> 404778L, 380285L, 472101L, 451486L, 689300L, 641007L, 323389L,
> 579680L, 660968L, 624387L, 601305L, 704301L, 708545L, 325927L,
> 304077L, 681973L, 370117L, 536414L, 355787L, 686312L, 464761L,
> 430765L, 313128L, 370015L, 520058L, 308146L, 700041L, 284328L,
> 641445L, 382795L, 419101L), Lat = c(5861664L, 5773823L, 5643796L,
> 5801793L, 5656630L, 5488602L, 5661469L, 5428965L, 5610551L, 5888993L,
> 5595190L, 5498706L, 5585348L, 5447873L, 5555464L, 5980796L, 5562753L,
> 5533326L, 5432936L, 5488765L, 5776730L, 5982225L, 5531237L, 6514448L,
> 6278448L, 6471427L, 6401046L, 6449487L, 6358353L, 6156961L, 6345385L,
> 6111516L, 6606224L, 6233217L, 6510482L, 6073002L, 6246362L, 6304842L,
> 6184398L, 5768919L, 5618707L, 5440930L, 5714384L, 5510039L, 5642229L,
> 5469758L, 5592190L, 5711317L, 5680306L, 5453896L, 5651687L, 5600655L,
> 5678368L, 5709223L, 5505129L, 5639776L, 5500421L, 5852322L, 5575467L,
> 5556498L, 5909447L, 5850231L, 5705197L, 5759364L, 5807763L, 5896953L,
> 5586493L, 5781340L, 5804407L, 5572216L, 5675712L, 5472494L, 5887928L,
> 5975151L, 5428373L, 5518940L, 5588450L, 5530168L, 5474349L, 5449946L,
> 6066019L, 6119675L, 5907208L, 6000473L, 5877156L, 6030491L, 5910972L,
> 5970172L, 6141752L, 6216038L, 6116434L, 6231769L, 5919241L, 5974015L,
> 6128195L, 6206356L, 6000898L, 6190147L, 5990754L, 5673065L, 5483528L,
> 5667392L, 5430185L, 5534421L, 5500543L, 5703751L, 5936934L, 5638482L,
> 5603087L, 5916899L, 5864980L, 5814647L, 5499049L, 5540892L, 5445238L,
> 5740548L, 5489532L, 5809788L, 5799135L, 5544801L)), .Names = c("Long",
> "Lat"), class = "data.frame", row.names = c(NA, -120L))
>
>
> Is there any difference between these points and those converted in R?
>
> Tahnks,
> Zilefac
>
>

	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Thu Nov 20 02:11:10 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Thu, 20 Nov 2014 01:11:10 +0000 (UTC)
Subject: [R] LAT/LON to UTM in R
In-Reply-To: <CAN5YmCH0ek0f645D5Jj_HLsy7rUaxkWN3V0BF48eox=hD52sCw@mail.gmail.com>
References: <CAN5YmCH0ek0f645D5Jj_HLsy7rUaxkWN3V0BF48eox=hD52sCw@mail.gmail.com>
Message-ID: <227616596.2888185.1416445870801.JavaMail.yahoo@jws10632.mail.bf1.yahoo.com>

Many thanks Jean for the clarification.Zilefac.
	[[alternative HTML version deleted]]


From thi_veloso at yahoo.com.br  Thu Nov 20 05:03:28 2014
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Thu, 20 Nov 2014 04:03:28 +0000 (UTC)
Subject: [R] Conditionally replace multiple rows in a dataframe
Message-ID: <1407061720.1898163.1416456208930.JavaMail.yahoo@jws100147.mail.ne1.yahoo.com>

Hi programming fellows,
Please consider the following data frame:
df <- structure(list(date = structure(c(1251350100.288, 1251351900,?1251353699.712, 1251355500.288, 1251357300, 1251359099.712), class = c("POSIXct",?"POSIXt")), mix.ratio.csi = c(442.78316237477, 436.757082063885,?425.742872761246, 395.770804307671, 386.758335309866, 392.115887652156), mix.ratio.licor = c(447.141491945547, 441.319548211994, 430.854166343173,?402.232640566763, 393.683007533694, 398.388336602215), ToKeep = c(FALSE,?FALSE, TRUE, TRUE, TRUE, TRUE)), .Names = c("date", "value1",?"value2", "ToKeep"), index = structure(integer(0), ToKeep = c(1L,?2L, 8L, 52L, 53L, 54L, 55L, 85L, 86L, 87L, 88L, 89L, 92L, 93L,?94L, 95L, 96L, 97L, 98L, 99L, 100L, 102L, 103L, 105L, 106L, 192L,?193L, 220L, 223L, 225L, 228L, 229L, 260L, 263L, 264L, 265L, 266L,?267L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L, 314L,?315L, 352L, 353L, 354L, 375L, 376L, 378L, 379L, 380L, 383L, 411L,?412L, 413L, 414L, 415L, 416L, 418L, 419L, 445L, 453L, 463L, 464L,?465L, 466L, 467L, 468L, 497L, 504L, 547L, 548L, 549L, 586L, 589L,?630L, 631L, 632L, 633L, 634L, 635L, 636L, 644L, 645L, 646L, 647L,?648L, 649L, 650L, 651L, 674L, 675L, 676L, 677L, 678L, 682L, 687L,?690L, 691L, 724L, 725L, 726L, 727L, 728L, 729L, 730L, 731L, 732L,?733L, 734L, 735L, 736L, 739L, 740L, 741L, 742L, 768L, 771L, 772L,?773L, 774L, 775L, 776L, 777L, 778L, 779L, 3L, 4L, 5L, 6L, 7L,?9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,?22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L,?35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L,?48L, 49L, 50L, 51L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L,?65L, 66L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L,?78L, 79L, 80L, 81L, 82L, 83L, 84L, 90L, 91L, 101L, 104L, 107L,?108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L,?119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 129L,?130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L, 140L,?141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L, 150L, 151L,?152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L, 161L, 162L,?163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L, 172L, 173L,?174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 182L, 183L, 184L,?185L, 186L, 187L, 188L, 189L, 190L, 191L, 194L, 195L, 196L, 197L,?198L, 199L, 200L, 201L, 202L, 203L, 204L, 205L, 206L, 207L, 208L,?209L, 210L, 211L, 212L, 213L, 214L, 215L, 216L, 217L, 218L, 219L,?221L, 222L, 224L, 226L, 227L, 230L, 231L, 232L, 233L, 234L, 235L,?236L, 237L, 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L,?247L, 248L, 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L,?258L, 259L, 261L, 262L, 268L, 269L, 270L, 271L, 272L, 273L, 274L,?275L, 276L, 277L, 278L, 279L, 280L, 281L, 282L, 283L, 284L, 285L,?286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L, 294L, 295L, 296L,?297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 316L, 317L, 318L,?319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L, 329L,?330L, 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L, 340L,?341L, 342L, 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L, 351L,?355L, 356L, 357L, 358L, 359L, 360L, 361L, 362L, 363L, 364L, 365L,?366L, 367L, 368L, 369L, 370L, 371L, 372L, 373L, 374L, 377L, 381L,?382L, 384L, 385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,?394L, 395L, 396L, 397L, 398L, 399L, 400L, 401L, 402L, 403L, 404L,?405L, 406L, 407L, 408L, 409L, 410L, 417L, 420L, 421L, 422L, 423L,?424L, 425L, 426L, 427L, 428L, 429L, 430L, 431L, 432L, 433L, 434L,?435L, 436L, 437L, 438L, 439L, 440L, 441L, 442L, 443L, 444L, 446L,?447L, 448L, 449L, 450L, 451L, 452L, 454L, 455L, 456L, 457L, 458L,?459L, 460L, 461L, 462L, 469L, 470L, 471L, 472L, 473L, 474L, 475L,?476L, 477L, 478L, 479L, 480L, 481L, 482L, 483L, 484L, 485L, 486L,?487L, 488L, 489L, 490L, 491L, 492L, 493L, 494L, 495L, 496L, 498L,?499L, 500L, 501L, 502L, 503L, 505L, 506L, 507L, 508L, 509L, 510L,?511L, 512L, 513L, 514L, 515L, 516L, 517L, 518L, 519L, 520L, 521L,?522L, 523L, 524L, 525L, 526L, 527L, 528L, 529L, 530L, 531L, 532L,?533L, 534L, 535L, 536L, 537L, 538L, 539L, 540L, 541L, 542L, 543L,?544L, 545L, 546L, 550L, 551L, 552L, 553L, 554L, 555L, 556L, 557L,?558L, 559L, 560L, 561L, 562L, 563L, 564L, 565L, 566L, 567L, 568L,?569L, 570L, 571L, 572L, 573L, 574L, 575L, 576L, 577L, 578L, 579L,?580L, 581L, 582L, 583L, 584L, 585L, 587L, 588L, 590L, 591L, 592L,?593L, 594L, 595L, 596L, 597L, 598L, 599L, 600L, 601L, 602L, 603L,?604L, 605L, 606L, 607L, 608L, 609L, 610L, 611L, 612L, 613L, 614L,?615L, 616L, 617L, 618L, 619L, 620L, 621L, 622L, 623L, 624L, 625L,?626L, 627L, 628L, 629L, 637L, 638L, 639L, 640L, 641L, 642L, 643L,?652L, 653L, 654L, 655L, 656L, 657L, 658L, 659L, 660L, 661L, 662L,?663L, 664L, 665L, 666L, 667L, 668L, 669L, 670L, 671L, 672L, 673L,?679L, 680L, 681L, 683L, 684L, 685L, 686L, 688L, 689L, 692L, 693L,?694L, 695L, 696L, 697L, 698L, 699L, 700L, 701L, 702L, 703L, 704L,?705L, 706L, 707L, 708L, 709L, 710L, 711L, 712L, 713L, 714L, 715L,?716L, 717L, 718L, 719L, 720L, 721L, 722L, 723L, 737L, 738L, 743L,?744L, 745L, 746L, 747L, 748L, 749L, 750L, 751L, 752L, 753L, 754L,?755L, 756L, 757L, 758L, 759L, 760L, 761L, 762L, 763L, 764L, 765L,?766L, 767L, 769L, 770L, 780L, 781L, 782L, 783L, 784L, 785L, 786L,?787L, 788L, 789L)), row.names = c(NA, 6L), class = "data.frame")
I need to create a new data.frame with the following structure:?
1) if column 'ToKeep' is TRUE, then columns 'date', 'value1' and 'value2' remain the same;
2) if column 'ToKeep' is FALSE, then columns 'value1' e 'value2' receive NA (and 'date' remains the same).
I have been trying to use ifelse so far, but still haven't found the right indexing procedure:
df[, c(2,3)] <- lapply(df[, 4], function(x) ifelse(x == FALSE, NA, x))
Any suggestion??Greetings,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898
	[[alternative HTML version deleted]]


From esra_ulasan at icloud.com  Thu Nov 20 05:29:26 2014
From: esra_ulasan at icloud.com (Esra Ulasan)
Date: Wed, 19 Nov 2014 23:29:26 -0500
Subject: [R] portfolio optimization in R
Message-ID: <C77E9D51-2AE0-4F06-BD67-F848E269C50F@icloud.com>

Dear Sir/Madam,

I am a PhD candidate and writing my dissertation about portfolio optimization in R. However, I have some problems with the codes. It always give the dimension error. Could you help me to fix it?

Yours sincerely,

Here are the codes:

optimization <- function(x) {
  mean <- colMeans(x)
  names(mean) <-assets.names
  p <- ncol(x)
  n <- nrow(x)
  M <- as.integer(p)
  S <- cov(x)
  invS<- solve(S)
  u <- rep(1,p)

#w <- matrix(rep(0,p), nrow=p)
#r <- seq(0,length=p); w <- cbind (diag(450));    #sum of 1 
#constraint <- cbind(diag(450), rep(0, 450));  #non-negativity constraint
  a <- matrix(rep(0,4), nrow=2)
  a[1,1] <- u%*%invS%*%u; 
  a[1,2] <- a[2,1] <- u%*%invS%*%mean
  a[2,2] <-mean%*%invS%*%mean 
  d <- a[1,1]*a[2,2]-a[1,2]*a[1,2] 
  f <- (invS%*%(a[2,2]*u-a[1,2]*mean))/d 
  g <- (invS%*%(-a[1,2]*u+a[1,1]*mean))/d
  rho <- 0.5
  r <- seq(0, rho,length= M)
  w <- matrix(rep(0, p*M), nrow=p)
  for(m in 1:M) w[,m] <- f+r[,m]*g
  #w <- f+(rho*g)
  w[,m] >=0
  sum([,m])==1
  s <- sqrt(a[1,1]*((r-a[1,2]/a[1,1])^2)/d+ 1/a[1,1]) 
  ss <- sqrt(diag(S))
  names(ss) <- assets.name
  minp <- c(sqrt(1/a[1,1]), a[1,2]/a[1,1])
  wmimp<- f+(a[1,2]/a[1,1])*g; 
  tanp <- c(sqrt(a[2,2])/a[1,2], a[2,2]/a[1,2]) 
  wtanp <- f+(a[2,2]/a[1,2])*g; 
  return(solve(s, r, ss, p, minp, tanp, wminp, wtanp))
}
result=optimization(x)

From statup.r at gmail.com  Thu Nov 20 07:33:18 2014
From: statup.r at gmail.com (statup r)
Date: Thu, 20 Nov 2014 12:03:18 +0530
Subject: [R] R - PLOT - X-AXIS - DECIMALS
In-Reply-To: <D0924A37.112BEE%macqueen1@llnl.gov>
References: <CAPZdAj2iks3Pk=-bjRe4N5X1nnO4C8E=BhAJtj5_jX+S-ffUmA@mail.gmail.com>
	<CAM_vjun+aL3c0CtjZG7quc9KwijCv265brMcU0KXs5SjYG2RDw@mail.gmail.com>
	<D0924A37.112BEE%macqueen1@llnl.gov>
Message-ID: <CAPZdAj1=Gq-iXmfAtOu8JY1LaeE=ifyDhi6QAXJbZO3b5+sRTA@mail.gmail.com>

this got fixed when I added 3 more rows to my existing test.csv file, i.e.
new file got below data, with additional 3 rows:

   year   sale
    2001  100
    2002  200
    2003  300
    2004  400
    2005  500

What's the secret behind 5 rows , i mean is there any link between plot
chart and 5 values ?
If I use less than 5 rows, it's breaking x-axis values into 5 decimals !!!

Hope you understood what I've told, if not, let me know...will provide you
reproducible steps.

Many Thanks.





On Thu, Nov 20, 2014 at 2:55 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> My guess is that perhaps
>   plot(aaa$year, aaa$sale)
> will produce something closer to what was expected.
>
> --
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 11/19/14, 8:26 AM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:
>
> >Hi,
> >
> >Since you didn't provide a reproducible example, we have no way of
> >knowing.
> >
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproduci
> >ble-example
> >
> >But if I were you, I'd start with
> >str(aaa)
> >because my first guess is that your data import did not work as you
> >expected.
> >
> >
> >
> >On Wed, Nov 19, 2014 at 10:13 AM, statup r <statup.r at gmail.com> wrote:
> >> I have a test.csv with two fields "year" and "sale", with below values:
> >>
> >> year   sale
> >> 2001    1002002    200
> >
> >That looks like three fields to me.
> >This may be an example of why you SHOULDN'T post to the list in HTML.
> >
> >
> >> This is what I did in R.
> >>
> >>>aaa<-read.csv("test.csv")
> >>
> >>>plot(aaa)
> >>
> >>
> >> But when I call the above plot function why I'm getting decimals in
> >>x-axis
> >> (year) ex: 2001.0, 2002.05
> >>
> >> Please help.
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >
> >--
> >Sarah Goslee
> >http://www.functionaldiversity.org
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From raphael.fraser at gmail.com  Thu Nov 20 07:54:15 2014
From: raphael.fraser at gmail.com (Raphael Fraser)
Date: Thu, 20 Nov 2014 01:54:15 -0500
Subject: [R] SVYPLOT
Message-ID: <CAAQQ577OAQKmZxxbfjzPfk-qiEasZqFWgXpLaFJOQdwjx1zROQ@mail.gmail.com>

How do I set the limits of my x and y axis in svyplot? xlim and ylim does
not work.

Regards,
Raphael

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Nov 20 08:23:35 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 19 Nov 2014 23:23:35 -0800
Subject: [R] Conditionally replace multiple rows in a dataframe
In-Reply-To: <1407061720.1898163.1416456208930.JavaMail.yahoo@jws100147.mail.ne1.yahoo.com>
References: <1407061720.1898163.1416456208930.JavaMail.yahoo@jws100147.mail.ne1.yahoo.com>
Message-ID: <5F1CB562-FA2E-4364-A8AA-49292ECF1429@dcn.davis.CA.us>

Hi. Your failure to post in plain text has nearly rendered your example code unusable. Please post in plain text, not HTML. Also, the ToKeep attribute was most of your example, yet was completely irrelevant.

I recommend avoiding the variable name "df" as it is easily confused with the base function of that name.

Assuming the data frame is in variable DF...

DF[ !DF$ToKeep, c("value1","value2") ] <- NA

should do it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 19, 2014 8:03:28 PM PST, "Thiago V. dos Santos" <thi_veloso at yahoo.com.br> wrote:
>Hi programming fellows,
>Please consider the following data frame:
>df <- structure(list(date = structure(c(1251350100.288,
>1251351900,?1251353699.712, 1251355500.288, 1251357300,
>1251359099.712), class = c("POSIXct",?"POSIXt")), mix.ratio.csi =
>c(442.78316237477, 436.757082063885,?425.742872761246,
>395.770804307671, 386.758335309866, 392.115887652156), mix.ratio.licor
>= c(447.141491945547, 441.319548211994,
>430.854166343173,?402.232640566763, 393.683007533694,
>398.388336602215), ToKeep = c(FALSE,?FALSE, TRUE, TRUE, TRUE, TRUE)),
>.Names = c("date", "value1",?"value2", "ToKeep"), index =
>structure(integer(0), ToKeep = c(1L,?2L, 8L, 52L, 53L, 54L, 55L, 85L,
>86L, 87L, 88L, 89L, 92L, 93L,?94L, 95L, 96L, 97L, 98L, 99L, 100L, 102L,
>103L, 105L, 106L, 192L,?193L, 220L, 223L, 225L, 228L, 229L, 260L, 263L,
>264L, 265L, 266L,?267L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L,
>313L, 314L,?315L, 352L, 353L, 354L, 375L, 376L, 378L, 379L, 380L, 383L,
>411L,?412L, 413L, 414L, 415L, 416L, 418L, 419L, 445L, 453L, 463L,
>464L,?465L, 466L, 467L, 468L, 497L, 504L, 547L, 548L, 549L, 586L,
>589L,?630L, 631L, 632L, 633L, 634L, 635L, 636L, 644L, 645L, 646L,
>647L,?648L, 649L, 650L, 651L, 674L, 675L, 676L, 677L, 678L, 682L,
>687L,?690L, 691L, 724L, 725L, 726L, 727L, 728L, 729L, 730L, 731L,
>732L,?733L, 734L, 735L, 736L, 739L, 740L, 741L, 742L, 768L, 771L,
>772L,?773L, 774L, 775L, 776L, 777L, 778L, 779L, 3L, 4L, 5L, 6L, 7L,?9L,
>10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,?22L, 23L,
>24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L,?35L, 36L, 37L,
>38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L,?48L, 49L, 50L, 51L,
>56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L,?65L, 66L, 67L, 68L, 69L,
>70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L,?78L, 79L, 80L, 81L, 82L, 83L,
>84L, 90L, 91L, 101L, 104L, 107L,?108L, 109L, 110L, 111L, 112L, 113L,
>114L, 115L, 116L, 117L, 118L,?119L, 120L, 121L, 122L, 123L, 124L, 125L,
>126L, 127L, 128L, 129L,?130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L,
>138L, 139L, 140L,?141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
>150L, 151L,?152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L, 161L,
>162L,?163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L, 172L,
>173L,?174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 182L, 183L,
>184L,?185L, 186L, 187L, 188L, 189L, 190L, 191L, 194L, 195L, 196L,
>197L,?198L, 199L, 200L, 201L, 202L, 203L, 204L, 205L, 206L, 207L,
>208L,?209L, 210L, 211L, 212L, 213L, 214L, 215L, 216L, 217L, 218L,
>219L,?221L, 222L, 224L, 226L, 227L, 230L, 231L, 232L, 233L, 234L,
>235L,?236L, 237L, 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L,
>246L,?247L, 248L, 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L,
>257L,?258L, 259L, 261L, 262L, 268L, 269L, 270L, 271L, 272L, 273L,
>274L,?275L, 276L, 277L, 278L, 279L, 280L, 281L, 282L, 283L, 284L,
>285L,?286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L, 294L, 295L,
>296L,?297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 316L, 317L,
>318L,?319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L,
>329L,?330L, 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L,
>340L,?341L, 342L, 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L,
>351L,?355L, 356L, 357L, 358L, 359L, 360L, 361L, 362L, 363L, 364L,
>365L,?366L, 367L, 368L, 369L, 370L, 371L, 372L, 373L, 374L, 377L,
>381L,?382L, 384L, 385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L,
>393L,?394L, 395L, 396L, 397L, 398L, 399L, 400L, 401L, 402L, 403L,
>404L,?405L, 406L, 407L, 408L, 409L, 410L, 417L, 420L, 421L, 422L,
>423L,?424L, 425L, 426L, 427L, 428L, 429L, 430L, 431L, 432L, 433L,
>434L,?435L, 436L, 437L, 438L, 439L, 440L, 441L, 442L, 443L, 444L,
>446L,?447L, 448L, 449L, 450L, 451L, 452L, 454L, 455L, 456L, 457L,
>458L,?459L, 460L, 461L, 462L, 469L, 470L, 471L, 472L, 473L, 474L,
>475L,?476L, 477L, 478L, 479L, 480L, 481L, 482L, 483L, 484L, 485L,
>486L,?487L, 488L, 489L, 490L, 491L, 492L, 493L, 494L, 495L, 496L,
>498L,?499L, 500L, 501L, 502L, 503L, 505L, 506L, 507L, 508L, 509L,
>510L,?511L, 512L, 513L, 514L, 515L, 516L, 517L, 518L, 519L, 520L,
>521L,?522L, 523L, 524L, 525L, 526L, 527L, 528L, 529L, 530L, 531L,
>532L,?533L, 534L, 535L, 536L, 537L, 538L, 539L, 540L, 541L, 542L,
>543L,?544L, 545L, 546L, 550L, 551L, 552L, 553L, 554L, 555L, 556L,
>557L,?558L, 559L, 560L, 561L, 562L, 563L, 564L, 565L, 566L, 567L,
>568L,?569L, 570L, 571L, 572L, 573L, 574L, 575L, 576L, 577L, 578L,
>579L,?580L, 581L, 582L, 583L, 584L, 585L, 587L, 588L, 590L, 591L,
>592L,?593L, 594L, 595L, 596L, 597L, 598L, 599L, 600L, 601L, 602L,
>603L,?604L, 605L, 606L, 607L, 608L, 609L, 610L, 611L, 612L, 613L,
>614L,?615L, 616L, 617L, 618L, 619L, 620L, 621L, 622L, 623L, 624L,
>625L,?626L, 627L, 628L, 629L, 637L, 638L, 639L, 640L, 641L, 642L,
>643L,?652L, 653L, 654L, 655L, 656L, 657L, 658L, 659L, 660L, 661L,
>662L,?663L, 664L, 665L, 666L, 667L, 668L, 669L, 670L, 671L, 672L,
>673L,?679L, 680L, 681L, 683L, 684L, 685L, 686L, 688L, 689L, 692L,
>693L,?694L, 695L, 696L, 697L, 698L, 699L, 700L, 701L, 702L, 703L,
>704L,?705L, 706L, 707L, 708L, 709L, 710L, 711L, 712L, 713L, 714L,
>715L,?716L, 717L, 718L, 719L, 720L, 721L, 722L, 723L, 737L, 738L,
>743L,?744L, 745L, 746L, 747L, 748L, 749L, 750L, 751L, 752L, 753L,
>754L,?755L, 756L, 757L, 758L, 759L, 760L, 761L, 762L, 763L, 764L,
>765L,?766L, 767L, 769L, 770L, 780L, 781L, 782L, 783L, 784L, 785L,
>786L,?787L, 788L, 789L)), row.names = c(NA, 6L), class = "data.frame")
>I need to create a new data.frame with the following structure:?
>1) if column 'ToKeep' is TRUE, then columns 'date', 'value1' and
>'value2' remain the same;
>2) if column 'ToKeep' is FALSE, then columns 'value1' e 'value2'
>receive NA (and 'date' remains the same).
>I have been trying to use ifelse so far, but still haven't found the
>right indexing procedure:
>df[, c(2,3)] <- lapply(df[, 4], function(x) ifelse(x == FALSE, NA, x))
>Any suggestion??Greetings,
>--
>Thiago V. dos Santos
>PhD student
>Land and Atmospheric Science
>University of Minnesota
>http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
>Phone: (612) 323 9898
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Nov 20 09:08:16 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 20 Nov 2014 08:08:16 +0000
Subject: [R] R - PLOT - X-AXIS - DECIMALS
In-Reply-To: <CAPZdAj1=Gq-iXmfAtOu8JY1LaeE=ifyDhi6QAXJbZO3b5+sRTA@mail.gmail.com>
References: <CAPZdAj2iks3Pk=-bjRe4N5X1nnO4C8E=BhAJtj5_jX+S-ffUmA@mail.gmail.com>
	<CAM_vjun+aL3c0CtjZG7quc9KwijCv265brMcU0KXs5SjYG2RDw@mail.gmail.com>
	<D0924A37.112BEE%macqueen1@llnl.gov>
	<CAPZdAj1=Gq-iXmfAtOu8JY1LaeE=ifyDhi6QAXJbZO3b5+sRTA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEF1AD@SRVEXCHMBX.precheza.cz>

Hi

Plot calls function pretty which calculates values for annotating axes.

You can get rid of this behaviour by

plot(..., axes=FALSE)

and calling
axis(1, ...)

see

?plot
?pretty
?axis

Cheers
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of statup r
> Sent: Thursday, November 20, 2014 7:33 AM
> To: MacQueen, Don
> Cc: r-help
> Subject: Re: [R] R - PLOT - X-AXIS - DECIMALS
>
> this got fixed when I added 3 more rows to my existing test.csv file,
> i.e.
> new file got below data, with additional 3 rows:
>
>    year   sale
>     2001  100
>     2002  200
>     2003  300
>     2004  400
>     2005  500
>
> What's the secret behind 5 rows , i mean is there any link between plot
> chart and 5 values ?
> If I use less than 5 rows, it's breaking x-axis values into 5 decimals
> !!!
>
> Hope you understood what I've told, if not, let me know...will provide
> you
> reproducible steps.
>
> Many Thanks.
>
>
>
>
>
> On Thu, Nov 20, 2014 at 2:55 AM, MacQueen, Don <macqueen1 at llnl.gov>
> wrote:
>
> > My guess is that perhaps
> >   plot(aaa$year, aaa$sale)
> > will produce something closer to what was expected.
> >
> > --
> > Don MacQueen
> >
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> >
> >
> >
> >
> >
> > On 11/19/14, 8:26 AM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:
> >
> > >Hi,
> > >
> > >Since you didn't provide a reproducible example, we have no way of
> > >knowing.
> > >
> > http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> reproduci
> > >ble-example
> > >
> > >But if I were you, I'd start with
> > >str(aaa)
> > >because my first guess is that your data import did not work as you
> > >expected.
> > >
> > >
> > >
> > >On Wed, Nov 19, 2014 at 10:13 AM, statup r <statup.r at gmail.com>
> wrote:
> > >> I have a test.csv with two fields "year" and "sale", with below
> values:
> > >>
> > >> year   sale
> > >> 2001    1002002    200
> > >
> > >That looks like three fields to me.
> > >This may be an example of why you SHOULDN'T post to the list in
> HTML.
> > >
> > >
> > >> This is what I did in R.
> > >>
> > >>>aaa<-read.csv("test.csv")
> > >>
> > >>>plot(aaa)
> > >>
> > >>
> > >> But when I call the above plot function why I'm getting decimals
> in
> > >>x-axis
> > >> (year) ex: 2001.0, 2002.05
> > >>
> > >> Please help.
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >
> > >--
> > >Sarah Goslee
> > >http://www.functionaldiversity.org
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ntfredo at gmail.com  Thu Nov 20 11:03:40 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 20 Nov 2014 13:03:40 +0300
Subject: [R] Adapt sweave function to produce an automatic pdf.
Message-ID: <CAGh51gSyq7A_0ETnoKmrb03Z0GRVUX5k8+Y_ZRjjQ4Lc_yidSA@mail.gmail.com>

Hi All,

I want to make a climate method ("sweave_function"). The aim is to be able
to adapt sweave code that produces an automatic pdf so that it can works
for my climate object. i.e. instead of compile pdf, I call :
data_obj$sweave_function() and get the pdf. for instance I have
boxplot_method() and I want to output it in this way. Thanks for the help!!!

Ex: This how I started but I don't understand how I can proceed.

climate$methods(sweave_function = function(climate_data_objs_str,
climate_data_objs_ind
) {

#---------------------------------------------------------------------------------------------
  #  This function returns the pdf using sweave function in R
  #  The required arguments are:
  #   climate_data_objs_str  : list of the names of climate data objects in
the climate object
  #   climate_data_objs_ind  : list of the indices of climate data object
in the climate object
  #   note that one of the above arguments is enough.

#--------------------------------------------------------------------------------------------


  # get_climate_data_objects returns a list of the climate_data objects
specified
  # in the arguements.
  # If no objects specified then all climate_data objects will be taken by
default

  climate_data_objs = get_climate_data_objects(climate_data_objs_str,
climate_data_objs_ind)
})

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From amitmt at techmahindra.com  Thu Nov 20 11:13:47 2014
From: amitmt at techmahindra.com (Amit Thombre)
Date: Thu, 20 Nov 2014 15:43:47 +0530
Subject: [R] Using sapply instead of for loop
In-Reply-To: <CAOLJphkWysgmoCbVCh3dPgczYTv7Q9AePko8+5dAkstkpsZpTg@mail.gmail.com>
References: <4A753D3F0C227041AB666DA6283A81F313C5C3716A@SINPUNMBX002.TechMahindra.com>
	<CAOLJph=yCjT3AFUYFq2fbZymnpv-s+Yk_P28kZJF3_aPWDam7Q@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716C@SINPUNMBX002.TechMahindra.com>
	<CAOLJphmJO4vPZbcHadarSWdrXjgxtKvgBb_508df5tp4RaGgjQ@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716E@SINPUNMBX002.TechMahindra.com>
	<CAOLJph=ZP4D5wYx-THEN5G63VcAtPzj3o0h4+B3gjTudpJZ=Bg@mail.gmail.com>
	<4A753D3F0C227041AB666DA6283A81F313C5C3716F@SINPUNMBX002.TechMahindra.com>,
	<CAOLJphkWysgmoCbVCh3dPgczYTv7Q9AePko8+5dAkstkpsZpTg@mail.gmail.com>
Message-ID: <4A753D3F0C227041AB666DA6283A81F313C5C37172@SINPUNMBX002.TechMahindra.com>

Thanks Charles. I will have to extract the min value from the list A by selecting the proper index.

________________________________
From: Charles Determan Jr [deter088 at umn.edu]
Sent: Wednesday, November 19, 2014 11:48 PM
To: Amit Thombre
Cc: r-help at r-project.org
Subject: Re: [R] Using sapply instead of for loop

Ah, this is because you are overwriting your 'A' with each loop.  As a simple way to demonstrate this I changed:

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2))

to

A <- list()

and then I changed
A <- sapply((1:Permax),function(p) far(p, i, j, k, l, m,n, ervalue),simplify=FALSE)

to

A<-append(A, sapply((1:Permax),function(p) far(p, i, j, k, l, m,n, ervalue),simplify=FALSE))

Once the run is complete you can find the 6.28757 in A[126].  You can easily create another index so you can find it easily in the list but the ervalue is indeed , , 2,2,2,1,2 as you show above.


On Wed, Nov 19, 2014 at 11:46 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
The following is printed for  i,j,k,l,m,n,p 2 2 2 2 2 1 2

"Value of error 6.281757Value of i,j,k,l,m,n,p 2 2 2 2 2 1 2, , 1, 1, 1, 1, 1"
Thus ervalue[2,2,2,2,2,1,2] should be 6.28175, But after all the runs if you try to get this array value it is NA. Also I think A is a list so not sure how to extract the same but the following is displayed for the same array as ervalue for A when I type A after all the runs .
, , 2, 2, 2, 1, 2
     [,1] [,2]
[1,]   NA   NA
[2,]   NA   NA
The ervalue itself loses the values , I think and hence A does not have it.

________________________________
From: Charles Determan Jr [deter088 at umn.edu<mailto:deter088 at umn.edu>]
Sent: Wednesday, November 19, 2014 10:04 PM

To: Amit Thombre
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Using sapply instead of for loop

The following provides array A with 3.212016 as the last value.  The error values are indeed in the array here.  There is also another with 6.281757 that I noticed at first glance.

errf<-function(act, res, testsize, flag)
{
  j=1
  if(flag==1)
  {
    j<-nrow(d)-testsize
  }

  print(act)
  print(res)
  print(flag)
  diff<-0
  s<-0
  # loop for iterating to each value of the actual value and finding the difference with thepredicted value
  for (mn in 1:length(act))
  {
    cat("Value of mn in err", mn)
    cat("Value of j in err", j)
    cat("Value of res[j] in err", res[j])
    diff<-(act[mn]-res[j])
    print(act[mn])
    print(res[j])
    print(diff)
    s<-s+(diff*diff)

    j<-j+1
  }

  er1<-sqrt(s/length(act)) #forecasting error
  print(er1)
  return(er1)
}



far<-function(p, i, j, k, l, m, n, ervalue)
{
  flagarima=0
  testsize1 = 5
  cat("does it come here value of p", p)
  tryCatch({
    air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima model  # the arima model

    f<- forecast(air.model,h=testsize1) # for getting the error

    ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

  }, error=function(e)
  {

    return(NA)
  }
  )
  cat("Value of error", ervalue[i,j,k,l,m,n,p])
  cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
  print(ervalue)
  return(ervalue)
}
---------------------------

  library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time
testsize1=5
act1<-d[16:20] # the array of actual values, the forecasted values will be compared against these values

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
  for (j in 1:dmax)
  {
    for (k in 1:qmax)
    {
      for (l in 1:Pmax)
      {
        for (m in 1:Dmax)
        {
          for (n in 1:Qmax)
          {
            A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n, ervalue),simplify=FALSE)

          }
        }
      }
    }
  }  #for looping through period value
}

A


On Wed, Nov 19, 2014 at 9:46 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
Charles,

Some variables were missing in the code. I have put them in this code. Now what happens is the value of cat("Value of error", ervalue[i,j,k,l,m,n,p]) gives error value for various runs but they are not in the final Array A. You will have to go through the runs carefully. The array ervalue which is printed shows the value only for that run with previous values as NA. It is like with every new value of p the previous values of ervalue are lost. Just for confirmation the A and ervalue array has the last value as 3.212016. This si just for information so that you can confirm if you are getting this value.
----------------------------------------------------------------------------------------------

errf<-function(act, res, testsize, flag)
{
j=1
if(flag==1)
{
j<-nrow(d)-testsize
}

print(act)
print(res)
print(flag)
diff<-0
s<-0
# loop for iterating to each value of the actual value and finding the difference with thepredicted value
for (mn in 1:length(act))
{
cat("Value of mn in err", mn)
cat("Value of j in err", j)
cat("Value of res[j] in err", res[j])
diff<-(act[mn]-res[j])
print(act[mn])
print(res[j])
print(diff)
s<-s+(diff*diff)

j<-j+1
}

er1<-sqrt(s/length(act)) #forecasting error
print(er1)
return(er1)
}



far<-function(p)
{
flagarima=0
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=-0.254)  # the arima model

f<- forecast(air.model,h=5) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(3, 2, 5,29, 6, 10, 8, 4, 4, 5, 4, 6, 6, 1, 2, 3,5, 6, 9, 10)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time
testsize1=5
act1<-d[16:20] # the array of actual values, the forecasted values will be compared against these values



A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}






















________________________________
From: Charles Determan Jr [deter088 at umn.edu<mailto:deter088 at umn.edu>]
Sent: Wednesday, November 19, 2014 8:40 PM

To: Amit Thombre
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Using sapply instead of for loop

Amit,

Even if you aren't getting an error with your original global variables it is far better practice to avoid global variables to make you code much more stable.  Of course you ultimately get to decide how your code is written.

That said, your error from the modified far function to include the variables is because you added too much to the sapply statement.  Here is what it should look like:

            A<-sapply((1:Permax),function(p) far(p, i, j, k, l, m,n, ervalue),simplify=FALSE)

You can think apply statements as nothing more than a for loop that has been made 'pretty'.  You wanted to iterate from 1:Permax and use the other variables, therefore you only have the anonymous function (i.e. function(p)) only include the iterator and supply the other values from your nested for loops to the function.  When I run this with you code, making sure the function accepts the extra parameters, the A array appears to fill appropriately whereby most are 'NA' as specified by your 'far' function.  Is this what you expect?


On Wed, Nov 19, 2014 at 8:16 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
Charles ,

I am not getting an error . The final array A does not have the values in it. Here is the reproducible code.  I have even tried using paasing ervalue as a parameter to the function far.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

errf<-function(act, res, testsize, flag)
{
j=1
if(flag==1)
{
j<-nrow(d)-testsize
}

print(act)
print(res)
print(flag)
diff<-0
s<-0
# loop for iterating to each value of the actual value and finding the difference with thepredicted value
for (mn in 1:length(act))
{
cat("Value of mn in err", mn)
cat("Value of j in err", j)
cat("Value of res[j] in err", res[j])
diff<-(act[mn]-res[j])
print(act[mn])
print(res[j])
print(diff)
s<-s+(diff*diff)

j<-j+1
}

er1<-sqrt(s/length(act)) #forecasting error
print(er1)
return(er1)
}



far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
library('TTR')
library('forecast')
library('timeSeries')
library('xts')
library('RODBC')


maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.
freq=12
d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
st=2013   # start year value for getting the time series
month=4
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
er<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval,2)) # depdending on the max value set the , stores the error value.array size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
erval1<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size
for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}





________________________________
From: Charles Determan Jr [deter088 at umn.edu<mailto:deter088 at umn.edu>]
Sent: Wednesday, November 19, 2014 7:05 PM
To: Amit Thombre
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] Using sapply instead of for loop

Amit,

Your question isn't necessarily complete.  You haven't provided a reproducible example of your data or an error message.  At first glance you aren't passing anything to your 'far' function except for 'p' and yet it uses i,j,k,l,m,n,testsize1, and act1.  You should generally try to avoid global variables as they can lead to broken code.  You should redefine your function with all the needed parameters and try again.

Regards,

On Wed, Nov 19, 2014 at 3:47 AM, Amit Thombre <amitmt at techmahindra.com<mailto:amitmt at techmahindra.com>> wrote:
I am trying to replace a for loop by using sapply, The code is for forecasting using arima. The code is as follows:-
-------------------------------------------------------
far<-function(p)
{

cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p-1), lambda=lbda)  # the arima model

f<- forecast(air.model,h=testsize1) # for getting the error

ervalue[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)

}, error=function(e)
{

return(NA)
}
)
cat("Value of error", ervalue[i,j,k,l,m,n,p])
cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
print(ervalue)
return(ervalue)
}
---------------------------
maxval=2  # set the array size as well as the maximum parameter value here.
pmax=maxval  # set max p value of the ARIMA model
dmax=maxval  # set max d value of the ARIMA model
qmax=maxval  # set max q value of the ARIMA model
Pmax=maxval  # set max P value of the ARIMA model
Dmax=maxval  # set max D value of the ARIMA model
Qmax=maxval  # set max Q value of the ARIMA model
Permax=2     # maximum value of period.

st=2013   # start year value for getting the time series
month=4 d<-c(10, 13, 14, 4, 5, 6, 7, 10, 12, 13, 14, 20, 3, 4, 5, 19, 23, 21, 18, 19, 21, 14, 15, 16, 17, 12, 20, 19, 17)
tsa<-ts(d, frequency=freq, start=c(st,month))  # store the data in tsa as  the time

A<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , also it stores the AIC valuearray size
ervalue<-array(, c(maxval,maxval,maxval,maxval,maxval,maxval, 2)) # depdending on the max value set the , stores the error value.array size

for (i in 1:pmax)
{
for (j in 1:dmax)
{
for (k in 1:qmax)
{
for (l in 1:Pmax)
{
for (m in 1:Dmax)
{
for (n in 1:Qmax)
{
A<-sapply((1:Permax),function(p) far(p),simplify=FALSE)

}
}
}
}
}  #for looping through period value
}
------------------------------------------------------------------
The sapply replaces the for loop
for (p in 1:Permax)
{
cat("does it come here value of p", p)
tryCatch({
air.model <-Arima(tsa,order=c(i-1,j-1,k-1), seasonal=list(order=c(l-1,m-1,n-1),period=p), lambda=lbda)  # the arima model
A[i,j,k,l,m,n,p]<-AIC(air.model)
f<- forecast(air.model,h=testsize1) # for getting the error
er[i,j,k,l,m,n,p]<-errf(act1,f$mean,testsize1,flagarima)
}, error=function(e)
{

return(NA)
}
)
 cat("Value of error", er[i,j,k,l,m,n,p])
 cat("Value of i,j,k,l,m,n,p", i, j, k, l, m, n,p)
}
--------------------------------------------------------------------------
Now the er[I,j,k,l,m,n,p] I.e the error get populated but on every call to the function far() the array loses the previous value and gets replaced with NA and gets the newly calculated error value. Finally the array A gets populated with only the latest value and does not hold the old values. Please help


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Dr. Charles Determan, PhD
Integrated Biosciences

________________________________
============================================================================================================================
Disclaimer: This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================



--
Dr. Charles Determan, PhD
Integrated Biosciences

________________________________
============================================================================================================================
Disclaimer: This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================



--
Dr. Charles Determan, PhD
Integrated Biosciences

________________________________
============================================================================================================================
Disclaimer: This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================



--
Dr. Charles Determan, PhD
Integrated Biosciences


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From i.petzev at gmail.com  Thu Nov 20 11:23:30 2014
From: i.petzev at gmail.com (i.petzev)
Date: Thu, 20 Nov 2014 11:23:30 +0100
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <8780E3CE-13F9-43B3-A6D3-5034BBE6304C@comcast.net>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
	<B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
	<79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>
	<8780E3CE-13F9-43B3-A6D3-5034BBE6304C@comcast.net>
Message-ID: <12A4CACA-73C3-42A8-BC54-053A891B7B7C@gmail.com>

Hi David,

sorry, I was not clear. The difference comes from defining or not defining ?w? in the boot() function. The results with your function and your approach are thus:

set.seed(1111)
x <- rnorm(50)
y <- rnorm(50)
weights <- runif(50)
weights <- weights / sum(weights)
dataset <- cbind(x,y,weights)

vw_m_diff <- function(dataset,w) {
  differences <- dataset[w,1]-dataset[w,2]
  weights <- dataset[w, "weights"]
  return(weighted.mean(x=differences, w=weights))
}
res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
boot.ci(res_boot)

BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 1000 bootstrap replicates

CALL : 
boot.ci(boot.out = res_boot)

Intervals : 
Level      Normal              Basic         
95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )  

Level     Percentile            BCa          
95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )  
Calculations and Intervals on Original Scale

********************************************************************************************************************

However, without defining ?w? in the bootstrap function, i.e., running an ordinary and not a weighted bootstrap, the results are:

res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000)
boot.ci(res_boot)

BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 1000 bootstrap replicates

CALL : 
boot.ci(boot.out = res_boot)

Intervals : 
Level      Normal              Basic         
95%   (-0.6265,  0.4966 )   (-0.6125,  0.5249 )  

Level     Percentile            BCa          
95%   (-0.6714,  0.4661 )   (-0.6747,  0.4559 )  
Calculations and Intervals on Original Scale

On 19 Nov 2014, at 17:49, David Winsemius <dwinsemius at comcast.net> wrote:

>>> vw_m_diff <- function(dataset,w) {
>>>     differences <- dataset[w,1]-dataset[w,2]
>>>    weights <- dataset[w, "weights"]
>>>    return(weighted.mean(x=differences, w=weights))
>>>  }


	[[alternative HTML version deleted]]


From akhil.dua.12 at gmail.com  Thu Nov 20 11:52:40 2014
From: akhil.dua.12 at gmail.com (Akhil dua)
Date: Thu, 20 Nov 2014 16:22:40 +0530
Subject: [R] auto.arima function in R
Message-ID: <CAPSaRtCajO2QEb384zuuSQuL92PRweYWfu7piUJC277peWycaQ@mail.gmail.com>

Hello every one,

I am using daily data of the flight departure.

Departure Date           Load (Seats booked/Capacity)
12/01/2011                                 10
13/01/2011                                 12
14/01/2011                                 09

I want to fit an arima model to the data for forecasting the load for the
next day flight. I am using auto.arima function in R.

Residuals and fitted values that I am getting from auto.arima has NAs
whereas I don't have any NA in my original data.

Can anyone please help me with the probable reason for this.


-- 
Akhil Dua
Consultant
 National Institute of Public Finance and Policy
18/2 Satsang Vihar Marg,
Special Institutional Area,
New Delhi 110067.
[Near JNU East Gate]

Mo:+91-7827-662-202
Location:- http://goo.gl/ICCjh

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Thu Nov 20 13:04:09 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 20 Nov 2014 04:04:09 -0800
Subject: [R] Conditionally replace multiple rows in a dataframe
In-Reply-To: <5F1CB562-FA2E-4364-A8AA-49292ECF1429@dcn.davis.CA.us>
References: <1407061720.1898163.1416456208930.JavaMail.yahoo@jws100147.mail.ne1.yahoo.com>
	<5F1CB562-FA2E-4364-A8AA-49292ECF1429@dcn.davis.CA.us>
Message-ID: <CACk-te2kkjW40JxPsHmJV-Er4PtKTv_Cqx4p0uUozm+ehC7m5g@mail.gmail.com>

No comment on whether Jeff's solution is correct or not, but for
setting elements to NA, perhaps preferable, as it invokes the NA
method for data frames -- see ?NA -- is:

is,na(DF[ , c("value1","value2") ]) <- !DF$ToKeep

(I would welcome comments from cogniscenti as to whether this is
actually preferable and why or why not)

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Nov 19, 2014 at 11:23 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Hi. Your failure to post in plain text has nearly rendered your example code unusable. Please post in plain text, not HTML. Also, the ToKeep attribute was most of your example, yet was completely irrelevant.
>
> I recommend avoiding the variable name "df" as it is easily confused with the base function of that name.
>
> Assuming the data frame is in variable DF...
>
> DF[ !DF$ToKeep, c("value1","value2") ] <- NA
>
> should do it.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 19, 2014 8:03:28 PM PST, "Thiago V. dos Santos" <thi_veloso at yahoo.com.br> wrote:
>>Hi programming fellows,
>>Please consider the following data frame:
>>df <- structure(list(date = structure(c(1251350100.288,
>>1251351900, 1251353699.712, 1251355500.288, 1251357300,
>>1251359099.712), class = c("POSIXct", "POSIXt")), mix.ratio.csi =
>>c(442.78316237477, 436.757082063885, 425.742872761246,
>>395.770804307671, 386.758335309866, 392.115887652156), mix.ratio.licor
>>= c(447.141491945547, 441.319548211994,
>>430.854166343173, 402.232640566763, 393.683007533694,
>>398.388336602215), ToKeep = c(FALSE, FALSE, TRUE, TRUE, TRUE, TRUE)),
>>.Names = c("date", "value1", "value2", "ToKeep"), index =
>>structure(integer(0), ToKeep = c(1L, 2L, 8L, 52L, 53L, 54L, 55L, 85L,
>>86L, 87L, 88L, 89L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 102L,
>>103L, 105L, 106L, 192L, 193L, 220L, 223L, 225L, 228L, 229L, 260L, 263L,
>>264L, 265L, 266L, 267L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L,
>>313L, 314L, 315L, 352L, 353L, 354L, 375L, 376L, 378L, 379L, 380L, 383L,
>>411L, 412L, 413L, 414L, 415L, 416L, 418L, 419L, 445L, 453L, 463L,
>>464L, 465L, 466L, 467L, 468L, 497L, 504L, 547L, 548L, 549L, 586L,
>>589L, 630L, 631L, 632L, 633L, 634L, 635L, 636L, 644L, 645L, 646L,
>>647L, 648L, 649L, 650L, 651L, 674L, 675L, 676L, 677L, 678L, 682L,
>>687L, 690L, 691L, 724L, 725L, 726L, 727L, 728L, 729L, 730L, 731L,
>>732L, 733L, 734L, 735L, 736L, 739L, 740L, 741L, 742L, 768L, 771L,
>>772L, 773L, 774L, 775L, 776L, 777L, 778L, 779L, 3L, 4L, 5L, 6L, 7L, 9L,
>>10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
>>24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L,
>>38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L,
>>56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L,
>>70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L, 81L, 82L, 83L,
>>84L, 90L, 91L, 101L, 104L, 107L, 108L, 109L, 110L, 111L, 112L, 113L,
>>114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L,
>>126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L,
>>138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
>>150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L, 161L,
>>162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L, 172L,
>>173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 182L, 183L,
>>184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 194L, 195L, 196L,
>>197L, 198L, 199L, 200L, 201L, 202L, 203L, 204L, 205L, 206L, 207L,
>>208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L, 216L, 217L, 218L,
>>219L, 221L, 222L, 224L, 226L, 227L, 230L, 231L, 232L, 233L, 234L,
>>235L, 236L, 237L, 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L,
>>246L, 247L, 248L, 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L,
>>257L, 258L, 259L, 261L, 262L, 268L, 269L, 270L, 271L, 272L, 273L,
>>274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L, 282L, 283L, 284L,
>>285L, 286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L, 294L, 295L,
>>296L, 297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 316L, 317L,
>>318L, 319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L,
>>329L, 330L, 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L,
>>340L, 341L, 342L, 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L,
>>351L, 355L, 356L, 357L, 358L, 359L, 360L, 361L, 362L, 363L, 364L,
>>365L, 366L, 367L, 368L, 369L, 370L, 371L, 372L, 373L, 374L, 377L,
>>381L, 382L, 384L, 385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L,
>>393L, 394L, 395L, 396L, 397L, 398L, 399L, 400L, 401L, 402L, 403L,
>>404L, 405L, 406L, 407L, 408L, 409L, 410L, 417L, 420L, 421L, 422L,
>>423L, 424L, 425L, 426L, 427L, 428L, 429L, 430L, 431L, 432L, 433L,
>>434L, 435L, 436L, 437L, 438L, 439L, 440L, 441L, 442L, 443L, 444L,
>>446L, 447L, 448L, 449L, 450L, 451L, 452L, 454L, 455L, 456L, 457L,
>>458L, 459L, 460L, 461L, 462L, 469L, 470L, 471L, 472L, 473L, 474L,
>>475L, 476L, 477L, 478L, 479L, 480L, 481L, 482L, 483L, 484L, 485L,
>>486L, 487L, 488L, 489L, 490L, 491L, 492L, 493L, 494L, 495L, 496L,
>>498L, 499L, 500L, 501L, 502L, 503L, 505L, 506L, 507L, 508L, 509L,
>>510L, 511L, 512L, 513L, 514L, 515L, 516L, 517L, 518L, 519L, 520L,
>>521L, 522L, 523L, 524L, 525L, 526L, 527L, 528L, 529L, 530L, 531L,
>>532L, 533L, 534L, 535L, 536L, 537L, 538L, 539L, 540L, 541L, 542L,
>>543L, 544L, 545L, 546L, 550L, 551L, 552L, 553L, 554L, 555L, 556L,
>>557L, 558L, 559L, 560L, 561L, 562L, 563L, 564L, 565L, 566L, 567L,
>>568L, 569L, 570L, 571L, 572L, 573L, 574L, 575L, 576L, 577L, 578L,
>>579L, 580L, 581L, 582L, 583L, 584L, 585L, 587L, 588L, 590L, 591L,
>>592L, 593L, 594L, 595L, 596L, 597L, 598L, 599L, 600L, 601L, 602L,
>>603L, 604L, 605L, 606L, 607L, 608L, 609L, 610L, 611L, 612L, 613L,
>>614L, 615L, 616L, 617L, 618L, 619L, 620L, 621L, 622L, 623L, 624L,
>>625L, 626L, 627L, 628L, 629L, 637L, 638L, 639L, 640L, 641L, 642L,
>>643L, 652L, 653L, 654L, 655L, 656L, 657L, 658L, 659L, 660L, 661L,
>>662L, 663L, 664L, 665L, 666L, 667L, 668L, 669L, 670L, 671L, 672L,
>>673L, 679L, 680L, 681L, 683L, 684L, 685L, 686L, 688L, 689L, 692L,
>>693L, 694L, 695L, 696L, 697L, 698L, 699L, 700L, 701L, 702L, 703L,
>>704L, 705L, 706L, 707L, 708L, 709L, 710L, 711L, 712L, 713L, 714L,
>>715L, 716L, 717L, 718L, 719L, 720L, 721L, 722L, 723L, 737L, 738L,
>>743L, 744L, 745L, 746L, 747L, 748L, 749L, 750L, 751L, 752L, 753L,
>>754L, 755L, 756L, 757L, 758L, 759L, 760L, 761L, 762L, 763L, 764L,
>>765L, 766L, 767L, 769L, 770L, 780L, 781L, 782L, 783L, 784L, 785L,
>>786L, 787L, 788L, 789L)), row.names = c(NA, 6L), class = "data.frame")
>>I need to create a new data.frame with the following structure:
>>1) if column 'ToKeep' is TRUE, then columns 'date', 'value1' and
>>'value2' remain the same;
>>2) if column 'ToKeep' is FALSE, then columns 'value1' e 'value2'
>>receive NA (and 'date' remains the same).
>>I have been trying to use ifelse so far, but still haven't found the
>>right indexing procedure:
>>df[, c(2,3)] <- lapply(df[, 4], function(x) ifelse(x == FALSE, NA, x))
>>Any suggestion? Greetings,
>>--
>>Thiago V. dos Santos
>>PhD student
>>Land and Atmospheric Science
>>University of Minnesota
>>http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
>>Phone: (612) 323 9898
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Thu Nov 20 13:16:43 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Nov 2014 12:16:43 +0000
Subject: [R] auto.arima function in R
In-Reply-To: <CAPSaRtCajO2QEb384zuuSQuL92PRweYWfu7piUJC277peWycaQ@mail.gmail.com>
References: <CAPSaRtCajO2QEb384zuuSQuL92PRweYWfu7piUJC277peWycaQ@mail.gmail.com>
Message-ID: <546DDBAB.6040802@stats.ox.ac.uk>

There is no auto.arima function 'in R'.  Do give credit/blame where it 
is due (probably package 'forecast').

Without the reproducible example the posting guide asked for, we can 
only guess wildly.  I at least decline to do so.


On 20/11/2014 10:52, Akhil dua wrote:
> Hello every one,
>
> I am using daily data of the flight departure.
>
> Departure Date           Load (Seats booked/Capacity)
> 12/01/2011                                 10
> 13/01/2011                                 12
> 14/01/2011                                 09
>
> I want to fit an arima model to the data for forecasting the load for the
> next day flight. I am using auto.arima function in R.
>
> Residuals and fitted values that I am getting from auto.arima has NAs
> whereas I don't have any NA in my original data.
>
> Can anyone please help me with the probable reason for this.
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From gunter.berton at gene.com  Thu Nov 20 13:32:24 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 20 Nov 2014 04:32:24 -0800
Subject: [R] Conditionally replace multiple rows in a dataframe
In-Reply-To: <CACk-te2kkjW40JxPsHmJV-Er4PtKTv_Cqx4p0uUozm+ehC7m5g@mail.gmail.com>
References: <1407061720.1898163.1416456208930.JavaMail.yahoo@jws100147.mail.ne1.yahoo.com>
	<5F1CB562-FA2E-4364-A8AA-49292ECF1429@dcn.davis.CA.us>
	<CACk-te2kkjW40JxPsHmJV-Er4PtKTv_Cqx4p0uUozm+ehC7m5g@mail.gmail.com>
Message-ID: <CACk-te2dDGH7ysF23_AXPhewJK7yapy7C_0pwjtL4SGO+3Sd6Q@mail.gmail.com>

Sorry, just noticed the typo: it's is.na() of course.

-- Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Nov 20, 2014 at 4:04 AM, Bert Gunter <bgunter at gene.com> wrote:
> No comment on whether Jeff's solution is correct or not, but for
> setting elements to NA, perhaps preferable, as it invokes the NA
> method for data frames -- see ?NA -- is:
>
> is,na(DF[ , c("value1","value2") ]) <- !DF$ToKeep
>
> (I would welcome comments from cogniscenti as to whether this is
> actually preferable and why or why not)
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Wed, Nov 19, 2014 at 11:23 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> Hi. Your failure to post in plain text has nearly rendered your example code unusable. Please post in plain text, not HTML. Also, the ToKeep attribute was most of your example, yet was completely irrelevant.
>>
>> I recommend avoiding the variable name "df" as it is easily confused with the base function of that name.
>>
>> Assuming the data frame is in variable DF...
>>
>> DF[ !DF$ToKeep, c("value1","value2") ] <- NA
>>
>> should do it.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 19, 2014 8:03:28 PM PST, "Thiago V. dos Santos" <thi_veloso at yahoo.com.br> wrote:
>>>Hi programming fellows,
>>>Please consider the following data frame:
>>>df <- structure(list(date = structure(c(1251350100.288,
>>>1251351900, 1251353699.712, 1251355500.288, 1251357300,
>>>1251359099.712), class = c("POSIXct", "POSIXt")), mix.ratio.csi =
>>>c(442.78316237477, 436.757082063885, 425.742872761246,
>>>395.770804307671, 386.758335309866, 392.115887652156), mix.ratio.licor
>>>= c(447.141491945547, 441.319548211994,
>>>430.854166343173, 402.232640566763, 393.683007533694,
>>>398.388336602215), ToKeep = c(FALSE, FALSE, TRUE, TRUE, TRUE, TRUE)),
>>>.Names = c("date", "value1", "value2", "ToKeep"), index =
>>>structure(integer(0), ToKeep = c(1L, 2L, 8L, 52L, 53L, 54L, 55L, 85L,
>>>86L, 87L, 88L, 89L, 92L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L, 102L,
>>>103L, 105L, 106L, 192L, 193L, 220L, 223L, 225L, 228L, 229L, 260L, 263L,
>>>264L, 265L, 266L, 267L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L,
>>>313L, 314L, 315L, 352L, 353L, 354L, 375L, 376L, 378L, 379L, 380L, 383L,
>>>411L, 412L, 413L, 414L, 415L, 416L, 418L, 419L, 445L, 453L, 463L,
>>>464L, 465L, 466L, 467L, 468L, 497L, 504L, 547L, 548L, 549L, 586L,
>>>589L, 630L, 631L, 632L, 633L, 634L, 635L, 636L, 644L, 645L, 646L,
>>>647L, 648L, 649L, 650L, 651L, 674L, 675L, 676L, 677L, 678L, 682L,
>>>687L, 690L, 691L, 724L, 725L, 726L, 727L, 728L, 729L, 730L, 731L,
>>>732L, 733L, 734L, 735L, 736L, 739L, 740L, 741L, 742L, 768L, 771L,
>>>772L, 773L, 774L, 775L, 776L, 777L, 778L, 779L, 3L, 4L, 5L, 6L, 7L, 9L,
>>>10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
>>>24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L,
>>>38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 51L,
>>>56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L,
>>>70L, 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L, 81L, 82L, 83L,
>>>84L, 90L, 91L, 101L, 104L, 107L, 108L, 109L, 110L, 111L, 112L, 113L,
>>>114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L,
>>>126L, 127L, 128L, 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L,
>>>138L, 139L, 140L, 141L, 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L,
>>>150L, 151L, 152L, 153L, 154L, 155L, 156L, 157L, 158L, 159L, 160L, 161L,
>>>162L, 163L, 164L, 165L, 166L, 167L, 168L, 169L, 170L, 171L, 172L,
>>>173L, 174L, 175L, 176L, 177L, 178L, 179L, 180L, 181L, 182L, 183L,
>>>184L, 185L, 186L, 187L, 188L, 189L, 190L, 191L, 194L, 195L, 196L,
>>>197L, 198L, 199L, 200L, 201L, 202L, 203L, 204L, 205L, 206L, 207L,
>>>208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L, 216L, 217L, 218L,
>>>219L, 221L, 222L, 224L, 226L, 227L, 230L, 231L, 232L, 233L, 234L,
>>>235L, 236L, 237L, 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L,
>>>246L, 247L, 248L, 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L,
>>>257L, 258L, 259L, 261L, 262L, 268L, 269L, 270L, 271L, 272L, 273L,
>>>274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L, 282L, 283L, 284L,
>>>285L, 286L, 287L, 288L, 289L, 290L, 291L, 292L, 293L, 294L, 295L,
>>>296L, 297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 316L, 317L,
>>>318L, 319L, 320L, 321L, 322L, 323L, 324L, 325L, 326L, 327L, 328L,
>>>329L, 330L, 331L, 332L, 333L, 334L, 335L, 336L, 337L, 338L, 339L,
>>>340L, 341L, 342L, 343L, 344L, 345L, 346L, 347L, 348L, 349L, 350L,
>>>351L, 355L, 356L, 357L, 358L, 359L, 360L, 361L, 362L, 363L, 364L,
>>>365L, 366L, 367L, 368L, 369L, 370L, 371L, 372L, 373L, 374L, 377L,
>>>381L, 382L, 384L, 385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L,
>>>393L, 394L, 395L, 396L, 397L, 398L, 399L, 400L, 401L, 402L, 403L,
>>>404L, 405L, 406L, 407L, 408L, 409L, 410L, 417L, 420L, 421L, 422L,
>>>423L, 424L, 425L, 426L, 427L, 428L, 429L, 430L, 431L, 432L, 433L,
>>>434L, 435L, 436L, 437L, 438L, 439L, 440L, 441L, 442L, 443L, 444L,
>>>446L, 447L, 448L, 449L, 450L, 451L, 452L, 454L, 455L, 456L, 457L,
>>>458L, 459L, 460L, 461L, 462L, 469L, 470L, 471L, 472L, 473L, 474L,
>>>475L, 476L, 477L, 478L, 479L, 480L, 481L, 482L, 483L, 484L, 485L,
>>>486L, 487L, 488L, 489L, 490L, 491L, 492L, 493L, 494L, 495L, 496L,
>>>498L, 499L, 500L, 501L, 502L, 503L, 505L, 506L, 507L, 508L, 509L,
>>>510L, 511L, 512L, 513L, 514L, 515L, 516L, 517L, 518L, 519L, 520L,
>>>521L, 522L, 523L, 524L, 525L, 526L, 527L, 528L, 529L, 530L, 531L,
>>>532L, 533L, 534L, 535L, 536L, 537L, 538L, 539L, 540L, 541L, 542L,
>>>543L, 544L, 545L, 546L, 550L, 551L, 552L, 553L, 554L, 555L, 556L,
>>>557L, 558L, 559L, 560L, 561L, 562L, 563L, 564L, 565L, 566L, 567L,
>>>568L, 569L, 570L, 571L, 572L, 573L, 574L, 575L, 576L, 577L, 578L,
>>>579L, 580L, 581L, 582L, 583L, 584L, 585L, 587L, 588L, 590L, 591L,
>>>592L, 593L, 594L, 595L, 596L, 597L, 598L, 599L, 600L, 601L, 602L,
>>>603L, 604L, 605L, 606L, 607L, 608L, 609L, 610L, 611L, 612L, 613L,
>>>614L, 615L, 616L, 617L, 618L, 619L, 620L, 621L, 622L, 623L, 624L,
>>>625L, 626L, 627L, 628L, 629L, 637L, 638L, 639L, 640L, 641L, 642L,
>>>643L, 652L, 653L, 654L, 655L, 656L, 657L, 658L, 659L, 660L, 661L,
>>>662L, 663L, 664L, 665L, 666L, 667L, 668L, 669L, 670L, 671L, 672L,
>>>673L, 679L, 680L, 681L, 683L, 684L, 685L, 686L, 688L, 689L, 692L,
>>>693L, 694L, 695L, 696L, 697L, 698L, 699L, 700L, 701L, 702L, 703L,
>>>704L, 705L, 706L, 707L, 708L, 709L, 710L, 711L, 712L, 713L, 714L,
>>>715L, 716L, 717L, 718L, 719L, 720L, 721L, 722L, 723L, 737L, 738L,
>>>743L, 744L, 745L, 746L, 747L, 748L, 749L, 750L, 751L, 752L, 753L,
>>>754L, 755L, 756L, 757L, 758L, 759L, 760L, 761L, 762L, 763L, 764L,
>>>765L, 766L, 767L, 769L, 770L, 780L, 781L, 782L, 783L, 784L, 785L,
>>>786L, 787L, 788L, 789L)), row.names = c(NA, 6L), class = "data.frame")
>>>I need to create a new data.frame with the following structure:
>>>1) if column 'ToKeep' is TRUE, then columns 'date', 'value1' and
>>>'value2' remain the same;
>>>2) if column 'ToKeep' is FALSE, then columns 'value1' e 'value2'
>>>receive NA (and 'date' remains the same).
>>>I have been trying to use ifelse so far, but still haven't found the
>>>right indexing procedure:
>>>df[, c(2,3)] <- lapply(df[, 4], function(x) ifelse(x == FALSE, NA, x))
>>>Any suggestion? Greetings,
>>>--
>>>Thiago V. dos Santos
>>>PhD student
>>>Land and Atmospheric Science
>>>University of Minnesota
>>>http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
>>>Phone: (612) 323 9898
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Thu Nov 20 14:18:13 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 20 Nov 2014 08:18:13 -0500
Subject: [R] portfolio optimization in R
In-Reply-To: <C77E9D51-2AE0-4F06-BD67-F848E269C50F@icloud.com>
References: <C77E9D51-2AE0-4F06-BD67-F848E269C50F@icloud.com>
Message-ID: <3C1B2C93-5863-4301-A860-121E383383C1@utoronto.ca>

Indeed.
Start here: 
http://www.r-bloggers.com/three-tips-for-posting-good-questions-to-r-help-and-stack-overflow/

and then read this: 
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Then put some comments into your code about what you think it should do. Oh, and clean up the formatting.
Hope this helps.
B.



On Nov 19, 2014, at 11:29 PM, Esra Ulasan <esra_ulasan at icloud.com> wrote:

> Dear Sir/Madam,
> 
> I am a PhD candidate and writing my dissertation about portfolio optimization in R. However, I have some problems with the codes. It always give the dimension error. Could you help me to fix it?
> 
> Yours sincerely,
> 
> Here are the codes:
> 
> optimization <- function(x) {
>  mean <- colMeans(x)
>  names(mean) <-assets.names
>  p <- ncol(x)
>  n <- nrow(x)
>  M <- as.integer(p)
>  S <- cov(x)
>  invS<- solve(S)
>  u <- rep(1,p)
> 
> #w <- matrix(rep(0,p), nrow=p)
> #r <- seq(0,length=p); w <- cbind (diag(450));    #sum of 1 
> #constraint <- cbind(diag(450), rep(0, 450));  #non-negativity constraint
>  a <- matrix(rep(0,4), nrow=2)
>  a[1,1] <- u%*%invS%*%u; 
>  a[1,2] <- a[2,1] <- u%*%invS%*%mean
>  a[2,2] <-mean%*%invS%*%mean 
>  d <- a[1,1]*a[2,2]-a[1,2]*a[1,2] 
>  f <- (invS%*%(a[2,2]*u-a[1,2]*mean))/d 
>  g <- (invS%*%(-a[1,2]*u+a[1,1]*mean))/d
>  rho <- 0.5
>  r <- seq(0, rho,length= M)
>  w <- matrix(rep(0, p*M), nrow=p)
>  for(m in 1:M) w[,m] <- f+r[,m]*g
>  #w <- f+(rho*g)
>  w[,m] >=0
>  sum([,m])==1
>  s <- sqrt(a[1,1]*((r-a[1,2]/a[1,1])^2)/d+ 1/a[1,1]) 
>  ss <- sqrt(diag(S))
>  names(ss) <- assets.name
>  minp <- c(sqrt(1/a[1,1]), a[1,2]/a[1,1])
>  wmimp<- f+(a[1,2]/a[1,1])*g; 
>  tanp <- c(sqrt(a[2,2])/a[1,2], a[2,2]/a[1,2]) 
>  wtanp <- f+(a[2,2]/a[1,2])*g; 
>  return(solve(s, r, ss, p, minp, tanp, wminp, wtanp))
> }
> result=optimization(x)
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cyberpunk002 at gmail.com  Thu Nov 20 09:31:15 2014
From: cyberpunk002 at gmail.com (Muraki Kazutaka)
Date: Thu, 20 Nov 2014 12:31:15 +0400
Subject: [R] install R without texlive dependencies
Message-ID: <CAFyhbn4tpYa-Sz+P17OBWEH=p-Uv9OPLkB7Gpx_pMuwg3p5CHw@mail.gmail.com>

Hi all
I'm trying install R from EPEL repo on Scientific Linux. It's going
together texlive rpm dependencies also from repo, but I already have
installed TexLive with tlmgr from CTAN mirror and I don't want texlive
rpms from linux repo.
So... Question is... How can I install R without these deps and at the
same time work in without any problems in R and TexLive.
Thanks a lot


From murdoch.duncan at gmail.com  Thu Nov 20 15:00:23 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 20 Nov 2014 09:00:23 -0500
Subject: [R] install R without texlive dependencies
In-Reply-To: <CAFyhbn4tpYa-Sz+P17OBWEH=p-Uv9OPLkB7Gpx_pMuwg3p5CHw@mail.gmail.com>
References: <CAFyhbn4tpYa-Sz+P17OBWEH=p-Uv9OPLkB7Gpx_pMuwg3p5CHw@mail.gmail.com>
Message-ID: <546DF3F7.6070405@gmail.com>

On 20/11/2014 3:31 AM, Muraki Kazutaka wrote:
> Hi all
> I'm trying install R from EPEL repo on Scientific Linux. It's going
> together texlive rpm dependencies also from repo, but I already have
> installed TexLive with tlmgr from CTAN mirror and I don't want texlive
> rpms from linux repo.
> So... Question is... How can I install R without these deps and at the
> same time work in without any problems in R and TexLive.

You might get an answer to your question here, but this is more a 
question about your Linux distribution, and you will likely have better 
luck asking on a forum dedicated to it.  R should be perfectly happy 
working with the TexLive you already have.

Duncan Murdoch


From jvadams at usgs.gov  Thu Nov 20 15:19:10 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 20 Nov 2014 08:19:10 -0600
Subject: [R] SVYPLOT
In-Reply-To: <CAAQQ577OAQKmZxxbfjzPfk-qiEasZqFWgXpLaFJOQdwjx1zROQ@mail.gmail.com>
References: <CAAQQ577OAQKmZxxbfjzPfk-qiEasZqFWgXpLaFJOQdwjx1zROQ@mail.gmail.com>
Message-ID: <CAN5YmCEFdkV7DJ8-ZTuSk3mNt=kpa_dQHX57zZs4f5dZcCY8sA@mail.gmail.com>

Raphael

I just ran an example from the help file, and the xlim argument worked
fine.  Can you post a small example where the xlim argument doesn't work?

Jean

library(survey)
data(api)
dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)
svyplot(api00~api99, design=dstrat, style="bubble")
svyplot(api00~api99, design=dstrat, style="bubble", xlim=c(500, 700))


On Thu, Nov 20, 2014 at 12:54 AM, Raphael Fraser <raphael.fraser at gmail.com>
wrote:

> How do I set the limits of my x and y axis in svyplot? xlim and ylim does
> not work.
>
> Regards,
> Raphael
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Nov 20 16:19:42 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 20 Nov 2014 09:19:42 -0600
Subject: [R] install R without texlive dependencies
In-Reply-To: <546DF3F7.6070405@gmail.com>
References: <CAFyhbn4tpYa-Sz+P17OBWEH=p-Uv9OPLkB7Gpx_pMuwg3p5CHw@mail.gmail.com>
	<546DF3F7.6070405@gmail.com>
Message-ID: <1B1016B3-9BFB-4928-8F6D-56B1EA74822F@me.com>


> On Nov 20, 2014, at 8:00 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 20/11/2014 3:31 AM, Muraki Kazutaka wrote:
>> Hi all
>> I'm trying install R from EPEL repo on Scientific Linux. It's going
>> together texlive rpm dependencies also from repo, but I already have
>> installed TexLive with tlmgr from CTAN mirror and I don't want texlive
>> rpms from linux repo.
>> So... Question is... How can I install R without these deps and at the
>> same time work in without any problems in R and TexLive.
> 
> You might get an answer to your question here, but this is more a question about your Linux distribution, and you will likely have better luck asking on a forum dedicated to it.  R should be perfectly happy working with the TexLive you already have.
> 
> Duncan Murdoch


As Duncan noted, since this is Linux distro specific, you would be better off posting to R-SIG-Fedora, which is for R on RH based distros:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

A number of the R related RH/Fedora package maintainers monitor that list and you can discuss the nuances of some of the dependencies for R there.

That being said and while it has been a number of years for me on Linux, a Google search did not turn up any CLI options for 'yum' to be able to install without the hard coded RPM dependencies.

However, there would be an option using 'rpm' at the command line, along the lines of:

  rpm -ivh --nodeps RPMName.rpm

where you can either download the R RPM and install it locally, or include the full URL to the RPM on the EPEL server.

Of course, the above incantation can leave you without other needed dependencies, so use with caution.

Regards,

Marc Schwartz


From raphael.fraser at gmail.com  Thu Nov 20 16:31:34 2014
From: raphael.fraser at gmail.com (Raphael Fraser)
Date: Thu, 20 Nov 2014 10:31:34 -0500
Subject: [R] SVYPLOT
In-Reply-To: <CAN5YmCEFdkV7DJ8-ZTuSk3mNt=kpa_dQHX57zZs4f5dZcCY8sA@mail.gmail.com>
References: <CAAQQ577OAQKmZxxbfjzPfk-qiEasZqFWgXpLaFJOQdwjx1zROQ@mail.gmail.com>
	<CAN5YmCEFdkV7DJ8-ZTuSk3mNt=kpa_dQHX57zZs4f5dZcCY8sA@mail.gmail.com>
Message-ID: <CAAQQ577nWJB3h5LL3QDorU0v3yjOGeo=pX5piv1k9wSEuscJ8A@mail.gmail.com>

Does not work when ,style="grayhex".

library(survey)
data(api)
dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)
svyplot(api00~api99, design=dstrat, style="grayhex")
svyplot(api00~api99, design=dstrat, style="grayhex", ylim=c(500, 700))

On Thu, Nov 20, 2014 at 9:19 AM, Adams, Jean <jvadams at usgs.gov> wrote:

> Raphael
>
> I just ran an example from the help file, and the xlim argument worked
> fine.  Can you post a small example where the xlim argument doesn't work?
>
> Jean
>
> library(survey)
> data(api)
> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
> fpc=~fpc)
> svyplot(api00~api99, design=dstrat, style="bubble")
> svyplot(api00~api99, design=dstrat, style="bubble", xlim=c(500, 700))
>
>
> On Thu, Nov 20, 2014 at 12:54 AM, Raphael Fraser <raphael.fraser at gmail.com
> > wrote:
>
>> How do I set the limits of my x and y axis in svyplot? xlim and ylim does
>> not work.
>>
>> Regards,
>> Raphael
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Nov 20 17:00:24 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 20 Nov 2014 10:00:24 -0600
Subject: [R] Adapt sweave function to produce an automatic pdf.
In-Reply-To: <CAGh51gSyq7A_0ETnoKmrb03Z0GRVUX5k8+Y_ZRjjQ4Lc_yidSA@mail.gmail.com>
References: <CAGh51gSyq7A_0ETnoKmrb03Z0GRVUX5k8+Y_ZRjjQ4Lc_yidSA@mail.gmail.com>
Message-ID: <B1A8B98E-6307-40C2-BDBB-FF8DCEAFF279@me.com>


> On Nov 20, 2014, at 4:03 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> 
> Hi All,
> 
> I want to make a climate method ("sweave_function"). The aim is to be able
> to adapt sweave code that produces an automatic pdf so that it can works
> for my climate object. i.e. instead of compile pdf, I call :
> data_obj$sweave_function() and get the pdf. for instance I have
> boxplot_method() and I want to output it in this way. Thanks for the help!!!
> 
> Ex: This how I started but I don't understand how I can proceed.
> 
> climate$methods(sweave_function = function(climate_data_objs_str,
> climate_data_objs_ind
> ) {
> 
> #---------------------------------------------------------------------------------------------
>  #  This function returns the pdf using sweave function in R
>  #  The required arguments are:
>  #   climate_data_objs_str  : list of the names of climate data objects in
> the climate object
>  #   climate_data_objs_ind  : list of the indices of climate data object
> in the climate object
>  #   note that one of the above arguments is enough.
> 
> #--------------------------------------------------------------------------------------------
> 
> 
>  # get_climate_data_objects returns a list of the climate_data objects
> specified
>  # in the arguements.
>  # If no objects specified then all climate_data objects will be taken by
> default
> 
>  climate_data_objs = get_climate_data_objects(climate_data_objs_str,
> climate_data_objs_ind)
> })


You need to either dynamically generate the entire final .tex file including the preamble and so forth via your function(s)

or:

alternatively use a .Rnw Sweave "master" file template that contains the static content and then in that file, insert the dynamic content using one or more directives along the lines of \input{InsertContentHere.tex}, where InsertContentHere.tex contains raw TeX content to be inserted at that point in the master file when processed by Sweave. 

The content of the *.tex files can be generated via various R functions including ?cat for raw text and others like the xtable() function in the CRAN package of the same name or the latex() function in Hmisc, which can be used to create tables, etc.

Note that the content of InsertContentHere.tex will not itself be processed by Sweave, as if it was a "child" .Rnw file. If you want that type of functionality, you would need to use \SweaveInput{InsertContentHere.Rnw}.

Once you have your final .tex file, you can then run pdflatex on that file via ?system.

Regards,

Marc Schwartz


From ajdamico at gmail.com  Thu Nov 20 17:10:29 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 20 Nov 2014 11:10:29 -0500
Subject: [R] SVYPLOT
In-Reply-To: <CAAQQ577nWJB3h5LL3QDorU0v3yjOGeo=pX5piv1k9wSEuscJ8A@mail.gmail.com>
References: <CAAQQ577OAQKmZxxbfjzPfk-qiEasZqFWgXpLaFJOQdwjx1zROQ@mail.gmail.com>
	<CAN5YmCEFdkV7DJ8-ZTuSk3mNt=kpa_dQHX57zZs4f5dZcCY8sA@mail.gmail.com>
	<CAAQQ577nWJB3h5LL3QDorU0v3yjOGeo=pX5piv1k9wSEuscJ8A@mail.gmail.com>
Message-ID: <CAOwvMDyPLcwtStdc0DcrLFkKhTVYu_JGxy8nGyY744NaB1HjyQ@mail.gmail.com>

survey:::svyplot.default   with style="grayhex"   calls
hexbin:::gplot.hexbin

an internet search turns up lots of people asking the question "how do i
set xlim and ylim on hexbin plots?" but i don't see any easy solutions.  :/

On Thu, Nov 20, 2014 at 10:31 AM, Raphael Fraser <raphael.fraser at gmail.com>
wrote:

> Does not work when ,style="grayhex".
>
> library(survey)
> data(api)
> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
> fpc=~fpc)
> svyplot(api00~api99, design=dstrat, style="grayhex")
> svyplot(api00~api99, design=dstrat, style="grayhex", ylim=c(500, 700))
>
> On Thu, Nov 20, 2014 at 9:19 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>
> > Raphael
> >
> > I just ran an example from the help file, and the xlim argument worked
> > fine.  Can you post a small example where the xlim argument doesn't work?
> >
> > Jean
> >
> > library(survey)
> > data(api)
> > dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
> > fpc=~fpc)
> > svyplot(api00~api99, design=dstrat, style="bubble")
> > svyplot(api00~api99, design=dstrat, style="bubble", xlim=c(500, 700))
> >
> >
> > On Thu, Nov 20, 2014 at 12:54 AM, Raphael Fraser <
> raphael.fraser at gmail.com
> > > wrote:
> >
> >> How do I set the limits of my x and y axis in svyplot? xlim and ylim
> does
> >> not work.
> >>
> >> Regards,
> >> Raphael
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From akhil.dua.12 at gmail.com  Thu Nov 20 17:19:55 2014
From: akhil.dua.12 at gmail.com (Akhil dua)
Date: Thu, 20 Nov 2014 21:49:55 +0530
Subject: [R] auto.arima function in R
In-Reply-To: <CAPSaRtDtkciYDcVNEjMJb=o0_okCF3JFEfwVt3A-a5qUAL6F3g@mail.gmail.com>
References: <CAPSaRtCajO2QEb384zuuSQuL92PRweYWfu7piUJC277peWycaQ@mail.gmail.com>
	<546DDBAB.6040802@stats.ox.ac.uk>
	<CAPSaRtD_uR6GwCx96k-hgcdLRTuXsCe2u41BJR90+Jxbpf2Q-w@mail.gmail.com>
	<CAPSaRtDtkciYDcVNEjMJb=o0_okCF3JFEfwVt3A-a5qUAL6F3g@mail.gmail.com>
Message-ID: <CAPSaRtBKgcNzFBbwoGAaEagbahWhEc6P8eAgOn8=6uO9hQN+Uw@mail.gmail.com>

I am sorry for violating the guidelines but the data that I am using is
highly confidential so I can't disclose it.I posted sample data just for
giving the flavour of the data.
On Nov 20, 2014 5:46 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

There is no auto.arima function 'in R'.  Do give credit/blame where it is
due (probably package 'forecast').

Without the reproducible example the posting guide asked for, we can only
guess wildly.  I at least decline to do so.



On 20/11/2014 10:52, Akhil dua wrote:

> Hello every one,
>
> I am using daily data of the flight departure.
>
> Departure Date           Load (Seats booked/Capacity)
> 12/01/2011                                 10
> 13/01/2011                                 12
> 14/01/2011                                 09
>
> I want to fit an arima model to the data for forecasting the load for the
> next day flight. I am using auto.arima function in R.
>
> Residuals and fitted values that I am getting from auto.arima has NAs
> whereas I don't have any NA in my original data.
>
> Can anyone please help me with the probable reason for this.
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK

	[[alternative HTML version deleted]]


From alanm at crab.org  Thu Nov 20 17:25:00 2014
From: alanm at crab.org (alanm (Alan Mitchell))
Date: Thu, 20 Nov 2014 16:25:00 +0000
Subject: [R] Symbolic equations to R code?
In-Reply-To: <546D0213.3030108@ucsd.edu>
References: <546CD0A3.30201@ucsd.edu>
	<7E8D730B-BBB1-4A5A-B3CA-CAB52E1A0B0E@comcast.net>
	<546D0213.3030108@ucsd.edu>
Message-ID: <C9DA61C582A6614CB27AB2920BF437CD011747BF@svr-mbx-sea.crab.org>

Have you thought about programming a function builder into the Shiny applet?  It might simplify the process for your students a bit.  A highly simplified version of the page David suggested could be built that generates the R code.  

Best of luck,
Alan

-----Original Message-----
From: Scott Rifkin [mailto:sarifkin at ucsd.edu] 
Sent: Wednesday, November 19, 2014 12:48 PM
To: David Winsemius
Cc: r-help at r-project.org
Subject: Re: [R] Symbolic equations to R code?

David, Thanks for your reply and suggestions of packages - let me clarify what I am looking for:

The web editor you pointed out is the sort of equation editor I'm 
looking for and I had seen others like this.    Let's say I use that one 
(step 1) and then have Latex code (step 2).  Step (3) would be converting the Latex into an R function automatically.  That's the key package. In searching for Latex and R there seem to be lots of ways to embed R code into Latex but not to translate Latex into R.

As far as R commander, I do indeed know about that and am not looking for an R GUI for my students. They are not going be learning R in the class.  As far as I know, R commander can't do steps 1-3, but please let me know if I am wrong.  After students use the interface in step (1), the software in steps (2) and (3) would be for my benefit, to programmatically translate the equations of 150+ students into R code.

Thanks,
Scott


From pdalgd at gmail.com  Thu Nov 20 17:50:36 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 20 Nov 2014 17:50:36 +0100
Subject: [R] auto.arima function in R
In-Reply-To: <CAPSaRtBKgcNzFBbwoGAaEagbahWhEc6P8eAgOn8=6uO9hQN+Uw@mail.gmail.com>
References: <CAPSaRtCajO2QEb384zuuSQuL92PRweYWfu7piUJC277peWycaQ@mail.gmail.com>
	<546DDBAB.6040802@stats.ox.ac.uk>
	<CAPSaRtD_uR6GwCx96k-hgcdLRTuXsCe2u41BJR90+Jxbpf2Q-w@mail.gmail.com>
	<CAPSaRtDtkciYDcVNEjMJb=o0_okCF3JFEfwVt3A-a5qUAL6F3g@mail.gmail.com>
	<CAPSaRtBKgcNzFBbwoGAaEagbahWhEc6P8eAgOn8=6uO9hQN+Uw@mail.gmail.com>
Message-ID: <35E4604E-0447-4A13-85A3-F1C443AD0591@gmail.com>


On 20 Nov 2014, at 17:19 , Akhil dua <akhil.dua.12 at gmail.com> wrote:

> I am sorry for violating the guidelines but the data that I am using is
> highly confidential so I can't disclose it.I posted sample data just for
> giving the flavour of the data.

This happens, but then you need to simulate some data that show the effect. 

It's not happening with the fit from example(auto.arima), so clearly not always. 

-pd


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Thu Nov 20 18:16:07 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 20 Nov 2014 18:16:07 +0100
Subject: [R] Equivalent to matlab ".*" operator in R
In-Reply-To: <546CB0A1.2010503@ttk.mta.hu>
References: <CAJYLPFdMVUPAU482zwxjQN9-raoVxNLdnUV5mRwWWcWyZFkuEA@mail.gmail.com>
	<2257487D-EFDD-4F13-BF12-A03A9B1AEC47@xs4all.nl>
	<546CB0A1.2010503@ttk.mta.hu>
Message-ID: <BA405D48-621A-4081-8710-58FA79522710@gmail.com>

Not sure you really want the overhead of sweep() for this, but logically, you want z as a vector or maybe 1d array since sweep() is designed as complimentary to apply(). I.e., you can sweep out marginal means using, say,

m <- matrix(c(5, 7, 9, 13), 2)
colmean <- apply(m, 2, mean)
sweep(m, 2, colmean, "-")

in which colmean is a vector. In general, apply() yields an array with fewer extents, and sweep expects one.

-pd

On 19 Nov 2014, at 16:00 , D?nes T?th <toth.denes at ttk.mta.hu> wrote:

> Hi,
> 
> It is better to use sweep() for these kinds of problems, see ?sweep
> 
> y <- matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
> z <- matrix(c(12, -6),ncol=2)
> sweep(y, 2, z, "*")
> 
> 
> Best,
>  Denes
> 
> 
> 
> On 11/19/2014 03:50 PM, Berend Hasselman wrote:
>> On 19-11-2014, at 15:22, Ruima E. <ruimaximo at gmail.com> wrote:
>> 
>>> Hi,
>>> 
>>> I have this:
>>> 
>>> y = matrix(cbind(c(0, 0.5, 1),c(0, 0.5, 1)),ncol=2)
>>> z = matrix(c(12, -6),ncol=2)
>>> 
>>> In matlab I would do this
>>> 
>>>> y .* x
>>> I would get this in matlab
>>> 
>>>> ans
>>> 0    -0
>>> 6    -3
>>> 12   -6
>>> 
>>> What is the equivalent in R?
>>> 
>> One way of doing this could be:
>> 
>> y * rep(z,1,each=nrow(y))
>> 
>> Berend
>> 
>>> Thanks
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dvernerey at chu-besancon.fr  Thu Nov 20 16:56:52 2014
From: dvernerey at chu-besancon.fr (Dewi VERNEREY)
Date: Thu, 20 Nov 2014 15:56:52 +0000
Subject: [R]  [R-pkgs] rms 4.1-0
Message-ID: <1DD408E0-0356-4544-B350-616124817D90@chu-besancon.fr>


Hi Franck,

I am using the calibrate function from the package rms (4.2-1) with R (3.1.2) in a Mac OS 10.10.1 environment .

With my previous configuration (other computer) the function calibrate worked very well.

Unfortunately, now the calibrate function doesn?t work. Do you have an idea to help me in order to solve this problem. The validate function works.

Thank you very much for your help

Kind regards,

Dewi


Please find bellow my code :


W =read.table("export_R_model_proba.txt",sep="\t",header=TRUE)

W= as.data.frame(W)

ls()

summary(W)

library(survival)

library(survplot)

library(rms)

library(SvyNom)

library(SvyNom)

library(survey)


f <- cph(Surv(OS_time_months, OS_event) ~ CT + VE + Nratio_rcd + log_LYPREOP + log_LYPO , dist='lognormal',data=W,surv=T,dxy = TRUE,time.inc =48,x=TRUE, y=TRUE)

f

Cox Proportional Hazards Model

cph(formula = Surv(OS_time_months, OS_event) ~ CT + VE + Nratio_rcd +

    log_LYPREOP + log_LYPO, data = W, x = TRUE, y = TRUE, surv = T,

    time.inc = 48, dist = "lognormal", dxy = TRUE)


                     Model Tests       Discrimination

                                          Indexes

Obs        241    LR chi2     42.15    R2       0.161

Events     179    d.f.            5    Dxy     -0.283

Center -5.6749    Pr(> chi2) 0.0000    g        0.608

                  Score chi2  46.25    gr       1.837

                  Pr(> chi2) 0.0000


            Coef    S.E.   Wald Z Pr(>|Z|)

CT          -0.6056 0.1891 -3.20  0.0014

VE           0.4153 0.1640  2.53  0.0114

Nratio_rcd   0.6746 0.1778  3.79  0.0001

etc etc

plot(calibrate(f,u=48,method="boot",cmethod="KM",xlim=c(0,1),ylim=c(0,1),surv=T,m=33),xlim=c(0,1),ylim=c(0,1))

Erreur dans UseMethod("calibrate") :

  pas de m?thode pour 'calibrate' applicable pour un objet de classe "c('cph', 'rms', 'coxph')"


	[[alternative HTML version deleted]]


From nashjc at uottawa.ca  Thu Nov 20 20:10:02 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 20 Nov 2014 14:10:02 -0500
Subject: [R] R website
Message-ID: <546E3C8A.7030000@uottawa.ca>

I was looking at the R website (r-project.org).

1) The Books page does not list several books about R, including one of
my own (Nonlinear parameter optimization tools in R) nor that of Karline
Soetaert on differential equations. How is the list updated?

2) The wiki seems to be dead. Is anyone in charge of it? If not, please
contact me off-line. I am willing to help out (I run several Dokuwiki
wikis).

Best, JN


From dwinsemius at comcast.net  Thu Nov 20 20:19:25 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 20 Nov 2014 11:19:25 -0800
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <12A4CACA-73C3-42A8-BC54-053A891B7B7C@gmail.com>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
	<B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
	<79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>
	<8780E3CE-13F9-43B3-A6D3-5034BBE6304C@comcast.net>
	<12A4CACA-73C3-42A8-BC54-053A891B7B7C@gmail.com>
Message-ID: <72B60A76-2390-43AC-95C7-E0B7B3609ADF@comcast.net>


On Nov 20, 2014, at 2:23 AM, i.petzev wrote:

> Hi David,
> 
> sorry, I was not clear.

Right. You never were clear about what you wanted and your examples was so statistically symmetric that it is still hard to see what is needed. The examples below show CI's that are arguably equivalent. I can be faulted for attempting to provide code that produced a sensible answer to a vague question to which I was only guessing at the intent.


> The difference comes from defining or not defining ?w? in the boot() function. The results with your function and your approach are thus:
> 
> set.seed(1111)
> x <- rnorm(50)
> y <- rnorm(50)
> weights <- runif(50)
> weights <- weights / sum(weights)
> dataset <- cbind(x,y,weights)
> 
> vw_m_diff <- function(dataset,w) {
>   differences <- dataset[w,1]-dataset[w,2]
>   weights <- dataset[w, "weights"]
>   return(weighted.mean(x=differences, w=weights))
> }
> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
> boot.ci(res_boot)
> 
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 1000 bootstrap replicates
> 
> CALL : 
> boot.ci(boot.out = res_boot)
> 
> Intervals : 
> Level      Normal              Basic         
> 95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )  
> 
> Level     Percentile            BCa          
> 95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )  
> Calculations and Intervals on Original Scale
> 
> ********************************************************************************************************************
> 
> However, without defining ?w? in the bootstrap function, i.e., running an ordinary and not a weighted bootstrap, the results are:
> 
> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000)
> boot.ci(res_boot)
> 
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 1000 bootstrap replicates
> 
> CALL : 
> boot.ci(boot.out = res_boot)
> 
> Intervals : 
> Level      Normal              Basic         
> 95%   (-0.6265,  0.4966 )   (-0.6125,  0.5249 )  

I hope you are not saying that because those CI's are different that there is some meaning in that difference. Bootstrap runs will always be "different" than each other unless you use set.seed(.) before the runs.

> 
> Level     Percentile            BCa          
> 95%   (-0.6714,  0.4661 )   (-0.6747,  0.4559 )  
> Calculations and Intervals on Original Scale
> 
> On 19 Nov 2014, at 17:49, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>>>> vw_m_diff <- function(dataset,w) {
>>>>     differences <- dataset[w,1]-dataset[w,2]
>>>>    weights <- dataset[w, "weights"]
>>>>    return(weighted.mean(x=differences, w=weights))
>>>>  }
> 

David Winsemius
Alameda, CA, USA


From sarifkin at ucsd.edu  Thu Nov 20 20:35:21 2014
From: sarifkin at ucsd.edu (Scott Rifkin)
Date: Thu, 20 Nov 2014 11:35:21 -0800
Subject: [R] Symbolic equations to R code?
In-Reply-To: <CA+vqiLFzysf9=tiW6mMAnUe5k2hKhXYZ_oirET0DCDy0i0dMVw@mail.gmail.com>
References: <546CD0A3.30201@ucsd.edu>
	<CA+vqiLFzysf9=tiW6mMAnUe5k2hKhXYZ_oirET0DCDy0i0dMVw@mail.gmail.com>
Message-ID: <546E4279.5070201@ucsd.edu>

Ista,

On the one hand I'd like it to be as flexible as possible so the 
students could really come up with whatever they like.  On the other 
hand, restricting their choices probably would make it easier to do the 
backend.  The goal would be to get them to realize that the apparatus of 
hypothesis testing (when done via simulation/randomization techniques) 
doesn't depend on what the statistic is. The flow of steps is the same 
whether the statistic is a mean, variance, or their own kooky thing. 
Obviously this isn't the end of the story - what the statistic is 
actually describing is also a crucial component to interpreting the 
results of a hypothesis test, but I think it teaches an important 
pedagogical point about where statistics come from and that if they find 
themselves in a situation in the future where they need to make up their 
own, then that is perfectly okay.

So they could make up ones like:  arctan( (max({x})^2)/ (min({x})^2) 
)-3), max({x})-min({x}), sum from i to n of (x_i - 25th%ile({x}) )^3)  
[that might be tricky to write in a standard equation editor]
none of these is hard to write in R, but translating from an equation 
editor might be.

Perhaps the best solution is (as Alan suggests below) to write a Shiny 
function builder myself so that I can control the whole process and make 
sure that they can't enter anything that would break the backend.  Or to 
have them learn the rudiments of writing equations in R so that it 
bypasses the whole process.

Thanks,
Scott



On 11/19/14 1:52 PM, Ista Zahn wrote:
> Hi Scott,
>
> Can you give a couple of examples of the equations you have in mind
> along with how those should be translated to R?
>
> Thanks,
> Ista
>


From murdoch.duncan at gmail.com  Thu Nov 20 20:36:32 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 20 Nov 2014 14:36:32 -0500
Subject: [R] R website
In-Reply-To: <546E3C8A.7030000@uottawa.ca>
References: <546E3C8A.7030000@uottawa.ca>
Message-ID: <546E42C0.1050802@gmail.com>

On 20/11/2014 2:10 PM, Prof J C Nash (U30A) wrote:
> I was looking at the R website (r-project.org).
>
> 1) The Books page does not list several books about R, including one of
> my own (Nonlinear parameter optimization tools in R) nor that of Karline
> Soetaert on differential equations. How is the list updated?
>
> 2) The wiki seems to be dead. Is anyone in charge of it? If not, please
> contact me off-line. I am willing to help out (I run several Dokuwiki
> wikis).

Files on www.r-project.org can be edited by any member of R core. You 
just need to convince one of us to enter it, send us the data, and the 
book will eventually show up.  (To do that, take a look at the Bibtex 
.bib file, available at http://www.r-project.org/doc/bib/R.bib, and put 
together additions in a consistent format.  If it is not obvious why 
your book should be included, explain why.)

Duncan Murdoch


From boris.steipe at utoronto.ca  Thu Nov 20 20:57:15 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 20 Nov 2014 14:57:15 -0500
Subject: [R] Symbolic equations to R code?
In-Reply-To: <546E4279.5070201@ucsd.edu>
References: <546CD0A3.30201@ucsd.edu>
	<CA+vqiLFzysf9=tiW6mMAnUe5k2hKhXYZ_oirET0DCDy0i0dMVw@mail.gmail.com>
	<546E4279.5070201@ucsd.edu>
Message-ID: <658D2805-A8AB-4B1D-AB20-C26A154799E2@utoronto.ca>

I usually find my students appreciate it when I teach them something that has utility in multiple contexts. Teaching them how to express an idea in R code is valuable. And as far as structuring thought and expressing ideas go, it's quite equivalent to symbolic equations. Both are just notation.

$ 0.02
Cheers,
B.


On Nov 20, 2014, at 2:35 PM, Scott Rifkin <sarifkin at ucsd.edu> wrote:

> Ista,
> 
> On the one hand I'd like it to be as flexible as possible so the students could really come up with whatever they like.  On the other hand, restricting their choices probably would make it easier to do the backend.  The goal would be to get them to realize that the apparatus of hypothesis testing (when done via simulation/randomization techniques) doesn't depend on what the statistic is. The flow of steps is the same whether the statistic is a mean, variance, or their own kooky thing. Obviously this isn't the end of the story - what the statistic is actually describing is also a crucial component to interpreting the results of a hypothesis test, but I think it teaches an important pedagogical point about where statistics come from and that if they find themselves in a situation in the future where they need to make up their own, then that is perfectly okay.
> 
> So they could make up ones like:  arctan( (max({x})^2)/ (min({x})^2) )-3), max({x})-min({x}), sum from i to n of (x_i - 25th%ile({x}) )^3)  [that might be tricky to write in a standard equation editor]
> none of these is hard to write in R, but translating from an equation editor might be.
> 
> Perhaps the best solution is (as Alan suggests below) to write a Shiny function builder myself so that I can control the whole process and make sure that they can't enter anything that would break the backend.  Or to have them learn the rudiments of writing equations in R so that it bypasses the whole process.
> 
> Thanks,
> Scott
> 
> 
> 
> On 11/19/14 1:52 PM, Ista Zahn wrote:
>> Hi Scott,
>> 
>> Can you give a couple of examples of the equations you have in mind
>> along with how those should be translated to R?
>> 
>> Thanks,
>> Ista
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Nov 20 21:48:28 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 20 Nov 2014 12:48:28 -0800
Subject: [R] [R-pkgs] rms 4.1-0
In-Reply-To: <1DD408E0-0356-4544-B350-616124817D90@chu-besancon.fr>
References: <1DD408E0-0356-4544-B350-616124817D90@chu-besancon.fr>
Message-ID: <BAD7786A-5962-4702-9C29-1CF015EEC789@comcast.net>


On Nov 20, 2014, at 7:56 AM, Dewi VERNEREY wrote:

> 
> Hi Franck,
> 
> I am using the calibrate function from the package rms (4.2-1) with R (3.1.2) in a Mac OS 10.10.1 environment .

That's the Yosemite platform. I'm running R 3.1.2 with the current CRAN binaries (which were recently updated) and I get no error with the example in the help page for `calibrate`. At the moment you example is not reproducible since we do not have your data. Do you get an error with the code on `?calibrate`  (and are you using the most up-to-date versions of everything?
> 
> With my previous configuration (other computer) the function calibrate worked very well.
> 
> Unfortunately, now the calibrate function doesn?t work. Do you have an idea to help me in order to solve this problem. The validate function works.
> 
> Thank you very much for your help
> 
> Kind regards,
> 
> Dewi
> 
> 
> Please find bellow my code :
> 
> 
> W =read.table("export_R_model_proba.txt",sep="\t",header=TRUE)
> 
> W= as.data.frame(W)
> 
> ls()
> 
> summary(W)
> 
> library(survival)
> 
> library(survplot)
> 
> library(rms)
> 
> library(SvyNom)
> 
> library(SvyNom)
> 
> library(survey)
> 
> 
> f <- cph(Surv(OS_time_months, OS_event) ~ CT + VE + Nratio_rcd + log_LYPREOP + log_LYPO , dist='lognormal',data=W,surv=T,dxy = TRUE,time.inc =48,x=TRUE, y=TRUE)
> 
> f
> 
> Cox Proportional Hazards Model
> 
> cph(formula = Surv(OS_time_months, OS_event) ~ CT + VE + Nratio_rcd +
> 
>    log_LYPREOP + log_LYPO, data = W, x = TRUE, y = TRUE, surv = T,
> 
>    time.inc = 48, dist = "lognormal", dxy = TRUE)
> 
> 
>                     Model Tests       Discrimination
> 
>                                          Indexes
> 
> Obs        241    LR chi2     42.15    R2       0.161
> 
> Events     179    d.f.            5    Dxy     -0.283
> 
> Center -5.6749    Pr(> chi2) 0.0000    g        0.608
> 
>                  Score chi2  46.25    gr       1.837
> 
>                  Pr(> chi2) 0.0000
> 
> 
>            Coef    S.E.   Wald Z Pr(>|Z|)
> 
> CT          -0.6056 0.1891 -3.20  0.0014
> 
> VE           0.4153 0.1640  2.53  0.0114
> 
> Nratio_rcd   0.6746 0.1778  3.79  0.0001
> 
> etc etc
> 
> plot(calibrate(f,u=48,method="boot",cmethod="KM",xlim=c(0,1),ylim=c(0,1),surv=T,m=33),xlim=c(0,1),ylim=c(0,1))
> 
> Erreur dans UseMethod("calibrate") :
> 
>  pas de m?thode pour 'calibrate' applicable pour un objet de classe "c('cph', 'rms', 'coxph')"
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Nov 20 21:56:21 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 20 Nov 2014 12:56:21 -0800
Subject: [R] SVYPLOT
In-Reply-To: <CAOwvMDyPLcwtStdc0DcrLFkKhTVYu_JGxy8nGyY744NaB1HjyQ@mail.gmail.com>
References: <CAAQQ577OAQKmZxxbfjzPfk-qiEasZqFWgXpLaFJOQdwjx1zROQ@mail.gmail.com>
	<CAN5YmCEFdkV7DJ8-ZTuSk3mNt=kpa_dQHX57zZs4f5dZcCY8sA@mail.gmail.com>
	<CAAQQ577nWJB3h5LL3QDorU0v3yjOGeo=pX5piv1k9wSEuscJ8A@mail.gmail.com>
	<CAOwvMDyPLcwtStdc0DcrLFkKhTVYu_JGxy8nGyY744NaB1HjyQ@mail.gmail.com>
Message-ID: <895E88FA-1F70-40B4-B780-8352B2D0594F@comcast.net>


On Nov 20, 2014, at 8:10 AM, Anthony Damico wrote:

> survey:::svyplot.default   with style="grayhex"   calls
> hexbin:::gplot.hexbin
> 
> an internet search turns up lots of people asking the question "how do i
> set xlim and ylim on hexbin plots?" but i don't see any easy solutions.  :/

Looking at the code, which calls hexViewport and then at the help page for hexbin::hexViewport I see that function provides:

xbnds, ybnds	
bounds for x- and y- plotting range; these default to the corresponding slots of x.

... but I do not see that there is any ellipsis provision for passing those arguments via `hexbin::gplot.hexbin`. Perhaps a bit of hacking could provide such?

-- 
David.

> 
> On Thu, Nov 20, 2014 at 10:31 AM, Raphael Fraser <raphael.fraser at gmail.com>
> wrote:
> 
>> Does not work when ,style="grayhex".
>> 
>> library(survey)
>> data(api)
>> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
>> fpc=~fpc)
>> svyplot(api00~api99, design=dstrat, style="grayhex")
>> svyplot(api00~api99, design=dstrat, style="grayhex", ylim=c(500, 700))
>> 
>> On Thu, Nov 20, 2014 at 9:19 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>> 
>>> Raphael
>>> 
>>> I just ran an example from the help file, and the xlim argument worked
>>> fine.  Can you post a small example where the xlim argument doesn't work?
>>> 
>>> Jean
>>> 
>>> library(survey)
>>> data(api)
>>> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
>>> fpc=~fpc)
>>> svyplot(api00~api99, design=dstrat, style="bubble")
>>> svyplot(api00~api99, design=dstrat, style="bubble", xlim=c(500, 700))
>>> 
>>> 
>>> On Thu, Nov 20, 2014 at 12:54 AM, Raphael Fraser <
>> raphael.fraser at gmail.com
>>>> wrote:
>>> 
>>>> How do I set the limits of my x and y axis in svyplot? xlim and ylim
>> does
>>>> not work.
>>>> 
>>>> Regards,
>>>> Raphael
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Nov 20 22:04:05 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 20 Nov 2014 13:04:05 -0800
Subject: [R] SVYPLOT
In-Reply-To: <895E88FA-1F70-40B4-B780-8352B2D0594F@comcast.net>
References: <CAAQQ577OAQKmZxxbfjzPfk-qiEasZqFWgXpLaFJOQdwjx1zROQ@mail.gmail.com>
	<CAN5YmCEFdkV7DJ8-ZTuSk3mNt=kpa_dQHX57zZs4f5dZcCY8sA@mail.gmail.com>
	<CAAQQ577nWJB3h5LL3QDorU0v3yjOGeo=pX5piv1k9wSEuscJ8A@mail.gmail.com>
	<CAOwvMDyPLcwtStdc0DcrLFkKhTVYu_JGxy8nGyY744NaB1HjyQ@mail.gmail.com>
	<895E88FA-1F70-40B4-B780-8352B2D0594F@comcast.net>
Message-ID: <FE1DCFB6-7BC2-45CA-BFE4-34E1A7F0AE31@comcast.net>


On Nov 20, 2014, at 12:56 PM, David Winsemius wrote:

> 
> On Nov 20, 2014, at 8:10 AM, Anthony Damico wrote:
> 
>> survey:::svyplot.default   with style="grayhex"   calls
>> hexbin:::gplot.hexbin
>> 
>> an internet search turns up lots of people asking the question "how do i
>> set xlim and ylim on hexbin plots?" but i don't see any easy solutions.  :/
> 
> Looking at the code, which calls hexViewport and then at the help page for hexbin::hexViewport I see that function provides:
> 
> xbnds, ybnds	
> bounds for x- and y- plotting range; these default to the corresponding slots of x.
> 
> ... but I do not see that there is any ellipsis provision for passing those arguments via `hexbin::gplot.hexbin`. Perhaps a bit of hacking could provide such?

Or  perhaps svyplot.default (and cousins) could hacked to accept an argument for xlim and ylim that would then create the proper slots (xbnds and ybnds) in the S4 object it passes? Looks as though some of the argument "expectations" of hexbin plotting functions is via slots and perhaps the ellipsis mechanism would not be needed.

-- 
David.

> 
> -- 
> David.
> 
>> 
>> On Thu, Nov 20, 2014 at 10:31 AM, Raphael Fraser <raphael.fraser at gmail.com>
>> wrote:
>> 
>>> Does not work when ,style="grayhex".
>>> 
>>> library(survey)
>>> data(api)
>>> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
>>> fpc=~fpc)
>>> svyplot(api00~api99, design=dstrat, style="grayhex")
>>> svyplot(api00~api99, design=dstrat, style="grayhex", ylim=c(500, 700))
>>> 
>>> On Thu, Nov 20, 2014 at 9:19 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>>> 
>>>> Raphael
>>>> 
>>>> I just ran an example from the help file, and the xlim argument worked
>>>> fine.  Can you post a small example where the xlim argument doesn't work?
>>>> 
>>>> Jean
>>>> 
>>>> library(survey)
>>>> data(api)
>>>> dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat,
>>>> fpc=~fpc)
>>>> svyplot(api00~api99, design=dstrat, style="bubble")
>>>> svyplot(api00~api99, design=dstrat, style="bubble", xlim=c(500, 700))
>>>> 
>>>> 
>>>> On Thu, Nov 20, 2014 at 12:54 AM, Raphael Fraser <
>>> raphael.fraser at gmail.com
>>>>> wrote:
>>>> 
>>>>> How do I set the limits of my x and y axis in svyplot? xlim and ylim
>>> does
>>>>> not work.
>>>>> 
>>>>> Regards,
>>>>> Raphael
>>>>> 
>>>>>       [[alternative HTML version deleted]]
>>>>> snipped

David Winsemius
Alameda, CA, USA


From dimitri.liakhovitski at gmail.com  Thu Nov 20 23:14:27 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 20 Nov 2014 17:14:27 -0500
Subject: [R] ggplot question error: Error in s(x,
	bs = "cs") : object 'x' not found
Message-ID: <CAN2xGJZ5uWoQGkA2kCzN4M_GqGiWg=qM9oLAfR6pDzS23iRwpw@mail.gmail.com>

Dear R-ers,

apologies for not providing the full code. I just need a point in the
right direction.
I have a data frame ('temp') with 1,200 rows and 2 variables.
I am using ggplot2 to create a scatter plot:

This is my code and it works fine, it creates a scatter plot:

library(ggplot2)
sp10<-ggplot(temp,aes(x=p.used_L1,y=l.to.r.ratio_L1))
sp10 + geom_point()

However, when I change the last line to:
sp10 + geom_point() + stat_smooth(se=FALSE)

Then I am getting these messages (and no fitted line on the graph):

geom_smooth: method="auto" and size of largest group is >=1000, so
using gam with formula: y ~ s(x, bs = "cs"). Use 'method = x' to
change the smoothing method.
Error in s(x, bs = "cs") : object 'x' not found

I don't understand what x in in s(x, bs = "cs") is or should be.
I lookeed up ?geom_smooth and tried this:

sp10 + geom_point() + stat_smooth(se=FALSE,formula = l.to.r.ratio_L1 ~
p.used_L1)

Still, the same error message.

Thanks a lot for your advice!


From istazahn at gmail.com  Thu Nov 20 22:35:39 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 20 Nov 2014 16:35:39 -0500
Subject: [R] R website
In-Reply-To: <546E42C0.1050802@gmail.com>
References: <546E3C8A.7030000@uottawa.ca> <546E42C0.1050802@gmail.com>
Message-ID: <CA+vqiLGTwojH=aNvyCW25WePke3fbhxzfy2xyr=0aeMWUYabog@mail.gmail.com>

This prompted me to do something I've been meaning to do for a long
time, which is to try to get the R website updated in terms of visual
style. It really is showing it's age and could use a facelift in my
opinion. Toward than end I've mocked up a copy of cran.r-project.or
using css from the python.org website. You can see the result at
http://izahn.crabdance.com/~izahn/cran-new-css . This is a rough draft
and needs to be cleaned up, but I though I would float this here first
to see if there is any hope of getting such a change to be adopted
before I spent more time on it. Feedback and comments welcome.

Best,
Ista

On Thu, Nov 20, 2014 at 2:36 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 20/11/2014 2:10 PM, Prof J C Nash (U30A) wrote:
>>
>> I was looking at the R website (r-project.org).
>>
>> 1) The Books page does not list several books about R, including one of
>> my own (Nonlinear parameter optimization tools in R) nor that of Karline
>> Soetaert on differential equations. How is the list updated?
>>
>> 2) The wiki seems to be dead. Is anyone in charge of it? If not, please
>> contact me off-line. I am willing to help out (I run several Dokuwiki
>> wikis).
>
>
> Files on www.r-project.org can be edited by any member of R core. You just
> need to convince one of us to enter it, send us the data, and the book will
> eventually show up.  (To do that, take a look at the Bibtex .bib file,
> available at http://www.r-project.org/doc/bib/R.bib, and put together
> additions in a consistent format.  If it is not obvious why your book should
> be included, explain why.)
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aps6dl at yahoo.com  Thu Nov 20 22:46:31 2014
From: aps6dl at yahoo.com (Aditya Singh)
Date: Thu, 20 Nov 2014 21:46:31 +0000 (UTC)
Subject: [R] Function returns NULL on running this code in latest version of
	R!
In-Reply-To: <CAN5YmCEFdkV7DJ8-ZTuSk3mNt=kpa_dQHX57zZs4f5dZcCY8sA@mail.gmail.com>
References: <CAN5YmCEFdkV7DJ8-ZTuSk3mNt=kpa_dQHX57zZs4f5dZcCY8sA@mail.gmail.com>
Message-ID: <1270075366.3321881.1416519991694.JavaMail.yahoo@jws10654.mail.bf1.yahoo.com>

Any help on this issue will be greatly appreciated. Spent days sitting alone in a remote corner of the world--> Patiala, Punjab, India.. trying to do this!

---------------------------------------------------------------------------------------------------------------
setwd("C:/Documents and Settings/Administrator/Desktop/Coursera/ProgrammingAssignment3/ProgrammingAssignment3") 
my_disease=0 
my_min_index=0 
best <- function(my_state, my_outcome) { 

outcome_data = read.csv("outcome-of-care-measures.csv",na.strings="Not Available") 
my_vector= which(outcome_data[,"State"]==my_state) 
my_initial_vector=my_vector[1] 
my_length=length(my_vector) 
my_final=my_length+my_initial_vector 
#   return(my_initial_vector) 

if (my_outcome == "heart attack") { 
my_disease=11 
outcome_data[ ,my_disease] <- as.numeric(outcome_data[ ,my_disease]) 

my_attack_lowest = min(outcome_data[my_initial_vector:my_final, 11],na.rm=TRUE) 
#my_attack_lowest_scalar = my_attack_lowest[1] 
} 
for (i in 1:my_length) { 
my_check_outcome= outcome_data[(my_initial_vector+i-1), 11] 
#my_check_outcome_scalar= my_check_outcome[1] 
#my_check_outcome= outcome_data[which(outcome_data[,"State"]==my_state),11] 
#    my_check_outcome<-as.numeric(my_check_outcome) 
if (my_check_outcome_scalar==my_attack_lowest_scalar) { 
my_min_index = i 
#    my_min_index 
return(subset(outcome_data$Provider.Number==my_min_index, outcome_data$Hospital.Name)) 
} 

return() 
} 

if (my_outcome == "heart failure") { 
my_disease=17 
} 

if (my_outcome == "pneumonia") { 
my_disease=23 
} 
#outcome_data[my_min_index,"Hospital.Name"] 
return() 
} 
#outcome_data[my_min_index,"Hospital.Name"]-------------------------------------------------------------------------------------------------------------
 Aditya


From murdoch.duncan at gmail.com  Thu Nov 20 23:02:05 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 20 Nov 2014 17:02:05 -0500
Subject: [R] R website
In-Reply-To: <CA+vqiLGTwojH=aNvyCW25WePke3fbhxzfy2xyr=0aeMWUYabog@mail.gmail.com>
References: <546E3C8A.7030000@uottawa.ca> <546E42C0.1050802@gmail.com>
	<CA+vqiLGTwojH=aNvyCW25WePke3fbhxzfy2xyr=0aeMWUYabog@mail.gmail.com>
Message-ID: <546E64DD.8090708@gmail.com>

On 20/11/2014, 4:35 PM, Ista Zahn wrote:
> This prompted me to do something I've been meaning to do for a long
> time, which is to try to get the R website updated in terms of visual
> style. It really is showing it's age and could use a facelift in my
> opinion. Toward than end I've mocked up a copy of cran.r-project.or
> using css from the python.org website. You can see the result at
> http://izahn.crabdance.com/~izahn/cran-new-css . This is a rough draft
> and needs to be cleaned up, but I though I would float this here first
> to see if there is any hope of getting such a change to be adopted
> before I spent more time on it. Feedback and comments welcome.

You're sending that to the wrong place.  The R website is
www.r-project.org; cran.r-project.org is the CRAN website.  You'll need
to discuss that one with CRAN.

Duncan Murdoch
> 
> Best,
> Ista
> 
> On Thu, Nov 20, 2014 at 2:36 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 20/11/2014 2:10 PM, Prof J C Nash (U30A) wrote:
>>>
>>> I was looking at the R website (r-project.org).
>>>
>>> 1) The Books page does not list several books about R, including one of
>>> my own (Nonlinear parameter optimization tools in R) nor that of Karline
>>> Soetaert on differential equations. How is the list updated?
>>>
>>> 2) The wiki seems to be dead. Is anyone in charge of it? If not, please
>>> contact me off-line. I am willing to help out (I run several Dokuwiki
>>> wikis).
>>
>>
>> Files on www.r-project.org can be edited by any member of R core. You just
>> need to convince one of us to enter it, send us the data, and the book will
>> eventually show up.  (To do that, take a look at the Bibtex .bib file,
>> available at http://www.r-project.org/doc/bib/R.bib, and put together
>> additions in a consistent format.  If it is not obvious why your book should
>> be included, explain why.)
>>
>> Duncan Murdoch
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Nov 20 23:09:51 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 20 Nov 2014 17:09:51 -0500
Subject: [R] R website
In-Reply-To: <546E64DD.8090708@gmail.com>
References: <546E3C8A.7030000@uottawa.ca> <546E42C0.1050802@gmail.com>
	<CA+vqiLGTwojH=aNvyCW25WePke3fbhxzfy2xyr=0aeMWUYabog@mail.gmail.com>
	<546E64DD.8090708@gmail.com>
Message-ID: <CA+vqiLGnz5KJQUEBJhdROfpPra-yJiHP=uryANZuuhGow16+Og@mail.gmail.com>

On Thu, Nov 20, 2014 at 5:02 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 20/11/2014, 4:35 PM, Ista Zahn wrote:
>> This prompted me to do something I've been meaning to do for a long
>> time, which is to try to get the R website updated in terms of visual
>> style. It really is showing it's age and could use a facelift in my
>> opinion. Toward than end I've mocked up a copy of cran.r-project.or
>> using css from the python.org website. You can see the result at
>> http://izahn.crabdance.com/~izahn/cran-new-css . This is a rough draft
>> and needs to be cleaned up, but I though I would float this here first
>> to see if there is any hope of getting such a change to be adopted
>> before I spent more time on it. Feedback and comments welcome.
>
> You're sending that to the wrong place.  The R website is
> www.r-project.org; cran.r-project.org is the CRAN website.  You'll need
> to discuss that one with CRAN.

Thanks Duncan. How does one contact CRAN? I've looked but didn't
manage to find contact information.

In terms of the dated visual style r-project.org is in the same boat
as cran.r-project.org. A mockup of r-project.org is also available at
http://izahn.crabdance.com/~izahn/r-project-new-css/index.html. Again,
I'd appreciate comments or feedback on the proposal to modernize the
website style.

Best,
Ista

>
> Duncan Murdoch
>>
>> Best,
>> Ista
>>
>> On Thu, Nov 20, 2014 at 2:36 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 20/11/2014 2:10 PM, Prof J C Nash (U30A) wrote:
>>>>
>>>> I was looking at the R website (r-project.org).
>>>>
>>>> 1) The Books page does not list several books about R, including one of
>>>> my own (Nonlinear parameter optimization tools in R) nor that of Karline
>>>> Soetaert on differential equations. How is the list updated?
>>>>
>>>> 2) The wiki seems to be dead. Is anyone in charge of it? If not, please
>>>> contact me off-line. I am willing to help out (I run several Dokuwiki
>>>> wikis).
>>>
>>>
>>> Files on www.r-project.org can be edited by any member of R core. You just
>>> need to convince one of us to enter it, send us the data, and the book will
>>> eventually show up.  (To do that, take a look at the Bibtex .bib file,
>>> available at http://www.r-project.org/doc/bib/R.bib, and put together
>>> additions in a consistent format.  If it is not obvious why your book should
>>> be included, explain why.)
>>>
>>> Duncan Murdoch
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From dimitri.liakhovitski at gmail.com  Thu Nov 20 23:27:35 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 20 Nov 2014 17:27:35 -0500
Subject: [R] ggplot question error: Error in s(x,
	bs = "cs") : object 'x' not found
In-Reply-To: <CAN2xGJZ5uWoQGkA2kCzN4M_GqGiWg=qM9oLAfR6pDzS23iRwpw@mail.gmail.com>
References: <CAN2xGJZ5uWoQGkA2kCzN4M_GqGiWg=qM9oLAfR6pDzS23iRwpw@mail.gmail.com>
Message-ID: <CAN2xGJb4hF2qFGPU6O9yMfyYCcw2Y-Xxx_MA8pMxBcpZoOS=gQ@mail.gmail.com>

Never mind, I found the problem.
In my profile s was assigned to summary.
This is why it did not work.

On Thu, Nov 20, 2014 at 5:14 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Dear R-ers,
>
> apologies for not providing the full code. I just need a point in the
> right direction.
> I have a data frame ('temp') with 1,200 rows and 2 variables.
> I am using ggplot2 to create a scatter plot:
>
> This is my code and it works fine, it creates a scatter plot:
>
> library(ggplot2)
> sp10<-ggplot(temp,aes(x=p.used_L1,y=l.to.r.ratio_L1))
> sp10 + geom_point()
>
> However, when I change the last line to:
> sp10 + geom_point() + stat_smooth(se=FALSE)
>
> Then I am getting these messages (and no fitted line on the graph):
>
> geom_smooth: method="auto" and size of largest group is >=1000, so
> using gam with formula: y ~ s(x, bs = "cs"). Use 'method = x' to
> change the smoothing method.
> Error in s(x, bs = "cs") : object 'x' not found
>
> I don't understand what x in in s(x, bs = "cs") is or should be.
> I lookeed up ?geom_smooth and tried this:
>
> sp10 + geom_point() + stat_smooth(se=FALSE,formula = l.to.r.ratio_L1 ~
> p.used_L1)
>
> Still, the same error message.
>
> Thanks a lot for your advice!



-- 
Dimitri Liakhovitski


From plessthanpointohfive at gmail.com  Fri Nov 21 00:44:55 2014
From: plessthanpointohfive at gmail.com (Jennifer Sabatier)
Date: Thu, 20 Nov 2014 23:44:55 +0000
Subject: [R] Saving Google worksheets with common prefix
Message-ID: <CAOxgQ=WQLEUqtWDS2FCQDRZEEDhe=n1C+DSjQeoG7-NBCTZ=7Q@mail.gmail.com>

Hi R-Help,

So, I will try to provide a reproducible example...I basically made a dummy
spreadsheet that contains the same number of tabs as the spreadsheet I am
really interested in.  The data on that spreadsheet is really sensitive so
I couldn't use it.

Anyway, here are the various sheets in the spreadsheet:
> names(ts)
[1] "Operations"    "Financing"     "Income"        "Balance sheet" "Cash
Flows211"
[6] "Cash Flows210" "Cash Flows29"  "Cash Flows28"  "Cash Flows27"

I am only interested in these sheets:
> names(ts2)
[1] "Cash Flows211" "Cash Flows210" "Cash Flows29"  "Cash Flows28"  "Cash
Flows27"

I want to save them to csv files that contain the same name or similar as
the sheet name.

Here's the error I'm getting (using traceback i ran it twice to get the
trace):
[1] "Cash Flows211"
[1] "Cash Flows211 - 2014-11-20.csv"
6: stop(err)
5: stop.if.HTTP.error(http.header)
4: getURLContent(uri, .opts = .opts, .encoding = .encoding, binary =
binary,
       curl = curl)
3: getForm("https://www.google.com/accounts/ClientLogin", accountType =
"HOSTED_OR_GOOGLE",
       Email = login, Passwd = password, service = service, source = appID,
       .opts = list(ssl.verifypeer = FALSE))
2: getGoogleAuth(usrname, pword, "...", service = "wise")
1: getGoogleDocsConnection(getGoogleAuth(usrname, pword, "...",
       service = "wise"))
Error in getURL(sheet at cellsfeed, curl = getCurlCon(con), followlocation =
TRUE) :
  trying to get slot "cellsfeed" from an object of a basic class ("NULL")
with no slots


Here's the code:

# install the RGoogleDocs package
install.packages("RGoogleDocs", repos = "http://www.omegahat.org/R",
type="source", dep=F)

library(RGoogleDocs)

usrname <- "r.project.user at gmail.com"

pword <- "fakepword"

sheets.con <- getGoogleDocsConnection(getGoogleAuth(usrname, pword, "...",
service = "wise"))

a <- getDocs(sheets.con)

ts <- getWorksheets('Google spreadsheet example', sheets.con)

ts2 <- ts[grep("^Cash Flow", names(ts))]
nms <- names(ts2)
lnth <- length(ts2)
sheetz <- list("integer" = lnth, "names" = nms)
sheetz

for (i in sheetz$names) {
print(i)
file.name <- paste(i, " - ", Sys.Date(), ".csv", sep="")
print(file.name)
traceback()
tab <- sheetAsMatrix(ts2$i, header = TRUE, as.data.frame = TRUE, trim =
TRUE)
writecsv(tab, file.name)

}


Now, if I do this as below it works:



tab <- sheetAsMatrix(ts$"Cash Flows211", header = T, as.data.frame = TRUE,
trim = TRUE)

head(tab)

> head(tab)
              STATEMENTS OF CASH FLOWS    NA    NA    NA    NA
1                                 Year   0.0   1.0   2.0   3.0
2                           Net income  <NA> -43.0  -6.0  32.0
3                    Plus depreciation  <NA> 100.0 100.0 100.0
4           Less increase in inventory -10.0 -15.0 -10.0  -8.0
5 Less increase in accounts receivable     - -60.0 -24.0 -18.0
6    Plus increase in accounts payable   8.0  12.0   8.0   6.0



So, why can't I automate this?

BTW, you should be able to access this spreadsheet.  I made a dummy Google
account and put this dummy spreadsheet on it.

	[[alternative HTML version deleted]]


From mamillerpa at gmail.com  Fri Nov 21 01:16:04 2014
From: mamillerpa at gmail.com (Mark Miller)
Date: Thu, 20 Nov 2014 19:16:04 -0500
Subject: [R] see rcurl contents before they're sent?
Message-ID: <CAADrioQPaDmVmiiEUzDg66LEMJKKwpChsLwZd_uX_U6RxcgZZg@mail.gmail.com>

I am trying to use the R / solr integration from
https://github.com/datadolphyn/R/blob/master/r_solr_integration.R

I have the query function working, but I'm having trouble with the post
functions, which uses rcurl.

Is it possible to see the string that rcurl is going to send to a webserver
(instead of, or in addition to send it to the server?)

thanks,
Mark

	[[alternative HTML version deleted]]


From hasan.diwan at gmail.com  Fri Nov 21 01:39:57 2014
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Thu, 20 Nov 2014 16:39:57 -0800
Subject: [R] see rcurl contents before they're sent?
In-Reply-To: <CAADrioQPaDmVmiiEUzDg66LEMJKKwpChsLwZd_uX_U6RxcgZZg@mail.gmail.com>
References: <CAADrioQPaDmVmiiEUzDg66LEMJKKwpChsLwZd_uX_U6RxcgZZg@mail.gmail.com>
Message-ID: <CAP+bYWAKky3jZjfPy6Yeg-uP5zBrFC-NsOZ2QoNvgfYu8-Wm-g@mail.gmail.com>

RCurl has a verbose switch, which may be set as follows:

response <- postForm(getUpdateURL(),.opts = list(postfields = '{"delete":
{"query":"*:*"}}',httpheader = c('Content-Type' = 'application/json',Accept
= 'application/json', *verbose = TRUE*) # emphasis mine

On 20 November 2014 16:16, Mark Miller <mamillerpa at gmail.com> wrote:

> I am trying to use the R / solr integration from
> https://github.com/datadolphyn/R/blob/master/r_solr_integration.R
>
> I have the query function working, but I'm having trouble with the post
> functions, which uses rcurl.
>
> Is it possible to see the string that rcurl is going to send to a webserver
> (instead of, or in addition to send it to the server?)
>
> thanks,
> Mark
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable

	[[alternative HTML version deleted]]


From matt at considine.net  Fri Nov 21 02:42:16 2014
From: matt at considine.net (Matt Considine)
Date: Thu, 20 Nov 2014 20:42:16 -0500
Subject: [R] Parsing Google Finance page data?
Message-ID: <546E9878.9010607@considine.net>

Hi,
I'm wondering if anyone can point me to code to parse data on Google 
Finance pages, i.e. parse the results of a URL request such as this
   http://www.google.com/finance?q=apple

I know how to return the contents of the page; it's figuring out the 
best tools to parse it that I'm interested in and hopefully someone has 
already done this.

(For what it is worth, the only info I am looking for are the ticker, 
exchange, currency and "Mkt Cap" datapoint)

Thanks in advance for any help - scraping is not my strong suit.
Matt


---
This email is free from viruses and malware because avast! Antivirus protection is active.


From spencer.graves at structuremonitoring.com  Fri Nov 21 02:57:50 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 20 Nov 2014 17:57:50 -0800
Subject: [R] Parsing Google Finance page data?
In-Reply-To: <546E9878.9010607@considine.net>
References: <546E9878.9010607@considine.net>
Message-ID: <546E9C1E.70602@structuremonitoring.com>

       The Ecfun package includes functions written to scrape data from 
web pages.  See, e.g., readUShouse, readUSsenate, 
readUSstateAbbreviations.  They use getURL{RCurl} and readHTMLTable{XML}.


       Hope this helps.


       Spencer Graves



On 11/20/2014 5:42 PM, Matt Considine wrote:
> Hi,
> I'm wondering if anyone can point me to code to parse data on Google 
> Finance pages, i.e. parse the results of a URL request such as this
>   http://www.google.com/finance?q=apple
>
> I know how to return the contents of the page; it's figuring out the 
> best tools to parse it that I'm interested in and hopefully someone 
> has already done this.
>
> (For what it is worth, the only info I am looking for are the ticker, 
> exchange, currency and "Mkt Cap" datapoint)
>
> Thanks in advance for any help - scraping is not my strong suit.
> Matt
>
>
> ---
> This email is free from viruses and malware because avast! Antivirus 
> protection is active.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cflynch at ncsu.edu  Fri Nov 21 03:22:27 2014
From: cflynch at ncsu.edu (Collin Lynch)
Date: Thu, 20 Nov 2014 21:22:27 -0500
Subject: [R] Parsing Google Finance page data?
In-Reply-To: <546E9C1E.70602@structuremonitoring.com>
References: <546E9878.9010607@considine.net>
	<546E9C1E.70602@structuremonitoring.com>
Message-ID: <CAE=6FXaSyvbZa3w6F8-hekrp0OfOCmMLOpCz8_98gf8VQ1+Kug@mail.gmail.com>

If you do not need a pure R solution, you might also find it helpful to
blend languages.  For scraping and munging tasks such as this I generally
turn to python to do extraction then feed data to R for analysis via rpy.

On Thu, Nov 20, 2014 at 8:57 PM, Spencer Graves <
spencer.graves at structuremonitoring.com> wrote:

>       The Ecfun package includes functions written to scrape data from web
> pages.  See, e.g., readUShouse, readUSsenate, readUSstateAbbreviations.
> They use getURL{RCurl} and readHTMLTable{XML}.
>
>
>       Hope this helps.
>
>
>       Spencer Graves
>
>
>
> On 11/20/2014 5:42 PM, Matt Considine wrote:
>
>> Hi,
>> I'm wondering if anyone can point me to code to parse data on Google
>> Finance pages, i.e. parse the results of a URL request such as this
>>   http://www.google.com/finance?q=apple
>>
>> I know how to return the contents of the page; it's figuring out the best
>> tools to parse it that I'm interested in and hopefully someone has already
>> done this.
>>
>> (For what it is worth, the only info I am looking for are the ticker,
>> exchange, currency and "Mkt Cap" datapoint)
>>
>> Thanks in advance for any help - scraping is not my strong suit.
>> Matt
>>
>>
>> ---
>> This email is free from viruses and malware because avast! Antivirus
>> protection is active.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From matt at considine.net  Fri Nov 21 03:45:14 2014
From: matt at considine.net (Matt Considine)
Date: Thu, 20 Nov 2014 21:45:14 -0500
Subject: [R] Parsing Google Finance page data?
In-Reply-To: <CAE=6FXaSyvbZa3w6F8-hekrp0OfOCmMLOpCz8_98gf8VQ1+Kug@mail.gmail.com>
References: <546E9878.9010607@considine.net>	<546E9C1E.70602@structuremonitoring.com>
	<CAE=6FXaSyvbZa3w6F8-hekrp0OfOCmMLOpCz8_98gf8VQ1+Kug@mail.gmail.com>
Message-ID: <546EA73A.1070507@considine.net>

FWIW, this is the kludge I came up with.  The idea is that I only know 
the name of the company and not the ticker/exchange.  So the following 
admittedly doesn't work in all cases (e.g. "Time Warner").  So if anyone 
alternatively knows how to return a list of tickers/exchanges of 
companies matching a name, that would be helpful.  (Though that question 
should probably go to the finance list).  In any case, thanks in advance 
for any thoughts put towards this.
Matt

library(RCurl)
library(xts)
library(XML)

#want to return results of this
# http://www.google.com/finance?q=ibm

coname <- "ibm"

baseurl <-paste("http://www.google.com/finance?q=",coname,sep="")

# Read and parse HTML file
doc.html = htmlTreeParse(baseurl, useInternalNodes=TRUE)

tables <- 
readHTMLTable(doc.html,which=2,as.data.frame=T,stringsAsFactors = FALSE)
mktcap <- tables[4,2]

doc.text = unlist(xpathApply(doc.html, '//script', xmlValue))

block <- doc.text[11]
exchangeticker<-unlist(strsplit(block,'\n'))[11]

doc.text = unlist(xpathApply(doc.html, '//div', xmlValue))
currency <- doc.text[60]

print(mktcap)
print(exchangeticker)
print(currency)


---
This email is free from viruses and malware because avast! Antivirus protection is active.


	[[alternative HTML version deleted]]


From amitmt at techmahindra.com  Fri Nov 21 07:07:42 2014
From: amitmt at techmahindra.com (Amit Thombre)
Date: Fri, 21 Nov 2014 11:37:42 +0530
Subject: [R] Optimization function
Message-ID: <4A753D3F0C227041AB666DA6283A81F313C5C37173@SINPUNMBX002.TechMahindra.com>


Hi,

I want to optimize the root mean square error objective function using the optim function. Thus the function will look like sqrt(sum((yi - f(xi))^2)/n). Now the f(xi) is the Arima function.  I am not clear how do I get the f(xi) because the call to arima function in C gives the value of the arima function which takes in the entire vector x, or do I restrict the value of x  to the arima function in C. That is for getting he f(x1) value give only x1 as the input to arima, for getting f(x2) give only x1 and x2 as input to arima function in C.

Any help on this will be highly appreciated.

Regards
Amit


============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From jwd at surewest.net  Fri Nov 21 08:57:53 2014
From: jwd at surewest.net (jwd)
Date: Thu, 20 Nov 2014 23:57:53 -0800
Subject: [R] Rose Diagrams for Geology
In-Reply-To: <CACftpvqYVCVLU4bn0oA607SQLw7mVTO1ZW0hxaH0AHx-pKQk3Q@mail.gmail.com>
References: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>
	<BABF13FF-F9ED-4DAF-9E53-A71FB5BE58E3@comcast.net>
	<CACftpvqYVCVLU4bn0oA607SQLw7mVTO1ZW0hxaH0AHx-pKQk3Q@mail.gmail.com>
Message-ID: <20141120235753.09ec5816@draco>

On Tue, 18 Nov 2014 22:06:03 -0600
David Doyle <kydaviddoyle at gmail.com> wrote:

> Thank you to David and David for their help.  The code below
> generated what I needed.
> 
> 
> library(circular)
> mydata <- read.table("http://doylesdartden.com/R/Joints.csv",
> header=TRUE, sep=",",)
> x <- circular(mydata$JointsRad)
> rose.diag(x,
> 
>           #Set point character to use
>           pch = 20,
>           #sets font size
>           cex = 1,
>           #parameter that controls the size of the circle.
>           #1= default <1 makes it larger > makes it smaller
>           shrink = 1,
>           #the color for filling the rose diagram.
>           col=2,
>           prop = 2,
>           # number of bins.  36 = 10 degrees each.  18 = 20 degree
> each bins=36,
>           # Ticks showing bins
>           ticks=TRUE,
>           # Unites.
>           units="degrees",
>           # list main title
>           main="Rose Diagram of XXX")
> # for more info see
> http://www.inside-r.org/packages/cran/circular/docs/rose.diag
> 
I've been following this thread with some interest.  One problem that I
might have with the code above is that as it is, the plot is labeled
with 0-deg to the left, and numbered counter clockwise (standard
trigonometric format). Most field mapping data I have collected has been
either in quadrant form (rarely) or more commonly in azimuthal form
(0-360 degrees order clockwise from the top).  Is that an issue? 

jwdougherty


From Rainer at krugs.de  Fri Nov 21 09:21:46 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 21 Nov 2014 09:21:46 +0100
Subject: [R] Symbolic equations to R code?
In-Reply-To: <546E4279.5070201@ucsd.edu> (Scott Rifkin's message of "Thu, 20
	Nov 2014 11:35:21 -0800")
References: <546CD0A3.30201@ucsd.edu>
	<CA+vqiLFzysf9=tiW6mMAnUe5k2hKhXYZ_oirET0DCDy0i0dMVw@mail.gmail.com>
	<546E4279.5070201@ucsd.edu>
Message-ID: <m2y4r5ge05.fsf@krugs.de>

Scott Rifkin <sarifkin at ucsd.edu> writes:

> Ista,
>
> On the one hand I'd like it to be as flexible as possible so the
> students could really come up with whatever they like.  On the other
> hand, restricting their choices probably would make it easier to do
> the backend.  The goal would be to get them to realize that the
> apparatus of hypothesis testing (when done via
> simulation/randomization techniques) doesn't depend on what the
> statistic is. The flow of steps is the same whether the statistic is a
> mean, variance, or their own kooky thing. Obviously this isn't the end
> of the story - what the statistic is actually describing is also a
> crucial component to interpreting the results of a hypothesis test,
> but I think it teaches an important pedagogical point about where
> statistics come from and that if they find themselves in a situation
> in the future where they need to make up their own, then that is
> perfectly okay.
>
> So they could make up ones like:  arctan( (max({x})^2)/ (min({x})^2)
> )-3), max({x})-min({x}), sum from i to n of (x_i - 25th%ile({x}) )^3)
> [that might be tricky to write in a standard equation editor]
> none of these is hard to write in R, but translating from an equation
> editor might be.
>
> Perhaps the best solution is (as Alan suggests below) to write a Shiny
> function builder myself so that I can control the whole process and
> make sure that they can't enter anything that would break the backend.
> Or to have them learn the rudiments of writing equations in R so that
> it bypasses the whole process.

Teach them to write equations in R will make them more used to the
logic in R and make them feel easier to use R.

On the other hand, a converter from LaTeX equations to R formulas and
back would be quite a useful thing for e.g. documentation and paper
writing (e.g a formula entered in LaTeX could be immediately tested in
R) - but I guess that would be quite a complex task...

Cheers,

Rainer



>
> Thanks,
> Scott
>
>
>
> On 11/19/14 1:52 PM, Ista Zahn wrote:
>> Hi Scott,
>>
>> Can you give a couple of examples of the equations you have in mind
>> along with how those should be translated to R?
>>
>> Thanks,
>> Ista
>>
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141121/e4624983/attachment.bin>

From petretta at unina.it  Fri Nov 21 09:51:48 2014
From: petretta at unina.it (Mario Petretta)
Date: Fri, 21 Nov 2014 09:51:48 +0100
Subject: [R] Comparing summary hazard ratios in meta-analysis
In-Reply-To: <001901cff51f$ace1e370$06a5aa50$@unina.it>
References: <001901cff51f$ace1e370$06a5aa50$@unina.it>
Message-ID: <006d01d00568$62a56ad0$27f04070$@it>

Dear all,

I use R 3.1.1 for Windows.

I performed two different meta-analysis assessing the prognostic value of
two different tests in patients with coronary artery disease. The study
included in the two analysis are different.

The variable of interest in dichotomous (normal/abnormal result) for both
tests.
  
The effects size is hazard ratio and its standard error (ln units) for both
meta-analysis. 

I would like to statistically compare the two summary hazard ratios and 95%
CI (eform) obtained from the two meta-analysis.

For one meta-analysis: HR 3.12 (95% CI 2.2 - 4.1)
For the other: HR 1.25 (95% CI 1.03 - 2.6) 

It is possible or I'm comparing apples with oranges?

Any suggestion is welcome.

-------------------------------------------------------
Mario Petretta
Associate Professor of Internal Medicine
Department of Translational Medical Sciences Naples
University Federico II Italy










---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
http://www.avast.com


From info at aghmed.fsnet.co.uk  Fri Nov 21 13:24:48 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 21 Nov 2014 12:24:48 +0000
Subject: [R] Comparing summary hazard ratios in meta-analysis
In-Reply-To: <006d01d00568$62a56ad0$27f04070$@it>
References: <001901cff51f$ace1e370$06a5aa50$@unina.it>
	<006d01d00568$62a56ad0$27f04070$@it>
Message-ID: <546F2F10.201@aghmed.fsnet.co.uk>



On 21/11/2014 08:51, Mario Petretta wrote:
> Dear all,
>
> I use R 3.1.1 for Windows.
>
> I performed two different meta-analysis assessing the prognostic value of
> two different tests in patients with coronary artery disease. The study
> included in the two analysis are different.

That makes life simpler.

>
> The variable of interest in dichotomous (normal/abnormal result) for both
> tests.
>
> The effects size is hazard ratio and its standard error (ln units) for both
> meta-analysis.

It sounds as though you might want to use meta-regression. You will need 
a single data frame containing at least log hr, se of log hr, an 
identifier for the test. I would use the metafor package for this, look 
in the documentation for how to incorporate a moderator (your test 
variable). The advantage of meta-regression is that you not only get a 
test but also a measure of how different the hr are with a confidence 
interval.

>
> I would like to statistically compare the two summary hazard ratios and 95%
> CI (eform) obtained from the two meta-analysis.
>
> For one meta-analysis: HR 3.12 (95% CI 2.2 - 4.1)
> For the other: HR 1.25 (95% CI 1.03 - 2.6)
>
> It is possible or I'm comparing apples with oranges?
>
> Any suggestion is welcome.
>
> -------------------------------------------------------
> Mario Petretta
> Associate Professor of Internal Medicine
> Department of Translational Medical Sciences Naples
> University Federico II Italy
>
>
>
>
>
>
>
>
>
>
> ---
> Questa e-mail ? stata controllata per individuare virus con Avast antivirus.
> http://www.avast.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4213/8604 - Release Date: 11/21/14
>

-- 
Michael
http://www.dewey.myzen.co.uk


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Nov 21 15:36:50 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 21 Nov 2014 15:36:50 +0100
Subject: [R] Comparing summary hazard ratios in meta-analysis
In-Reply-To: <546F2F10.201@aghmed.fsnet.co.uk>
References: <001901cff51f$ace1e370$06a5aa50$@unina.it>
	<006d01d00568$62a56ad0$27f04070$@it> <546F2F10.201@aghmed.fsnet.co.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730EFA099A36@UM-MAIL4112.unimaas.nl>

Those hazard ratios and CIs seem a bit strange. On the log-scale, they should be symmetric, but they are not. Could be due to heavy rounding though. At any rate, it comes down to this:

hr    <- c(3.12, 1.15)
ci.lb <- c(2.2, 1.03)
ci.ub <- c(4.1, 2.6)
meta  <- c(1,2)

### log-transform hazard ratios and compute standard error based on the CI bounds
yi  <- log(hr)
sei <- (log(ci.ub) - log(ci.lb)) / (2*1.96)

library(metafor)
res <- rma(yi ~ factor(meta), sei=sei, method="FE")
res

So, yes, the two hazard ratios are significantly different from each other.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Michael Dewey
> Sent: Friday, November 21, 2014 13:25
> To: Mario Petretta; r-help at r-project.org
> Subject: Re: [R] Comparing summary hazard ratios in meta-analysis
> 
> On 21/11/2014 08:51, Mario Petretta wrote:
> > Dear all,
> >
> > I use R 3.1.1 for Windows.
> >
> > I performed two different meta-analysis assessing the prognostic value
> of
> > two different tests in patients with coronary artery disease. The study
> > included in the two analysis are different.
> 
> That makes life simpler.
> 
> >
> > The variable of interest in dichotomous (normal/abnormal result) for
> both
> > tests.
> >
> > The effects size is hazard ratio and its standard error (ln units) for
> both
> > meta-analysis.
> 
> It sounds as though you might want to use meta-regression. You will need
> a single data frame containing at least log hr, se of log hr, an
> identifier for the test. I would use the metafor package for this, look
> in the documentation for how to incorporate a moderator (your test
> variable). The advantage of meta-regression is that you not only get a
> test but also a measure of how different the hr are with a confidence
> interval.
> 
> > I would like to statistically compare the two summary hazard ratios and
> 95%
> > CI (eform) obtained from the two meta-analysis.
> >
> > For one meta-analysis: HR 3.12 (95% CI 2.2 - 4.1)
> > For the other: HR 1.25 (95% CI 1.03 - 2.6)
> >
> > It is possible or I'm comparing apples with oranges?
> >
> > Any suggestion is welcome.
> >
> > -------------------------------------------------------
> > Mario Petretta
> > Associate Professor of Internal Medicine
> > Department of Translational Medical Sciences Naples
> > University Federico II Italy

From i.petzev at gmail.com  Fri Nov 21 15:52:27 2014
From: i.petzev at gmail.com (ivan)
Date: Fri, 21 Nov 2014 15:52:27 +0100
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <72B60A76-2390-43AC-95C7-E0B7B3609ADF@comcast.net>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
	<B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
	<79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>
	<8780E3CE-13F9-43B3-A6D3-5034BBE6304C@comcast.net>
	<12A4CACA-73C3-42A8-BC54-053A891B7B7C@gmail.com>
	<72B60A76-2390-43AC-95C7-E0B7B3609ADF@comcast.net>
Message-ID: <CAOrU2ZJvz0K7sE8eRXv3xxWkWFZuwBdKZeidA7w2wQ4EYNCvLw@mail.gmail.com>

I am aware of the fact that bootstrapping produces different CIs with every
run. I still believe that there is a difference between both types of
procedures. My understanding is that setting "w" in the boot() function
influences the "importance" of observations or how the bootstrap selects
the observations. I.e, observation i does not have the same probability of
being chosen as observation j when "w" is defined in the boot() function.
If you return res_boot you will notice that with "w" being set in the
boot() function, the function call states "weighted bootstrap". If not, it
states "ordinary nonparametric bootstrap". But maybe I am wrong.

On Thu, Nov 20, 2014 at 8:19 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Nov 20, 2014, at 2:23 AM, i.petzev wrote:
>
> > Hi David,
> >
> > sorry, I was not clear.
>
> Right. You never were clear about what you wanted and your examples was so
> statistically symmetric that it is still hard to see what is needed. The
> examples below show CI's that are arguably equivalent. I can be faulted for
> attempting to provide code that produced a sensible answer to a vague
> question to which I was only guessing at the intent.
>
>
> > The difference comes from defining or not defining ?w? in the boot()
> function. The results with your function and your approach are thus:
> >
> > set.seed(1111)
> > x <- rnorm(50)
> > y <- rnorm(50)
> > weights <- runif(50)
> > weights <- weights / sum(weights)
> > dataset <- cbind(x,y,weights)
> >
> > vw_m_diff <- function(dataset,w) {
> >   differences <- dataset[w,1]-dataset[w,2]
> >   weights <- dataset[w, "weights"]
> >   return(weighted.mean(x=differences, w=weights))
> > }
> > res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
> > boot.ci(res_boot)
> >
> > BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> > Based on 1000 bootstrap replicates
> >
> > CALL :
> > boot.ci(boot.out = res_boot)
> >
> > Intervals :
> > Level      Normal              Basic
> > 95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )
> >
> > Level     Percentile            BCa
> > 95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )
> > Calculations and Intervals on Original Scale
> >
> >
> ********************************************************************************************************************
> >
> > However, without defining ?w? in the bootstrap function, i.e., running
> an ordinary and not a weighted bootstrap, the results are:
> >
> > res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000)
> > boot.ci(res_boot)
> >
> > BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> > Based on 1000 bootstrap replicates
> >
> > CALL :
> > boot.ci(boot.out = res_boot)
> >
> > Intervals :
> > Level      Normal              Basic
> > 95%   (-0.6265,  0.4966 )   (-0.6125,  0.5249 )
>
> I hope you are not saying that because those CI's are different that there
> is some meaning in that difference. Bootstrap runs will always be
> "different" than each other unless you use set.seed(.) before the runs.
>
> >
> > Level     Percentile            BCa
> > 95%   (-0.6714,  0.4661 )   (-0.6747,  0.4559 )
> > Calculations and Intervals on Original Scale
> >
> > On 19 Nov 2014, at 17:49, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >>>> vw_m_diff <- function(dataset,w) {
> >>>>     differences <- dataset[w,1]-dataset[w,2]
> >>>>    weights <- dataset[w, "weights"]
> >>>>    return(weighted.mean(x=differences, w=weights))
> >>>>  }
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Nov 21 15:53:49 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 21 Nov 2014 14:53:49 +0000
Subject: [R] Rose Diagrams for Geology
In-Reply-To: <20141120235753.09ec5816@draco>
References: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>
	<BABF13FF-F9ED-4DAF-9E53-A71FB5BE58E3@comcast.net>
	<CACftpvqYVCVLU4bn0oA607SQLw7mVTO1ZW0hxaH0AHx-pKQk3Q@mail.gmail.com>
	<20141120235753.09ec5816@draco>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB3CD7@mb02.ads.tamu.edu>

No. Just use the circular() function to specify that your data are in degrees and clockwise and the graph will be labeled that way.

David C (I was beginning to think that this thread was only for Davids).

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of jwd
Sent: Friday, November 21, 2014 1:58 AM
To: r-help at r-project.org
Subject: Re: [R] Rose Diagrams for Geology

On Tue, 18 Nov 2014 22:06:03 -0600
David Doyle <kydaviddoyle at gmail.com> wrote:

> Thank you to David and David for their help.  The code below
> generated what I needed.
> 
> 
> library(circular)
> mydata <- read.table("http://doylesdartden.com/R/Joints.csv",
> header=TRUE, sep=",",)
> x <- circular(mydata$JointsRad)
> rose.diag(x,
> 
>           #Set point character to use
>           pch = 20,
>           #sets font size
>           cex = 1,
>           #parameter that controls the size of the circle.
>           #1= default <1 makes it larger > makes it smaller
>           shrink = 1,
>           #the color for filling the rose diagram.
>           col=2,
>           prop = 2,
>           # number of bins.  36 = 10 degrees each.  18 = 20 degree
> each bins=36,
>           # Ticks showing bins
>           ticks=TRUE,
>           # Unites.
>           units="degrees",
>           # list main title
>           main="Rose Diagram of XXX")
> # for more info see
> http://www.inside-r.org/packages/cran/circular/docs/rose.diag
> 
I've been following this thread with some interest.  One problem that I
might have with the code above is that as it is, the plot is labeled
with 0-deg to the left, and numbered counter clockwise (standard
trigonometric format). Most field mapping data I have collected has been
either in quadrant form (rarely) or more commonly in azimuthal form
(0-360 degrees order clockwise from the top).  Is that an issue? 

jwdougherty

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From plessthanpointohfive at gmail.com  Fri Nov 21 16:19:17 2014
From: plessthanpointohfive at gmail.com (Jennifer Sabatier)
Date: Fri, 21 Nov 2014 10:19:17 -0500
Subject: [R] Saving Google worksheets with common prefix
In-Reply-To: <CAOxgQ=WQLEUqtWDS2FCQDRZEEDhe=n1C+DSjQeoG7-NBCTZ=7Q@mail.gmail.com>
References: <CAOxgQ=WQLEUqtWDS2FCQDRZEEDhe=n1C+DSjQeoG7-NBCTZ=7Q@mail.gmail.com>
Message-ID: <CAOxgQ=XHY8o6mvP4X-szD2Xk2SKidvY41hgYahxoFy-aLxQXzQ@mail.gmail.com>

Anyone can help?

On Thu, Nov 20, 2014 at 6:44 PM, Jennifer Sabatier <
plessthanpointohfive at gmail.com> wrote:

> Hi R-Help,
>
> So, I will try to provide a reproducible example...I basically made a
> dummy spreadsheet that contains the same number of tabs as the spreadsheet
> I am really interested in.  The data on that spreadsheet is really
> sensitive so I couldn't use it.
>
> Anyway, here are the various sheets in the spreadsheet:
> > names(ts)
> [1] "Operations"    "Financing"     "Income"        "Balance sheet" "Cash
> Flows211"
> [6] "Cash Flows210" "Cash Flows29"  "Cash Flows28"  "Cash Flows27"
>
> I am only interested in these sheets:
> > names(ts2)
> [1] "Cash Flows211" "Cash Flows210" "Cash Flows29"  "Cash Flows28"  "Cash
> Flows27"
>
> I want to save them to csv files that contain the same name or similar as
> the sheet name.
>
> Here's the error I'm getting (using traceback i ran it twice to get the
> trace):
> [1] "Cash Flows211"
> [1] "Cash Flows211 - 2014-11-20.csv"
> 6: stop(err)
> 5: stop.if.HTTP.error(http.header)
> 4: getURLContent(uri, .opts = .opts, .encoding = .encoding, binary =
> binary,
>        curl = curl)
> 3: getForm("https://www.google.com/accounts/ClientLogin", accountType =
> "HOSTED_OR_GOOGLE",
>        Email = login, Passwd = password, service = service, source =
> appID,
>        .opts = list(ssl.verifypeer = FALSE))
> 2: getGoogleAuth(usrname, pword, "...", service = "wise")
> 1: getGoogleDocsConnection(getGoogleAuth(usrname, pword, "...",
>        service = "wise"))
> Error in getURL(sheet at cellsfeed, curl = getCurlCon(con), followlocation =
> TRUE) :
>   trying to get slot "cellsfeed" from an object of a basic class ("NULL")
> with no slots
>
>
> Here's the code:
>
> # install the RGoogleDocs package
> install.packages("RGoogleDocs", repos = "http://www.omegahat.org/R",
> type="source", dep=F)
>
> library(RGoogleDocs)
>
> usrname <- "r.project.user at gmail.com"
>
> pword <- "fakepword"
>
> sheets.con <- getGoogleDocsConnection(getGoogleAuth(usrname, pword, "...",
> service = "wise"))
>
> a <- getDocs(sheets.con)
>
> ts <- getWorksheets('Google spreadsheet example', sheets.con)
>
> ts2 <- ts[grep("^Cash Flow", names(ts))]
> nms <- names(ts2)
> lnth <- length(ts2)
> sheetz <- list("integer" = lnth, "names" = nms)
> sheetz
>
> for (i in sheetz$names) {
> print(i)
> file.name <- paste(i, " - ", Sys.Date(), ".csv", sep="")
> print(file.name)
> traceback()
> tab <- sheetAsMatrix(ts2$i, header = TRUE, as.data.frame = TRUE, trim =
> TRUE)
> writecsv(tab, file.name)
>
> }
>
>
> Now, if I do this as below it works:
>
>
>
> tab <- sheetAsMatrix(ts$"Cash Flows211", header = T, as.data.frame = TRUE,
> trim = TRUE)
>
> head(tab)
>
> > head(tab)
>               STATEMENTS OF CASH FLOWS    NA    NA    NA    NA
> 1                                 Year   0.0   1.0   2.0   3.0
> 2                           Net income  <NA> -43.0  -6.0  32.0
> 3                    Plus depreciation  <NA> 100.0 100.0 100.0
> 4           Less increase in inventory -10.0 -15.0 -10.0  -8.0
> 5 Less increase in accounts receivable     - -60.0 -24.0 -18.0
> 6    Plus increase in accounts payable   8.0  12.0   8.0   6.0
>
>
>
> So, why can't I automate this?
>
> BTW, you should be able to access this spreadsheet.  I made a dummy Google
> account and put this dummy spreadsheet on it.
>

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Fri Nov 21 16:36:23 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 21 Nov 2014 07:36:23 -0800
Subject: [R] Saving Google worksheets with common prefix
In-Reply-To: <CAOxgQ=XHY8o6mvP4X-szD2Xk2SKidvY41hgYahxoFy-aLxQXzQ@mail.gmail.com>
References: <CAOxgQ=WQLEUqtWDS2FCQDRZEEDhe=n1C+DSjQeoG7-NBCTZ=7Q@mail.gmail.com>
	<CAOxgQ=XHY8o6mvP4X-szD2Xk2SKidvY41hgYahxoFy-aLxQXzQ@mail.gmail.com>
Message-ID: <CAFDcVCQdE4Go7DO7FTbzFabkyWN93RtFyZS+Ta=x=JGzSJONfw@mail.gmail.com>

Add a print(ts2$i) to see if that really gives what you think it does.

Then take it from there.

Henrik
On Nov 21, 2014 7:19 AM, "Jennifer Sabatier" <plessthanpointohfive at gmail.com>
wrote:

> Anyone can help?
>
> On Thu, Nov 20, 2014 at 6:44 PM, Jennifer Sabatier <
> plessthanpointohfive at gmail.com> wrote:
>
> > Hi R-Help,
> >
> > So, I will try to provide a reproducible example...I basically made a
> > dummy spreadsheet that contains the same number of tabs as the
> spreadsheet
> > I am really interested in.  The data on that spreadsheet is really
> > sensitive so I couldn't use it.
> >
> > Anyway, here are the various sheets in the spreadsheet:
> > > names(ts)
> > [1] "Operations"    "Financing"     "Income"        "Balance sheet" "Cash
> > Flows211"
> > [6] "Cash Flows210" "Cash Flows29"  "Cash Flows28"  "Cash Flows27"
> >
> > I am only interested in these sheets:
> > > names(ts2)
> > [1] "Cash Flows211" "Cash Flows210" "Cash Flows29"  "Cash Flows28"  "Cash
> > Flows27"
> >
> > I want to save them to csv files that contain the same name or similar as
> > the sheet name.
> >
> > Here's the error I'm getting (using traceback i ran it twice to get the
> > trace):
> > [1] "Cash Flows211"
> > [1] "Cash Flows211 - 2014-11-20.csv"
> > 6: stop(err)
> > 5: stop.if.HTTP.error(http.header)
> > 4: getURLContent(uri, .opts = .opts, .encoding = .encoding, binary =
> > binary,
> >        curl = curl)
> > 3: getForm("https://www.google.com/accounts/ClientLogin", accountType =
> > "HOSTED_OR_GOOGLE",
> >        Email = login, Passwd = password, service = service, source =
> > appID,
> >        .opts = list(ssl.verifypeer = FALSE))
> > 2: getGoogleAuth(usrname, pword, "...", service = "wise")
> > 1: getGoogleDocsConnection(getGoogleAuth(usrname, pword, "...",
> >        service = "wise"))
> > Error in getURL(sheet at cellsfeed, curl = getCurlCon(con), followlocation
> =
> > TRUE) :
> >   trying to get slot "cellsfeed" from an object of a basic class ("NULL")
> > with no slots
> >
> >
> > Here's the code:
> >
> > # install the RGoogleDocs package
> > install.packages("RGoogleDocs", repos = "http://www.omegahat.org/R",
> > type="source", dep=F)
> >
> > library(RGoogleDocs)
> >
> > usrname <- "r.project.user at gmail.com"
> >
> > pword <- "fakepword"
> >
> > sheets.con <- getGoogleDocsConnection(getGoogleAuth(usrname, pword,
> "...",
> > service = "wise"))
> >
> > a <- getDocs(sheets.con)
> >
> > ts <- getWorksheets('Google spreadsheet example', sheets.con)
> >
> > ts2 <- ts[grep("^Cash Flow", names(ts))]
> > nms <- names(ts2)
> > lnth <- length(ts2)
> > sheetz <- list("integer" = lnth, "names" = nms)
> > sheetz
> >
> > for (i in sheetz$names) {
> > print(i)
> > file.name <- paste(i, " - ", Sys.Date(), ".csv", sep="")
> > print(file.name)
> > traceback()
> > tab <- sheetAsMatrix(ts2$i, header = TRUE, as.data.frame = TRUE, trim =
> > TRUE)
> > writecsv(tab, file.name)
> >
> > }
> >
> >
> > Now, if I do this as below it works:
> >
> >
> >
> > tab <- sheetAsMatrix(ts$"Cash Flows211", header = T, as.data.frame =
> TRUE,
> > trim = TRUE)
> >
> > head(tab)
> >
> > > head(tab)
> >               STATEMENTS OF CASH FLOWS    NA    NA    NA    NA
> > 1                                 Year   0.0   1.0   2.0   3.0
> > 2                           Net income  <NA> -43.0  -6.0  32.0
> > 3                    Plus depreciation  <NA> 100.0 100.0 100.0
> > 4           Less increase in inventory -10.0 -15.0 -10.0  -8.0
> > 5 Less increase in accounts receivable     - -60.0 -24.0 -18.0
> > 6    Plus increase in accounts payable   8.0  12.0   8.0   6.0
> >
> >
> >
> > So, why can't I automate this?
> >
> > BTW, you should be able to access this spreadsheet.  I made a dummy
> Google
> > account and put this dummy spreadsheet on it.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From plessthanpointohfive at gmail.com  Fri Nov 21 17:02:05 2014
From: plessthanpointohfive at gmail.com (Jennifer Sabatier)
Date: Fri, 21 Nov 2014 11:02:05 -0500
Subject: [R] Saving Google worksheets with common prefix
In-Reply-To: <CAFDcVCQdE4Go7DO7FTbzFabkyWN93RtFyZS+Ta=x=JGzSJONfw@mail.gmail.com>
References: <CAOxgQ=WQLEUqtWDS2FCQDRZEEDhe=n1C+DSjQeoG7-NBCTZ=7Q@mail.gmail.com>
	<CAOxgQ=XHY8o6mvP4X-szD2Xk2SKidvY41hgYahxoFy-aLxQXzQ@mail.gmail.com>
	<CAFDcVCQdE4Go7DO7FTbzFabkyWN93RtFyZS+Ta=x=JGzSJONfw@mail.gmail.com>
Message-ID: <CAOxgQ=VKKtaT4zoH-vkEcphUPreznANZYdcSHzFeyD9KRE=8SQ@mail.gmail.com>

On Fri, Nov 21, 2014 at 10:36 AM, Henrik Bengtsson <hb at biostat.ucsf.edu>
wrote:

> print(ts2$i)



You're right.  It's not doing what I think it's supposed to be doing.  The
print(ts2$i) gives NULL:


[1] "Cash Flows211"
NULL
[1] "Cash Flows211 - 2014-11-21.csv"
7: getURL(sheet at cellsfeed, curl = getCurlCon(con), followlocation = TRUE)
6: getCells(sheet, con = con)
5: xmlParse(getCells(sheet, con = con))
4: xpathApply(doc, path, fun, ..., namespaces = namespaces, sessionEncoding
= sessionEncoding,
       addFinalizer = addFinalizer)
3: getNodeSet(doc, "//a:entry/gs:cell", c(a = "http://www.w3.org/2005/Atom",

       gs = "http://schemas.google.com/spreadsheets/2006"))
2: processCells2(doc, trim, header, as.data.frame, stringsAsFactors =
stringsAsFactors)
1: sheetAsMatrix(ts$i, header = TRUE, as.data.frame = TRUE, trim = TRUE) at
#7
Error in getURL(sheet at cellsfeed, curl = getCurlCon(con), followlocation =
TRUE) :
  trying to get slot "cellsfeed" from an object of a basic class ("NULL")
with no slots

So, I've got to figure out how to feed that list of names properly.

Thanks!

Jen

	[[alternative HTML version deleted]]


From plessthanpointohfive at gmail.com  Fri Nov 21 17:19:48 2014
From: plessthanpointohfive at gmail.com (Jennifer Sabatier)
Date: Fri, 21 Nov 2014 11:19:48 -0500
Subject: [R] Saving Google worksheets with common prefix
In-Reply-To: <CAOxgQ=VKKtaT4zoH-vkEcphUPreznANZYdcSHzFeyD9KRE=8SQ@mail.gmail.com>
References: <CAOxgQ=WQLEUqtWDS2FCQDRZEEDhe=n1C+DSjQeoG7-NBCTZ=7Q@mail.gmail.com>
	<CAOxgQ=XHY8o6mvP4X-szD2Xk2SKidvY41hgYahxoFy-aLxQXzQ@mail.gmail.com>
	<CAFDcVCQdE4Go7DO7FTbzFabkyWN93RtFyZS+Ta=x=JGzSJONfw@mail.gmail.com>
	<CAOxgQ=VKKtaT4zoH-vkEcphUPreznANZYdcSHzFeyD9KRE=8SQ@mail.gmail.com>
Message-ID: <CAOxgQ=WYepmsky-M-rgx5C5fNa5CdtWGD9bOr6yhzBpfeX6zxw@mail.gmail.com>

I got it!


for (i in sheetz$names) {
print(i)
file.name <- paste(i, " - ", Sys.Date(), ".csv", sep="")
print(file.name)
#traceback()
i <- sheetAsMatrix(ts[[i]], header = TRUE, as.data.frame = TRUE, trim =
TRUE)
write.csv(i, file.name)
i
}

I have to use ts[[i]] rather than ts$i (or ts2, either)

Thanks!

Jen

PS - if anyone wants to use that code and that dummy gmail account to play
around with R, that's fine - be my guest.  The email address is hidden but
it's "r dot project dot user at gmail dot com" and the password is in the
code.  Upload your own data and play, if you like.




On Fri, Nov 21, 2014 at 11:02 AM, Jennifer Sabatier <
plessthanpointohfive at gmail.com> wrote:

>
> On Fri, Nov 21, 2014 at 10:36 AM, Henrik Bengtsson <hb at biostat.ucsf.edu>
> wrote:
>
>> print(ts2$i)
>
>
>
> You're right.  It's not doing what I think it's supposed to be doing.  The
> print(ts2$i) gives NULL:
>
>
> [1] "Cash Flows211"
> NULL
> [1] "Cash Flows211 - 2014-11-21.csv"
> 7: getURL(sheet at cellsfeed, curl = getCurlCon(con), followlocation = TRUE)
> 6: getCells(sheet, con = con)
> 5: xmlParse(getCells(sheet, con = con))
> 4: xpathApply(doc, path, fun, ..., namespaces = namespaces,
> sessionEncoding = sessionEncoding,
>        addFinalizer = addFinalizer)
> 3: getNodeSet(doc, "//a:entry/gs:cell", c(a = "http://www.w3.org/2005/Atom",
>
>        gs = "http://schemas.google.com/spreadsheets/2006"))
> 2: processCells2(doc, trim, header, as.data.frame, stringsAsFactors =
> stringsAsFactors)
> 1: sheetAsMatrix(ts$i, header = TRUE, as.data.frame = TRUE, trim = TRUE)
> at #7
> Error in getURL(sheet at cellsfeed, curl = getCurlCon(con), followlocation =
> TRUE) :
>   trying to get slot "cellsfeed" from an object of a basic class ("NULL")
> with no slots
>
> So, I've got to figure out how to feed that list of names properly.
>
> Thanks!
>
> Jen
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Nov 21 17:48:34 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 21 Nov 2014 08:48:34 -0800
Subject: [R] Rose Diagrams for Geology
In-Reply-To: <20141120235753.09ec5816@draco>
References: <CACftpvqhc5YNP7ETgK26H4LqjjpsKo712rQ3TJcXODcgjhvWjQ@mail.gmail.com>
	<BABF13FF-F9ED-4DAF-9E53-A71FB5BE58E3@comcast.net>
	<CACftpvqYVCVLU4bn0oA607SQLw7mVTO1ZW0hxaH0AHx-pKQk3Q@mail.gmail.com>
	<20141120235753.09ec5816@draco>
Message-ID: <CAF8bMca1fTL0c0cQZQ_z2ZVF_Vq+tYqY4YTQEpd757kDSzrzNQ@mail.gmail.com>

> Most field mapping data I have collected has been
> either in quadrant form (rarely) or more commonly in azimuthal form
> (0-360 degrees order clockwise from the top).

You can specify that when making the 'circular' object, by using the
zero and roation arguments.  Compare the plots made by the following:
  par(mfrow=c(1,2))
  A <- circular(rep(seq(0, 180, len=11), c(1:11)), units="degrees",
zero=pi/2, rotation="clock")
  rose.diag(A)
  B <- circular(rep(seq(0, 180, len=11), c(1:11)), units="degrees")
  rose.diag(B)



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 20, 2014 at 11:57 PM, jwd <jwd at surewest.net> wrote:

> On Tue, 18 Nov 2014 22:06:03 -0600
> David Doyle <kydaviddoyle at gmail.com> wrote:
>
> > Thank you to David and David for their help.  The code below
> > generated what I needed.
> >
> >
> > library(circular)
> > mydata <- read.table("http://doylesdartden.com/R/Joints.csv",
> > header=TRUE, sep=",",)
> > x <- circular(mydata$JointsRad)
> > rose.diag(x,
> >
> >           #Set point character to use
> >           pch = 20,
> >           #sets font size
> >           cex = 1,
> >           #parameter that controls the size of the circle.
> >           #1= default <1 makes it larger > makes it smaller
> >           shrink = 1,
> >           #the color for filling the rose diagram.
> >           col=2,
> >           prop = 2,
> >           # number of bins.  36 = 10 degrees each.  18 = 20 degree
> > each bins=36,
> >           # Ticks showing bins
> >           ticks=TRUE,
> >           # Unites.
> >           units="degrees",
> >           # list main title
> >           main="Rose Diagram of XXX")
> > # for more info see
> > http://www.inside-r.org/packages/cran/circular/docs/rose.diag
> >
> I've been following this thread with some interest.  One problem that I
> might have with the code above is that as it is, the plot is labeled
> with 0-deg to the left, and numbered counter clockwise (standard
> trigonometric format). Most field mapping data I have collected has been
> either in quadrant form (rarely) or more commonly in azimuthal form
> (0-360 degrees order clockwise from the top).  Is that an issue?
>
> jwdougherty
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri Nov 21 18:01:08 2014
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 21 Nov 2014 09:01:08 -0800
Subject: [R] ggplot question error: Error in s(x,
 bs = "cs") : object  'x' not found
In-Reply-To: <CAN2xGJZ5uWoQGkA2kCzN4M_GqGiWg=qM9oLAfR6pDzS23iRwpw@mail.gmail.com>
Message-ID: <380D2E606AB.000000C5jrkrideau@inbox.com>

Hi Dimitri,

I am not sure I completely understand the issue but here is what I think you want (using my variable names :) )

library(ggplot2)
dat1  <- data.frame(aa = sample(1:20, 100, replace = TRUE), bb = 1:100 )

p  <-  ggplot(dat1, aes(aa, bb)) + geom_point()
                  
p  <-  p + geom_smooth(se = FALSE) 
p

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dimitri.liakhovitski at gmail.com
> Sent: Thu, 20 Nov 2014 17:14:27 -0500
> To: r-help at r-project.org
> Subject: [R] ggplot question error: Error in s(x, bs = "cs") : object 'x'
> not found
> 
> Dear R-ers,
> 
> apologies for not providing the full code. I just need a point in the
> right direction.
> I have a data frame ('temp') with 1,200 rows and 2 variables.
> I am using ggplot2 to create a scatter plot:
> 
> This is my code and it works fine, it creates a scatter plot:
> 
> library(ggplot2)
> sp10<-ggplot(temp,aes(x=p.used_L1,y=l.to.r.ratio_L1))
> sp10 + geom_point()
> 
> However, when I change the last line to:
> sp10 + geom_point() + stat_smooth(se=FALSE)
> 
> Then I am getting these messages (and no fitted line on the graph):
> 
> geom_smooth: method="auto" and size of largest group is >=1000, so
> using gam with formula: y ~ s(x, bs = "cs"). Use 'method = x' to
> change the smoothing method.
> Error in s(x, bs = "cs") : object 'x' not found
> 
> I don't understand what x in in s(x, bs = "cs") is or should be.
> I lookeed up ?geom_smooth and tried this:
> 
> sp10 + geom_point() + stat_smooth(se=FALSE,formula = l.to.r.ratio_L1 ~
> p.used_L1)
> 
> Still, the same error message.
> 
> Thanks a lot for your advice!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From john.posner at MJBIOSTAT.COM  Fri Nov 21 18:10:16 2014
From: john.posner at MJBIOSTAT.COM (John Posner)
Date: Fri, 21 Nov 2014 17:10:16 +0000
Subject: [R] dplyr/summarize does not create a true data frame
Message-ID: <9E73F88F04AA25408DBB58FB730BA65329AFF1D3@AUSP01DAG0503.collaborationhost.net>

I got an error when trying to extract a 1-column subset of a data frame (called "my.output") created by dplyr/summarize. The ncol() function says that my.output has 4 columns, but "my.output[4]" fails. Note that converting my.output using as.data.frame() makes for a happy ending.

Is this the intended behavior of dplyr?

Tx,
John

> library(dplyr)

> # set up data frame
> rows = 100
> repcnt = 50
> sexes = c("Female", "Male")
> heights = c("Med", "Short", "Tall")

> frm = data.frame(
+   Id = paste("P", sprintf("%04d", 1:rows), sep=""),
+   Sex = sample(rep(sexes, repcnt), rows, replace=T),
+   Height = sample(rep(heights, repcnt), rows, replace=T),
+   V1 = round(runif(rows)*25, 2) + 50,
+   V2 = round(runif(rows)*1000, 2) + 50,
+   V3 = round(runif(rows)*350, 2) - 175
+ )
> 
> # use dplyr/summarize to create data frame
> my.output = frm %>%
+   group_by(Sex, Height) %>%
+   summarize(V1sum=sum(V1), V2sum=sum(V2))

> # work with columns in the output data frame
> ncol(my.output)
[1] 4

> my.output[1]
Source: local data frame [6 x 1]
Groups: Sex

     Sex
1 Female
2 Female
3 Female
4   Male
5   Male
6   Male

> my.output[4]
Error in eval(expr, envir, enclos) : index out of bounds  ######## ERROR HERE

> as.data.frame(my.output)[4]
     V2sum
1 12427.97
2  8449.82
3  8610.97
4  7249.20
5 12616.91
6 10372.15
>


From petretta at unina.it  Fri Nov 21 18:18:53 2014
From: petretta at unina.it (Mario Petretta)
Date: Fri, 21 Nov 2014 18:18:53 +0100
Subject: [R] R:  Comparing summary hazard ratios in meta-analysis
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730EFA099A36@UM-MAIL4112.unimaas.nl>
References: <001901cff51f$ace1e370$06a5aa50$@unina.it>	<006d01d00568$62a56ad0$27f04070$@it>
	<546F2F10.201@aghmed.fsnet.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730EFA099A36@UM-MAIL4112.unimaas.nl>
Message-ID: <00d401d005af$3994e7a0$acbeb6e0$@it>

Many many thanks to Michael Dewey and to Viechtbauer Wolfgang for the kindly and useful replay !!

I only ask to Wolfgang if I should log-transform hazard ratios and compute standard error only for the summary hazard ratio estimates or, as suggested by Michael, for each single study, combining them in a single data frame and thereafter performing the meta-regression incorporating the moderator.

Mario

-----Messaggio originale-----
Da: Viechtbauer Wolfgang (STAT) [mailto:wolfgang.viechtbauer at maastrichtuniversity.nl] 
Inviato: venerd? 21 novembre 2014 15:37
A: Michael Dewey; Mario Petretta; r-help at r-project.org
Oggetto: RE: [R] Comparing summary hazard ratios in meta-analysis

Those hazard ratios and CIs seem a bit strange. On the log-scale, they should be symmetric, but they are not. Could be due to heavy rounding though. At any rate, it comes down to this:

hr    <- c(3.12, 1.15)
ci.lb <- c(2.2, 1.03)
ci.ub <- c(4.1, 2.6)
meta  <- c(1,2)

### log-transform hazard ratios and compute standard error based on the CI bounds yi  <- log(hr) sei <- (log(ci.ub) - log(ci.lb)) / (2*1.96)

library(metafor)
res <- rma(yi ~ factor(meta), sei=sei, method="FE") res

So, yes, the two hazard ratios are significantly different from each other.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org]
> On Behalf Of Michael Dewey
> Sent: Friday, November 21, 2014 13:25
> To: Mario Petretta; r-help at r-project.org
> Subject: Re: [R] Comparing summary hazard ratios in meta-analysis
> 
> On 21/11/2014 08:51, Mario Petretta wrote:
> > Dear all,
> >
> > I use R 3.1.1 for Windows.
> >
> > I performed two different meta-analysis assessing the prognostic 
> > value
> of
> > two different tests in patients with coronary artery disease. The 
> > study included in the two analysis are different.
> 
> That makes life simpler.
> 
> >
> > The variable of interest in dichotomous (normal/abnormal result) for
> both
> > tests.
> >
> > The effects size is hazard ratio and its standard error (ln units) 
> > for
> both
> > meta-analysis.
> 
> It sounds as though you might want to use meta-regression. You will 
> need a single data frame containing at least log hr, se of log hr, an 
> identifier for the test. I would use the metafor package for this, 
> look in the documentation for how to incorporate a moderator (your 
> test variable). The advantage of meta-regression is that you not only 
> get a test but also a measure of how different the hr are with a 
> confidence interval.
> 
> > I would like to statistically compare the two summary hazard ratios 
> > and
> 95%
> > CI (eform) obtained from the two meta-analysis.
> >
> > For one meta-analysis: HR 3.12 (95% CI 2.2 - 4.1) For the other: HR 
> > 1.25 (95% CI 1.03 - 2.6)
> >
> > It is possible or I'm comparing apples with oranges?
> >
> > Any suggestion is welcome.
> >
> > -------------------------------------------------------
> > Mario Petretta
> > Associate Professor of Internal Medicine Department of Translational 
> > Medical Sciences Naples University Federico II Italy


---
Questa e-mail ? stata controllata per individuare virus con Avast antivirus.


From jrkrideau at inbox.com  Fri Nov 21 18:32:48 2014
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 21 Nov 2014 09:32:48 -0800
Subject: [R] dplyr/summarize does not create a true data frame
In-Reply-To: <9E73F88F04AA25408DBB58FB730BA65329AFF1D3@AUSP01DAG0503.collaborationhost.net>
Message-ID: <3853F648623.00000147jrkrideau@inbox.com>

Your code in creating 'frm' is not working for me and it is complicated enough that I don't want to work it out. See ?dput for a better way to supply data. Also see:
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

That said, I don't see why 'my.output[4]' is not working.  Try something like str(frm) to see what you have there and/or resubmit the data in dput format

See simple example below:

dat1  <- data.frame(aa = sample(1:20, 100, replace = TRUE), bb = 1:100 )
dat1[2]

John Kane
Kingston ON Canada


> -----Original Message-----
> From: john.posner at mjbiostat.com
> Sent: Fri, 21 Nov 2014 17:10:16 +0000
> To: r-help at r-project.org
> Subject: [R] dplyr/summarize does not create a true data frame
> 
> I got an error when trying to extract a 1-column subset of a data frame
> (called "my.output") created by dplyr/summarize. The ncol() function says
> that my.output has 4 columns, but "my.output[4]" fails. Note that
> converting my.output using as.data.frame() makes for a happy ending.
> 
> Is this the intended behavior of dplyr?
> 
> Tx,
> John
> 
>> library(dplyr)
> 
>> # set up data frame
>> rows = 100
>> repcnt = 50
>> sexes = c("Female", "Male")
>> heights = c("Med", "Short", "Tall")
> 
>> frm = data.frame(
> +   Id = paste("P", sprintf("%04d", 1:rows), sep=""),
> +   Sex = sample(rep(sexes, repcnt), rows, replace=T),
> +   Height = sample(rep(heights, repcnt), rows, replace=T),
> +   V1 = round(runif(rows)*25, 2) + 50,
> +   V2 = round(runif(rows)*1000, 2) + 50,
> +   V3 = round(runif(rows)*350, 2) - 175
> + )
>> 
>> # use dplyr/summarize to create data frame
>> my.output = frm %>%
> +   group_by(Sex, Height) %>%
> +   summarize(V1sum=sum(V1), V2sum=sum(V2))
> 
>> # work with columns in the output data frame
>> ncol(my.output)
> [1] 4
> 
>> my.output[1]
> Source: local data frame [6 x 1]
> Groups: Sex
> 
>      Sex
> 1 Female
> 2 Female
> 3 Female
> 4   Male
> 5   Male
> 6   Male
> 
>> my.output[4]
> Error in eval(expr, envir, enclos) : index out of bounds  ######## ERROR
> HERE
> 
>> as.data.frame(my.output)[4]
>      V2sum
> 1 12427.97
> 2  8449.82
> 3  8610.97
> 4  7249.20
> 5 12616.91
> 6 10372.15
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From dwinsemius at comcast.net  Fri Nov 21 19:18:30 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 21 Nov 2014 10:18:30 -0800
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <CAOrU2ZJvz0K7sE8eRXv3xxWkWFZuwBdKZeidA7w2wQ4EYNCvLw@mail.gmail.com>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
	<B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
	<79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>
	<8780E3CE-13F9-43B3-A6D3-5034BBE6304C@comcast.net>
	<12A4CACA-73C3-42A8-BC54-053A891B7B7C@gmail.com>
	<72B60A76-2390-43AC-95C7-E0B7B3609ADF@comcast.net>
	<CAOrU2ZJvz0K7sE8eRXv3xxWkWFZuwBdKZeidA7w2wQ4EYNCvLw@mail.gmail.com>
Message-ID: <C28C47E6-BDDC-46E2-AFB2-9C858581F5E2@comcast.net>


On Nov 21, 2014, at 6:52 AM, ivan wrote:

> I am aware of the fact that bootstrapping produces different CIs with every run. I still believe that there is a difference between both types of procedures. My understanding is that setting "w" in the boot() function influences the "importance" of observations or how the bootstrap selects the observations. I.e, observation i does not have the same probability of being chosen as observation j when "w" is defined in the boot() function. If you return res_boot you will notice that with "w" being set in the boot() function, the function call states "weighted bootstrap". If not, it states "ordinary nonparametric bootstrap". But maybe I am wrong. 

OK. So in the the second call w affects the probability of a case being sent to the boot-function as well as being used in the boot-function; while with the "non-weighted call" the w's are only affecting the individual mean estimates. So the second one is different. And as I suggested earlier you never described the goals of the investigation or the meaning of the variables. 

   I can tell you that when Davison and Hinkley offered examples of using a bootstrap for a weighted bootstrap mean, they compared a stratified analysis with an example where the weighting was only used on the inner function (example 3.2, practical 3.14 pp 72, 131 of their book) with one where the strata parameter was used. But so far I don't think you have ever described what sort of weights these actually are. In that example the weights were the inverse variances of the sample groups. They didn't use a 'weights' parameter in the boot call. I'm do not know if it was part of the S package that was being used at the time.

I tried to find an example of a weighted bootstrap in V&R 4e but did not see one. Prof Ripley is the maintainer of the boot package. In the V&R book, Angelo Canty is given the credit for writing the boot package for S. I think you should consult the code, first. And you should also look at the `stype` parameter where "w" is one option.

-- 
David.

> 
> On Thu, Nov 20, 2014 at 8:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Nov 20, 2014, at 2:23 AM, i.petzev wrote:
> 
> > Hi David,
> >
> > sorry, I was not clear.
> 
> Right. You never were clear about what you wanted and your examples was so statistically symmetric that it is still hard to see what is needed. The examples below show CI's that are arguably equivalent. I can be faulted for attempting to provide code that produced a sensible answer to a vague question to which I was only guessing at the intent.
> 
> 
> > The difference comes from defining or not defining ?w? in the boot() function. The results with your function and your approach are thus:
> >
> > set.seed(1111)
> > x <- rnorm(50)
> > y <- rnorm(50)
> > weights <- runif(50)
> > weights <- weights / sum(weights)
> > dataset <- cbind(x,y,weights)
> >
> > vw_m_diff <- function(dataset,w) {
> >   differences <- dataset[w,1]-dataset[w,2]
> >   weights <- dataset[w, "weights"]
> >   return(weighted.mean(x=differences, w=weights))
> > }
> > res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
> > boot.ci(res_boot)
> >
> > BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> > Based on 1000 bootstrap replicates
> >
> > CALL :
> > boot.ci(boot.out = res_boot)
> >
> > Intervals :
> > Level      Normal              Basic
> > 95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )
> >
> > Level     Percentile            BCa
> > 95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )
> > Calculations and Intervals on Original Scale
> >
> > ********************************************************************************************************************
> >
> > However, without defining ?w? in the bootstrap function, i.e., running an ordinary and not a weighted bootstrap, the results are:
> >
> > res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000)
> > boot.ci(res_boot)
> >
> > BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> > Based on 1000 bootstrap replicates
> >
> > CALL :
> > boot.ci(boot.out = res_boot)
> >
> > Intervals :
> > Level      Normal              Basic
> > 95%   (-0.6265,  0.4966 )   (-0.6125,  0.5249 )
> 
> I hope you are not saying that because those CI's are different that there is some meaning in that difference. Bootstrap runs will always be "different" than each other unless you use set.seed(.) before the runs.
> 
> >
> > Level     Percentile            BCa
> > 95%   (-0.6714,  0.4661 )   (-0.6747,  0.4559 )
> > Calculations and Intervals on Original Scale
> >
> > On 19 Nov 2014, at 17:49, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> >>>> vw_m_diff <- function(dataset,w) {
> >>>>     differences <- dataset[w,1]-dataset[w,2]
> >>>>    weights <- dataset[w, "weights"]
> >>>>    return(weighted.mean(x=differences, w=weights))
> >>>>  }
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From aps6dl at yahoo.com  Fri Nov 21 19:19:01 2014
From: aps6dl at yahoo.com (Aditya Singh)
Date: Fri, 21 Nov 2014 18:19:01 +0000 (UTC)
Subject: [R] Wondering why I get a NULL output for this if condition!
In-Reply-To: <00d401d005af$3994e7a0$acbeb6e0$@it>
References: <00d401d005af$3994e7a0$acbeb6e0$@it>
Message-ID: <128804764.3725637.1416593941839.JavaMail.yahoo@jws10684.mail.bf1.yahoo.com>

1 my_min= min(outcome_data[which(outcome_data$State==my_state),11],na.rm=TRUE) 
2 print(my_min) 
3 jkr=0 
4 if (jkr<= 4706) {jkr=jkr+1 
5 if (identical(outcome_data[jkr,11],my_min) && identical(outcome_data[jkr,7],my_state)) { 
6 print((outcome_data[jkr,2])) 
7 break 
8 } 


Dear Experts,

My computer is never 'inside' of  the if condition at line 5, as jkr=0 always. my_min is a numeric. my_state is a 2 letter American State (character).

This code gives NULL as output. Wondering!

Its either very obvious or I am very dumb.

Please do do reply!

Aditya


From boris.steipe at utoronto.ca  Fri Nov 21 20:06:43 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 21 Nov 2014 14:06:43 -0500
Subject: [R] Wondering why I get a NULL output for this if condition!
In-Reply-To: <128804764.3725637.1416593941839.JavaMail.yahoo@jws10684.mail.bf1.yahoo.com>
References: <00d401d005af$3994e7a0$acbeb6e0$@it>
	<128804764.3725637.1416593941839.JavaMail.yahoo@jws10684.mail.bf1.yahoo.com>
Message-ID: <CD5F4FD8-AA16-4673-8748-9495FB5308FF@utoronto.ca>

Seems to me you probably wanted a "while" in line 4.

N.b.  There's also a missing "}" and totally messed up formatting :-(

B.

 
On Nov 21, 2014, at 1:19 PM, Aditya Singh <aps6dl at yahoo.com> wrote:

> 1 my_min= min(outcome_data[which(outcome_data$State==my_state),11],na.rm=TRUE) 
> 2 print(my_min) 
> 3 jkr=0 
> 4 if (jkr<= 4706) {jkr=jkr+1 
> 5 if (identical(outcome_data[jkr,11],my_min) && identical(outcome_data[jkr,7],my_state)) { 
> 6 print((outcome_data[jkr,2])) 
> 7 break 
> 8 } 
> 
> 
> Dear Experts,
> 
> My computer is never 'inside' of  the if condition at line 5, as jkr=0 always. my_min is a numeric. my_state is a 2 letter American State (character).
> 
> This code gives NULL as output. Wondering!
> 
> Its either very obvious or I am very dumb.
> 
> Please do do reply!
> 
> Aditya
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From optionsraghu at gmail.com  Fri Nov 21 23:52:57 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Fri, 21 Nov 2014 22:52:57 +0000
Subject: [R] Help with Time
Message-ID: <CADgEnD=MnvGDoAM4d3ca+JuqbLg+3VRJBrf7d53eLyMtpr1W1Q@mail.gmail.com>

Dear guRus

How can I round of time in R to the nearest 30th minute please?

For example suppose if
>Sys.time()
[1] "2014-11-21 22:49:05.59042 GMT"
then I would like a function that outputs 22:30:00.

if Sys.time is 12:13:22 then I would like to get 12:00:00 etc.

Any help would be appreciated.

Many thanks and regards,
Raghu


From pdalgd at gmail.com  Fri Nov 21 10:39:39 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 21 Nov 2014 10:39:39 +0100
Subject: [R] R website
In-Reply-To: <546E64DD.8090708@gmail.com>
References: <546E3C8A.7030000@uottawa.ca> <546E42C0.1050802@gmail.com>
	<CA+vqiLGTwojH=aNvyCW25WePke3fbhxzfy2xyr=0aeMWUYabog@mail.gmail.com>
	<546E64DD.8090708@gmail.com>
Message-ID: <C919FBE2-0EA1-4618-B329-A6C0902DAEBF@gmail.com>


On 20 Nov 2014, at 23:02 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 20/11/2014, 4:35 PM, Ista Zahn wrote:
>> This prompted me to do something I've been meaning to do for a long
>> time, which is to try to get the R website updated in terms of visual
>> style. It really is showing it's age and could use a facelift in my
>> opinion. Toward than end I've mocked up a copy of cran.r-project.or
>> using css from the python.org website. You can see the result at
>> http://izahn.crabdance.com/~izahn/cran-new-css . This is a rough draft
>> and needs to be cleaned up, but I though I would float this here first
>> to see if there is any hope of getting such a change to be adopted
>> before I spent more time on it. Feedback and comments welcome.
> 
> You're sending that to the wrong place.  The R website is
> www.r-project.org; cran.r-project.org is the CRAN website.  You'll need
> to discuss that one with CRAN.
> 

Hmm. The two websites are pretty similar in terms of their infrastructure, so I don't see much point in taking it up with CRAN specifically. The CRAN architects have a lot of other stuff on their minds so probably prefer not to take ownership of a website redesign. 

R-help is probably the wrong place, but I don't see a problem with discussing such matters over at r-devel. (I had a look at the facelift, and it sort of looks OK, but it is purely a style-sheet makeover, and it doesn't address the structural issues -- the use of frames, etc.)  

-pd

> Duncan Murdoch
>> 
>> Best,
>> Ista
>> 
>> On Thu, Nov 20, 2014 at 2:36 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 20/11/2014 2:10 PM, Prof J C Nash (U30A) wrote:
>>>> 
>>>> I was looking at the R website (r-project.org).
>>>> 
>>>> 1) The Books page does not list several books about R, including one of
>>>> my own (Nonlinear parameter optimization tools in R) nor that of Karline
>>>> Soetaert on differential equations. How is the list updated?
>>>> 
>>>> 2) The wiki seems to be dead. Is anyone in charge of it? If not, please
>>>> contact me off-line. I am willing to help out (I run several Dokuwiki
>>>> wikis).
>>> 
>>> 
>>> Files on www.r-project.org can be edited by any member of R core. You just
>>> need to convince one of us to enter it, send us the data, and the book will
>>> eventually show up.  (To do that, take a look at the Bibtex .bib file,
>>> available at http://www.r-project.org/doc/bib/R.bib, and put together
>>> additions in a consistent format.  If it is not obvious why your book should
>>> be included, explain why.)
>>> 
>>> Duncan Murdoch
>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pmassicotte at hotmail.com  Fri Nov 21 14:23:11 2014
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Fri, 21 Nov 2014 13:23:11 +0000
Subject: [R] Formula with dynamic number of variables
Message-ID: <COL127-W499AEC335D0E546714810AB3770@phx.gbl>

Hi everyone.

I have a non-linear model specified as this (6 variables, a0, S, K, p0, p1, p2):

fit <- nlsLM(formula = dat ~ a0 * exp(-S*(x - 250)) + K + ( C ) )

where C = (p0*exp(-0.5*((x-p1)/p2)^2))

The problem is that I do not know in advance how many component (C) I will have in the model. That means It could be:

nlsLM(formula = dat ~ a0 * exp(-S*(x - 250)) + K + ( (p0*exp(-0.5*((x-p1)/p2)^2)) ) )

or 

nlsLM(formula = dat ~ a0 * exp(-S*(x - 250)) + K + ( (p0*exp(-0.5*((x-p1)/p2)^2)) ) +   ( (p0b*exp(-0.5*((x-p1b)/p2b)^2)) ))

or


nlsLM(formula = dat ~ a0 * exp(-S*(x - 250)) + K + ( (p0*exp(-0.5*((x-p1)/p2)^2)) ) +   ( (p0b*exp(-0.5*((x-p1b)/p2b)^2)) +   ( (p0c*exp(-0.5*((x-p1c)/p2c)^2))))

So I was wondering if it was possible to dynamically build the formula that I will use in my model? The first part of my model will always be "a0 * exp(-S*(x - 250)) + K", I just want to add a certain number of "components" dynamically.

I guess it will be related with "reformulate()" but I can't not find how to make it works.

Thank you for your help,
Philippe

 		 	   		  
	[[alternative HTML version deleted]]


From alagador at uevora.pt  Fri Nov 21 21:02:53 2014
From: alagador at uevora.pt (=?iso-8859-1?Q?Diogo_Andr=E9_Alagador?=)
Date: Fri, 21 Nov 2014 20:02:53 -0000
Subject: [R] C project within R function
Message-ID: <000001d005c6$2318b670$694a2350$@pt>

Hi all,

 

I need some assistance regarding the use of C project (set of programming
files)  as R functions in Windows OS.

By now I really would like to avoid package-building.

What are the steps to undergo or where can I check to perform that
successfully?

 

Thanks in advance,

My best regards,

Diogo Alagador

 <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador

CIBIO/UE - Research Center in Biodiversity and Genetic Resources, University
of ?vora, Portugal

 


	[[alternative HTML version deleted]]


From optionsraghu at gmail.com  Fri Nov 21 23:55:23 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Fri, 21 Nov 2014 22:55:23 +0000
Subject: [R] Help with Time
In-Reply-To: <CADgEnD=MnvGDoAM4d3ca+JuqbLg+3VRJBrf7d53eLyMtpr1W1Q@mail.gmail.com>
References: <CADgEnD=MnvGDoAM4d3ca+JuqbLg+3VRJBrf7d53eLyMtpr1W1Q@mail.gmail.com>
Message-ID: <CADgEnDnHpbxiQXPiOHefS3zBY8yanSC-dyD585uE60GQks_aFw@mail.gmail.com>

Sorry I forgot to mention it clearly. I like to round it to the
nearest 30th minute that is past. So 12:28:59 will be again 12:00:00
and
12:59:59 will be 12:30:00 etc. Apologies for the lack of clarity in
the beginning.

Many thanks
Raghu

On Fri, Nov 21, 2014 at 10:52 PM, Raghuraman Ramachandran
<optionsraghu at gmail.com> wrote:
> Dear guRus
>
> How can I round of time in R to the nearest 30th minute please?
>
> For example suppose if
>>Sys.time()
> [1] "2014-11-21 22:49:05.59042 GMT"
> then I would like a function that outputs 22:30:00.
>
> if Sys.time is 12:13:22 then I would like to get 12:00:00 etc.
>
> Any help would be appreciated.
>
> Many thanks and regards,
> Raghu


From dwinsemius at comcast.net  Sat Nov 22 00:09:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 21 Nov 2014 15:09:13 -0800
Subject: [R] Help with Time
In-Reply-To: <CADgEnD=MnvGDoAM4d3ca+JuqbLg+3VRJBrf7d53eLyMtpr1W1Q@mail.gmail.com>
References: <CADgEnD=MnvGDoAM4d3ca+JuqbLg+3VRJBrf7d53eLyMtpr1W1Q@mail.gmail.com>
Message-ID: <FA028472-A997-4769-BC55-3884EEAE4025@comcast.net>


On Nov 21, 2014, at 2:52 PM, Raghuraman Ramachandran wrote:

> Dear guRus
> 
> How can I round of time in R to the nearest 30th minute please?
> 
> For example suppose if
>> Sys.time()
> [1] "2014-11-21 22:49:05.59042 GMT"
> then I would like a function that outputs 22:30:00.
> 
> if Sys.time is 12:13:22 then I would like to get 12:00:00 etc.

There already are round and trunc functions for POSIXt objects so why not take a look a that code and hack it into a shape that you find useful.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Nov 22 00:19:57 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 21 Nov 2014 15:19:57 -0800
Subject: [R] Help with Time
In-Reply-To: <CADgEnDnHpbxiQXPiOHefS3zBY8yanSC-dyD585uE60GQks_aFw@mail.gmail.com>
References: <CADgEnD=MnvGDoAM4d3ca+JuqbLg+3VRJBrf7d53eLyMtpr1W1Q@mail.gmail.com>
	<CADgEnDnHpbxiQXPiOHefS3zBY8yanSC-dyD585uE60GQks_aFw@mail.gmail.com>
Message-ID: <42D19E3A-E6E5-4278-84F2-84AC070BCC8E@comcast.net>


On Nov 21, 2014, at 2:55 PM, Raghuraman Ramachandran wrote:

> Sorry I forgot to mention it clearly. I like to round it to the
> nearest 30th minute that is past. So 12:28:59 will be again 12:00:00
> and
> 12:59:59 will be 12:30:00 etc. Apologies for the lack of clarity in
> the beginning.
> 

That's just truncation. Should be very easy to hack trunc.POSIXt to deliver that result. Add a "half_hr" unit to the list and then a simple extra clause that check for minutes >30.

> base::trunc.POSIXt
function (x, units = c("secs", "mins", "hours", "days"), ...) 
{
    units <- match.arg(units)
    x <- as.POSIXlt(x)
    if (length(x$sec)) 
        switch(units, secs = {
            x$sec <- trunc(x$sec)
        }, mins = {
            x$sec[] <- 0
        }, hours = {
            x$sec[] <- 0
            x$min[] <- 0L
        }, days = {
            x$sec[] <- 0
            x$min[] <- 0L
            x$hour[] <- 0L
            x$isdst[] <- -1L
        })
    x
}
<bytecode: 0x10a54b038>
<environment: namespace:base>
-- 
David.


> Many thanks
> Raghu
> 
> On Fri, Nov 21, 2014 at 10:52 PM, Raghuraman Ramachandran
> <optionsraghu at gmail.com> wrote:
>> Dear guRus
>> 
>> How can I round of time in R to the nearest 30th minute please?
>> 
>> For example suppose if
>>> Sys.time()
>> [1] "2014-11-21 22:49:05.59042 GMT"
>> then I would like a function that outputs 22:30:00.
>> 
>> if Sys.time is 12:13:22 then I would like to get 12:00:00 etc.
>> 
>> Any help would be appreciated.
>> 
>> Many thanks and regards,
>> Raghu
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ahz001 at gmail.com  Sat Nov 22 00:26:35 2014
From: ahz001 at gmail.com (Andrew Z)
Date: Fri, 21 Nov 2014 16:26:35 -0700
Subject: [R] memory usage with party::cforest
Message-ID: <CAL0tEj_uz+J3wc9fMWXXgF7+_nTDjFWaAikH0UFDfpJbWjv8LQ@mail.gmail.com>

Is there a way to shrink the size of RandomForest-class (an S4
object), so that it requires less memory during run-time and less disk
space for serialization?

On my system the data slot is about 2GB, which is causing problems,
and I'd like to see whether predict() works without it.

# example with a much smaller data set (i.e., less than 2GB)
require(party)
data(iris)
cf <- cforest(Species ~ ., data=iris)
str(cf, max.level=2)
cf at data <- NULL # this fails



Andrew


From boris.steipe at utoronto.ca  Sat Nov 22 00:36:38 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 21 Nov 2014 18:36:38 -0500
Subject: [R] Help with Time
In-Reply-To: <CADgEnDnHpbxiQXPiOHefS3zBY8yanSC-dyD585uE60GQks_aFw@mail.gmail.com>
References: <CADgEnD=MnvGDoAM4d3ca+JuqbLg+3VRJBrf7d53eLyMtpr1W1Q@mail.gmail.com>
	<CADgEnDnHpbxiQXPiOHefS3zBY8yanSC-dyD585uE60GQks_aFw@mail.gmail.com>
Message-ID: <2197C965-53DC-4EB3-BBD2-A720F6708BC8@utoronto.ca>

Perhaps this ...

roundToHalf <- function(t) { 
	t <- as.POSIXlt(t)
	if (t$min < 15) {
		t$min <- 0
	} 
	else if (t$min < 45) {
		t$min <- 30		
	}
	else {
		t$min <- 0
		t$hour <- t$hour + 1
	}
	return(t)
}

# check
for (i in 1:20) {
	a <- Sys.time() + (i*490)  # semi arbitrary intervals
	b <- roundToHalf(a)
	print(paste(a, "  ", b))
}


B.


On Nov 21, 2014, at 5:55 PM, Raghuraman Ramachandran <optionsraghu at gmail.com> wrote:

> Sorry I forgot to mention it clearly. I like to round it to the
> nearest 30th minute that is past. So 12:28:59 will be again 12:00:00
> and
> 12:59:59 will be 12:30:00 etc. Apologies for the lack of clarity in
> the beginning.
> 
> Many thanks
> Raghu
> 
> On Fri, Nov 21, 2014 at 10:52 PM, Raghuraman Ramachandran
> <optionsraghu at gmail.com> wrote:
>> Dear guRus
>> 
>> How can I round of time in R to the nearest 30th minute please?
>> 
>> For example suppose if
>>> Sys.time()
>> [1] "2014-11-21 22:49:05.59042 GMT"
>> then I would like a function that outputs 22:30:00.
>> 
>> if Sys.time is 12:13:22 then I would like to get 12:00:00 etc.
>> 
>> Any help would be appreciated.
>> 
>> Many thanks and regards,
>> Raghu
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Nov 22 01:52:47 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 21 Nov 2014 19:52:47 -0500
Subject: [R] C project within R function
In-Reply-To: <000001d005c6$2318b670$694a2350$@pt>
References: <000001d005c6$2318b670$694a2350$@pt>
Message-ID: <546FDE5F.8030407@gmail.com>

On 21/11/2014, 3:02 PM, Diogo Andr? Alagador wrote:
> Hi all,
> 
>  
> 
> I need some assistance regarding the use of C project (set of programming
> files)  as R functions in Windows OS.
> 
> By now I really would like to avoid package-building.
> 
> What are the steps to undergo or where can I check to perform that
> successfully?
> 

Sorry, but your constraint (no package building) is irrational.  By
*far* the easiest way to do this is to write a package.

Duncan Murdoch

>  
> 
> Thanks in advance,
> 
> My best regards,
> 
> Diogo Alagador
> 
>  <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
> http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador
> 
> CIBIO/UE - Research Center in Biodiversity and Genetic Resources, University
> of ?vora, Portugal
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sat Nov 22 01:59:53 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 21 Nov 2014 16:59:53 -0800
Subject: [R] Help with Time
In-Reply-To: <42D19E3A-E6E5-4278-84F2-84AC070BCC8E@comcast.net>
References: <CADgEnD=MnvGDoAM4d3ca+JuqbLg+3VRJBrf7d53eLyMtpr1W1Q@mail.gmail.com>
	<CADgEnDnHpbxiQXPiOHefS3zBY8yanSC-dyD585uE60GQks_aFw@mail.gmail.com>
	<42D19E3A-E6E5-4278-84F2-84AC070BCC8E@comcast.net>
Message-ID: <F36B74FC-511A-4E27-97C5-F1E308844749@comcast.net>


On Nov 21, 2014, at 3:19 PM, David Winsemius wrote:

> 
> On Nov 21, 2014, at 2:55 PM, Raghuraman Ramachandran wrote:
> 
>> Sorry I forgot to mention it clearly. I like to round it to the
>> nearest 30th minute that is past. So 12:28:59 will be again 12:00:00
>> and
>> 12:59:59 will be 12:30:00 etc. Apologies for the lack of clarity in
>> the beginning.
>> 
> 
> That's just truncation. Should be very easy to hack trunc.POSIXt to deliver that result. Add a "half_hr" unit to the list and then a simple extra clause that check for minutes >30.

In my first effort I used an if(){}else{} construction, committing the newbie mistake of forgetting it was not the vectoRized way. So this performs better:

trunc.POSIXt <- 
function (x, units = c("secs", "mins", "half_hrs", "hours", "days"), ...) 
{
    units <- match.arg(units)
    x <- as.POSIXlt(x)
    if (length(x$sec)) 
        switch(units, secs = {
            x$sec <- trunc(x$sec)
        }, mins = {
            x$sec[] <- 0
        }, half_hrs = { 
            x$sec[] <- 0
            x$min[] <- 0L+ 30L*(x$min >=30)
        }, hours = {
            x$sec[] <- 0
            x$min[] <- 0L
        }, days = {
            x$sec[] <- 0
            x$min[] <- 0L
            x$hour[] <- 0L
            x$isdst[] <- -1L
        })
    x
}

> time <- seq(Sys.time(), Sys.time()+60*120, by= 60*5)
> trunc(time, "half_hrs")
 [1] "2014-11-21 15:30:00 PST" "2014-11-21 15:30:00 PST"
 [3] "2014-11-21 15:30:00 PST" "2014-11-21 15:30:00 PST"
 [5] "2014-11-21 15:30:00 PST" "2014-11-21 15:30:00 PST"
 [7] "2014-11-21 16:00:00 PST" "2014-11-21 16:00:00 PST"
 [9] "2014-11-21 16:00:00 PST" "2014-11-21 16:00:00 PST"
[11] "2014-11-21 16:00:00 PST" "2014-11-21 16:00:00 PST"
[13] "2014-11-21 16:30:00 PST" "2014-11-21 16:30:00 PST"
[15] "2014-11-21 16:30:00 PST" "2014-11-21 16:30:00 PST"
[17] "2014-11-21 16:30:00 PST" "2014-11-21 16:30:00 PST"
[19] "2014-11-21 17:00:00 PST" "2014-11-21 17:00:00 PST"
[21] "2014-11-21 17:00:00 PST" "2014-11-21 17:00:00 PST"
[23] "2014-11-21 17:00:00 PST" "2014-11-21 17:00:00 PST"
[25] "2014-11-21 17:30:00 PST"


> -- 
> David.
> 
> 
>> Many thanks
>> Raghu
>> 
>> On Fri, Nov 21, 2014 at 10:52 PM, Raghuraman Ramachandran
>> <optionsraghu at gmail.com> wrote:
>>> Dear guRus
>>> 
>>> How can I round of time in R to the nearest 30th minute please?
>>> 
>>> For example suppose if
>>>> Sys.time()
>>> [1] "2014-11-21 22:49:05.59042 GMT"
>>> then I would like a function that outputs 22:30:00.
>>> 
>>> if Sys.time is 12:13:22 then I would like to get 12:00:00 etc.
>>> 
>>> Any help would be appreciated.
>>> 
>>> Many thanks and regards,
>>> Raghu
>> 
>> __________________________________

> 

David Winsemius
Alameda, CA, USA


From yqzhang at ucsd.edu  Sat Nov 22 05:56:17 2014
From: yqzhang at ucsd.edu (Yunqi Zhang)
Date: Fri, 21 Nov 2014 23:56:17 -0500
Subject: [R] Interpreting ANOVA / quantile regression results
Message-ID: <CA+56VKJy380Mv3_bGtH3ZR7-ikAsMHkN7cpzRMim+=_uoK=YZA@mail.gmail.com>

Hi all,

I think this is probably a very simple question related to ANOVA or
quantile regression.

Let's say if I'm doing ANOVA on 2 factors (f_a and f_b) and trying to
figure out whether they have an impact on the output. The result shows me
that f_a has a significant impact while f_b does not as following, where
the std. error (confidence interval) is

         estimate    std. error      p-value
f_a    10              0.2               0.001
f_b    0.5             2                  0.56

If I take this result, and I want to make my best guess for the output of a
pair of f_a and f_b values. Should I calculate the output using both f_a
and f_b or only the f_a because f_b is statistically insignificant? And
what the std. error (confidence interval) would be?

Specifically, should I do

guessed output = 10 * f_a + 0.5 * f_b and the std. error is 0.2 + 2 = 2.2

or

guessed output = 10 * f_a and the std.err is 0.2

Thank you very much!

Yunqi

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Sat Nov 22 06:37:38 2014
From: msharp at txbiomed.org (Mark Sharp)
Date: Fri, 21 Nov 2014 23:37:38 -0600
Subject: [R] C project within R function
In-Reply-To: <546FDE5F.8030407@gmail.com>
References: <000001d005c6$2318b670$694a2350$@pt> <546FDE5F.8030407@gmail.com>
Message-ID: <9207F84B-DCBE-4D6E-9BAA-500C4FF12ACF@txbiomed.org>

Diogo,

For a gentle introduction to package creation see Hadley Wickham's book in progress on the subject at http://r-pkgs.had.co.nz. This site is particularly accessible if you use RStudio, but is not dependent on its use.

I use very simple packages that are not designed to be used by others to organize my work because it is the easiest way to structure projects that use many functions. As Duncan has stated, it is the only reasonable way to use C, FORTRAN, or C++ subroutines and functions.

Mark
> On Nov 21, 2014, at 6:52 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 21/11/2014, 3:02 PM, Diogo Andr? Alagador wrote:
>> Hi all,
>>
>>
>>
>> I need some assistance regarding the use of C project (set of programming
>> files)  as R functions in Windows OS.
>>
>> By now I really would like to avoid package-building.
>>
>> What are the steps to undergo or where can I check to perform that
>> successfully?
>>
>
> Sorry, but your constraint (no package building) is irrational.  By
> *far* the easiest way to do this is to write a package.
>
> Duncan Murdoch
>
>>
>>
>> Thanks in advance,
>>
>> My best regards,
>>
>> Diogo Alagador
>>
>> <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
>> http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador
>>
>> CIBIO/UE - Research Center in Biodiversity and Genetic Resources, University
>> of ?vora, Portugal
>>
>>
>>
>>
>>      [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

R. Mark Sharp, Ph.D.
msharp at TxBiomed.org






NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.

From aps6dl at yahoo.com  Sat Nov 22 08:12:24 2014
From: aps6dl at yahoo.com (Aditya Singh)
Date: Sat, 22 Nov 2014 07:12:24 +0000 (UTC)
Subject: [R] How do I extract single entries from a factor?
In-Reply-To: <CD5F4FD8-AA16-4673-8748-9495FB5308FF@utoronto.ca>
References: <CD5F4FD8-AA16-4673-8748-9495FB5308FF@utoronto.ca>
Message-ID: <2086974137.3928193.1416640344471.JavaMail.yahoo@jws10652.mail.bf1.yahoo.com>

Dear Boris and R-Experts,

I have a variable my_state which is a 2-letter character string telling which American state the user inputs. This I am do a if(identical(database entry,my_state)) to check for occurrences in the database.

The problem is that the database entry[i,j] shows as a factor with various levels, e.g. the output when I do class(database[i,j])is:

[1] "TX" 
AL.. levels through WY

How do I convert a factor into a character?

Aditya



On Saturday, November 22, 2014 12:40 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
Seems to me you probably wanted a "while" in line 4.

N.b.  There's also a missing "}" and totally messed up formatting :-(

B.



On Nov 21, 2014, at 1:19 PM, Aditya Singh <aps6dl at yahoo.com> wrote:

> 1 my_min= min(outcome_data[which(outcome_data$State==my_state),11],na.rm=TRUE) 
> 2 print(my_min) 
> 3 jkr=0 
> 4 if (jkr<= 4706) {jkr=jkr+1 
> 5 if (identical(outcome_data[jkr,11],my_min) && identical(outcome_data[jkr,7],my_state)) { 
> 6 print((outcome_data[jkr,2])) 
> 7 break 
> 8 } 
> 
> 
> Dear Experts,
> 
> My computer is never 'inside' of  the if condition at line 5, as jkr=0 always. my_min is a numeric. my_state is a 2 letter American State (character).
> 
> This code gives NULL as output. Wondering!
> 
> Its either very obvious or I am very dumb.
> 
> Please do do reply!
> 
> Aditya
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Nov 22 08:29:16 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 21 Nov 2014 23:29:16 -0800
Subject: [R] Interpreting ANOVA / quantile regression results
In-Reply-To: <CA+56VKJy380Mv3_bGtH3ZR7-ikAsMHkN7cpzRMim+=_uoK=YZA@mail.gmail.com>
References: <CA+56VKJy380Mv3_bGtH3ZR7-ikAsMHkN7cpzRMim+=_uoK=YZA@mail.gmail.com>
Message-ID: <CACk-te1L4B_jBLz0t89kBkFJV94aVT6_YW8uXz7qMAmLuNsrvg@mail.gmail.com>

This is off topic here.Post to a statistics forum like
stats.stackexchange.com instead -- or talk to your professor or TA (if
you're a student).

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Nov 21, 2014 at 8:56 PM, Yunqi Zhang <yqzhang at ucsd.edu> wrote:
> Hi all,
>
> I think this is probably a very simple question related to ANOVA or
> quantile regression.
>
> Let's say if I'm doing ANOVA on 2 factors (f_a and f_b) and trying to
> figure out whether they have an impact on the output. The result shows me
> that f_a has a significant impact while f_b does not as following, where
> the std. error (confidence interval) is
>
>          estimate    std. error      p-value
> f_a    10              0.2               0.001
> f_b    0.5             2                  0.56
>
> If I take this result, and I want to make my best guess for the output of a
> pair of f_a and f_b values. Should I calculate the output using both f_a
> and f_b or only the f_a because f_b is statistically insignificant? And
> what the std. error (confidence interval) would be?
>
> Specifically, should I do
>
> guessed output = 10 * f_a + 0.5 * f_b and the std. error is 0.2 + 2 = 2.2
>
> or
>
> guessed output = 10 * f_a and the std.err is 0.2
>
> Thank you very much!
>
> Yunqi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Nov 22 12:50:16 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 22 Nov 2014 12:50:16 +0100
Subject: [R] How do I extract single entries from a factor?
In-Reply-To: <2086974137.3928193.1416640344471.JavaMail.yahoo@jws10652.mail.bf1.yahoo.com>
References: <CD5F4FD8-AA16-4673-8748-9495FB5308FF@utoronto.ca>
	<2086974137.3928193.1416640344471.JavaMail.yahoo@jws10652.mail.bf1.yahoo.com>
Message-ID: <897D6853-38BF-49F7-8590-D93317F03B67@gmail.com>


> On 22 Nov 2014, at 08:12 , Aditya Singh <aps6dl at yahoo.com> wrote:
> 
> Dear Boris and R-Experts,
> 
> I have a variable my_state which is a 2-letter character string telling which American state the user inputs. This I am do a if(identical(database entry,my_state)) to check for occurrences in the database.
> 
> The problem is that the database entry[i,j] shows as a factor with various levels, e.g. the output when I do class(database[i,j])is:
> 
> [1] "TX" 
> AL.. levels through WY
> 
> How do I convert a factor into a character?

How about as.character()? 

(Or, nip it in the bud using stringsAsFactors=FALSE when reading)

-pd


> 
> Aditya
> 
> 
> 
> On Saturday, November 22, 2014 12:40 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Seems to me you probably wanted a "while" in line 4.
> 
> N.b.  There's also a missing "}" and totally messed up formatting :-(
> 
> B.
> 
> 
> 
> On Nov 21, 2014, at 1:19 PM, Aditya Singh <aps6dl at yahoo.com> wrote:
> 
>> 1 my_min= min(outcome_data[which(outcome_data$State==my_state),11],na.rm=TRUE) 
>> 2 print(my_min) 
>> 3 jkr=0 
>> 4 if (jkr<= 4706) {jkr=jkr+1 
>> 5 if (identical(outcome_data[jkr,11],my_min) && identical(outcome_data[jkr,7],my_state)) { 
>> 6 print((outcome_data[jkr,2])) 
>> 7 break 
>> 8 } 
>> 
>> 
>> Dear Experts,
>> 
>> My computer is never 'inside' of  the if condition at line 5, as jkr=0 always. my_min is a numeric. my_state is a 2 letter American State (character).
>> 
>> This code gives NULL as output. Wondering!
>> 
>> Its either very obvious or I am very dumb.
>> 
>> Please do do reply!
>> 
>> Aditya
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ragia11 at hotmail.com  Sat Nov 22 15:29:34 2014
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 22 Nov 2014 16:29:34 +0200
Subject: [R] Generate random numbers under constrain
In-Reply-To: <mailman.18.1416654007.11329.r-help@r-project.org>
References: <mailman.18.1416654007.11329.r-help@r-project.org>
Message-ID: <DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>

 
Dear all,
I use R 3.1.1 for Windows.
kindly how can I generate n number of random numbers with probability from [0,1]
and their sum must not be more than one
thanks in advance
Ragia

    
 		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sat Nov 22 16:14:53 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 22 Nov 2014 07:14:53 -0800
Subject: [R] Generate random numbers under constrain
In-Reply-To: <DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>
References: <mailman.18.1416654007.11329.r-help@r-project.org>
	<DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>
Message-ID: <CACk-te3cp2FkTJEg_xS8GoaqZR58kcQ0sURrZYZ-DgwYB4pHHA@mail.gmail.com>

Well, if their sum must be < 1 they ain't random...

But anyway... given n

randnums <- function(n)
{


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Nov 22, 2014 at 6:29 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>
> Dear all,
> I use R 3.1.1 for Windows.
> kindly how can I generate n number of random numbers with probability from [0,1]
> and their sum must not be more than one
> thanks in advance
> Ragia
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Nov 22 16:19:03 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 22 Nov 2014 07:19:03 -0800
Subject: [R] Generate random numbers under constrain
In-Reply-To: <CACk-te3cp2FkTJEg_xS8GoaqZR58kcQ0sURrZYZ-DgwYB4pHHA@mail.gmail.com>
References: <mailman.18.1416654007.11329.r-help@r-project.org>
	<DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>
	<CACk-te3cp2FkTJEg_xS8GoaqZR58kcQ0sURrZYZ-DgwYB4pHHA@mail.gmail.com>
Message-ID: <CACk-te1E9jv-eZMvA19_8SAqsDqqH4zWnr=cbd-=NFzt6evY0w@mail.gmail.com>

(Hit send key by accident before I was finished ...)

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Nov 22, 2014 at 7:14 AM, Bert Gunter <bgunter at gene.com> wrote:
> Well, if their sum must be < 1 they ain't random...
>
 But anyway, one way is ... given n

 randnums <- function(n)
 {
u <- runif(n)
u/sum(u)
}

 Bert Gunter

>
>
> On Sat, Nov 22, 2014 at 6:29 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>>
>> Dear all,
>> I use R 3.1.1 for Windows.
>> kindly how can I generate n number of random numbers with probability from [0,1]
>> and their sum must not be more than one
>> thanks in advance
>> Ragia
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sat Nov 22 16:29:18 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 22 Nov 2014 10:29:18 -0500
Subject: [R] Generate random numbers under constrain
In-Reply-To: <DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>
References: <mailman.18.1416654007.11329.r-help@r-project.org>
	<DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>
Message-ID: <4885A545-1CD1-4A8C-B69E-4CE42D86332C@utoronto.ca>

These are contradictory requirements: either you have n random numbers from the interval [0,1), then you can't guarantee anything about their sum except that it will be in [0,n). Or you constrain the sum, then your random numbers cannot be random in [0,1). You could possibly scale the random numbers:
n <- 13
x <- runif(n)
x <- x / sum(x)
x; sum(x)

This will guarantee that their sum is 1 (to numerical accuracy), but your numbers are then effectively drawn from the interval [0,2/n) for large n.

B.


On Nov 22, 2014, at 9:29 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:

> 
> Dear all,
> I use R 3.1.1 for Windows.
> kindly how can I generate n number of random numbers with probability from [0,1]
> and their sum must not be more than one
> thanks in advance
> Ragia
> 
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maitra.mbox.ignored at inbox.com  Sat Nov 22 16:54:19 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sat, 22 Nov 2014 09:54:19 -0600
Subject: [R] Generate random numbers under constrain
In-Reply-To: <4885A545-1CD1-4A8C-B69E-4CE42D86332C@utoronto.ca>
References: <mailman.18.1416654007.11329.r-help@r-project.org>
	<DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>
	<4885A545-1CD1-4A8C-B69E-4CE42D86332C@utoronto.ca>
Message-ID: <20141122095419.313b2bae5f8aed7ff3e64311@inbox.com>

I don't understand this discussion at all.

n random numbers constrained to have sum <=1 are still random. They are not all independent.

That said, the original poster's question is ill=formed since there can be multiple distributions these random numbers come from.

best wishes,
Ranjan



On Sat, 22 Nov 2014 10:29:18 -0500 Boris Steipe <boris.steipe at utoronto.ca> wrote:

> These are contradictory requirements: either you have n random numbers from the interval [0,1), then you can't guarantee anything about their sum except that it will be in [0,n). Or you constrain the sum, then your random numbers cannot be random in [0,1). You could possibly scale the random numbers:
> n <- 13
> x <- runif(n)
> x <- x / sum(x)
> x; sum(x)
> 
> This will guarantee that their sum is 1 (to numerical accuracy), but your numbers are then effectively drawn from the interval [0,2/n) for large n.
> 
> B.
> 
> 
> On Nov 22, 2014, at 9:29 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
> 
> > 
> > Dear all,
> > I use R 3.1.1 for Windows.
> > kindly how can I generate n number of random numbers with probability from [0,1]
> > and their sum must not be more than one
> > thanks in advance
> > Ragia
> > 
> > 
> > 		 	   		  
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From boris.steipe at utoronto.ca  Sat Nov 22 17:01:38 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 22 Nov 2014 11:01:38 -0500
Subject: [R] Generate random numbers under constrain
In-Reply-To: <20141122095419.313b2bae5f8aed7ff3e64311@inbox.com>
References: <mailman.18.1416654007.11329.r-help@r-project.org>
	<DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>
	<4885A545-1CD1-4A8C-B69E-4CE42D86332C@utoronto.ca>
	<20141122095419.313b2bae5f8aed7ff3e64311@inbox.com>
Message-ID: <E6EA7E37-F99C-48C1-B9F6-1F15439061CC@utoronto.ca>

Of course they are random. But they can't all be randomly picked from [0,1).
By scaling them, one is effectively scaling the interval from which they are picked.

B.
Nb: the scaling procedure will work for any probability distribution.



On Nov 22, 2014, at 10:54 AM, Ranjan Maitra <maitra.mbox.ignored at inbox.com> wrote:

> I don't understand this discussion at all.
> 
> n random numbers constrained to have sum <=1 are still random. They are not all independent.
> 
> That said, the original poster's question is ill=formed since there can be multiple distributions these random numbers come from.
> 
> best wishes,
> Ranjan
> 
> 
> 
> On Sat, 22 Nov 2014 10:29:18 -0500 Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
>> These are contradictory requirements: either you have n random numbers from the interval [0,1), then you can't guarantee anything about their sum except that it will be in [0,n). Or you constrain the sum, then your random numbers cannot be random in [0,1). You could possibly scale the random numbers:
>> n <- 13
>> x <- runif(n)
>> x <- x / sum(x)
>> x; sum(x)
>> 
>> This will guarantee that their sum is 1 (to numerical accuracy), but your numbers are then effectively drawn from the interval [0,2/n) for large n.
>> 
>> B.
>> 
>> 
>> On Nov 22, 2014, at 9:29 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>> 
>>> 
>>> Dear all,
>>> I use R 3.1.1 for Windows.
>>> kindly how can I generate n number of random numbers with probability from [0,1]
>>> and their sum must not be more than one
>>> thanks in advance
>>> Ragia
>>> 
>>> 
>>> 		 	   		  
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
> 
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From i.petzev at gmail.com  Sat Nov 22 17:12:21 2014
From: i.petzev at gmail.com (i.petzev)
Date: Sat, 22 Nov 2014 17:12:21 +0100
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <C28C47E6-BDDC-46E2-AFB2-9C858581F5E2@comcast.net>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
	<B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
	<79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>
	<8780E3CE-13F9-43B3-A6D3-5034BBE6304C@comcast.net>
	<12A4CACA-73C3-42A8-BC54-053A891B7B7C@gmail.com>
	<72B60A76-2390-43AC-95C7-E0B7B3609ADF@comcast.net>
	<CAOrU2ZJvz0K7sE8eRXv3xxWkWFZuwBdKZeidA7w2wQ4EYNCvLw@mail.gmail.com>
	<C28C47E6-BDDC-46E2-AFB2-9C858581F5E2@comcast.net>
Message-ID: <4485A978-DF61-4A18-B810-214478406E5D@gmail.com>


On 21 Nov 2014, at 19:18, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Nov 21, 2014, at 6:52 AM, ivan wrote:
> 
>> I am aware of the fact that bootstrapping produces different CIs with every run. I still believe that there is a difference between both types of procedures. My understanding is that setting "w" in the boot() function influences the "importance" of observations or how the bootstrap selects the observations. I.e, observation i does not have the same probability of being chosen as observation j when "w" is defined in the boot() function. If you return res_boot you will notice that with "w" being set in the boot() function, the function call states "weighted bootstrap". If not, it states "ordinary nonparametric bootstrap". But maybe I am wrong. 
> 
> OK. So in the the second call w affects the probability of a case being sent to the boot-function as well as being used in the boot-function; while with the "non-weighted call" the w's are only affecting the individual mean estimates. So the second one is different. And as I suggested earlier you never described the goals of the investigation or the meaning of the variables. 
> 
>   I can tell you that when Davison and Hinkley offered examples of using a bootstrap for a weighted bootstrap mean, they compared a stratified analysis with an example where the weighting was only used on the inner function (example 3.2, practical 3.14 pp 72, 131 of their book) with one where the strata parameter was used. But so far I don't think you have ever described what sort of weights these actually are. In that example the weights were the inverse variances of the sample groups. They didn't use a 'weights' parameter in the boot call. I'm do not know if it was part of the S package that was being used at the time.
> 
> I tried to find an example of a weighted bootstrap in V&R 4e but did not see one. Prof Ripley is the maintainer of the boot package. In the V&R book, Angelo Canty is given the credit for writing the boot package for S. I think you should consult the code, first. And you should also look at the `stype` parameter where "w" is one option.
> 
> -- 
> David.
> 
>> 
>> On Thu, Nov 20, 2014 at 8:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Nov 20, 2014, at 2:23 AM, i.petzev wrote:
>> 
>>> Hi David,
>>> 
>>> sorry, I was not clear.
>> 
>> Right. You never were clear about what you wanted and your examples was so statistically symmetric that it is still hard to see what is needed. The examples below show CI's that are arguably equivalent. I can be faulted for attempting to provide code that produced a sensible answer to a vague question to which I was only guessing at the intent.
>> 
>> 
>>> The difference comes from defining or not defining ?w? in the boot() function. The results with your function and your approach are thus:
>>> 
>>> set.seed(1111)
>>> x <- rnorm(50)
>>> y <- rnorm(50)
>>> weights <- runif(50)
>>> weights <- weights / sum(weights)
>>> dataset <- cbind(x,y,weights)
>>> 
>>> vw_m_diff <- function(dataset,w) {
>>>  differences <- dataset[w,1]-dataset[w,2]
>>>  weights <- dataset[w, "weights"]
>>>  return(weighted.mean(x=differences, w=weights))
>>> }
>>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
>>> boot.ci(res_boot)
>>> 
>>> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
>>> Based on 1000 bootstrap replicates
>>> 
>>> CALL :
>>> boot.ci(boot.out = res_boot)
>>> 
>>> Intervals :
>>> Level      Normal              Basic
>>> 95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )
>>> 
>>> Level     Percentile            BCa
>>> 95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )
>>> Calculations and Intervals on Original Scale
>>> 
>>> ********************************************************************************************************************
>>> 
>>> However, without defining ?w? in the bootstrap function, i.e., running an ordinary and not a weighted bootstrap, the results are:
>>> 
>>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000)
>>> boot.ci(res_boot)
>>> 
>>> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
>>> Based on 1000 bootstrap replicates
>>> 
>>> CALL :
>>> boot.ci(boot.out = res_boot)
>>> 
>>> Intervals :
>>> Level      Normal              Basic
>>> 95%   (-0.6265,  0.4966 )   (-0.6125,  0.5249 )
>> 
>> I hope you are not saying that because those CI's are different that there is some meaning in that difference. Bootstrap runs will always be "different" than each other unless you use set.seed(.) before the runs.
>> 
>>> 
>>> Level     Percentile            BCa
>>> 95%   (-0.6714,  0.4661 )   (-0.6747,  0.4559 )
>>> Calculations and Intervals on Original Scale
>>> 
>>> On 19 Nov 2014, at 17:49, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>>>>> vw_m_diff <- function(dataset,w) {
>>>>>>    differences <- dataset[w,1]-dataset[w,2]
>>>>>>   weights <- dataset[w, "weights"]
>>>>>>   return(weighted.mean(x=differences, w=weights))
>>>>>> }
>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 
> 
> David Winsemius
> Alameda, CA, USA


	[[alternative HTML version deleted]]


From i.petzev at gmail.com  Sat Nov 22 17:21:18 2014
From: i.petzev at gmail.com (i.petzev)
Date: Sat, 22 Nov 2014 17:21:18 +0100
Subject: [R] Bootstrap CIs for weighted means of paired differences
In-Reply-To: <C28C47E6-BDDC-46E2-AFB2-9C858581F5E2@comcast.net>
References: <CAOrU2Z+2EzkaYBy+f5A_fP-w7_EjFW72MkqgGgbrZ9fDGPDRyQ@mail.gmail.com>
	<C45CBD22-3C40-4CFD-AA46-75B42BC3AC39@comcast.net>
	<B55A487B-0A11-495C-858E-6C3981F76AAD@comcast.net>
	<79B026B8-DA06-4FFE-9893-BB680518865A@gmail.com>
	<8780E3CE-13F9-43B3-A6D3-5034BBE6304C@comcast.net>
	<12A4CACA-73C3-42A8-BC54-053A891B7B7C@gmail.com>
	<72B60A76-2390-43AC-95C7-E0B7B3609ADF@comcast.net>
	<CAOrU2ZJvz0K7sE8eRXv3xxWkWFZuwBdKZeidA7w2wQ4EYNCvLw@mail.gmail.com>
	<C28C47E6-BDDC-46E2-AFB2-9C858581F5E2@comcast.net>
Message-ID: <9EF71BE1-90BA-44CB-A993-C9C74894A885@gmail.com>

Ok, thanks for the suggestions. I will look into that. And you are absolutely right that I should have been more clear about what type of weighting I want. So to clarify: I run time series regressions of returns of company i on two different sets of explanatory variables. Then I extract the respective intercepts of the two regressions and take the difference between both. I repeat this for the whole sample of companies and then compute the market value weighted average of those differences. 




On 21 Nov 2014, at 19:18, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Nov 21, 2014, at 6:52 AM, ivan wrote:
> 
>> I am aware of the fact that bootstrapping produces different CIs with every run. I still believe that there is a difference between both types of procedures. My understanding is that setting "w" in the boot() function influences the "importance" of observations or how the bootstrap selects the observations. I.e, observation i does not have the same probability of being chosen as observation j when "w" is defined in the boot() function. If you return res_boot you will notice that with "w" being set in the boot() function, the function call states "weighted bootstrap". If not, it states "ordinary nonparametric bootstrap". But maybe I am wrong. 
> 
> OK. So in the the second call w affects the probability of a case being sent to the boot-function as well as being used in the boot-function; while with the "non-weighted call" the w's are only affecting the individual mean estimates. So the second one is different. And as I suggested earlier you never described the goals of the investigation or the meaning of the variables. 
> 
>   I can tell you that when Davison and Hinkley offered examples of using a bootstrap for a weighted bootstrap mean, they compared a stratified analysis with an example where the weighting was only used on the inner function (example 3.2, practical 3.14 pp 72, 131 of their book) with one where the strata parameter was used. But so far I don't think you have ever described what sort of weights these actually are. In that example the weights were the inverse variances of the sample groups. They didn't use a 'weights' parameter in the boot call. I'm do not know if it was part of the S package that was being used at the time.
> 
> I tried to find an example of a weighted bootstrap in V&R 4e but did not see one. Prof Ripley is the maintainer of the boot package. In the V&R book, Angelo Canty is given the credit for writing the boot package for S. I think you should consult the code, first. And you should also look at the `stype` parameter where "w" is one option.
> 
> -- 
> David.
> 
>> 
>> On Thu, Nov 20, 2014 at 8:19 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Nov 20, 2014, at 2:23 AM, i.petzev wrote:
>> 
>>> Hi David,
>>> 
>>> sorry, I was not clear.
>> 
>> Right. You never were clear about what you wanted and your examples was so statistically symmetric that it is still hard to see what is needed. The examples below show CI's that are arguably equivalent. I can be faulted for attempting to provide code that produced a sensible answer to a vague question to which I was only guessing at the intent.
>> 
>> 
>>> The difference comes from defining or not defining ?w? in the boot() function. The results with your function and your approach are thus:
>>> 
>>> set.seed(1111)
>>> x <- rnorm(50)
>>> y <- rnorm(50)
>>> weights <- runif(50)
>>> weights <- weights / sum(weights)
>>> dataset <- cbind(x,y,weights)
>>> 
>>> vw_m_diff <- function(dataset,w) {
>>>  differences <- dataset[w,1]-dataset[w,2]
>>>  weights <- dataset[w, "weights"]
>>>  return(weighted.mean(x=differences, w=weights))
>>> }
>>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000, w=dataset[,3])
>>> boot.ci(res_boot)
>>> 
>>> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
>>> Based on 1000 bootstrap replicates
>>> 
>>> CALL :
>>> boot.ci(boot.out = res_boot)
>>> 
>>> Intervals :
>>> Level      Normal              Basic
>>> 95%   (-0.5657,  0.4962 )   (-0.5713,  0.5062 )
>>> 
>>> Level     Percentile            BCa
>>> 95%   (-0.6527,  0.4249 )   (-0.5579,  0.5023 )
>>> Calculations and Intervals on Original Scale
>>> 
>>> ********************************************************************************************************************
>>> 
>>> However, without defining ?w? in the bootstrap function, i.e., running an ordinary and not a weighted bootstrap, the results are:
>>> 
>>> res_boot <- boot(dataset, statistic=vw_m_diff, R = 1000)
>>> boot.ci(res_boot)
>>> 
>>> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
>>> Based on 1000 bootstrap replicates
>>> 
>>> CALL :
>>> boot.ci(boot.out = res_boot)
>>> 
>>> Intervals :
>>> Level      Normal              Basic
>>> 95%   (-0.6265,  0.4966 )   (-0.6125,  0.5249 )
>> 
>> I hope you are not saying that because those CI's are different that there is some meaning in that difference. Bootstrap runs will always be "different" than each other unless you use set.seed(.) before the runs.
>> 
>>> 
>>> Level     Percentile            BCa
>>> 95%   (-0.6714,  0.4661 )   (-0.6747,  0.4559 )
>>> Calculations and Intervals on Original Scale
>>> 
>>> On 19 Nov 2014, at 17:49, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>>>>> vw_m_diff <- function(dataset,w) {
>>>>>>    differences <- dataset[w,1]-dataset[w,2]
>>>>>>   weights <- dataset[w, "weights"]
>>>>>>   return(weighted.mean(x=differences, w=weights))
>>>>>> }
>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 
> 
> David Winsemius
> Alameda, CA, USA


	[[alternative HTML version deleted]]


From optionsraghu at gmail.com  Sat Nov 22 18:45:43 2014
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Sat, 22 Nov 2014 17:45:43 +0000
Subject: [R] Help with Time
Message-ID: <CADgEnD=YMYqXwZrHb5OGbAiBy2L+w3-AXbQiZYcyPV3t2xbvdw@mail.gmail.com>

Hi Boris/ David

Many thanks for the kind assistance. I will try following your codes.
Time has always been a slippery subject to me!

Cheers


On Sat, Nov 22, 2014 at 12:59 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Nov 21, 2014, at 3:19 PM, David Winsemius wrote:
>
>>
>> On Nov 21, 2014, at 2:55 PM, Raghuraman Ramachandran wrote:
>>
>>> Sorry I forgot to mention it clearly. I like to round it to the
>>> nearest 30th minute that is past. So 12:28:59 will be again 12:00:00
>>> and
>>> 12:59:59 will be 12:30:00 etc. Apologies for the lack of clarity in
>>> the beginning.
>>>
>>
>> That's just truncation. Should be very easy to hack trunc.POSIXt to deliver that result. Add a "half_hr" unit to the list and then a simple extra clause that check for minutes >30.
>
> In my first effort I used an if(){}else{} construction, committing the newbie mistake of forgetting it was not the vectoRized way. So this performs better:
>
> trunc.POSIXt <-
> function (x, units = c("secs", "mins", "half_hrs", "hours", "days"), ...)
> {
>     units <- match.arg(units)
>     x <- as.POSIXlt(x)
>     if (length(x$sec))
>         switch(units, secs = {
>             x$sec <- trunc(x$sec)
>         }, mins = {
>             x$sec[] <- 0
>         }, half_hrs = {
>             x$sec[] <- 0
>             x$min[] <- 0L+ 30L*(x$min >=30)
>         }, hours = {
>             x$sec[] <- 0
>             x$min[] <- 0L
>         }, days = {
>             x$sec[] <- 0
>             x$min[] <- 0L
>             x$hour[] <- 0L
>             x$isdst[] <- -1L
>         })
>     x
> }
>
>> time <- seq(Sys.time(), Sys.time()+60*120, by= 60*5)
>> trunc(time, "half_hrs")
>  [1] "2014-11-21 15:30:00 PST" "2014-11-21 15:30:00 PST"
>  [3] "2014-11-21 15:30:00 PST" "2014-11-21 15:30:00 PST"
>  [5] "2014-11-21 15:30:00 PST" "2014-11-21 15:30:00 PST"
>  [7] "2014-11-21 16:00:00 PST" "2014-11-21 16:00:00 PST"
>  [9] "2014-11-21 16:00:00 PST" "2014-11-21 16:00:00 PST"
> [11] "2014-11-21 16:00:00 PST" "2014-11-21 16:00:00 PST"
> [13] "2014-11-21 16:30:00 PST" "2014-11-21 16:30:00 PST"
> [15] "2014-11-21 16:30:00 PST" "2014-11-21 16:30:00 PST"
> [17] "2014-11-21 16:30:00 PST" "2014-11-21 16:30:00 PST"
> [19] "2014-11-21 17:00:00 PST" "2014-11-21 17:00:00 PST"
> [21] "2014-11-21 17:00:00 PST" "2014-11-21 17:00:00 PST"
> [23] "2014-11-21 17:00:00 PST" "2014-11-21 17:00:00 PST"
> [25] "2014-11-21 17:30:00 PST"
>
>
>> --
>> David.
>>
>>
>>> Many thanks
>>> Raghu
>>>
>>> On Fri, Nov 21, 2014 at 10:52 PM, Raghuraman Ramachandran
>>> <optionsraghu at gmail.com> wrote:
>>>> Dear guRus
>>>>
>>>> How can I round of time in R to the nearest 30th minute please?
>>>>
>>>> For example suppose if
>>>>> Sys.time()
>>>> [1] "2014-11-21 22:49:05.59042 GMT"
>>>> then I would like a function that outputs 22:30:00.
>>>>
>>>> if Sys.time is 12:13:22 then I would like to get 12:00:00 etc.
>>>>
>>>> Any help would be appreciated.
>>>>
>>>> Many thanks and regards,
>>>> Raghu
>>>
>>> __________________________________
>
>>
>
> David Winsemius
> Alameda, CA, USA
>


From chl948 at mail.usask.ca  Sat Nov 22 08:41:13 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Sat, 22 Nov 2014 01:41:13 -0600
Subject: [R] How do I extract single entries from a factor?
In-Reply-To: <2086974137.3928193.1416640344471.JavaMail.yahoo@jws10652.mail.bf1.yahoo.com>
References: <CD5F4FD8-AA16-4673-8748-9495FB5308FF@utoronto.ca>
	<2086974137.3928193.1416640344471.JavaMail.yahoo@jws10652.mail.bf1.yahoo.com>
Message-ID: <54703E19.7050803@mail.usask.ca>

 > xx <- as.factor(c("AL", "AK", "CA", "FL"))
 > xx
[1] AL AK CA FL
Levels: AK AL CA FL
 > as.character(xx)
[1] "AL" "AK" "CA" "FL"

I hope this helps.

Chel Hee Lee

On 14-11-22 01:12 AM, Aditya Singh wrote:
> Dear Boris and R-Experts,
>
> I have a variable my_state which is a 2-letter character string telling which American state the user inputs. This I am do a if(identical(database entry,my_state)) to check for occurrences in the database.
>
> The problem is that the database entry[i,j] shows as a factor with various levels, e.g. the output when I do class(database[i,j])is:
>
> [1] "TX"
> AL.. levels through WY
>
> How do I convert a factor into a character?
>
> Aditya
>
>
>
> On Saturday, November 22, 2014 12:40 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Seems to me you probably wanted a "while" in line 4.
>
> N.b.  There's also a missing "}" and totally messed up formatting :-(
>
> B.
>
>
>
> On Nov 21, 2014, at 1:19 PM, Aditya Singh <aps6dl at yahoo.com> wrote:
>
>> 1 my_min= min(outcome_data[which(outcome_data$State==my_state),11],na.rm=TRUE)
>> 2 print(my_min)
>> 3 jkr=0
>> 4 if (jkr<= 4706) {jkr=jkr+1
>> 5 if (identical(outcome_data[jkr,11],my_min) && identical(outcome_data[jkr,7],my_state)) {
>> 6 print((outcome_data[jkr,2]))
>> 7 break
>> 8 }
>>
>>
>> Dear Experts,
>>
>> My computer is never 'inside' of  the if condition at line 5, as jkr=0 always. my_min is a numeric. my_state is a 2 letter American State (character).
>>
>> This code gives NULL as output. Wondering!
>>
>> Its either very obvious or I am very dumb.
>>
>> Please do do reply!
>>
>> Aditya
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sven.templer at gmail.com  Sat Nov 22 20:00:57 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Sat, 22 Nov 2014 20:00:57 +0100
Subject: [R] Formula with dynamic number of variables
In-Reply-To: <COL127-W499AEC335D0E546714810AB3770@phx.gbl>
References: <COL127-W499AEC335D0E546714810AB3770@phx.gbl>
Message-ID: <CAHuTOvrfamUDxmnqGmDCZKQO9nLrgMAgk2bRDzzD4MiEV1p=HA@mail.gmail.com>

# fixed formula part:
f <- dat ~ a0 * exp(-S*(x - 250)) + K
# convert to character
f <- as.character(f)
# component:
C <- "(p0*exp(-0.5*((x-p1)/p2)^2))"
# number of components (defined randomly):
n <- sample(1:3, 1)
C <- rep(C, n)
# collapse:
C <- paste(C, collapse = "+")
# combine
f <- paste(f[2], f[1], f[3], "+", C)
as.formula(f)
# hope this helps.
# best, s

On 21 November 2014 at 14:23, philippe massicotte
<pmassicotte at hotmail.com> wrote:
> Hi everyone.
>
> I have a non-linear model specified as this (6 variables, a0, S, K, p0, p1, p2):
>
> fit <- nlsLM(formula = dat ~ a0 * exp(-S*(x - 250)) + K + ( C ) )
>
> where C = (p0*exp(-0.5*((x-p1)/p2)^2))
>
> The problem is that I do not know in advance how many component (C) I will have in the model. That means It could be:
>
> nlsLM(formula = dat ~ a0 * exp(-S*(x - 250)) + K + ( (p0*exp(-0.5*((x-p1)/p2)^2)) ) )
>
> or
>
> nlsLM(formula = dat ~ a0 * exp(-S*(x - 250)) + K + ( (p0*exp(-0.5*((x-p1)/p2)^2)) ) +   ( (p0b*exp(-0.5*((x-p1b)/p2b)^2)) ))
>
> or
>
>
> nlsLM(formula = dat ~ a0 * exp(-S*(x - 250)) + K + ( (p0*exp(-0.5*((x-p1)/p2)^2)) ) +   ( (p0b*exp(-0.5*((x-p1b)/p2b)^2)) +   ( (p0c*exp(-0.5*((x-p1c)/p2c)^2))))
>
> So I was wondering if it was possible to dynamically build the formula that I will use in my model? The first part of my model will always be "a0 * exp(-S*(x - 250)) + K", I just want to add a certain number of "components" dynamically.
>
> I guess it will be related with "reformulate()" but I can't not find how to make it works.
>
> Thank you for your help,
> Philippe
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Nov 22 20:06:00 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 22 Nov 2014 11:06:00 -0800
Subject: [R] Generate random numbers under constrain
In-Reply-To: <E6EA7E37-F99C-48C1-B9F6-1F15439061CC@utoronto.ca>
References: <mailman.18.1416654007.11329.r-help@r-project.org>
	<DUB125-W5735070367D5D71AE1EB02B3740@phx.gbl>
	<4885A545-1CD1-4A8C-B69E-4CE42D86332C@utoronto.ca>
	<20141122095419.313b2bae5f8aed7ff3e64311@inbox.com>
	<E6EA7E37-F99C-48C1-B9F6-1F15439061CC@utoronto.ca>
Message-ID: <8616A2B6-B515-4206-846C-63AC31B771CF@comcast.net>

In the 2 and 3 vector case it is possible do define a fairly simple sampling space where this is possible.

Consider the unit square where the sample space is the area where x+y <1.

It generalizes to 3 dimensions with no difficulty. 

 x= (0:100)/100
 y= (0:100)/100
 z=outer(x,y, function(x,y) 1-x-y)
library(lattice)
 wireframe(z~x+y, data.frame(x=x,y=rep(y,each=101), z) ,zlim=c(0,1) , scales=list(arrows=FALSE))

So I think the OP _is_ asking for a _random_ variable drawn from a sample space in an n-dimensional hyper-"triangular pyramid",  with base being the  n-1 dimensional analogue of an equilateral regular triaggle and the height of the pyramid being  some value that corresponds to a value of 

1-(nthroot(of some sum( that I cannot state with clarity right now))


-- 
David.




On Nov 22, 2014, at 8:01 AM, Boris Steipe wrote:

> Of course they are random. But they can't all be randomly picked from [0,1).
> By scaling them, one is effectively scaling the interval from which they are picked.
> 
> B.
> Nb: the scaling procedure will work for any probability distribution.
> 
> 
> 
> On Nov 22, 2014, at 10:54 AM, Ranjan Maitra <maitra.mbox.ignored at inbox.com> wrote:
> 
>> I don't understand this discussion at all.
>> 
>> n random numbers constrained to have sum <=1 are still random. They are not all independent.
>> 
>> That said, the original poster's question is ill=formed since there can be multiple distributions these random numbers come from.
>> 
>> best wishes,
>> Ranjan
>> 
>> 
>> 
>> On Sat, 22 Nov 2014 10:29:18 -0500 Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> 
>>> These are contradictory requirements: either you have n random numbers from the interval [0,1), then you can't guarantee anything about their sum except that it will be in [0,n). Or you constrain the sum, then your random numbers cannot be random in [0,1). You could possibly scale the random numbers:
>>> n <- 13
>>> x <- runif(n)
>>> x <- x / sum(x)
>>> x; sum(x)
>>> 
>>> This will guarantee that their sum is 1 (to numerical accuracy), but your numbers are then effectively drawn from the interval [0,2/n) for large n.
>>> 
>>> B.
>>> 
>>> 
>>> On Nov 22, 2014, at 9:29 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>>> 
>>>> 
>>>> Dear all,
>>>> I use R 3.1.1 for Windows.
>>>> kindly how can I generate n number of random numbers with probability from [0,1]
>>>> and their sum must not be more than one
>>>> thanks in advance
>>>> Ragia
>>>> 
>>>> 
>>>> 		 	   		  
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> -- 
>> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From petretta at unina.it  Sun Nov 23 11:46:09 2014
From: petretta at unina.it (Mario Petretta)
Date: Sun, 23 Nov 2014 11:46:09 +0100
Subject: [R] Comparing summary hazard ratios in meta-analysis
Message-ID: <000101d0070a$b14b8bd0$13e2a370$@unina.it>

Many thanks again for your suggestions.

 

Sorry. Effectvely there was a mistake in the HR I previously submitted.

 

As suggested, I started from scratch and the correct HR are:

 

HR 3,12 (2,24-4.35)

HR 1,25 (1,03-1,52)

 

Mario

 

 

On 23/11/2014 09:23, Viechtbauer Wolfgang (STAT) wrote:

I actually don't see Michael suggesting that you should work with the
individual studies. My interpretation of his reply is that he is suggesting
the same thing that I have done. But in the end, you should get similar
results whether you test those two summary (log) HRs against each other or
if you work with the individual studies and test whether the summary (log)
HRs of the first set is different from the second.

I have cc-ed Michael in case I am misinterpreting his suggestion.

I had originally thought of using the individual studies as Mario
interpreted but I do not have strong feelings either way. I suppose I was
thinking of cases I have seen where either injudicious rounding or typos has
meant that it was better to start from scratch.

[Show Quoted Text - 122 lines][Nascondi Testo quotato] 


Best,
Wolfgang

-----Original Message-----
From: Mario Petretta [mailto:
<https://inbox.unina.it/horde/imp/message.php?mailbox=INBOX&index=101432>
petretta at unina.it]
Sent: Friday, November 21, 2014 18:19
To:
<https://inbox.unina.it/horde/imp/message.php?mailbox=INBOX&index=101432>
r-help at r-project.org
Cc: Viechtbauer Wolfgang (STAT)
Subject: R: [R] Comparing summary hazard ratios in meta-analysis

Many many thanks to Michael Dewey and to Viechtbauer Wolfgang for the
kindly and useful replay !!

I only ask to Wolfgang if I should log-transform hazard ratios and
compute standard error only for the summary hazard ratio estimates or, as
suggested by Michael, for each single study, combining them in a single
data frame and thereafter performing the meta-regression incorporating
the moderator.

Mario

-----Messaggio originale-----
Da: Viechtbauer Wolfgang (STAT)
[mailto:
<https://inbox.unina.it/horde/imp/message.php?mailbox=INBOX&index=101432>
wolfgang.viechtbauer at maastrichtuniversity.nl]
Inviato: venerd? 21 novembre 2014 15:37
A: Michael Dewey; Mario Petretta;
<https://inbox.unina.it/horde/imp/message.php?mailbox=INBOX&index=101432>
r-help at r-project.org
Oggetto: RE: [R] Comparing summary hazard ratios in meta-analysis

Those hazard ratios and CIs seem a bit strange. On the log-scale, they
should be symmetric, but they are not. Could be due to heavy rounding
though. At any rate, it comes down to this:

hr    <- c(3.12, 1.15)
ci.lb <- c(2.2, 1.03)
ci.ub <- c(4.1, 2.6)
meta  <- c(1,2)

### log-transform hazard ratios and compute standard error based on the
CI bounds yi  <- log(hr) sei <- (log(ci.ub) - log(ci.lb)) / (2*1.96)

library(metafor)
res <- rma(yi ~ factor(meta), sei=sei, method="FE") res

So, yes, the two hazard ratios are significantly different from each
other.

Best,
Wolfgang

--
Wolfgang Viechtbauer, Ph.D., Statistician
Department of Psychiatry and Psychology
School for Mental Health and Neuroscience
Faculty of Health, Medicine, and Life Sciences
Maastricht University, P.O. Box 616 (VIJV1)
6200 MD Maastricht, The Netherlands
+31 (43) 388-4170 |  <http://www.wvbauer.com/> http://www.wvbauer.com

-----Original Message-----
From:
<https://inbox.unina.it/horde/imp/message.php?mailbox=INBOX&index=101432>
r-help-bounces at r-project.org
[mailto:
<https://inbox.unina.it/horde/imp/message.php?mailbox=INBOX&index=101432>
r-help-bounces at r-project.org]
On Behalf Of Michael Dewey
Sent: Friday, November 21, 2014 13:25
To: Mario Petretta;
<https://inbox.unina.it/horde/imp/message.php?mailbox=INBOX&index=101432>
r-help at r-project.org
Subject: Re: [R] Comparing summary hazard ratios in meta-analysis

On 21/11/2014 08:51, Mario Petretta wrote:

Dear all,

I use R 3.1.1 for Windows.

I performed two different meta-analysis assessing the prognostic
value

of 

two different tests in patients with coronary artery disease. The
study included in the two analysis are different.

That makes life simpler.


The variable of interest in dichotomous (normal/abnormal result) for

both 

tests.

The effects size is hazard ratio and its standard error (ln units)
for

both 

meta-analysis.

It sounds as though you might want to use meta-regression. You will
need a single data frame containing at least log hr, se of log hr, an
identifier for the test. I would use the metafor package for this,
look in the documentation for how to incorporate a moderator (your
test variable). The advantage of meta-regression is that you not only
get a test but also a measure of how different the hr are with a
confidence interval.

I would like to statistically compare the two summary hazard ratios
and

95% 

CI (eform) obtained from the two meta-analysis.

For one meta-analysis: HR 3.12 (95% CI 2.2 - 4.1) For the other: HR
1.25 (95% CI 1.03 - 2.6)

It is possible or I'm comparing apples with oranges?

Any suggestion is welcome.

-------------------------------------------------------
Mario Petretta
Associate Professor of Internal Medicine Department of Translational
Medical Sciences Naples University Federico II Italy



-- 
Michael
 <http://www.dewey.myzen.co.uk/> http://www.dewey.myzen.co.uk


	[[alternative HTML version deleted]]


From hutchesonjohn at att.net  Sun Nov 23 16:50:47 2014
From: hutchesonjohn at att.net (John Hutcheson)
Date: Sun, 23 Nov 2014 10:50:47 -0500
Subject: [R] Vignette from existing .pdf manual
Message-ID: <3CDD8EA2-20E6-46D6-BA12-AABC0592A5D4@att.net>

Greetings!  I am trying to develop a package for R for Search and Rescue planning.  I'd like to  re-use an existing PDF file that was created in emacs (so I have the .tex and source data) for use in inst/docs.  The vignette sections of the 'Writing r extensions' manual starts off implying that this can be done, but after lots of effort, I find no way of getting it done.  I did find a suggestion to use a 'dummy' .Rnw file stored alongside the pdf in the inst/doc folder, but haven't been able to make that work. 

Here's the setup data:

Package name:   rSARP
directory structure :  rSARP/inst/doc
					    rSARP/inst/extdata
					    rSARP/man
					    rSARP/R
					   

Existing pdf manual:  rSARP.pdf located in rSARP/inst/doc/  (Its less than 5 meg in size)
VignetteIndexEntry file:  	rSARP.Rnw located in rSARP/inst/doc/    The file contents for the dummy .Rnw are:

%\VignetteIndexEntry{User manual}
\documentclass{article}
\begin{document}
\end{document}

I've tried creating an rSARP/vignette folder and storing the .Rnw file there - no luck.  
I appreciate any assistance I can get to incorporate the existing documentation into the package.  


      John Hutcheson
     hutchesonjohn at att.net
            989 - 430 - 7560





	[[alternative HTML version deleted]]


From john.posner at MJBIOSTAT.COM  Sun Nov 23 17:42:58 2014
From: john.posner at MJBIOSTAT.COM (John Posner)
Date: Sun, 23 Nov 2014 16:42:58 +0000
Subject: [R] dplyr/summarize does not create a true data frame
In-Reply-To: <3853F648623.00000147jrkrideau@inbox.com>
References: <9E73F88F04AA25408DBB58FB730BA65329AFF1D3@AUSP01DAG0503.collaborationhost.net>
	<3853F648623.00000147jrkrideau@inbox.com>
Message-ID: <9E73F88F04AA25408DBB58FB730BA65329B027B5@AUSP01DAG0503.collaborationhost.net>

Thanks to John Kane for an off-list consultation. As the following annotated transcript shows, it's the group_by() function that transforms a data frame into something else:  a "grouped_df" object that *looks* identical to the original data frame (e.g. the rows are in the original order -- *not* grouped, as arrange() would do), but does not always act like a data frame.

> library(dplyr)

> # set up data frame, and show its structure [ see below for clean copy of dput() code ]
> 
> frm = structure(list(Id = structure(1:10, .Label = c("P01", "P02", 
+ "P03", "P04", "P05", "P06", "P07", "P08", "P09", "P10"), class = "factor"), 
+     Sex = structure(c(2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 1L), .Label = c("Female", 
+     "Male"), class = "factor"), Height = structure(c(1L, 1L, 
+     3L, 2L, 1L, 3L, 1L, 2L, 1L, 1L), .Label = c("Short", "Medium", 
+     "Tall"), class = "factor"), Value = c(69.47, 64.61, 74.77, 
+     73.31, 64.76, 72.78, 64.64, 55.96, 60.45, 51.11)), .Names = c("Id", 
+ "Sex", "Height", "Value"), row.names = c(NA, -10L), class = "data.frame")
> 
> str(frm)
'data.frame':	10 obs. of  4 variables:
 $ Id    : Factor w/ 10 levels "P01","P02","P03",..: 1 2 3 4 5 6 7 8 9 10
 $ Sex   : Factor w/ 2 levels "Female","Male": 2 1 1 2 2 2 1 2 2 1
 $ Height: Factor w/ 3 levels "Short","Medium",..: 1 1 3 2 1 3 1 2 1 1
 $ Value : num  69.5 64.6 74.8 73.3 64.8 ...

> # run group_by() on data frame, and show resulting structure
> 
> after.group_by = frm %>% group_by(Sex, Height)

> str(after.group_by)
Classes 'grouped_df', 'tbl_df', 'tbl' and 'data.frame':	10 obs. of  4 variables:
 $ Id    : Factor w/ 10 levels "P01","P02","P03",..: 1 2 3 4 5 6 7 8 9 10
 $ Sex   : Factor w/ 2 levels "Female","Male": 2 1 1 2 2 2 1 2 2 1
 $ Height: Factor w/ 3 levels "Short","Medium",..: 1 1 3 2 1 3 1 2 1 1
 $ Value : num  69.5 64.6 74.8 73.3 64.8 ...
 - attr(*, "vars")=List of 2
  ..$ : symbol Sex
  ..$ : symbol Height
 - attr(*, "drop")= logi TRUE
 - attr(*, "indices")=List of 5
  ..$ : int  1 6 9
  ..$ : int 2
  ..$ : int  0 4 8
  ..$ : int  3 7
  ..$ : int 5
 - attr(*, "group_sizes")= int  3 1 3 2 1
 - attr(*, "biggest_group_size")= int 3
 - attr(*, "labels")='data.frame':	5 obs. of  2 variables:
  ..$ Sex   : Factor w/ 2 levels "Female","Male": 1 1 2 2 2
  ..$ Height: Factor w/ 3 levels "Short","Medium",..: 1 3 1 2 3
  ..- attr(*, "vars")=List of 2
  .. ..$ : symbol Sex
  .. ..$ : symbol Height

> # the two data structure *seem* to be the same ...  

> frm == after.group_by
        Id  Sex Height Value
 [1,] TRUE TRUE   TRUE  TRUE
 [2,] TRUE TRUE   TRUE  TRUE
 [3,] TRUE TRUE   TRUE  TRUE
   ...etc.

> # ... but they're not

> frm[4]
   Value
1  69.47
2  64.61
   ...etc.

> after.group_by[4]
Error in eval(expr, envir, enclos) : index out of bounds

> # fortunately, we can convert back to a true data frame

> as.data.frame(after.group_by)[4]
   Value
1  69.47
2  64.61
   ...etc.

################################## dput() code below

structure(list(Id = structure(1:10, .Label = c("P01", "P02", 
"P03", "P04", "P05", "P06", "P07", "P08", "P09", "P10"), class = "factor"), 
    Sex = structure(c(2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 1L), .Label = c("Female", 
    "Male"), class = "factor"), Height = structure(c(1L, 1L, 
    3L, 2L, 1L, 3L, 1L, 2L, 1L, 1L), .Label = c("Short", "Medium", 
    "Tall"), class = "factor"), Value = c(69.47, 64.61, 74.77, 
    73.31, 64.76, 72.78, 64.64, 55.96, 60.45, 51.11)), .Names = c("Id", 
"Sex", "Height", "Value"), row.names = c(NA, -10L), class = "data.frame")




> -----Original Message-----
> From: John Kane [mailto:jrkrideau at inbox.com]
> Sent: Friday, November 21, 2014 12:33 PM
> To: John Posner; 'r-help at r-project.org'
> Subject: RE: [R] dplyr/summarize does not create a true data frame
> 
> Your code in creating 'frm' is not working for me and it is complicated enough
> that I don't want to work it out. See ?dput for a better way to supply data.
> Also see:
> https://github.com/hadley/devtools/wiki/Reproducibility
>  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> reproducible-example
> 
> That said, I don't see why 'my.output[4]' is not working.  Try something like
> str(frm) to see what you have there and/or resubmit the data in dput format
> 
> See simple example below:
> 
> dat1  <- data.frame(aa = sample(1:20, 100, replace = TRUE), bb = 1:100 )
> dat1[2]
> 
> John Kane
> Kingston ON Canada
> 
> 
> > -----Original Message-----
> > From: john.posner at mjbiostat.com
> > Sent: Fri, 21 Nov 2014 17:10:16 +0000
> > To: r-help at r-project.org
> > Subject: [R] dplyr/summarize does not create a true data frame
> >
> > I got an error when trying to extract a 1-column subset of a data
> > frame (called "my.output") created by dplyr/summarize. The ncol()
> > function says that my.output has 4 columns, but "my.output[4]" fails.
> > Note that converting my.output using as.data.frame() makes for a happy
> ending.
> >
> > Is this the intended behavior of dplyr?
> >
> > Tx,
> > John
> >
> >> library(dplyr)
> >
> >> # set up data frame
> >> rows = 100
> >> repcnt = 50
> >> sexes = c("Female", "Male")
> >> heights = c("Med", "Short", "Tall")
> >
> >> frm = data.frame(
> > +   Id = paste("P", sprintf("%04d", 1:rows), sep=""),
> > +   Sex = sample(rep(sexes, repcnt), rows, replace=T),
> > +   Height = sample(rep(heights, repcnt), rows, replace=T),
> > +   V1 = round(runif(rows)*25, 2) + 50,
> > +   V2 = round(runif(rows)*1000, 2) + 50,
> > +   V3 = round(runif(rows)*350, 2) - 175
> > + )
> >>
> >> # use dplyr/summarize to create data frame my.output = frm %>%
> > +   group_by(Sex, Height) %>%
> > +   summarize(V1sum=sum(V1), V2sum=sum(V2))
> >
> >> # work with columns in the output data frame
> >> ncol(my.output)
> > [1] 4
> >
> >> my.output[1]
> > Source: local data frame [6 x 1]
> > Groups: Sex
> >
> >      Sex
> > 1 Female
> > 2 Female
> > 3 Female
> > 4   Male
> > 5   Male
> > 6   Male
> >
> >> my.output[4]
> > Error in eval(expr, envir, enclos) : index out of bounds  ########
> > ERROR HERE
> >
> >> as.data.frame(my.output)[4]
> >      V2sum
> > 1 12427.97
> > 2  8449.82
> > 3  8610.97
> > 4  7249.20
> > 5 12616.91
> > 6 10372.15
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> __________________________________________________________
> __
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> and family!
> Visit http://www.inbox.com/photosharing to find out more!
> 


From h.wickham at gmail.com  Sun Nov 23 18:34:38 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sun, 23 Nov 2014 11:34:38 -0600
Subject: [R] dplyr/summarize does not create a true data frame
In-Reply-To: <9E73F88F04AA25408DBB58FB730BA65329B027B5@AUSP01DAG0503.collaborationhost.net>
References: <9E73F88F04AA25408DBB58FB730BA65329AFF1D3@AUSP01DAG0503.collaborationhost.net>
	<3853F648623.00000147jrkrideau@inbox.com>
	<9E73F88F04AA25408DBB58FB730BA65329B027B5@AUSP01DAG0503.collaborationhost.net>
Message-ID: <CABdHhvFnqhfTV5FaXSxP=JSsb2T5fN0zKCKcO8tjDpjHn08F=g@mail.gmail.com>

This bug is fixed in the dev version.
Hadley

On Sunday, November 23, 2014, John Posner <john.posner at mjbiostat.com> wrote:

> Thanks to John Kane for an off-list consultation. As the following
> annotated transcript shows, it's the group_by() function that transforms a
> data frame into something else:  a "grouped_df" object that *looks*
> identical to the original data frame (e.g. the rows are in the original
> order -- *not* grouped, as arrange() would do), but does not always act
> like a data frame.
>
> > library(dplyr)
>
> > # set up data frame, and show its structure [ see below for clean copy
> of dput() code ]
> >
> > frm = structure(list(Id = structure(1:10, .Label = c("P01", "P02",
> + "P03", "P04", "P05", "P06", "P07", "P08", "P09", "P10"), class =
> "factor"),
> +     Sex = structure(c(2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 1L), .Label =
> c("Female",
> +     "Male"), class = "factor"), Height = structure(c(1L, 1L,
> +     3L, 2L, 1L, 3L, 1L, 2L, 1L, 1L), .Label = c("Short", "Medium",
> +     "Tall"), class = "factor"), Value = c(69.47, 64.61, 74.77,
> +     73.31, 64.76, 72.78, 64.64, 55.96, 60.45, 51.11)), .Names = c("Id",
> + "Sex", "Height", "Value"), row.names = c(NA, -10L), class = "data.frame")
> >
> > str(frm)
> 'data.frame':   10 obs. of  4 variables:
>  $ Id    : Factor w/ 10 levels "P01","P02","P03",..: 1 2 3 4 5 6 7 8 9 10
>  $ Sex   : Factor w/ 2 levels "Female","Male": 2 1 1 2 2 2 1 2 2 1
>  $ Height: Factor w/ 3 levels "Short","Medium",..: 1 1 3 2 1 3 1 2 1 1
>  $ Value : num  69.5 64.6 74.8 73.3 64.8 ...
>
> > # run group_by() on data frame, and show resulting structure
> >
> > after.group_by = frm %>% group_by(Sex, Height)
>
> > str(after.group_by)
> Classes 'grouped_df', 'tbl_df', 'tbl' and 'data.frame': 10 obs. of  4
> variables:
>  $ Id    : Factor w/ 10 levels "P01","P02","P03",..: 1 2 3 4 5 6 7 8 9 10
>  $ Sex   : Factor w/ 2 levels "Female","Male": 2 1 1 2 2 2 1 2 2 1
>  $ Height: Factor w/ 3 levels "Short","Medium",..: 1 1 3 2 1 3 1 2 1 1
>  $ Value : num  69.5 64.6 74.8 73.3 64.8 ...
>  - attr(*, "vars")=List of 2
>   ..$ : symbol Sex
>   ..$ : symbol Height
>  - attr(*, "drop")= logi TRUE
>  - attr(*, "indices")=List of 5
>   ..$ : int  1 6 9
>   ..$ : int 2
>   ..$ : int  0 4 8
>   ..$ : int  3 7
>   ..$ : int 5
>  - attr(*, "group_sizes")= int  3 1 3 2 1
>  - attr(*, "biggest_group_size")= int 3
>  - attr(*, "labels")='data.frame':      5 obs. of  2 variables:
>   ..$ Sex   : Factor w/ 2 levels "Female","Male": 1 1 2 2 2
>   ..$ Height: Factor w/ 3 levels "Short","Medium",..: 1 3 1 2 3
>   ..- attr(*, "vars")=List of 2
>   .. ..$ : symbol Sex
>   .. ..$ : symbol Height
>
> > # the two data structure *seem* to be the same ...
>
> > frm == after.group_by
>         Id  Sex Height Value
>  [1,] TRUE TRUE   TRUE  TRUE
>  [2,] TRUE TRUE   TRUE  TRUE
>  [3,] TRUE TRUE   TRUE  TRUE
>    ...etc.
>
> > # ... but they're not
>
> > frm[4]
>    Value
> 1  69.47
> 2  64.61
>    ...etc.
>
> > after.group_by[4]
> Error in eval(expr, envir, enclos) : index out of bounds
>
> > # fortunately, we can convert back to a true data frame
>
> > as.data.frame(after.group_by)[4]
>    Value
> 1  69.47
> 2  64.61
>    ...etc.
>
> ################################## dput() code below
>
> structure(list(Id = structure(1:10, .Label = c("P01", "P02",
> "P03", "P04", "P05", "P06", "P07", "P08", "P09", "P10"), class = "factor"),
>     Sex = structure(c(2L, 1L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 1L), .Label =
> c("Female",
>     "Male"), class = "factor"), Height = structure(c(1L, 1L,
>     3L, 2L, 1L, 3L, 1L, 2L, 1L, 1L), .Label = c("Short", "Medium",
>     "Tall"), class = "factor"), Value = c(69.47, 64.61, 74.77,
>     73.31, 64.76, 72.78, 64.64, 55.96, 60.45, 51.11)), .Names = c("Id",
> "Sex", "Height", "Value"), row.names = c(NA, -10L), class = "data.frame")
>
>
>
>
> > -----Original Message-----
> > From: John Kane [mailto:jrkrideau at inbox.com <javascript:;>]
> > Sent: Friday, November 21, 2014 12:33 PM
> > To: John Posner; 'r-help at r-project.org <javascript:;>'
> > Subject: RE: [R] dplyr/summarize does not create a true data frame
> >
> > Your code in creating 'frm' is not working for me and it is complicated
> enough
> > that I don't want to work it out. See ?dput for a better way to supply
> data.
> > Also see:
> > https://github.com/hadley/devtools/wiki/Reproducibility
> >  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> > reproducible-example
> >
> > That said, I don't see why 'my.output[4]' is not working.  Try something
> like
> > str(frm) to see what you have there and/or resubmit the data in dput
> format
> >
> > See simple example below:
> >
> > dat1  <- data.frame(aa = sample(1:20, 100, replace = TRUE), bb = 1:100 )
> > dat1[2]
> >
> > John Kane
> > Kingston ON Canada
> >
> >
> > > -----Original Message-----
> > > From: john.posner at mjbiostat.com <javascript:;>
> > > Sent: Fri, 21 Nov 2014 17:10:16 +0000
> > > To: r-help at r-project.org <javascript:;>
> > > Subject: [R] dplyr/summarize does not create a true data frame
> > >
> > > I got an error when trying to extract a 1-column subset of a data
> > > frame (called "my.output") created by dplyr/summarize. The ncol()
> > > function says that my.output has 4 columns, but "my.output[4]" fails.
> > > Note that converting my.output using as.data.frame() makes for a happy
> > ending.
> > >
> > > Is this the intended behavior of dplyr?
> > >
> > > Tx,
> > > John
> > >
> > >> library(dplyr)
> > >
> > >> # set up data frame
> > >> rows = 100
> > >> repcnt = 50
> > >> sexes = c("Female", "Male")
> > >> heights = c("Med", "Short", "Tall")
> > >
> > >> frm = data.frame(
> > > +   Id = paste("P", sprintf("%04d", 1:rows), sep=""),
> > > +   Sex = sample(rep(sexes, repcnt), rows, replace=T),
> > > +   Height = sample(rep(heights, repcnt), rows, replace=T),
> > > +   V1 = round(runif(rows)*25, 2) + 50,
> > > +   V2 = round(runif(rows)*1000, 2) + 50,
> > > +   V3 = round(runif(rows)*350, 2) - 175
> > > + )
> > >>
> > >> # use dplyr/summarize to create data frame my.output = frm %>%
> > > +   group_by(Sex, Height) %>%
> > > +   summarize(V1sum=sum(V1), V2sum=sum(V2))
> > >
> > >> # work with columns in the output data frame
> > >> ncol(my.output)
> > > [1] 4
> > >
> > >> my.output[1]
> > > Source: local data frame [6 x 1]
> > > Groups: Sex
> > >
> > >      Sex
> > > 1 Female
> > > 2 Female
> > > 3 Female
> > > 4   Male
> > > 5   Male
> > > 6   Male
> > >
> > >> my.output[4]
> > > Error in eval(expr, envir, enclos) : index out of bounds  ########
> > > ERROR HERE
> > >
> > >> as.data.frame(my.output)[4]
> > >      V2sum
> > > 1 12427.97
> > > 2  8449.82
> > > 3  8610.97
> > > 4  7249.20
> > > 5 12616.91
> > > 6 10372.15
> > >>
> > >
> > > ______________________________________________
> > > R-help at r-project.org <javascript:;> mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > __________________________________________________________
> > __
> > FREE ONLINE PHOTOSHARING - Share your photos online with your friends
> > and family!
> > Visit http://www.inbox.com/photosharing to find out more!
> >
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
http://had.co.nz/

	[[alternative HTML version deleted]]


From antoviral at gmail.com  Mon Nov 24 00:34:42 2014
From: antoviral at gmail.com (Antonello Preti)
Date: Mon, 24 Nov 2014 00:34:42 +0100
Subject: [R] arcsine transformation with metafor
Message-ID: <CAPmpGDs2JkEOhfHyD5+UX7VyYMHQuoxF8aD_75dBQF7DZsgkYw@mail.gmail.com>

# I'm trying to adapt to my own data the double arcsine transformation
according to Miller (1978) as described in the metafor site
# I've understood all passages (I think)
# I'm able to build a forest plot with the correct data
# I would like to build a funnel plot and a radial plot
# However, the rule that is helpful to build a forest plot does not work
for the radial or the funnel plot
# When I use the results of the fixed (or random) effects model, as
expected, the estimates are wrong (about two times the correct estimates)
# How can the radial and funnel plot be built for the double arcsine
transformation?

# Thank you in advance, Antonello

# Here the code I've used

library(metafor)

# The data used by Miller (1978) to illustrate the transformation and its
inversion can be re-created with:

dat <- data.frame(xi=c(3, 6, 10, 1), ni=c(11, 17, 21, 6))
dat$pi <- with(dat, xi/ni)
dat <- escalc(measure="PFT", xi=xi, ni=ni, data=dat)

dat

# The yi values are the Freeman-Tukey (double arcsine) transformed
proportions,
# while the vi values are the corresponding sampling variances.

# We can check whether the back-transformation works for individual values
with:

transf.ipft(dat$yi, dat$ni)


#  As described by Miller (1978), we can aggregate the transformed values,
# either by computing an unweighted or a weighted mean (with
inverse-variance weights).
# The unweighted mean can be obtained with:

res <- rma(yi, vi, method="FE", data=dat, weighted=FALSE)
res


# The value reported by Miller for the unweighted mean is again twice as
large as the value given above,
# which we can confirm with:

predict(res, transf=function(x) x*2)



# To back-transform the average, a value for the sample size is needed.
# Miller suggests to use the harmonic mean of the individual sample sizes
in the inversion formula.
# This can be accomplished with:

predict(res, transf=transf.ipft.hm, targs=list(ni=dat$ni))


# Since the true proportions appear to be homogeneous (e.g., Q(3)=2.18,
p=.54),
# a more efficient estimate of the true proportion can be obtained by using
inverse-variance weights.
# For this, we first synthesize the transformed values with:

res <- rma(yi, vi, method="FE", data=dat)
res


# Again, the value reported by Miller is twice as large.
# We can back-transform the estimated transformed average with:

predict(res, transf=transf.ipft.hm, targs=list(ni=dat$ni))


# When using the Freeman-Tukey transformation,
# an additional complication arises when using the back-transformation.



# To back-transform the individual proportions, we need the individual
sample sizes:

transf.ipft(dat$yi, dat$ni)


# To back-transform the estimated average transformed proportion,
# we need to use the harmonic mean of the sample sizes:

res <- rma(yi, vi, method="FE", data=dat)
pred <- predict(res, transf=transf.ipft.hm, targs=list(ni=dat$ni))
pred



# To build  a forest plot we need to first obtain the CI bounds of the
individual studies with:

dat.back <- summary(dat, transf=transf.ipft, ni=dat$ni)



# Now the back-transformation is applied to each transformed proportion
with the study-specific sample sizes.
# The yi values are now the back-transformed values (i.e., the raw
proportions)
# and the ci.lb and ci.ub values are the back-transformed 95% CI bounds.1)

# Finally, we can create the forest plot by directly passing the observed
outcomes (i.e., proportions)
# and the CI bounds to the function. Then the back-transformed average with
the corresponding CI bounds obtained earlier
# can be added to the plot with the addpoly() function. We add a couple
tweaks to make the final forest plot look nice:


forest(dat.back$yi, ci.lb=dat.back$ci.lb, ci.ub=dat.back$ci.ub,
       xlim=c(-.5,1.8), alim=c(0,1), ylim=c(-1,8), refline=NA, digits=3,
xlab="Proportion")
addpoly(pred$pred, ci.lb=pred$ci.lb, ci.ub=pred$ci.ub, row=-0.5, digits=3,
mlab="FE Model", efac=1.3)
abline(h=0.5)
text(-0.5, 7, "Study",               pos=4)
text( 1.8, 7, "Proportion [95% CI]", pos=2)


### However, this is wrong

radial(res)
funnel(res)

##  sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
[3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
[5] LC_TIME=Italian_Italy.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] metafor_1.9-3 Matrix_1.1-0  Formula_1.1-1

loaded via a namespace (and not attached):
[1] grid_3.0.2      lattice_0.20-24

	[[alternative HTML version deleted]]


From SHAHROBM at ucmail.uc.edu  Mon Nov 24 04:35:43 2014
From: SHAHROBM at ucmail.uc.edu (Shahrooz, Bahram (shahrobm))
Date: Mon, 24 Nov 2014 03:35:43 +0000
Subject: [R] R 3.1.2 GUI 1.65 Mavericks build (6833) freezes in Yosemite
Message-ID: <05CD682B-AFE8-4406-8814-160BE8A4927F@ucmail.uc.edu>

Hi,

I?ve the latest version of R, which I know is for Mavericks.  I?ve upgraded to Yosemite, and R is acting strangely.

R becomes unresponsive when I try to use ?R File to Source/Load?.  Since this morning, this problem was happening every time that I had a script open, but now the problem has become intermittent.  When this problem came up, I had to kill R and start again.

Now, I?ve started getting the following ?mysterious? messages, which again is intermittent.

2014-11-23 22:14:09.339 R[24870:4519960] plugin com.getdropbox.dropbox.garcon interrupted
2014-11-23 22:14:09.339 R[24870:4522129] Unable to setup extension context - error: Couldn?t communicate with a helper application.

I?ve Xcode version 6.1 (6A1052d).

I was wondering whether any of you have had similar issues, and if you?ve any solutions.  These problems seem to be random.

Thanks in advance for your time,
Bahram


____________________________________________
Bahram M. Shahrooz, Ph.D., P.E., FACI, FASCE, FSEI
Professor of Structural Engineering
University of Cincinnati
College of Engineering and Applied Science
Department of CAECM
765 Baldwin Hall
2850 Campus Way
Cincinnati, OH  45221-0071
Phone: (513) 556-3677
Fax:   (513) 556-2599



	[[alternative HTML version deleted]]


From SHAHROBM at ucmail.uc.edu  Mon Nov 24 04:41:32 2014
From: SHAHROBM at ucmail.uc.edu (Shahrooz, Bahram (shahrobm))
Date: Mon, 24 Nov 2014 03:41:32 +0000
Subject: [R] R 3.1.2 GUI 1.65 Mavericks build (6833) freezes in Yosemite
In-Reply-To: <05CD682B-AFE8-4406-8814-160BE8A4927F@ucmail.uc.edu>
References: <05CD682B-AFE8-4406-8814-160BE8A4927F@ucmail.uc.edu>
Message-ID: <A0E78732-A74C-489B-AF7C-D3D8875AFD31@ucmail.uc.edu>

Sorry, I forgot to mention the following strange message, which again comes up intermittently.

2014-11-23 22:39:36.698 R[25438:4659519] *** WARNING: Method convertPointFromBase: in class NSView is deprecated on 10.7 and later. It should not be used in new applications.

Thanks again,
Bahram

____________________________________________
Bahram M. Shahrooz, Ph.D., P.E., FACI, FASCE, FSEI
Professor of Structural Engineering
University of Cincinnati
College of Engineering and Applied Science
Department of CAECM
765 Baldwin Hall
2850 Campus Way
Cincinnati, OH  45221-0071
Phone: (513) 556-3677
Fax:   (513) 556-2599


On Nov 23, 2014, at 10:35 PM, Shahrooz, Bahram (shahrobm) <SHAHROBM at UCMAIL.UC.EDU<mailto:SHAHROBM at UCMAIL.UC.EDU>> wrote:

Hi,

I?ve the latest version of R, which I know is for Mavericks.  I?ve upgraded to Yosemite, and R is acting strangely.

R becomes unresponsive when I try to use ?R File to Source/Load?.  Since this morning, this problem was happening every time that I had a script open, but now the problem has become intermittent.  When this problem came up, I had to kill R and start again.

Now, I?ve started getting the following ?mysterious? messages, which again is intermittent.

2014-11-23 22:14:09.339 R[24870:4519960] plugin com.getdropbox.dropbox.garcon interrupted
2014-11-23 22:14:09.339 R[24870:4522129] Unable to setup extension context - error: Couldn?t communicate with a helper application.

I?ve Xcode version 6.1 (6A1052d).

I was wondering whether any of you have had similar issues, and if you?ve any solutions.  These problems seem to be random.

Thanks in advance for your time,
Bahram


____________________________________________
Bahram M. Shahrooz, Ph.D., P.E., FACI, FASCE, FSEI
Professor of Structural Engineering
University of Cincinnati
College of Engineering and Applied Science
Department of CAECM
765 Baldwin Hall
2850 Campus Way
Cincinnati, OH  45221-0071
Phone: (513) 556-3677
Fax:   (513) 556-2599




	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Nov 24 06:41:30 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Nov 2014 21:41:30 -0800
Subject: [R] R 3.1.2 GUI 1.65 Mavericks build (6833) freezes in Yosemite
In-Reply-To: <05CD682B-AFE8-4406-8814-160BE8A4927F@ucmail.uc.edu>
References: <05CD682B-AFE8-4406-8814-160BE8A4927F@ucmail.uc.edu>
Message-ID: <811A7ACB-02FF-4201-AB13-0513518E3EDE@comcast.net>

I can reproduce the problem but only once so far. (I never use that GUI menu option.) R hangs with a spinning disc when you choose that option from the GUI menu. It?s a MacGUI specific issue so this is the wrong mailing list. Forwarding to R-Mac-SIG.

(Doesn?t seem to be an XCode issue.)
 Model Identifier:	MacBookPro5,3
  Processor Name:	Intel Core 2 Duo
  Processor Speed:	2.8 GHz
  Memory:	8 GB

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     


? 
David
> On Nov 23, 2014, at 7:35 PM, Shahrooz, Bahram (shahrobm) <SHAHROBM at ucmail.uc.edu> wrote:
> 
> Hi,
> 
> I?ve the latest version of R, which I know is for Mavericks.  I?ve upgraded to Yosemite, and R is acting strangely.
> 
> R becomes unresponsive when I try to use ?R File to Source/Load?.  Since this morning, this problem was happening every time that I had a script open, but now the problem has become intermittent.  When this problem came up, I had to kill R and start again.
> 
> Now, I?ve started getting the following ?mysterious? messages, which again is intermittent.
> 
> 2014-11-23 22:14:09.339 R[24870:4519960] plugin com.getdropbox.dropbox.garcon interrupted
> 2014-11-23 22:14:09.339 R[24870:4522129] Unable to setup extension context - error: Couldn?t communicate with a helper application.
> 
> I?ve Xcode version 6.1 (6A1052d).
> 
> I was wondering whether any of you have had similar issues, and if you?ve any solutions.  These problems seem to be random.
> 
> Thanks in advance for your time,
> Bahram
> 
> 
> ____________________________________________
> Bahram M. Shahrooz, Ph.D., P.E., FACI, FASCE, FSEI
> Professor of Structural Engineering
> University of Cincinnati
> College of Engineering and Applied Science
> Department of CAECM
> 765 Baldwin Hall
> 2850 Campus Way
> Cincinnati, OH  45221-0071
> Phone: (513) 556-3677
> Fax:   (513) 556-2599
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From plessthanpointohfive at gmail.com  Fri Nov 21 20:30:38 2014
From: plessthanpointohfive at gmail.com (Jennifer Sabatier)
Date: Fri, 21 Nov 2014 14:30:38 -0500
Subject: [R] More RGoogleDocs - R1C1 reference style
Message-ID: <CAOxgQ=WOE-+zaeDWBZdKMoU5WqtnAvcBGzNBEhDydFDrUZfE7w@mail.gmail.com>

Thank you all for helping grab data off Google Docs.

Now I have another problem.

When I pull the data all the formulas come into R as R1C1 reference style,
while in Google Docs they're A1 reference style.

As a result, the formulas are strings in the cells, rather than values:


=AND((R[0]C[34]=1),(R[0]C[36]=3),(R[0]C[40]=3))

Now this isn't happening in the example I made up.  It's just happening
with the real data, which I can't even begin to share.

Is there a way to prevent this from happening?

Best,

Jen

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Nov 24 12:22:52 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 24 Nov 2014 12:22:52 +0100
Subject: [R] arcsine transformation with metafor
In-Reply-To: <CAPmpGDs2JkEOhfHyD5+UX7VyYMHQuoxF8aD_75dBQF7DZsgkYw@mail.gmail.com>
References: <CAPmpGDs2JkEOhfHyD5+UX7VyYMHQuoxF8aD_75dBQF7DZsgkYw@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730EFA099D01@UM-MAIL4112.unimaas.nl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Antonello Preti
> Sent: Monday, November 24, 2014 00:35
> To: r-help at r-project.org
> Subject: [R] arcsine transformation with metafor
> 
> # I'm trying to adapt to my own data the double arcsine transformation
> according to Miller (1978) as described in the metafor site
> # I've understood all passages (I think)
> # I'm able to build a forest plot with the correct data
> # I would like to build a funnel plot and a radial plot
> # However, the rule that is helpful to build a forest plot does not work
> for the radial or the funnel plot
> # When I use the results of the fixed (or random) effects model, as
> expected, the estimates are wrong (about two times the correct estimates)
> # How can the radial and funnel plot be built for the double arcsine
> transformation?
> 
> # Thank you in advance, Antonello
> 
> # Here the code I've used
> 
> library(metafor)
> 
> # The data used by Miller (1978) to illustrate the transformation and its
> inversion can be re-created with:
> 
> dat <- data.frame(xi=c(3, 6, 10, 1), ni=c(11, 17, 21, 6))
> dat$pi <- with(dat, xi/ni)
> dat <- escalc(measure="PFT", xi=xi, ni=ni, data=dat)

[SNIP]

> res <- rma(yi, vi, method="FE", data=dat)

[SNIP]
 
> ### However, this is wrong
> 
> radial(res)
> funnel(res)

They are not wrong. The double arcsine transformed values are used for the plotting, not the raw proportions. In particular, the plots are based on 'yi' in:

> dat
  xi ni        pi     yi     vi
1  3 11 0.2727273 0.5695 0.0217
2  6 17 0.3529412 0.6444 0.0143
3 10 21 0.4761905 0.7626 0.0116
4  1  6 0.1666667 0.4758 0.0385

Best,
Wolfgang


From marongiu.luigi at gmail.com  Mon Nov 24 15:18:07 2014
From: marongiu.luigi at gmail.com (Luigi)
Date: Mon, 24 Nov 2014 14:18:07 +0000
Subject: [R] Reading FCS files with flowCore package
In-Reply-To: <54733C73.7020205@gmail.com>
References: <54733C73.7020205@gmail.com>
Message-ID: <54733E1F.5050202@gmail.com>

Dear all,
I would like to use the R's Bioconductor package flowCore to do flow 
cytometry analysis.
I generated a FCS file using the file>export function of the FACSDiva 
Software Version 8 from a BD LSRII machine. I then used the functions:
     file.name <-system.file("extdata", "cd cells_FMO 8_003.fcs", 
package="flowCore")
     x <-read.FCS(file.name, transformation = FALSE)
as shown in the flowCore: data structure package... vignette (20 May 
2014) as available from the internet. However the result is an error:
     >Error in read.FCS(file.name, transformation = FALSE) : ' ' is not 
a valid file
I then used the function:
     isFCSfile("cd cells_FMO 8_003.fcs")
where cd cells_FMO 8_003.fcs is the name of the file. As expected I 
obtained the following message:
     >cd cells_FMO 8_003.fcs FALSE
meaning I reckon that the file is not a FCS. Since I am completely new 
to this kind of analysis but I would not like to use flowJo, could 
anybody tell me how to load the FCS files? In the rest of the file I am 
pasting the beginning of the cd cells_FMO 8_003.fcs file for further 
reference (I can't attach the whole thing or even attaching the file 
because it is too big). From its gibberish I reckon that the encoding is 
probably wrong: I was expecting a flatfile after all not ASCII. Would 
the problem be how the run was exported? FlowJo however recognizes the 
files...
Best regards,
Luigi

==============================
FCS3.0         256    1927    1933 1192532       
0 0 
$BEGINANALYSIS0$ENDANALYSIS0$BEGINSTEXT0$ENDSTEXT0$BEGINDATA1933$ENDDATA1192532 
$FIL180444.fcs$SYSWindows 7 6.1$TOT29765 
$PAR10$MODEL$BYTEORD4,3,2,1$DATATYPEF$NEXTDATA0CREATORBD 
FACSDiva Software Version 8.0TUBE 
NAMEFMO 8$SRCcd cellsEXPERIMENT 
NAMEExperiment_001GUID4171c2f1-427b-4cc5-bf86-39bb76803c48$DATE31-OCT-2014$BTIM16:07:12$ETIM16:09:25SETTINGSCytometerWINDOW 
EXTENSION0.00EXPORT USER NAMELuigiMarongiuEXPORT 
TIME31-OCT-2014-16:07:11FSC ASF0.78AUTOBSTRUE$INST 
$TIMESTEP0.01SPILL3,405-450/50-A,405-655/8-A,405-525/50-A,1,0.0028442147740618787,0.0923076944711957,0,1,0,0.3425525014147933,0.08630456626553264,1APPLY 
COMPENSATIONTRUETHRESHOLDFSC,5000$P1NTime$P1R262144$P1B32$P1E0,0$P1G0.01P1BS0P1MS0$P2NFSC-A$P2R262144$P2B32$P2E0,0$P2V450$P2G1.0P2DISPLAYLINP2BS-1P2MS0$P3NFSC-H$P3R262144$P3B32$P3E0,0$P3V450$P3G1.0P3DISPLAYLINP3BS-1P3MS0$P4NFSC-W$P4R262144$P4B32$P4E0,0$P4V450$P4G1.0P4BS-1P4MS0$P5NSSC-A$P5R262144$P5B32$P5E0,0$P5V319$P5G1.0P5DISPLAYLINP5BS-1P5MS0$P6NSSC-H$P6R262144$P6B32$P6E0,0$P6V319$P6G1.0P6DISPLAYLINP6BS-1P6MS0$P7NSSC-W$P7R262144$P7B32$P7E0,0$P7V319$P7G1.0P7BS-1P7MS0$P8N405-450/50-A$P8Scd8 
- pac 
blue$P8R262144$P8B32$P8E0,0$P8V450$P8G1.0P8DISPLAYLOGP8BS-1P8MS0$P9N405-655/8-A$P9Scd45ra 
- 
q655$P9R262144$P9B32$P9E0,0$P9V450$P9G1.0P9DISPLAYLOGP9BS-1P9MS0$P10N405-525/50-A$P10Sld 
- 
acqua$P10R262144$P10B32$P10E0,0$P10V450$P10G1.0P10DISPLAYLOGP10BS-1P10MS0CST 
BEADS EXPIREDFalse     BHffE???GwI,E p F??gG?    F{? 
D????G?C???BI33GA??G??GA G1?qG?
?G"? B?k?Ab=pB?.BI33E?-?G???E?  Fe??G?h?Fc DN
=?A??C??qBK33F??G?JF?? FV?G{?eF| Bp?Cb=pA?  BM33G??G???G?? 
G???G?;G?? C??REY6?CiO\BO33E??fG?PlE?8 El G?4.E0 
Cp??H?qC!??BQ33FK?G?U?F6  F?G??vF  ?-?RC0? ?J  BTffG^??G?m at G5L 
GH??G???G8? Ap?F??B???BV??F???G??dFr? G8??G???G!? C&?fB?? ??G?BZ  
F???G?)~F?b F???G???F ? ??=pB?W
B    \)B]33F?u?G?0?F?? G?.G?E?G
? B?=pF0fB=?HB_??E???G??dE?( FR?G???FE? Dg????C?z?Ba??F???G???F?? 
F??HG??:F?~ B?u?C#??BA??Bb??G?a?G?G?: G$?OG???G? 
C#??F??=B?ffBhffG??^G???Gw@ G~G?SF?( B?Q?F???CW
BhffF?
(G??OF?? F}v)G???FHL B????b=pB9?
Bi??G?MG?i0G???GD?G?f?G*? B?\)C???CA??Bj  G5[?G?s?GG 
G]?G??!G3 CR{F$HB?G?Bj  F??G?/F? G(?G?G? B
ffGxRC??Bl??E??G???E?? E??G??E? ??=pCtk?@?G?Bn??G???G?cG? 
G/$;G??]G!` B???F??BfG?BzffE??QG?:zE ? F0y G???F/? 
D?E???C???B{??G??\G?)JGz G,?G???G? B?k?G(??B?.B|ffG*<?G??}G? 
F???G??8F?` A?z???L?B?\B|??G?}\G??G???GY
G???G@) C??qGp?CnB~??F??3G??pF? F??G??F?? C?G?F9

etc.


From holtermann at hwwi.org  Mon Nov 24 16:32:04 2014
From: holtermann at hwwi.org (Linus Holtermann)
Date: Mon, 24 Nov 2014 16:32:04 +0100
Subject: [R] PANEL model (MCMC): Equivalent of system GMM in MCMC
Message-ID: <AD0050057515F54084E7D5B93478C8481FC6620732@winxbede39.exchange.xchg>

Dear list members,

I want to fit a PANEL model via MCMC. I am concerned, that I got some covariates that are endogenous. I use MCMC for various reasons, particularly cause I got some spatial dependencies in my model. I am afraid that there are no valid instruments, so i like to apply a procedure that is similiar to system GMM within the MCMC framework. I need to solve the endogeneity problem without IV. Are there any solutions to this kind of problem? Are those implemented in R or are there any codes that might help.

Thanks in advance,


Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org
 
Amtsgericht Hamburg HRB 94303
Gesch?ftsf?hrer: PD Dr. Christian Growitsch | Prof. Dr. Henning V?pel
Prokura: Dipl. Kauffrau Alexis Malchin
Umsatzsteuer-ID: DE 241849425

From jscheun at zoology.up.ac.za  Mon Nov 24 10:08:39 2014
From: jscheun at zoology.up.ac.za (Juan Scheun)
Date: Mon, 24 Nov 2014 11:08:39 +0200
Subject: [R] DOT PLOT help!!
Message-ID: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>

Morning everyone


I am relatively new to R and although there are tons of "how to" websites,
some are just way over my head. I am currently trying to figure out how to
create dot plot graphs with my data, where I have categories (i.e male
/female) and values for each. I would like to display this as categories
on the x axis and all values for each directly above the applicable
category, thus not a scatter graph but in a line above for each.

I have attached a quick picture I found on the internet to demonstrate
roughly what I would like.

Thank you all for your time
Juan Scheun
Department of Zoology and Entomology
University of Pretoria
Lynnwood Road
Hillcrest
Pretoria
South Africa
0002

Cell: +27 76 860 3315
Email: jscheun at zoology.up.ac.za




---------------------------------------------------------------------
This message and attachments are subject to a disclaimer. Please refer to http://www.it.up.ac.za/documentation/governance/disclaimer/ for full details. / Hierdie boodskap en aanhangsels is aan 'n vrywaringsklousule onderhewig. Volledige besonderhede is by http://www.it.up.ac.za/documentation/governance/disclaimer/ beskikbaar.

From AARTI.MUNJAL at ucdenver.edu  Mon Nov 24 07:55:00 2014
From: AARTI.MUNJAL at ucdenver.edu (Munjal, Aarti)
Date: Mon, 24 Nov 2014 06:55:00 +0000
Subject: [R] ASA Stat. Computing & Stat. Graphics Student Paper Competition
	2015
Message-ID: <D0982400.3A0C%aarti.munjal@ucdenver.edu>

Statistical Computing and Statistical Graphics Sections
American Statistical Association

Student Paper Competition 2015

The Statistical Computing and Statistical Graphics Sections of the ASA
are co-sponsoring a student paper competition on the topics of
Statistical Computing and Statistical Graphics.  Students are
encouraged to submit a paper in one of these areas, which might be
original methodological research, some novel computing or graphical
application in statistics, or any other suitable contribution (for
example, a software-related project).  The selected winners will
present their papers in a topic-contributed session at the 2015 Joint
Statistical Meetings.  The Sections will pay registration fees for the
winners as well as a substantial allowance for transportation to the
meetings and lodging.

Anyone who is a student (graduate or undergraduate) on or after
September 1, 2014 is eligible to participate.  An entry must include
an abstract, a six page manuscript (including figures, tables and
references), blinded versions of the abstract and manuscript (with no
authors and no references that easily lead to identifying the
authors), a C.V., and a letter from a faculty member familiar with the
student's work.  The applicant must be the first author of the paper.
The faculty letter must include a verification of the applicant's
student status and, in the case of joint authorship, should indicate
what fraction of the contribution is attributable to the applicant.
We prefer that electronic submissions of papers be in Postscript or
PDF.  All materials must be in English.

Students may submit papers to no more than two sections and may accept
only one section's award. Students must inform both sections applied
to when he or she wins and accepts an award, thereby removing the
student from the award competition for the second section.

All application materials MUST BE RECEIVED by 5:00 PM EST, Sunday,
December 14, 2014 at the address below.  They will be reviewed by the
Student Paper Competition Award committee of the Statistical Computing
and Graphics Sections.  The selection criteria used by the committee
will include innovation and significance of the contribution as well
as the professional quality of the manuscript.  Award announcements
will be made by January 15th, 2015.

Additional important information on the competition can be accessed on
ASA's "Student Paper Competition/Travel Award to Attend the Joint
Statistical Meetings" page at
http://www.amstat.org/sections/studentpaperawards.cfm, or at the
website of the Statistical Computing Section,
http://www.statcomputing.org<http://www.statcomputing.org/>.  Inquiries and application materials
should be emailed or mailed to:

Student Paper Competition
c/o Aarti Munjal
Colorado School of Public Health
University of Colorado Denver
aarti.munjal at ucdenver.edu<mailto:aarti.munjal at ucdenver.edu>

--
Aarti Munjal, PhD
Assistant Research Professor
Department of Biostatistics and Informatics
Colorado School of Public Health
University of Colorado, Denver
Phone: 303-724-6273
aarti.munjal at ucdenver.edu<mailto:aarti.munjal at ucdenver.edu>

	[[alternative HTML version deleted]]


From SHAHROBM at ucmail.uc.edu  Mon Nov 24 14:21:51 2014
From: SHAHROBM at ucmail.uc.edu (Shahrooz, Bahram (shahrobm))
Date: Mon, 24 Nov 2014 13:21:51 +0000
Subject: [R] R 3.1.2 GUI 1.65 Mavericks build (6833) freezes in Yosemite
In-Reply-To: <811A7ACB-02FF-4201-AB13-0513518E3EDE@comcast.net>
References: <05CD682B-AFE8-4406-8814-160BE8A4927F@ucmail.uc.edu>
	<811A7ACB-02FF-4201-AB13-0513518E3EDE@comcast.net>
Message-ID: <1493093D-8D18-4D79-8B10-94109786435E@ucmail.uc.edu>

David:

Thanks for your response and forwarding my question to R-Mac-SIG.

What do you use instead of the GUI menu option that I?v been using?

Thanks,
Bahram

____________________________________________
Bahram M. Shahrooz, Ph.D., P.E., FACI, FASCE, FSEI
Professor of Structural Engineering
University of Cincinnati
College of Engineering and Applied Science
Department of CAECM
765 Baldwin Hall
2850 Campus Way
Cincinnati, OH  45221-0071
Phone: (513) 556-3677
Fax:   (513) 556-2599


On Nov 24, 2014, at 12:41 AM, David Winsemius <dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>> wrote:

I can reproduce the problem but only once so far. (I never use that GUI menu option.) R hangs with a spinning disc when you choose that option from the GUI menu. It?s a MacGUI specific issue so this is the wrong mailing list. Forwarding to R-Mac-SIG.

(Doesn?t seem to be an XCode issue.)
Model Identifier: MacBookPro5,3
 Processor Name: Intel Core 2 Duo
 Processor Speed: 2.8 GHz
 Memory: 8 GB

sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


?
David
On Nov 23, 2014, at 7:35 PM, Shahrooz, Bahram (shahrobm) <SHAHROBM at ucmail.uc.edu<mailto:SHAHROBM at ucmail.uc.edu>> wrote:

Hi,

I?ve the latest version of R, which I know is for Mavericks.  I?ve upgraded to Yosemite, and R is acting strangely.

R becomes unresponsive when I try to use ?R File to Source/Load?.  Since this morning, this problem was happening every time that I had a script open, but now the problem has become intermittent.  When this problem came up, I had to kill R and start again.

Now, I?ve started getting the following ?mysterious? messages, which again is intermittent.

2014-11-23 22:14:09.339 R[24870:4519960] plugin com.getdropbox.dropbox.garcon interrupted
2014-11-23 22:14:09.339 R[24870:4522129] Unable to setup extension context - error: Couldn?t communicate with a helper application.

I?ve Xcode version 6.1 (6A1052d).

I was wondering whether any of you have had similar issues, and if you?ve any solutions.  These problems seem to be random.

Thanks in advance for your time,
Bahram


____________________________________________
Bahram M. Shahrooz, Ph.D., P.E., FACI, FASCE, FSEI
Professor of Structural Engineering
University of Cincinnati
College of Engineering and Applied Science
Department of CAECM
765 Baldwin Hall
2850 Campus Way
Cincinnati, OH  45221-0071
Phone: (513) 556-3677
Fax:   (513) 556-2599



[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA



	[[alternative HTML version deleted]]


From maarten.blaauw at qub.ac.uk  Mon Nov 24 16:10:08 2014
From: maarten.blaauw at qub.ac.uk (Maarten Blaauw)
Date: Mon, 24 Nov 2014 15:10:08 +0000
Subject: [R] Gender balance in R
Message-ID: <54734A50.8090600@qub.ac.uk>

Hi there,

I can't help to notice that the gender balance among R developers and 
ordinary members is extremely skewed (as it is with open source software 
in general).

Have a look at http://www.r-project.org/foundation/memberlist.html - at 
most a handful of women are listed among the 'supporting members', and 
none at all among the 29 'ordinary members'.

On the other hand I personally know many happy R users of both genders.

My questions are thus: Should R developers (and users) be worried that 
the 'other half' is excluded? If so, how could female R users/developers 
be persuaded to become more visible (e.g. added as supporting or 
ordinary members)?

Thanks,

Maarten

-- 
| Dr. Maarten Blaauw
| Lecturer in Chronology
|
| School of Geography, Archaeology & Palaeoecology
| Queen's University Belfast, UK
|
| www  http://www.chrono.qub.ac.uk/blaauw
| tel  +44 (0)28 9097 3895


From salwa_elaty11 at hotmail.com  Mon Nov 24 12:17:26 2014
From: salwa_elaty11 at hotmail.com (salwa_elaty11)
Date: Mon, 24 Nov 2014 13:17:26 +0200
Subject: [R] Help me
Message-ID: <DUB408-EAS2544C3301D0095DC3964E939D720@phx.gbl>

Please any one can help me to find the estimate of 5 parameters for multiple regression model under condition multicolinearity between x's from simulation data suppose n=10 for example
Thanks allot


Sent from Samsung Mobile
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Mon Nov 24 17:55:45 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 24 Nov 2014 08:55:45 -0800
Subject: [R] DOT PLOT help!!
In-Reply-To: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>
References: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>
Message-ID: <CACk-te0aNWzckiQKMFKPHO4TguCPLyNStBTapVwESXPZ6nTc6g@mail.gmail.com>

Juan (and probably many others):

If you are unwilling or unable to learn R by doing some minimal work
on your own, then I think you ought to look for other statistical/data
analysis software; or, alternatively, use R from one of several GUI
interfaces that are available: R Commander, http://www.rcommander.com/
, is one that is well documented and well developed. Pestering us on
this list to tell you how to do everything from the R command line is
unfair to us and a foolish strategy for you. IMO only, of course.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Nov 24, 2014 at 1:08 AM, Juan Scheun <jscheun at zoology.up.ac.za> wrote:
> Morning everyone
>
>
> I am relatively new to R and although there are tons of "how to" websites,
> some are just way over my head. I am currently trying to figure out how to
> create dot plot graphs with my data, where I have categories (i.e male
> /female) and values for each. I would like to display this as categories
> on the x axis and all values for each directly above the applicable
> category, thus not a scatter graph but in a line above for each.
>
> I have attached a quick picture I found on the internet to demonstrate
> roughly what I would like.
>
> Thank you all for your time
> Juan Scheun
> Department of Zoology and Entomology
> University of Pretoria
> Lynnwood Road
> Hillcrest
> Pretoria
> South Africa
> 0002
>
> Cell: +27 76 860 3315
> Email: jscheun at zoology.up.ac.za
>
>
>
>
> ---------------------------------------------------------------------
> This message and attachments are subject to a disclaimer. Please refer to http://www.it.up.ac.za/documentation/governance/disclaimer/ for full details. / Hierdie boodskap en aanhangsels is aan 'n vrywaringsklousule onderhewig. Volledige besonderhede is by http://www.it.up.ac.za/documentation/governance/disclaimer/ beskikbaar.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gunter.berton at gene.com  Mon Nov 24 17:58:10 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 24 Nov 2014 08:58:10 -0800
Subject: [R] Help me
In-Reply-To: <DUB408-EAS2544C3301D0095DC3964E939D720@phx.gbl>
References: <DUB408-EAS2544C3301D0095DC3964E939D720@phx.gbl>
Message-ID: <CACk-te3pYiuFFoBSb=YB=iw1jeBxkXRW+4tWTHbXB4_i9c34ow@mail.gmail.com>

No. See the posting guide link below for how to ask an intelligible
question. Better yet, do your homework (is that what this is?)
yourself:  http://cran.r-project.org/doc/manuals/R-intro.pdf

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Nov 24, 2014 at 3:17 AM, salwa_elaty11
<salwa_elaty11 at hotmail.com> wrote:
> Please any one can help me to find the estimate of 5 parameters for multiple regression model under condition multicolinearity between x's from simulation data suppose n=10 for example
> Thanks allot
>
>
> Sent from Samsung Mobile
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Nov 24 18:34:05 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 24 Nov 2014 12:34:05 -0500
Subject: [R] Gender balance in R
In-Reply-To: <54734A50.8090600@qub.ac.uk>
References: <54734A50.8090600@qub.ac.uk>
Message-ID: <CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>

I took a look at apparent gender among list participants a few years ago:
https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html

Same general thing: very few regular participants on the list were
women. I don't see any sign that that has changed in the last three
years. The bar to participation in the R-help list is much, much lower
than that to become a developer.

It would be interesting to look at the stats for CRAN packages as well.

The very low percentage of regular female participants is one of the
things that keeps me active on this list: to demonstrate that it's not
only men who use R and participate in the community.

(If you decide to do the stats for 2014, be aware that I've been out
on medical leave for the past two months, so the numbers are even
lower than usual.)

Sarah

On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
<maarten.blaauw at qub.ac.uk> wrote:
> Hi there,
>
> I can't help to notice that the gender balance among R developers and
> ordinary members is extremely skewed (as it is with open source software in
> general).
>
> Have a look at http://www.r-project.org/foundation/memberlist.html - at most
> a handful of women are listed among the 'supporting members', and none at
> all among the 29 'ordinary members'.
>
> On the other hand I personally know many happy R users of both genders.
>
> My questions are thus: Should R developers (and users) be worried that the
> 'other half' is excluded? If so, how could female R users/developers be
> persuaded to become more visible (e.g. added as supporting or ordinary
> members)?
>
> Thanks,
>
> Maarten
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From macqueen1 at llnl.gov  Mon Nov 24 18:52:03 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 24 Nov 2014 17:52:03 +0000
Subject: [R] DOT PLOT help!!
In-Reply-To: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>
References: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>
Message-ID: <D098AC83.113A94%macqueen1@llnl.gov>

This example (five groups instead of your two) may be close to what you
are looking for:

  plot( rep(1:5, 20), rnorm(100))

Hopefully the ?trick? is self-evident.

(R-help doesn?t pass on most attachments, so I can?t look at your example)


To improve the labels I would do something like this:

  plot( rep(1:5, 20), rnorm(100), xaxt='n')
  axis(1, at=1:5, labels=letters[1:5])


The help pages you will want to look at include
  ?plot
  ?par

If you haven?t already, look at the Graphical Procedures section of the
R-intro manual that you can download from CRAN.

There is a more advanced function called ?dotchart? that creates dotplots.
It is nice if you can figure out how to use it. When I tried it, it
insisted on being fancier than what I assume you?re looking for. I think
the above, which uses base graphics tools, is easier.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/24/14, 1:08 AM, "Juan Scheun" <jscheun at zoology.up.ac.za> wrote:

>Morning everyone
>
>
>I am relatively new to R and although there are tons of "how to" websites,
>some are just way over my head. I am currently trying to figure out how to
>create dot plot graphs with my data, where I have categories (i.e male
>/female) and values for each. I would like to display this as categories
>on the x axis and all values for each directly above the applicable
>category, thus not a scatter graph but in a line above for each.
>
>I have attached a quick picture I found on the internet to demonstrate
>roughly what I would like.
>
>Thank you all for your time
>Juan Scheun
>Department of Zoology and Entomology
>University of Pretoria
>Lynnwood Road
>Hillcrest
>Pretoria
>South Africa
>0002
>
>Cell: +27 76 860 3315
>Email: jscheun at zoology.up.ac.za
>
>
>
>
>---------------------------------------------------------------------
>This message and attachments are subject to a disclaimer. Please refer to
>http://www.it.up.ac.za/documentation/governance/disclaimer/ for full
>details. / Hierdie boodskap en aanhangsels is aan 'n vrywaringsklousule
>onderhewig. Volledige besonderhede is by
>http://www.it.up.ac.za/documentation/governance/disclaimer/ beskikbaar.


From edoardo.prestianni at gmail.com  Mon Nov 24 19:23:16 2014
From: edoardo.prestianni at gmail.com (Edoardo Prestianni)
Date: Mon, 24 Nov 2014 19:23:16 +0100
Subject: [R] How to print labels and how to add missing label values?
Message-ID: <CAB-RVxTshzXxYDqv13nSgbmpuF1pDB6sLOsy6FZC9QxgYYOExw@mail.gmail.com>

Hello everyone,

Sorry for the "rookie" question but this is really beyond me at the moment.

Here is my problem

I have three datasets I am trying to work on. They're three panels.

They have this variable, 'kecnum', which is present in all the three
datasets, and it looks like it has been labeled in only one of the three
datasets.

When I import the datasets, R gives me a WARNING, stating

[code] value labels (?kecnum?) for ?kecnum? are missing [/code]

for two datasets out of three.


Looking at the tables, you see that the variable grows normally...   (like
1, 1, 2, 2, 3, 3, 4, 4, 5, 5...) in the datasets for which the warning is
given.
For the dataset for which the warning is NOT given, I just have a list of
"NA"


If I use the "describe" command, R prints out just
[code] kecnum : Variable label for variable kecnum [/code]

for all the THREE datasets.


Only using Rstudio I can "see" a difference in the labeling of the variable
between the datasets for which I am "warned" and the one for which I am not
(screenshots attatched)


But I have no idea on how to print that stuff out on a terminal. And most
of all, on how to fix my datasets.


Thank you very much for your time.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: here it is missing.png
Type: image/png
Size: 9446 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141124/2983537b/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: here it is not.png
Type: image/png
Size: 8577 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141124/2983537b/attachment-0001.png>

From edoardo.prestianni at gmail.com  Mon Nov 24 19:32:13 2014
From: edoardo.prestianni at gmail.com (Edoardo Prestianni)
Date: Mon, 24 Nov 2014 19:32:13 +0100
Subject: [R] How to print labels and how to add missing label values?
In-Reply-To: <CAB-RVxTshzXxYDqv13nSgbmpuF1pDB6sLOsy6FZC9QxgYYOExw@mail.gmail.com>
References: <CAB-RVxTshzXxYDqv13nSgbmpuF1pDB6sLOsy6FZC9QxgYYOExw@mail.gmail.com>
Message-ID: <CAB-RVxSgjXnEsvx6njCUH74f9P3OiBUhAeJuH+Yo=qy771Dq3Q@mail.gmail.com>

P.S. huge typo in the e-mail object: I guess I want to print and edit
"value labels", not "label values"



2014-11-24 19:23 GMT+01:00 Edoardo Prestianni <edoardo.prestianni at gmail.com>
:

> Hello everyone,
>
> Sorry for the "rookie" question but this is really beyond me at the moment.
>
> Here is my problem
>
> I have three datasets I am trying to work on. They're three panels.
>
> They have this variable, 'kecnum', which is present in all the three
> datasets, and it looks like it has been labeled in only one of the three
> datasets.
>
> When I import the datasets, R gives me a WARNING, stating
>
> [code] value labels (?kecnum?) for ?kecnum? are missing [/code]
>
> for two datasets out of three.
>
>
> Looking at the tables, you see that the variable grows normally...   (like
> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5...) in the datasets for which the warning is
> given.
> For the dataset for which the warning is NOT given, I just have a list of
> "NA"
>
>
> If I use the "describe" command, R prints out just
> [code] kecnum : Variable label for variable kecnum [/code]
>
> for all the THREE datasets.
>
>
> Only using Rstudio I can "see" a difference in the labeling of the
> variable between the datasets for which I am "warned" and the one for which
> I am not
> (screenshots attatched)
>
>
> But I have no idea on how to print that stuff out on a terminal. And most
> of all, on how to fix my datasets.
>
>
> Thank you very much for your time.
>



-- 
Edoardo Prestianni

	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Mon Nov 24 19:36:58 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Mon, 24 Nov 2014 10:36:58 -0800
Subject: [R] Reading FCS files with flowCore package
In-Reply-To: <54733E1F.5050202@gmail.com>
References: <54733C73.7020205@gmail.com> <54733E1F.5050202@gmail.com>
Message-ID: <54737ACA.8020809@fredhutch.org>

On 11/24/2014 06:18 AM, Luigi wrote:
> Dear all,
> I would like to use the R's Bioconductor package flowCore to do flow cytometry

Please address questions about Bioconductor packages to the Bioconductor support 
site

   https://support.bioconductor.org

and...

> analysis.
> I generated a FCS file using the file>export function of the FACSDiva Software
> Version 8 from a BD LSRII machine. I then used the functions:
>      file.name <-system.file("extdata", "cd cells_FMO 8_003.fcs",
> package="flowCore")

system.file() is used to access files installed in R packages, but probably you 
want to access your own file. Try

   file.name = file.choose()

and selecting the file that you want to iniptu. Verify that the path is correct 
by displaying the result

   file.name

Martin

>      x <-read.FCS(file.name, transformation = FALSE)
> as shown in the flowCore: data structure package... vignette (20 May 2014) as
> available from the internet. However the result is an error:
>      >Error in read.FCS(file.name, transformation = FALSE) : ' ' is not a valid
> file
> I then used the function:
>      isFCSfile("cd cells_FMO 8_003.fcs")
> where cd cells_FMO 8_003.fcs is the name of the file. As expected I obtained the
> following message:
>      >cd cells_FMO 8_003.fcs FALSE
> meaning I reckon that the file is not a FCS. Since I am completely new to this
> kind of analysis but I would not like to use flowJo, could anybody tell me how
> to load the FCS files? In the rest of the file I am pasting the beginning of the
> cd cells_FMO 8_003.fcs file for further reference (I can't attach the whole
> thing or even attaching the file because it is too big). From its gibberish I
> reckon that the encoding is probably wrong: I was expecting a flatfile after all
> not ASCII. Would the problem be how the run was exported? FlowJo however
> recognizes the files...
> Best regards,
> Luigi
>
> ==============================
> FCS3.0         256    1927    1933 1192532 0 0
> $BEGINANALYSIS0$ENDANALYSIS0$BEGINSTEXT0$ENDSTEXT0$BEGINDATA1933$ENDDATA1192532
> $FIL180444.fcs$SYSWindows 7 6.1$TOT29765
> $PAR10$MODEL$BYTEORD4,3,2,1$DATATYPEF$NEXTDATA0CREATORBD FACSDiva
> Software Version 8.0TUBE NAMEFMO 8$SRCcd
> cellsEXPERIMENT
> NAMEExperiment_001GUID4171c2f1-427b-4cc5-bf86-39bb76803c48$DATE31-OCT-2014$BTIM16:07:12$ETIM16:09:25SETTINGSCytometerWINDOW
> EXTENSION0.00EXPORT USER NAMELuigiMarongiuEXPORT
> TIME31-OCT-2014-16:07:11FSC ASF0.78AUTOBSTRUE$INST
> $TIMESTEP0.01SPILL3,405-450/50-A,405-655/8-A,405-525/50-A,1,0.0028442147740618787,0.0923076944711957,0,1,0,0.3425525014147933,0.08630456626553264,1APPLY
> COMPENSATIONTRUETHRESHOLDFSC,5000$P1NTime$P1R262144$P1B32$P1E0,0$P1G0.01P1BS0P1MS0$P2NFSC-A$P2R262144$P2B32$P2E0,0$P2V450$P2G1.0P2DISPLAYLINP2BS-1P2MS0$P3NFSC-H$P3R262144$P3B32$P3E0,0$P3V450$P3G1.0P3DISPLAYLINP3BS-1P3MS0$P4NFSC-W$P4R262144$P4B32$P4E0,0$P4V450$P4G1.0P4BS-1P4MS0$P5NSSC-A$P5R262144$P5B32$P5E0,0$P5V319$P5G1.0P5DISPLAYLINP5BS-1P5MS0$P6NSSC-H$P6R262144$P6B32$P6E0,0$P6V319$P6G1.0P6DISPLAYLINP6BS-1P6MS0$P7NSSC-W$P7R262144$P7B32$P7E0,0$P7V319$P7G1.0P7BS-1P7MS0$P8N405-450/50-A$P8Scd8
> - pac
> blue$P8R262144$P8B32$P8E0,0$P8V450$P8G1.0P8DISPLAYLOGP8BS-1P8MS0$P9N405-655/8-A$P9Scd45ra
> -
> q655$P9R262144$P9B32$P9E0,0$P9V450$P9G1.0P9DISPLAYLOGP9BS-1P9MS0$P10N405-525/50-A$P10Sld
> -
> acqua$P10R262144$P10B32$P10E0,0$P10V450$P10G1.0P10DISPLAYLOGP10BS-1P10MS0CST
> BEADS EXPIREDFalse     BHffE???GwI,E p F??gG?    F{?
> D????G?C???BI33GA??G??GA G1?qG?
> ?G"? B?k?Ab=pB?.BI33E?-?G???E?  Fe??G?h?Fc DN
> =?A??C??qBK33F??G?JF?? FV?G{?eF| Bp?Cb=pA?  BM33G??G???G?? G???G?;G??
> C??REY6?CiO\BO33E??fG?PlE?8 El G?4.E0 Cp??H?qC!??BQ33FK?G?U?F6  F?G??vF
> ?-?RC0? ?J  BTffG^??G?m at G5L GH??G???G8? Ap?F??B???BV??F???G??dFr? G8??G???G!?
> C&?fB?? ??G?BZ F???G?)~F?b F???G???F ? ??=pB?W
> B    \)B]33F?u?G?0?F?? G?.G?E?G
> ? B?=pF0fB=?HB_??E???G??dE?( FR?G???FE? Dg????C?z?Ba??F???G???F??
> F??HG??:F?~ B?u?C#??BA??Bb??G?a?G?G?: G$?OG???G?
> C#??F??=B?ffBhffG??^G???Gw@ G~G?SF?( B?Q?F???CW
> BhffF?
> (G??OF?? F}v)G???FHL B????b=pB9?
> Bi??G?MG?i0G???GD?G?f?G*? B?\)C???CA??Bj  G5[?G?s?GG G]?G??!G3
> CR{F$HB?G?Bj  F??G?/F? G(?G?G? B
> ffGxRC??Bl??E??G???E?? E??G??E? ??=pCtk?@?G?Bn??G???G?cG?
> G/$;G??]G!` B???F??BfG?BzffE??QG?:zE ? F0y G???F/?
> D?E???C???B{??G??\G?)JGz G,?G???G? B?k?G(??B?.B|ffG*<?G??}G?
> F???G??8F?` A?z???L?B?\B|??G?}\G??G???GY
> G???G@) C??qGp?CnB~??F??3G??pF? F??G??F?? C?G?F9
>
> etc.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From jdnewmil at dcn.davis.CA.us  Mon Nov 24 20:21:07 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 24 Nov 2014 11:21:07 -0800
Subject: [R] DOT PLOT help!!
In-Reply-To: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>
References: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>
Message-ID: <16A33C0B-01C3-454F-A896-A0A0EA485A56@dcn.davis.CA.us>

"Some" of the web sites are likely always going to be over your head. The correct strategy is to find some that are within reach, and work your way through them. If you cannot copy some example code into R and execute it from one of the sites that comes up when you search for "R dotplot" (e.g. [1]) then you won't have much success communicating in a mailing list. You really need to be able to give us the sequence of commands you are having trouble with to get useful assistance via email.

One of the biggest stumbling blocks for new R users is understanding data, how it is imported, and how it is stored [2]. It might not seem like the most likely place to start, but the Intro to R document and the Importing Data document that come with R have a treasure trove of useful stuff. If you need more handholding than that then there are quite a few books and online courses.

[1] http://www.statmethods.net/graphs/dot.html
[2] R is interactive..  learn to use the str function and the help system (try typing ?str at the R prompt) to examine variables that examples are using.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 24, 2014 1:08:39 AM PST, Juan Scheun <jscheun at zoology.up.ac.za> wrote:
>Morning everyone
>
>
>I am relatively new to R and although there are tons of "how to"
>websites,
>some are just way over my head. I am currently trying to figure out how
>to
>create dot plot graphs with my data, where I have categories (i.e male
>/female) and values for each. I would like to display this as
>categories
>on the x axis and all values for each directly above the applicable
>category, thus not a scatter graph but in a line above for each.
>
>I have attached a quick picture I found on the internet to demonstrate
>roughly what I would like.
>
>Thank you all for your time
>Juan Scheun
>Department of Zoology and Entomology
>University of Pretoria
>Lynnwood Road
>Hillcrest
>Pretoria
>South Africa
>0002
>
>Cell: +27 76 860 3315
>Email: jscheun at zoology.up.ac.za
>
>
>
>
>---------------------------------------------------------------------
>This message and attachments are subject to a disclaimer. Please refer
>to http://www.it.up.ac.za/documentation/governance/disclaimer/ for full
>details. / Hierdie boodskap en aanhangsels is aan 'n vrywaringsklousule
>onderhewig. Volledige besonderhede is by
>http://www.it.up.ac.za/documentation/governance/disclaimer/ beskikbaar.
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Nov 24 20:27:46 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 24 Nov 2014 11:27:46 -0800
Subject: [R] Reading FCS files with flowCore package
In-Reply-To: <54733E1F.5050202@gmail.com>
References: <54733C73.7020205@gmail.com> <54733E1F.5050202@gmail.com>
Message-ID: <FB6BBA13-3CCF-422D-8E7C-1450208D1350@dcn.davis.CA.us>

Wrong list. See http://www.bioconductor.org/help/support/
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 24, 2014 6:18:07 AM PST, Luigi <marongiu.luigi at gmail.com> wrote:
>Dear all,
>I would like to use the R's Bioconductor package flowCore to do flow 
>cytometry analysis.
>I generated a FCS file using the file>export function of the FACSDiva 
>Software Version 8 from a BD LSRII machine. I then used the functions:
>     file.name <-system.file("extdata", "cd cells_FMO 8_003.fcs", 
>package="flowCore")
>     x <-read.FCS(file.name, transformation = FALSE)
>as shown in the flowCore: data structure package... vignette (20 May 
>2014) as available from the internet. However the result is an error:
>    >Error in read.FCS(file.name, transformation = FALSE) : ' ' is not 
>a valid file
>I then used the function:
>     isFCSfile("cd cells_FMO 8_003.fcs")
>where cd cells_FMO 8_003.fcs is the name of the file. As expected I 
>obtained the following message:
>     >cd cells_FMO 8_003.fcs FALSE
>meaning I reckon that the file is not a FCS. Since I am completely new 
>to this kind of analysis but I would not like to use flowJo, could 
>anybody tell me how to load the FCS files? In the rest of the file I am
>
>pasting the beginning of the cd cells_FMO 8_003.fcs file for further 
>reference (I can't attach the whole thing or even attaching the file 
>because it is too big). From its gibberish I reckon that the encoding
>is 
>probably wrong: I was expecting a flatfile after all not ASCII. Would 
>the problem be how the run was exported? FlowJo however recognizes the 
>files...
>Best regards,
>Luigi
>
>==============================
>FCS3.0         256    1927    1933 1192532       
>0 0 
>>$BEGINANALYSIS>0>$ENDANALYSIS>0>$BEGINSTEXT>0>$ENDSTEXT>0>$BEGINDATA>1933>$ENDDATA>1192532
>
>>$FIL>180444.fcs>$SYS>Windows 7 6.1>$TOT>29765 
>>$PAR>10>$MODE>L>$BYTEORD>4,3,2,1>$DATATYPE>F>$NEXTDATA>0>CREATOR>BD 
>FACSDiva Software Version 8.0>TUBE 
>NAME>FMO 8>$SRC>cd cells>EXPERIMENT 
>NAME>Experiment_001>GUID>4171c2f1-427b-4cc5-bf86-39bb76803c48>$DATE>31-OCT-2014>$BTIM>16:07:12>$ETIM>16:09:25>SETTINGS>Cytometer>WINDOW
>
>EXTENSION>0.00>EXPORT USER NAME>LuigiMarongiu>EXPORT 
>TIME>31-OCT-2014-16:07:11>FSC ASF>0.78>AUTOBS>TRUE>$INST> 
>>$TIMESTEP>0.01>SPILL>3,405-450/50-A,405-655/8-A,405-525/50-A,1,0.0028442147740618787,0.0923076944711957,0,1,0,0.3425525014147933,0.08630456626553264,1>APPLY
>
>COMPENSATION>TRUE>THRESHOLD>FSC,5000>$P1N>Time>$P1R>262144>$P1B>32>$P1E>0,0>$P1G>0.01>P1BS>0>P1MS>0>$P2N>FSC-A>$P2R>262144>$P2B>32>$P2E>0,0>$P2V>450>$P2G>1.0>P2DISPLAY>LIN>P2BS>-1>P2MS>0>$P3N>FSC-H>$P3R>262144>$P3B>32>$P3E>0,0>$P3V>450>$P3G>1.0>P3DISPLAY>LIN>P3BS>-1>P3MS>0>$P4N>FSC-W>$P4R>262144>$P4B>32>$P4E>0,0>$P4V>450>$P4G>1.0>P4BS>-1>P4MS>0>$P5N>SSC-A>$P5R>262144>$P5B>32>$P5E>0,0>$P5V>319>$P5G>1.0>P5DISPLAY>LIN>P5BS>-1>P5MS>0>$P6N>SSC-H>$P6R>262144>$P6B>32>$P6E>0,0>$P6V>319>$P6G>1.0>P6DISPLAY>LIN>P6BS>-1>P6MS>0>$P7N>SSC-W>$P7R>262144>$P7B>32>$P7E>0,0>$P7V>319>$P7G>1.0>P7BS>-1>P7MS>0>$P8N>405-450/50-A>$P8S>cd8
>
>- pac 
>blue>$P8R>262144>$P8B>32>$P8E>0,0>$P8V>450>$P8G>1.0>P8DISPLAY>LOG>P8BS>-1>P8MS>0>$P9N>405-655/8-A>$P9S>cd45ra
>
>- 
>q655>$P9R>262144>$P9B>32>$P9E>0,0>$P9V>450>$P9G>1.0>P9DISPLAY>LOG>P9BS>-1>P9MS>0>$P10N>405-525/50-A>$P10S>ld
>
>- 
>acqua>$P10R>262144>$P10B>32>$P10E>0,0>$P10V>450>$P10G>1.0>P10DISPLAY>LOG>P10BS>-1>P10MS>0>CST
>
>BEADS EXPIRED>False>     BHffE???GwI,E p F??gG?    F{? 
>D????G?C???BI33GA??G??GA G1?qG?
>?G"? B?k?Ab=pB?.BI33E?-?G???E?  Fe??G?h?Fc DN
>=?A??C??qBK33F??G?JF?? FV?G{?eF| Bp?Cb=pA?  BM33G??G???G?? 
>G???G?;G?? C??REY6?CiO\BO33E??fG?PlE?8 El G?4.E0 
>Cp??H?qC!??BQ33FK?G?U?F6  F?G??vF  ?-?RC0? ?J  BTffG^??G?m at G5L 
>GH??G???G8? Ap?F??B???BV??F???G??dFr? G8??G???G!? C&?fB?? ??G?BZ  
>F???G?)~F?b F???G???F ? ??=pB?W
>B    \)B]33F?u?G?0?F?? G?.G?E?G
>? B?=pF0
fB=?HB_??E???G??dE?( FR?G???FE? Dg????C?z?Ba??F???G???F?? 
>F??HG??:F?~ B?u?C#??BA??Bb??G?a?G?G?: G$?OG???G? 
>C#??F??=B?ffBhffG??^G???Gw@ G~G?SF?( B?Q?F???CW
>BhffF?
>(G??OF?? F}v)G???FHL B????b=pB9?
>Bi??G?MG?i0G???GD?G?f?G*? B?\)C???CA??Bj  G5[?G?s?GG 
>G]?G??!G3 CR{F$HB?G?Bj  F??
G?/F?
 G(?G?G>? B
>ffGxRC
??Bl??E??G???E?? E?>?G??E? ??=pCtk?@?G?Bn??G???G?c
G? 
>G/$;G??]G!` B???F?
?BfG?BzffE??QG?:zE ? F0y G???F/? 
>D?E???C???B{??G??\G?)JGz G,?
G???G? B?k?G(??B?.B|ffG*<?G??}G? 
>F???G??8F?` A?z???L?B
?\B|??G?}\G??G???GY
>G???G@) C??qGp?CnB~??F??3G??pF? F??G??F?? C?G?F9
>
>etc.
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Nov 24 20:38:29 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 24 Nov 2014 11:38:29 -0800
Subject: [R] Reading FCS files with flowCore package
In-Reply-To: <54737ACA.8020809@fredhutch.org>
References: <54733C73.7020205@gmail.com> <54733E1F.5050202@gmail.com>
	<54737ACA.8020809@fredhutch.org>
Message-ID: <CAF8bMcaZHJaRP3Ea44mBqDf=aopE=sJuud9SFx55wdhfabWwSg@mail.gmail.com>

If help files used the mustWork=TRUE argument to system.file() this sort of
problem
would become more apparent to the user.  It would give a clear error
message from
system.file() instead of a mysterious error about file "" not being valid
or, worse, a hang
from an input command waiting for the user to type something into standard
input (because
scan() and others treat file="" the same as scan=stdin()).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 24, 2014 at 10:36 AM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

> On 11/24/2014 06:18 AM, Luigi wrote:
>
>> Dear all,
>> I would like to use the R's Bioconductor package flowCore to do flow
>> cytometry
>>
>
> Please address questions about Bioconductor packages to the Bioconductor
> support site
>
>   https://support.bioconductor.org
>
> and...
>
>  analysis.
>> I generated a FCS file using the file>export function of the FACSDiva
>> Software
>> Version 8 from a BD LSRII machine. I then used the functions:
>>      file.name <-system.file("extdata", "cd cells_FMO 8_003.fcs",
>> package="flowCore")
>>
>
> system.file() is used to access files installed in R packages, but
> probably you want to access your own file. Try
>
>   file.name = file.choose()
>
> and selecting the file that you want to iniptu. Verify that the path is
> correct by displaying the result
>
>   file.name
>
> Martin
>
>       x <-read.FCS(file.name, transformation = FALSE)
>> as shown in the flowCore: data structure package... vignette (20 May
>> 2014) as
>> available from the internet. However the result is an error:
>>      >Error in read.FCS(file.name, transformation = FALSE) : ' ' is not
>> a valid
>> file
>> I then used the function:
>>      isFCSfile("cd cells_FMO 8_003.fcs")
>> where cd cells_FMO 8_003.fcs is the name of the file. As expected I
>> obtained the
>> following message:
>>      >cd cells_FMO 8_003.fcs FALSE
>> meaning I reckon that the file is not a FCS. Since I am completely new to
>> this
>> kind of analysis but I would not like to use flowJo, could anybody tell
>> me how
>> to load the FCS files? In the rest of the file I am pasting the beginning
>> of the
>> cd cells_FMO 8_003.fcs file for further reference (I can't attach the
>> whole
>> thing or even attaching the file because it is too big). From its
>> gibberish I
>> reckon that the encoding is probably wrong: I was expecting a flatfile
>> after all
>> not ASCII. Would the problem be how the run was exported? FlowJo however
>> recognizes the files...
>> Best regards,
>> Luigi
>>
>> ==============================
>> FCS3.0         256    1927    1933 1192532 0 0
>> $BEGINANALYSIS 0 $ENDANALYSIS 0 $BEGINSTEXT 0 $ENDSTEXT 0 $BEGINDATA 1933
>> $ENDDATA 1192532
>> $FIL 180444.fcs $SYS Windows 7 6.1 $TOT 29765
>> $PAR 10 $MODE L $BYTEORD 4,3,2,1 $DATATYPE F $NEXTDATA 0 CREATOR BD
>> FACSDiva
>> Software Version 8.0 TUBE NAME FMO 8 $SRC cd
>> cells EXPERIMENT
>> NAME Experiment_001 GUID 4171c2f1-427b-4cc5-bf86-39bb76803c48 $DATE
>> 31-OCT-2014 $BTIM 16:07:12 $ETIM 16:09:25 SETTINGS Cytometer WINDOW
>> EXTENSION 0.00 EXPORT USER NAME LuigiMarongiu EXPORT
>> TIME 31-OCT-2014-16:07:11 FSC ASF 0.78 AUTOBS TRUE $INST
>> $TIMESTEP 0.01 SPILL 3,405-450/50-A,405-655/8-A,405-525/50-A,1,0.
>> 0028442147740618787,0.0923076944711957,0,1,0,0.3425525014147933,0.08630456626553264,1
>> APPLY
>> COMPENSATION TRUE THRESHOLD FSC,5000 $P1N Time $P1R 262144 $P1B 32 $P1E
>> 0,0 $P1G 0.01 P1BS 0 P1MS 0 $P2N FSC-A $P2R 262144 $P2B 32 $P2E 0,0 $P2V
>> 450 $P2G 1.0 P2DISPLAY LIN P2BS -1 P2MS 0 $P3N FSC-H $P3R 262144 $P3B 32
>> $P3E 0,0 $P3V 450 $P3G 1.0 P3DISPLAY LIN P3BS -1 P3MS 0 $P4N FSC-W $P4R
>> 262144 $P4B 32 $P4E 0,0 $P4V 450 $P4G 1.0 P4BS -1 P4MS 0 $P5N SSC-A $P5R
>> 262144 $P5B 32 $P5E 0,0 $P5V 319 $P5G 1.0 P5DISPLAY LIN P5BS -1 P5MS 0 $P6N
>> SSC-H $P6R 262144 $P6B 32 $P6E 0,0 $P6V 319 $P6G 1.0 P6DISPLAY LIN P6BS -1
>> P6MS 0 $P7N SSC-W $P7R 262144 $P7B 32 $P7E 0,0 $P7V 319 $P7G 1.0 P7BS -1
>> P7MS 0 $P8N 405-450/50-A $P8S cd8
>> - pac
>> blue $P8R 262144 $P8B 32 $P8E 0,0 $P8V 450 $P8G 1.0 P8DISPLAY LOG P8BS -1
>> P8MS 0 $P9N 405-655/8-A $P9S cd45ra
>> -
>> q655 $P9R 262144 $P9B 32 $P9E 0,0 $P9V 450 $P9G 1.0 P9DISPLAY LOG P9BS -1
>> P9MS 0 $P10N 405-525/50-A $P10S ld
>> -
>> acqua $P10R 262144 $P10B 32 $P10E 0,0 $P10V 450 $P10G 1.0 P10DISPLAY LOG
>> P10BS -1 P10MS 0 CST
>> BEADS EXPIRED False      BHffE???GwI,E p F ?gG?     F{?
>> D???? G?C???BI33GA??G? ?G A G1?qG?
>> ?G"  B?k?Ab=pB?. BI33E?-?G ??E?  Fe ?G h?Fc  DN
>> =?A??C??qBK33F?? G?J F?? F V?G{?eF | B p?Cb=pA?  BM33G? ?G???G?? G???G?
>> ;G??
>> C??REY6 CiO\BO33E??fG?PlE?8 E l G?4.E 0 C p??H?qC!??BQ33FK? G U?F6  F ?
>> G??vF ?-?RC0? ?J  BTffG^??G m at G5L GH??G???G8? A p?F ?
>> B???BV??F???G??dFr? G8??G???G!?
>> C&?fB?? ? G?BZ F???G?)~F?b F???G ??F ? ??=pB?W
>> B    \)B]33F?u?G?0?F?? G ?.G?E?G
>> ? B?=pF0 fB=?HB_??E???G??dE?( FR? G???FE? Dg??? ? C?z?Ba??F???G? ?F??
>> F??HG ?:F?~ B?u?C#??BA??Bb??G?a?G?  G?: G$?OG???G ?
>> C#??F??=B ffBhffG??^G???Gw@ G  ~G  SF?( B?Q?F???C W
>> BhffF?
>> (G??OF?? F}v)G???FHL B????b=pB9?
>> Bi??G?M G?i0G???GD? G?f?G*? B?\)C???CA??Bj  G5[?G?s?G G G ]?G??!G 3
>> CR {F $HB G?Bj  F?? G?/ F?  G (?G?  G ? B
>> ffG xRC ??Bl??E? ?G?? E?? E? ?G?? E?  ??=pCtk?@ G?Bn??G???G?c G?
>> G/$;G??]G!` B???F? ?BfG?BzffE??QG :zE ? F0y G???F/?
>> D?E ??? C???B{??G??\G?)JGz  G,? G???G ? B k?G(??B?. B|ffG*<?G??}G ?
>> F???G ?8F?` A?z???L?B  \B|??G?}\G?? G ??GY
>> G ??G@) C??qG p?C n B~??F??3G??pF?  F? ?G? ?F?? C G?F9
>>
>> etc.
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From nissimkaufmann at yahoo.com  Mon Nov 24 20:07:51 2014
From: nissimkaufmann at yahoo.com (Nissim Kaufmann)
Date: Mon, 24 Nov 2014 19:07:51 +0000 (UTC)
Subject: [R] list.files() not compatible with all Unicode characters;
 file.exists() is compatible.
Message-ID: <96642237.216372.1416856071710.JavaMail.yahoo@jws10083.mail.ne1.yahoo.com>

Hello,I have some files with strange Unicode characters in their names that I am trying to remove.But list.files() does not return their names faithfully so that I can deal with them.
> list.files()[1] "? text.txt" ? ? ? ? ? ? ? ? ?<--- here you should see a question mark, a space, then text.txt> file.exists("? text.txt") ? ?<----by copying and pasting the output from above[1] FALSE> file.exists('? text.txt') ? ?<--- here you should see a black triangle, what looks like a space, and text.txt[1] TRUE
Documentation for file.exists() and file.access() do not seem to discuss this.
The file name has these Unicode characters:BLACK RIGHT-POINTING TRIANGLE WITH DOUBLE VERTICAL BAR U+23EF BLACK RIGHT-POINTING TRIANGLE WITH DOUBLE VERTICAL BAR ?BLACK RIGHT-POINTING TRIANGLE U+25B6 BLACK RIGHT-POINTING TRIANGLE ?
Thank you!CheersNissim KaufmannNSOL.altervista.org
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Nov 24 21:14:46 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 24 Nov 2014 12:14:46 -0800
Subject: [R] How to print labels and how to add missing label values?
In-Reply-To: <CAB-RVxTshzXxYDqv13nSgbmpuF1pDB6sLOsy6FZC9QxgYYOExw@mail.gmail.com>
References: <CAB-RVxTshzXxYDqv13nSgbmpuF1pDB6sLOsy6FZC9QxgYYOExw@mail.gmail.com>
Message-ID: <B5B18820-B286-43FB-A495-7DAC88720CDF@comcast.net>


On Nov 24, 2014, at 10:23 AM, Edoardo Prestianni wrote:

> Hello everyone,
> 
> Sorry for the "rookie" question but this is really beyond me at the moment.
> 
> Here is my problem
> 
> I have three datasets I am trying to work on. They're three panels.
> 
> They have this variable, 'kecnum', which is present in all the three
> datasets, and it looks like it has been labeled in only one of the three
> datasets.
> 
> When I import the datasets, R gives me a WARNING, stating
> 
> [code] value labels (?kecnum?) for ?kecnum? are missing [/code]

You did not offer the input statements that you used. The warning suggest to me that you are using a function for reading SPSS or SAS data files.. The "here it is not.png" image shows a factor variable, suggesting there was a non-numeric value detected in the automatic guessing process used by the read.* functions, and that a character/integer representation was automatically chosen for only one. The otehr two were all unquoted integers and so came in as integers.

> 
> for two datasets out of three.
> 
> 
> Looking at the tables, you see that the variable grows normally...   (like
> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5...) in the datasets for which the warning is
> given.
> For the dataset for which the warning is NOT given, I just have a list of
> "NA"

 Was there a value in that position in the first line of data?

> 
> 
> If I use the "describe" command, R prints out just
> [code] kecnum : Variable label for variable kecnum [/code]
> for all the THREE datasets.
> 

There must be 5 or six packages with a 'describe' function, and it's clear you are not using the one I typically use.
> 
> Only using Rstudio I can "see" a difference in the labeling of the variable
> between the datasets for which I am "warned" and the one for which I am not
> (screenshots attatched)
> 
> 
> But I have no idea on how to print that stuff out on a terminal. And most
> of all, on how to fix my datasets.

Most people would use the 'str' function.  And if we are to advise on how to fix a dataset, then we would need to know what you consider correct, which you have not yet stated.

> 
> 
> Thank you very much for your time.
> <here it is missing.png><here it is not.png>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mtmorgan at fredhutch.org  Mon Nov 24 21:23:14 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Mon, 24 Nov 2014 12:23:14 -0800
Subject: [R] Reading FCS files with flowCore package
In-Reply-To: <CAF8bMcaZHJaRP3Ea44mBqDf=aopE=sJuud9SFx55wdhfabWwSg@mail.gmail.com>
References: <54733C73.7020205@gmail.com> <54733E1F.5050202@gmail.com>
	<54737ACA.8020809@fredhutch.org>
	<CAF8bMcaZHJaRP3Ea44mBqDf=aopE=sJuud9SFx55wdhfabWwSg@mail.gmail.com>
Message-ID: <547393B2.2000502@fredhutch.org>

On 11/24/2014 11:38 AM, William Dunlap wrote:
> If help files used the mustWork=TRUE argument to system.file() this sort of problem
> would become more apparent to the user.  It would give a clear error message from

or to change the default to mustWork=TRUE, since there are not many use cases 
for querying a non-existent system file?

(one irony I've stumbled across in my own code is to misspell 'mustWork', e.g., 
system.file("foo", mustwork=TRUE), which happily returns "").

Martin

> system.file() instead of a mysterious error about file "" not being valid or,
> worse, a hang
> from an input command waiting for the user to type something into standard input
> (because
> scan() and others treat file="" the same as scan=stdin()).
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Mon, Nov 24, 2014 at 10:36 AM, Martin Morgan <mtmorgan at fredhutch.org
> <mailto:mtmorgan at fredhutch.org>> wrote:
>
>     On 11/24/2014 06:18 AM, Luigi wrote:
>
>         Dear all,
>         I would like to use the R's Bioconductor package flowCore to do flow
>         cytometry
>
>
>     Please address questions about Bioconductor packages to the Bioconductor
>     support site
>
>     https://support.bioconductor.__org <https://support.bioconductor.org>
>
>     and...
>
>         analysis.
>         I generated a FCS file using the file>export function of the FACSDiva
>         Software
>         Version 8 from a BD LSRII machine. I then used the functions:
>         file.name <http://file.name> <-system.file("extdata", "cd cells_FMO
>         8_003.fcs",
>         package="flowCore")
>
>
>     system.file() is used to access files installed in R packages, but probably
>     you want to access your own file. Try
>
>     file.name <http://file.name> = file.choose()
>
>     and selecting the file that you want to iniptu. Verify that the path is
>     correct by displaying the result
>
>     file.name <http://file.name>
>
>     Martin
>
>               x <-read.FCS(file.name <http://file.name>, transformation = FALSE)
>         as shown in the flowCore: data structure package... vignette (20 May
>         2014) as
>         available from the internet. However the result is an error:
>               >Error in read.FCS(file.name <http://file.name>, transformation =
>         FALSE) : ' ' is not a valid
>         file
>         I then used the function:
>               isFCSfile("cd cells_FMO 8_003.fcs")
>         where cd cells_FMO 8_003.fcs is the name of the file. As expected I
>         obtained the
>         following message:
>               >cd cells_FMO 8_003.fcs FALSE
>         meaning I reckon that the file is not a FCS. Since I am completely new
>         to this
>         kind of analysis but I would not like to use flowJo, could anybody tell
>         me how
>         to load the FCS files? In the rest of the file I am pasting the
>         beginning of the
>         cd cells_FMO 8_003.fcs file for further reference (I can't attach the whole
>         thing or even attaching the file because it is too big). From its
>         gibberish I
>         reckon that the encoding is probably wrong: I was expecting a flatfile
>         after all
>         not ASCII. Would the problem be how the run was exported? FlowJo however
>         recognizes the files...
>         Best regards,
>         Luigi
>
>         ==============================
>         FCS3.0         256    1927    1933 1192532 0 0
>         $BEGINANALYSIS0$ENDANALYSIS0$BEGINSTEXT0$ENDSTEXT0$BEGINDATA1933$ENDDATA1192532
>         $FIL180444.fcs$SYSWindows 7 6.1$TOT29765
>         $PAR10$MODEL$BYTEORD4,3,2,1$DATATYPEF$NEXTDATA0CREATORBD
>         FACSDiva
>         Software Version 8.0TUBE NAMEFMO 8$SRCcd
>         cellsEXPERIMENT
>         NAMEExperiment_001GUID4171c2f1-427b-4cc5-bf86-__39bb76803c48$DATE31-OCT-2014$BTIM16:07:12$ETIM16:09:25SETTINGSCytometerWINDOW
>         EXTENSION0.00EXPORT USER NAMELuigiMarongiuEXPORT
>         TIME31-OCT-2014-16:07:11FSC ASF0.78AUTOBSTRUE$INST
>         $TIMESTEP0.01SPILL3,405-450/50-A,405-655/8-A,__405-525/50-A,1,0.__0028442147740618787,0.__0923076944711957,0,1,0,0.__3425525014147933,0.__08630456626553264,1APPLY
>         COMPENSATIONTRUETHRESHOLDFSC,5000$P1NTime$P1R262144$P1B32$P1E0,0$P1G0.01P1BS0P1MS0$P2NFSC-A$P2R262144$P2B32$P2E0,0$P2V450$P2G1.0P2DISPLAYLINP2BS-1P2MS0$P3NFSC-H$P3R262144$P3B32$P3E0,0$P3V450$P3G1.0P3DISPLAYLINP3BS-1P3MS0$P4NFSC-W$P4R262144$P4B32$P4E0,0$P4V450$P4G1.0P4BS-1P4MS0$P5NSSC-A$P5R262144$P5B32$P5E0,0$P5V319$P5G1.0P5DISPLAYLINP5BS-1P5MS0$P6NSSC-H$P6R262144$P6B32$P6E0,0$P6V319$P6G1.0P6DISPLAYLINP6BS-1P6MS0$P7NSSC-W$P7R262144$P7B32$P7E0,0$P7V319$P7G1.0P7BS-1P7MS0$P8N405-450/50-A$P8Scd8
>         - pac
>         blue$P8R262144$P8B32$P8E0,0$P8V450$P8G1.0P8DISPLAYLOGP8BS-1P8MS0$P9N405-655/8-A$P9Scd45ra
>         -
>         q655$P9R262144$P9B32$P9E0,0$P9V450$P9G1.0P9DISPLAYLOGP9BS-1P9MS0$P10N405-525/50-A$P10Sld
>         -
>         acqua$P10R262144$P10B32$P10E0,0$P10V450$P10G1.0P10DISPLAYLOGP10BS-1P10MS0CST
>         BEADS EXPIREDFalse     BHffE???GwI,E p F ?gG?     F{?
>         D???? G?C???BI33GA??G? ?G A G1?qG?
>         ?G"  B?k?Ab=pB?. BI33E?-?G ??E?  Fe ?G h?Fc  DN
>         =?A??C??qBK33F?? G?J F?? F V?G{?eF | B p?Cb=pA?  BM33G? ?G???G?? G???G? ;G??
>         C??REY6 CiO\BO33E??fG?PlE?8 E l G?4.E 0 C p??H?qC!??BQ33FK? G U?F6  F ?
>         G??vF ?-?RC0? ?J  BTffG^??G m at G5L GH??G???G8? A p?F ?
>         B???BV??F???G??dFr? G8??G???G!?
>         C&?fB?? ? G?BZ F???G?)~F?b F???G ??F ? ??=pB?W
>         B    \)B]33F?u?G?0?F?? G ?.G?E?G
>         ? B?=pF0 fB=?HB_??E???G??dE?( FR? G???FE? Dg??? ? C?z?Ba??F???G? ?F??
>         F??HG ?:F?~ B?u?C#??BA??Bb??G?a?G?  G?: G$?OG???G ?
>         C#??F??=B ffBhffG??^G???Gw@ G  ~G  SF?( B?Q?F???C W
>         BhffF?
>         (G??OF?? F}v)G???FHL B????b=pB9?
>         Bi??G?M G?i0G???GD? G?f?G*? B?\)C???CA??Bj  G5[?G?s?G G G ]?G??!G 3
>         CR {F $HB G?Bj  F?? G?/ F?  G (?G?  G? B
>         ffG xRC ??Bl??E? ?G?? E?? E? ?G?? E?  ??=pCtk?@ G?Bn??G???G?c G?
>         G/$;G??]G!` B???F? ?BfG?BzffE??QG :zE ? F0y G???F/?
>         D?E ??? C???B{??G??\G?)JGz  G,? G???G ? B k?G(??B?. B|ffG*<?G??}G ?
>         F???G ?8F?` A?z???L?B  \B|??G?}\G?? G ??GY
>         G ??G@) C??qG p?C n B~??F??3G??pF?  F? ?G? ?F?? C G?F9
>
>         etc.
>
>
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     --
>     Computational Biology / Fred Hutchinson Cancer Research Center
>     1100 Fairview Ave. N.
>     PO Box 19024 Seattle, WA 98109
>
>     Location: Arnold Building M1 B861
>     Phone: (206) 667-2793 <tel:%28206%29%20667-2793>
>
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From wdunlap at tibco.com  Mon Nov 24 21:41:25 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 24 Nov 2014 12:41:25 -0800
Subject: [R] Reading FCS files with flowCore package
In-Reply-To: <547393B2.2000502@fredhutch.org>
References: <54733C73.7020205@gmail.com> <54733E1F.5050202@gmail.com>
	<54737ACA.8020809@fredhutch.org>
	<CAF8bMcaZHJaRP3Ea44mBqDf=aopE=sJuud9SFx55wdhfabWwSg@mail.gmail.com>
	<547393B2.2000502@fredhutch.org>
Message-ID: <CAF8bMcaAMAfPNEsJPyFsYxSQDjphaoE+4wnwKjugOkA8FS9OCQ@mail.gmail.com>

> or to change the default to mustWork=TRUE, since there are not
> many use cases for querying a non-existent system file?

There are a fair number of packages depending on the current semantics.
E.g.
  ./proxy/R/dissimilarities.R:    if (system.file(package="cba") == "")
  ./openNLP/R/pos.R:                      if(system.file(package = package)
== "") {
  ./relations/R/plot.R:    if(system.file(package = "Rgraphviz") == "")
  ./e1071/R/bclust.R:        if (system.file(package = "cluster") == "")
  ./repmis/R/utils.R:     idx = mapply(system.file, package = x) == ''
In most of those, the next statement is stop("package <name> is required")
but
in the last there is only a warning.

> (one irony I've stumbled across in my own code is to misspell 'mustWork',
> e.g., system.file("foo", mustwork=TRUE), which happily returns "").

I've run into the same issue.  Functions with ... in the argument list
often let
things go by that should not.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 24, 2014 at 12:23 PM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

> On 11/24/2014 11:38 AM, William Dunlap wrote:
>
>> If help files used the mustWork=TRUE argument to system.file() this sort
>> of problem
>> would become more apparent to the user.  It would give a clear error
>> message from
>>
>
> or to change the default to mustWork=TRUE, since there are not many use
> cases for querying a non-existent system file?
>
> (one irony I've stumbled across in my own code is to misspell 'mustWork',
> e.g., system.file("foo", mustwork=TRUE), which happily returns "").
>
> Martin
>
>  system.file() instead of a mysterious error about file "" not being valid
>> or,
>> worse, a hang
>> from an input command waiting for the user to type something into
>> standard input
>> (because
>> scan() and others treat file="" the same as scan=stdin()).
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com>
>>
>> On Mon, Nov 24, 2014 at 10:36 AM, Martin Morgan <mtmorgan at fredhutch.org
>> <mailto:mtmorgan at fredhutch.org>> wrote:
>>
>>     On 11/24/2014 06:18 AM, Luigi wrote:
>>
>>         Dear all,
>>         I would like to use the R's Bioconductor package flowCore to do
>> flow
>>         cytometry
>>
>>
>>     Please address questions about Bioconductor packages to the
>> Bioconductor
>>     support site
>>
>>     https://support.bioconductor.__org <https://support.bioconductor.org>
>>
>>     and...
>>
>>         analysis.
>>         I generated a FCS file using the file>export function of the
>> FACSDiva
>>         Software
>>         Version 8 from a BD LSRII machine. I then used the functions:
>>         file.name <http://file.name> <-system.file("extdata", "cd
>> cells_FMO
>>         8_003.fcs",
>>         package="flowCore")
>>
>>
>>     system.file() is used to access files installed in R packages, but
>> probably
>>     you want to access your own file. Try
>>
>>     file.name <http://file.name> = file.choose()
>>
>>     and selecting the file that you want to iniptu. Verify that the path
>> is
>>     correct by displaying the result
>>
>>     file.name <http://file.name>
>>
>>     Martin
>>
>>               x <-read.FCS(file.name <http://file.name>, transformation
>> = FALSE)
>>         as shown in the flowCore: data structure package... vignette (20
>> May
>>         2014) as
>>         available from the internet. However the result is an error:
>>               >Error in read.FCS(file.name <http://file.name>,
>> transformation =
>>         FALSE) : ' ' is not a valid
>>         file
>>         I then used the function:
>>               isFCSfile("cd cells_FMO 8_003.fcs")
>>         where cd cells_FMO 8_003.fcs is the name of the file. As expected
>> I
>>         obtained the
>>         following message:
>>               >cd cells_FMO 8_003.fcs FALSE
>>         meaning I reckon that the file is not a FCS. Since I am
>> completely new
>>         to this
>>         kind of analysis but I would not like to use flowJo, could
>> anybody tell
>>         me how
>>         to load the FCS files? In the rest of the file I am pasting the
>>         beginning of the
>>         cd cells_FMO 8_003.fcs file for further reference (I can't attach
>> the whole
>>         thing or even attaching the file because it is too big). From its
>>         gibberish I
>>         reckon that the encoding is probably wrong: I was expecting a
>> flatfile
>>         after all
>>         not ASCII. Would the problem be how the run was exported? FlowJo
>> however
>>         recognizes the files...
>>         Best regards,
>>         Luigi
>>
>>         ==============================
>>         FCS3.0         256    1927    1933 1192532 0 0
>>         $BEGINANALYSIS 0 $ENDANALYSIS 0 $BEGINSTEXT 0 $ENDSTEXT 0
>> $BEGINDATA 1933 $ENDDATA 1192532
>>         $FIL 180444.fcs $SYS Windows 7 6.1 $TOT 29765
>>         $PAR 10 $MODE L $BYTEORD 4,3,2,1 $DATATYPE F $NEXTDATA 0 CREATOR
>> BD
>>         FACSDiva
>>         Software Version 8.0 TUBE NAME FMO 8 $SRC cd
>>         cells EXPERIMENT
>>         NAME Experiment_001 GUID 4171c2f1-427b-4cc5-bf86-__39bb76803c48
>> $DATE 31-OCT-2014 $BTIM 16:07:12 $ETIM 16:09:25 SETTINGS Cytometer WINDOW
>>         EXTENSION 0.00 EXPORT USER NAME LuigiMarongiu EXPORT
>>         TIME 31-OCT-2014-16:07:11 FSC ASF 0.78 AUTOBS TRUE $INST
>>         $TIMESTEP 0.01 SPILL 3,405-450/50-A,405-655/8-A,__
>> 405-525/50-A,1,0.__0028442147740618787,0.__0923076944711957,0,1,0,0.__
>> 3425525014147933,0.__08630456626553264,1 APPLY
>>         COMPENSATION TRUE THRESHOLD FSC,5000 $P1N Time $P1R 262144 $P1B
>> 32 $P1E 0,0 $P1G 0.01 P1BS 0 P1MS 0 $P2N FSC-A $P2R 262144 $P2B 32 $P2E 0,0
>> $P2V 450 $P2G 1.0 P2DISPLAY LIN P2BS -1 P2MS 0 $P3N FSC-H $P3R 262144 $P3B
>> 32 $P3E 0,0 $P3V 450 $P3G 1.0 P3DISPLAY LIN P3BS -1 P3MS 0 $P4N FSC-W $P4R
>> 262144 $P4B 32 $P4E 0,0 $P4V 450 $P4G 1.0 P4BS -1 P4MS 0 $P5N SSC-A $P5R
>> 262144 $P5B 32 $P5E 0,0 $P5V 319 $P5G 1.0 P5DISPLAY LIN P5BS -1 P5MS 0 $P6N
>> SSC-H $P6R 262144 $P6B 32 $P6E 0,0 $P6V 319 $P6G 1.0 P6DISPLAY LIN P6BS -1
>> P6MS 0 $P7N SSC-W $P7R 262144 $P7B 32 $P7E 0,0 $P7V 319 $P7G 1.0 P7BS -1
>> P7MS 0 $P8N 405-450/50-A $P8S cd8
>>         - pac
>>         blue $P8R 262144 $P8B 32 $P8E 0,0 $P8V 450 $P8G 1.0 P8DISPLAY LOG
>> P8BS -1 P8MS 0 $P9N 405-655/8-A $P9S cd45ra
>>         -
>>         q655 $P9R 262144 $P9B 32 $P9E 0,0 $P9V 450 $P9G 1.0 P9DISPLAY LOG
>> P9BS -1 P9MS 0 $P10N 405-525/50-A $P10S ld
>>         -
>>         acqua $P10R 262144 $P10B 32 $P10E 0,0 $P10V 450 $P10G 1.0
>> P10DISPLAY LOG P10BS -1 P10MS 0 CST
>>         BEADS EXPIRED False      BHffE???GwI,E p F ?gG?     F{?
>>         D???? G?C???BI33GA??G? ?G A G1?qG?
>>         ?G"  B?k?Ab=pB?. BI33E?-?G ??E?  Fe ?G h?Fc  DN
>>         =?A??C??qBK33F?? G?J F?? F V?G{?eF | B p?Cb=pA?  BM33G? ?G???G??
>> G???G? ;G??
>>         C??REY6 CiO\BO33E??fG?PlE?8 E l G?4.E 0 C p??H?qC!??BQ33FK? G
>> U?F6  F ?
>>         G??vF ?-?RC0? ?J  BTffG^??G m at G5L GH??G???G8? A p?F ?
>>         B???BV??F???G??dFr? G8??G???G!?
>>         C&?fB?? ? G?BZ F???G?)~F?b F???G ??F ? ??=pB?W
>>         B    \)B]33F?u?G?0?F?? G ?.G?E?G
>>         ? B?=pF0 fB=?HB_??E???G??dE?( FR? G???FE? Dg??? ? C?z?Ba??F???G?
>> ?F??
>>         F??HG ?:F?~ B?u?C#??BA??Bb??G?a?G?  G?: G$?OG???G ?
>>         C#??F??=B ffBhffG??^G???Gw@ G  ~G  SF?( B?Q?F???C W
>>         BhffF?
>>         (G??OF?? F}v)G???FHL B????b=pB9?
>>         Bi??G?M G?i0G???GD? G?f?G*? B?\)C???CA??Bj  G5[?G?s?G G G ]?G??!G
>> 3
>>         CR {F $HB G?Bj  F?? G?/ F?  G (?G?  G ? B
>>         ffG xRC ??Bl??E? ?G?? E?? E? ?G?? E?  ??=pCtk?@ G?Bn??G???G?c G?
>>         G/$;G??]G!` B???F? ?BfG?BzffE??QG :zE ? F0y G???F/?
>>         D?E ??? C???B{??G??\G?)JGz  G,? G???G ? B k?G(??B?. B|ffG*<?G??}G
>> ?
>>         F???G ?8F?` A?z???L?B  \B|??G?}\G?? G ??GY
>>         G ??G@) C??qG p?C n B~??F??3G??pF?  F? ?G? ?F?? C G?F9
>>
>>         etc.
>>
>>
>>
>>         ________________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         https://stat.ethz.ch/mailman/__listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/__posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>     --
>>     Computational Biology / Fred Hutchinson Cancer Research Center
>>     1100 Fairview Ave. N.
>>     PO Box 19024 Seattle, WA 98109
>>
>>     Location: Arnold Building M1 B861
>>     Phone: (206) 667-2793 <tel:%28206%29%20667-2793>
>>
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Tue Nov 25 00:12:47 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Mon, 24 Nov 2014 18:12:47 -0500
Subject: [R] More elegant way of stacking the data
Message-ID: <CAN2xGJaAZO4m8d6J=_ztZ0HzjsrTLaD+S_pPpcjVw0p4XK=wjg@mail.gmail.com>

I have the data frame 'df' and my desired solution 'out'.
I am sure there is a more elegant R-way to do it - without a loop.

df = data.frame(a=1:5,b=letters[1:5],c1=1:5,c2=2:6,c3=3:7,c4=4:8)
mylist=NULL
for(i in 1:4){
  myname<-paste("c",i,sep="")
  mylist[[i]]<-df[c("a","b",myname)]
  names(mylist[[i]])<-c("a","b","c")
}
out<-do.call(rbind,mylist)
out

Thank you!

-- 
Dimitri Liakhovitski


From dwinsemius at comcast.net  Tue Nov 25 00:28:46 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 24 Nov 2014 15:28:46 -0800
Subject: [R] More elegant way of stacking the data
In-Reply-To: <CAN2xGJaAZO4m8d6J=_ztZ0HzjsrTLaD+S_pPpcjVw0p4XK=wjg@mail.gmail.com>
References: <CAN2xGJaAZO4m8d6J=_ztZ0HzjsrTLaD+S_pPpcjVw0p4XK=wjg@mail.gmail.com>
Message-ID: <8EA3FE72-0263-4428-9625-544B0E263C8E@comcast.net>


On Nov 24, 2014, at 3:12 PM, Dimitri Liakhovitski wrote:

> I have the data frame 'df' and my desired solution 'out'.
> I am sure there is a more elegant R-way to do it - without a loop.
> 
> df = data.frame(a=1:5,b=letters[1:5],c1=1:5,c2=2:6,c3=3:7,c4=4:8)
> mylist=NULL
> for(i in 1:4){
>  myname<-paste("c",i,sep="")
>  mylist[[i]]<-df[c("a","b",myname)]
>  names(mylist[[i]])<-c("a","b","c")
> }
> out<-do.call(rbind,mylist)
> out
> 

Observe the wonders of recycling in dataframes. If you wanted to drop the last column from this it would be the same modulo changing one column nmae.

 cbind( df[1:2], stack(df[-c(1:2)] )  )
#
   a b values ind
1  1 a      1  c1
2  2 b      2  c1
3  3 c      3  c1
4  4 d      4  c1
5  5 e      5  c1
6  1 a      2  c2
7  2 b      3  c2
8  3 c      4  c2
9  4 d      5  c2
10 5 e      6  c2
11 1 a      3  c3
12 2 b      4  c3
13 3 c      5  c3
14 4 d      6  c3
15 5 e      7  c3
16 1 a      4  c4
17 2 b      5  c4
18 3 c      6  c4
19 4 d      7  c4
20 5 e      8  c4

-- 

David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Tue Nov 25 02:10:04 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Tue, 25 Nov 2014 01:10:04 +0000
Subject: [R] DOT PLOT help!!
In-Reply-To: <16A33C0B-01C3-454F-A896-A0A0EA485A56@dcn.davis.CA.us>
References: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>
	<16A33C0B-01C3-454F-A896-A0A0EA485A56@dcn.davis.CA.us>
Message-ID: <D099122D.113B1E%macqueen1@llnl.gov>

Turns out that
  stripchart()
is the easiest way to get what I believe the OP is looking for.

Here is some example data

tmp <- data.frame( g=sample(c('M','F'), 25, replace=TRUE),
                   val = runif(25, 1, 10))


Then:
  stripchart(val ~ g, data=tmp, vertical=TRUE)
or with some improvement to aesthetics:
  stripchart(val ~ g, data=tmp, vertical=TRUE, xlim=c(0.5, 2.5))


This was actually not easy to find, and I am a very experienced R user.
  help.search('dotplot')
did not find it.
  require(sos)
  findFn('dotplot')
did not find it.

This is despite the fact that
  ?stripchart
refers to itself as a function to create "dot plots".

(So I do not think the OP should be chided for having difficulty)


I did not find
  dotchart()
to be useful, because it has a different concept of "dot plot", and I
could not easily find a way to make it do the version I believe the OP
wants. Unfortunately, that's what internet searching for "R dotplot" tends
to lead to.

Of course, if I misunderstand the OP request, this is so much blather!

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/24/14, 11:21 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

>"Some" of the web sites are likely always going to be over your head. The
>correct strategy is to find some that are within reach, and work your way
>through them. If you cannot copy some example code into R and execute it
>from one of the sites that comes up when you search for "R dotplot" (e.g.
>[1]) then you won't have much success communicating in a mailing list.
>You really need to be able to give us the sequence of commands you are
>having trouble with to get useful assistance via email.
>
>One of the biggest stumbling blocks for new R users is understanding
>data, how it is imported, and how it is stored [2]. It might not seem
>like the most likely place to start, but the Intro to R document and the
>Importing Data document that come with R have a treasure trove of useful
>stuff. If you need more handholding than that then there are quite a few
>books and online courses.
>
>[1] http://www.statmethods.net/graphs/dot.html
>[2] R is interactive..  learn to use the str function and the help system
>(try typing ?str at the R prompt) to examine variables that examples are
>using.
>--------------------------------------------------------------------------
>-
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.
>rocks...1k
>--------------------------------------------------------------------------
>- 
>Sent from my phone. Please excuse my brevity.
>
>On November 24, 2014 1:08:39 AM PST, Juan Scheun
><jscheun at zoology.up.ac.za> wrote:
>>Morning everyone
>>
>>
>>I am relatively new to R and although there are tons of "how to"
>>websites,
>>some are just way over my head. I am currently trying to figure out how
>>to
>>create dot plot graphs with my data, where I have categories (i.e male
>>/female) and values for each. I would like to display this as
>>categories
>>on the x axis and all values for each directly above the applicable
>>category, thus not a scatter graph but in a line above for each.
>>
>>I have attached a quick picture I found on the internet to demonstrate
>>roughly what I would like.
>>
>>Thank you all for your time
>>Juan Scheun
>>Department of Zoology and Entomology
>>University of Pretoria
>>Lynnwood Road
>>Hillcrest
>>Pretoria
>>South Africa
>>0002
>>
>>Cell: +27 76 860 3315
>>Email: jscheun at zoology.up.ac.za
>>
>>
>>
>>
>>---------------------------------------------------------------------
>>This message and attachments are subject to a disclaimer. Please refer
>>to http://www.it.up.ac.za/documentation/governance/disclaimer/ for full
>>details. / Hierdie boodskap en aanhangsels is aan 'n vrywaringsklousule
>>onderhewig. Volledige besonderhede is by
>>http://www.it.up.ac.za/documentation/governance/disclaimer/ beskikbaar.
>>
>>
>>------------------------------------------------------------------------
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Tue Nov 25 02:25:32 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Tue, 25 Nov 2014 01:25:32 +0000
Subject: [R] list.files() not compatible with all Unicode characters;
 file.exists() is compatible.
In-Reply-To: <96642237.216372.1416856071710.JavaMail.yahoo@jws10083.mail.ne1.yahoo.com>
References: <96642237.216372.1416856071710.JavaMail.yahoo@jws10083.mail.ne1.yahoo.com>
Message-ID: <D0991A42.113B4B%macqueen1@llnl.gov>

Sorry, your email was undecipherable because you sent HTML formatted email.
Please send plain text

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/24/14, 11:07 AM, "Nissim Kaufmann" <nissimkaufmann at yahoo.com> wrote:

>Hello,I have some files with strange Unicode characters in their names
>that I am trying to remove.But list.files() does not return their names
>faithfully so that I can deal with them.
>> list.files()[1] "? text.txt"                  <--- here you should see
>>a question mark, a space, then text.txt> file.exists("? text.txt")
>><----by copying and pasting the output from above[1] FALSE>
>>file.exists('? text.txt')    <--- here you should see a black triangle,
>>what looks like a space, and text.txt[1] TRUE
>Documentation for file.exists() and file.access() do not seem to discuss
>this.
>The file name has these Unicode characters:BLACK RIGHT-POINTING TRIANGLE
>WITH DOUBLE VERTICAL BAR U+23EF BLACK RIGHT-POINTING TRIANGLE WITH DOUBLE
>VERTICAL BAR ?BLACK RIGHT-POINTING TRIANGLE U+25B6 BLACK RIGHT-POINTING
>TRIANGLE ?
>Thank you!CheersNissim KaufmannNSOL.altervista.org
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Nov 25 07:53:37 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Nov 2014 06:53:37 +0000
Subject: [R] list.files() not compatible with all Unicode characters;
 file.exists() is compatible.
In-Reply-To: <D0991A42.113B4B%macqueen1@llnl.gov>
References: <96642237.216372.1416856071710.JavaMail.yahoo@jws10083.mail.ne1.yahoo.com>
	<D0991A42.113B4B%macqueen1@llnl.gov>
Message-ID: <54742771.5020903@stats.ox.ac.uk>

On 25/11/2014 01:25, MacQueen, Don wrote:
> Sorry, your email was undecipherable because you sent HTML formatted email.
> Please send plain text
>

Also, the 'at a minimum' information requested by the posting guide is 
essential here (which OS and locale, in particular).  In general file 
names not in the locale's encoding are unsupported.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jdnewmil at dcn.davis.CA.us  Tue Nov 25 07:35:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 24 Nov 2014 22:35:48 -0800
Subject: [R] More RGoogleDocs - R1C1 reference style
In-Reply-To: <CAOxgQ=WOE-+zaeDWBZdKMoU5WqtnAvcBGzNBEhDydFDrUZfE7w@mail.gmail.com>
References: <CAOxgQ=WOE-+zaeDWBZdKMoU5WqtnAvcBGzNBEhDydFDrUZfE7w@mail.gmail.com>
Message-ID: <996A2005-9CF0-43E9-BB65-B935BA676B29@dcn.davis.CA.us>

You appear to be using a package that are not even on CRAN, much less base R, so you need to tell us that in your (missing) reproducible example. It is self-described as "primitive", so don't be surprised when it acts odd.

Note that your creation of an exposed Google account in your previous thread violates your terms of service with Google.. they provide perfectly straightforward mechanisms for sharing individual documents publicly without creating opportunities for abuse or risking your other data.

Please do read the footer of any message on this list:

>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html

which says, among other things, that you should be posting in plain text on this list.
Also note:

>and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 21, 2014 11:30:38 AM PST, Jennifer Sabatier <plessthanpointohfive at gmail.com> wrote:
>Thank you all for helping grab data off Google Docs.
>
>Now I have another problem.
>
>When I pull the data all the formulas come into R as R1C1 reference
>style,
>while in Google Docs they're A1 reference style.
>
>As a result, the formulas are strings in the cells, rather than values:
>
>
>=AND((R[0]C[34]=1),(R[0]C[36]=3),(R[0]C[40]=3))
>
>Now this isn't happening in the example I made up.  It's just happening
>with the real data, which I can't even begin to share.
>
>Is there a way to prevent this from happening?
>
>Best,
>
>Jen
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Rainer at krugs.de  Tue Nov 25 10:15:57 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 25 Nov 2014 10:15:57 +0100
Subject: [R] Gender balance in R
In-Reply-To: <CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
	(Sarah Goslee's message of "Mon, 24 Nov 2014 12:34:05 -0500")
References: <54734A50.8090600@qub.ac.uk>
	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
Message-ID: <m2sih7tzci.fsf@krugs.de>

Sarah Goslee <sarah.goslee at gmail.com> writes:

> I took a look at apparent gender among list participants a few years ago:
> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
>
> Same general thing: very few regular participants on the list were
> women. I don't see any sign that that has changed in the last three
> years. The bar to participation in the R-help list is much, much lower
> than that to become a developer.
>
> It would be interesting to look at the stats for CRAN packages as well.
>
> The very low percentage of regular female participants is one of the
> things that keeps me active on this list: to demonstrate that it's not
> only men who use R and participate in the community.

Apart from that, your input is very valuable and your answers very
hands-on helpful - and this is why I am glad that you are on the list -
and not because you are female.

Looking at R developers / CRAN package developers / list posts gender ratios might be
interesting, but I don't think it tells you anything: If there is a
skewed ratio in any of these, the question is if this is the gender
ratio in the user base and, more importantly, in the pool of potential
users.

I have no idea about the gender ratios in potential users, but I would
guess that some disciplines already have a skewed gender ratio, which is
then reflected in R.

The gender ratio in R should reflect the gender ratio of the potential
users, as this is the pool the R users / developers are coming from.

As long as nobody is excluded because of their gender, background, hair
or eye color, OS usage, or whatever ridiculous excuse one could find, I
think R will thrive.
Don't get me wring - nothing against promoting R to new user groups.

But anyway - interesting question.

I was teaching True Basic for several years, and I definitely did not
see a gender bias in their programming abilities - the differences was
in many cases that males thought they could do it, and females thought
they could not do it because it involves maths... But I was able to
prove quite a few wrong.

Cheers,

Rainer

>
> (If you decide to do the stats for 2014, be aware that I've been out
> on medical leave for the past two months, so the numbers are even
> lower than usual.)
>
> Sarah
>
> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
> <maarten.blaauw at qub.ac.uk> wrote:
>> Hi there,
>>
>> I can't help to notice that the gender balance among R developers and
>> ordinary members is extremely skewed (as it is with open source software in
>> general).
>>
>> Have a look at http://www.r-project.org/foundation/memberlist.html - at most
>> a handful of women are listed among the 'supporting members', and none at
>> all among the 29 'ordinary members'.
>>
>> On the other hand I personally know many happy R users of both genders.
>>
>> My questions are thus: Should R developers (and users) be worried that the
>> 'other half' is excluded? If so, how could female R users/developers be
>> persuaded to become more visible (e.g. added as supporting or ordinary
>> members)?
>>
>> Thanks,
>>
>> Maarten
>>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141125/497e092c/attachment.bin>

From ntfredo at gmail.com  Tue Nov 25 12:44:59 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 25 Nov 2014 14:44:59 +0300
Subject: [R] Creating a new column inside a function.
Message-ID: <CAGh51gQQ-BSPiptFOkL4qpsbP78ii+cyBtFs1o1u8yehREHvRw@mail.gmail.com>

Dear All,

i need a help on how I can create a new column on my dataset and use it as
argument inside the following function. The column i want to create and
vary is "Evapolation". It varies that'S why I need it as argument.

When I make it like this is not working:
water_blnce=function(data,capacity_max=100, rain_col=NULL, day_col=NULL,
year_col=NULL, month_col=NULL, Evaporation = 5)

## function for water balance
require(reshape2)
water_blnce=function(data,capacity_max=100, rain_col=NULL, day_col=NULL,
year_col=NULL, month_col=NULL){

#==========================================================================================================
  # This function computes water balance of a dataset.
  # Input: data, variable(s)= capacity_max
  # It adds two new columns Water_balance and Evaporation to the dataset.
  # The function use the formula:  Water balance of today = water balance
of yesterday + Rainfall -Evaporation.
  #If Water balance today < 0 then  Water balance today = 0
  #If Water balance today > 100 then Water balance today = 100
  # the NAs due to non recording values are considered as zero.

#===========================================================================================================
  # finding the indices of all NAs in the data
  indicNAs <- which(data[[rain_col]] %in% NA)
  ind_nonleap = c() # NAs due to non leap years
  ind_nonrecord = c() # NAs due to non recording values
  for (i_NA in indicNAs ){
    if(data[[day_col]][i_NA] == 60){
      ind_nonleap <- append(ind_nonleap,i_NA)
    }
    else {
      ind_nonrecord<-append(ind_nonrecord,i_NA)
    }
   #cat(ind_nonrecord)
   #cat( ind_nonleap)
  }
  #ind_nonleap
  #ind_nonrecord
  # assign the NAs due to non recording values to be zero.
  for(j in ind_nonrecord){
    data[[rain_col]][j]=0
  }
  # remove the rows which has missing values
  data<-na.omit(data)
  # Adding a new column for water balance  and evaporation to the data frame
  data$Water_Balance <- NA
  data$Evaporation<-5
  # initialization
  data$Water_Balance[1]=0
  # loop for calculating water balance for a given dataset
  ndays <- nrow(data)
  for (iday in 2:ndays) {
    data$Water_Balance[iday] <- data$Water_Balance[iday-1] +
data[[rain_col]][iday] - data$Evaporation[iday]
    if (data$Water_Balance[iday]<0){
      data$Water_Balance[iday]=0
    }else if(data$Water_Balance[iday]>capacity_max){
      data$Water_Balance[iday]=capacity_max
    }
  }
  # Table of water balance for a specific year.
  #subset the data for each year

  out = list() # list of output
  for (year in unique(data[[year_col]])){
    dat<-subset(data, data[[year_col]]==year)
    out[[year -(min(unique(data[[year_col]]))-1)]] <- dcast(dat,
dat[[day_col]]~dat[[month_col]], value.var="Water_Balance")
    #add column names as month
    colnames(out[[year
-(min(unique(data[[year_col]]))-1)]])[2:13]<-month.abb[1:12]
  }
  out
}

Any help is appreciated!!!

Regards,
Frederic.





Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From skostysh at princeton.edu  Tue Nov 25 13:11:21 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Tue, 25 Nov 2014 07:11:21 -0500
Subject: [R] Gender balance in R
In-Reply-To: <CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
References: <54734A50.8090600@qub.ac.uk>
	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
Message-ID: <CAE3=dmdyACtXiLD40ju7uBi0+KspQk7Z1nW+R4c=w8KgB7v_zw@mail.gmail.com>

On Mon, Nov 24, 2014 at 12:34 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> I took a look at apparent gender among list participants a few years ago:
> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
>
> Same general thing: very few regular participants on the list were
> women. I don't see any sign that that has changed in the last three
> years. The bar to participation in the R-help list is much, much lower
> than that to become a developer.

I plotted the gender of posters on r-help over time. The plot is here:
https://twitter.com/scottkosty/status/449933971644633088

The code to reproduce that plot is here:
https://github.com/scottkosty/genderAnalysis
The R file there will call devtools::install_github to install a
package from Github used for guessing the gender based on the first
name (https://github.com/scottkosty/gender).

Note also on that tweet that Gabriela de Queiroz posted it, who is the
founder of R-ladies; and that David Smith showed interest in
discussing the topic. So there is definitely demand for some data
analysis and discussion on the topic.

> It would be interesting to look at the stats for CRAN packages as well.
>
> The very low percentage of regular female participants is one of the
> things that keeps me active on this list: to demonstrate that it's not
> only men who use R and participate in the community.

Thank you for that!

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University

> (If you decide to do the stats for 2014, be aware that I've been out
> on medical leave for the past two months, so the numbers are even
> lower than usual.)
>
> Sarah
>
> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
> <maarten.blaauw at qub.ac.uk> wrote:
>> Hi there,
>>
>> I can't help to notice that the gender balance among R developers and
>> ordinary members is extremely skewed (as it is with open source software in
>> general).
>>
>> Have a look at http://www.r-project.org/foundation/memberlist.html - at most
>> a handful of women are listed among the 'supporting members', and none at
>> all among the 29 'ordinary members'.
>>
>> On the other hand I personally know many happy R users of both genders.
>>
>> My questions are thus: Should R developers (and users) be worried that the
>> 'other half' is excluded? If so, how could female R users/developers be
>> persuaded to become more visible (e.g. added as supporting or ordinary
>> members)?
>>
>> Thanks,
>>
>> Maarten
>>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ntfredo at gmail.com  Tue Nov 25 13:19:53 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 25 Nov 2014 15:19:53 +0300
Subject: [R] Error Missing values where true/false needed
Message-ID: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>

Dear All,

I am getting this error and don't know why it comes. can you please help ?

Error in if (data$Rain[i_NA] == 60) { :
  missing value where TRUE/FALSE needed

The loop is :

indicNAs <- which(data$Rain %in% NA)
  ind_nonleap = c() # NAs due to non leap years
  ind_nonrecord = c() # NAs due to non recording values
  for (i_NA in indicNAs ){
    if(data$Rain[i_NA] == 60){
      ind_nonleap <- append(ind_nonleap,i_NA)
    }
    else {
      ind_nonrecord<-append(ind_nonrecord,i_NA)
    }
   #cat(ind_nonrecord)
   #cat( ind_nonleap)
  }
  ind_nonleap

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Nov 25 13:40:04 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 25 Nov 2014 12:40:04 +0000
Subject: [R] Error Missing values where true/false needed
In-Reply-To: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>
References: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFBEC@SRVEXCHMBX.precheza.cz>

Hi

Error message seems to be clear

> Error in if (data$Rain[i_NA] == 60) { :
>   missing value where TRUE/FALSE needed

data$Rain[i_NA] produces probably NA

> x<-NA
> if(x==60) print(1+1) else print("Errrorrr")
Error in if (x == 60) 1 + 1 : missing value where TRUE/FALSE needed
> x<-10
> if(x==60) print(1+1) else print("Errrorrr")
[1] "Errrorrr"

Cheers
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Frederic Ntirenganya
> Sent: Tuesday, November 25, 2014 1:20 PM
> To: r-help at r-project.org
> Subject: [R] Error Missing values where true/false needed
>
> Dear All,
>
> I am getting this error and don't know why it comes. can you please
> help ?
>
> Error in if (data$Rain[i_NA] == 60) { :
>   missing value where TRUE/FALSE needed
>
> The loop is :
>
> indicNAs <- which(data$Rain %in% NA)
>   ind_nonleap = c() # NAs due to non leap years
>   ind_nonrecord = c() # NAs due to non recording values
>   for (i_NA in indicNAs ){
>     if(data$Rain[i_NA] == 60){
>       ind_nonleap <- append(ind_nonleap,i_NA)
>     }
>     else {
>       ind_nonrecord<-append(ind_nonrecord,i_NA)
>     }
>    #cat(ind_nonrecord)
>    #cat( ind_nonleap)
>   }
>   ind_nonleap
>
> Regards,
> Frederic.
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From info at aghmed.fsnet.co.uk  Tue Nov 25 13:51:18 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 25 Nov 2014 12:51:18 +0000
Subject: [R] Error Missing values where true/false needed
In-Reply-To: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>
References: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>
Message-ID: <54747B46.5000607@aghmed.fsnet.co.uk>

You do not tell us what you are trying to do but I think there is 
something wrong in the logic of your thinking as on the one hand you are 
selecting just precisely those elements of data$Rain which are NA and 
then testing whether any of them equals 60.


On 25/11/2014 12:19, Frederic Ntirenganya wrote:
> Dear All,
>
> I am getting this error and don't know why it comes. can you please help ?
>
> Error in if (data$Rain[i_NA] == 60) { :
>    missing value where TRUE/FALSE needed
>
> The loop is :
>
> indicNAs <- which(data$Rain %in% NA)
>    ind_nonleap = c() # NAs due to non leap years
>    ind_nonrecord = c() # NAs due to non recording values
>    for (i_NA in indicNAs ){
>      if(data$Rain[i_NA] == 60){
>        ind_nonleap <- append(ind_nonleap,i_NA)
>      }
>      else {
>        ind_nonrecord<-append(ind_nonrecord,i_NA)
>      }
>     #cat(ind_nonrecord)
>     #cat( ind_nonleap)
>    }
>    ind_nonleap
>
> Regards,
> Frederic.
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4223/8627 - Release Date: 11/25/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From chl948 at mail.usask.ca  Tue Nov 25 15:42:16 2014
From: chl948 at mail.usask.ca (Lee, Chel Hee)
Date: Tue, 25 Nov 2014 08:42:16 -0600
Subject: [R] More elegant way of stacking the data
In-Reply-To: <CAN2xGJaAZO4m8d6J=_ztZ0HzjsrTLaD+S_pPpcjVw0p4XK=wjg@mail.gmail.com>
References: <CAN2xGJaAZO4m8d6J=_ztZ0HzjsrTLaD+S_pPpcjVw0p4XK=wjg@mail.gmail.com>
Message-ID: <54749548.6010106@mail.usask.ca>

If you do not want to use the loop, a function called 'reshape' may be 
useful:

 > df <- data.frame(a=1:5,b=letters[1:5],c1=1:5,c2=2:6,c3=3:7,c4=4:8)
 > out2 <- reshape(data=df, direction="long", varying=list(3:6), 
times=paste("c",1:4,sep=""))
 > out2
      a b time c1 id
1.c1 1 a   c1  1  1
2.c1 2 b   c1  2  2
3.c1 3 c   c1  3  3
4.c1 4 d   c1  4  4
5.c1 5 e   c1  5  5
1.c2 1 a   c2  2  1
2.c2 2 b   c2  3  2
3.c2 3 c   c2  4  3
4.c2 4 d   c2  5  4
5.c2 5 e   c2  6  5
1.c3 1 a   c3  3  1
2.c3 2 b   c3  4  2
3.c3 3 c   c3  5  3
4.c3 4 d   c3  6  4
5.c3 5 e   c3  7  5
1.c4 1 a   c4  4  1
2.c4 2 b   c4  5  2
3.c4 3 c   c4  6  3
4.c4 4 d   c4  7  4
5.c4 5 e   c4  8  5

I hope this helps.

Chel Hee Lee

On 11/24/2014 5:12 PM, Dimitri Liakhovitski wrote:
> I have the data frame 'df' and my desired solution 'out'.
> I am sure there is a more elegant R-way to do it - without a loop.
>
> df = data.frame(a=1:5,b=letters[1:5],c1=1:5,c2=2:6,c3=3:7,c4=4:8)
> mylist=NULL
> for(i in 1:4){
>    myname<-paste("c",i,sep="")
>    mylist[[i]]<-df[c("a","b",myname)]
>    names(mylist[[i]])<-c("a","b","c")
> }
> out<-do.call(rbind,mylist)
> out
>
> Thank you!
>


From dimitri.liakhovitski at gmail.com  Tue Nov 25 15:44:27 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 25 Nov 2014 09:44:27 -0500
Subject: [R] More elegant way of stacking the data
In-Reply-To: <54749548.6010106@mail.usask.ca>
References: <CAN2xGJaAZO4m8d6J=_ztZ0HzjsrTLaD+S_pPpcjVw0p4XK=wjg@mail.gmail.com>
	<54749548.6010106@mail.usask.ca>
Message-ID: <CAN2xGJbW4sr36+vO6zcqwwkGjr0Y5WdFBqov1UQWCMbG-FUnrw@mail.gmail.com>

Thanks a lot, guys!

On Tue, Nov 25, 2014 at 9:42 AM, Lee, Chel Hee <chl948 at mail.usask.ca> wrote:
> If you do not want to use the loop, a function called 'reshape' may be
> useful:
>
>> df <- data.frame(a=1:5,b=letters[1:5],c1=1:5,c2=2:6,c3=3:7,c4=4:8)
>> out2 <- reshape(data=df, direction="long", varying=list(3:6),
>> times=paste("c",1:4,sep=""))
>> out2
>      a b time c1 id
> 1.c1 1 a   c1  1  1
> 2.c1 2 b   c1  2  2
> 3.c1 3 c   c1  3  3
> 4.c1 4 d   c1  4  4
> 5.c1 5 e   c1  5  5
> 1.c2 1 a   c2  2  1
> 2.c2 2 b   c2  3  2
> 3.c2 3 c   c2  4  3
> 4.c2 4 d   c2  5  4
> 5.c2 5 e   c2  6  5
> 1.c3 1 a   c3  3  1
> 2.c3 2 b   c3  4  2
> 3.c3 3 c   c3  5  3
> 4.c3 4 d   c3  6  4
> 5.c3 5 e   c3  7  5
> 1.c4 1 a   c4  4  1
> 2.c4 2 b   c4  5  2
> 3.c4 3 c   c4  6  3
> 4.c4 4 d   c4  7  4
> 5.c4 5 e   c4  8  5
>
> I hope this helps.
>
> Chel Hee Lee
>
>
> On 11/24/2014 5:12 PM, Dimitri Liakhovitski wrote:
>>
>> I have the data frame 'df' and my desired solution 'out'.
>> I am sure there is a more elegant R-way to do it - without a loop.
>>
>> df = data.frame(a=1:5,b=letters[1:5],c1=1:5,c2=2:6,c3=3:7,c4=4:8)
>> mylist=NULL
>> for(i in 1:4){
>>    myname<-paste("c",i,sep="")
>>    mylist[[i]]<-df[c("a","b",myname)]
>>    names(mylist[[i]])<-c("a","b","c")
>> }
>> out<-do.call(rbind,mylist)
>> out
>>
>> Thank you!
>>
>



-- 
Dimitri Liakhovitski


From pdalgd at gmail.com  Tue Nov 25 17:28:15 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 25 Nov 2014 17:28:15 +0100
Subject: [R] Gender balance in R
In-Reply-To: <CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
References: <54734A50.8090600@qub.ac.uk>
	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
Message-ID: <29227D98-4E84-48F4-AE89-238182EB0F2B@gmail.com>


On 24 Nov 2014, at 18:34 , Sarah Goslee <sarah.goslee at gmail.com> wrote:

> I took a look at apparent gender among list participants a few years ago:
> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
> 
> Same general thing: very few regular participants on the list were
> women. I don't see any sign that that has changed in the last three
> years. The bar to participation in the R-help list is much, much lower
> than that to become a developer.
> 
> It would be interesting to look at the stats for CRAN packages as well.
> 
> The very low percentage of regular female participants is one of the
> things that keeps me active on this list: to demonstrate that it's not
> only men who use R and participate in the community.
> 
> (If you decide to do the stats for 2014, be aware that I've been out
> on medical leave for the past two months, so the numbers are even
> lower than usual.)


...and very welcome back!!! (I did notice the chronicles on your blog).

Re. the gender issue, it is certainly not that women aren't welcome, it's more that they aren't there. There are various potential reasons that come to mind, but it easily ends up in speculation and stereotyping. 

It is a bit of an embarrasment and people are discussing what to do about it, but some of the countermeasures have a tendency to backfire, so we need to be a little careful. 

- Peter D.


> 
> Sarah
> 
> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
> <maarten.blaauw at qub.ac.uk> wrote:
>> Hi there,
>> 
>> I can't help to notice that the gender balance among R developers and
>> ordinary members is extremely skewed (as it is with open source software in
>> general).
>> 
>> Have a look at http://www.r-project.org/foundation/memberlist.html - at most
>> a handful of women are listed among the 'supporting members', and none at
>> all among the 29 'ordinary members'.
>> 
>> On the other hand I personally know many happy R users of both genders.
>> 
>> My questions are thus: Should R developers (and users) be worried that the
>> 'other half' is excluded? If so, how could female R users/developers be
>> persuaded to become more visible (e.g. added as supporting or ordinary
>> members)?
>> 
>> Thanks,
>> 
>> Maarten
>> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jluo.rhelp at gmail.com  Tue Nov 25 17:36:32 2014
From: jluo.rhelp at gmail.com (Jack Luo)
Date: Tue, 25 Nov 2014 11:36:32 -0500
Subject: [R] question regarding rmvDAG in package pcalg
Message-ID: <CAD-E8+43oCb8XtBL3U2NK6VM9_4-cPB+9=464F7LLnQ6W19gDQ@mail.gmail.com>

Hi,

I am trying to use rmvDAG in pcalg package to generate data from DAG
structure. One thing I found is that when the number of variables gets
large, there can be really large numbers in the data matrix. I played
around with different parameters and it looks like the same case.

library(pcalg)
> p = 20
> n = 100
> rDAG <- randomDAG(p, prob = 0.2, lB=0.1, uB=1)
> d.normMat <- rmvDAG(n, rDAG, errDist="normal")
> max(d.normMat)
[1] 5.763518
> p = 200
> n = 100
> rDAG <- randomDAG(p, prob = 0.2, lB=0.1, uB=1)
> d.normMat <- rmvDAG(n, rDAG, errDist="normal")
> max(d.normMat)
[1] 365099508
> p = 2000
> n = 100
> rDAG <- randomDAG(p, prob = 0.2, lB=0.1, uB=1)
> d.normMat <- rmvDAG(n, rDAG, errDist="normal")
> max(d.normMat)
[1] 3.880373e+90

Did anyone know how to fix this?

Thanks a lot!

-Jack

	[[alternative HTML version deleted]]


From maarten.blaauw at qub.ac.uk  Tue Nov 25 11:15:48 2014
From: maarten.blaauw at qub.ac.uk (Maarten Blaauw)
Date: Tue, 25 Nov 2014 10:15:48 +0000
Subject: [R] Gender balance in R
In-Reply-To: <m2sih7tzci.fsf@krugs.de>
References: <54734A50.8090600@qub.ac.uk>	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
	<m2sih7tzci.fsf@krugs.de>
Message-ID: <547456D4.3050100@qub.ac.uk>

Thanks for the responses so far.

 > The gender ratio in R should reflect the gender ratio of the potential
 > users, as this is the pool the R users / developers are coming from.

I agree with this, but then again I don't think R really has 0% female 
users/developers as the R member list suggests. I'd rather expect to see 
10-50% women (my quick guess of gender balance in STEM areas, depending 
on where on the ladder and in which country one samples). Perhaps the R 
community should be assessing if there's some additional bias applied 
during the selection of supporting or ordinary members?

Cheers,

Maarten

On 25/11/14 09:15, Rainer M Krug wrote:
> Sarah Goslee <sarah.goslee at gmail.com> writes:
>
>> I took a look at apparent gender among list participants a few years ago:
>> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
>>
>> Same general thing: very few regular participants on the list were
>> women. I don't see any sign that that has changed in the last three
>> years. The bar to participation in the R-help list is much, much lower
>> than that to become a developer.
>>
>> It would be interesting to look at the stats for CRAN packages as well.
>>
>> The very low percentage of regular female participants is one of the
>> things that keeps me active on this list: to demonstrate that it's not
>> only men who use R and participate in the community.
>
> Apart from that, your input is very valuable and your answers very
> hands-on helpful - and this is why I am glad that you are on the list -
> and not because you are female.
>
> Looking at R developers / CRAN package developers / list posts gender ratios might be
> interesting, but I don't think it tells you anything: If there is a
> skewed ratio in any of these, the question is if this is the gender
> ratio in the user base and, more importantly, in the pool of potential
> users.
>
> I have no idea about the gender ratios in potential users, but I would
> guess that some disciplines already have a skewed gender ratio, which is
> then reflected in R.
>
> The gender ratio in R should reflect the gender ratio of the potential
> users, as this is the pool the R users / developers are coming from.
>
> As long as nobody is excluded because of their gender, background, hair
> or eye color, OS usage, or whatever ridiculous excuse one could find, I
> think R will thrive.
> Don't get me wring - nothing against promoting R to new user groups.
>
> But anyway - interesting question.
>
> I was teaching True Basic for several years, and I definitely did not
> see a gender bias in their programming abilities - the differences was
> in many cases that males thought they could do it, and females thought
> they could not do it because it involves maths... But I was able to
> prove quite a few wrong.
>
> Cheers,
>
> Rainer
>
>>
>> (If you decide to do the stats for 2014, be aware that I've been out
>> on medical leave for the past two months, so the numbers are even
>> lower than usual.)
>>
>> Sarah
>>
>> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
>> <maarten.blaauw at qub.ac.uk> wrote:
>>> Hi there,
>>>
>>> I can't help to notice that the gender balance among R developers and
>>> ordinary members is extremely skewed (as it is with open source software in
>>> general).
>>>
>>> Have a look at http://www.r-project.org/foundation/memberlist.html - at most
>>> a handful of women are listed among the 'supporting members', and none at
>>> all among the 29 'ordinary members'.
>>>
>>> On the other hand I personally know many happy R users of both genders.
>>>
>>> My questions are thus: Should R developers (and users) be worried that the
>>> 'other half' is excluded? If so, how could female R users/developers be
>>> persuaded to become more visible (e.g. added as supporting or ordinary
>>> members)?
>>>
>>> Thanks,
>>>
>>> Maarten
>>>
>

-- 
| Dr. Maarten Blaauw
| Lecturer in Chronology
|
| School of Geography, Archaeology & Palaeoecology
| Queen's University Belfast, UK
|
| www  http://www.chrono.qub.ac.uk/blaauw
| tel  +44 (0)28 9097 3895


From i.am.stack at gmail.com  Tue Nov 25 00:58:12 2014
From: i.am.stack at gmail.com (=?UTF-8?Q?Stack_Koror=C4=81?=)
Date: Mon, 24 Nov 2014 17:58:12 -0600
Subject: [R] RStuido seg faults
Message-ID: <CAGAtKrJ82AnSrGdrG_oDf+hmfymajxvgD=ma+xyDi99ue5_Ztg@mail.gmail.com>

Greetings,
I am having a big issue with RStudio segfaulting recently. It is
becoming a very big problem for me. I have attached most of the
information to the support site but no one has responded there. Can
someone please help me fix RStudio?

https://support.rstudio.com/hc/communities/public/questions/203655446-Core-Crash-on-SL6-6-and-rstudio-0-98-1091-1

Thank you!


From mtripoli at istat.it  Tue Nov 25 13:07:38 2014
From: mtripoli at istat.it (Massimiliano Tripoli)
Date: Tue, 25 Nov 2014 13:07:38 +0100 (CET)
Subject: [R] Converting list to character
In-Reply-To: <1737833032.1762866.1416917195653.JavaMail.root@istat.it>
Message-ID: <1322988993.1763032.1416917258615.JavaMail.root@istat.it>



Dear all,

I can't convert the result of aggregate function in a dataframe. My data
looks like:

mydata <- structure(list(ID = c(11, 11, 460, 460, 986, 986, 986, 986, 1251,
1251, 1251, 1251, 1251, 1251, 1251, 1251, 1801, 1801, 1801, 1801
), YEAR = c(2009, 2010, 2010, 2011, 2008, 2009, 2010, 2011, 2008,
2008, 2009, 2009, 2010, 2010, 2011, 2011, 2008, 2009, 2010, 2011
), Y = c(158126, 153015, 3701, 5880, 718663, 661112, 527233,
558281, 450, 131714, 427, 124648, 425, 116500, 434, 123853, 17400,
16493, 8057, 8329), CODE = c("GR.3.7", "GR.3.7", "GR.3.1", "GR.3.1",
"GR.3.8", "GR.3.8", "GR.3.8", "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.1",
"GR.3.8", "GR.3.1", "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.8", "GR.3.8",
"GR.3.8", "GR.3.8")), .Names = c("ID", "YEAR", "Y", "CODE"), row.names = c(NA,
20L), class = "data.frame")

and by using aggregate function

TAB <- aggregate(mydata$CODE,by=list(ID=mydata$ID,YEAR=mydata$YEAR),FUN=paste0)

What I want is a dataframe like of printing TAB:
> TAB
     ID YEAR              x
1   986 2008         GR.3.8
2  1251 2008 GR.3.1, GR.3.8
3  1801 2008         GR.3.8
4    11 2009         GR.3.7
5   986 2009         GR.3.8
6  1251 2009 GR.3.1, GR.3.8
7  1801 2009         GR.3.8
8    11 2010         GR.3.7
9   460 2010         GR.3.1
10  986 2010         GR.3.8
11 1251 2010 GR.3.1, GR.3.8
12 1801 2010         GR.3.8
13  460 2011         GR.3.1
14  986 2011         GR.3.8
15 1251 2011 GR.3.1, GR.3.8
16 1801 2011         GR.3.8

> str(TAB)[1:10]
'data.frame':        16 obs. of  3 variables:
 $ ID  : num  986 1251 1801 11 986 ...
 $ YEAR: num  2008 2008 2008 2009 2009 ...
 $ x   :List of 16
  ..$ 1 : chr "GR.3.8"
  ..$ 2 : chr  "GR.3.1" "GR.3.8"
  ..$ 4 : chr "GR.3.8"
  ..$ 5 : chr "GR.3.7"
  ..$ 6 : chr "GR.3.8"
  ..$ 7 : chr  "GR.3.1" "GR.3.8"
  ..$ 9 : chr "GR.3.8"
  ..$ 10: chr "GR.3.7"
  ..$ 11: chr "GR.3.1"
  ..$ 12: chr "GR.3.8"
  ..$ 13: chr  "GR.3.1" "GR.3.8"
  ..$ 15: chr "GR.3.8"
  ..$ 16: chr "GR.3.1"
  ..$ 17: chr "GR.3.8"
  ..$ 18: chr  "GR.3.1" "GR.3.8"
  ..$ 20: chr "GR.3.8"
NULL

As you can see the "x" coloumn is a list and I would want to change it to character variable.
Anyone may help me?
Thanks,

Massimiliano
-- 
Massimiliano Tripoli 
Collaboratore T.E.R. scado il 31/12/2014 
ISTAT - DCCN - Direzione Centrale della Contabilit? Nazionale 
U.O. Contabilit? dei flussi di materia del sistema economico - CSA/C 
Via Depretis, 74/B 00184 Roma 
Tel. 06.4673.3132 
E-mail: mtripoli at istat.it 


From jeethghambole at gmail.com  Tue Nov 25 14:06:54 2014
From: jeethghambole at gmail.com (jeeth ghambole)
Date: Tue, 25 Nov 2014 18:36:54 +0530
Subject: [R] Packages for Handling Large Data Set
Message-ID: <CAFp0RzW_ig=QMwtg0DV4_kuV4nVy8h411mLXyrEurTOFtWTneg@mail.gmail.com>

Hello All,

I am working on BackTesting Strategies on stocks using daily prices.

Initially the size of data was very limited and can be easily handled using
R and SQL, but now my analysis has been extending on large set of data. Can
anyone suggest me the best packages available for handling large datasets.

Thank you.

With Regards,
Jeeth G.

	[[alternative HTML version deleted]]


From maarten.blaauw at qub.ac.uk  Tue Nov 25 14:24:34 2014
From: maarten.blaauw at qub.ac.uk (Maarten Blaauw)
Date: Tue, 25 Nov 2014 13:24:34 +0000
Subject: [R] Gender balance in R
In-Reply-To: <CAE3=dmdyACtXiLD40ju7uBi0+KspQk7Z1nW+R4c=w8KgB7v_zw@mail.gmail.com>
References: <54734A50.8090600@qub.ac.uk>	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
	<CAE3=dmdyACtXiLD40ju7uBi0+KspQk7Z1nW+R4c=w8KgB7v_zw@mail.gmail.com>
Message-ID: <54748312.8020707@qub.ac.uk>

Nice graph, Scott, thanks!

Based on your code I plotted not the absolute numbers but the ratios, 
which show slowly increasing relative participation of female Rhelpers 
over time (red = women, blue=men, black=unknown). After a c. 5% female 
contribution in 1998, this has grown to about 15% now. At this rate 
we'll reach parity around AD 2080.

My code:

if (!require(gender)) {
library(devtools)
install_github("scottkosty/gender")
library(gender)
}
rHelp <- rHelpNames
rHelp[is.na(rHelp$gender), "gender"] <- "unknown"

yr <- unique(rHelp$year)

helpers <- list(dates, M=rep(0, length(yr)), F=rep(0, length(yr)), 
unkn=rep(0, length(yr)))

for(i in 1:nrow(rHelp))
  {
   j <- which(yr == rHelp$year[i])
   gender <- rHelp$gender[i]
   if(gender == "M")
    helpers$M[[j]] <- helpers$M[[j]]+1 else
     if(gender == "F")
      helpers$F[[j]] <- helpers$F[[j]]+1 else
       if(gender == "unknown")
        helpers$unkn[[j]] <- helpers$unkn[[j]]+1
  }
plot(yr, helpers$M / (helpers$M+helpers$F+helpers$unkn), type="l", 
col=4, ylim=c(0,1), ylab="proportions", yaxs="i")
lines(yr, helpers$F / (helpers$M+helpers$F+helpers$unkn), col=2) 

lines(yr, helpers$unkn / (helpers$M+helpers$F+helpers$unkn))

Cheers,

Maarten

On 25/11/14 12:11, Scott Kostyshak wrote:
> On Mon, Nov 24, 2014 at 12:34 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> I took a look at apparent gender among list participants a few years ago:
>> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
>>
>> Same general thing: very few regular participants on the list were
>> women. I don't see any sign that that has changed in the last three
>> years. The bar to participation in the R-help list is much, much lower
>> than that to become a developer.
>
> I plotted the gender of posters on r-help over time. The plot is here:
> https://twitter.com/scottkosty/status/449933971644633088
>
> The code to reproduce that plot is here:
> https://github.com/scottkosty/genderAnalysis
> The R file there will call devtools::install_github to install a
> package from Github used for guessing the gender based on the first
> name (https://github.com/scottkosty/gender).
>
> Note also on that tweet that Gabriela de Queiroz posted it, who is the
> founder of R-ladies; and that David Smith showed interest in
> discussing the topic. So there is definitely demand for some data
> analysis and discussion on the topic.
>
>> It would be interesting to look at the stats for CRAN packages as well.
>>
>> The very low percentage of regular female participants is one of the
>> things that keeps me active on this list: to demonstrate that it's not
>> only men who use R and participate in the community.
>
> Thank you for that!
>
> Scott
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University
>
>> (If you decide to do the stats for 2014, be aware that I've been out
>> on medical leave for the past two months, so the numbers are even
>> lower than usual.)
>>
>> Sarah
>>
>> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
>> <maarten.blaauw at qub.ac.uk> wrote:
>>> Hi there,
>>>
>>> I can't help to notice that the gender balance among R developers and
>>> ordinary members is extremely skewed (as it is with open source software in
>>> general).
>>>
>>> Have a look at http://www.r-project.org/foundation/memberlist.html - at most
>>> a handful of women are listed among the 'supporting members', and none at
>>> all among the 29 'ordinary members'.
>>>
>>> On the other hand I personally know many happy R users of both genders.
>>>
>>> My questions are thus: Should R developers (and users) be worried that the
>>> 'other half' is excluded? If so, how could female R users/developers be
>>> persuaded to become more visible (e.g. added as supporting or ordinary
>>> members)?
>>>
>>> Thanks,
>>>
>>> Maarten
>>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
| Dr. Maarten Blaauw
| Lecturer in Chronology
|
| School of Geography, Archaeology & Palaeoecology
| Queen's University Belfast, UK
|
| www  http://www.chrono.qub.ac.uk/blaauw
| tel  +44 (0)28 9097 3895
-------------- next part --------------
A non-text attachment was scrubbed...
Name: gendeR.pdf
Type: application/pdf
Size: 4671 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141125/0c5dc54f/attachment.pdf>

From charlotte.whitham at gmail.com  Tue Nov 25 17:21:38 2014
From: charlotte.whitham at gmail.com (Charlotte Whitham)
Date: Tue, 25 Nov 2014 16:21:38 +0000
Subject: [R] Checking the proportional odds assumption holds in an ordinal
	logistic regression using polr function
Message-ID: <92C9BF3E-698C-4F79-936C-6AD2F662A6B1@gmail.com>

Dear list,

I have used the ?polr? function in the MASS package to run an ordinal logistic regression for an ordinal categorical response variable with 15 continuous explanatory variables.
I have used the code (shown below) to check that my model meets the proportional odds assumption following advice provided at (http://www.ats.ucla.edu/stat/r/dae/ologit.htm) ? which has been extremely helpful, thank you to the authors! However, I?m a little worried about the output implying that not only are the coefficients across various cutpoints similar, but they are exactly the same (see graphic below).

Here is the code I used (and see attached for the output graphic)

FGV1b<-data.frame(FG1_val_cat=factor(FGV1b[,"FG1_val_cat"]),scale(FGV1[,c("X","Y","Slope","Ele","Aspect","Prox_to_for_FG","Prox_to_for_mL","Prox_to_nat_border","Prox_to_village","Prox_to_roads","Prox_to_rivers","Prox_to_waterFG","Prox_to_watermL","Prox_to_core","Prox_to_NR","PCA1","PCA2","PCA3")]))

b<-polr(FGV1b$FG1_val_cat ~ FGV1b$X + FGV1b$Y + FGV1b$Slope + FGV1b$Ele + FGV1b$Aspect + FGV1b$Prox_to_for_FG + FGV1b$Prox_to_for_mL + FGV1b$Prox_to_nat_border + FGV1b$Prox_to_village + FGV1b$Prox_to_roads + FGV1b$Prox_to_rivers + FGV1b$Prox_to_waterFG + FGV1b$Prox_to_watermL + FGV1b$Prox_to_core + FGV1b$Prox_to_NR, data = FGV1b, Hess=TRUE)

#Checking the assumption. So the following code will estimate the values to be graphed. First it shows us #the logit transformations of the probabilities of being greater than or equal to each value of the target #variable

FGV1b$FG1_val_cat<-as.numeric(FGV1b$FG1_val_cat) 

sf <- function(y) {

  c('VC>=1' = qlogis(mean(FGV1b$FG1_val_cat >= 1)),

    'VC>=2' = qlogis(mean(FGV1b$FG1_val_cat >= 2)),

    'VC>=3' = qlogis(mean(FGV1b$FG1_val_cat >= 3)),

    'VC>=4' = qlogis(mean(FGV1b$FG1_val_cat >= 4)),

    'VC>=5' = qlogis(mean(FGV1b$FG1_val_cat >= 5)),

    'VC>=6' = qlogis(mean(FGV1b$FG1_val_cat >= 6)),

    'VC>=7' = qlogis(mean(FGV1b$FG1_val_cat >= 7)),

    'VC>=8' = qlogis(mean(FGV1b$FG1_val_cat >= 8)))

}

  (t <- with(FGV1b, summary(as.numeric(FGV1b$FG1_val_cat) ~ FGV1b$X + FGV1b$Y + FGV1b$Slope + FGV1b$Ele + FGV1b$Aspect + FGV1b$Prox_to_for_FG + FGV1b$Prox_to_for_mL + FGV1b$Prox_to_nat_border + FGV1b$Prox_to_village + FGV1b$Prox_to_roads + FGV1b$Prox_to_rivers + FGV1b$Prox_to_waterFG + FGV1b$Prox_to_watermL + FGV1b$Prox_to_core + FGV1b$Prox_to_NR, fun=sf)))

 

#The table displays the (linear) predicted values we would get if we regressed our

#dependent variable on our predictor variables one at a time, without the parallel slopes

#assumption. So now, we can run a series of binary logistic regressions with varying cutpoints

#on the dependent variable to check the equality of coefficients across cutpoints

par(mfrow=c(1,1))

plot(t, which=1:8, pch=1:8, xlab='logit', main=' ', xlim=range(s[,7:8]))

 

Apologies that I am no statistics expert and perhaps I am missing something obvious here. However, I have spent a long time trying to figure out if there is a problem in how I tested the model assumption and also trying to figure out other ways to run the same kind of model.

 For example, I read in many help mailing lists that others use the vglm function (in the VGAM package) and the lrm function (in the rms package) (for example see here:  http://stats.stackexchange.com/questions/25988/proportional-odds-assumption-in-ordinal-logistic-regression-in-r-with-the-packag). I have tried to run the same models but am continuously coming up against warnings and errors.

 For example, when I try to fit the vglm model with the ?parallel=FALSE? argument (as the previous link mentions is important for testing the proportional odds assumption), I encounter the following error:

 

Error in lm.fit(X.vlm, y = z.vlm, ...) : NA/NaN/Inf in 'y'

In addition: Warning message:

In Deviance.categorical.data.vgam(mu = mu, y = y, w = w, residuals = residuals,  :

  fitted values close to 0 or 1

 

And after many searches for help, I can?t seem to find a way to fix this problem.

I would like to ask please if there is anyone who might understand and be able to explain to me why the graph I produced above looks as it does. If indeed it means that something isn?t right, could you please help me find a way to test the proportional odds assumption when just using the polr function. Or if that is just not possible, then I will resort to trying to use the vglm function, but would then need some help to explain why I keep getting the error given above. 

I hope this is clear. Please do let me know if I should provide some more information that would help address this query.

NOTE: As a background, there are 1000 datapoints here, which are actually location points across a study area. I am looking to see if there are any relationships between the categorical response variable and these 15 explanatory variables. All of those 15 explanatory variables are spatial characteristics (for example, elevation, x-y coordinates, proximity to forest etc.). The 1000 datapoints were randomly allocated using a GIS, but I took a stratified sampling approach. I made sure that 125 points were randomly chosen within each of the 8 different categorical response levels. I hope this information is also helpful.

I am extremely grateful to anyone who could please give me some guidance with this. 

Thank you very much for your time,

Charlie

From cnhatcher at vols.utk.edu  Tue Nov 25 17:43:04 2014
From: cnhatcher at vols.utk.edu (Hatcher, Catherine)
Date: Tue, 25 Nov 2014 16:43:04 +0000
Subject: [R] Gender balance in R
In-Reply-To: <29227D98-4E84-48F4-AE89-238182EB0F2B@gmail.com>
References: <54734A50.8090600@qub.ac.uk>
	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
	<29227D98-4E84-48F4-AE89-238182EB0F2B@gmail.com>
Message-ID: <D09A1AAD.2EAE%cnyinyi@vols.utk.edu>

I just saw this comment and I agree with Peter. I have occasion to ask
questions and get help on the R forum but I am not a programmer and use
programs as I need them and I suppose I must comment more often. :)

On 11/25/14, 11:28 AM, "peter dalgaard" <pdalgd at gmail.com> wrote:

>
>On 24 Nov 2014, at 18:34 , Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
>> I took a look at apparent gender among list participants a few years
>>ago:
>> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
>> 
>> Same general thing: very few regular participants on the list were
>> women. I don't see any sign that that has changed in the last three
>> years. The bar to participation in the R-help list is much, much lower
>> than that to become a developer.
>> 
>> It would be interesting to look at the stats for CRAN packages as well.
>> 
>> The very low percentage of regular female participants is one of the
>> things that keeps me active on this list: to demonstrate that it's not
>> only men who use R and participate in the community.
>> 
>> (If you decide to do the stats for 2014, be aware that I've been out
>> on medical leave for the past two months, so the numbers are even
>> lower than usual.)
>
>
>...and very welcome back!!! (I did notice the chronicles on your blog).
>
>Re. the gender issue, it is certainly not that women aren't welcome, it's
>more that they aren't there. There are various potential reasons that
>come to mind, but it easily ends up in speculation and stereotyping.
>
>It is a bit of an embarrasment and people are discussing what to do about
>it, but some of the countermeasures have a tendency to backfire, so we
>need to be a little careful.
>
>- Peter D.
>
>
>> 
>> Sarah
>> 
>> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
>> <maarten.blaauw at qub.ac.uk> wrote:
>>> Hi there,
>>> 
>>> I can't help to notice that the gender balance among R developers and
>>> ordinary members is extremely skewed (as it is with open source
>>>software in
>>> general).
>>> 
>>> Have a look at http://www.r-project.org/foundation/memberlist.html -
>>>at most
>>> a handful of women are listed among the 'supporting members', and none
>>>at
>>> all among the 29 'ordinary members'.
>>> 
>>> On the other hand I personally know many happy R users of both genders.
>>> 
>>> My questions are thus: Should R developers (and users) be worried that
>>>the
>>> 'other half' is excluded? If so, how could female R users/developers be
>>> persuaded to become more visible (e.g. added as supporting or ordinary
>>> members)?
>>> 
>>> Thanks,
>>> 
>>> Maarten
>>> 
>> -- 
>> Sarah Goslee
>> http://www.functionaldiversity.org
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Peter Dalgaard, Professor,
>Center for Statistics, Copenhagen Business School
>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>Phone: (+45)38153501
>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From MMason at benaroyaresearch.org  Tue Nov 25 18:13:12 2014
From: MMason at benaroyaresearch.org (Michael Mason)
Date: Tue, 25 Nov 2014 17:13:12 +0000
Subject: [R] plot.hclust point to older version
Message-ID: <D099F8A7.A3D1%mmason@benaroyaresearch.org>

Hello fellow R users,

I have recently updated to R 3.1.2. When trying to plot an hclust object to generate the dendrogram I get the following error:

Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
  there is no .Internal function 'dend.window'


I am indeed using R3.1.2 but my understanding is that the .Internal API to the C code is no longer used. I have tried detaching the stats package and restarting R to no avail.
I would love any help from any wiser guRus.
Thanks in advance,
Mike
________________________________
--CONFIDENTIALITY NOTICE--: The information contained in this email is intended for the exclusive use of the addressee and may contain confidential information. If you are not the intended recipient, you are hereby notified that any form of dissemination of this communication is strictly prohibited. www.benaroyaresearch.org

	[[alternative HTML version deleted]]


From rv15i at yahoo.se  Tue Nov 25 18:41:38 2014
From: rv15i at yahoo.se (ravi)
Date: Tue, 25 Nov 2014 17:41:38 +0000 (UTC)
Subject: [R] porting an access database to sqlite
Message-ID: <420701908.1025092.1416937298206.JavaMail.yahoo@jws11104.mail.ir2.yahoo.com>

Hi,All my data is presently locked in a Microsoft access database. This has huge data in a number of large tables. Using RODBC and connecting to it takes too long a time, sometimes making the system to hang up. 

To make things more manageable, I have tried to transfer the data to manageable .RData or .csv files. But I am not able to do this with some of the larger files. I am currently stuck in the one of the preliminary steps. I am not able to find the number of rows in a table. If I know this, I can transfer chunks of the tables to a sqlite database.
I am able to connect to connect to the access data base with :
library(RODBC)
con<-odbcConnect("TestDB")d1<-sqlFetch(ch,"table1",max=1e5,as.is=TRUE)d2<-sqlFetchMore(ch,max=1e5,as.is=TRUE)
d3<-rbind(d1,d2)I wanted to develop this into a loop to get a concatenated data frame, which I wanted to save either as a binary file, or transfer it to a sqlite data base. I would like to have some help on the simplest route to follow. But first, I will proceed in describing my immediate problem. In some of the tables, I find that the sqlFetchMore returns a value of -1L, meaning that the end has been reached. In RODBC, I find no command for getting the row count in a table. I have found this in DBI. But I have not been able to figure out how I should specify the connection to an acccess database (con in the following).

while(!dbHasCompleted(con)){?? print(dbGetRowCount(con))}
I would appreciate help on the following points :1. How can I get the row count (and size) of a table in an access data base? With RODBC, DBI or any other way.2. I have found that saving the tables as .RData files reduces the file size and and reduces the reading time. Is there some way of appending to an already saved data frame with this method?3. I have come across alternative ways of saving data - using writeBin and packages like saves, rhdf5 etc. Would they be useful alternatives?
4. Is there an advantage in combining binary files and databases like sqlite? Or, are files already saved in a binary format in databases like sqlite?5. What is the simplest method of porting from the access to the sqlite database? With RSQlite and RODBC, can I have connections to the access and sqlite databases open at the same time? Or, should I close one and then open the other? It would help if I can get a detailed bit if code for doing this in a simple way.

I would appreciate all help that I can get.Thanks,Ravi





	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Tue Nov 25 19:09:26 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 25 Nov 2014 19:09:26 +0100
Subject: [R] RStuido seg faults
In-Reply-To: <CAGAtKrJ82AnSrGdrG_oDf+hmfymajxvgD=ma+xyDi99ue5_Ztg@mail.gmail.com>
References: <CAGAtKrJ82AnSrGdrG_oDf+hmfymajxvgD=ma+xyDi99ue5_Ztg@mail.gmail.com>
Message-ID: <A90CF857-227C-4B99-8470-BEABB94E75AF@xs4all.nl>


> On 25-11-2014, at 00:58, Stack Koror? <i.am.stack at gmail.com> wrote:
> 
> Greetings,
> I am having a big issue with RStudio segfaulting recently. It is
> becoming a very big problem for me. I have attached most of the
> information to the support site but no one has responded there. Can
> someone please help me fix RStudio?
> 
> https://support.rstudio.com/hc/communities/public/questions/203655446-Core-Crash-on-SL6-6-and-rstudio-0-98-1091-1
> 

If SL is Snow Leopard (no system mentioned by you) this belongs on R-SIG-Mac.
But this is really for RStudio support. If RStudio needs fixing the RStudio people will have to do that.

Berend

> Thank you!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mtmorgan at fredhutch.org  Tue Nov 25 19:15:27 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Tue, 25 Nov 2014 10:15:27 -0800
Subject: [R] Gender balance in R
In-Reply-To: <CAE3=dmdyACtXiLD40ju7uBi0+KspQk7Z1nW+R4c=w8KgB7v_zw@mail.gmail.com>
References: <54734A50.8090600@qub.ac.uk>	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
	<CAE3=dmdyACtXiLD40ju7uBi0+KspQk7Z1nW+R4c=w8KgB7v_zw@mail.gmail.com>
Message-ID: <5474C73F.8020409@fredhutch.org>

On 11/25/2014 04:11 AM, Scott Kostyshak wrote:
> On Mon, Nov 24, 2014 at 12:34 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> I took a look at apparent gender among list participants a few years ago:
>> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
>>
>> Same general thing: very few regular participants on the list were
>> women. I don't see any sign that that has changed in the last three
>> years. The bar to participation in the R-help list is much, much lower
>> than that to become a developer.
>
> I plotted the gender of posters on r-help over time. The plot is here:
> https://twitter.com/scottkosty/status/449933971644633088
>
> The code to reproduce that plot is here:
> https://github.com/scottkosty/genderAnalysis
> The R file there will call devtools::install_github to install a
> package from Github used for guessing the gender based on the first
> name (https://github.com/scottkosty/gender).

It would be great to include in your package the script that scraped author 
names from R-help archives (I guess that's what you did?). Presumably it easily 
applies to other mailing lists hosted at the same location (R-devel, further 
along the ladder from user to developer, and Bioconductor / Bioc-devel, in a 
different domain and perhaps confounded with a different 'feel' to the list). 
Also the R community is definitely international, so finding more versatile 
gender-assignment approaches seems important.

it might be interesting to ask about participation in mailing list forums versus 
other, and in particular the recent Bioconductor transition from mailing list to 
'StackOverflow' style support forum (https://support.bioconductor.org) -- on the 
one hand the 'gamification' elements might seem to only entrench male 
participation, while on the other we have already seen increased (quantifiable) 
and broader (subjective) participation from the Bioconductor community. I'd be 
happy to make support site usage data available, and am interested in 
collaborating in an academically well-founded analysis of this data; any 
interested parties please feel free to contact me off-list.

Martin Morgan
Bioconductor

>
> Note also on that tweet that Gabriela de Queiroz posted it, who is the
> founder of R-ladies; and that David Smith showed interest in
> discussing the topic. So there is definitely demand for some data
> analysis and discussion on the topic.
>
>> It would be interesting to look at the stats for CRAN packages as well.
>>
>> The very low percentage of regular female participants is one of the
>> things that keeps me active on this list: to demonstrate that it's not
>> only men who use R and participate in the community.
>
> Thank you for that!
>
> Scott
>
>
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University
>
>> (If you decide to do the stats for 2014, be aware that I've been out
>> on medical leave for the past two months, so the numbers are even
>> lower than usual.)
>>
>> Sarah
>>
>> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
>> <maarten.blaauw at qub.ac.uk> wrote:
>>> Hi there,
>>>
>>> I can't help to notice that the gender balance among R developers and
>>> ordinary members is extremely skewed (as it is with open source software in
>>> general).
>>>
>>> Have a look at http://www.r-project.org/foundation/memberlist.html - at most
>>> a handful of women are listed among the 'supporting members', and none at
>>> all among the 29 'ordinary members'.
>>>
>>> On the other hand I personally know many happy R users of both genders.
>>>
>>> My questions are thus: Should R developers (and users) be worried that the
>>> 'other half' is excluded? If so, how could female R users/developers be
>>> persuaded to become more visible (e.g. added as supporting or ordinary
>>> members)?
>>>
>>> Thanks,
>>>
>>> Maarten
>>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From chl948 at mail.usask.ca  Tue Nov 25 18:22:49 2014
From: chl948 at mail.usask.ca (Lee, Chel Hee)
Date: Tue, 25 Nov 2014 11:22:49 -0600
Subject: [R] Converting list to character
In-Reply-To: <1322988993.1763032.1416917258615.JavaMail.root@istat.it>
References: <1322988993.1763032.1416917258615.JavaMail.root@istat.it>
Message-ID: <5474BAE9.3060500@mail.usask.ca>

 > do.call("rbind", TAB$x)
    [,1]     [,2]
1  "GR.3.8" "GR.3.8"
2  "GR.3.1" "GR.3.8"
4  "GR.3.8" "GR.3.8"
5  "GR.3.7" "GR.3.7"
6  "GR.3.8" "GR.3.8"
7  "GR.3.1" "GR.3.8"
9  "GR.3.8" "GR.3.8"
10 "GR.3.7" "GR.3.7"
11 "GR.3.1" "GR.3.1"
12 "GR.3.8" "GR.3.8"
13 "GR.3.1" "GR.3.8"
15 "GR.3.8" "GR.3.8"
16 "GR.3.1" "GR.3.1"
17 "GR.3.8" "GR.3.8"
18 "GR.3.1" "GR.3.8"
20 "GR.3.8" "GR.3.8"
 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 11/25/2014 6:07 AM, Massimiliano Tripoli wrote:
>
>
> Dear all,
>
> I can't convert the result of aggregate function in a dataframe. My data
> looks like:
>
> mydata <- structure(list(ID = c(11, 11, 460, 460, 986, 986, 986, 986, 1251,
> 1251, 1251, 1251, 1251, 1251, 1251, 1251, 1801, 1801, 1801, 1801
> ), YEAR = c(2009, 2010, 2010, 2011, 2008, 2009, 2010, 2011, 2008,
> 2008, 2009, 2009, 2010, 2010, 2011, 2011, 2008, 2009, 2010, 2011
> ), Y = c(158126, 153015, 3701, 5880, 718663, 661112, 527233,
> 558281, 450, 131714, 427, 124648, 425, 116500, 434, 123853, 17400,
> 16493, 8057, 8329), CODE = c("GR.3.7", "GR.3.7", "GR.3.1", "GR.3.1",
> "GR.3.8", "GR.3.8", "GR.3.8", "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.1",
> "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.8", "GR.3.8",
> "GR.3.8", "GR.3.8")), .Names = c("ID", "YEAR", "Y", "CODE"), row.names = c(NA,
> 20L), class = "data.frame")
>
> and by using aggregate function
>
> TAB <- aggregate(mydata$CODE,by=list(ID=mydata$ID,YEAR=mydata$YEAR),FUN=paste0)
>
> What I want is a dataframe like of printing TAB:
>> TAB
>       ID YEAR              x
> 1   986 2008         GR.3.8
> 2  1251 2008 GR.3.1, GR.3.8
> 3  1801 2008         GR.3.8
> 4    11 2009         GR.3.7
> 5   986 2009         GR.3.8
> 6  1251 2009 GR.3.1, GR.3.8
> 7  1801 2009         GR.3.8
> 8    11 2010         GR.3.7
> 9   460 2010         GR.3.1
> 10  986 2010         GR.3.8
> 11 1251 2010 GR.3.1, GR.3.8
> 12 1801 2010         GR.3.8
> 13  460 2011         GR.3.1
> 14  986 2011         GR.3.8
> 15 1251 2011 GR.3.1, GR.3.8
> 16 1801 2011         GR.3.8
>
>> str(TAB)[1:10]
> 'data.frame':        16 obs. of  3 variables:
>   $ ID  : num  986 1251 1801 11 986 ...
>   $ YEAR: num  2008 2008 2008 2009 2009 ...
>   $ x   :List of 16
>    ..$ 1 : chr "GR.3.8"
>    ..$ 2 : chr  "GR.3.1" "GR.3.8"
>    ..$ 4 : chr "GR.3.8"
>    ..$ 5 : chr "GR.3.7"
>    ..$ 6 : chr "GR.3.8"
>    ..$ 7 : chr  "GR.3.1" "GR.3.8"
>    ..$ 9 : chr "GR.3.8"
>    ..$ 10: chr "GR.3.7"
>    ..$ 11: chr "GR.3.1"
>    ..$ 12: chr "GR.3.8"
>    ..$ 13: chr  "GR.3.1" "GR.3.8"
>    ..$ 15: chr "GR.3.8"
>    ..$ 16: chr "GR.3.1"
>    ..$ 17: chr "GR.3.8"
>    ..$ 18: chr  "GR.3.1" "GR.3.8"
>    ..$ 20: chr "GR.3.8"
> NULL
>
> As you can see the "x" coloumn is a list and I would want to change it to character variable.
> Anyone may help me?
> Thanks,
>
> Massimiliano
>


From dcarlson at tamu.edu  Tue Nov 25 19:40:51 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 25 Nov 2014 18:40:51 +0000
Subject: [R] Converting list to character
In-Reply-To: <5474BAE9.3060500@mail.usask.ca>
References: <1322988993.1763032.1416917258615.JavaMail.root@istat.it>
	<5474BAE9.3060500@mail.usask.ca>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FB4E38@mb02.ads.tamu.edu>

Or just modify your aggregate() command:

> TAB <- aggregate(mydata$CODE, by=list(ID=mydata$ID, 
+        YEAR=mydata$YEAR), FUN=paste0, collapse=", ")
> TAB
     ID YEAR              x
1   986 2008         GR.3.8
2  1251 2008 GR.3.1, GR.3.8
3  1801 2008         GR.3.8
4    11 2009         GR.3.7
5   986 2009         GR.3.8
6  1251 2009 GR.3.1, GR.3.8
7  1801 2009         GR.3.8
8    11 2010         GR.3.7
9   460 2010         GR.3.1
10  986 2010         GR.3.8
11 1251 2010 GR.3.1, GR.3.8
12 1801 2010         GR.3.8
13  460 2011         GR.3.1
14  986 2011         GR.3.8
15 1251 2011 GR.3.1, GR.3.8
16 1801 2011         GR.3.8

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Lee, Chel Hee
Sent: Tuesday, November 25, 2014 11:23 AM
To: Massimiliano Tripoli; r-help at r-project.org
Subject: Re: [R] Converting list to character

 > do.call("rbind", TAB$x)
    [,1]     [,2]
1  "GR.3.8" "GR.3.8"
2  "GR.3.1" "GR.3.8"
4  "GR.3.8" "GR.3.8"
5  "GR.3.7" "GR.3.7"
6  "GR.3.8" "GR.3.8"
7  "GR.3.1" "GR.3.8"
9  "GR.3.8" "GR.3.8"
10 "GR.3.7" "GR.3.7"
11 "GR.3.1" "GR.3.1"
12 "GR.3.8" "GR.3.8"
13 "GR.3.1" "GR.3.8"
15 "GR.3.8" "GR.3.8"
16 "GR.3.1" "GR.3.1"
17 "GR.3.8" "GR.3.8"
18 "GR.3.1" "GR.3.8"
20 "GR.3.8" "GR.3.8"
 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 11/25/2014 6:07 AM, Massimiliano Tripoli wrote:
>
>
> Dear all,
>
> I can't convert the result of aggregate function in a dataframe. My data
> looks like:
>
> mydata <- structure(list(ID = c(11, 11, 460, 460, 986, 986, 986, 986, 1251,
> 1251, 1251, 1251, 1251, 1251, 1251, 1251, 1801, 1801, 1801, 1801
> ), YEAR = c(2009, 2010, 2010, 2011, 2008, 2009, 2010, 2011, 2008,
> 2008, 2009, 2009, 2010, 2010, 2011, 2011, 2008, 2009, 2010, 2011
> ), Y = c(158126, 153015, 3701, 5880, 718663, 661112, 527233,
> 558281, 450, 131714, 427, 124648, 425, 116500, 434, 123853, 17400,
> 16493, 8057, 8329), CODE = c("GR.3.7", "GR.3.7", "GR.3.1", "GR.3.1",
> "GR.3.8", "GR.3.8", "GR.3.8", "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.1",
> "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.8", "GR.3.8",
> "GR.3.8", "GR.3.8")), .Names = c("ID", "YEAR", "Y", "CODE"), row.names = c(NA,
> 20L), class = "data.frame")
>
> and by using aggregate function
>
> TAB <- aggregate(mydata$CODE,by=list(ID=mydata$ID,YEAR=mydata$YEAR),FUN=paste0)
>
> What I want is a dataframe like of printing TAB:
>> TAB
>       ID YEAR              x
> 1   986 2008         GR.3.8
> 2  1251 2008 GR.3.1, GR.3.8
> 3  1801 2008         GR.3.8
> 4    11 2009         GR.3.7
> 5   986 2009         GR.3.8
> 6  1251 2009 GR.3.1, GR.3.8
> 7  1801 2009         GR.3.8
> 8    11 2010         GR.3.7
> 9   460 2010         GR.3.1
> 10  986 2010         GR.3.8
> 11 1251 2010 GR.3.1, GR.3.8
> 12 1801 2010         GR.3.8
> 13  460 2011         GR.3.1
> 14  986 2011         GR.3.8
> 15 1251 2011 GR.3.1, GR.3.8
> 16 1801 2011         GR.3.8
>
>> str(TAB)[1:10]
> 'data.frame':        16 obs. of  3 variables:
>   $ ID  : num  986 1251 1801 11 986 ...
>   $ YEAR: num  2008 2008 2008 2009 2009 ...
>   $ x   :List of 16
>    ..$ 1 : chr "GR.3.8"
>    ..$ 2 : chr  "GR.3.1" "GR.3.8"
>    ..$ 4 : chr "GR.3.8"
>    ..$ 5 : chr "GR.3.7"
>    ..$ 6 : chr "GR.3.8"
>    ..$ 7 : chr  "GR.3.1" "GR.3.8"
>    ..$ 9 : chr "GR.3.8"
>    ..$ 10: chr "GR.3.7"
>    ..$ 11: chr "GR.3.1"
>    ..$ 12: chr "GR.3.8"
>    ..$ 13: chr  "GR.3.1" "GR.3.8"
>    ..$ 15: chr "GR.3.8"
>    ..$ 16: chr "GR.3.1"
>    ..$ 17: chr "GR.3.8"
>    ..$ 18: chr  "GR.3.1" "GR.3.8"
>    ..$ 20: chr "GR.3.8"
> NULL
>
> As you can see the "x" coloumn is a list and I would want to change it to character variable.
> Anyone may help me?
> Thanks,
>
> Massimiliano
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Nov 25 19:57:32 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 25 Nov 2014 11:57:32 -0700
Subject: [R] Packages for Handling Large Data Set
In-Reply-To: <CAFp0RzW_ig=QMwtg0DV4_kuV4nVy8h411mLXyrEurTOFtWTneg@mail.gmail.com>
References: <CAFp0RzW_ig=QMwtg0DV4_kuV4nVy8h411mLXyrEurTOFtWTneg@mail.gmail.com>
Message-ID: <CAFEqCdwB--i9AFcY6i8Eoy-Kb=gRNa9QTXwtmXPxk7foL707eg@mail.gmail.com>

Look at the task view for High Performance Computing (
http://cran.r-project.org/web/views/HighPerformanceComputing.html) there is
a section on packages for large memory and out-of-memory analyses.  There
are also sections on parallel computing which is one way to deal with large
data if you have access to the right type of cluster (part of the dataset
lives on each machine so can fit in the local memory).


On Tue, Nov 25, 2014 at 6:06 AM, jeeth ghambole <jeethghambole at gmail.com>
wrote:

> Hello All,
>
> I am working on BackTesting Strategies on stocks using daily prices.
>
> Initially the size of data was very limited and can be easily handled using
> R and SQL, but now my analysis has been extending on large set of data. Can
> anyone suggest me the best packages available for handling large datasets.
>
> Thank you.
>
> With Regards,
> Jeeth G.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Nov 25 20:03:38 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 25 Nov 2014 11:03:38 -0800
Subject: [R] porting an access database to sqlite
In-Reply-To: <420701908.1025092.1416937298206.JavaMail.yahoo@jws11104.mail.ir2.yahoo.com>
References: <420701908.1025092.1416937298206.JavaMail.yahoo@jws11104.mail.ir2.yahoo.com>
Message-ID: <43C777F0-6198-4B40-8185-18311F1B70AE@dcn.davis.CA.us>

Counting rows is not something RODBC is supposed to do. That is a very basic SQL query that you can use RODBC to execute:

SELECT COUNT(*) FROM yourtablename

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 25, 2014 9:41:38 AM PST, ravi <rv15i at yahoo.se> wrote:
>Hi,All my data is presently locked in a Microsoft access database. This
>has huge data in a number of large tables. Using RODBC and connecting
>to it takes too long a time, sometimes making the system to hang up. 
>
>To make things more manageable, I have tried to transfer the data to
>manageable .RData or .csv files. But I am not able to do this with some
>of the larger files. I am currently stuck in the one of the preliminary
>steps. I am not able to find the number of rows in a table. If I know
>this, I can transfer chunks of the tables to a sqlite database.
>I am able to connect to connect to the access data base with :
>library(RODBC)
>con<-odbcConnect("TestDB")d1<-sqlFetch(ch,"table1",max=1e5,as.is=TRUE)d2<-sqlFetchMore(ch,max=1e5,as.is=TRUE)
>d3<-rbind(d1,d2)I wanted to develop this into a loop to get a
>concatenated data frame, which I wanted to save either as a binary
>file, or transfer it to a sqlite data base. I would like to have some
>help on the simplest route to follow. But first, I will proceed in
>describing my immediate problem. In some of the tables, I find that the
>sqlFetchMore returns a value of -1L, meaning that the end has been
>reached. In RODBC, I find no command for getting the row count in a
>table. I have found this in DBI. But I have not been able to figure out
>how I should specify the connection to an acccess database (con in the
>following).
>
>while(!dbHasCompleted(con)){?? print(dbGetRowCount(con))}
>I would appreciate help on the following points :1. How can I get the
>row count (and size) of a table in an access data base? With RODBC, DBI
>or any other way.2. I have found that saving the tables as .RData files
>reduces the file size and and reduces the reading time. Is there some
>way of appending to an already saved data frame with this method?3. I
>have come across alternative ways of saving data - using writeBin and
>packages like saves, rhdf5 etc. Would they be useful alternatives?
>4. Is there an advantage in combining binary files and databases like
>sqlite? Or, are files already saved in a binary format in databases
>like sqlite?5. What is the simplest method of porting from the access
>to the sqlite database? With RSQlite and RODBC, can I have connections
>to the access and sqlite databases open at the same time? Or, should I
>close one and then open the other? It would help if I can get a
>detailed bit if code for doing this in a simple way.
>
>I would appreciate all help that I can get.Thanks,Ravi
>
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Nov 25 20:29:07 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 26 Nov 2014 08:29:07 +1300
Subject: [R] plot.hclust point to older version
In-Reply-To: <D099F8A7.A3D1%mmason@benaroyaresearch.org>
References: <D099F8A7.A3D1%mmason@benaroyaresearch.org>
Message-ID: <5474D883.8090304@auckland.ac.nz>



Reproducible example???

(I know from noddink about hclust, but I tried the example from the help 
page and it plotted without any problem.)

cheers,

Rolf Turner

On 26/11/14 06:13, Michael Mason wrote:
> Hello fellow R users,
>
> I have recently updated to R 3.1.2. When trying to plot an hclust object to generate the dendrogram I get the following error:
>
> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>    there is no .Internal function 'dend.window'
>
>
> I am indeed using R3.1.2 but my understanding is that the .Internal API to the C code is no longer used. I have tried detaching the stats package and restarting R to no avail.
> I would love any help from any wiser guRus.

-- 
Rolf Turner
Technical Editor ANZJS


From tom at maladmin.com  Tue Nov 25 21:12:21 2014
From: tom at maladmin.com (Tom Wright)
Date: Tue, 25 Nov 2014 15:12:21 -0500
Subject: [R] Presentation tables in R (knitr)
Message-ID: <1416946341.1909.23.camel@tom-laptop>

Hi,
This problem has me stumped so I thought I'd ask the experts. I'm trying
to create a pretty summary table of some data (which patients have had
what tests at what times). Ideally I'd like to knitr this into a pretty
PDF for presentation.
If anyone has pointers I'll be grateful.

require(tables)
require(reshape2)

data<-data.frame('ID'=paste0('pat',c(rep(1,8),rep(2,8))),
                 'Time'=c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4),
                 'Eye'=rep(c('OS','OS','OD','OD'),4),
                 'Measure'=rep(c('Height','Weight'),8))

tabular(Measure~factor(ID)*factor(Time)*factor(Eye),data)
#All levels of Time are repeated for all IDs, I'd prefer to just show
the relevant times.

tabular(Measure~factor(ID)*Time*factor(Eye),data)
#Time is getting collapsed by ID

data$value=1
dcast(data,Measure~ID+Time+Eye)
#close but not very pretty


From i.am.stack at gmail.com  Tue Nov 25 19:43:24 2014
From: i.am.stack at gmail.com (~Stack~)
Date: Tue, 25 Nov 2014 12:43:24 -0600
Subject: [R] RStuido seg faults
In-Reply-To: <A90CF857-227C-4B99-8470-BEABB94E75AF@xs4all.nl>
References: <CAGAtKrJ82AnSrGdrG_oDf+hmfymajxvgD=ma+xyDi99ue5_Ztg@mail.gmail.com>
	<A90CF857-227C-4B99-8470-BEABB94E75AF@xs4all.nl>
Message-ID: <5474CDCC.1040104@gmail.com>

On 11/25/2014 12:09 PM, Berend Hasselman wrote:
> 
> If SL is Snow Leopard (no system mentioned by you) this belongs on R-SIG-Mac.

Actually, I did mention it:
"My OS: Scientific Linux 6.6"

> But this is really for RStudio support. If RStudio needs fixing the RStudio people will have to do that.

I tried that with the link above and have not gotten a reply. I thought
I would try the mailing list to see if someone else might recognize the
problem and provide some assistance. Maybe I will luck out? :-)

Thanks!


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 198 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141125/f0bb7a43/attachment.bin>

From i.am.stack at gmail.com  Tue Nov 25 19:44:34 2014
From: i.am.stack at gmail.com (~Stack~)
Date: Tue, 25 Nov 2014 12:44:34 -0600
Subject: [R] RStuido seg faults
In-Reply-To: <7AD20F17-B626-4321-8D83-29B6F02E7ADF@TxBiomed.org>
References: <CAGAtKrJ82AnSrGdrG_oDf+hmfymajxvgD=ma+xyDi99ue5_Ztg@mail.gmail.com>
	<7AD20F17-B626-4321-8D83-29B6F02E7ADF@TxBiomed.org>
Message-ID: <5474CE12.2070908@gmail.com>

On 11/25/2014 12:01 PM, Mark Sharp wrote:
> Have you tried the current version of R, 3.1.2?

I have not. I haven't had many issues in the past using what was in the
EPEL repos. Let me take one of my dev boxes and give it a try.

I will post back what I find.

Thanks!


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 198 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141125/71a97116/attachment.bin>

From r.turner at auckland.ac.nz  Tue Nov 25 21:18:14 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 26 Nov 2014 09:18:14 +1300
Subject: [R] plot.hclust point to older version
In-Reply-To: <D09A1DE8.A4AF%mmason@benaroyaresearch.org>
References: <D09A1DE8.A4AF%mmason@benaroyaresearch.org>
Message-ID: <5474E406.40806@auckland.ac.nz>

On 26/11/14 08:53, Michael Mason wrote:
> Here you are. I expect most folks won't get the error.
>
> N   = 100; M = 1000
> mat = matrix(1:(N*M) + rnorm(N*M,0,.5),N,M)
> h   = hclust(as.dist(1-cor(mat)))
> plot(h)
>
> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>    there is no .Internal function 'dend.window'
>
>
>
> Thanks again
>
>
> On 11/25/14 11:29 AM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>
>>
>>
>> Reproducible example???
>>
>> (I know from noddink about hclust, but I tried the example from the help
>> page and it plotted without any problem.)
>>
>> cheers,
>>
>> Rolf Turner
>>
>> On 26/11/14 06:13, Michael Mason wrote:
>>> Hello fellow R users,
>>>
>>> I have recently updated to R 3.1.2. When trying to plot an hclust
>>> object to generate the dendrogram I get the following error:
>>>
>>> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>>>     there is no .Internal function 'dend.window'
>>>
>>>
>>> I am indeed using R3.1.2 but my understanding is that the .Internal API
>>> to the C code is no longer used. I have tried detaching the stats
>>> package and restarting R to no avail.
>>> I would love any help from any wiser guRus.

Please keep communications on-list; there are others on the list far 
more likely to be able to help you than I.  I am cc-ing this reply to 
the list.

For what it's worth, I can run your example without error.

As to how to track down what is going wrong on your system, I'm afraid I 
have no idea.  Someone on the list may have some thoughts.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From msharp at txbiomed.org  Tue Nov 25 21:37:17 2014
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 25 Nov 2014 14:37:17 -0600
Subject: [R] Presentation tables in R (knitr)
In-Reply-To: <1416946341.1909.23.camel@tom-laptop>
References: <1416946341.1909.23.camel@tom-laptop>
Message-ID: <FD3A290A-3CE7-4B97-AA9D-18F3C58490A9@txbiomed.org>

Tom,

If you are wanting PDF as your output, are you wanting to use LaTeX or Markdown with knitr. LaTeX will give you more options. You have not shown an attempt to use either for your table construction. Can you define what you mean by pretty? Is it the underscores in the column names that are the problem?

Mark
> On Nov 25, 2014, at 2:12 PM, Tom Wright <tom at maladmin.com> wrote:
>
> Hi,
> This problem has me stumped so I thought I'd ask the experts. I'm trying
> to create a pretty summary table of some data (which patients have had
> what tests at what times). Ideally I'd like to knitr this into a pretty
> PDF for presentation.
> If anyone has pointers I'll be grateful.
>
> require(tables)
> require(reshape2)
>
> data<-data.frame('ID'=paste0('pat',c(rep(1,8),rep(2,8))),
>                 'Time'=c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4),
>                 'Eye'=rep(c('OS','OS','OD','OD'),4),
>                 'Measure'=rep(c('Height','Weight'),8))
>
> tabular(Measure~factor(ID)*factor(Time)*factor(Eye),data)
> #All levels of Time are repeated for all IDs, I'd prefer to just show
> the relevant times.
>
> tabular(Measure~factor(ID)*Time*factor(Eye),data)
> #Time is getting collapsed by ID
>
> data$value=1
> dcast(data,Measure~ID+Time+Eye)
> #close but not very pretty
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From wdunlap at tibco.com  Tue Nov 25 21:53:14 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 25 Nov 2014 12:53:14 -0800
Subject: [R] plot.hclust point to older version
In-Reply-To: <5474E406.40806@auckland.ac.nz>
References: <D09A1DE8.A4AF%mmason@benaroyaresearch.org>
	<5474E406.40806@auckland.ac.nz>
Message-ID: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>

You probably have a local copy of an old version of plot.hclust or
plot.dendrogram in your global environmenet or another package that masks
the one in package:stats.  E.g., I fired up R-2.14.2 and copied those 2
plot methods to .GlobalEnv and then saved by workspace when quitting R.  I
then fired up R-3.1.1, which loads the workspace saved by the older version
of R.  I get:

> objects()
[1] "plot.dendrogram" "plot.hclust"
> plot(hclust(dist(c(2,3,5,7,11,13,17,19))))
Error in .Internal(dend.window(n, merge, height, hang, labels, ...)) :
  there is no .Internal function 'dend.window'
> traceback()
2: plot.hclust(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
1: plot(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))

Note how calling traceback() after an error gives more information about
the source of the error.

To fix this, get rid of the .RData file that is being loaded when R starts.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 25, 2014 at 12:18 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 26/11/14 08:53, Michael Mason wrote:
>
>> Here you are. I expect most folks won't get the error.
>>
>> N   = 100; M = 1000
>> mat = matrix(1:(N*M) + rnorm(N*M,0,.5),N,M)
>> h   = hclust(as.dist(1-cor(mat)))
>> plot(h)
>>
>> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>>    there is no .Internal function 'dend.window'
>>
>>
>>
>> Thanks again
>>
>>
>> On 11/25/14 11:29 AM, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>
>>
>>>
>>> Reproducible example???
>>>
>>> (I know from noddink about hclust, but I tried the example from the help
>>> page and it plotted without any problem.)
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>> On 26/11/14 06:13, Michael Mason wrote:
>>>
>>>> Hello fellow R users,
>>>>
>>>> I have recently updated to R 3.1.2. When trying to plot an hclust
>>>> object to generate the dendrogram I get the following error:
>>>>
>>>> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>>>>     there is no .Internal function 'dend.window'
>>>>
>>>>
>>>> I am indeed using R3.1.2 but my understanding is that the .Internal API
>>>> to the C code is no longer used. I have tried detaching the stats
>>>> package and restarting R to no avail.
>>>> I would love any help from any wiser guRus.
>>>>
>>>
> Please keep communications on-list; there are others on the list far more
> likely to be able to help you than I.  I am cc-ing this reply to the list.
>
> For what it's worth, I can run your example without error.
>
> As to how to track down what is going wrong on your system, I'm afraid I
> have no idea.  Someone on the list may have some thoughts.
>
> cheers,
>
> Rolf Turner
>
> --
> Rolf Turner
> Technical Editor ANZJS
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom at maladmin.com  Tue Nov 25 22:07:00 2014
From: tom at maladmin.com (Tom Wright)
Date: Tue, 25 Nov 2014 16:07:00 -0500
Subject: [R] Presentation tables in R (knitr)
In-Reply-To: <FD3A290A-3CE7-4B97-AA9D-18F3C58490A9@txbiomed.org>
References: <1416946341.1909.23.camel@tom-laptop>
	<FD3A290A-3CE7-4B97-AA9D-18F3C58490A9@txbiomed.org>
Message-ID: <CAKmUXV9mA+m6HoWvPhCNF=FWN19A_tmkTK3zvmYY08VFkk7a+w@mail.gmail.com>

Hi Mark,
It is the underscores that are my issue, I'd prefer multiple level row
titles:

           |ID1                 |ID2
           |Time1   |Time2  |Time1  |Time2
           |OD |OS |OD |OS|OD |OS |OD |OS
Height | 1    | 1  |  1   | 1 |  1   |  1  |  1  |  1
Weight| 1    | 1  |  1   | 1 |  1   |  1  |  1  |  1

Currently I'm using markdown in r-studio.

And yes, I know the same information is in the dcast solution but I'm
trying to convince people R is an alternative to excel.



On Tue, Nov 25, 2014 at 3:37 PM, Mark Sharp <msharp at txbiomed.org> wrote:

> Tom,
>
> If you are wanting PDF as your output, are you wanting to use LaTeX or
> Markdown with knitr. LaTeX will give you more options. You have not shown
> an attempt to use either for your table construction. Can you define what
> you mean by pretty? Is it the underscores in the column names that are the
> problem?
>
> Mark
> > On Nov 25, 2014, at 2:12 PM, Tom Wright <tom at maladmin.com> wrote:
> >
> > Hi,
> > This problem has me stumped so I thought I'd ask the experts. I'm trying
> > to create a pretty summary table of some data (which patients have had
> > what tests at what times). Ideally I'd like to knitr this into a pretty
> > PDF for presentation.
> > If anyone has pointers I'll be grateful.
> >
> > require(tables)
> > require(reshape2)
> >
> > data<-data.frame('ID'=paste0('pat',c(rep(1,8),rep(2,8))),
> >                 'Time'=c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4),
> >                 'Eye'=rep(c('OS','OS','OD','OD'),4),
> >                 'Measure'=rep(c('Height','Weight'),8))
> >
> > tabular(Measure~factor(ID)*factor(Time)*factor(Eye),data)
> > #All levels of Time are repeated for all IDs, I'd prefer to just show
> > the relevant times.
> >
> > tabular(Measure~factor(ID)*Time*factor(Eye),data)
> > #Time is getting collapsed by ID
> >
> > data$value=1
> > dcast(data,Measure~ID+Time+Eye)
> > #close but not very pretty
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
> NOTICE:  This E-Mail (including attachments) is confidential and may be
> legally privileged.  It is covered by the Electronic Communications Privacy
> Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are
> hereby notified that any retention, dissemination, distribution or copying
> of this communication is strictly prohibited.  Please reply to the sender
> that you have received this message in error, then delete it.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Nov 25 22:37:02 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Nov 2014 16:37:02 -0500
Subject: [R] Presentation tables in R (knitr)
In-Reply-To: <1416946341.1909.23.camel@tom-laptop>
References: <1416946341.1909.23.camel@tom-laptop>
Message-ID: <5474F67E.5090203@gmail.com>

On 25/11/2014 3:12 PM, Tom Wright wrote:
> Hi,
> This problem has me stumped so I thought I'd ask the experts. I'm trying
> to create a pretty summary table of some data (which patients have had
> what tests at what times). Ideally I'd like to knitr this into a pretty
> PDF for presentation.
> If anyone has pointers I'll be grateful.
>
> require(tables)
> require(reshape2)
>
> data<-data.frame('ID'=paste0('pat',c(rep(1,8),rep(2,8))),
>                   'Time'=c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4),
>                   'Eye'=rep(c('OS','OS','OD','OD'),4),
>                   'Measure'=rep(c('Height','Weight'),8))
>
> tabular(Measure~factor(ID)*factor(Time)*factor(Eye),data)
> #All levels of Time are repeated for all IDs, I'd prefer to just show
> the relevant times.

You can drop certain rows of the table.  See the last example in 
?tabular.  (It's possible to do logical indexing, but a little harder.  
I think the vignette has an example of this...)

You can use latex() on the results, and display them in a knitr document.

Duncan Murdoch
>
> tabular(Measure~factor(ID)*Time*factor(Eye),data)
> #Time is getting collapsed by ID
>
> data$value=1
> dcast(data,Measure~ID+Time+Eye)
> #close but not very pretty
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tom at maladmin.com  Tue Nov 25 22:47:00 2014
From: tom at maladmin.com (Tom Wright)
Date: Tue, 25 Nov 2014 16:47:00 -0500
Subject: [R] Presentation tables in R (knitr)
In-Reply-To: <5474F67E.5090203@gmail.com>
References: <1416946341.1909.23.camel@tom-laptop> <5474F67E.5090203@gmail.com>
Message-ID: <CAKmUXV-aPPpGhFrLLERPag3h5ghhVUYxM+Y7kTrCm=nPJjuLyw@mail.gmail.com>

Thanks Duncan,
Dropping the extra columns might be the way forward. I'm sure I can work
out how to embed latex into a markdown document ;-)

On Tue, Nov 25, 2014 at 4:37 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 25/11/2014 3:12 PM, Tom Wright wrote:
>
>> Hi,
>> This problem has me stumped so I thought I'd ask the experts. I'm trying
>> to create a pretty summary table of some data (which patients have had
>> what tests at what times). Ideally I'd like to knitr this into a pretty
>> PDF for presentation.
>> If anyone has pointers I'll be grateful.
>>
>> require(tables)
>> require(reshape2)
>>
>> data<-data.frame('ID'=paste0('pat',c(rep(1,8),rep(2,8))),
>>                   'Time'=c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4),
>>                   'Eye'=rep(c('OS','OS','OD','OD'),4),
>>                   'Measure'=rep(c('Height','Weight'),8))
>>
>> tabular(Measure~factor(ID)*factor(Time)*factor(Eye),data)
>> #All levels of Time are repeated for all IDs, I'd prefer to just show
>> the relevant times.
>>
>
> You can drop certain rows of the table.  See the last example in
> ?tabular.  (It's possible to do logical indexing, but a little harder.  I
> think the vignette has an example of this...)
>
> You can use latex() on the results, and display them in a knitr document.
>
> Duncan Murdoch
>
>>
>> tabular(Measure~factor(ID)*Time*factor(Eye),data)
>> #Time is getting collapsed by ID
>>
>> data$value=1
>> dcast(data,Measure~ID+Time+Eye)
>> #close but not very pretty
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Nov 25 22:54:44 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 25 Nov 2014 13:54:44 -0800
Subject: [R] Presentation tables in R (knitr)
In-Reply-To: <CAKmUXV9mA+m6HoWvPhCNF=FWN19A_tmkTK3zvmYY08VFkk7a+w@mail.gmail.com>
References: <1416946341.1909.23.camel@tom-laptop>
	<FD3A290A-3CE7-4B97-AA9D-18F3C58490A9@txbiomed.org>
	<CAKmUXV9mA+m6HoWvPhCNF=FWN19A_tmkTK3zvmYY08VFkk7a+w@mail.gmail.com>
Message-ID: <62533149-A8A5-4922-9A3C-DD4A36F25A55@dcn.davis.CA.us>

Pebbles in sand are also an alternative to Excel, but that doesn't mean people want to switch to abaci. Horse, meet water.

If you use LaTeX (or Rmarkdown-to-pdf in RStudio), then you can obtain much better looking tables using latex.tabular(). Unfortunately, LaTeX is just too scary for some people.  First time you try tell them how to tweak the column widths they will drop your toolchain like a hot rock. I recommend the Tom Sawyer approach for long-lasting results... but don't expect your fence to get painted this year.

Also, this is neither a LaTeX nor an RStudio support forum, but R is sort of in the middle and we presume you know about the others. Getting your lessons in multiple forums seems unfriendly, but that is the price of feeding a file through a sequence of knitr, rmarkdown, pandoc, and pdflatex processing, even if RStudio lets you do it with a single push of a button.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 25, 2014 1:07:00 PM PST, Tom Wright <tom at maladmin.com> wrote:
>Hi Mark,
>It is the underscores that are my issue, I'd prefer multiple level row
>titles:
>
>           |ID1                 |ID2
>           |Time1   |Time2  |Time1  |Time2
>           |OD |OS |OD |OS|OD |OS |OD |OS
>Height | 1    | 1  |  1   | 1 |  1   |  1  |  1  |  1
>Weight| 1    | 1  |  1   | 1 |  1   |  1  |  1  |  1
>
>Currently I'm using markdown in r-studio.
>
>And yes, I know the same information is in the dcast solution but I'm
>trying to convince people R is an alternative to excel.
>
>
>
>On Tue, Nov 25, 2014 at 3:37 PM, Mark Sharp <msharp at txbiomed.org>
>wrote:
>
>> Tom,
>>
>> If you are wanting PDF as your output, are you wanting to use LaTeX
>or
>> Markdown with knitr. LaTeX will give you more options. You have not
>shown
>> an attempt to use either for your table construction. Can you define
>what
>> you mean by pretty? Is it the underscores in the column names that
>are the
>> problem?
>>
>> Mark
>> > On Nov 25, 2014, at 2:12 PM, Tom Wright <tom at maladmin.com> wrote:
>> >
>> > Hi,
>> > This problem has me stumped so I thought I'd ask the experts. I'm
>trying
>> > to create a pretty summary table of some data (which patients have
>had
>> > what tests at what times). Ideally I'd like to knitr this into a
>pretty
>> > PDF for presentation.
>> > If anyone has pointers I'll be grateful.
>> >
>> > require(tables)
>> > require(reshape2)
>> >
>> > data<-data.frame('ID'=paste0('pat',c(rep(1,8),rep(2,8))),
>> >                 'Time'=c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4),
>> >                 'Eye'=rep(c('OS','OS','OD','OD'),4),
>> >                 'Measure'=rep(c('Height','Weight'),8))
>> >
>> > tabular(Measure~factor(ID)*factor(Time)*factor(Eye),data)
>> > #All levels of Time are repeated for all IDs, I'd prefer to just
>show
>> > the relevant times.
>> >
>> > tabular(Measure~factor(ID)*Time*factor(Eye),data)
>> > #Time is getting collapsed by ID
>> >
>> > data$value=1
>> > dcast(data,Measure~ID+Time+Eye)
>> > #close but not very pretty
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> NOTICE:  This E-Mail (including attachments) is confidential and may
>be
>> legally privileged.  It is covered by the Electronic Communications
>Privacy
>> Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you
>are
>> hereby notified that any retention, dissemination, distribution or
>copying
>> of this communication is strictly prohibited.  Please reply to the
>sender
>> that you have received this message in error, then delete it.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kristi.glover at hotmail.com  Wed Nov 26 01:57:44 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Tue, 25 Nov 2014 20:57:44 -0400
Subject: [R] covariate or predictor
Message-ID: <COL130-W48F49774E273E5AE354DEDFA700@phx.gbl>

Hi, 
I am wondering how I can separate whether it is covariate or predictor in the ANOVA analysis. For example
 A<-structure(list(Machine = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 3L, 3L, 3L, 3L, 3L), Diameter = c(20L, 25L, 24L, 25L, 32L, 
22L, 28L, 22L, 30L, 28L, 21L, 23L, 26L, 21L, 15L), Strength = c(36L, 
41L, 39L, 42L, 49L, 40L, 48L, 39L, 45L, 44L, 35L, 37L, 42L, 34L, 
32L)), .Names = c("Machine", "Diameter", "Strength"), class = "data.frame", row.names = c(NA, 
-15L))
attach(A)
b<-aov(Strength~Diameter)
summary(b)
c<-aov(Strength~Diameter+as.factor(Machine))
summary(c)
I am confused here whether the "Mechine" is covariate or predictor.  How do I know which one is covariate and predictor? 
If Machine is predictor (just like Diameter), how I am supposed to write in the model?
is the equation (below) for this one in the condition that the Machine is predictor? 
c1<-aov(Strength~Diameter+Machine), ?????. If it is so, it means that co-variate is  dummy variable, right????
Your help will really help me to clear the concept. 

Thanks 

KG


 		 	   		  
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Nov 26 03:13:02 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 26 Nov 2014 15:13:02 +1300
Subject: [R] covariate or predictor
In-Reply-To: <COL130-W48F49774E273E5AE354DEDFA700@phx.gbl>
References: <COL130-W48F49774E273E5AE354DEDFA700@phx.gbl>
Message-ID: <5475372E.3010304@auckland.ac.nz>

On 26/11/14 13:57, Kristi Glover wrote:
> Hi,
> I am wondering how I can separate whether it is covariate or predictor in the ANOVA analysis. For example
>   A<-structure(list(Machine = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L), Diameter = c(20L, 25L, 24L, 25L, 32L,
> 22L, 28L, 22L, 30L, 28L, 21L, 23L, 26L, 21L, 15L), Strength = c(36L,
> 41L, 39L, 42L, 49L, 40L, 48L, 39L, 45L, 44L, 35L, 37L, 42L, 34L,
> 32L)), .Names = c("Machine", "Diameter", "Strength"), class = "data.frame", row.names = c(NA,
> -15L))
> attach(A)
> b<-aov(Strength~Diameter)
> summary(b)
> c<-aov(Strength~Diameter+as.factor(Machine))
> summary(c)
> I am confused here whether the "Mechine" is covariate or predictor.  How do I know which one is covariate and predictor?
> If Machine is predictor (just like Diameter), how I am supposed to write in the model?
> is the equation (below) for this one in the condition that the Machine is predictor?
> c1<-aov(Strength~Diameter+Machine), ?????. If it is so, it means that co-variate is  dummy variable, right????
> Your help will really help me to clear the concept.


(1) Please don't post in HTML; messages with code in them become unreadable.

(2) This isn't really an R question is it?  Possibly better posted to 
stackexchange.

(3) What in your mind is the difference between "covariate" and 
"predictor"?  In my (possibly limited) understanding, the words are 
synonymous.

(4) Are you perhaps concerned with the difference between a continuous 
predictor and a categorical (factor) predictor?

(5) In your example "Machine" is pretty clearly *categorical*; the
numbers 1, 2, and 3 are just *labels* for the machines; their numerical 
value is of no significance.  The labels could just as well be "A", "B"
and "C", or "melvin", "irving" and "clyde".

(6) OTOH "Diameter" is pretty obviously interpretable as a *numerical*
measurement.

(7) I have no idea what you mean by "If it is so, it means that 
co-variate is  dummy variable, right????"  Would you care to translate 
that into English?

cheers,

Rolf Turner


-- 
Rolf Turner
Technical Editor ANZJS


From gunter.berton at gene.com  Wed Nov 26 03:49:04 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 25 Nov 2014 18:49:04 -0800
Subject: [R] covariate or predictor
In-Reply-To: <5475372E.3010304@auckland.ac.nz>
References: <COL130-W48F49774E273E5AE354DEDFA700@phx.gbl>
	<5475372E.3010304@auckland.ac.nz>
Message-ID: <CACk-te2=NSM1oPL6cWaU0V9Lsxg4PdBUUDvE_K6_UdFnUR+Y_Q@mail.gmail.com>

Yes, Rolf -- she seems to think that covariates must be categorical
and predictors categorical -- or maybe it's vice-versa. Anyway, she
apparently has not done any homework (e.g. by reading an Intro to R)
and so doesn't understand the use of modeling formulas in lm() and
thus does not understand the use of contrasts (= dummy variables). As
you said, either stackexchange or perhaps a local consultant is
probably where she should be seeking advice,

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Nov 25, 2014 at 6:13 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 26/11/14 13:57, Kristi Glover wrote:
>>
>> Hi,
>> I am wondering how I can separate whether it is covariate or predictor in
>> the ANOVA analysis. For example
>>   A<-structure(list(Machine = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 2L, 3L, 3L, 3L, 3L, 3L), Diameter = c(20L, 25L, 24L, 25L, 32L,
>> 22L, 28L, 22L, 30L, 28L, 21L, 23L, 26L, 21L, 15L), Strength = c(36L,
>> 41L, 39L, 42L, 49L, 40L, 48L, 39L, 45L, 44L, 35L, 37L, 42L, 34L,
>> 32L)), .Names = c("Machine", "Diameter", "Strength"), class =
>> "data.frame", row.names = c(NA,
>> -15L))
>> attach(A)
>> b<-aov(Strength~Diameter)
>> summary(b)
>> c<-aov(Strength~Diameter+as.factor(Machine))
>> summary(c)
>> I am confused here whether the "Mechine" is covariate or predictor.  How
>> do I know which one is covariate and predictor?
>> If Machine is predictor (just like Diameter), how I am supposed to write
>> in the model?
>> is the equation (below) for this one in the condition that the Machine is
>> predictor?
>> c1<-aov(Strength~Diameter+Machine), ?????. If it is so, it means that
>> co-variate is  dummy variable, right????
>> Your help will really help me to clear the concept.
>
>
>
> (1) Please don't post in HTML; messages with code in them become unreadable.
>
> (2) This isn't really an R question is it?  Possibly better posted to
> stackexchange.
>
> (3) What in your mind is the difference between "covariate" and "predictor"?
> In my (possibly limited) understanding, the words are synonymous.
>
> (4) Are you perhaps concerned with the difference between a continuous
> predictor and a categorical (factor) predictor?
>
> (5) In your example "Machine" is pretty clearly *categorical*; the
> numbers 1, 2, and 3 are just *labels* for the machines; their numerical
> value is of no significance.  The labels could just as well be "A", "B"
> and "C", or "melvin", "irving" and "clyde".
>
> (6) OTOH "Diameter" is pretty obviously interpretable as a *numerical*
> measurement.
>
> (7) I have no idea what you mean by "If it is so, it means that co-variate
> is  dummy variable, right????"  Would you care to translate that into
> English?
>
> cheers,
>
> Rolf Turner
>
>
> --
> Rolf Turner
> Technical Editor ANZJS
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Nov 26 04:08:52 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 26 Nov 2014 16:08:52 +1300
Subject: [R] covariate or predictor
In-Reply-To: <CACk-te2=NSM1oPL6cWaU0V9Lsxg4PdBUUDvE_K6_UdFnUR+Y_Q@mail.gmail.com>
References: <COL130-W48F49774E273E5AE354DEDFA700@phx.gbl>	<5475372E.3010304@auckland.ac.nz>
	<CACk-te2=NSM1oPL6cWaU0V9Lsxg4PdBUUDvE_K6_UdFnUR+Y_Q@mail.gmail.com>
Message-ID: <54754444.5040307@auckland.ac.nz>

On 26/11/14 15:49, Bert Gunter wrote:
> Yes, Rolf -- she seems to think that covariates must be categorical
> and predictors categorical -- or maybe it's vice-versa.


You of course meant "... covariates must be categorical
and predictors numerical -- or maybe it's vice-versa."

(I can't help persistently putting my Technical Editor hat on. :-))

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS


From MMason at benaroyaresearch.org  Tue Nov 25 22:01:32 2014
From: MMason at benaroyaresearch.org (Michael Mason)
Date: Tue, 25 Nov 2014 21:01:32 +0000
Subject: [R] plot.hclust point to older version
In-Reply-To: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
Message-ID: <D09A2E1A.A4BF%mmason@benaroyaresearch.org>

Thanks! That worked

From: William Dunlap <wdunlap at tibco.com<mailto:wdunlap at tibco.com>>
Date: Tuesday, November 25, 2014 12:53 PM
To: Rolf Turner <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>
Cc: Michael Mason <mmason at benaroyaresearch.org<mailto:mmason at benaroyaresearch.org>>, R help <R-help at r-project.org<mailto:R-help at r-project.org>>
Subject: Re: [R] plot.hclust point to older version

You probably have a local copy of an old version of plot.hclust or plot.dendrogram in your global environmenet or another package that masks the one in package:stats.  E.g., I fired up R-2.14.2 and copied those 2 plot methods to .GlobalEnv and then saved by workspace when quitting R.  I then fired up R-3.1.1, which loads the workspace saved by the older version of R.  I get:

> objects()
[1] "plot.dendrogram" "plot.hclust"
> plot(hclust(dist(c(2,3,5,7,11,13,17,19))))
Error in .Internal(dend.window(n, merge, height, hang, labels, ...)) :
  there is no .Internal function 'dend.window'
> traceback()
2: plot.hclust(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
1: plot(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))

Note how calling traceback() after an error gives more information about the source of the error.

To fix this, get rid of the .RData file that is being loaded when R starts.


Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Tue, Nov 25, 2014 at 12:18 PM, Rolf Turner <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:
On 26/11/14 08:53, Michael Mason wrote:
Here you are. I expect most folks won't get the error.

N   = 100; M = 1000
mat = matrix(1:(N*M) + rnorm(N*M,0,.5),N,M)
h   = hclust(as.dist(1-cor(mat)))
plot(h)

Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
   there is no .Internal function 'dend.window'



Thanks again


On 11/25/14 11:29 AM, "Rolf Turner" <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:



Reproducible example???

(I know from noddink about hclust, but I tried the example from the help
page and it plotted without any problem.)

cheers,

Rolf Turner

On 26/11/14 06:13, Michael Mason wrote:
Hello fellow R users,

I have recently updated to R 3.1.2. When trying to plot an hclust
object to generate the dendrogram I get the following error:

Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
    there is no .Internal function 'dend.window'


I am indeed using R3.1.2 but my understanding is that the .Internal API
to the C code is no longer used. I have tried detaching the stats
package and restarting R to no avail.
I would love any help from any wiser guRus.

Please keep communications on-list; there are others on the list far more likely to be able to help you than I.  I am cc-ing this reply to the list.

For what it's worth, I can run your example without error.

As to how to track down what is going wrong on your system, I'm afraid I have no idea.  Someone on the list may have some thoughts.

cheers,

Rolf Turner

--
Rolf Turner
Technical Editor ANZJS

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
--CONFIDENTIALITY NOTICE--: The information contained in this email is intended for the exclusive use of the addressee and may contain confidential information. If you are not the intended recipient, you are hereby notified that any form of dissemination of this communication is strictly prohibited. www.benaroyaresearch.org

	[[alternative HTML version deleted]]


From skostysh at princeton.edu  Wed Nov 26 07:13:48 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Wed, 26 Nov 2014 01:13:48 -0500
Subject: [R] Gender balance in R
In-Reply-To: <54748312.8020707@qub.ac.uk>
References: <54734A50.8090600@qub.ac.uk>
	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
	<CAE3=dmdyACtXiLD40ju7uBi0+KspQk7Z1nW+R4c=w8KgB7v_zw@mail.gmail.com>
	<54748312.8020707@qub.ac.uk>
Message-ID: <CAE3=dmd3vJ_KQ0_9NTcGr+Ojum=Lt-7j-DHy91LQxfA-YjUFWA@mail.gmail.com>

On Tue, Nov 25, 2014 at 8:24 AM, Maarten Blaauw
<maarten.blaauw at qub.ac.uk> wrote:
> Nice graph, Scott, thanks!
>
> Based on your code I plotted not the absolute numbers but the ratios, which
> show slowly increasing relative participation of female Rhelpers over time
> (red = women, blue=men, black=unknown). After a c. 5% female contribution in
> 1998, this has grown to about 15% now. At this rate we'll reach parity
> around AD 2080.

Interesting forecasts Maarten! Let's hope for a trend break to make them wrong.

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University

> My code:
>
> if (!require(gender)) {
> library(devtools)
> install_github("scottkosty/gender")
> library(gender)
> }
> rHelp <- rHelpNames
> rHelp[is.na(rHelp$gender), "gender"] <- "unknown"
>
> yr <- unique(rHelp$year)
>
> helpers <- list(dates, M=rep(0, length(yr)), F=rep(0, length(yr)),
> unkn=rep(0, length(yr)))
>
> for(i in 1:nrow(rHelp))
>  {
>   j <- which(yr == rHelp$year[i])
>   gender <- rHelp$gender[i]
>   if(gender == "M")
>    helpers$M[[j]] <- helpers$M[[j]]+1 else
>     if(gender == "F")
>      helpers$F[[j]] <- helpers$F[[j]]+1 else
>       if(gender == "unknown")
>        helpers$unkn[[j]] <- helpers$unkn[[j]]+1
>  }
> plot(yr, helpers$M / (helpers$M+helpers$F+helpers$unkn), type="l", col=4,
> ylim=c(0,1), ylab="proportions", yaxs="i")
> lines(yr, helpers$F / (helpers$M+helpers$F+helpers$unkn), col=2)
> lines(yr, helpers$unkn / (helpers$M+helpers$F+helpers$unkn))
>
> Cheers,
>
> Maarten
>
>
> On 25/11/14 12:11, Scott Kostyshak wrote:
>>
>> On Mon, Nov 24, 2014 at 12:34 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>>
>>> I took a look at apparent gender among list participants a few years ago:
>>> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
>>>
>>> Same general thing: very few regular participants on the list were
>>> women. I don't see any sign that that has changed in the last three
>>> years. The bar to participation in the R-help list is much, much lower
>>> than that to become a developer.
>>
>>
>> I plotted the gender of posters on r-help over time. The plot is here:
>> https://twitter.com/scottkosty/status/449933971644633088
>>
>> The code to reproduce that plot is here:
>> https://github.com/scottkosty/genderAnalysis
>> The R file there will call devtools::install_github to install a
>> package from Github used for guessing the gender based on the first
>> name (https://github.com/scottkosty/gender).
>>
>> Note also on that tweet that Gabriela de Queiroz posted it, who is the
>> founder of R-ladies; and that David Smith showed interest in
>> discussing the topic. So there is definitely demand for some data
>> analysis and discussion on the topic.
>>
>>> It would be interesting to look at the stats for CRAN packages as well.
>>>
>>> The very low percentage of regular female participants is one of the
>>> things that keeps me active on this list: to demonstrate that it's not
>>> only men who use R and participate in the community.
>>
>>
>> Thank you for that!
>>
>> Scott
>>
>>
>> --
>> Scott Kostyshak
>> Economics PhD Candidate
>> Princeton University
>>
>>> (If you decide to do the stats for 2014, be aware that I've been out
>>> on medical leave for the past two months, so the numbers are even
>>> lower than usual.)
>>>
>>> Sarah
>>>
>>> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
>>> <maarten.blaauw at qub.ac.uk> wrote:
>>>>
>>>> Hi there,
>>>>
>>>> I can't help to notice that the gender balance among R developers and
>>>> ordinary members is extremely skewed (as it is with open source software
>>>> in
>>>> general).
>>>>
>>>> Have a look at http://www.r-project.org/foundation/memberlist.html - at
>>>> most
>>>> a handful of women are listed among the 'supporting members', and none
>>>> at
>>>> all among the 29 'ordinary members'.
>>>>
>>>> On the other hand I personally know many happy R users of both genders.
>>>>
>>>> My questions are thus: Should R developers (and users) be worried that
>>>> the
>>>> 'other half' is excluded? If so, how could female R users/developers be
>>>> persuaded to become more visible (e.g. added as supporting or ordinary
>>>> members)?
>>>>
>>>> Thanks,
>>>>
>>>> Maarten
>>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> | Dr. Maarten Blaauw
> | Lecturer in Chronology
> |
> | School of Geography, Archaeology & Palaeoecology
> | Queen's University Belfast, UK
> |
> | www  http://www.chrono.qub.ac.uk/blaauw
> | tel  +44 (0)28 9097 3895


From skostysh at princeton.edu  Wed Nov 26 07:19:42 2014
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Wed, 26 Nov 2014 01:19:42 -0500
Subject: [R] Gender balance in R
In-Reply-To: <5474C73F.8020409@fredhutch.org>
References: <54734A50.8090600@qub.ac.uk>
	<CAM_vjukUqcWnvWiMNtm4OTG=anew1PTgQxy4CmhZ9OnQBg67jw@mail.gmail.com>
	<CAE3=dmdyACtXiLD40ju7uBi0+KspQk7Z1nW+R4c=w8KgB7v_zw@mail.gmail.com>
	<5474C73F.8020409@fredhutch.org>
Message-ID: <CAE3=dmdh3z1NeLA7g=rB7YuUN54Gz=drW0UvnkfcoTzwT6GOBg@mail.gmail.com>

On Tue, Nov 25, 2014 at 1:15 PM, Martin Morgan <mtmorgan at fredhutch.org> wrote:
> On 11/25/2014 04:11 AM, Scott Kostyshak wrote:
>>
>> On Mon, Nov 24, 2014 at 12:34 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>>
>>> I took a look at apparent gender among list participants a few years ago:
>>> https://stat.ethz.ch/pipermail/r-help/2011-June/280272.html
>>>
>>> Same general thing: very few regular participants on the list were
>>> women. I don't see any sign that that has changed in the last three
>>> years. The bar to participation in the R-help list is much, much lower
>>> than that to become a developer.
>>
>>
>> I plotted the gender of posters on r-help over time. The plot is here:
>> https://twitter.com/scottkosty/status/449933971644633088
>>
>> The code to reproduce that plot is here:
>> https://github.com/scottkosty/genderAnalysis
>> The R file there will call devtools::install_github to install a
>> package from Github used for guessing the gender based on the first
>> name (https://github.com/scottkosty/gender).
>
>
> It would be great to include in your package the script that scraped author
> names from R-help archives (I guess that's what you did?). Presumably it
> easily applies to other mailing lists hosted at the same location (R-devel,
> further along the ladder from user to developer, and Bioconductor /
> Bioc-devel, in a different domain and perhaps confounded with a different
> 'feel' to the list). Also the R community is definitely international, so
> finding more versatile gender-assignment approaches seems important.

I just put the script up on https://github.com/scottkosty/genderAnalysis
I don't have much time at the moment to generalize it, but a pull
request is always welcome. Alternatively, anyone is welcome (at least
as far as I'm concerned) to take the script and modify it for any
purpose.

> it might be interesting to ask about participation in mailing list forums
> versus other, and in particular the recent Bioconductor transition from
> mailing list to 'StackOverflow' style support forum
> (https://support.bioconductor.org) -- on the one hand the 'gamification'
> elements might seem to only entrench male participation, while on the other
> we have already seen increased (quantifiable) and broader (subjective)
> participation from the Bioconductor community. I'd be happy to make support
> site usage data available, and am interested in collaborating in an
> academically well-founded analysis of this data; any interested parties
> please feel free to contact me off-list.

I would be interested in collaborating on such a project in the future also.

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University

>
> Martin Morgan
> Bioconductor
>
>
>>
>> Note also on that tweet that Gabriela de Queiroz posted it, who is the
>> founder of R-ladies; and that David Smith showed interest in
>> discussing the topic. So there is definitely demand for some data
>> analysis and discussion on the topic.
>>
>>> It would be interesting to look at the stats for CRAN packages as well.
>>>
>>> The very low percentage of regular female participants is one of the
>>> things that keeps me active on this list: to demonstrate that it's not
>>> only men who use R and participate in the community.
>>
>>
>> Thank you for that!
>>
>> Scott
>>
>>
>> --
>> Scott Kostyshak
>> Economics PhD Candidate
>> Princeton University
>>
>>> (If you decide to do the stats for 2014, be aware that I've been out
>>> on medical leave for the past two months, so the numbers are even
>>> lower than usual.)
>>>
>>> Sarah
>>>
>>> On Mon, Nov 24, 2014 at 10:10 AM, Maarten Blaauw
>>> <maarten.blaauw at qub.ac.uk> wrote:
>>>>
>>>> Hi there,
>>>>
>>>> I can't help to notice that the gender balance among R developers and
>>>> ordinary members is extremely skewed (as it is with open source software
>>>> in
>>>> general).
>>>>
>>>> Have a look at http://www.r-project.org/foundation/memberlist.html - at
>>>> most
>>>> a handful of women are listed among the 'supporting members', and none
>>>> at
>>>> all among the 29 'ordinary members'.
>>>>
>>>> On the other hand I personally know many happy R users of both genders.
>>>>
>>>> My questions are thus: Should R developers (and users) be worried that
>>>> the
>>>> 'other half' is excluded? If so, how could female R users/developers be
>>>> persuaded to become more visible (e.g. added as supporting or ordinary
>>>> members)?
>>>>
>>>> Thanks,
>>>>
>>>> Maarten
>>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793


From ntfredo at gmail.com  Wed Nov 26 07:27:24 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 26 Nov 2014 09:27:24 +0300
Subject: [R] Error Missing values where true/false needed
In-Reply-To: <54747B46.5000607@aghmed.fsnet.co.uk>
References: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>
	<54747B46.5000607@aghmed.fsnet.co.uk>
Message-ID: <CAGh51gRhVJ1kLP93w-AbDh==_HFD3ZdqYAAQwya7TwjQKX6FAg@mail.gmail.com>

Hi PIKAL,

The error seems to be starnge to me because i access the indices of NAs.
Indices can't be non-applicable.
This is the output of indecs having the NA in my dataset. my dataset is
very big that's why I did not provide it.

> indicNAs <- which(data$Rain %in% NA)
> indicNAs
 [1]   426   792  1158  1890  2256  2622  3354  3720  4086  4818  5184
5550  6282  6648  7014  7746  8112
[18]  8478  9210  9576  9942 10674 11040 11406 12138 12504 12870 13602
13968 14334 15066 15432 15798 16530
[35] 16896 17262 17994 18360 18726 19458 19824 20190

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Tue, Nov 25, 2014 at 3:51 PM, Michael Dewey <info at aghmed.fsnet.co.uk>
wrote:

> You do not tell us what you are trying to do but I think there is
> something wrong in the logic of your thinking as on the one hand you are
> selecting just precisely those elements of data$Rain which are NA and then
> testing whether any of them equals 60.
>
>
>
> On 25/11/2014 12:19, Frederic Ntirenganya wrote:
>
>> Dear All,
>>
>> I am getting this error and don't know why it comes. can you please help ?
>>
>> Error in if (data$Rain[i_NA] == 60) { :
>>    missing value where TRUE/FALSE needed
>>
>> The loop is :
>>
>> indicNAs <- which(data$Rain %in% NA)
>>    ind_nonleap = c() # NAs due to non leap years
>>    ind_nonrecord = c() # NAs due to non recording values
>>    for (i_NA in indicNAs ){
>>      if(data$Rain[i_NA] == 60){
>>        ind_nonleap <- append(ind_nonleap,i_NA)
>>      }
>>      else {
>>        ind_nonrecord<-append(ind_nonrecord,i_NA)
>>      }
>>     #cat(ind_nonrecord)
>>     #cat( ind_nonleap)
>>    }
>>    ind_nonleap
>>
>> Regards,
>> Frederic.
>>
>> Frederic Ntirenganya
>> Maseno University,
>> African Maths Initiative,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> -----
>> No virus found in this message.
>> Checked by AVG - www.avg.com
>> Version: 2015.0.5577 / Virus Database: 4223/8627 - Release Date: 11/25/14
>>
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Nov 26 08:26:03 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 26 Nov 2014 02:26:03 -0500
Subject: [R] Error Missing values where true/false needed
In-Reply-To: <CAGh51gRhVJ1kLP93w-AbDh==_HFD3ZdqYAAQwya7TwjQKX6FAg@mail.gmail.com>
References: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>
	<54747B46.5000607@aghmed.fsnet.co.uk>
	<CAGh51gRhVJ1kLP93w-AbDh==_HFD3ZdqYAAQwya7TwjQKX6FAg@mail.gmail.com>
Message-ID: <3DEC9D11-DBB9-44F9-9429-7982A5DAA8CC@utoronto.ca>


On Nov 26, 2014, at 1:27 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:

> The error seems to be starnge to me because i access the indices of NAs.

No you don't. You access the contents of the cell via an index for which you have previously determined that the contents is NA. Then you compare that contents with 60.

The error is in the logic of these steps:
>> indicNAs <- which(data$Rain %in% NA)    # indices for NA
>>   for (i_NA in indicNAs ){              # i_NA is one of these indices
>>     if(data$Rain[i_NA] == 60){          # data$Rain[i_NA] contains ... NA ! Never 60.


HTH,
B.

From petr.pikal at precheza.cz  Wed Nov 26 08:41:14 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Nov 2014 07:41:14 +0000
Subject: [R] Error Missing values where true/false needed
In-Reply-To: <CAGh51gRhVJ1kLP93w-AbDh==_HFD3ZdqYAAQwya7TwjQKX6FAg@mail.gmail.com>
References: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>
	<54747B46.5000607@aghmed.fsnet.co.uk>
	<CAGh51gRhVJ1kLP93w-AbDh==_HFD3ZdqYAAQwya7TwjQKX6FAg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFD5C@SRVEXCHMBX.precheza.cz>

Huh

and what is the result of e.g.

data$Rain[indicNAs[1]]

I bet that you will see

[1] NA

and your if question askes if (NA eqals 60) which results in NA and "if" is telling you that it expects TRUE or FALSE but not NA.

I do not see how much clearer the error message shall be.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Frederic Ntirenganya
> Sent: Wednesday, November 26, 2014 7:27 AM
> To: Michael Dewey
> Cc: r-help at r-project.org
> Subject: Re: [R] Error Missing values where true/false needed
>
> Hi PIKAL,
>
> The error seems to be starnge to me because i access the indices of
> NAs.
> Indices can't be non-applicable.
> This is the output of indecs having the NA in my dataset. my dataset is
> very big that's why I did not provide it.
>
> > indicNAs <- which(data$Rain %in% NA)
> > indicNAs
>  [1]   426   792  1158  1890  2256  2622  3354  3720  4086  4818  5184
> 5550  6282  6648  7014  7746  8112
> [18]  8478  9210  9576  9942 10674 11040 11406 12138 12504 12870 13602
> 13968 14334 15066 15432 15798 16530
> [35] 16896 17262 17994 18360 18726 19458 19824 20190
>
> Regards,
> Frederic.
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Nov 25, 2014 at 3:51 PM, Michael Dewey
> <info at aghmed.fsnet.co.uk>
> wrote:
>
> > You do not tell us what you are trying to do but I think there is
> > something wrong in the logic of your thinking as on the one hand you
> > are selecting just precisely those elements of data$Rain which are NA
> > and then testing whether any of them equals 60.
> >
> >
> >
> > On 25/11/2014 12:19, Frederic Ntirenganya wrote:
> >
> >> Dear All,
> >>
> >> I am getting this error and don't know why it comes. can you please
> help ?
> >>
> >> Error in if (data$Rain[i_NA] == 60) { :
> >>    missing value where TRUE/FALSE needed
> >>
> >> The loop is :
> >>
> >> indicNAs <- which(data$Rain %in% NA)
> >>    ind_nonleap = c() # NAs due to non leap years
> >>    ind_nonrecord = c() # NAs due to non recording values
> >>    for (i_NA in indicNAs ){
> >>      if(data$Rain[i_NA] == 60){
> >>        ind_nonleap <- append(ind_nonleap,i_NA)
> >>      }
> >>      else {
> >>        ind_nonrecord<-append(ind_nonrecord,i_NA)
> >>      }
> >>     #cat(ind_nonrecord)
> >>     #cat( ind_nonleap)
> >>    }
> >>    ind_nonleap
> >>
> >> Regards,
> >> Frederic.
> >>
> >> Frederic Ntirenganya
> >> Maseno University,
> >> African Maths Initiative,
> >> Kenya.
> >> Mobile:(+254)718492836
> >> Email: fredo at aims.ac.za
> >> https://sites.google.com/a/aims.ac.za/fredo/
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> >>
> >>
> >> -----
> >> No virus found in this message.
> >> Checked by AVG - www.avg.com
> >> Version: 2015.0.5577 / Virus Database: 4223/8627 - Release Date:
> >> 11/25/14
> >>
> >>
> >>
> > --
> > Michael
> > http://www.dewey.myzen.co.uk
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From maechler at stat.math.ethz.ch  Wed Nov 26 10:02:43 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 26 Nov 2014 10:02:43 +0100
Subject: [R] plot.hclust point to older version
In-Reply-To: <D09A2E1A.A4BF%mmason@benaroyaresearch.org>
References: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
	<D09A2E1A.A4BF%mmason@benaroyaresearch.org>
Message-ID: <21621.38707.24672.588235@stat.math.ethz.ch>


> Thanks! That worked

Of course: As in about 99.99% of all cases where Bill Dunlap  helps.


> You probably have a local copy of an old version of plot.hclust or plot.dendrogram in your global environmenet or another package that masks the one in package:stats.  E.g., I fired up R-2.14.2 and copied those 2 plot methods to .GlobalEnv and then saved by workspace when quitting R.  I then fired up R-3.1.1, which loads the workspace saved by the older version of R.  I get:

> > objects()
> [1] "plot.dendrogram" "plot.hclust"
> > plot(hclust(dist(c(2,3,5,7,11,13,17,19))))
> Error in .Internal(dend.window(n, merge, height, hang, labels, ...)) :
>   there is no .Internal function 'dend.window'
> > traceback()
> 2: plot.hclust(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
> 1: plot(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))

> Note how calling traceback() after an error gives more information about the source of the error.

> To fix this, get rid of the .RData file that is being loaded when R starts.

In the spirit of the old -- now politically incorrect -- sayings
 `` Real men don't ..... '''
I'd like to emphasize my own view that
 "Real useRs don't use .RData"

in other words, experienced R users do not let their workspace
be saved automatically (to '.RData') and hence do not load any
.RData automatically at startup.

Consequently, use R with the '--no-save' command line argument
(maybe also with '--no-restore').

ESS (Emacs Speaks Statistics) users can put

(custom-set-variables
 '(inferior-R-args "--no-restore-history --no-save ")
)

into their ~/.emacs
{and I'd like to see a way to do this easily with RStudio...}

Martin Maechler,
ETH Zurich and R Core Team 

> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>

> On Tue, Nov 25, 2014 at 12:18 PM, Rolf Turner <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:
> On 26/11/14 08:53, Michael Mason wrote:
> Here you are. I expect most folks won't get the error.

> N   = 100; M = 1000
> mat = matrix(1:(N*M) + rnorm(N*M,0,.5),N,M)
> h   = hclust(as.dist(1-cor(mat)))
> plot(h)

> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>    there is no .Internal function 'dend.window'



> Thanks again


> On 11/25/14 11:29 AM, "Rolf Turner" <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:



> Reproducible example???

> (I know from noddink about hclust, but I tried the example from the help
> page and it plotted without any problem.)

> cheers,

> Rolf Turner

> On 26/11/14 06:13, Michael Mason wrote:
> Hello fellow R users,

> I have recently updated to R 3.1.2. When trying to plot an hclust
> object to generate the dendrogram I get the following error:

> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>     there is no .Internal function 'dend.window'


> I am indeed using R3.1.2 but my understanding is that the .Internal API
> to the C code is no longer used. I have tried detaching the stats
> package and restarting R to no avail.
> I would love any help from any wiser guRus.

> Please keep communications on-list; there are others on the list far more likely to be able to help you than I.  I am cc-ing this reply to the list.

> For what it's worth, I can run your example without error.

> As to how to track down what is going wrong on your system, I'm afraid I have no idea.  Someone on the list may have some thoughts.

> cheers,

> Rolf Turner

> --
> Rolf Turner
> Technical Editor ANZJS

> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

> ________________________________
> --CONFIDENTIALITY NOTICE--: The information contained in this email is intended for the exclusive use of the addressee and may contain confidential information. If you are not the intended recipient, you are hereby notified that any form of dissemination of this communication is strictly prohibited. www.benaroyaresearch.org

> 	[[alternative HTML version deleted]]

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Wed Nov 26 10:41:20 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 26 Nov 2014 18:41:20 +0900
Subject: [R] plot.hclust point to older version
In-Reply-To: <21621.38707.24672.588235@stat.math.ethz.ch>
References: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
	<D09A2E1A.A4BF%mmason@benaroyaresearch.org>
	<21621.38707.24672.588235@stat.math.ethz.ch>
Message-ID: <CAAcyNCwk38n8QRwDRDXREzh_ySszScSsj=Gy8XCsRLjAoUiywg@mail.gmail.com>

> into their ~/.emacs
> {and I'd like to see a way to do this easily with RStudio...}
>

In RStudio:

Tools -> Global Options -> General -> uncheck "Restore .RData into
workspace at startup" and choose "Never" for "Save workspace to .RData
on exit"


-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From petr.pikal at precheza.cz  Wed Nov 26 11:05:54 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Nov 2014 10:05:54 +0000
Subject: [R] plot.hclust point to older version
In-Reply-To: <21621.38707.24672.588235@stat.math.ethz.ch>
References: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
	<D09A2E1A.A4BF%mmason@benaroyaresearch.org>
	<21621.38707.24672.588235@stat.math.ethz.ch>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFE3A@SRVEXCHMBX.precheza.cz>

Hi

You say

> in other words, experienced R users do not let their workspace be saved
> automatically (to '.RData') and hence do not load any .RData
> automatically at startup.

I save/load .RData for years without any issues (except of not installed packages when working on different PCs).I usually keep each project in separated .RData (and separated folder, together with all stuff belonging to that project), which prevent to mess things together.

There is no such warning as "do not use .RData" in books I have available.

I wonder how experienced useR keep track of several projects without using startup loading .RData?
What would you recommend for keeping track of commands and created objects instead of .RData?

Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin
> Maechler
> Sent: Wednesday, November 26, 2014 10:03 AM
> To: Michael Mason
> Cc: R help
> Subject: Re: [R] plot.hclust point to older version
>
>
> > Thanks! That worked
>
> Of course: As in about 99.99% of all cases where Bill Dunlap  helps.
>
>
> > You probably have a local copy of an old version of plot.hclust or
> plot.dendrogram in your global environmenet or another package that
> masks the one in package:stats.  E.g., I fired up R-2.14.2 and copied
> those 2 plot methods to .GlobalEnv and then saved by workspace when
> quitting R.  I then fired up R-3.1.1, which loads the workspace saved
> by the older version of R.  I get:
>
> > > objects()
> > [1] "plot.dendrogram" "plot.hclust"
> > > plot(hclust(dist(c(2,3,5,7,11,13,17,19))))
> > Error in .Internal(dend.window(n, merge, height, hang, labels, ...))
> :
> >   there is no .Internal function 'dend.window'
> > > traceback()
> > 2: plot.hclust(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
> > 1: plot(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
>
> > Note how calling traceback() after an error gives more information
> about the source of the error.
>
> > To fix this, get rid of the .RData file that is being loaded when R
> starts.
>
> In the spirit of the old -- now politically incorrect -- sayings  ``
> Real men don't ..... '''
> I'd like to emphasize my own view that
>  "Real useRs don't use .RData"
>
> in other words, experienced R users do not let their workspace be saved
> automatically (to '.RData') and hence do not load any .RData
> automatically at startup.
>
> Consequently, use R with the '--no-save' command line argument (maybe
> also with '--no-restore').
>
> ESS (Emacs Speaks Statistics) users can put
>
> (custom-set-variables
>  '(inferior-R-args "--no-restore-history --no-save ")
> )
>
> into their ~/.emacs
> {and I'd like to see a way to do this easily with RStudio...}
>
> Martin Maechler,
> ETH Zurich and R Core Team
>
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com<http://tibco.com>
>
> > On Tue, Nov 25, 2014 at 12:18 PM, Rolf Turner
> <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:
> > On 26/11/14 08:53, Michael Mason wrote:
> > Here you are. I expect most folks won't get the error.
>
> > N   = 100; M = 1000
> > mat = matrix(1:(N*M) + rnorm(N*M,0,.5),N,M)
> > h   = hclust(as.dist(1-cor(mat)))
> > plot(h)
>
> > Error in .Internal(dend.window(n, merge, height2, hang, labels, ...))
> :
> >    there is no .Internal function 'dend.window'
>
>
>
> > Thanks again
>
>
> > On 11/25/14 11:29 AM, "Rolf Turner"
> <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:
>
>
>
> > Reproducible example???
>
> > (I know from noddink about hclust, but I tried the example from the
> > help page and it plotted without any problem.)
>
> > cheers,
>
> > Rolf Turner
>
> > On 26/11/14 06:13, Michael Mason wrote:
> > Hello fellow R users,
>
> > I have recently updated to R 3.1.2. When trying to plot an hclust
> > object to generate the dendrogram I get the following error:
>
> > Error in .Internal(dend.window(n, merge, height2, hang, labels, ...))
> :
> >     there is no .Internal function 'dend.window'
>
>
> > I am indeed using R3.1.2 but my understanding is that the .Internal
> > API to the C code is no longer used. I have tried detaching the stats
> > package and restarting R to no avail.
> > I would love any help from any wiser guRus.
>
> > Please keep communications on-list; there are others on the list far
> more likely to be able to help you than I.  I am cc-ing this reply to
> the list.
>
> > For what it's worth, I can run your example without error.
>
> > As to how to track down what is going wrong on your system, I'm
> afraid I have no idea.  Someone on the list may have some thoughts.
>
> > cheers,
>
> > Rolf Turner
>
> > --
> > Rolf Turner
> > Technical Editor ANZJS
>
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> > ________________________________
> > --CONFIDENTIALITY NOTICE--: The information contained in this email
> is
> > intended for the exclusive use of the addressee and may contain
> > confidential information. If you are not the intended recipient, you
> > are hereby notified that any form of dissemination of this
> > communication is strictly prohibited. www.benaroyaresearch.org
>
> >     [[alternative HTML version deleted]]
>
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Gabriele.Franzini at nervianoms.com  Wed Nov 26 13:35:01 2014
From: Gabriele.Franzini at nervianoms.com (Franzini, Gabriele [Nervianoms])
Date: Wed, 26 Nov 2014 13:35:01 +0100
Subject: [R] Presentation tables in R (knitr)
In-Reply-To: <1416946341.1909.23.camel@tom-laptop>
References: <1416946341.1909.23.camel@tom-laptop>
Message-ID: <69D768435B870B498704129A048CDB190C475635@nermbxs08.nervianoms.com>


I found also knitr + html + the ReporteRs package a good combination,
and less intimidating than Latex. Have a look at their FlexTable tool.

HTH,
Gabriele  


-----Original Message-----
From: Tom Wright [mailto:tom at maladmin.com] 
Sent: Tuesday, November 25, 2014 9:12 PM
To: r-help at r-project.org
Subject: [R] Presentation tables in R (knitr)

Hi,
This problem has me stumped so I thought I'd ask the experts. I'm trying
to create a pretty summary table of some data (which patients have had
what tests at what times). Ideally I'd like to knitr this into a pretty
PDF for presentation.
If anyone has pointers I'll be grateful.

require(tables)
require(reshape2)

data<-data.frame('ID'=paste0('pat',c(rep(1,8),rep(2,8))),
                 'Time'=c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4),
                 'Eye'=rep(c('OS','OS','OD','OD'),4),
                 'Measure'=rep(c('Height','Weight'),8))

tabular(Measure~factor(ID)*factor(Time)*factor(Eye),data)
#All levels of Time are repeated for all IDs, I'd prefer to just show
the relevant times.

tabular(Measure~factor(ID)*Time*factor(Eye),data)
#Time is getting collapsed by ID

data$value=1
dcast(data,Measure~ID+Time+Eye)
#close but not very pretty


From info at aghmed.fsnet.co.uk  Wed Nov 26 14:38:53 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 26 Nov 2014 13:38:53 +0000
Subject: [R] Error Missing values where true/false needed
In-Reply-To: <CAGh51gRhVJ1kLP93w-AbDh==_HFD3ZdqYAAQwya7TwjQKX6FAg@mail.gmail.com>
References: <CAGh51gR71gOcLEkh1S5quKnQ1_kTVqCwPspWmj7JRj0f+pjFBw@mail.gmail.com>	<54747B46.5000607@aghmed.fsnet.co.uk>
	<CAGh51gRhVJ1kLP93w-AbDh==_HFD3ZdqYAAQwya7TwjQKX6FAg@mail.gmail.com>
Message-ID: <5475D7ED.1040400@aghmed.fsnet.co.uk>

Comments in-line below

On 26/11/2014 06:27, Frederic Ntirenganya wrote:
> Hi PIKAL,
>
Actually I am Michael, Petr is one of the other respondents.

> The error seems to be starnge to me because i access the indices of NAs.
> Indices can't be non-applicable.

But you are not testing the indexes, see below

> This is the output of indecs having the NA in my dataset. my dataset is
> very big that's why I did not provide it.
>
>  > indicNAs <- which(data$Rain %in% NA)
>  > indicNAs
>   [1]   426   792  1158  1890  2256  2622  3354  3720  4086  4818  5184
> 5550  6282  6648  7014  7746  8112
> [18]  8478  9210  9576  9942 10674 11040 11406 12138 12504 12870 13602
> 13968 14334 15066 15432 15798 16530
> [35] 16896 17262 17994 18360 18726 19458 19824 20190
>
> Regards,
> Frederic.
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za <mailto:fredo at aims.ac.za>
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Tue, Nov 25, 2014 at 3:51 PM, Michael Dewey <info at aghmed.fsnet.co.uk
> <mailto:info at aghmed.fsnet.co.uk>> wrote:
>
>     You do not tell us what you are trying to do but I think there is
>     something wrong in the logic of your thinking as on the one hand you
>     are selecting just precisely those elements of data$Rain which are
>     NA and then testing whether any of them equals 60.
>

My comments on your code are preceded ## to make them clear

>
>
>     On 25/11/2014 12:19, Frederic Ntirenganya wrote:
>
>         Dear All,
>
>         I am getting this error and don't know why it comes. can you
>         please help ?
>
>         Error in if (data$Rain[i_NA] == 60) { :
>             missing value where TRUE/FALSE needed
>
>         The loop is :
>
>         indicNAs <- which(data$Rain %in% NA)
## so at this point indicNAs is the indexes of all the NA
## values in dat$Rain
>             ind_nonleap = c() # NAs due to non leap years
>             ind_nonrecord = c() # NAs due to non recording values
>             for (i_NA in indicNAs ){ ## step through those indexes
>               if(data$Rain[i_NA] == 60){
## since i_NA is the index of a value of data$Rain which
## you know to be NA this evaluates to NA and if() complains
## I expect you really meant some other variable in data
## incidentally it is better not to call your data data
>                 ind_nonleap <- append(ind_nonleap,i_NA)
>               }
>               else {
>                 ind_nonrecord<-append(ind___nonrecord,i_NA)
>               }
>              #cat(ind_nonrecord)
>              #cat( ind_nonleap)
>             }
>             ind_nonleap
>
>         Regards,
>         Frederic.
>
>         Frederic Ntirenganya
>         Maseno University,
>         African Maths Initiative,
>         Kenya.
>         Mobile:(+254)718492836
>         Email: fredo at aims.ac.za <mailto:fredo at aims.ac.za>
>         https://sites.google.com/a/__aims.ac.za/fredo/
>         <https://sites.google.com/a/aims.ac.za/fredo/>
>
>                  [[alternative HTML version deleted]]
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>         -----
>         No virus found in this message.
>         Checked by AVG - www.avg.com <http://www.avg.com>
>         Version: 2015.0.5577 / Virus Database: 4223/8627 - Release Date:
>         11/25/14
>
>
>
>     --
>     Michael
>     http://www.dewey.myzen.co.uk
>
>
> No virus found in this message.
> Checked by AVG - www.avg.com <http://www.avg.com>
> Version: 2015.0.5577 / Virus Database: 4223/8632 - Release Date: 11/25/14
>

-- 
Michael
http://www.dewey.myzen.co.uk


From petr.pikal at precheza.cz  Wed Nov 26 14:40:07 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Nov 2014 13:40:07 +0000
Subject: [R] ggplot facet and subsetting
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFED4@SRVEXCHMBX.precheza.cz>

Dear all

I encountered strange behaviour of ggplot with combination of facet and subsetting. I use for creating plots sometimes a for cycle, something like this

for (i in n:m) { p<-ggplot(data, aes(x=x, y=data[,i], colour=f))), ...}

However I found strange result with this combination

This is OK but only in BW
p<-ggplot(vec.c, aes(x=fi, y=nad1mi))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

this is OK with colour
p<-ggplot(vec.c, aes(x=fi, y=nad1mi, colour=as.factor(cas)))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

Here results in facets are mismatched
p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2], colour=as.factor(cas)))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

and this is mismatched too
p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2]))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

Doeas anybody know what I am doing wrong?

> dput(vec.c)
structure(list(cas = c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L,
1L, 2L, 0L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L),
    nad1mi = c(3, 2.7, 0.3, 0.5, 1.9, 5.3, 0.4, 3, 5.4, 0.7,
    20.6, 16.7, 16.6, 20.7, 16.1, 15.2, 20.5, 16.4, 14.8, 24.6,
    19.3, 15.2, 26.9, 21.3, 20.6, 22.6, 16.3, 15.7, 19.3, 16.5,
    15.5, 3.6, 3.4, 5.9, 4.6, 5.4, 4.2, 5.3, 5.6, 5.1, 5), stroj = structure(c(3L,
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("mastersizer",
    "odstredivka", "zetasizer"), class = "factor"), fi = c(341L,
    341L, 285L, 285L, 401L, 401L, 231L, 231L, 190L, 190L, 341L,
    341L, 341L, 285L, 285L, 285L, 401L, 401L, 401L, 231L, 231L,
    231L, 190L, 190L, 190L, 167L, 167L, 167L, 161L, 161L, 161L,
    341L, 341L, 285L, 285L, 401L, 401L, 231L, 231L, 190L, 190L
    )), .Names = c("cas", "nad1mi", "stroj", "fi"), class = "data.frame", row.names = c(1L,
2L, 6L, 7L, 11L, 12L, 16L, 17L, 21L, 22L, 26L, 27L, 28L, 32L,
33L, 34L, 38L, 39L, 40L, 44L, 45L, 46L, 50L, 51L, 52L, 56L, 57L,
58L, 62L, 63L, 64L, 68L, 69L, 73L, 74L, 78L, 79L, 83L, 84L, 88L,
89L))
>

Regards
Petr

> sessionInfo(package = NULL)
R Under development (unstable) (2014-07-16 r66175)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech Republic.1250
[3] LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C
[5] LC_TIME=Czech_Czech Republic.1250

attached base packages:
[1] stats     datasets  utils     grDevices graphics  methods   base

other attached packages:
[1] ggplot2_1.0.0   lattice_0.20-29 fun_1.0

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4 digest_0.6.4     grid_3.2.0       gtable_0.1.2
 [5] labeling_0.2     MASS_7.3-33      munsell_0.4.2    plyr_1.8.1
 [9] proto_0.3-10     Rcpp_0.11.2      reshape2_1.4     scales_0.2.4
[13] stringr_0.6.2    tools_3.2.0
>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From rune.haubo at gmail.com  Wed Nov 26 15:08:36 2014
From: rune.haubo at gmail.com (Rune Haubo)
Date: Wed, 26 Nov 2014 15:08:36 +0100
Subject: [R] Checking the proportional odds assumption holds in an
 ordinal logistic regression using polr function
In-Reply-To: <92C9BF3E-698C-4F79-936C-6AD2F662A6B1@gmail.com>
References: <92C9BF3E-698C-4F79-936C-6AD2F662A6B1@gmail.com>
Message-ID: <CAG_uk91uZdz=X2nSKnUDwACae=1n25SeoeMFkMQV+3pRNp1t4A@mail.gmail.com>

Dear Charlie,

I admit that I haven't read your email closely, but here is a way to
test for non-proportional odds using the ordinal package (warning:
self-promotion) using the wine data set also from the ordinal package.
There is more information in the package vignettes

Hope this is something you can use.
Cheers,
Rune

> library(ordinal)
> ## Fit model:
> fm <- clm(rating ~ temp + contact, data=wine)
> summary(fm)
formula: rating ~ temp + contact
data:    wine

 link  threshold nobs logLik AIC    niter max.grad cond.H
 logit flexible  72   -86.49 184.98 6(0)  4.64e-15 2.7e+01

Coefficients:
           Estimate Std. Error z value Pr(>|z|)
tempwarm     2.5031     0.5287   4.735 2.19e-06 ***
contactyes   1.5278     0.4766   3.205  0.00135 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.3444     0.5171  -2.600
2|3   1.2508     0.4379   2.857
3|4   3.4669     0.5978   5.800
4|5   5.0064     0.7309   6.850
> ## Model with non-proportional odds for contact:
> fm2 <- clm(rating ~ temp, nominal=~contact, data=wine)
> ## Likelihood ratio test of non-proportional odds:
> anova(fm, fm2)
Likelihood ratio tests of cumulative link models:

    formula:                nominal: link: threshold:
fm  rating ~ temp + contact ~1       logit flexible
fm2 rating ~ temp           ~contact logit flexible

    no.par    AIC  logLik LR.stat df Pr(>Chisq)
fm       6 184.98 -86.492
fm2      9 190.42 -86.209  0.5667  3      0.904
> ## Automatic tests of non-proportional odds for all varibles:
> nominal_test(fm)
Tests of nominal effects

formula: rating ~ temp + contact
        Df  logLik    AIC    LRT Pr(>Chi)
<none>     -86.492 184.98
temp     3 -84.904 187.81 3.1750   0.3654
contact  3 -86.209 190.42 0.5667   0.9040

On 25 November 2014 at 17:21, Charlotte Whitham
<charlotte.whitham at gmail.com> wrote:
> Dear list,
>
> I have used the ?polr? function in the MASS package to run an ordinal logistic regression for an ordinal categorical response variable with 15 continuous explanatory variables.
> I have used the code (shown below) to check that my model meets the proportional odds assumption following advice provided at (http://www.ats.ucla.edu/stat/r/dae/ologit.htm) ? which has been extremely helpful, thank you to the authors! However, I?m a little worried about the output implying that not only are the coefficients across various cutpoints similar, but they are exactly the same (see graphic below).
>
> Here is the code I used (and see attached for the output graphic)
>
> FGV1b<-data.frame(FG1_val_cat=factor(FGV1b[,"FG1_val_cat"]),scale(FGV1[,c("X","Y","Slope","Ele","Aspect","Prox_to_for_FG","Prox_to_for_mL","Prox_to_nat_border","Prox_to_village","Prox_to_roads","Prox_to_rivers","Prox_to_waterFG","Prox_to_watermL","Prox_to_core","Prox_to_NR","PCA1","PCA2","PCA3")]))
>
> b<-polr(FGV1b$FG1_val_cat ~ FGV1b$X + FGV1b$Y + FGV1b$Slope + FGV1b$Ele + FGV1b$Aspect + FGV1b$Prox_to_for_FG + FGV1b$Prox_to_for_mL + FGV1b$Prox_to_nat_border + FGV1b$Prox_to_village + FGV1b$Prox_to_roads + FGV1b$Prox_to_rivers + FGV1b$Prox_to_waterFG + FGV1b$Prox_to_watermL + FGV1b$Prox_to_core + FGV1b$Prox_to_NR, data = FGV1b, Hess=TRUE)
>
> #Checking the assumption. So the following code will estimate the values to be graphed. First it shows us #the logit transformations of the probabilities of being greater than or equal to each value of the target #variable
>
> FGV1b$FG1_val_cat<-as.numeric(FGV1b$FG1_val_cat)
>
> sf <- function(y) {
>
>   c('VC>=1' = qlogis(mean(FGV1b$FG1_val_cat >= 1)),
>
>     'VC>=2' = qlogis(mean(FGV1b$FG1_val_cat >= 2)),
>
>     'VC>=3' = qlogis(mean(FGV1b$FG1_val_cat >= 3)),
>
>     'VC>=4' = qlogis(mean(FGV1b$FG1_val_cat >= 4)),
>
>     'VC>=5' = qlogis(mean(FGV1b$FG1_val_cat >= 5)),
>
>     'VC>=6' = qlogis(mean(FGV1b$FG1_val_cat >= 6)),
>
>     'VC>=7' = qlogis(mean(FGV1b$FG1_val_cat >= 7)),
>
>     'VC>=8' = qlogis(mean(FGV1b$FG1_val_cat >= 8)))
>
> }
>
>   (t <- with(FGV1b, summary(as.numeric(FGV1b$FG1_val_cat) ~ FGV1b$X + FGV1b$Y + FGV1b$Slope + FGV1b$Ele + FGV1b$Aspect + FGV1b$Prox_to_for_FG + FGV1b$Prox_to_for_mL + FGV1b$Prox_to_nat_border + FGV1b$Prox_to_village + FGV1b$Prox_to_roads + FGV1b$Prox_to_rivers + FGV1b$Prox_to_waterFG + FGV1b$Prox_to_watermL + FGV1b$Prox_to_core + FGV1b$Prox_to_NR, fun=sf)))
>
>
>
> #The table displays the (linear) predicted values we would get if we regressed our
>
> #dependent variable on our predictor variables one at a time, without the parallel slopes
>
> #assumption. So now, we can run a series of binary logistic regressions with varying cutpoints
>
> #on the dependent variable to check the equality of coefficients across cutpoints
>
> par(mfrow=c(1,1))
>
> plot(t, which=1:8, pch=1:8, xlab='logit', main=' ', xlim=range(s[,7:8]))
>
>
>
> Apologies that I am no statistics expert and perhaps I am missing something obvious here. However, I have spent a long time trying to figure out if there is a problem in how I tested the model assumption and also trying to figure out other ways to run the same kind of model.
>
>  For example, I read in many help mailing lists that others use the vglm function (in the VGAM package) and the lrm function (in the rms package) (for example see here:  http://stats.stackexchange.com/questions/25988/proportional-odds-assumption-in-ordinal-logistic-regression-in-r-with-the-packag). I have tried to run the same models but am continuously coming up against warnings and errors.
>
>  For example, when I try to fit the vglm model with the ?parallel=FALSE? argument (as the previous link mentions is important for testing the proportional odds assumption), I encounter the following error:
>
>
>
> Error in lm.fit(X.vlm, y = z.vlm, ...) : NA/NaN/Inf in 'y'
>
> In addition: Warning message:
>
> In Deviance.categorical.data.vgam(mu = mu, y = y, w = w, residuals = residuals,  :
>
>   fitted values close to 0 or 1
>
>
>
> And after many searches for help, I can?t seem to find a way to fix this problem.
>
> I would like to ask please if there is anyone who might understand and be able to explain to me why the graph I produced above looks as it does. If indeed it means that something isn?t right, could you please help me find a way to test the proportional odds assumption when just using the polr function. Or if that is just not possible, then I will resort to trying to use the vglm function, but would then need some help to explain why I keep getting the error given above.
>
> I hope this is clear. Please do let me know if I should provide some more information that would help address this query.
>
> NOTE: As a background, there are 1000 datapoints here, which are actually location points across a study area. I am looking to see if there are any relationships between the categorical response variable and these 15 explanatory variables. All of those 15 explanatory variables are spatial characteristics (for example, elevation, x-y coordinates, proximity to forest etc.). The 1000 datapoints were randomly allocated using a GIS, but I took a stratified sampling approach. I made sure that 125 points were randomly chosen within each of the 8 different categorical response levels. I hope this information is also helpful.
>
> I am extremely grateful to anyone who could please give me some guidance with this.
>
> Thank you very much for your time,
>
> Charlie
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Nov 26 16:10:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 26 Nov 2014 07:10:16 -0800
Subject: [R] ggplot facet and subsetting
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFED4@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFED4@SRVEXCHMBX.precheza.cz>
Message-ID: <746784FD-1C23-4FFD-9EFD-0DC0166D7983@dcn.davis.CA.us>

I am not quite sure what you want to achieve here, but you only have one factor column so shouldn't you be using facet_wrap(~stroj), perhaps with nrow or ncol parameters?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 26, 2014 5:40:07 AM PST, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Dear all
>
>I encountered strange behaviour of ggplot with combination of facet and
>subsetting. I use for creating plots sometimes a for cycle, something
>like this
>
>for (i in n:m) { p<-ggplot(data, aes(x=x, y=data[,i], colour=f))), ...}
>
>However I found strange result with this combination
>
>This is OK but only in BW
>p<-ggplot(vec.c, aes(x=fi, y=nad1mi))
>p+geom_point(size=5)+geom_line()+facet_grid(.~ p<-ggplot(vec.c, aes(x=fi, y=nad1mi))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj) )
>
>this is OK with colour
>p<-ggplot(vec.c, aes(x=fi, y=nad1mi, colour=as.factor(cas)))
>p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
>Here results in facets are mismatched
>p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2], colour=as.factor(cas)))
>p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
>and this is mismatched too
>p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2]))
>p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
>Doeas anybody know what I am doing wrong?
>
>> dput(vec.c)
>structure(list(cas = c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L,
>1L, 2L, 0L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L),
>    nad1mi = c(3, 2.7, 0.3, 0.5, 1.9, 5.3, 0.4, 3, 5.4, 0.7,
>    20.6, 16.7, 16.6, 20.7, 16.1, 15.2, 20.5, 16.4, 14.8, 24.6,
>    19.3, 15.2, 26.9, 21.3, 20.6, 22.6, 16.3, 15.7, 19.3, 16.5,
>15.5, 3.6, 3.4, 5.9, 4.6, 5.4, 4.2, 5.3, 5.6, 5.1, 5), stroj =
>structure(c(3L,
>    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L,
>    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("mastersizer",
>    "odstredivka", "zetasizer"), class = "factor"), fi = c(341L,
>    341L, 285L, 285L, 401L, 401L, 231L, 231L, 190L, 190L, 341L,
>    341L, 341L, 285L, 285L, 285L, 401L, 401L, 401L, 231L, 231L,
>    231L, 190L, 190L, 190L, 167L, 167L, 167L, 161L, 161L, 161L,
>    341L, 341L, 285L, 285L, 401L, 401L, 231L, 231L, 190L, 190L
>)), .Names = c("cas", "nad1mi", "stroj", "fi"), class = "data.frame",
>row.names = c(1L,
>2L, 6L, 7L, 11L, 12L, 16L, 17L, 21L, 22L, 26L, 27L, 28L, 32L,
>33L, 34L, 38L, 39L, 40L, 44L, 45L, 46L, 50L, 51L, 52L, 56L, 57L,
>58L, 62L, 63L, 64L, 68L, 69L, 73L, 74L, 78L, 79L, 83L, 84L, 88L,
>89L))
>>
>
>Regards
>Petr
>
>> sessionInfo(package = NULL)
>R Under development (unstable) (2014-07-16 r66175)
>Platform: i386-w64-mingw32/i386 (32-bit)
>
>locale:
>[1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech
>Republic.1250
>[3] LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C
>[5] LC_TIME=Czech_Czech Republic.1250
>
>attached base packages:
>[1] stats     datasets  utils     grDevices graphics  methods   base
>
>other attached packages:
>[1] ggplot2_1.0.0   lattice_0.20-29 fun_1.0
>
>loaded via a namespace (and not attached):
> [1] colorspace_1.2-4 digest_0.6.4     grid_3.2.0       gtable_0.1.2
> [5] labeling_0.2     MASS_7.3-33      munsell_0.4.2    plyr_1.8.1
> [9] proto_0.3-10     Rcpp_0.11.2      reshape2_1.4     scales_0.2.4
>[13] stringr_0.6.2    tools_3.2.0
>>
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Nov 26 16:39:36 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Nov 2014 15:39:36 +0000
Subject: [R] list.files() not compatible with all Unicode characters;
 file.exists() is compatible.
In-Reply-To: <54742771.5020903@stats.ox.ac.uk>
References: <96642237.216372.1416856071710.JavaMail.yahoo@jws10083.mail.ne1.yahoo.com>	<D0991A42.113B4B%macqueen1@llnl.gov>
	<54742771.5020903@stats.ox.ac.uk>
Message-ID: <5475F438.1050408@stats.ox.ac.uk>

On 25/11/2014 06:53, Prof Brian Ripley wrote:
> On 25/11/2014 01:25, MacQueen, Don wrote:
>> Sorry, your email was undecipherable because you sent HTML formatted
>> email.
>> Please send plain text
>>
>
> Also, the 'at a minimum' information requested by the posting guide is
> essential here (which OS and locale, in particular).  In general file
> names not in the locale's encoding are unsupported.

An off-list reply indicated this was Windows XP.  Although the message 
body was unreadable, the gist is in the subject line.

 From ?list.files under Windows

   path must specify paths which can be represented in the current
   codepage.

whereas ?file.exists says

   Most of these functions accept UTF-8 filepaths not valid in the
   current locale.

So this is documented behaviour.

[For anyone curious as to why list.files is different: note that it does 
regexp pattern matching.  Adding support for Unicode file paths would 
not be impossible but it would require hundreds of lines of Windows-only 
code.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jarod_v6 at libero.it  Wed Nov 26 18:04:21 2014
From: jarod_v6 at libero.it (jarod_v6 at libero.it)
Date: Wed, 26 Nov 2014 18:04:21 +0100 (CET)
Subject: [R] How to use ggplot2
Message-ID: <1025283138.326481417021461309.JavaMail.httpd@webmail-07.iol.local>

Dear All!!
I'll try to plot a barplot using aggplot2

head(alt)
  as.factor.data...7..    Col ColMat  Fastq  miseq
1                  189    158    158    158    104
2                  190  54272  54272  54272  32122
3                  191 301574 301574 301574 152625
4                  192 161620 161620 161620 100469
5                  193  61263  61263  61263  38109
6                  194  83800  83800  83800  40095
> 
p<- ggplot(data = alt, aes(y = alt[,2]))  +  geom_bar() 

Error : Mapping a variable to y and also using stat="bin".
  With stat="bin", it will attempt to set the y value to the count of cases in each group.
  This can result in unexpected behavior and will not be allowed in a future version of ggplot2.
  If you want y to represent counts of cases, use stat="bin" and don't map a variable to y.
  If you want y to represent values in the data, use stat="identity".
  See ?geom_bar for examples. (Defunct; last used in version 0.9.2)
How can resolve this problem?
My data are in column: each columns are conditions and each row rappresnt a sample
thanks for your help!
M


	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed Nov 26 18:13:00 2014
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 26 Nov 2014 09:13:00 -0800
Subject: [R] ggplot facet and subsetting
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFED4@SRVEXCHMBX.precheza.cz>
Message-ID: <7704FB6436C.00001311jrkrideau@inbox.com>

Below

John Kane
Kingston ON Canada
> This is OK but only in BW
> p<-ggplot(vec.c, aes(x=fi, y=nad1mi))
> p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
Perhaps:
p <- ggplot(vec.c, aes(x=fi, y=nad1mi, colour = stroj))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)


> and this is mismatched too
> p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2]))
> p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

I don'[ understand what you want  here so cannot suggest anything

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Wed Nov 26 18:42:19 2014
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 26 Nov 2014 09:42:19 -0800
Subject: [R] How to use ggplot2
In-Reply-To: <1025283138.326481417021461309.JavaMail.httpd@webmail-07.iol.local>
Message-ID: <77467CC94AD.00001375jrkrideau@inbox.com>

It is useful to have a reproducable example
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

However is this somethingl like what you want?  Note I changed variable names and removed caps to make life easier and renamed the dataset to dat1 (just handier for me).  I think "col" as a reserved word should not be used. It seemed to be causing a problem.

library(ggplot2)
dat1  <-  structure(list(aa = 189:194, bb = c(158L, 54272L, 301574L, 161620L, 
61263L, 83800L), colmat = c(158L, 54272L, 301574L, 161620L, 61263L, 
83800L), fastq = c(158L, 54272L, 301574L, 161620L, 61263L, 83800L
), miseq = c(104L, 32122L, 152625L, 100469L, 38109L, 40095L)), .Names = c("aa", 
"bb", "colmat", "fastq", "miseq"), class = "data.frame", row.names = c(NA, 
-6L))

p1  <-  ggplot(dat1, aes( as.factor(aa), y = bb, fill = as.factor(aa))) 
p1  <-  p1 + geom_bar(stat = "identity")
p1 


John Kane
Kingston ON Canada


> -----Original Message-----
> From: jarod_v6 at libero.it
> Sent: Wed, 26 Nov 2014 18:04:21 +0100 (CET)
> To: r-help at r-project.org
> Subject: [R] How to use ggplot2
> 
> Dear All!!
> I'll try to plot a barplot using aggplot2
> 
> head(alt)
>   as.factor.data...7..    Col ColMat  Fastq  miseq
> 1                  189    158    158    158    104
> 2                  190  54272  54272  54272  32122
> 3                  191 301574 301574 301574 152625
> 4                  192 161620 161620 161620 100469
> 5                  193  61263  61263  61263  38109
> 6                  194  83800  83800  83800  40095
>> 
> p<- ggplot(data = alt, aes(y = alt[,2]))  +  geom_bar()
> 
> Error : Mapping a variable to y and also using stat="bin".
>   With stat="bin", it will attempt to set the y value to the count of
> cases in each group.
>   This can result in unexpected behavior and will not be allowed in a
> future version of ggplot2.
>   If you want y to represent counts of cases, use stat="bin" and don't
> map a variable to y.
>   If you want y to represent values in the data, use stat="identity".
>   See ?geom_bar for examples. (Defunct; last used in version 0.9.2)
> How can resolve this problem?
> My data are in column: each columns are conditions and each row rappresnt
> a sample
> thanks for your help!
> M
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From wdunlap at tibco.com  Wed Nov 26 18:49:32 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 26 Nov 2014 09:49:32 -0800
Subject: [R] plot.hclust point to older version
In-Reply-To: <21621.38707.24672.588235@stat.math.ethz.ch>
References: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
	<D09A2E1A.A4BF%mmason@benaroyaresearch.org>
	<21621.38707.24672.588235@stat.math.ethz.ch>
Message-ID: <CAF8bMcZFK2rne51Vjp6wBhYcMPHWNFfNqgL_CcYqEEAbOjU5DQ@mail.gmail.com>

How disruptive would it be if R were changed so the startup line
   [Previously saved workspace restored]
were changed to show the complete name, from normalizePath(), of the
saved workspace file?  E.g.,
   [Previously saved workspace restored from 'C:\Program Files\R\.RData']

(It is bad enough that the file name starts with a dot so it is hidden from
'ls',
but on Windows lots of people don't know what directory R is starting in.
On
my Windows PC R-3.1.2 starts in C:/Program Files/R, the parent of its RHOME
directory.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Nov 26, 2014 at 1:02 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

>
> > Thanks! That worked
>
> Of course: As in about 99.99% of all cases where Bill Dunlap  helps.
>
>
> > You probably have a local copy of an old version of plot.hclust or
> plot.dendrogram in your global environmenet or another package that masks
> the one in package:stats.  E.g., I fired up R-2.14.2 and copied those 2
> plot methods to .GlobalEnv and then saved by workspace when quitting R.  I
> then fired up R-3.1.1, which loads the workspace saved by the older version
> of R.  I get:
>
> > > objects()
> > [1] "plot.dendrogram" "plot.hclust"
> > > plot(hclust(dist(c(2,3,5,7,11,13,17,19))))
> > Error in .Internal(dend.window(n, merge, height, hang, labels, ...)) :
> >   there is no .Internal function 'dend.window'
> > > traceback()
> > 2: plot.hclust(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
> > 1: plot(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
>
> > Note how calling traceback() after an error gives more information about
> the source of the error.
>
> > To fix this, get rid of the .RData file that is being loaded when R
> starts.
>
> In the spirit of the old -- now politically incorrect -- sayings
>  `` Real men don't ..... '''
> I'd like to emphasize my own view that
>  "Real useRs don't use .RData"
>
> in other words, experienced R users do not let their workspace
> be saved automatically (to '.RData') and hence do not load any
> .RData automatically at startup.
>
> Consequently, use R with the '--no-save' command line argument
> (maybe also with '--no-restore').
>
> ESS (Emacs Speaks Statistics) users can put
>
> (custom-set-variables
>  '(inferior-R-args "--no-restore-history --no-save ")
> )
>
> into their ~/.emacs
> {and I'd like to see a way to do this easily with RStudio...}
>
> Martin Maechler,
> ETH Zurich and R Core Team
>
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com<http://tibco.com>
>
> > On Tue, Nov 25, 2014 at 12:18 PM, Rolf Turner <r.turner at auckland.ac.nz
> <mailto:r.turner at auckland.ac.nz>> wrote:
> > On 26/11/14 08:53, Michael Mason wrote:
> > Here you are. I expect most folks won't get the error.
>
> > N   = 100; M = 1000
> > mat = matrix(1:(N*M) + rnorm(N*M,0,.5),N,M)
> > h   = hclust(as.dist(1-cor(mat)))
> > plot(h)
>
> > Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
> >    there is no .Internal function 'dend.window'
>
>
>
> > Thanks again
>
>
> > On 11/25/14 11:29 AM, "Rolf Turner" <r.turner at auckland.ac.nz<mailto:
> r.turner at auckland.ac.nz>> wrote:
>
>
>
> > Reproducible example???
>
> > (I know from noddink about hclust, but I tried the example from the help
> > page and it plotted without any problem.)
>
> > cheers,
>
> > Rolf Turner
>
> > On 26/11/14 06:13, Michael Mason wrote:
> > Hello fellow R users,
>
> > I have recently updated to R 3.1.2. When trying to plot an hclust
> > object to generate the dendrogram I get the following error:
>
> > Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
> >     there is no .Internal function 'dend.window'
>
>
> > I am indeed using R3.1.2 but my understanding is that the .Internal API
> > to the C code is no longer used. I have tried detaching the stats
> > package and restarting R to no avail.
> > I would love any help from any wiser guRus.
>
> > Please keep communications on-list; there are others on the list far
> more likely to be able to help you than I.  I am cc-ing this reply to the
> list.
>
> > For what it's worth, I can run your example without error.
>
> > As to how to track down what is going wrong on your system, I'm afraid I
> have no idea.  Someone on the list may have some thoughts.
>
> > cheers,
>
> > Rolf Turner
>
> > --
> > Rolf Turner
> > Technical Editor ANZJS
>
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> > ________________________________
> > --CONFIDENTIALITY NOTICE--: The information contained in this email is
> intended for the exclusive use of the addressee and may contain
> confidential information. If you are not the intended recipient, you are
> hereby notified that any form of dissemination of this communication is
> strictly prohibited. www.benaroyaresearch.org
>
> >       [[alternative HTML version deleted]]
>
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Wed Nov 26 18:56:32 2014
From: rune.haubo at gmail.com (Rune Haubo)
Date: Wed, 26 Nov 2014 18:56:32 +0100
Subject: [R] Checking the proportional odds assumption holds in an
 ordinal logistic regression using polr function
In-Reply-To: <1BAF62E2-7CB7-4845-9A54-44A36F5E1030@gmail.com>
References: <92C9BF3E-698C-4F79-936C-6AD2F662A6B1@gmail.com>
	<CAG_uk91uZdz=X2nSKnUDwACae=1n25SeoeMFkMQV+3pRNp1t4A@mail.gmail.com>
	<1BAF62E2-7CB7-4845-9A54-44A36F5E1030@gmail.com>
Message-ID: <CAG_uk93n4yeox7Wb95JO1QTKq2sU9YJSxxwf-EwUETfML_wYyw@mail.gmail.com>

On 26 November 2014 at 17:55, Charlotte Whitham
<charlotte.whitham at gmail.com> wrote:
> Dear Rune,
>
> Thank you for your prompt reply and it looks like the ordinal package could be the answer I was looking for!
>
> If you don't mind, I'd also like to know please what to do if the tests show the proportional odds assumption is NOT met. (Unfortunately I notice effects from almost all variables that breach the proportional odds assumption in my dataset)

That depends almost entirely on the purpose of the analysis and is not
a topic fit for email - consulting a local statistician is probably
sound advice... Yet: With enough data these tests can be sensitive
beyond practical significance; if the 'proportional' part of the
effect explains the majority of the deviance, perhaps the proportional
odds model provides a reasonably good description of the main
structures in the data anyway. On the other hand, if the magnitude
(not significance!) of the non-proportional effects are large, perhaps
a cumulative link model is not the right kind of model structure and
you should be looking at alternative approaches in your analysis.

Cheers,
Rune

>
> Would you recommend a multinomial logistic model? Or re-scaling of the data?
>
> Thank you for your time,
> Best wishes,
>
> Charlie
>


From jdnewmil at dcn.davis.CA.us  Wed Nov 26 20:09:05 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 26 Nov 2014 11:09:05 -0800
Subject: [R] plot.hclust point to older version
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFE3A@SRVEXCHMBX.precheza.cz>
References: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
	<D09A2E1A.A4BF%mmason@benaroyaresearch.org>
	<21621.38707.24672.588235@stat.math.ethz.ch>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFE3A@SRVEXCHMBX.precheza.cz>
Message-ID: <1086A524-C4B8-4664-BF68-9092810B3DF0@dcn.davis.CA.us>

Short answer to your question is "R files" and original data from external sources.

I tend to keep my projects in separate directories. I make a core R file that I can run from beginning to end using source() to generate my primary analysis objects. I then make another file to keep my source() function call in, as well as a few exploratory plot commands. Recently I have been also sourcing the analysis script in Rmd or Rnw files to "knit" my observations with the output.

Some people complain that their analysis takes too long to be sourcing it all the time. When I have that problem I set up a variable outside my analysis script that I test in my analysis script. If the variable indicates it is time to recalculate, then I do all of that and then save the data in sn rds or rda file. If the variable indicates that I should reuse the cached data, then it skips the calculations and just loads the data. This way I always load the right libraries along with the data, and I don't accidentally save data that I changed outside the analysis script... keeping my results reproducible. (Rds files can be convenient if I have several different slow analyses to compare and I want to only work on one at a time. I set up one control variable for each analysis.)

Some people (smarter than me?) like to build their analysis into an Sweave or knitr file. They can then strip out an analysis R file to use the way I have described if they choose to do so ("literate programming") but I have not picked up that habit yet.

The key is keeping a record of how every object that is in your save file was originally created. If you tolerate auto saving and loading of the environment then you lose that record, and pernicious errors can creep into your environment from who knows where, and you might as well be using Excel if that is how you work. (Note that this means I hardly ever copy data straight from Excel via the clipboard as that is not reproducible. Usually this means Save As CSV in Excel to start my R analysis if that is the data source.)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 26, 2014 2:05:54 AM PST, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi
>
>You say
>
>> in other words, experienced R users do not let their workspace be
>saved
>> automatically (to '.RData') and hence do not load any .RData
>> automatically at startup.
>
>I save/load .RData for years without any issues (except of not
>installed packages when working on different PCs).I usually keep each
>project in separated .RData (and separated folder, together with all
>stuff belonging to that project), which prevent to mess things
>together.
>
>There is no such warning as "do not use .RData" in books I have
>available.
>
>I wonder how experienced useR keep track of several projects without
>using startup loading .RData?
>What would you recommend for keeping track of commands and created
>objects instead of .RData?
>
>Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Martin
>> Maechler
>> Sent: Wednesday, November 26, 2014 10:03 AM
>> To: Michael Mason
>> Cc: R help
>> Subject: Re: [R] plot.hclust point to older version
>>
>>
>> > Thanks! That worked
>>
>> Of course: As in about 99.99% of all cases where Bill Dunlap  helps.
>>
>>
>> > You probably have a local copy of an old version of plot.hclust or
>> plot.dendrogram in your global environmenet or another package that
>> masks the one in package:stats.  E.g., I fired up R-2.14.2 and copied
>> those 2 plot methods to .GlobalEnv and then saved by workspace when
>> quitting R.  I then fired up R-3.1.1, which loads the workspace saved
>> by the older version of R.  I get:
>>
>> > > objects()
>> > [1] "plot.dendrogram" "plot.hclust"
>> > > plot(hclust(dist(c(2,3,5,7,11,13,17,19))))
>> > Error in .Internal(dend.window(n, merge, height, hang, labels,
>...))
>> :
>> >   there is no .Internal function 'dend.window'
>> > > traceback()
>> > 2: plot.hclust(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
>> > 1: plot(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
>>
>> > Note how calling traceback() after an error gives more information
>> about the source of the error.
>>
>> > To fix this, get rid of the .RData file that is being loaded when R
>> starts.
>>
>> In the spirit of the old -- now politically incorrect -- sayings  ``
>> Real men don't ..... '''
>> I'd like to emphasize my own view that
>>  "Real useRs don't use .RData"
>>
>> in other words, experienced R users do not let their workspace be
>saved
>> automatically (to '.RData') and hence do not load any .RData
>> automatically at startup.
>>
>> Consequently, use R with the '--no-save' command line argument (maybe
>> also with '--no-restore').
>>
>> ESS (Emacs Speaks Statistics) users can put
>>
>> (custom-set-variables
>>  '(inferior-R-args "--no-restore-history --no-save ")
>> )
>>
>> into their ~/.emacs
>> {and I'd like to see a way to do this easily with RStudio...}
>>
>> Martin Maechler,
>> ETH Zurich and R Core Team
>>
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com<http://tibco.com>
>>
>> > On Tue, Nov 25, 2014 at 12:18 PM, Rolf Turner
>> <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:
>> > On 26/11/14 08:53, Michael Mason wrote:
>> > Here you are. I expect most folks won't get the error.
>>
>> > N   = 100; M = 1000
>> > mat = matrix(1:(N*M) + rnorm(N*M,0,.5),N,M)
>> > h   = hclust(as.dist(1-cor(mat)))
>> > plot(h)
>>
>> > Error in .Internal(dend.window(n, merge, height2, hang, labels,
>...))
>> :
>> >    there is no .Internal function 'dend.window'
>>
>>
>>
>> > Thanks again
>>
>>
>> > On 11/25/14 11:29 AM, "Rolf Turner"
>> <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>> wrote:
>>
>>
>>
>> > Reproducible example???
>>
>> > (I know from noddink about hclust, but I tried the example from the
>> > help page and it plotted without any problem.)
>>
>> > cheers,
>>
>> > Rolf Turner
>>
>> > On 26/11/14 06:13, Michael Mason wrote:
>> > Hello fellow R users,
>>
>> > I have recently updated to R 3.1.2. When trying to plot an hclust
>> > object to generate the dendrogram I get the following error:
>>
>> > Error in .Internal(dend.window(n, merge, height2, hang, labels,
>...))
>> :
>> >     there is no .Internal function 'dend.window'
>>
>>
>> > I am indeed using R3.1.2 but my understanding is that the .Internal
>> > API to the C code is no longer used. I have tried detaching the
>stats
>> > package and restarting R to no avail.
>> > I would love any help from any wiser guRus.
>>
>> > Please keep communications on-list; there are others on the list
>far
>> more likely to be able to help you than I.  I am cc-ing this reply to
>> the list.
>>
>> > For what it's worth, I can run your example without error.
>>
>> > As to how to track down what is going wrong on your system, I'm
>> afraid I have no idea.  Someone on the list may have some thoughts.
>>
>> > cheers,
>>
>> > Rolf Turner
>>
>> > --
>> > Rolf Turner
>> > Technical Editor ANZJS
>>
>> > ______________________________________________
>> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> > ________________________________
>> > --CONFIDENTIALITY NOTICE--: The information contained in this email
>> is
>> > intended for the exclusive use of the addressee and may contain
>> > confidential information. If you are not the intended recipient,
>you
>> > are hereby notified that any form of dissemination of this
>> > communication is strictly prohibited. www.benaroyaresearch.org
>>
>> >     [[alternative HTML version deleted]]
>>
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Nov 26 20:26:19 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 26 Nov 2014 11:26:19 -0800
Subject: [R] plot.hclust point to older version
In-Reply-To: <CAF8bMcZFK2rne51Vjp6wBhYcMPHWNFfNqgL_CcYqEEAbOjU5DQ@mail.gmail.com>
References: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
	<D09A2E1A.A4BF%mmason@benaroyaresearch.org>
	<21621.38707.24672.588235@stat.math.ethz.ch>
	<CAF8bMcZFK2rne51Vjp6wBhYcMPHWNFfNqgL_CcYqEEAbOjU5DQ@mail.gmail.com>
Message-ID: <AC9ECA23-B403-4B5B-B0CD-3DCF5AD51E02@comcast.net>


On Nov 26, 2014, at 9:49 AM, William Dunlap wrote:

> How disruptive would it be if R were changed so the startup line
>   [Previously saved workspace restored]
> were changed to show the complete name, from normalizePath(), of the
> saved workspace file?  E.g.,
>   [Previously saved workspace restored from 'C:\Program Files\R\.RData']
> 
> (It is bad enough that the file name starts with a dot so it is hidden from
> 'ls',
> but on Windows lots of people don't know what directory R is starting in.
> On
> my Windows PC R-3.1.2 starts in C:/Program Files/R, the parent of its RHOME
> directory.)

On the Mac Gui that happens with no effort as well as a message saying where the GUI history file resides. I just checked my .Rprofile file to make sure it wasn't doing that. I also have a line that prints the data and time:

utils:::timestamp(stamp = Sys.Date() )

Couldn't you just create a template .Rprofile with the appropriate message printed to console?

-- 
david.
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Wed, Nov 26, 2014 at 1:02 AM, Martin Maechler <maechler at stat.math.ethz.ch
>> wrote:
> 
>> 
>>> Thanks! That worked
>> 
>> Of course: As in about 99.99% of all cases where Bill Dunlap  helps.
>> 
>> 
>>> You probably have a local copy of an old version of plot.hclust or
>> plot.dendrogram in your global environmenet or another package that masks
>> the one in package:stats.  E.g., I fired up R-2.14.2 and copied those 2
>> plot methods to .GlobalEnv and then saved by workspace when quitting R.  I
>> then fired up R-3.1.1, which loads the workspace saved by the older version
>> of R.  I get:
>> 
>>>> objects()
>>> [1] "plot.dendrogram" "plot.hclust"
>>>> plot(hclust(dist(c(2,3,5,7,11,13,17,19))))
>>> Error in .Internal(dend.window(n, merge, height, hang, labels, ...)) :
>>>  there is no .Internal function 'dend.window'
>>>> traceback()
>>> 2: plot.hclust(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
>>> 1: plot(hclust(dist(c(2, 3, 5, 7, 11, 13, 17, 19))))
>> 
>>> Note how calling traceback() after an error gives more information about
>> the source of the error.
>> 
>>> To fix this, get rid of the .RData file that is being loaded when R
>> starts.
>> 
>> In the spirit of the old -- now politically incorrect -- sayings
>> `` Real men don't ..... '''
>> I'd like to emphasize my own view that
>> "Real useRs don't use .RData"
>> 
>> in other words, experienced R users do not let their workspace
>> be saved automatically (to '.RData') and hence do not load any
>> .RData automatically at startup.
>> 
>> Consequently, use R with the '--no-save' command line argument
>> (maybe also with '--no-restore').
>> 
>> ESS (Emacs Speaks Statistics) users can put
>> 
>> (custom-set-variables
>> '(inferior-R-args "--no-restore-history --no-save ")
>> )
>> 
>> into their ~/.emacs
>> {and I'd like to see a way to do this easily with RStudio...}
>> 
>> Martin Maechler,
>> ETH Zurich and R Core Team
>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com<http://tibco.com>
>> 
>>> On Tue, Nov 25, 2014 at 12:18 PM, Rolf Turner <r.turner at auckland.ac.nz
>> <mailto:r.turner at auckland.ac.nz>> wrote:
>>> On 26/11/14 08:53, Michael Mason wrote:
>>> Here you are. I expect most folks won't get the error.
>> 
>>> N   = 100; M = 1000
>>> mat = matrix(1:(N*M) + rnorm(N*M,0,.5),N,M)
>>> h   = hclust(as.dist(1-cor(mat)))
>>> plot(h)
>> 
>>> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>>>   there is no .Internal function 'dend.window'
>> 
>> 
>> 
>>> Thanks again
>> 
>> 
>>> On 11/25/14 11:29 AM, "Rolf Turner" <r.turner at auckland.ac.nz<mailto:
>> r.turner at auckland.ac.nz>> wrote:
>> 
>> 
>> 
>>> Reproducible example???
>> 
>>> (I know from noddink about hclust, but I tried the example from the help
>>> page and it plotted without any problem.)
>> 
>>> cheers,
>> 
>>> Rolf Turner
>> 
>>> On 26/11/14 06:13, Michael Mason wrote:
>>> Hello fellow R users,
>> 
>>> I have recently updated to R 3.1.2. When trying to plot an hclust
>>> object to generate the dendrogram I get the following error:
>> 
>>> Error in .Internal(dend.window(n, merge, height2, hang, labels, ...)) :
>>>    there is no .Internal function 'dend.window'
>> 
>> 
>>> I am indeed using R3.1.2 but my understanding is that the .Internal API
>>> to the C code is no longer used. I have tried detaching the stats
>>> package and restarting R to no avail.
>>> I would love any help from any wiser guRus.
>> 
>>> Please keep communications on-list; there are others on the list far
>> more likely to be able to help you than I.  I am cc-ing this reply to the
>> list.
>> 
>>> For what it's worth, I can run your example without error.
>> 
>>> As to how to track down what is going wrong on your system, I'm afraid I
>> have no idea.  Someone on the list may have some thoughts.
>> 
>>> cheers,
>> 
>>> Rolf Turner
>> 
>>> --
>>> Rolf Turner
>>> Technical Editor ANZJS
>> 
>>> ______________________________________________
>>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>> ________________________________
>>> --CONFIDENTIALITY NOTICE--: The information contained in this email is
>> intended for the exclusive use of the addressee and may contain
>> confidential information. If you are not the intended recipient, you are
>> hereby notified that any form of dissemination of this communication is
>> strictly prohibited. www.benaroyaresearch.org
>> 
>>>      [[alternative HTML version deleted]]
>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From yousri.fanous at gmail.com  Wed Nov 26 23:04:31 2014
From: yousri.fanous at gmail.com (Yousri Fanous)
Date: Wed, 26 Nov 2014 17:04:31 -0500
Subject: [R] How can I run a TSP program inside R
Message-ID: <CADsEwSd4DAK_2rqh8+vZE9d38xcVF+5d2ObB+4v=AMAcjrz0xw@mail.gmail.com>

I have the following TSP code:

options memory = 6;
options crt;
in 'mydat.tlb' ;
?
? Create 2 new variables
?
age20 = age -20;
lwage = log(wage);
?
?
olsq lwage c f edy tenure age20 pu;

How can I run it inside R?
Where can I get more explanation on how to code for TSP

	[[alternative HTML version deleted]]


From mtripoli at istat.it  Wed Nov 26 11:27:47 2014
From: mtripoli at istat.it (Massimiliano Tripoli)
Date: Wed, 26 Nov 2014 11:27:47 +0100 (CET)
Subject: [R] Converting list to character
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FB4E38@mb02.ads.tamu.edu>
Message-ID: <201386709.1978933.1416997667322.JavaMail.root@istat.it>

Thanks David,
that's I was looking for.
Thanks to Chel too.

Massimiliano

----- Messaggio originale -----
Da: "David L Carlson" <dcarlson at tamu.edu>
A: "Chel Hee Lee" <chl948 at mail.usask.ca>, "Massimiliano Tripoli" <mtripoli at istat.it>, r-help at r-project.org
Inviato: Marted?, 25 novembre 2014 19:40:51
Oggetto: RE: [R] Converting list to character

Or just modify your aggregate() command:

> TAB <- aggregate(mydata$CODE, by=list(ID=mydata$ID, 
+        YEAR=mydata$YEAR), FUN=paste0, collapse=", ")
> TAB
     ID YEAR              x
1   986 2008         GR.3.8
2  1251 2008 GR.3.1, GR.3.8
3  1801 2008         GR.3.8
4    11 2009         GR.3.7
5   986 2009         GR.3.8
6  1251 2009 GR.3.1, GR.3.8
7  1801 2009         GR.3.8
8    11 2010         GR.3.7
9   460 2010         GR.3.1
10  986 2010         GR.3.8
11 1251 2010 GR.3.1, GR.3.8
12 1801 2010         GR.3.8
13  460 2011         GR.3.1
14  986 2011         GR.3.8
15 1251 2011 GR.3.1, GR.3.8
16 1801 2011         GR.3.8

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Lee, Chel Hee
Sent: Tuesday, November 25, 2014 11:23 AM
To: Massimiliano Tripoli; r-help at r-project.org
Subject: Re: [R] Converting list to character

 > do.call("rbind", TAB$x)
    [,1]     [,2]
1  "GR.3.8" "GR.3.8"
2  "GR.3.1" "GR.3.8"
4  "GR.3.8" "GR.3.8"
5  "GR.3.7" "GR.3.7"
6  "GR.3.8" "GR.3.8"
7  "GR.3.1" "GR.3.8"
9  "GR.3.8" "GR.3.8"
10 "GR.3.7" "GR.3.7"
11 "GR.3.1" "GR.3.1"
12 "GR.3.8" "GR.3.8"
13 "GR.3.1" "GR.3.8"
15 "GR.3.8" "GR.3.8"
16 "GR.3.1" "GR.3.1"
17 "GR.3.8" "GR.3.8"
18 "GR.3.1" "GR.3.8"
20 "GR.3.8" "GR.3.8"
 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 11/25/2014 6:07 AM, Massimiliano Tripoli wrote:
>
>
> Dear all,
>
> I can't convert the result of aggregate function in a dataframe. My data
> looks like:
>
> mydata <- structure(list(ID = c(11, 11, 460, 460, 986, 986, 986, 986, 1251,
> 1251, 1251, 1251, 1251, 1251, 1251, 1251, 1801, 1801, 1801, 1801
> ), YEAR = c(2009, 2010, 2010, 2011, 2008, 2009, 2010, 2011, 2008,
> 2008, 2009, 2009, 2010, 2010, 2011, 2011, 2008, 2009, 2010, 2011
> ), Y = c(158126, 153015, 3701, 5880, 718663, 661112, 527233,
> 558281, 450, 131714, 427, 124648, 425, 116500, 434, 123853, 17400,
> 16493, 8057, 8329), CODE = c("GR.3.7", "GR.3.7", "GR.3.1", "GR.3.1",
> "GR.3.8", "GR.3.8", "GR.3.8", "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.1",
> "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.1", "GR.3.8", "GR.3.8", "GR.3.8",
> "GR.3.8", "GR.3.8")), .Names = c("ID", "YEAR", "Y", "CODE"), row.names = c(NA,
> 20L), class = "data.frame")
>
> and by using aggregate function
>
> TAB <- aggregate(mydata$CODE,by=list(ID=mydata$ID,YEAR=mydata$YEAR),FUN=paste0)
>
> What I want is a dataframe like of printing TAB:
>> TAB
>       ID YEAR              x
> 1   986 2008         GR.3.8
> 2  1251 2008 GR.3.1, GR.3.8
> 3  1801 2008         GR.3.8
> 4    11 2009         GR.3.7
> 5   986 2009         GR.3.8
> 6  1251 2009 GR.3.1, GR.3.8
> 7  1801 2009         GR.3.8
> 8    11 2010         GR.3.7
> 9   460 2010         GR.3.1
> 10  986 2010         GR.3.8
> 11 1251 2010 GR.3.1, GR.3.8
> 12 1801 2010         GR.3.8
> 13  460 2011         GR.3.1
> 14  986 2011         GR.3.8
> 15 1251 2011 GR.3.1, GR.3.8
> 16 1801 2011         GR.3.8
>
>> str(TAB)[1:10]
> 'data.frame':        16 obs. of  3 variables:
>   $ ID  : num  986 1251 1801 11 986 ...
>   $ YEAR: num  2008 2008 2008 2009 2009 ...
>   $ x   :List of 16
>    ..$ 1 : chr "GR.3.8"
>    ..$ 2 : chr  "GR.3.1" "GR.3.8"
>    ..$ 4 : chr "GR.3.8"
>    ..$ 5 : chr "GR.3.7"
>    ..$ 6 : chr "GR.3.8"
>    ..$ 7 : chr  "GR.3.1" "GR.3.8"
>    ..$ 9 : chr "GR.3.8"
>    ..$ 10: chr "GR.3.7"
>    ..$ 11: chr "GR.3.1"
>    ..$ 12: chr "GR.3.8"
>    ..$ 13: chr  "GR.3.1" "GR.3.8"
>    ..$ 15: chr "GR.3.8"
>    ..$ 16: chr "GR.3.1"
>    ..$ 17: chr "GR.3.8"
>    ..$ 18: chr  "GR.3.1" "GR.3.8"
>    ..$ 20: chr "GR.3.8"
> NULL
>
> As you can see the "x" coloumn is a list and I would want to change it to character variable.
> Anyone may help me?
> Thanks,
>
> Massimiliano
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
Massimiliano Tripoli 
Collaboratore T.E.R. scado il 31/12/2014 
ISTAT - DCCN - Direzione Centrale della Contabilit? Nazionale 
U.O. Contabilit? dei flussi di materia del sistema economico - CSA/C
Via Depretis, 74/B 00184 Roma 
Tel. 06.4673.3132 
E-mail: mtripoli at istat.it 


From satu.helske at jyu.fi  Wed Nov 26 12:16:01 2014
From: satu.helske at jyu.fi (Helske Satu)
Date: Wed, 26 Nov 2014 11:16:01 +0000
Subject: [R] Using grid.layout inside grid.layout with grid package: naming
 of the viewports affects plotting
Message-ID: <F56518F8CBDA4144A1AF39EC7DF4858F48A5831A@mbs2.ad.jyu.fi>

R version 3.1.1 (2014-07-10)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] C

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.1


I have a plotting function to produce plots with stacked plots (for simplicity, here two rectangles).

library(grid)
stackedplot <- function(main=""){
  top.vp <- viewport(
    layout=grid.layout(2, 1))
  p1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="plot1")
  p2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="plot2")
  splot <- vpTree(top.vp, vpList(p1,p2))
  pushViewport(splot)
  seekViewport("plot1")
  grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
  seekViewport("plot2")
  grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
 }

For creating a 2x2 grid with four stacked plots I tried to use the following code:

grid.newpage()
multitop.vp <- viewport(layout=grid.layout(2,2))
pl1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="A")
pl2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="B")
pl3 <- viewport(layout.pos.col=2, layout.pos.row=1, name="C")
pl4 <- viewport(layout.pos.col=2, layout.pos.row=2, name="D")
vpall <- vpTree(multitop.vp, vpList(pl1,pl2,pl3,pl4))
pushViewport(vpall)
seekViewport("A")
stackedplot(main="A")
seekViewport("B")
stackedplot(main="B")
seekViewport("C")
stackedplot(main="C")
seekViewport("D")
stackedplot(main="D")

This does not work as all the plots are plotted in the same cell of the grid (viewport A). However, if I plot them in a reversed order, the plots arrange as was supposed to: D to D, C to C and so on.

seekViewport("D")
stackedplot(main="D")
seekViewport("C")
stackedplot(main="C")
seekViewport("B")
stackedplot(main="B")
seekViewport("A")
stackedplot(main="A")

I tried with different names and found out that if I plot in reversed alphabetical order everything works fine. Once I try to plot in a viewport with a name earlier in alphabetical order, all other plots thereafter are plotted in the same viewport.

Why is this happening?

Regards,
Satu Helske

	[[alternative HTML version deleted]]


From Krishna.SK at lnttechservices.com  Wed Nov 26 13:31:28 2014
From: Krishna.SK at lnttechservices.com (Krishna Bhargava S K)
Date: Wed, 26 Nov 2014 12:31:28 +0000
Subject: [R] rJava Package
Message-ID: <68166E6770E5A94AA057F7AB31085E0B4DE2F7AC@POCITMSEXMB03.LntUniverse.com>

Hi All,

                I am a beginner to R. I have installed tried a sample of JRI using Rengine and Rserve.
                I found normalization and sqrt function in some sample code.
                Is there any link where there is a list of functions that is provided in R which I can use to process data in java programs.

Regards
KB

L&T Technology Services Ltd

www.LntTechservices.com<http://www.lnttechservices.com/>

This Email may contain confidential or privileged information for the intended recipient (s). If you are not the intended recipient, please do not use or disseminate the information, notify the sender and delete it from your system.

	[[alternative HTML version deleted]]


From charlotte.whitham at gmail.com  Wed Nov 26 17:55:20 2014
From: charlotte.whitham at gmail.com (Charlotte Whitham)
Date: Wed, 26 Nov 2014 16:55:20 +0000
Subject: [R] Checking the proportional odds assumption holds in an
	ordinal logistic regression using polr function
In-Reply-To: <CAG_uk91uZdz=X2nSKnUDwACae=1n25SeoeMFkMQV+3pRNp1t4A@mail.gmail.com>
References: <92C9BF3E-698C-4F79-936C-6AD2F662A6B1@gmail.com>
	<CAG_uk91uZdz=X2nSKnUDwACae=1n25SeoeMFkMQV+3pRNp1t4A@mail.gmail.com>
Message-ID: <1BAF62E2-7CB7-4845-9A54-44A36F5E1030@gmail.com>

Dear Rune,

Thank you for your prompt reply and it looks like the ordinal package could be the answer I was looking for!

If you don't mind, I'd also like to know please what to do if the tests show the proportional odds assumption is NOT met. (Unfortunately I notice effects from almost all variables that breach the proportional odds assumption in my dataset) 

Would you recommend a multinomial logistic model? Or re-scaling of the data?

Thank you for your time,
Best wishes,

Charlie

On 26 Nov 2014, at 14:08, Rune Haubo <rune.haubo at gmail.com> wrote:

> Dear Charlie,
> 
> I admit that I haven't read your email closely, but here is a way to
> test for non-proportional odds using the ordinal package (warning:
> self-promotion) using the wine data set also from the ordinal package.
> There is more information in the package vignettes
> 
> Hope this is something you can use.
> Cheers,
> Rune
> 
>> library(ordinal)
>> ## Fit model:
>> fm <- clm(rating ~ temp + contact, data=wine)
>> summary(fm)
> formula: rating ~ temp + contact
> data:    wine
> 
> link  threshold nobs logLik AIC    niter max.grad cond.H
> logit flexible  72   -86.49 184.98 6(0)  4.64e-15 2.7e+01
> 
> Coefficients:
>           Estimate Std. Error z value Pr(>|z|)
> tempwarm     2.5031     0.5287   4.735 2.19e-06 ***
> contactyes   1.5278     0.4766   3.205  0.00135 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Threshold coefficients:
>    Estimate Std. Error z value
> 1|2  -1.3444     0.5171  -2.600
> 2|3   1.2508     0.4379   2.857
> 3|4   3.4669     0.5978   5.800
> 4|5   5.0064     0.7309   6.850
>> ## Model with non-proportional odds for contact:
>> fm2 <- clm(rating ~ temp, nominal=~contact, data=wine)
>> ## Likelihood ratio test of non-proportional odds:
>> anova(fm, fm2)
> Likelihood ratio tests of cumulative link models:
> 
>    formula:                nominal: link: threshold:
> fm  rating ~ temp + contact ~1       logit flexible
> fm2 rating ~ temp           ~contact logit flexible
> 
>    no.par    AIC  logLik LR.stat df Pr(>Chisq)
> fm       6 184.98 -86.492
> fm2      9 190.42 -86.209  0.5667  3      0.904
>> ## Automatic tests of non-proportional odds for all varibles:
>> nominal_test(fm)
> Tests of nominal effects
> 
> formula: rating ~ temp + contact
>        Df  logLik    AIC    LRT Pr(>Chi)
> <none>     -86.492 184.98
> temp     3 -84.904 187.81 3.1750   0.3654
> contact  3 -86.209 190.42 0.5667   0.9040
> 
> On 25 November 2014 at 17:21, Charlotte Whitham
> <charlotte.whitham at gmail.com> wrote:
>> Dear list,
>> 
>> I have used the ?polr? function in the MASS package to run an ordinal logistic regression for an ordinal categorical response variable with 15 continuous explanatory variables.
>> I have used the code (shown below) to check that my model meets the proportional odds assumption following advice provided at (http://www.ats.ucla.edu/stat/r/dae/ologit.htm) ? which has been extremely helpful, thank you to the authors! However, I?m a little worried about the output implying that not only are the coefficients across various cutpoints similar, but they are exactly the same (see graphic below).
>> 
>> Here is the code I used (and see attached for the output graphic)
>> 
>> FGV1b<-data.frame(FG1_val_cat=factor(FGV1b[,"FG1_val_cat"]),scale(FGV1[,c("X","Y","Slope","Ele","Aspect","Prox_to_for_FG","Prox_to_for_mL","Prox_to_nat_border","Prox_to_village","Prox_to_roads","Prox_to_rivers","Prox_to_waterFG","Prox_to_watermL","Prox_to_core","Prox_to_NR","PCA1","PCA2","PCA3")]))
>> 
>> b<-polr(FGV1b$FG1_val_cat ~ FGV1b$X + FGV1b$Y + FGV1b$Slope + FGV1b$Ele + FGV1b$Aspect + FGV1b$Prox_to_for_FG + FGV1b$Prox_to_for_mL + FGV1b$Prox_to_nat_border + FGV1b$Prox_to_village + FGV1b$Prox_to_roads + FGV1b$Prox_to_rivers + FGV1b$Prox_to_waterFG + FGV1b$Prox_to_watermL + FGV1b$Prox_to_core + FGV1b$Prox_to_NR, data = FGV1b, Hess=TRUE)
>> 
>> #Checking the assumption. So the following code will estimate the values to be graphed. First it shows us #the logit transformations of the probabilities of being greater than or equal to each value of the target #variable
>> 
>> FGV1b$FG1_val_cat<-as.numeric(FGV1b$FG1_val_cat)
>> 
>> sf <- function(y) {
>> 
>>  c('VC>=1' = qlogis(mean(FGV1b$FG1_val_cat >= 1)),
>> 
>>    'VC>=2' = qlogis(mean(FGV1b$FG1_val_cat >= 2)),
>> 
>>    'VC>=3' = qlogis(mean(FGV1b$FG1_val_cat >= 3)),
>> 
>>    'VC>=4' = qlogis(mean(FGV1b$FG1_val_cat >= 4)),
>> 
>>    'VC>=5' = qlogis(mean(FGV1b$FG1_val_cat >= 5)),
>> 
>>    'VC>=6' = qlogis(mean(FGV1b$FG1_val_cat >= 6)),
>> 
>>    'VC>=7' = qlogis(mean(FGV1b$FG1_val_cat >= 7)),
>> 
>>    'VC>=8' = qlogis(mean(FGV1b$FG1_val_cat >= 8)))
>> 
>> }
>> 
>>  (t <- with(FGV1b, summary(as.numeric(FGV1b$FG1_val_cat) ~ FGV1b$X + FGV1b$Y + FGV1b$Slope + FGV1b$Ele + FGV1b$Aspect + FGV1b$Prox_to_for_FG + FGV1b$Prox_to_for_mL + FGV1b$Prox_to_nat_border + FGV1b$Prox_to_village + FGV1b$Prox_to_roads + FGV1b$Prox_to_rivers + FGV1b$Prox_to_waterFG + FGV1b$Prox_to_watermL + FGV1b$Prox_to_core + FGV1b$Prox_to_NR, fun=sf)))
>> 
>> 
>> 
>> #The table displays the (linear) predicted values we would get if we regressed our
>> 
>> #dependent variable on our predictor variables one at a time, without the parallel slopes
>> 
>> #assumption. So now, we can run a series of binary logistic regressions with varying cutpoints
>> 
>> #on the dependent variable to check the equality of coefficients across cutpoints
>> 
>> par(mfrow=c(1,1))
>> 
>> plot(t, which=1:8, pch=1:8, xlab='logit', main=' ', xlim=range(s[,7:8]))
>> 
>> 
>> 
>> Apologies that I am no statistics expert and perhaps I am missing something obvious here. However, I have spent a long time trying to figure out if there is a problem in how I tested the model assumption and also trying to figure out other ways to run the same kind of model.
>> 
>> For example, I read in many help mailing lists that others use the vglm function (in the VGAM package) and the lrm function (in the rms package) (for example see here:  http://stats.stackexchange.com/questions/25988/proportional-odds-assumption-in-ordinal-logistic-regression-in-r-with-the-packag). I have tried to run the same models but am continuously coming up against warnings and errors.
>> 
>> For example, when I try to fit the vglm model with the ?parallel=FALSE? argument (as the previous link mentions is important for testing the proportional odds assumption), I encounter the following error:
>> 
>> 
>> 
>> Error in lm.fit(X.vlm, y = z.vlm, ...) : NA/NaN/Inf in 'y'
>> 
>> In addition: Warning message:
>> 
>> In Deviance.categorical.data.vgam(mu = mu, y = y, w = w, residuals = residuals,  :
>> 
>>  fitted values close to 0 or 1
>> 
>> 
>> 
>> And after many searches for help, I can?t seem to find a way to fix this problem.
>> 
>> I would like to ask please if there is anyone who might understand and be able to explain to me why the graph I produced above looks as it does. If indeed it means that something isn?t right, could you please help me find a way to test the proportional odds assumption when just using the polr function. Or if that is just not possible, then I will resort to trying to use the vglm function, but would then need some help to explain why I keep getting the error given above.
>> 
>> I hope this is clear. Please do let me know if I should provide some more information that would help address this query.
>> 
>> NOTE: As a background, there are 1000 datapoints here, which are actually location points across a study area. I am looking to see if there are any relationships between the categorical response variable and these 15 explanatory variables. All of those 15 explanatory variables are spatial characteristics (for example, elevation, x-y coordinates, proximity to forest etc.). The 1000 datapoints were randomly allocated using a GIS, but I took a stratified sampling approach. I made sure that 125 points were randomly chosen within each of the 8 different categorical response levels. I hope this information is also helpful.
>> 
>> I am extremely grateful to anyone who could please give me some guidance with this.
>> 
>> Thank you very much for your time,
>> 
>> Charlie
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Thierry.ONKELINX at inbo.be  Thu Nov 27 09:29:24 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 27 Nov 2014 08:29:24 +0000
Subject: [R] ggplot facet and subsetting
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFED4@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFED4@SRVEXCHMBX.precheza.cz>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B52A98@inbomail.inbo.be>

Dear Petr,

You need to use aes_string() instead of aes().

The.cols <- colnames(data)[n:m]
for (i in The.cols) { p<-ggplot(data, aes_string(x="x", y= i, colour="f"))), ...}

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-help [mailto:r-help-bounces at r-project.org] Namens PIKAL Petr
Verzonden: woensdag 26 november 2014 14:40
Aan: R help
Onderwerp: [R] ggplot facet and subsetting

Dear all

I encountered strange behaviour of ggplot with combination of facet and subsetting. I use for creating plots sometimes a for cycle, something like this

for (i in n:m) { p<-ggplot(data, aes(x=x, y=data[,i], colour=f))), ...}

However I found strange result with this combination

This is OK but only in BW
p<-ggplot(vec.c, aes(x=fi, y=nad1mi))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

this is OK with colour
p<-ggplot(vec.c, aes(x=fi, y=nad1mi, colour=as.factor(cas)))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

Here results in facets are mismatched
p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2], colour=as.factor(cas)))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

and this is mismatched too
p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2]))
p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)

Doeas anybody know what I am doing wrong?

> dput(vec.c)
structure(list(cas = c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L),
    nad1mi = c(3, 2.7, 0.3, 0.5, 1.9, 5.3, 0.4, 3, 5.4, 0.7,
    20.6, 16.7, 16.6, 20.7, 16.1, 15.2, 20.5, 16.4, 14.8, 24.6,
    19.3, 15.2, 26.9, 21.3, 20.6, 22.6, 16.3, 15.7, 19.3, 16.5,
    15.5, 3.6, 3.4, 5.9, 4.6, 5.4, 4.2, 5.3, 5.6, 5.1, 5), stroj = structure(c(3L,
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("mastersizer",
    "odstredivka", "zetasizer"), class = "factor"), fi = c(341L,
    341L, 285L, 285L, 401L, 401L, 231L, 231L, 190L, 190L, 341L,
    341L, 341L, 285L, 285L, 285L, 401L, 401L, 401L, 231L, 231L,
    231L, 190L, 190L, 190L, 167L, 167L, 167L, 161L, 161L, 161L,
    341L, 341L, 285L, 285L, 401L, 401L, 231L, 231L, 190L, 190L
    )), .Names = c("cas", "nad1mi", "stroj", "fi"), class = "data.frame", row.names = c(1L, 2L, 6L, 7L, 11L, 12L, 16L, 17L, 21L, 22L, 26L, 27L, 28L, 32L, 33L, 34L, 38L, 39L, 40L, 44L, 45L, 46L, 50L, 51L, 52L, 56L, 57L, 58L, 62L, 63L, 64L, 68L, 69L, 73L, 74L, 78L, 79L, 83L, 84L, 88L,
89L))
>

Regards
Petr

> sessionInfo(package = NULL)
R Under development (unstable) (2014-07-16 r66175)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech Republic.1250 [3] LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C [5] LC_TIME=Czech_Czech Republic.1250

attached base packages:
[1] stats     datasets  utils     grDevices graphics  methods   base

other attached packages:
[1] ggplot2_1.0.0   lattice_0.20-29 fun_1.0

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4 digest_0.6.4     grid_3.2.0       gtable_0.1.2
 [5] labeling_0.2     MASS_7.3-33      munsell_0.4.2    plyr_1.8.1
 [9] proto_0.3-10     Rcpp_0.11.2      reshape2_1.4     scales_0.2.4
[13] stringr_0.6.2    tools_3.2.0
>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From dario.beraldi at gmail.com  Thu Nov 27 10:07:16 2014
From: dario.beraldi at gmail.com (Dario Beraldi)
Date: Thu, 27 Nov 2014 09:07:16 +0000
Subject: [R] R argparse: Line breaks in description
Message-ID: <CAEa0nG4dTRh2RGGSm1ogv1GB5tyPpxaP-ojWj=GXDuw1-uWpgw@mail.gmail.com>

Hello,

I'm using the R package argparse to parse command line arguments.

For readability, I'd like to add line breaks in the "description" of the
script and in the help of the arguments. However, I can't do it... Let's
see an example. Given this script:

    #!/usr/bin/env Rscript

    require(argparse)

    docstring<- "Description\nDone"

    parser<- ArgumentParser(description= docstring)
    args<- parser$parse_args()

When executed with *-h* it should print:

    Description
    Done

However, I'm getting the error:

    Error in rjson::fromJSON(output) : unexpected character 'F'
    Calls: <Anonymous> -> <Anonymous> -> <Anonymous>
    Execution halted

Variation of docstring like *paste("Description", "Done", sep= '\n')* are
equally unsuccessful.

As well as passing RawTextHelpFormatter like:
parser<- ArgumentParser(description= docstring, RawTextHelpFormatter= TRUE)

Any idea how to put line breaks in argparse?

Many thanks!

NB: Cross posted on StackOverflow http://stackoverflow.com/posts/27150625/

Dario

    sessionInfo()
    R version 3.0.1 (2013-05-16)
    Platform: x86_64-apple-darwin10.8.0 (64-bit)

    locale:
    [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

    attached base packages:
    [1] stats     graphics  grDevices utils     datasets  methods
base

    other attached packages:
    [1] argparse_1.0.1 proto_0.3-10

    loaded via a namespace (and not attached):
    [1] findpython_1.0.1 getopt_1.20.0    rjson_0.2.13

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Nov 27 10:10:39 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 27 Nov 2014 10:10:39 +0100
Subject: [R] Using Rmpfr to round with precision in R
In-Reply-To: <CAGP33S4k2qfwzA0txNBHh_xndxnWr=HiP4FjRmyrZ_cL9Auauw@mail.gmail.com>
References: <CAGP33S4k2qfwzA0txNBHh_xndxnWr=HiP4FjRmyrZ_cL9Auauw@mail.gmail.com>
Message-ID: <21622.60047.959693.244631@stat.math.ethz.ch>

>>>>> Artur Augusto <arturaugusto at gmail.com>
>>>>>     on Wed, 19 Nov 2014 15:26:12 -0200 writes:

    > I'm trying to use the Rmpfr library with the round() function to apply
    > the round half to even rule and achieve correct results, without
    > errors due the finite precision of float point values.

    > Example of problem:

    > round(1.225,2)
    > #[1] 1.23

    > So far, this is what I've achieved:

    > library(Rmpfr)
    > x <- c(1.225, 1.2225, 1.22225, 1.222225)
    > n <- c(2, 3, 4, 5)
    > round2 <- function(x, n){
    > sprintf(paste("%#.", n, "f", sep=""), round(mpfr(as.character(x), 200), n))
    > }
    > mapply(round2, x, n)
    > #[1] "1.22"    "1.222"   "1.2222"  "1.22222"

The above  round2() function is really pretty strange [what do you really want?]
but below,  you have a very good point :

    > But in some cases I don't get the desired results:

    > round2(1.152, 2)# Should be 1.15
    > #[1] "1.16"

    > Reading the Rmpfr docs, at the roundMpfr() function, it says:

Actually,  roundMpfr() is *not* used  by  round(<mpfr>, *)
It has somewhat different semantics. That's why I used a new
function name, roundMpfr(),  whereas the round() method for
"mpfr" objects is what you get from

selectMethod(round, "mpfr")

    > The mpfr class group method Math2 implements a method for round(x,
    > digits) which rounds to decimal digits.

Indeed... and that is different from the roundMpfr() as
mentioned above.

    > But I can't figure how to use it.

    > How can I achieve desired rounded results?
    > Artur

Wait a day or two [depending on how quickly the new Rmpfr version 0.5-7
gets published on CRAN], and update your Rmpfr package.
The problem is fixed in Rmpfr 0.5-7.

If you had CC'ed your e-mail to  
   maintainer("Rmpfr")
I would have heard of the problem earlier and almost surely
have fixed it earlier.

Best regards,
Martin Maechler  (maintainer of 'Rmpfr').


From petr.pikal at precheza.cz  Thu Nov 27 14:14:01 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 27 Nov 2014 13:14:01 +0000
Subject: [R] ggplot facet and subsetting
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3B52A98@inbomail.inbo.be>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFED4@SRVEXCHMBX.precheza.cz>
	<AA818EAD2576BC488B4F623941DA7427F3B52A98@inbomail.inbo.be>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF00C5@SRVEXCHMBX.precheza.cz>

Thank you Thierry

Still I wonder why without facet_grid code

for (i in n:m) { p<-ggplot(data, aes(x=x, y=data[,i], colour=f))), ...}

works

and with facet_grid does not.

Best regards
Petr

> -----Original Message-----
> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
> Sent: Thursday, November 27, 2014 9:29 AM
> To: PIKAL Petr; R help
> Subject: RE: ggplot facet and subsetting
>
> Dear Petr,
>
> You need to use aes_string() instead of aes().
>
> The.cols <- colnames(data)[n:m]
> for (i in The.cols) { p<-ggplot(data, aes_string(x="x", y= i,
> colour="f"))), ...}
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance Kliniekstraat 25 1070 Anderlecht Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: R-help [mailto:r-help-bounces at r-project.org] Namens PIKAL Petr
> Verzonden: woensdag 26 november 2014 14:40
> Aan: R help
> Onderwerp: [R] ggplot facet and subsetting
>
> Dear all
>
> I encountered strange behaviour of ggplot with combination of facet and
> subsetting. I use for creating plots sometimes a for cycle, something
> like this
>
> for (i in n:m) { p<-ggplot(data, aes(x=x, y=data[,i], colour=f))), ...}
>
> However I found strange result with this combination
>
> This is OK but only in BW
> p<-ggplot(vec.c, aes(x=fi, y=nad1mi))
> p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
> this is OK with colour
> p<-ggplot(vec.c, aes(x=fi, y=nad1mi, colour=as.factor(cas)))
> p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
> Here results in facets are mismatched
> p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2], colour=as.factor(cas)))
> p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
> and this is mismatched too
> p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2]))
> p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
> Doeas anybody know what I am doing wrong?
>
> > dput(vec.c)
> structure(list(cas = c(1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 0L, 1L,
> 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L, 2L, 0L, 1L,
> 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L),
>     nad1mi = c(3, 2.7, 0.3, 0.5, 1.9, 5.3, 0.4, 3, 5.4, 0.7,
>     20.6, 16.7, 16.6, 20.7, 16.1, 15.2, 20.5, 16.4, 14.8, 24.6,
>     19.3, 15.2, 26.9, 21.3, 20.6, 22.6, 16.3, 15.7, 19.3, 16.5,
>     15.5, 3.6, 3.4, 5.9, 4.6, 5.4, 4.2, 5.3, 5.6, 5.1, 5), stroj =
> structure(c(3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("mastersizer",
>     "odstredivka", "zetasizer"), class = "factor"), fi = c(341L,
>     341L, 285L, 285L, 401L, 401L, 231L, 231L, 190L, 190L, 341L,
>     341L, 341L, 285L, 285L, 285L, 401L, 401L, 401L, 231L, 231L,
>     231L, 190L, 190L, 190L, 167L, 167L, 167L, 161L, 161L, 161L,
>     341L, 341L, 285L, 285L, 401L, 401L, 231L, 231L, 190L, 190L
>     )), .Names = c("cas", "nad1mi", "stroj", "fi"), class =
> "data.frame", row.names = c(1L, 2L, 6L, 7L, 11L, 12L, 16L, 17L, 21L,
> 22L, 26L, 27L, 28L, 32L, 33L, 34L, 38L, 39L, 40L, 44L, 45L, 46L, 50L,
> 51L, 52L, 56L, 57L, 58L, 62L, 63L, 64L, 68L, 69L, 73L, 74L, 78L, 79L,
> 83L, 84L, 88L,
> 89L))
> >
>
> Regards
> Petr
>
> > sessionInfo(package = NULL)
> R Under development (unstable) (2014-07-16 r66175)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=Czech_Czech Republic.1250  LC_CTYPE=Czech_Czech
> Republic.1250 [3] LC_MONETARY=Czech_Czech Republic.1250 LC_NUMERIC=C
> [5] LC_TIME=Czech_Czech Republic.1250
>
> attached base packages:
> [1] stats     datasets  utils     grDevices graphics  methods   base
>
> other attached packages:
> [1] ggplot2_1.0.0   lattice_0.20-29 fun_1.0
>
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-4 digest_0.6.4     grid_3.2.0       gtable_0.1.2
>  [5] labeling_0.2     MASS_7.3-33      munsell_0.4.2    plyr_1.8.1
>  [9] proto_0.3-10     Rcpp_0.11.2      reshape2_1.4     scales_0.2.4
> [13] stringr_0.6.2    tools_3.2.0
> >
>
> ________________________________

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Nov 27 14:40:36 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 27 Nov 2014 13:40:36 +0000
Subject: [R] plot.hclust point to older version
In-Reply-To: <1086A524-C4B8-4664-BF68-9092810B3DF0@dcn.davis.CA.us>
References: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
	<D09A2E1A.A4BF%mmason@benaroyaresearch.org>
	<21621.38707.24672.588235@stat.math.ethz.ch>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFE3A@SRVEXCHMBX.precheza.cz>
	<1086A524-C4B8-4664-BF68-9092810B3DF0@dcn.davis.CA.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF00EF@SRVEXCHMBX.precheza.cz>

Hm

> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
> Sent: Wednesday, November 26, 2014 8:09 PM
> To: PIKAL Petr; Martin Maechler
> Cc: R help
> Subject: Re: [R] plot.hclust point to older version
>
> Short answer to your question is "R files" and original data from
> external sources.
>
> I tend to keep my projects in separate directories. I make a core R

I do the same.

> file that I can run from beginning to end using source() to generate my
> primary analysis objects. I then make another file to keep my source()
> function call in, as well as a few exploratory plot commands. Recently
> I have been also sourcing the analysis script in Rmd or Rnw files to
> "knit" my observations with the output.
>
> Some people complain that their analysis takes too long to be sourcing
> it all the time. When I have that problem I set up a variable outside
> my analysis script that I test in my analysis script. If the variable
> indicates it is time to recalculate, then I do all of that and then
> save the data in sn rds or rda file. If the variable indicates that I
> should reuse the cached data, then it skips the calculations and just
> loads the data. This way I always load the right libraries along with
> the data, and I don't accidentally save data that I changed outside the
> analysis script... keeping my results reproducible. (Rds files can be
> convenient if I have several different slow analyses to compare and I
> want to only work on one at a time. I set up one control variable for
> each analysis.)
>
> Some people (smarter than me?) like to build their analysis into an
> Sweave or knitr file. They can then strip out an analysis R file to use
> the way I have described if they choose to do so ("literate
> programming") but I have not picked up that habit yet.
>
> The key is keeping a record of how every object that is in your save
> file was originally created. If you tolerate auto saving and loading of
> the environment then you lose that record, and pernicious errors can

Not exactly. All commands are saved in .Rhistory, which from time to time I rename and keep for further use. And sometimes I also make a separate file with commands used, especially when I am at the end of my work on a project.


> creep into your environment from who knows where, and you might as well
> be using Excel if that is how you work. (Note that this means I hardly
> ever copy data straight from Excel via the clipboard as that is not
> reproducible. Usually this means Save As CSV in Excel to start my R
> analysis if that is the data source.)

As I understand you do more sophisticated version what I am doing. The key is to keep projects in separate directories and do not polute them with unrelated objects. The problem in my way is when I accidentaly destroy an object and I need to restore it, which can sometimes be tedious work. OTOH it keeps me focused on what I am doing :-)

Anyway, I shall consider save and saveRDS to keep copy of important objects outside .RData environment, if something went wrong.

Thanks for idea.

Best regards.
Petr


> -----------------------------------------------------------------------
> ----
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> -----------------------------------------------------------------------
> ----
> Sent from my phone. Please excuse my brevity.
>
> On November 26, 2014 2:05:54 AM PST, PIKAL Petr
> <petr.pikal at precheza.cz> wrote:
> >Hi
> >
> >You say
> >
> >> in other words, experienced R users do not let their workspace be
> >saved
> >> automatically (to '.RData') and hence do not load any .RData
> >> automatically at startup.
> >
> >I save/load .RData for years without any issues (except of not
> >installed packages when working on different PCs).I usually keep each
> >project in separated .RData (and separated folder, together with all
> >stuff belonging to that project), which prevent to mess things
> >together.
> >
> >There is no such warning as "do not use .RData" in books I have
> >available.
> >
> >I wonder how experienced useR keep track of several projects without
> >using startup loading .RData?
> >What would you recommend for keeping track of commands and created
> >objects instead of .RData?
> >
> >Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Nov 27 14:53:46 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 27 Nov 2014 13:53:46 +0000
Subject: [R] ggplot facet and subsetting
In-Reply-To: <7704FB6436C.00001311jrkrideau@inbox.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFED4@SRVEXCHMBX.precheza.cz>
	<7704FB6436C.00001311jrkrideau@inbox.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF0127@SRVEXCHMBX.precheza.cz>

Thanks to John, Denis, Jeff and Thierry

The key is to use aes_string instead of aes in cycle and preprocess objects to avoid creating factors on fly.

For some reason, facet_grid does not accept [,], while without facet_grid such subsetting works without problem.

I use such construction when I have big object and I want to make plot for each column for visual inspection. I usually populate pdf file with plots.

Thanks again, problem solved, curiosity remains.
Petr


> -----Original Message-----
> From: John Kane [mailto:jrkrideau at inbox.com]
> Sent: Wednesday, November 26, 2014 6:13 PM
> To: PIKAL Petr; R help
> Subject: RE: [R] ggplot facet and subsetting
>
> Below
>
> John Kane
> Kingston ON Canada
> > This is OK but only in BW
> > p<-ggplot(vec.c, aes(x=fi, y=nad1mi))
> > p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
> Perhaps:
> p <- ggplot(vec.c, aes(x=fi, y=nad1mi, colour = stroj))
> p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
>
> > and this is mismatched too
> > p<-ggplot(vec.c, aes(x=fi, y=vec.c[,2]))
> > p+geom_point(size=5)+geom_line()+facet_grid(.~stroj)
>
> I don'[ understand what you want  here so cannot suggest anything
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From lterlemez at anadolu.edu.tr  Thu Nov 27 17:36:24 2014
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Thu, 27 Nov 2014 16:36:24 +0000
Subject: [R] Cycling xerror values in cp of rpart...
Message-ID: <D09D1FA9.11D2E%lterlemez@anadolu.edu.tr>

Dear R Users,
Is it possible to get cycling xerror scores in cp of rpart while getting the same tree on every run (or am I missing something or understood wrong)? I build it with an old version of R in a Windows VM installed on a Intel based macbook and reuse the same codes with a newer version of R and required packages on an AMD pc installed with standalone windows.

Thanks in advanced,
Levent TERLEMEZ.

	[[alternative HTML version deleted]]


From rv15i at yahoo.se  Thu Nov 27 18:00:03 2014
From: rv15i at yahoo.se (ravi)
Date: Thu, 27 Nov 2014 17:00:03 +0000 (UTC)
Subject: [R] porting an access database to sqlite
In-Reply-To: <54747AF7020000CB0011B9AB@smtp.medicine.umaryland.edu>
References: <54747AF7020000CB0011B9AB@smtp.medicine.umaryland.edu>
Message-ID: <470114218.2149265.1417107603565.JavaMail.yahoo@jws11110.mail.ir2.yahoo.com>

Hi,Thanks for the replies. My problem is that the tables (at least, a few of them) are too large. I cannot directly export the tables to get text files. I tried the following :
c1<-sqlQuery(ch,"SELECT COUNT(*) FROM table1")
I got the following error (changed the text to alter table names) :[1] "AB000 -2001 [Microsoft][ODBC MicrosoftAccess Driver] ODBC--call failed."??????????????? [2] "[RODBC] ERROR: Could not SQLExecDirect'SELECT COUNT(*) FROM Table1'"

But the following works (with about 5 minutes for each step) :con<-odbcConnect("TestDB")
d1<-sqlFetch(ch,"table1",max=1e6,as.is=TRUE)
d2<-sqlFetchMore(ch,max=1e6,as.is=TRUE)

I could successively retrieve 6 million rows (with 52 columns). After that (with the next sqlFetchMore command), I got the following error : 
Error : cannot allocate vector of size 7.6 Mb
When this happened, I had saved all the data frames obtained with the saveRDS (found this to be the easiest method of limiting the size of the file on disk)? command and then deleted the data frames from memory. So, I do not know why the last error turned up.
Though I am not an expert in databases, I am quite sure that the database has not been put together in a sensible way. I am now trying to work with my amateurish methods and trying to see what I can. 

I would like to know if there is any sql query by which I can continue in retrieving data from 6e6 row onwards. That is, instead of starting from row 1, can I fetch rows from row number, 6e6+1?How do I know that I am near the tail end? There seems to be no simple method for finding the size of the table.
Thanks,Ravi
>>> ravi <rv15i at yahoo.se> 11/25/14 12:42 PM >>>


Hi,All my data is presently locked in a Microsoft access database. This has huge data in a number of large tables. Using RODBC and connecting to it takes too long a time, sometimes making the system to hang up. 

To make things more manageable, I have tried to transfer the data to manageable .RData or .csv files. But I am not able to do this with some of the larger files. I am currently stuck in the one of the preliminary steps. I am not able to find the number of rows in a table. If I know this, I can transfer chunks of the tables to a sqlite database.
I am able to connect to connect to the access data base with :
library(RODBC)
con<-odbcConnect("TestDB")d1<-sqlFetch(ch,"table1",max=1e5,as.is=TRUE)d2<-sqlFetchMore(ch,max=1e5,as.is=TRUE)
d3<-rbind(d1,d2)I wanted to develop this into a loop to get a concatenated data frame, which I wanted to save either as a binary file, or transfer it to a sqlite data base. I would like to have some help on the simplest route to follow. But first, I will proceed in describing my immediate problem. In some of the tables, I find that the sqlFetchMore returns a value of -1L, meaning that the end has been reached. In RODBC, I find no command for getting the row count in a table. I have found this in DBI. But I have not been able to figure out how I should specify the connection to an acccess database (con in the following).

while(!dbHasCompleted(con)){ print(dbGetRowCount(con))}
I would appreciate help on the following points :1. How can I get the row count (and size) of a table in an access data base? With RODBC, DBI or any other way.2. I have found that saving the tables as .RData files reduces the file size and and reduces the reading time. Is there some way of appending to an already saved data frame with this method?3. I have come across alternative ways of saving data - using writeBin and packages like saves, rhdf5 etc. Would they be useful alternatives?
4. Is there an advantage in combining binary files and databases like sqlite? Or, are files already saved in a binary format in databases like sqlite?5. What is the simplest method of porting from the access to the sqlite database? With RSQlite and RODBC, can I have connections to the access and sqlite databases open at the same time? Or, should I close one and then open the other? It would help if I can get a detailed bit if code for doing this in a simple way.

I would appreciate all help that I can get.Thanks,Ravi





????[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  Confidentiality Statement:   This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.  

  
	[[alternative HTML version deleted]]


From jl.iccp at gmail.com  Thu Nov 27 14:57:23 2014
From: jl.iccp at gmail.com (Jue Lin-Ye)
Date: Thu, 27 Nov 2014 14:57:23 +0100
Subject: [R] Generate random numbers under constrain
Message-ID: <CAAMkPW-+vVZza=bGDkTrrweGhTpuf1Grv4G-cFY=nXEq1NkOmQ@mail.gmail.com>

Hello! I am relatively new using R, but this is my contribution to the
answer. How about using a Monte-Carlo method. Generate m numbers in the
support [0,1], where m>n. Then constrain by constructing a loop that takes
every one of the elements in the m sized vector and select the ones that
sum up to one. If it is very uncommon to sum up to one, given the
distribution that you use to generate the random numbers, you can construct
a loop that generates as many random numbers as you need and then follow
the steps
1.generate
2.select

until you find a total of n number.

> Dear all,
> I use R 3.1.1 for Windows.
> kindly how can I generate n number of random numbers with probability
from [0,1]
> and their sum must not be more than one
> thanks in advance
> Ragia

?Best regards,?

-- 
Jue Lin-Ye

---------------------------------------------------------------
Civil Engineering phD candidate
Maritime Engineering Laboratory (LIM)
Universitat Polit?cnica de Catalunya (UPC)
C/Jordi Girona 1-3, Barcelona 08034 (Spain)
-----------------------------------------------------------------

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Nov 27 18:30:12 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 27 Nov 2014 18:30:12 +0100
Subject: [R] plot.hclust point to older version
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF00EF@SRVEXCHMBX.precheza.cz>
References: <CAF8bMcZrv=Ak9uLLV+=Ebu9qRQoWS9VcWKN7Yek1zg+Q0Qja1Q@mail.gmail.com>
	<D09A2E1A.A4BF%mmason@benaroyaresearch.org>
	<21621.38707.24672.588235@stat.math.ethz.ch>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEFE3A@SRVEXCHMBX.precheza.cz>
	<1086A524-C4B8-4664-BF68-9092810B3DF0@dcn.davis.CA.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF00EF@SRVEXCHMBX.precheza.cz>
Message-ID: <21623.24484.717487.301487@stat.math.ethz.ch>

>>>>> "PP" == PIKAL Petr <petr.pikal at precheza.cz>
>>>>>     on Thu, 27 Nov 2014 13:40:36 +0000 writes:

    PP> Hm
    >> -----Original Message-----
    >> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
    >> Sent: Wednesday, November 26, 2014 8:09 PM
    >> To: PIKAL Petr; Martin Maechler
    >> Cc: R help
    >> Subject: Re: [R] plot.hclust point to older version
    >> 
    >> Short answer to your question is "R files" and original data from
    >> external sources.
    >> 
    >> I tend to keep my projects in separate directories. I make a core R

    PP> I do the same.

    >> file that I can run from beginning to end using source() to generate my
    >> primary analysis objects. I then make another file to keep my source()
    >> function call in, as well as a few exploratory plot commands. Recently
    >> I have been also sourcing the analysis script in Rmd or Rnw files to
    >> "knit" my observations with the output.
    >> 
    >> Some people complain that their analysis takes too long to be sourcing
    >> it all the time. When I have that problem I set up a variable outside
    >> my analysis script that I test in my analysis script. If the variable
    >> indicates it is time to recalculate, then I do all of that and then
    >> save the data in sn rds or rda file. If the variable indicates that I
    >> should reuse the cached data, then it skips the calculations and just
    >> loads the data. This way I always load the right libraries along with
    >> the data, and I don't accidentally save data that I changed outside the
    >> analysis script... keeping my results reproducible. (Rds files can be
    >> convenient if I have several different slow analyses to compare and I
    >> want to only work on one at a time. I set up one control variable for
    >> each analysis.)

    >> Some people (smarter than me?) like to build their analysis into an
    >> Sweave or knitr file. They can then strip out an analysis R file to use
    >> the way I have described if they choose to do so ("literate
    >> programming") but I have not picked up that habit yet.

I do that occasionally, but in much less than in 50% of my R "hacking"

    >> The key is keeping a record of how every object that is in your save
    >> file was originally created. If you tolerate auto saving and loading of
    >> the environment then you lose that record, and pernicious errors can

    PP> Not exactly. All commands are saved in .Rhistory, which from time to time I rename and keep for further use. And sometimes I also make a separate file with commands used, especially when I am at the end of my work on a project.

Huaah.... Of course "real useRs don't use .Rhistory either !"
As Jeff says:  Use  <name>.R  files - often more than one per
project.

And I did not say one should not use save() and load() or the
*.rds equivalent which is preferable but I still did not get
into the full habit of using... one reason is the mismatch of
saveRDS() and readRDS()  {where as  write <-> read; or save <->
load are the natural word pairs for me}.

So, yes, Jeff indeed is one of the "real useRs .." in my sense ;-)

    >> creep into your environment from who knows where, and you might as well
    >> be using Excel if that is how you work. (Note that this means I hardly
    >> ever copy data straight from Excel via the clipboard as that is not
    >> reproducible. Usually this means Save As CSV in Excel to start my R
    >> analysis if that is the data source.)

    PP> As I understand you do more sophisticated version what I am doing. The key is to keep projects in separate directories and do not polute them with unrelated objects. The problem in my way is when I accidentaly destroy an object and I need to restore it, which can sometimes be tedious work. OTOH it keeps me focused on what I am doing :-)

    PP> Anyway, I shall consider save and saveRDS to keep copy of important objects outside .RData environment, if something went wrong.

    PP> Thanks for idea.

Once you become careful about that and organizing your *.R files
which keep the project  "100% reproducible"  you may start to
see that using .RData is just a hindrance for the discipline of
reproducible { research / data analysis / computational experiments }
using R...

Yes, I'm not sounding very nice, above... Sorry, please apologize.
Martin


    PP> Best regards.
    PP> Petr


    >> -----------------------------------------------------------------------
    >> ----
    >> Jeff Newmiller                        The     .....       .....  Go
    >> Live...
    >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
    >> Go...
    >> Live:   OO#.. Dead: OO#..
    >> Playing
    >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
    >> /Software/Embedded Controllers)               .OO#.       .OO#.
    >> rocks...1k
    >> -----------------------------------------------------------------------
    >> ----
    >> Sent from my phone. Please excuse my brevity.
    >> 
    >> On November 26, 2014 2:05:54 AM PST, PIKAL Petr
    >> <petr.pikal at precheza.cz> wrote:
    >> >Hi
    >> >
    >> >You say
    >> >
    >> >> in other words, experienced R users do not let their workspace be
    >> >saved
    >> >> automatically (to '.RData') and hence do not load any .RData
    >> >> automatically at startup.
    >> >
    >> >I save/load .RData for years without any issues (except of not
    >> >installed packages when working on different PCs).I usually keep each
    >> >project in separated .RData (and separated folder, together with all
    >> >stuff belonging to that project), which prevent to mess things
    >> >together.
    >> >
    >> >There is no such warning as "do not use .RData" in books I have
    >> >available.
    >> >
    >> >I wonder how experienced useR keep track of several projects without
    >> >using startup loading .RData?
    >> >What would you recommend for keeping track of commands and created
    >> >objects instead of .RData?
    >> >
    >> >Petr


    PP> ________________________________
    PP> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
    PP> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
    PP> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
    PP> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

    PP> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
    PP> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
    PP> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
    PP> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
    PP> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

    PP> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
    PP> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
    PP> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
    PP> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

    PP> In case that this e-mail forms part of business dealings:
    PP> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
    PP> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
    PP> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
    PP> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
    PP> ______________________________________________
    PP> R-help at r-project.org mailing list
    PP> https://stat.ethz.ch/mailman/listinfo/r-help
    PP> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    PP> and provide commented, minimal, self-contained, reproducible code.


From erich.neuwirth at univie.ac.at  Thu Nov 27 19:20:41 2014
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 27 Nov 2014 19:20:41 +0100
Subject: [R] Generate random numbers under constrain
In-Reply-To: <CAAMkPW-+vVZza=bGDkTrrweGhTpuf1Grv4G-cFY=nXEq1NkOmQ@mail.gmail.com>
References: <CAAMkPW-+vVZza=bGDkTrrweGhTpuf1Grv4G-cFY=nXEq1NkOmQ@mail.gmail.com>
Message-ID: <1C74A722-269A-401B-B28D-E45AAA0039F3@univie.ac.at>

You want random numbers within the n-dimensional simplex (sum xi <=1)
The easiest solution of course would be creating n-dimensions vectors
with iid uniform components on [0,1) and throwing away those
violating the inequality.
Since the volume of the n-dimensional simplex is 1/n! (factorial)
this becomes very wasteful even for low dimensions.

A possible  answer is to use the Dirichlet distribution from package lca)
since the uniform distribution on the simplex is a special case
of the Dirichlet distribution.


> On Nov 27, 2014, at 14:57, Jue Lin-Ye <jl.iccp at gmail.com> wrote:
> 
> Hello! I am relatively new using R, but this is my contribution to the
> answer. How about using a Monte-Carlo method. Generate m numbers in the
> support [0,1], where m>n. Then constrain by constructing a loop that takes
> every one of the elements in the m sized vector and select the ones that
> sum up to one. If it is very uncommon to sum up to one, given the
> distribution that you use to generate the random numbers, you can construct
> a loop that generates as many random numbers as you need and then follow
> the steps
> 1.generate
> 2.select
> 
> until you find a total of n number.
> 
>> Dear all,
>> I use R 3.1.1 for Windows.
>> kindly how can I generate n number of random numbers with probability
> from [0,1]
>> and their sum must not be more than one
>> thanks in advance
>> Ragia
> 
> ?Best regards,?
> 
> -- 
> Jue Lin-Ye
> 
> ---------------------------------------------------------------
> Civil Engineering phD candidate
> Maritime Engineering Laboratory (LIM)
> Universitat Polit?cnica de Catalunya (UPC)
> C/Jordi Girona 1-3, Barcelona 08034 (Spain)
> -----------------------------------------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paul at stat.auckland.ac.nz  Thu Nov 27 21:36:57 2014
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 28 Nov 2014 09:36:57 +1300
Subject: [R] Using grid.layout inside grid.layout with grid package:
 naming of the viewports affects plotting
In-Reply-To: <F56518F8CBDA4144A1AF39EC7DF4858F48A5831A@mbs2.ad.jyu.fi>
References: <F56518F8CBDA4144A1AF39EC7DF4858F48A5831A@mbs2.ad.jyu.fi>
Message-ID: <54778B69.4000008@stat.auckland.ac.nz>

Hi

The essence of your problem is that seekViewport() is much more 
ambiguous than downViewport().

Your set up involves creating a hierarchy of viewports four deep, with 
eight viewport paths (vpPaths) in total ...

vp1::A::vp2::plot1
            ::plot2
    ::B::vp3::plot1
            ::plot2
    ::C::vp4::plot1
            ::plot2
    ::D::vp5::plot1
            ::plot2

... and an important feature of that set of vpPaths is that the viewport 
name "plot1" (and "plot2") occurs more than once.

That is not necessarily a problem because you can distinguish between 
the different instances of "plot1" with complete paths, like this ...

downViewport("vp1::B::vp3::plot1")

... or by navigating part way down the tree of viewports first to a 
point where there is only one "plot1" viewport below it ...

downViewport("B")
downViewport("plot1")

However, seekViewport("plot1") does NOT do either of those things.  It 
does ...

upViewport(0) # go right up to the ROOT viewport
downViewport("plot1")

... and that will just find the first "plot1" match, which is the one 
below viewport "A".

The seekViewport() function should not therefore be relied on in 
non-interactive settings.  In fact, if you are writing code for general 
use, you should probably be much more disciplined about how you navigate 
between your viewports and make use of upViewport() and unambiguous 
downViewport() calls so that you know which viewport you will end up in. 
  The code below demonstrates a more disciplined version of your 
viewport set up ...

library(grid)
stackedplot <- function(main=""){
   top.vp <- viewport(
     layout=grid.layout(2, 1))
   p1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="plot1")
   p2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="plot2")
   splot <- vpTree(top.vp, vpList(p1,p2))
   pushViewport(splot)
   upViewport()
   downViewport("plot1")
   grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
   grid.text(paste(main, 1))
   upViewport()
   downViewport("plot2")
   grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
   grid.text(paste(main, 1))
   upViewport(2)
  }

grid.newpage()
multitop.vp <- viewport(layout=grid.layout(2,2))
pl1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="A")
pl2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="B")
pl3 <- viewport(layout.pos.col=2, layout.pos.row=1, name="C")
pl4 <- viewport(layout.pos.col=2, layout.pos.row=2, name="D")
vpall <- vpTree(multitop.vp, vpList(pl1,pl2,pl3,pl4))
pushViewport(vpall)
upViewport()
downViewport("A")
stackedplot(main="A")
upViewport()
downViewport("B")
stackedplot(main="B")
upViewport()
downViewport("C")
stackedplot(main="C")
upViewport()
downViewport("D")
stackedplot(main="D")
upViewport(2)

Hope that helps

Paul

On 11/27/14 00:16, Helske Satu wrote:
> R version 3.1.1 (2014-07-10)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.1
>
>
> I have a plotting function to produce plots with stacked plots (for simplicity, here two rectangles).
>
> library(grid)
> stackedplot <- function(main=""){
>    top.vp <- viewport(
>      layout=grid.layout(2, 1))
>    p1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="plot1")
>    p2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="plot2")
>    splot <- vpTree(top.vp, vpList(p1,p2))
>    pushViewport(splot)
>    seekViewport("plot1")
>    grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
>    seekViewport("plot2")
>    grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
>   }
>
> For creating a 2x2 grid with four stacked plots I tried to use the following code:
>
> grid.newpage()
> multitop.vp <- viewport(layout=grid.layout(2,2))
> pl1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="A")
> pl2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="B")
> pl3 <- viewport(layout.pos.col=2, layout.pos.row=1, name="C")
> pl4 <- viewport(layout.pos.col=2, layout.pos.row=2, name="D")
> vpall <- vpTree(multitop.vp, vpList(pl1,pl2,pl3,pl4))
> pushViewport(vpall)
> seekViewport("A")
> stackedplot(main="A")
> seekViewport("B")
> stackedplot(main="B")
> seekViewport("C")
> stackedplot(main="C")
> seekViewport("D")
> stackedplot(main="D")
>
> This does not work as all the plots are plotted in the same cell of the grid (viewport A). However, if I plot them in a reversed order, the plots arrange as was supposed to: D to D, C to C and so on.
>
> seekViewport("D")
> stackedplot(main="D")
> seekViewport("C")
> stackedplot(main="C")
> seekViewport("B")
> stackedplot(main="B")
> seekViewport("A")
> stackedplot(main="A")
>
> I tried with different names and found out that if I plot in reversed alphabetical order everything works fine. Once I try to plot in a viewport with a name earlier in alphabetical order, all other plots thereafter are plotted in the same viewport.
>
> Why is this happening?
>
> Regards,
> Satu Helske
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From mikeumo at gmail.com  Thu Nov 27 22:14:33 2014
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Thu, 27 Nov 2014 15:14:33 -0600
Subject: [R] Generate random numbers under constrain
In-Reply-To: <1C74A722-269A-401B-B28D-E45AAA0039F3@univie.ac.at>
References: <CAAMkPW-+vVZza=bGDkTrrweGhTpuf1Grv4G-cFY=nXEq1NkOmQ@mail.gmail.com>
	<1C74A722-269A-401B-B28D-E45AAA0039F3@univie.ac.at>
Message-ID: <5012C578-7C8E-46AE-B774-9AF3413F14AB@gmail.com>

How about generating the uniform numbers sequentially and keep the running sum of all the previous numbers. At each step check if the newly generated random number plus the running sum > 1 discard the number and generate a new one, repeat the condition check. If the new number plus old sum < 1 accept the number and repeat the step. Until you got n numbers. 

Mikhail



> On Nov 27, 2014, at 12:20, Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
> 
> You want random numbers within the n-dimensional simplex (sum xi <=1)
> The easiest solution of course would be creating n-dimensions vectors
> with iid uniform components on [0,1) and throwing away those
> violating the inequality.
> Since the volume of the n-dimensional simplex is 1/n! (factorial)
> this becomes very wasteful even for low dimensions.
> 
> A possible  answer is to use the Dirichlet distribution from package lca)
> since the uniform distribution on the simplex is a special case
> of the Dirichlet distribution.
> 
> 
>> On Nov 27, 2014, at 14:57, Jue Lin-Ye <jl.iccp at gmail.com> wrote:
>> 
>> Hello! I am relatively new using R, but this is my contribution to the
>> answer. How about using a Monte-Carlo method. Generate m numbers in the
>> support [0,1], where m>n. Then constrain by constructing a loop that takes
>> every one of the elements in the m sized vector and select the ones that
>> sum up to one. If it is very uncommon to sum up to one, given the
>> distribution that you use to generate the random numbers, you can construct
>> a loop that generates as many random numbers as you need and then follow
>> the steps
>> 1.generate
>> 2.select
>> 
>> until you find a total of n number.
>> 
>>> Dear all,
>>> I use R 3.1.1 for Windows.
>>> kindly how can I generate n number of random numbers with probability
>> from [0,1]
>>> and their sum must not be more than one
>>> thanks in advance
>>> Ragia
>> 
>> ?Best regards,?
>> 
>> -- 
>> Jue Lin-Ye
>> 
>> ---------------------------------------------------------------
>> Civil Engineering phD candidate
>> Maritime Engineering Laboratory (LIM)
>> Universitat Polit?cnica de Catalunya (UPC)
>> C/Jordi Girona 1-3, Barcelona 08034 (Spain)
>> -----------------------------------------------------------------
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From poonamr at iimahd.ernet.in  Thu Nov 27 23:26:29 2014
From: poonamr at iimahd.ernet.in (Poonam Rathi)
Date: Fri, 28 Nov 2014 03:56:29 +0530
Subject: [R] How to handle NA in fda (functional data analysis) package?
Message-ID: <CA+jRNZ6NC3AJX04PWzu6RmWvJyYzBzHLzbd1o0CXiVEdA34__g@mail.gmail.com>

My Question is:

How to handle NA in fda (functional data analysis) package?

Poonam Rathi
Doctoral Student - Production and Quantitative Methods
Indian Institute of Management - Ahmedabad
Dorm 6,Room 15 | +917966326615  | +919974183701

	[[alternative HTML version deleted]]


From brc.khi at gmail.com  Thu Nov 27 20:54:09 2014
From: brc.khi at gmail.com (BRC)
Date: Fri, 28 Nov 2014 00:54:09 +0500
Subject: [R] Data mtcars
Message-ID: <CAF54RnobtMRHX4oqtQG25C+w+eQKnRB5fRC7Y8mPnr8Y3b5PbA@mail.gmail.com>

I remembered that I had seen instruction to store mtcars build data in r,
but right now I missed it, Please advise how I can see it or what will be
procedure to define data frame with row and column names.  I need to
develop dendrogram of my own dataset contains 15 variables and more than
100 observation. I am check the example and have to convert as per that.

Regards
Faisal

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Fri Nov 28 00:06:20 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 27 Nov 2014 18:06:20 -0500
Subject: [R] Data mtcars
In-Reply-To: <CAF54RnobtMRHX4oqtQG25C+w+eQKnRB5fRC7Y8mPnr8Y3b5PbA@mail.gmail.com>
References: <CAF54RnobtMRHX4oqtQG25C+w+eQKnRB5fRC7Y8mPnr8Y3b5PbA@mail.gmail.com>
Message-ID: <C64BAA11-E984-4C3E-BF52-D6F4FBDF736D@utoronto.ca>

A simple Google search with "mtcars dendrogram" will find many explicit examples for you.
B.



On Nov 27, 2014, at 2:54 PM, BRC <brc.khi at gmail.com> wrote:

> I remembered that I had seen instruction to store mtcars build data in r,
> but right now I missed it, Please advise how I can see it or what will be
> procedure to define data frame with row and column names.  I need to
> develop dendrogram of my own dataset contains 15 variables and more than
> 100 observation. I am check the example and have to convert as per that.
> 
> Regards
> Faisal
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Nov 28 08:17:31 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 27 Nov 2014 23:17:31 -0800
Subject: [R] porting an access database to sqlite
In-Reply-To: <470114218.2149265.1417107603565.JavaMail.yahoo@jws11110.mail.ir2.yahoo.com>
References: <54747AF7020000CB0011B9AB@smtp.medicine.umaryland.edu>
	<470114218.2149265.1417107603565.JavaMail.yahoo@jws11110.mail.ir2.yahoo.com>
Message-ID: <13F63973-42B5-4D90-B2E2-F058C2594FA2@dcn.davis.CA.us>

This is not really on topic here. At best the R-sig-db mailing list would be on topic, but it seems you may be dealing with issues related to nonstandard sql so you might need to find some additional help in a more Access-specific forum.

One thing you might try is using a specific column name from your table instead of the "*" symbol in the COUNT function... preferably a unique primary key column.

The reason the primary key is important is because sql doesn't assume the date are ordered the way R does... it is only as ordered as the indexes that are used to retrieve it. That may also be a clue for you to use in figuring out how to divide up the data into smaller chunks.

One thing I can say is that allocating chunks of memory and then freeing them can break up your available memory into pieces and make allocating more memory impossible. Unfortunately, troubleshooting such problems is highly dependent on your hardware and software configuration as well as the exact steps you are following. Since you have not attempted to create a reproducible example yet, you might want to do that before posting at R-sig-db to improve your chances of getting help.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 27, 2014 9:00:03 AM PST, ravi <rv15i at yahoo.se> wrote:
>Hi,Thanks for the replies. My problem is that the tables (at least, a
>few of them) are too large. I cannot directly export the tables to get
>text files. I tried the following :
>c1<-sqlQuery(ch,"SELECT COUNT(*) FROM table1")
>I got the following error (changed the text to alter table names) :[1]
>"AB000 -2001 [Microsoft][ODBC MicrosoftAccess Driver] ODBC--call
>failed."??????????????? [2] "[RODBC] ERROR: Could not
>SQLExecDirect'SELECT COUNT(*) FROM Table1'"
>
>But the following works (with about 5 minutes for each step)
>:con<-odbcConnect("TestDB")
>d1<-sqlFetch(ch,"table1",max=1e6,as.is=TRUE)
>d2<-sqlFetchMore(ch,max=1e6,as.is=TRUE)
>
>I could successively retrieve 6 million rows (with 52 columns). After
>that (with the next sqlFetchMore command), I got the following error : 
>Error : cannot allocate vector of size 7.6 Mb
>When this happened, I had saved all the data frames obtained with the
>saveRDS (found this to be the easiest method of limiting the size of
>the file on disk)? command and then deleted the data frames from
>memory. So, I do not know why the last error turned up.
>Though I am not an expert in databases, I am quite sure that the
>database has not been put together in a sensible way. I am now trying
>to work with my amateurish methods and trying to see what I can. 
>
>I would like to know if there is any sql query by which I can continue
>in retrieving data from 6e6 row onwards. That is, instead of starting
>from row 1, can I fetch rows from row number, 6e6+1?How do I know that
>I am near the tail end? There seems to be no simple method for finding
>the size of the table.
>Thanks,Ravi
>>>> ravi <rv15i at yahoo.se> 11/25/14 12:42 PM >>>
>
>
>Hi,All my data is presently locked in a Microsoft access database. This
>has huge data in a number of large tables. Using RODBC and connecting
>to it takes too long a time, sometimes making the system to hang up. 
>
>To make things more manageable, I have tried to transfer the data to
>manageable .RData or .csv files. But I am not able to do this with some
>of the larger files. I am currently stuck in the one of the preliminary
>steps. I am not able to find the number of rows in a table. If I know
>this, I can transfer chunks of the tables to a sqlite database.
>I am able to connect to connect to the access data base with :
>library(RODBC)
>con<-odbcConnect("TestDB")d1<-sqlFetch(ch,"table1",max=1e5,as.is=TRUE)d2<-sqlFetchMore(ch,max=1e5,as.is=TRUE)
>d3<-rbind(d1,d2)I wanted to develop this into a loop to get a
>concatenated data frame, which I wanted to save either as a binary
>file, or transfer it to a sqlite data base. I would like to have some
>help on the simplest route to follow. But first, I will proceed in
>describing my immediate problem. In some of the tables, I find that the
>sqlFetchMore returns a value of -1L, meaning that the end has been
>reached. In RODBC, I find no command for getting the row count in a
>table. I have found this in DBI. But I have not been able to figure out
>how I should specify the connection to an acccess database (con in the
>following).
>
>while(!dbHasCompleted(con)){ print(dbGetRowCount(con))}
>I would appreciate help on the following points :1. How can I get the
>row count (and size) of a table in an access data base? With RODBC, DBI
>or any other way.2. I have found that saving the tables as .RData files
>reduces the file size and and reduces the reading time. Is there some
>way of appending to an already saved data frame with this method?3. I
>have come across alternative ways of saving data - using writeBin and
>packages like saves, rhdf5 etc. Would they be useful alternatives?
>4. Is there an advantage in combining binary files and databases like
>sqlite? Or, are files already saved in a binary format in databases
>like sqlite?5. What is the simplest method of porting from the access
>to the sqlite database? With RSQlite and RODBC, can I have connections
>to the access and sqlite databases open at the same time? Or, should I
>close one and then open the other? It would help if I can get a
>detailed bit if code for doing this in a simple way.
>
>I would appreciate all help that I can get.Thanks,Ravi
>
>
>
>
>
>????[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>Confidentiality Statement:   This email message, including any
>attachments, is for the sole use of the intended recipient(s) and may
>contain confidential and privileged information. Any unauthorized use,
>disclosure or distribution is prohibited. If you are not the intended
>recipient, please contact the sender by reply email and destroy all
>copies of the original message.


From satu.helske at jyu.fi  Fri Nov 28 08:22:56 2014
From: satu.helske at jyu.fi (Helske Satu)
Date: Fri, 28 Nov 2014 07:22:56 +0000
Subject: [R] Using grid.layout inside grid.layout with grid package:
 naming of the viewports affects plotting
In-Reply-To: <54778B69.4000008@stat.auckland.ac.nz>
References: <F56518F8CBDA4144A1AF39EC7DF4858F48A5831A@mbs2.ad.jyu.fi>
	<54778B69.4000008@stat.auckland.ac.nz>
Message-ID: <F56518F8CBDA4144A1AF39EC7DF4858F48A591BA@mbs2.ad.jyu.fi>

Hi Paul,

Thank you for your illustrative explanation and help with rewriting the code. It works now and, more importantly, I understand what is happening and why.

Best regards,
Satu



>-----Original Message-----
>From: Paul Murrell [mailto:paul at stat.auckland.ac.nz]
>Sent: 27. marraskuuta 2014 22:37
>To: Helske Satu; r-help at r-project.org
>Subject: Re: [R] Using grid.layout inside grid.layout with grid package: naming of
>the viewports affects plotting
>
>Hi
>
>The essence of your problem is that seekViewport() is much more ambiguous
>than downViewport().
>
>Your set up involves creating a hierarchy of viewports four deep, with eight
>viewport paths (vpPaths) in total ...
>
>vp1::A::vp2::plot1
>            ::plot2
>    ::B::vp3::plot1
>            ::plot2
>    ::C::vp4::plot1
>            ::plot2
>    ::D::vp5::plot1
>            ::plot2
>
>... and an important feature of that set of vpPaths is that the viewport name
>"plot1" (and "plot2") occurs more than once.
>
>That is not necessarily a problem because you can distinguish between the
>different instances of "plot1" with complete paths, like this ...
>
>downViewport("vp1::B::vp3::plot1")
>
>... or by navigating part way down the tree of viewports first to a point where
>there is only one "plot1" viewport below it ...
>
>downViewport("B")
>downViewport("plot1")
>
>However, seekViewport("plot1") does NOT do either of those things.  It does ...
>
>upViewport(0) # go right up to the ROOT viewport
>downViewport("plot1")
>
>... and that will just find the first "plot1" match, which is the one below viewport
>"A".
>
>The seekViewport() function should not therefore be relied on in non-interactive
>settings.  In fact, if you are writing code for general use, you should probably be
>much more disciplined about how you navigate between your viewports and
>make use of upViewport() and unambiguous
>downViewport() calls so that you know which viewport you will end up in.
>  The code below demonstrates a more disciplined version of your viewport set
>up ...
>
>library(grid)
>stackedplot <- function(main=""){
>   top.vp <- viewport(
>     layout=grid.layout(2, 1))
>   p1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="plot1")
>   p2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="plot2")
>   splot <- vpTree(top.vp, vpList(p1,p2))
>   pushViewport(splot)
>   upViewport()
>   downViewport("plot1")
>   grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
>   grid.text(paste(main, 1))
>   upViewport()
>   downViewport("plot2")
>   grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
>   grid.text(paste(main, 1))
>   upViewport(2)
>  }
>
>grid.newpage()
>multitop.vp <- viewport(layout=grid.layout(2,2))
>pl1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="A")
>pl2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="B")
>pl3 <- viewport(layout.pos.col=2, layout.pos.row=1, name="C")
>pl4 <- viewport(layout.pos.col=2, layout.pos.row=2, name="D") vpall <-
>vpTree(multitop.vp, vpList(pl1,pl2,pl3,pl4))
>pushViewport(vpall)
>upViewport()
>downViewport("A")
>stackedplot(main="A")
>upViewport()
>downViewport("B")
>stackedplot(main="B")
>upViewport()
>downViewport("C")
>stackedplot(main="C")
>upViewport()
>downViewport("D")
>stackedplot(main="D")
>upViewport(2)
>
>Hope that helps
>
>Paul
>
>On 11/27/14 00:16, Helske Satu wrote:
>> R version 3.1.1 (2014-07-10)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] C
>>
>> attached base packages:
>> [1] grid      stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.1.1
>>
>>
>> I have a plotting function to produce plots with stacked plots (for simplicity,
>here two rectangles).
>>
>> library(grid)
>> stackedplot <- function(main=""){
>>    top.vp <- viewport(
>>      layout=grid.layout(2, 1))
>>    p1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="plot1")
>>    p2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="plot2")
>>    splot <- vpTree(top.vp, vpList(p1,p2))
>>    pushViewport(splot)
>>    seekViewport("plot1")
>>    grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
>>    seekViewport("plot2")
>>    grid.rect(width=unit(0.9, "npc"), height=unit(0.9, "npc"))
>>   }
>>
>> For creating a 2x2 grid with four stacked plots I tried to use the following code:
>>
>> grid.newpage()
>> multitop.vp <- viewport(layout=grid.layout(2,2))
>> pl1 <- viewport(layout.pos.col=1, layout.pos.row=1, name="A")
>> pl2 <- viewport(layout.pos.col=1, layout.pos.row=2, name="B")
>> pl3 <- viewport(layout.pos.col=2, layout.pos.row=1, name="C")
>> pl4 <- viewport(layout.pos.col=2, layout.pos.row=2, name="D") vpall <-
>> vpTree(multitop.vp, vpList(pl1,pl2,pl3,pl4))
>> pushViewport(vpall)
>> seekViewport("A")
>> stackedplot(main="A")
>> seekViewport("B")
>> stackedplot(main="B")
>> seekViewport("C")
>> stackedplot(main="C")
>> seekViewport("D")
>> stackedplot(main="D")
>>
>> This does not work as all the plots are plotted in the same cell of the grid
>(viewport A). However, if I plot them in a reversed order, the plots arrange as
>was supposed to: D to D, C to C and so on.
>>
>> seekViewport("D")
>> stackedplot(main="D")
>> seekViewport("C")
>> stackedplot(main="C")
>> seekViewport("B")
>> stackedplot(main="B")
>> seekViewport("A")
>> stackedplot(main="A")
>>
>> I tried with different names and found out that if I plot in reversed alphabetical
>order everything works fine. Once I try to plot in a viewport with a name earlier
>in alphabetical order, all other plots thereafter are plotted in the same viewport.
>>
>> Why is this happening?
>>
>> Regards,
>> Satu Helske
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>--
>Dr Paul Murrell
>Department of Statistics
>The University of Auckland
>Private Bag 92019
>Auckland
>New Zealand
>64 9 3737599 x85392
>paul at stat.auckland.ac.nz
>http://www.stat.auckland.ac.nz/~paul/


From nmo_138 at usc.edu  Fri Nov 28 09:35:11 2014
From: nmo_138 at usc.edu (Noha Osman)
Date: Fri, 28 Nov 2014 08:35:11 +0000
Subject: [R] perl
Message-ID: <1417163711035.64980@usc.edu>

Hi Folks


Iam a new user in perl and I have two questions .Hopefully I get any help


my data like that


Chr1    TAIR10  chromosome      1       30427671        .       .       .       ID=Chr1;Name=Chr1
Chr1    TAIR10  gene    3631    5899    .       +       .       ID=AT1G01010;Note=protein_coding_gene;Name=AT1G01010
Chr1    TAIR10  mRNA    3631    5899    .       +       .       ID=AT1G01010.1;Parent=AT1G01010;Name=AT1G01010.1;Index=1
Chr1    TAIR10  protein 3760    5630    .       +       .       ID=AT1G01010.1-Protein;Name=AT1G01010.1;Derives_from=AT1G01010.1
Chr1    TAIR10  exon    3631    3913    .       +       .       Parent=AT1G01010.1
Chr1    TAIR10  five_prime_UTR  3631    3759    .       +       .       Parent=AT1G01010.1
Chr1    TAIR10  CDS     3760    3913    .       +       0       Parent=AT1G01010.1,AT1G01010.1-Protein;
Chr1    TAIR10  exon    3996    4276    .       +       .       Parent=AT1G01010.1
Chr1    TAIR10  CDS     3996    4276    .       +       2       Parent=AT1G01010.1,AT1G01010.1-Protein;
Chr1    TAIR10  exon    4486    4605    .       +       .       Parent=AT1G01010.1
Chr1    TAIR10  CDS     4486    4605    .       +       0       Parent=AT1G01010.1,AT1G01010.1-Protein;
Chr1    TAIR10  exon    4706    5095    .       +       .       Parent=AT1G01010.1
Chr1    TAIR10  CDS     4706    5095    .       +       0       Parent=AT1G01010.1,AT1G01010.1-Protein;
Chr1    TAIR10  exon    5174    5326    .       +       .       Parent=AT1G01010.1
Chr1    TAIR10  CDS     5174    5326    .       +       0       Parent=AT1G01010.1,AT1G01010.1-Protein;

I need to use Hash  to answer these questions

1: output a file that has Gene name in column 1 and the number of exons it contains in column 2

2: output a file that list all the transcripts/mRNA in column 2 and the gene it is found in column 1



	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Nov 28 13:33:06 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 28 Nov 2014 07:33:06 -0500
Subject: [R] perl
In-Reply-To: <1417163711035.64980@usc.edu>
References: <1417163711035.64980@usc.edu>
Message-ID: <CAM_vjun0ipUWDhN32_-y5Yf5Pa5=XnCh=GUU98i=ugQ=_ZL4mw@mail.gmail.com>

On Friday, November 28, 2014, Noha Osman <nmo_138 at usc.edu> wrote:

> Hi Folks
>
>
> Iam a new user in perl and I have two questions .Hopefully I get any help


Seems unlikely that  you'll get perl help on the R help list. Best try
again in a more appropriate forum.


>
>
> my data like that
>
>
> Chr1    TAIR10  chromosome      1       30427671        .       .       .
>      ID=Chr1;Name=Chr1
> Chr1    TAIR10  gene    3631    5899    .       +       .
>  ID=AT1G01010;Note=protein_coding_gene;Name=AT1G01010
> Chr1    TAIR10  mRNA    3631    5899    .       +       .
>  ID=AT1G01010.1;Parent=AT1G01010;Name=AT1G01010.1;Index=1
> Chr1    TAIR10  protein 3760    5630    .       +       .
>  ID=AT1G01010.1-Protein;Name=AT1G01010.1;Derives_from=AT1G01010.1
> Chr1    TAIR10  exon    3631    3913    .       +       .
>  Parent=AT1G01010.1
> Chr1    TAIR10  five_prime_UTR  3631    3759    .       +       .
>  Parent=AT1G01010.1
> Chr1    TAIR10  CDS     3760    3913    .       +       0
>  Parent=AT1G01010.1,AT1G01010.1-Protein;
> Chr1    TAIR10  exon    3996    4276    .       +       .
>  Parent=AT1G01010.1
> Chr1    TAIR10  CDS     3996    4276    .       +       2
>  Parent=AT1G01010.1,AT1G01010.1-Protein;
> Chr1    TAIR10  exon    4486    4605    .       +       .
>  Parent=AT1G01010.1
> Chr1    TAIR10  CDS     4486    4605    .       +       0
>  Parent=AT1G01010.1,AT1G01010.1-Protein;
> Chr1    TAIR10  exon    4706    5095    .       +       .
>  Parent=AT1G01010.1
> Chr1    TAIR10  CDS     4706    5095    .       +       0
>  Parent=AT1G01010.1,AT1G01010.1-Protein;
> Chr1    TAIR10  exon    5174    5326    .       +       .
>  Parent=AT1G01010.1
> Chr1    TAIR10  CDS     5174    5326    .       +       0
>  Parent=AT1G01010.1,AT1G01010.1-Protein;
>
> I need to use Hash  to answer these questions
>
> 1: output a file that has Gene name in column 1 and the number of exons it
> contains in column 2
>
> 2: output a file that list all the transcripts/mRNA in column 2 and the
> gene it is found in column 1
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From dan.vatnik at gmail.com  Fri Nov 28 15:16:22 2014
From: dan.vatnik at gmail.com (Dan Vatnik)
Date: Fri, 28 Nov 2014 09:16:22 -0500
Subject: [R] package submission
Message-ID: <CAPwpSvhef4gp6k=YDHqT+61qVJ7aHZ2_Cm9V286Ptf9mmznmeQ@mail.gmail.com>

Hi,

I am the maintainer of the "traj" package.
I have added a vignette to the package this week(Wednesday) and uploaded
the new tarball to CRAN.
I have not yet received a confirmation e-mail.I do not know if the e-mail
is sent automatically or if a person needs to approve manually. I am just
wondering if I did everything correctly
or if there is a mistake in my uploading procedure.

Thank you for your time,

Dan

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Nov 28 15:35:12 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Nov 2014 09:35:12 -0500
Subject: [R] package submission
In-Reply-To: <CAPwpSvhef4gp6k=YDHqT+61qVJ7aHZ2_Cm9V286Ptf9mmznmeQ@mail.gmail.com>
References: <CAPwpSvhef4gp6k=YDHqT+61qVJ7aHZ2_Cm9V286Ptf9mmznmeQ@mail.gmail.com>
Message-ID: <54788820.10502@gmail.com>

On 28/11/2014 9:16 AM, Dan Vatnik wrote:
> Hi,
>
> I am the maintainer of the "traj" package.
> I have added a vignette to the package this week(Wednesday) and uploaded
> the new tarball to CRAN.
> I have not yet received a confirmation e-mail.I do not know if the e-mail
> is sent automatically or if a person needs to approve manually. I am just
> wondering if I did everything correctly
> or if there is a mistake in my uploading procedure.

The CRAN people make the decisions manually, so it may just be that 
nobody has got to it yet.    If you don't hear from them in a week, you 
might consider writing to the submission email address, but I wouldn't 
do it sooner than that.

Duncan Murdoch


From jrkrideau at inbox.com  Fri Nov 28 16:24:13 2014
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 28 Nov 2014 07:24:13 -0800
Subject: [R] DOT PLOT help!!
In-Reply-To: <c0a585d2e754ef0cb8f3702fbcbdc1ec.squirrel@zoology.up.ac.za>
Message-ID: <8F3719EE2E0.00000315jrkrideau@inbox.com>

No sign of the attached plot. The R-help list is very picky about what files it will accept. IIRC, you usually are able to attach ASCII files with a txt suffix and to attach pdf files so probably you tried to send something like a png or jpeg and the R-help server stripped it away as a possible source of malware.

When asking a question on the list it is usually very helpful to send sample data and any (minimal) code that is applicable to the problem.

The easiest way to supply data is to use the dput() function. Example with your file named"testfile": dput(testfile) Then copy the output and paste into your email. For large data sets, you can just supply a representative sample. Usually, dput(head(testfile, 100)) will be sufficient. 

This is particularly important as R has many types of data formats, some of which look the same when printed on the screen, (see example, below) and by supplying the data in dput() format you ensure that R-help readers can load 'exactly' the same data as you are working with. 

#====================copy and run in R=================#
dat1  <- data.frame(aa = as.factor(1:5), bb = 1:5)   
dat1 # data looks identical on the screen      
5*dat1[,"aa"]  # oops   
5*dat1[, "bb"] # okay     
str(dat1)   
#===================================================#

Have a look at https://github.com/hadley/devtools/wiki/Reproducibility and  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example for some good suggestions on how to frame questions to the list.

BTW, did Don McQueen's response help?

Welcome to R .

John Kane Kingston ON Canada 

> -----Original Message-----
> From: jscheun at zoology.up.ac.za
> Sent: Mon, 24 Nov 2014 11:08:39 +0200
> To: r-help at r-project.org
> Subject: [R] DOT PLOT help!!
> 
> Morning everyone
> 
> 
> I am relatively new to R and although there are tons of "how to"
> websites,
> some are just way over my head. I am currently trying to figure out how
> to
> create dot plot graphs with my data, where I have categories (i.e male
> /female) and values for each. I would like to display this as categories
> on the x axis and all values for each directly above the applicable
> category, thus not a scatter graph but in a line above for each.
> 
> I have attached a quick picture I found on the internet to demonstrate
> roughly what I would like.
> 
> Thank you all for your time
> Juan Scheun
> Department of Zoology and Entomology
> University of Pretoria
> Lynnwood Road
> Hillcrest
> Pretoria
> South Africa
> 0002
> 
> Cell: +27 76 860 3315
> Email: jscheun at zoology.up.ac.za
> 
> 
> 
> 
> ---------------------------------------------------------------------
> This message and attachments are subject to a disclaimer. Please refer to
> http://www.it.up.ac.za/documentation/governance/disclaimer/ for full
> details. / Hierdie boodskap en aanhangsels is aan 'n vrywaringsklousule
> onderhewig. Volledige besonderhede is by
> http://www.it.up.ac.za/documentation/governance/disclaimer/ beskikbaar.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Fri Nov 28 16:26:57 2014
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 28 Nov 2014 07:26:57 -0800
Subject: [R] How to print labels and how to add missing label values?
In-Reply-To: <CAB-RVxSgjXnEsvx6njCUH74f9P3OiBUhAeJuH+Yo=qy771Dq3Q@mail.gmail.com>
References: <cab-rvxtshzxxydqv13nsgbmpuf1pdb6slosy6fzc9qxgyyoexw@mail.gmail.com>
Message-ID: <8F3D3CC5454.0000031Djrkrideau@inbox.com>

Reproducibility
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: edoardo.prestianni at gmail.com
> Sent: Mon, 24 Nov 2014 19:32:13 +0100
> To: r-help at r-project.org
> Subject: Re: [R] How to print labels and how to add missing label values?
> 
> P.S. huge typo in the e-mail object: I guess I want to print and edit
> "value labels", not "label values"
> 
> 
> 
> 2014-11-24 19:23 GMT+01:00 Edoardo Prestianni
> <edoardo.prestianni at gmail.com>
> :
> 
>> Hello everyone,
>> 
>> Sorry for the "rookie" question but this is really beyond me at the
>> moment.
>> 
>> Here is my problem
>> 
>> I have three datasets I am trying to work on. They're three panels.
>> 
>> They have this variable, 'kecnum', which is present in all the three
>> datasets, and it looks like it has been labeled in only one of the three
>> datasets.
>> 
>> When I import the datasets, R gives me a WARNING, stating
>> 
>> [code] value labels (?kecnum?) for ?kecnum? are missing [/code]
>> 
>> for two datasets out of three.
>> 
>> 
>> Looking at the tables, you see that the variable grows normally...
>> (like
>> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5...) in the datasets for which the warning
>> is
>> given.
>> For the dataset for which the warning is NOT given, I just have a list
>> of
>> "NA"
>> 
>> 
>> If I use the "describe" command, R prints out just
>> [code] kecnum : Variable label for variable kecnum [/code]
>> 
>> for all the THREE datasets.
>> 
>> 
>> Only using Rstudio I can "see" a difference in the labeling of the
>> variable between the datasets for which I am "warned" and the one for
>> which
>> I am not
>> (screenshots attatched)
>> 
>> 
>> But I have no idea on how to print that stuff out on a terminal. And
>> most
>> of all, on how to fix my datasets.
>> 
>> 
>> Thank you very much for your time.
>> 
> 
> 
> 
> --
> Edoardo Prestianni
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From hb at biostat.ucsf.edu  Fri Nov 28 21:11:10 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 28 Nov 2014 12:11:10 -0800
Subject: [R] package submission
In-Reply-To: <54788820.10502@gmail.com>
References: <CAPwpSvhef4gp6k=YDHqT+61qVJ7aHZ2_Cm9V286Ptf9mmznmeQ@mail.gmail.com>
	<54788820.10502@gmail.com>
Message-ID: <CAFDcVCTCM74_BahcBdH3Cqwp1ZQPZELzd2-23DDNxwAwVqZ+cA@mail.gmail.com>

>From http://cran.r-project.org/web/packages/policies.html:

"When submitting a package to CRAN you should use the submission form
at http://CRAN.R-project.org/submit.html (and not send an email). You
will be sent a confirmation email which needs to be accepted.(*)
...
In either case, you can check that the submission was received by
looking at ftp://CRAN.R-project.org/incoming/."

(*) That confirmation email is sent automatically and instantaneously.
It confirms you as a maintainer and the submission (not the
acceptance).

/Henrik

On Fri, Nov 28, 2014 at 6:35 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 28/11/2014 9:16 AM, Dan Vatnik wrote:
>>
>> Hi,
>>
>> I am the maintainer of the "traj" package.
>> I have added a vignette to the package this week(Wednesday) and uploaded
>> the new tarball to CRAN.
>> I have not yet received a confirmation e-mail.I do not know if the e-mail
>> is sent automatically or if a person needs to approve manually. I am just
>> wondering if I did everything correctly
>> or if there is a mistake in my uploading procedure.
>
>
> The CRAN people make the decisions manually, so it may just be that nobody
> has got to it yet.    If you don't hear from them in a week, you might
> consider writing to the submission email address, but I wouldn't do it
> sooner than that.
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From brc.khi at gmail.com  Fri Nov 28 14:24:21 2014
From: brc.khi at gmail.com (BRC)
Date: Fri, 28 Nov 2014 18:24:21 +0500
Subject: [R] r code for mtcars data frame
Message-ID: <CAF54RnpOA_LZeBq0Dxp6jAph-B_6iiX7zEAAn0hqMmOPZ3VJzw@mail.gmail.com>

I need r-code of data frame of "mtacrs". please advise how I can find it.

regards
faisal

	[[alternative HTML version deleted]]


From tduellmann+rhelp at googlemail.com  Fri Nov 28 12:31:02 2014
From: tduellmann+rhelp at googlemail.com (Thomas Duellmann)
Date: Fri, 28 Nov 2014 12:31:02 +0100
Subject: [R] Error when forecasting using ARIMA101
Message-ID: <CAEeWZcVDQ8BZrZUvDWMF02e5moKWkwiv2B4vb-xQsN2Eu4yRsQ@mail.gmail.com>

Hi there,

I am quite new to R and would like to use the arima101 forecast
approach in the "forecast"-library.
I tried to execute the following commands:
require(forecast)
var_1 <- c(372996.0)
var_1 <- ts(var_1, frequency=60)
var_2 <- arima(var_1,c(1,0,1),method="
CSS-ML")

Error in optim(init[mask], armaCSS, method = optim.method, hessian
 non-finite value supplied by optim

I don't really know where to find the cause of this error as I didn't
call "optim" in any way.
Could you give me a hint how to do it the right way?

Thanks a lot in advance.


From fabiofanoni at hotmail.com  Fri Nov 28 14:39:12 2014
From: fabiofanoni at hotmail.com (Fabio)
Date: Fri, 28 Nov 2014 14:39:12 +0100
Subject: [R] setup file corrupted
Message-ID: <DUB128-W591EF707606A00A2589D60AD7E0@phx.gbl>

Hi,

I downloaded the R-3.1.2-win.exe setup file (for Windows) but it doesn't work. When I double click on it, appeare this windows messagge "The setup files are corrupted. Please obtain a new copy of the program."

I use a 32 bit machine with Windows 7 operating system

I downoaded the file from both mirror:

http://cran.mirror.garr.it/mirrors/CRAN/
http://cran.at.r-project.org/

Can anyone help me?

Thanks,

Fabio


 		 	   		  
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Nov 28 22:17:16 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 29 Nov 2014 10:17:16 +1300
Subject: [R] package submission
In-Reply-To: <CAFDcVCTCM74_BahcBdH3Cqwp1ZQPZELzd2-23DDNxwAwVqZ+cA@mail.gmail.com>
References: <CAPwpSvhef4gp6k=YDHqT+61qVJ7aHZ2_Cm9V286Ptf9mmznmeQ@mail.gmail.com>	<54788820.10502@gmail.com>
	<CAFDcVCTCM74_BahcBdH3Cqwp1ZQPZELzd2-23DDNxwAwVqZ+cA@mail.gmail.com>
Message-ID: <5478E65C.7050603@auckland.ac.nz>



I was similarly bitten a couple of days ago when I submitted an update 
of my deldir package.  I'm *pretty* sure that I completed all the 
requisite steps in the steps in the web-based submission procedure, but 
I never received the promised "confirmation email".  Being a thicko, I 
overlooked this fact, and started to wonder why the update never 
appeared on CRAN.  Eventually I got my act together, went over the 
instructions and re-submitted the package.  This time I got the 
confirmation email, and the update duly appeared on CRAN.

Maybe there's a buglet in the software that effects the automated 
submission procedure.  I would have said it's more likely that I 
fumble-fingered something in my initial submission attempt.  However, 
hearing that someone else has had a similar experience makes me a wee 
bit more suspicious that there's a bug.  Could be tricky to track down 
but, given that if there is a bug its effect is intermittent and rare.

cheers,

Rolf Turner

P. S.  On my second try, the confirmation email arrived essentially 
instantaneously.  So I would advise package submitters:  if you don't 
get the confirmation email *right away* then something has very likely 
gone wrong.  Check the site ftp://CRAN.R-project.org/incoming/ as 
advised and if your package ain't there, try again.

R. T.

On 29/11/14 09:11, Henrik Bengtsson wrote:
>>From http://cran.r-project.org/web/packages/policies.html:
>
> "When submitting a package to CRAN you should use the submission form
> at http://CRAN.R-project.org/submit.html (and not send an email). You
> will be sent a confirmation email which needs to be accepted.(*)
> ...
> In either case, you can check that the submission was received by
> looking at ftp://CRAN.R-project.org/incoming/."
>
> (*) That confirmation email is sent automatically and instantaneously.
> It confirms you as a maintainer and the submission (not the
> acceptance).
>
> /Henrik
>
> On Fri, Nov 28, 2014 at 6:35 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 28/11/2014 9:16 AM, Dan Vatnik wrote:
>>>
>>> Hi,
>>>
>>> I am the maintainer of the "traj" package.
>>> I have added a vignette to the package this week(Wednesday) and uploaded
>>> the new tarball to CRAN.
>>> I have not yet received a confirmation e-mail.I do not know if the e-mail
>>> is sent automatically or if a person needs to approve manually. I am just
>>> wondering if I did everything correctly
>>> or if there is a mistake in my uploading procedure.
>>
>>
>> The CRAN people make the decisions manually, so it may just be that nobody
>> has got to it yet.    If you don't hear from them in a week, you might
>> consider writing to the submission email address, but I wouldn't do it
>> sooner than that.

-- 
Rolf Turner
Technical Editor ANZJS


From boris.steipe at utoronto.ca  Fri Nov 28 22:48:39 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 28 Nov 2014 16:48:39 -0500
Subject: [R] r code for mtcars data frame
In-Reply-To: <CAF54RnpOA_LZeBq0Dxp6jAph-B_6iiX7zEAAn0hqMmOPZ3VJzw@mail.gmail.com>
References: <CAF54RnpOA_LZeBq0Dxp6jAph-B_6iiX7zEAAn0hqMmOPZ3VJzw@mail.gmail.com>
Message-ID: <FCD69730-3958-48E4-AB88-1E65D11453CE@utoronto.ca>

try:
dput(mtcars)


B.

On Nov 28, 2014, at 8:24 AM, BRC <brc.khi at gmail.com> wrote:

> I need r-code of data frame of "mtacrs". please advise how I can find it.
> 
> regards
> faisal
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Fri Nov 28 23:26:36 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 28 Nov 2014 17:26:36 -0500
Subject: [R] setup file corrupted
In-Reply-To: <DUB128-W591EF707606A00A2589D60AD7E0@phx.gbl>
References: <DUB128-W591EF707606A00A2589D60AD7E0@phx.gbl>
Message-ID: <CAM_vjukgEew87+jpJ+BYxOcfyPyWB4mXq4RpL0++mwW2ofwHSg@mail.gmail.com>

Hi,

You should start by checking the checksum using the instructions given
on the download page to ensure your download obtained the complete
file.

My guess is that it didn't, and you'll need to redownload it.

Sarah

On Fri, Nov 28, 2014 at 8:39 AM, Fabio <fabiofanoni at hotmail.com> wrote:
> Hi,
>
> I downloaded the R-3.1.2-win.exe setup file (for Windows) but it doesn't work. When I double click on it, appeare this windows messagge "The setup files are corrupted. Please obtain a new copy of the program."
>
> I use a 32 bit machine with Windows 7 operating system
>
> I downoaded the file from both mirror:
>
> http://cran.mirror.garr.it/mirrors/CRAN/
> http://cran.at.r-project.org/
>
> Can anyone help me?
>
> Thanks,
>
> Fabio
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From brc.khi at gmail.com  Sat Nov 29 01:44:31 2014
From: brc.khi at gmail.com (BRC)
Date: Sat, 29 Nov 2014 05:44:31 +0500
Subject: [R] r code for mtcars data frame
In-Reply-To: <FCD69730-3958-48E4-AB88-1E65D11453CE@utoronto.ca>
References: <CAF54RnpOA_LZeBq0Dxp6jAph-B_6iiX7zEAAn0hqMmOPZ3VJzw@mail.gmail.com>
	<FCD69730-3958-48E4-AB88-1E65D11453CE@utoronto.ca>
Message-ID: <CAF54RnpnPL5wrc1_Qs3TvxKyMj+cEuWt1MYR0c8Sa7xNRMGvZg@mail.gmail.com>

it is not as I remembered, but I got the my requirement, so I can do my
task at my data. Thanks It helped me a lot.


On Sat, Nov 29, 2014 at 2:48 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> try:
> dput(mtcars)
>
>
> B.
>
> On Nov 28, 2014, at 8:24 AM, BRC <brc.khi at gmail.com> wrote:
>
> > I need r-code of data frame of "mtacrs". please advise how I can find it.
> >
> > regards
> > faisal
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Sat Nov 29 08:47:38 2014
From: chl948 at mail.usask.ca (Lee, Chel Hee)
Date: Sat, 29 Nov 2014 01:47:38 -0600
Subject: [R] r code for mtcars data frame
In-Reply-To: <CAF54RnpOA_LZeBq0Dxp6jAph-B_6iiX7zEAAn0hqMmOPZ3VJzw@mail.gmail.com>
References: <CAF54RnpOA_LZeBq0Dxp6jAph-B_6iiX7zEAAn0hqMmOPZ3VJzw@mail.gmail.com>
Message-ID: <54797A1A.9020100@mail.usask.ca>

 > dump("mtcars", file="")
mtcars <-
structure(list(mpg = c(21, 21, 22.8, 21.4, 18.7, 18.1, 14.3,
24.4, 22.8, 19.2, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4,
30.4, 33.9, 21.5, 15.5, 15.2, 13.3, 19.2, 27.3, 26, 30.4, 15.8,
19.7, 15, 21.4), cyl = c(6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8,
8, 8, 8, 8, 8, 4, 4, 4, 4, 8, 8, 8, 8, 4, 4, 4, 8, 6, 8, 4),
     disp = c(160, 160, 108, 258, 360, 225, 360, 146.7, 140.8,
     167.6, 167.6, 275.8, 275.8, 275.8, 472, 460, 440, 78.7, 75.7,
     71.1, 120.1, 318, 304, 350, 400, 79, 120.3, 95.1, 351, 145,
     301, 121), hp = c(110, 110, 93, 110, 175, 105, 245, 62, 95,
     123, 123, 180, 180, 180, 205, 215, 230, 66, 52, 65, 97, 150,
     150, 245, 175, 66, 91, 113, 264, 175, 335, 109), drat = c(3.9,
     3.9, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,
     3.07, 3.07, 3.07, 2.93, 3, 3.23, 4.08, 4.93, 4.22, 3.7, 2.76,
     3.15, 3.73, 3.08, 4.08, 4.43, 3.77, 4.22, 3.62, 3.54, 4.11
     ), wt = c(2.62, 2.875, 2.32, 3.215, 3.44, 3.46, 3.57, 3.19,
     3.15, 3.44, 3.44, 4.07, 3.73, 3.78, 5.25, 5.424, 5.345, 2.2,
     1.615, 1.835, 2.465, 3.52, 3.435, 3.84, 3.845, 1.935, 2.14,
     1.513, 3.17, 2.77, 3.57, 2.78), qsec = c(16.46, 17.02, 18.61,
     19.44, 17.02, 20.22, 15.84, 20, 22.9, 18.3, 18.9, 17.4, 17.6,
     18, 17.98, 17.82, 17.42, 19.47, 18.52, 19.9, 20.01, 16.87,
     17.3, 15.41, 17.05, 18.9, 16.7, 16.9, 14.5, 15.5, 14.6, 18.6
     ), vs = c(0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,
     0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1), am = c(1,
     1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,
     0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1), gear = c(4, 4, 4, 3,
     3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3,
     3, 3, 4, 5, 5, 5, 5, 5, 4), carb = c(4, 4, 1, 1, 2, 1, 4,
     2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2, 2, 4, 2, 1,
     2, 2, 4, 6, 8, 2)), .Names = c("mpg", "cyl", "disp", "hp",
"drat", "wt", "qsec", "vs", "am", "gear", "carb"), row.names = c("Mazda 
RX4",
"Mazda RX4 Wag", "Datsun 710", "Hornet 4 Drive", "Hornet Sportabout",
"Valiant", "Duster 360", "Merc 240D", "Merc 230", "Merc 280",
"Merc 280C", "Merc 450SE", "Merc 450SL", "Merc 450SLC", "Cadillac 
Fleetwood",
"Lincoln Continental", "Chrysler Imperial", "Fiat 128", "Honda Civic",
"Toyota Corolla", "Toyota Corona", "Dodge Challenger", "AMC Javelin",
"Camaro Z28", "Pontiac Firebird", "Fiat X1-9", "Porsche 914-2",
"Lotus Europa", "Ford Pantera L", "Ferrari Dino", "Maserati Bora",
"Volvo 142E"), class = "data.frame")
 >

Is this what you are looking for?  You can use the other function 
'dput()' instead of using 'dump()'.  I hope this helps.

Chel Hee Lee

On 11/28/2014 7:24 AM, BRC wrote:
> I need r-code of data frame of "mtacrs". please advise how I can find it.
>
> regards
> faisal
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mapar3 at gmail.com  Sat Nov 29 14:26:48 2014
From: mapar3 at gmail.com (=?UTF-8?B?TS4gQS4gUGFycmXDsW8=?=)
Date: Sat, 29 Nov 2014 14:26:48 +0100
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
Message-ID: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>

 i already sent this please unsusbscribe
passoword: 33311986
or 33311986dic


please unsubscribe me

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Sat Nov 29 16:48:22 2014
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 29 Nov 2014 09:48:22 -0600
Subject: [R] optimx
Message-ID: <40833BA0-F1F9-404A-988B-70BB0C191539@me.com>

Hello All,

I need some help with optimx, mostly due to my apparent lack of imagination than optimx itself.  Below is the pertinent code for which I have a question.  I am fitting to the term structure of swap rates per Cox, Ingersoll, and Ross.  As you can see the objective function is CIRTune.  I have set up the lower and upper bounds of the model for each kappa, lambda, and theta.  Everything works as expected.  

However, there is an additional constraint.
2 * kappa * lamba >= sigma^2

My question is as follows:  should the constraint be worked into the function or should I add an additional parameter in the function that is controlled by lower and upper?

 #Objective function
  CIRTune <- function(param = numeric(), shortrate = numeric(), sigma = .015, cfmatrix = matrix(), matmatrix = matrix()){
    kappa =   param[1]
    lambda = param[2]
    theta =     param[3]

    Disc <- CIRBondPrice(kappa = kappa, lambda = lambda, theta = theta, shortrate = shortrate, T= matmatrix,  step = 0, sigma = sigma)    
    
   CIRTune <- sqrt((sum(colSums((cfmatrix * Disc))^2))/ncol(matmatrix))
    return(CIRTune)
  }
  
  # Fit the model to the market   
  fit <- optimx(par = c(.1, .003, .03), 
                fn = CIRTune, 
                method = "L-BFGS-B",
                lower = c(rep(.001,3),
                upper = rep(1, 3), 
                shortrate = shortrate,
                sigma = .015,
                cfmatrix = CIR.CF.Matrix, 
                matmatrix = CIR.Mat.Matrix)  
  close(CalCIR1)
  return(fit)


Thank-you in advance,
Glenn
	[[alternative HTML version deleted]]


From kellert at ohsu.edu  Sat Nov 29 18:27:28 2014
From: kellert at ohsu.edu (Tom Keller)
Date: Sat, 29 Nov 2014 17:27:28 +0000
Subject: [R] R-help Digest, Vol 141, Issue 29
In-Reply-To: <mailman.14.1417258807.5863.r-help@r-project.org>
References: <mailman.14.1417258807.5863.r-help@r-project.org>
Message-ID: <2900770A-29B9-481B-BD31-E16891C29FD4@ohsu.edu>

http://www.bioperl.org/wiki/HOWTOs

On Nov 29, 2014, at 3:00 AM, r-help-request at r-project.org wrote:

Subject: Re: [R] perl


On Friday, November 28, 2014, Noha Osman <nmo_138 at usc.edu<mailto:nmo_138 at usc.edu>> wrote:

Hi Folks


Iam a new user in perl and I have two questions .Hopefully I get any help



	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sat Nov 29 19:12:40 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 29 Nov 2014 10:12:40 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
Message-ID: <CACk-te29rW-hTAN00caYuW=RGF=JD-KFU4+uUy_dFxUjnmgGGQ@mail.gmail.com>

Please please follow the mailing list link below and unsubscribe
yourself there as directed, not here.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Nov 29, 2014 at 5:26 AM, M. A. Parre?o <mapar3 at gmail.com> wrote:
>  i already sent this please unsusbscribe
> passoword: 33311986
> or 33311986dic
>
>
> please unsubscribe me
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From arturaugusto at gmail.com  Sat Nov 29 19:42:04 2014
From: arturaugusto at gmail.com (Artur Augusto)
Date: Sat, 29 Nov 2014 16:42:04 -0200
Subject: [R] Using Rmpfr to round with precision in R
In-Reply-To: <21622.60047.959693.244631@stat.math.ethz.ch>
References: <CAGP33S4k2qfwzA0txNBHh_xndxnWr=HiP4FjRmyrZ_cL9Auauw@mail.gmail.com>
	<21622.60047.959693.244631@stat.math.ethz.ch>
Message-ID: <CAGP33S6epn+RrkePY7xY8zStvcneNe93iqCEVTrg_cNmtqUcFA@mail.gmail.com>

Thanks Martin, looks like the update fixed the issue.

The round2 function is just to format the output.

now I can get the correct result:

library(Rmpfr)
sprintf("%#.2f", round(mpfr(1.152, 200),2))
round2(1.152, 2)
#[1] "1.15"

Artur

2014-11-27 7:10 GMT-02:00 Martin Maechler <maechler at stat.math.ethz.ch>:
>>>>>> Artur Augusto <arturaugusto at gmail.com>
>>>>>>     on Wed, 19 Nov 2014 15:26:12 -0200 writes:
>
>     > I'm trying to use the Rmpfr library with the round() function to apply
>     > the round half to even rule and achieve correct results, without
>     > errors due the finite precision of float point values.
>
>     > Example of problem:
>
>     > round(1.225,2)
>     > #[1] 1.23
>
>     > So far, this is what I've achieved:
>
>     > library(Rmpfr)
>     > x <- c(1.225, 1.2225, 1.22225, 1.222225)
>     > n <- c(2, 3, 4, 5)
>     > round2 <- function(x, n){
>     > sprintf(paste("%#.", n, "f", sep=""), round(mpfr(as.character(x), 200), n))
>     > }
>     > mapply(round2, x, n)
>     > #[1] "1.22"    "1.222"   "1.2222"  "1.22222"
>
> The above  round2() function is really pretty strange [what do you really want?]
> but below,  you have a very good point :
>
>     > But in some cases I don't get the desired results:
>
>     > round2(1.152, 2)# Should be 1.15
>     > #[1] "1.16"
>
>     > Reading the Rmpfr docs, at the roundMpfr() function, it says:
>
> Actually,  roundMpfr() is *not* used  by  round(<mpfr>, *)
> It has somewhat different semantics. That's why I used a new
> function name, roundMpfr(),  whereas the round() method for
> "mpfr" objects is what you get from
>
> selectMethod(round, "mpfr")
>
>     > The mpfr class group method Math2 implements a method for round(x,
>     > digits) which rounds to decimal digits.
>
> Indeed... and that is different from the roundMpfr() as
> mentioned above.
>
>     > But I can't figure how to use it.
>
>     > How can I achieve desired rounded results?
>     > Artur
>
> Wait a day or two [depending on how quickly the new Rmpfr version 0.5-7
> gets published on CRAN], and update your Rmpfr package.
> The problem is fixed in Rmpfr 0.5-7.
>
> If you had CC'ed your e-mail to
>    maintainer("Rmpfr")
> I would have heard of the problem earlier and almost surely
> have fixed it earlier.
>
> Best regards,
> Martin Maechler  (maintainer of 'Rmpfr').


From bbolker at gmail.com  Sat Nov 29 21:55:50 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 29 Nov 2014 20:55:50 +0000
Subject: [R] optimx
References: <40833BA0-F1F9-404A-988B-70BB0C191539@me.com>
Message-ID: <loom.20141129T214333-725@post.gmane.org>

Glenn Schultz <glennmschultz <at> me.com> writes:

> 
> Hello All,
 
> I need some help with optimx, mostly due to my apparent lack of
> imagination than optimx itself.  Below is the pertinent code for
> which I have a question.  I am fitting to the term structure of swap
> rates per Cox, Ingersoll, and Ross.  As you can see the objective
> function is CIRTune.  I have set up the lower and upper bounds of
> the model for each kappa, lambda, and theta.  Everything works as
> expected.
 
> However, there is an additional constraint.
> 2 * kappa * lamba >= sigma^2
 
> My question is as follows: should the constraint be worked into the
> function or should I add an additional parameter in the function
> that is controlled by lower and upper?

  This is a general question about constrained optimization, not
just about optimx (e.g. it would apply to the L-BFGS-B method for
base::optim() as well).  In general the best way to handle this
(I think) would be reparameterize your model slightly, substituting
gamma = 2*kappa*lambda-sigma^2 for either lambda or kappa.  Then
you know that gamma must be >=0, and you can compute the appropriate
value of (e.g.) lambda = (gamma+sigma^2)/(2*kappa) on the fly from
the specified values of kappa and gamma.  This will automatically
satisfy the lambda>0 constraint (if gamma, sigma, kappa are all >0),
but you need to check what's necessary to satisfy the other
(lambda<1) constraint; I haven't worked all the way through that
("left as an exercise"), but if it can't definitely be satisfied
by an independent constraint on gamma then you're in trouble
(you have to work out what values of kappa, sigma, and gamma
could lead to lambda>1, then see if it's possible to prevent them
by assigning independent constraints).

If you *are* in trouble, then you need to find an optimizer
that can handle nonlinear inequality constraints.  I think the nloptr
package might have one, or you can do this by hand (1) exactly by
Lagrange multipliers or (2) approximately by imposing a nonlinear penalty
when the constraint is violated.

>  #Objective function
>   CIRTune <- function(param = numeric(), 
> shortrate = numeric(), sigma = .015, cfmatrix = matrix(),
> matmatrix = matrix()){
>     kappa =   param[1]
>     lambda = param[2]
>     theta =     param[3]
> 
>     Disc <- CIRBondPrice(kappa = kappa, lambda = lambda, 
> theta = theta, shortrate = shortrate, T= matmatrix, 
> step = 0, sigma = sigma)    
> 
>    CIRTune <- sqrt((sum(colSums((cfmatrix * Disc))^2))/ncol(matmatrix))
>     return(CIRTune)
>   }
> 
>   # Fit the model to the market   
>   fit <- optimx(par = c(.1, .003, .03), 
>                 fn = CIRTune, 
>                 method = "L-BFGS-B",
>                 lower = c(rep(.001,3),
>                 upper = rep(1, 3), 
>                 shortrate = shortrate,
>                 sigma = .015,
>                 cfmatrix = CIR.CF.Matrix, 
>                 matmatrix = CIR.Mat.Matrix)  
>   close(CalCIR1)
>   return(fit)


From pgilbert902 at gmail.com  Sat Nov 29 22:46:43 2014
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 29 Nov 2014 16:46:43 -0500
Subject: [R] package submission
In-Reply-To: <mailman.15.1417258807.5863.r-help@r-project.org>
References: <mailman.15.1417258807.5863.r-help@r-project.org>
Message-ID: <547A3EC3.9080305@gmail.com>

>
> I was similarly bitten a couple of days ago when I submitted an update
> of my deldir package.  I'm*pretty*  sure that I completed all the
> requisite steps in the steps in the web-based submission procedure, but
> I never received the promised "confirmation email".  Being a thicko, I
> overlooked this fact, and started to wonder why the update never
> appeared on CRAN.  Eventually I got my act together, went over the
> instructions and re-submitted the package.  This time I got the
> confirmation email, and the update duly appeared on CRAN.
>
> Maybe there's a buglet in the software that effects the automated
> submission procedure.

I was similarly bitten but, paying closer attention on the second 
attempt, I suspect I thought I was finished at  "successfully uploaded" 
and I did not go all the way to the very bottom to see that I then had 
to click on submit to get the "successfully submitted" page. (Text of 
the messages from memory, so may not be exact.) Once successfully 
submitted, the email asking for confirmation is almost instantaneous.

For users like me that push the boundaries of discovering possible user 
errors, it would be helpful if the first message said "successfully 
uploaded - now read this page and submit at the bottom".

Paul

I would have said it's more likely that I
> fumble-fingered something in my initial submission attempt.  However,
> hearing that someone else has had a similar experience makes me a wee
> bit more suspicious that there's a bug.  Could be tricky to track down
> but, given that if there is a bug its effect is intermittent and rare.
>
> cheers,
>
> Rolf Turner
>
> P. S.  On my second try, the confirmation email arrived essentially
> instantaneously.  So I would advise package submitters:  if you don't
> get the confirmation email*right away*  then something has very likely
> gone wrong.  Check the siteftp://CRAN.R-project.org/incoming/  as
> advised and if your package ain't there, try again.
>
> R. T.
>
> On 29/11/14 09:11, Henrik Bengtsson wrote:
>> >>Fromhttp://cran.r-project.org/web/packages/policies.html:
>> >
>> >"When submitting a package to CRAN you should use the submission form
>> >athttp://CRAN.R-project.org/submit.html  (and not send an email). You
>> >will be sent a confirmation email which needs to be accepted.(*)
>> >...
>> >In either case, you can check that the submission was received by
>> >looking atftp://CRAN.R-project.org/incoming/."
>> >
>> >(*) That confirmation email is sent automatically and instantaneously.
>> >It confirms you as a maintainer and the submission (not the
>> >acceptance).
>> >
>> >/Henrik
>> >
>> >On Fri, Nov 28, 2014 at 6:35 AM, Duncan Murdoch
>> ><murdoch.duncan at gmail.com>  wrote:
>>> >>On 28/11/2014 9:16 AM, Dan Vatnik wrote:
>>>> >>>
>>>> >>>Hi,
>>>> >>>
>>>> >>>I am the maintainer of the "traj" package.
>>>> >>>I have added a vignette to the package this week(Wednesday) and uploaded
>>>> >>>the new tarball to CRAN.
>>>> >>>I have not yet received a confirmation e-mail.I do not know if the e-mail
>>>> >>>is sent automatically or if a person needs to approve manually. I am just
>>>> >>>wondering if I did everything correctly
>>>> >>>or if there is a mistake in my uploading procedure.
>>> >>
>>> >>
>>> >>The CRAN people make the decisions manually, so it may just be that nobody
>>> >>has got to it yet.    If you don't hear from them in a week, you might
>>> >>consider writing to the submission email address, but I wouldn't do it
>>> >>sooner than that.
> -- Rolf Turner Technical Editor ANZJS


From jsorkin at grecc.umaryland.edu  Sun Nov 30 01:09:29 2014
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 29 Nov 2014 19:09:29 -0500
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
Message-ID: <547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>

> Requests like this appear from time to time. Would it make sense to
add a link to the bottom of the email messages generated by the mail
program that is labeled and goes directly to the unsubscribe page?
> John


> On Nov 29, 2014, at 8:26 AM, M. A. Parre?o<mapar3 at gmail.com>
<mapar3 at gmail.com> wrote:
> 
> i already sent this please unsusbscribe
> passoword: 33311986
> or 33311986dic
> 
> 
> please unsubscribe me
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From jdnewmil at dcn.davis.CA.us  Sun Nov 30 01:34:47 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 29 Nov 2014 16:34:47 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
Message-ID: <84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>

In what way would that be unlike the link that is already there?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 29, 2014 4:09:29 PM PST, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>> Requests like this appear from time to time. Would it make sense to
>add a link to the bottom of the email messages generated by the mail
>program that is labeled and goes directly to the unsubscribe page?
>> John
>
>
>> On Nov 29, 2014, at 8:26 AM, M. A. Parre?o<mapar3 at gmail.com>
><mapar3 at gmail.com> wrote:
>> 
>> i already sent this please unsusbscribe
>> passoword: 33311986
>> or 33311986dic
>> 
>> 
>> please unsubscribe me
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>Confidentiality Statement:
>This email message, including any attachments, is for t...{{dropped:12}}


From jsorkin at grecc.umaryland.edu  Sun Nov 30 02:16:13 2014
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 29 Nov 2014 20:16:13 -0500
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
Message-ID: <547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>

I don't see a link that is labeled "unsubscribe".
John

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
wrote:
> 
> In what way would that be unlike the link that is already there?
>
---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go
Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
Go...
>                                      Live:   OO#.. Dead: OO#.. 
Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#. 
rocks...1k
>
---------------------------------------------------------------------------

> Sent from my phone. Please excuse my brevity.
> 
> On November 29, 2014 4:09:29 PM PST, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
>>> Requests like this appear from time to time. Would it make sense to
>> add a link to the bottom of the email messages generated by the mail
>> program that is labeled and goes directly to the unsubscribe page?
>>> John
>> 
>> 
>>> On Nov 29, 2014, at 8:26 AM, M. A. Parre?o<mapar3 at gmail.com>
>> <mapar3 at gmail.com> wrote:
>>> 
>>> i already sent this please unsusbscribe
>>> passoword: 33311986
>>> or 33311986dic
>>> 
>>> 
>>> please unsubscribe me
>>> 
>>>   [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of
>> the intended recipient(s) and may contain confidential and privileged
>> information. Any unauthorized use, disclosure or distribution is
>> prohibited. If you are not the intended recipient, please contact the
>> sender by reply email and destroy all copies of the original message.

>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From r.turner at auckland.ac.nz  Sun Nov 30 03:14:11 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 30 Nov 2014 15:14:11 +1300
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
Message-ID: <547A7D73.3030107@auckland.ac.nz>

On 30/11/14 14:16, John Sorkin wrote:
> I don't see a link that is labeled "unsubscribe".

<SNIP>

>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
> wrote:
>>
>> In what way would that be unlike the link that is already there?

<SNIP>

>> On November 29, 2014 4:09:29 PM PST, John Sorkin
> <jsorkin at grecc.umaryland.edu> wrote:
>>>> Requests like this appear from time to time. Would it make sense to
>>> add a link to the bottom of the email messages generated by the mail
>>> program that is labeled and goes directly to the unsubscribe page?

Well, there is no "unsubscribe" page as such.  The link given, i.e.

     https://stat.ethz.ch/mailman/listinfo/r-help

takes you to the primary help page. That provides a link to a (password 
protected) page where you can handle all matters pertaining to your
r-help subscription, including unsubscribing.

I suppose that it might be possible to provide a link taking one 
directly to this second page, but:

(1) It would add clutter (I'm sure we don't want to delete the link to 
the primary help page).

(2) The password protection might get complicated; I don't know about 
such matters.

(3) I don't think we want to waste time and resources helping people who 
are too stupid and illiterate to find their way to the unsubscribe 
facility on the basis of what is already provided.  They shouldn't be
R users in the first place.  One needs at least two grey cells to rub 
together to deal with R.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From fmagalhaes at gmail.com  Sun Nov 30 03:48:48 2014
From: fmagalhaes at gmail.com (=?UTF-8?B?RsOhYmlvIE1hZ2FsaMOjZXM=?=)
Date: Sun, 30 Nov 2014 00:48:48 -0200
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547A7D73.3030107@auckland.ac.nz>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz>
Message-ID: <CAAu8QF60cjdJAeTA8n8uz9HH2HaNeb4_if4OrDPTkPXQFvUreA@mail.gmail.com>

I think r-help list software supports unsubscribe headers. When this
option is enabled an additional header containing an unsubscribe link
is sent with every message do the list. This header is interpreted by
some email clients like Hotmail and Gmail, and a small unsubscribe
button is placed after the sender's email.

Enabling this won't hurt, it won't add more text to emails and maybe
can save a few messages like this.

#! F?bio


On Sun, Nov 30, 2014 at 12:14 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 30/11/14 14:16, John Sorkin wrote:
>>
>> I don't see a link that is labeled "unsubscribe".
>
>
> <SNIP>
>
>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>>
>> wrote:
>>>
>>>
>>> In what way would that be unlike the link that is already there?
>
>
> <SNIP>
>
>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>>
>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>>
>>>>> Requests like this appear from time to time. Would it make sense to
>>>>
>>>> add a link to the bottom of the email messages generated by the mail
>>>> program that is labeled and goes directly to the unsubscribe page?
>
>
> Well, there is no "unsubscribe" page as such.  The link given, i.e.
>
>     https://stat.ethz.ch/mailman/listinfo/r-help
>
> takes you to the primary help page. That provides a link to a (password
> protected) page where you can handle all matters pertaining to your
> r-help subscription, including unsubscribing.
>
> I suppose that it might be possible to provide a link taking one directly to
> this second page, but:
>
> (1) It would add clutter (I'm sure we don't want to delete the link to the
> primary help page).
>
> (2) The password protection might get complicated; I don't know about such
> matters.
>
> (3) I don't think we want to waste time and resources helping people who are
> too stupid and illiterate to find their way to the unsubscribe facility on
> the basis of what is already provided.  They shouldn't be
> R users in the first place.  One needs at least two grey cells to rub
> together to deal with R.
>
> cheers,
>
> Rolf Turner
>
> --
> Rolf Turner
> Technical Editor ANZJS
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Nov 30 04:32:24 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 29 Nov 2014 19:32:24 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547A7D73.3030107@auckland.ac.nz>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz>
Message-ID: <5E300A2F-61C6-48E8-9224-0A2F0E978F12@dcn.davis.CA.us>

To be fair, Rolf, they have already found difficulty and are trying to find their way out of this torrent, and impeding their way is not in anyone's interest.

John: I agree that adding the word "unsubscribe" to the footer would probably help those lost enough to be mailing the list. The existing web page does have that word on it, though.

Fabio: I was unaware of the unsubscribe header... looks interesting, though I would be concerned that it seems like it might bypass the password protection currently in place, making it susceptible to abuse. However, there seem to be quite a lot of organizations using it so it may work better than my initial impression tells me it does.


---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 29, 2014 6:14:11 PM PST, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>On 30/11/14 14:16, John Sorkin wrote:
>> I don't see a link that is labeled "unsubscribe".
>
><SNIP>
>
>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller
><jdnewmil at dcn.davis.CA.us>
>> wrote:
>>>
>>> In what way would that be unlike the link that is already there?
>
><SNIP>
>
>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>> Requests like this appear from time to time. Would it make sense
>to
>>>> add a link to the bottom of the email messages generated by the
>mail
>>>> program that is labeled and goes directly to the unsubscribe page?
>
>Well, there is no "unsubscribe" page as such.  The link given, i.e.
>
>     https://stat.ethz.ch/mailman/listinfo/r-help
>
>takes you to the primary help page. That provides a link to a (password
>
>protected) page where you can handle all matters pertaining to your
>r-help subscription, including unsubscribing.
>
>I suppose that it might be possible to provide a link taking one 
>directly to this second page, but:
>
>(1) It would add clutter (I'm sure we don't want to delete the link to 
>the primary help page).
>
>(2) The password protection might get complicated; I don't know about 
>such matters.
>
>(3) I don't think we want to waste time and resources helping people
>who 
>are too stupid and illiterate to find their way to the unsubscribe 
>facility on the basis of what is already provided.  They shouldn't be
>R users in the first place.  One needs at least two grey cells to rub 
>together to deal with R.
>
>cheers,
>
>Rolf Turner


From hb at biostat.ucsf.edu  Sun Nov 30 05:21:40 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 29 Nov 2014 20:21:40 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <5E300A2F-61C6-48E8-9224-0A2F0E978F12@dcn.davis.CA.us>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz>
	<5E300A2F-61C6-48E8-9224-0A2F0E978F12@dcn.davis.CA.us>
Message-ID: <CAFDcVCRtg5h=2kSc_8AgqRy82jcUbX-Skg66YVt_E29PytQuJA@mail.gmail.com>

On Sat, Nov 29, 2014 at 7:32 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> To be fair, Rolf, they have already found difficulty and are trying to find their way out of this torrent, and impeding their way is not in anyone's interest.
>
> John: I agree that adding the word "unsubscribe" to the footer would probably help those lost enough to be mailing the list. The existing web page does have that word on it, though.
>
> Fabio: I was unaware of the unsubscribe header... looks interesting, though I would be concerned that it seems like it might bypass the password protection currently in place, making it susceptible to abuse. However, there seem to be quite a lot of organizations using it so it may work better than my initial impression tells me it does.

FYI, if you look at the raw email messages, they all have the
following in the header:

X-Mailman-Version: 2.1.18-1
Precedence: list
List-Id: "Main R Mailing List: Primary help" <r-help.r-project.org>
List-Unsubscribe: <https://stat.ethz.ch/mailman/options/r-help>,
<mailto:r-help-request at r-project.org?subject=unsubscribe>
List-Archive: <https://stat.ethz.ch/pipermail/r-help/>
List-Post: <mailto:r-help at r-project.org>
List-Help: <mailto:r-help-request at r-project.org?subject=help>
List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
<mailto:r-help-request at r-project.org?subject=subscribe>

Note that "List-Unsubscribe" field
[http://www.faqs.org/rfcs/rfc2369.html].  That does not seem to be
enough to have Gmail add a "unsubscribe" button/link (which is indeed
a useful UX feature).  Google mention some more requirements in
https://support.google.com/mail/answer/81126#unsub, particularly
"'Precedence: bulk'", which I find on since mailing lists typically
use "list" just as r-help does.  I also found a mentioning on "DKIM
key signature" being required
[http://blog.mailchimp.com/gmails-new-unsubscribe-link-and-feedback-loop/].
So, not sure how easy it is to enable all this for the list(s) (which
are handled by Mailman).

My $.02

/Henrik


>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 29, 2014 6:14:11 PM PST, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>On 30/11/14 14:16, John Sorkin wrote:
>>> I don't see a link that is labeled "unsubscribe".
>>
>><SNIP>
>>
>>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.CA.us>
>>> wrote:
>>>>
>>>> In what way would that be unlike the link that is already there?
>>
>><SNIP>
>>
>>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>>> Requests like this appear from time to time. Would it make sense
>>to
>>>>> add a link to the bottom of the email messages generated by the
>>mail
>>>>> program that is labeled and goes directly to the unsubscribe page?
>>
>>Well, there is no "unsubscribe" page as such.  The link given, i.e.
>>
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>
>>takes you to the primary help page. That provides a link to a (password
>>
>>protected) page where you can handle all matters pertaining to your
>>r-help subscription, including unsubscribing.
>>
>>I suppose that it might be possible to provide a link taking one
>>directly to this second page, but:
>>
>>(1) It would add clutter (I'm sure we don't want to delete the link to
>>the primary help page).
>>
>>(2) The password protection might get complicated; I don't know about
>>such matters.
>>
>>(3) I don't think we want to waste time and resources helping people
>>who
>>are too stupid and illiterate to find their way to the unsubscribe
>>facility on the basis of what is already provided.  They shouldn't be
>>R users in the first place.  One needs at least two grey cells to rub
>>together to deal with R.
>>
>>cheers,
>>
>>Rolf Turner
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Sun Nov 30 05:51:23 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 29 Nov 2014 23:51:23 -0500
Subject: [R] trouble installing R from source on Windows 8
Message-ID: <CACxE24=FuCeZvoV3fp8L8OOVb5pGWzQvb1tT_wTSkMHsBACkxw@mail.gmail.com>

Hello everyone!

I'm trying to install R-3.1.2 from source on a Windows 8 laptop.

I installed Rtools 3.1 as administrator and is was fine so far.

Then I downloaded the R-3.1.2.tar.gz file and attempted to use the tar
command,
also from the shell as administrator.

I keep getting the following:
tar -xf R-3.1.2.tar.gz
tar(child): gzip: Cannot exec: no such file or directory
tar(child): Error is not recoverable: exiting now
tar: Child returned status 2
tar: Exiting with failure status due to previous errors

I have downloaded from several different mirrors, (both Rtools and
R-3.1.2.tar.gz), and have turned off the firewall (McAfee).

Has anyone else run into this, please?

Thanks so much,
Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Nov 30 06:29:29 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 29 Nov 2014 21:29:29 -0800
Subject: [R] trouble installing R from source on Windows 8
In-Reply-To: <CACxE24=FuCeZvoV3fp8L8OOVb5pGWzQvb1tT_wTSkMHsBACkxw@mail.gmail.com>
References: <CACxE24=FuCeZvoV3fp8L8OOVb5pGWzQvb1tT_wTSkMHsBACkxw@mail.gmail.com>
Message-ID: <80FF1D66-64E0-4016-BEDA-C8FE59538CB9@dcn.davis.CA.us>

Stop using administrator. If and only if Windows prompts you for permission to install, give it your password. Stay as far away from administrator as you can.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 29, 2014 8:51:23 PM PST, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello everyone!
>
>I'm trying to install R-3.1.2 from source on a Windows 8 laptop.
>
>I installed Rtools 3.1 as administrator and is was fine so far.
>
>Then I downloaded the R-3.1.2.tar.gz file and attempted to use the tar
>command,
>also from the shell as administrator.
>
>I keep getting the following:
>tar -xf R-3.1.2.tar.gz
>tar(child): gzip: Cannot exec: no such file or directory
>tar(child): Error is not recoverable: exiting now
>tar: Child returned status 2
>tar: Exiting with failure status due to previous errors
>
>I have downloaded from several different mirrors, (both Rtools and
>R-3.1.2.tar.gz), and have turned off the firewall (McAfee).
>
>Has anyone else run into this, please?
>
>Thanks so much,
>Sincerely,
>Erin


From stepbraun at yahoo.com  Sat Nov 29 22:59:14 2014
From: stepbraun at yahoo.com (=?UTF-8?Q?st=C3=A9phanie_braun?=)
Date: Sat, 29 Nov 2014 21:59:14 +0000 (UTC)
Subject: [R] Remove the border/frame in a dotplot()
Message-ID: <1915414038.2620031.1417298354946.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>

Dear listmembersI wouldlike to remove in a dotplot() the border/frame from the figure and only keepthe x- and y-axis. I can?t find a way to do this. bty="n" does notwork. Can somebody help? I include the r coding for my figure below.?dotplot(plant_species ~ mean, data =botany,????????????aspect= 1.5,??????????? scales=list(x=list(tck=c(-1,0)),y = list(tck=c(-1,0))),??????????? ylab= "Plant species",??????????? xlim= c(-1.1, 1.1),??????????? xlab= "Electivity index",prepanel = NULL,??????????? panel= function (x, y) {??????????? panel.abline(v=0)??????????? panel.xyplot(x,y, pch = 16, col = "black")??????????? panel.segments(botany$lower,as.numeric(y),??????????? botany$upper,as.numeric(y), lty = 1, col = "black")} 
?
Thank you!St?phanie

??
	[[alternative HTML version deleted]]


From tomuxiong at gmail.com  Sun Nov 30 03:58:23 2014
From: tomuxiong at gmail.com (listserve)
Date: Sat, 29 Nov 2014 21:58:23 -0500
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547A7D73.3030107@auckland.ac.nz>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz>
Message-ID: <547A87CF.2060305@gmail.com>

Any mailing list which respects its recipients makes unsubscribing as 
easy as possible. If users are having trouble doing so, it's clearly not 
easy enough.

I think putting a directly link in every message is certainly the right 
thing to do.

On 11/29/2014 09:14 PM, Rolf Turner wrote:
> On 30/11/14 14:16, John Sorkin wrote:
>> I don't see a link that is labeled "unsubscribe".
>
> <SNIP>
>
>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>> wrote:
>>>
>>> In what way would that be unlike the link that is already there?
>
> <SNIP>
>
>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>> Requests like this appear from time to time. Would it make sense to
>>>> add a link to the bottom of the email messages generated by the mail
>>>> program that is labeled and goes directly to the unsubscribe page?
>
> Well, there is no "unsubscribe" page as such.  The link given, i.e.
>
>      https://stat.ethz.ch/mailman/listinfo/r-help
>
> takes you to the primary help page. That provides a link to a (password
> protected) page where you can handle all matters pertaining to your
> r-help subscription, including unsubscribing.
>
> I suppose that it might be possible to provide a link taking one
> directly to this second page, but:
>
> (1) It would add clutter (I'm sure we don't want to delete the link to
> the primary help page).
>
> (2) The password protection might get complicated; I don't know about
> such matters.
>
> (3) I don't think we want to waste time and resources helping people who
> are too stupid and illiterate to find their way to the unsubscribe
> facility on the basis of what is already provided.  They shouldn't be
> R users in the first place.  One needs at least two grey cells to rub
> together to deal with R.
>
> cheers,
>
> Rolf Turner
>


From ligges at statistik.tu-dortmund.de  Sun Nov 30 07:45:58 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 30 Nov 2014 07:45:58 +0100
Subject: [R] trouble installing R from source on Windows 8
In-Reply-To: <80FF1D66-64E0-4016-BEDA-C8FE59538CB9@dcn.davis.CA.us>
References: <CACxE24=FuCeZvoV3fp8L8OOVb5pGWzQvb1tT_wTSkMHsBACkxw@mail.gmail.com>
	<80FF1D66-64E0-4016-BEDA-C8FE59538CB9@dcn.davis.CA.us>
Message-ID: <547ABD26.3020800@statistik.tu-dortmund.de>



On 30.11.2014 06:29, Jeff Newmiller wrote:
> Stop using administrator. If and only if Windows prompts you for permission to install, give it your password. Stay as far away from administrator as you can.

Which is not the reason here: gzip is not on  the PATH, i.e. Erin forgot 
to put the Rtools/bin directory on her PATH...

Best,
Uwe Ligges


> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 29, 2014 8:51:23 PM PST, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>> Hello everyone!
>>
>> I'm trying to install R-3.1.2 from source on a Windows 8 laptop.
>>
>> I installed Rtools 3.1 as administrator and is was fine so far.
>>
>> Then I downloaded the R-3.1.2.tar.gz file and attempted to use the tar
>> command,
>> also from the shell as administrator.
>>
>> I keep getting the following:
>> tar -xf R-3.1.2.tar.gz
>> tar(child): gzip: Cannot exec: no such file or directory
>> tar(child): Error is not recoverable: exiting now
>> tar: Child returned status 2
>> tar: Exiting with failure status due to previous errors
>>
>> I have downloaded from several different mirrors, (both Rtools and
>> R-3.1.2.tar.gz), and have turned off the firewall (McAfee).
>>
>> Has anyone else run into this, please?
>>
>> Thanks so much,
>> Sincerely,
>> Erin
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From erinm.hodgess at gmail.com  Sun Nov 30 09:03:38 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 30 Nov 2014 03:03:38 -0500
Subject: [R] trouble installing R from source on Windows 8
In-Reply-To: <547ABD26.3020800@statistik.tu-dortmund.de>
References: <CACxE24=FuCeZvoV3fp8L8OOVb5pGWzQvb1tT_wTSkMHsBACkxw@mail.gmail.com>
	<80FF1D66-64E0-4016-BEDA-C8FE59538CB9@dcn.davis.CA.us>
	<547ABD26.3020800@statistik.tu-dortmund.de>
Message-ID: <CACxE24=AzAO8fSZEnjoWmMN7udA_8OewQsk0aspb3-OGMJ85Tw@mail.gmail.com>

great...thank you



On Sun, Nov 30, 2014 at 1:45 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 30.11.2014 06:29, Jeff Newmiller wrote:
>
>> Stop using administrator. If and only if Windows prompts you for
>> permission to install, give it your password. Stay as far away from
>> administrator as you can.
>>
>
> Which is not the reason here: gzip is not on  the PATH, i.e. Erin forgot
> to put the Rtools/bin directory on her PATH...
>
> Best,
> Uwe Ligges
>
>
>  ------------------------------------------------------------
>> ---------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> ------------------------------------------------------------
>> ---------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 29, 2014 8:51:23 PM PST, Erin Hodgess <
>> erinm.hodgess at gmail.com> wrote:
>>
>>> Hello everyone!
>>>
>>> I'm trying to install R-3.1.2 from source on a Windows 8 laptop.
>>>
>>> I installed Rtools 3.1 as administrator and is was fine so far.
>>>
>>> Then I downloaded the R-3.1.2.tar.gz file and attempted to use the tar
>>> command,
>>> also from the shell as administrator.
>>>
>>> I keep getting the following:
>>> tar -xf R-3.1.2.tar.gz
>>> tar(child): gzip: Cannot exec: no such file or directory
>>> tar(child): Error is not recoverable: exiting now
>>> tar: Child returned status 2
>>> tar: Exiting with failure status due to previous errors
>>>
>>> I have downloaded from several different mirrors, (both Rtools and
>>> R-3.1.2.tar.gz), and have turned off the firewall (McAfee).
>>>
>>> Has anyone else run into this, please?
>>>
>>> Thanks so much,
>>> Sincerely,
>>> Erin
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From spencer.graves at structuremonitoring.com  Sun Nov 30 11:14:09 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 30 Nov 2014 02:14:09 -0800
Subject: [R] Comparing Latin characters with and without accents?
Message-ID: <547AEDF1.5000305@structuremonitoring.com>

Hello:


       How can one convert Latin characters with to the corresponding 
characters without?  For example, I want to convert "?" to "u", similar 
to how tolower('U') returns "u".


       This can be done using chartr{base}, e.g., chartr('?', 'u', 
'Ra?l') returns "Raul".  However, I wondered if a simpler version of 
this is available.


       Thanks,
       Spencer


p.s.   findFn('convert to ascii') found 117 help pages in 70 packages.  
A brief review identified two to "Convert to ASCII": ASCIIfy {gtools} 
and stri_enc_toascii {stringi}.  Neither of these did what I expected.


From nalimilan at club.fr  Sun Nov 30 11:25:32 2014
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sun, 30 Nov 2014 11:25:32 +0100
Subject: [R] Comparing Latin characters with and without accents?
In-Reply-To: <547AEDF1.5000305@structuremonitoring.com>
References: <547AEDF1.5000305@structuremonitoring.com>
Message-ID: <1417343132.23112.37.camel@club.fr>

Le dimanche 30 novembre 2014 ? 02:14 -0800, Spencer Graves a ?crit :
> Hello:
> 
> 
>        How can one convert Latin characters with to the corresponding 
> characters without?  For example, I want to convert "?" to "u", similar 
> to how tolower('U') returns "u".
> 
> 
>        This can be done using chartr{base}, e.g., chartr('?', 'u', 
> 'Ra?l') returns "Raul".  However, I wondered if a simpler version of 
> this is available.
This appears to work:
> iconv("?", "", "ASCII//TRANSLIT")
[1] "u"


Regards

> 
>        Thanks,
>        Spencer
> 
> 
> p.s.   findFn('convert to ascii') found 117 help pages in 70 packages.  
> A brief review identified two to "Convert to ASCII": ASCIIfy {gtools} 
> and stri_enc_toascii {stringi}.  Neither of these did what I expected.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at structuremonitoring.com  Sun Nov 30 11:32:28 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 30 Nov 2014 02:32:28 -0800
Subject: [R] Comparing Latin characters with and without accents?
In-Reply-To: <1417343132.23112.37.camel@club.fr>
References: <547AEDF1.5000305@structuremonitoring.com>
	<1417343132.23112.37.camel@club.fr>
Message-ID: <547AF23C.60206@structuremonitoring.com>

Wonderful.  Thanks very much.  Spencer


On 11/30/2014 2:25 AM, Milan Bouchet-Valat wrote:
> Le dimanche 30 novembre 2014 ? 02:14 -0800, Spencer Graves a ?crit :
>> Hello:
>>
>>
>>         How can one convert Latin characters with to the corresponding
>> characters without?  For example, I want to convert "?" to "u", similar
>> to how tolower('U') returns "u".
>>
>>
>>         This can be done using chartr{base}, e.g., chartr('?', 'u',
>> 'Ra?l') returns "Raul".  However, I wondered if a simpler version of
>> this is available.
> This appears to work:
>> iconv("?", "", "ASCII//TRANSLIT")
> [1] "u"
>
>
> Regards
>
>>         Thanks,
>>         Spencer
>>
>>
>> p.s.   findFn('convert to ascii') found 117 help pages in 70 packages.
>> A brief review identified two to "Convert to ASCII": ASCIIfy {gtools}
>> and stri_enc_toascii {stringi}.  Neither of these did what I expected.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jsorkin at grecc.umaryland.edu  Sun Nov 30 13:05:54 2014
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 30 Nov 2014 07:05:54 -0500
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <CAFDcVCRtg5h=2kSc_8AgqRy82jcUbX-Skg66YVt_E29PytQuJA@mail.gmail.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz>
	<5E300A2F-61C6-48E8-9224-0A2F0E978F12@dcn.davis.CA.us>
	<CAFDcVCRtg5h=2kSc_8AgqRy82jcUbX-Skg66YVt_E29PytQuJA@mail.gmail.com>
Message-ID: <547AC1D8020000CB0011BE26@smtp.medicine.umaryland.edu>

The headers listed below as being part of the ?raw" email messages are
not seen, at least not in the messages I receive.
John

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Nov 29, 2014, at 11:22 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
wrote:
> 
> On Sat, Nov 29, 2014 at 7:32 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> To be fair, Rolf, they have already found difficulty and are trying
to find their way out of this torrent, and impeding their way is not in
anyone's interest.
>> 
>> John: I agree that adding the word "unsubscribe" to the footer would
probably help those lost enough to be mailing the list. The existing web
page does have that word on it, though.
>> 
>> Fabio: I was unaware of the unsubscribe header... looks interesting,
though I would be concerned that it seems like it might bypass the
password protection currently in place, making it susceptible to abuse.
However, there seem to be quite a lot of organizations using it so it
may work better than my initial impression tells me it does.
> 
> FYI, if you look at the raw email messages, they all have the
> following in the header:
> 
> X-Mailman-Version: 2.1.18-1
> Precedence: list
> List-Id: "Main R Mailing List: Primary help" <r-help.r-project.org>
> List-Unsubscribe: <https://stat.ethz.ch/mailman/options/r-help>,
> <mailto:r-help-request at r-project.org?subject=unsubscribe>
> List-Archive: <https://stat.ethz.ch/pipermail/r-help/>
> List-Post: <mailto:r-help at r-project.org>
> List-Help: <mailto:r-help-request at r-project.org?subject=help>
> List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
> <mailto:r-help-request at r-project.org?subject=subscribe>
> 
> Note that "List-Unsubscribe" field
> [http://www.faqs.org/rfcs/rfc2369.html].  That does not seem to be
> enough to have Gmail add a "unsubscribe" button/link (which is indeed
> a useful UX feature).  Google mention some more requirements in
> https://support.google.com/mail/answer/81126#unsub, particularly
> "'Precedence: bulk'", which I find on since mailing lists typically
> use "list" just as r-help does.  I also found a mentioning on "DKIM
> key signature" being required
>
[http://blog.mailchimp.com/gmails-new-unsubscribe-link-and-feedback-loop/].
> So, not sure how easy it is to enable all this for the list(s) (which
> are handled by Mailman).
> 
> My $.02
> 
> /Henrik
> 
> 
>> 
>> 
>>
---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
Go...
>>                                      Live:   OO#.. Dead: OO#.. 
Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
rocks...1k
>>
---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>>> On November 29, 2014 6:14:11 PM PST, Rolf Turner
<r.turner at auckland.ac.nz> wrote:
>>>> On 30/11/14 14:16, John Sorkin wrote:
>>>> I don't see a link that is labeled "unsubscribe".
>>> 
>>> <SNIP>
>>> 
>>>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.CA.us>
>>>> wrote:
>>>>> 
>>>>> In what way would that be unlike the link that is already there?
>>> 
>>> <SNIP>
>>> 
>>>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>>>> Requests like this appear from time to time. Would it make sense
>>> to
>>>>>> add a link to the bottom of the email messages generated by the
>>> mail
>>>>>> program that is labeled>>> Well, there is no "unsubscribe" page as such.  The link given, i.e.
>>> 
>>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>> 
>>> takes you to the primary help page. That provides a link to a
(password
>>> 
>>> protected) page where you can handle all matters pertaining to your
>>> r-help subscription, including unsubscribing.
>>> 
>>> I suppose that it might be possible to provide a link taking one
>>> directly to this second page, but:
>>> 
>>> (1) It would add clutter (I'm sure we don't want to delete the link
to
>>> the primary help page).
>>> 
>>> (2) The password protection might get complicated; I don't know
about
>>> such matters.
>>> 
>>> (3) I don't think we want to waste time and resources helping people
>>> who
>>> are too stupid and illiterate to find their way to the unsubscribe
>>> facility on the basis of what is already provided.  They shouldn't
be
>>> R users in the first place.  One needs at least two grey cells to
rub
>>> together to deal with R.
>>> 
>>> cheers,
>>> 
>>> Rolf Turner
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From philip.c.robinson at gmail.com  Sun Nov 30 14:30:30 2014
From: philip.c.robinson at gmail.com (Philip Robinson)
Date: Sun, 30 Nov 2014 23:30:30 +1000
Subject: [R] TSLS / 2SLS with a binary outcome
Message-ID: <CAMMiRhxs58u8YhapqBB+kuFnOHxm7GK5gmDhj0rvyGb4Jt5HJw@mail.gmail.com>

Hi,

I am wanting to complete 2 stage least squared regression with a binary
outcome. I have found and implemented a continuous outcome with tsls() from
the sen package or ivreg() from the AER package.

However I am struggling to find a package/function that implements a
function for  a binary outcome. If someone could knows of a package or
function and could help by pointing me in the right direction I would be
most grateful.

Kind regards
Philip

	[[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Sun Nov 30 15:02:12 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sun, 30 Nov 2014 14:02:12 +0000
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547AC1D8020000CB0011BE26@smtp.medicine.umaryland.edu>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>	<547A7D73.3030107@auckland.ac.nz>	<5E300A2F-61C6-48E8-9224-0A2F0E978F12@dcn.davis.CA.us>	<CAFDcVCRtg5h=2kSc_8AgqRy82jcUbX-Skg66YVt_E29PytQuJA@mail.gmail.com>
	<547AC1D8020000CB0011BE26@smtp.medicine.umaryland.edu>
Message-ID: <547B2364.2010305@aghmed.fsnet.co.uk>

Dear John

Perhaps you have set your mail client to hide them? Your email certainly 
has them when I go Options | View | Headers | All in Thunderbird.

Michael

On 30/11/2014 12:05, John Sorkin wrote:
> The headers listed below as being part of the ?raw" email messages are
> not seen, at least not in the messages I receive.
> John
>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>> On Nov 29, 2014, at 11:22 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
> wrote:
>>
>> On Sat, Nov 29, 2014 at 7:32 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> To be fair, Rolf, they have already found difficulty and are trying
> to find their way out of this torrent, and impeding their way is not in
> anyone's interest.
>>>
>>> John: I agree that adding the word "unsubscribe" to the footer would
> probably help those lost enough to be mailing the list. The existing web
> page does have that word on it, though.
>>>
>>> Fabio: I was unaware of the unsubscribe header... looks interesting,
> though I would be concerned that it seems like it might bypass the
> password protection currently in place, making it susceptible to abuse.
> However, there seem to be quite a lot of organizations using it so it
> may work better than my initial impression tells me it does.
>>
>> FYI, if you look at the raw email messages, they all have the
>> following in the header:
>>
>> X-Mailman-Version: 2.1.18-1
>> Precedence: list
>> List-Id: "Main R Mailing List: Primary help" <r-help.r-project.org>
>> List-Unsubscribe: <https://stat.ethz.ch/mailman/options/r-help>,
>> <mailto:r-help-request at r-project.org?subject=unsubscribe>
>> List-Archive: <https://stat.ethz.ch/pipermail/r-help/>
>> List-Post: <mailto:r-help at r-project.org>
>> List-Help: <mailto:r-help-request at r-project.org?subject=help>
>> List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
>> <mailto:r-help-request at r-project.org?subject=subscribe>
>>
>> Note that "List-Unsubscribe" field
>> [http://www.faqs.org/rfcs/rfc2369.html].  That does not seem to be
>> enough to have Gmail add a "unsubscribe" button/link (which is indeed
>> a useful UX feature).  Google mention some more requirements in
>> https://support.google.com/mail/answer/81126#unsub, particularly
>> "'Precedence: bulk'", which I find on since mailing lists typically
>> use "list" just as r-help does.  I also found a mentioning on "DKIM
>> key signature" being required
>>
> [http://blog.mailchimp.com/gmails-new-unsubscribe-link-and-feedback-loop/].
>> So, not sure how easy it is to enable all this for the list(s) (which
>> are handled by Mailman).
>>
>> My $.02
>>
>> /Henrik
>>
>>
>>>
>>>
>>>
> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>>>                                       Live:   OO#.. Dead: OO#..
> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
>>>
> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>>> On November 29, 2014 6:14:11 PM PST, Rolf Turner
> <r.turner at auckland.ac.nz> wrote:
>>>>> On 30/11/14 14:16, John Sorkin wrote:
>>>>> I don't see a link that is labeled "unsubscribe".
>>>>
>>>> <SNIP>
>>>>
>>>>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller
>>>> <jdnewmil at dcn.davis.CA.us>
>>>>> wrote:
>>>>>>
>>>>>> In what way would that be unlike the link that is already there?
>>>>
>>>> <SNIP>
>>>>
>>>>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>>>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>>>>> Requests like this appear from time to time. Would it make sense
>>>> to
>>>>>>> add a link to the bottom of the email messages generated by the
>>>> mail
>>>>>>> program that is labeled>>> Well, there is no "unsubscribe" page as such.  The link given, i.e.
>>>>
>>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>>
>>>> takes you to the primary help page. That provides a link to a
> (password
>>>>
>>>> protected) page where you can handle all matters pertaining to your
>>>> r-help subscription, including unsubscribing.
>>>>
>>>> I suppose that it might be possible to provide a link taking one
>>>> directly to this second page, but:
>>>>
>>>> (1) It would add clutter (I'm sure we don't want to delete the link
> to
>>>> the primary help page).
>>>>
>>>> (2) The password protection might get complicated; I don't know
> about
>>>> such matters.
>>>>
>>>> (3) I don't think we want to waste time and resources helping people
>>>> who
>>>> are too stupid and illiterate to find their way to the unsubscribe
>>>> facility on the basis of what is already provided.  They shouldn't
> be
>>>> R users in the first place.  One needs at least two grey cells to
> rub
>>>> together to deal with R.
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:22}}


From jrkrideau at inbox.com  Sun Nov 30 15:16:55 2014
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 30 Nov 2014 06:16:55 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547B2364.2010305@aghmed.fsnet.co.uk>
References: <547a19ee020000cb0011bdf0@smtp.medicine.umaryland.edu>
	<547a7d73.3030107@auckland.ac.nz>
	<cafh18f22h7bqtdc_xu6aw83ekgedpw-v5+agzuwy4fasnt=rfw@mail.gmail.com>
	<cafdcvcrtg5h=2ksc_8agqry82jcubx-skg66yvt_e29pytquja@mail.gmail.com>
	<547a2994020000cb0011bdf6@smtp.medicine.umaryland.edu>
	<5e300a2f-61c6-48e8-9224-0a2f0e978f12@dcn.davis.ca.us>
	<84fbe77f-a67d-496b-8325-a6b974057145@dcn.davis.ca.us>
	<547ac1d8020000cb0011be26@smtp.medicine.umaryland.edu>
Message-ID: <A7C5FFC17AB.0000013Bjrkrideau@inbox.com>

The problem seems to be that the people who have a desire to unsubscrbe and post here are not the most sophisticated of users and expecting them to know how to track down the raw email or even to realise the message at the bottom of the post is meant to convey much of anything is not likely to occur to them. 

I have not had any need to look for the raw email and, while it only took a few seconds to find it in my email reader, one has to know it exists before one can look for it. 

I probably have not looked at a raw email for 3-5 years. Why would I?

The chances of a newbie, possibly without much "computer" experience vs user of MS Office and E-mail even being aware such a thing exists is slig\t (snowballl in ... ?)

A slight change to the footer seems like a good idea.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: info at aghmed.fsnet.co.uk
> Sent: Sun, 30 Nov 2014 14:02:12 +0000
> To: jsorkin at grecc.umaryland.edu, hb at biostat.ucsf.edu
> Subject: Re: [R] please please unsubscribe!!!!!!!!!!!!!!!!
> 
> Dear John
> 
> Perhaps you have set your mail client to hide them? Your email certainly
> has them when I go Options | View | Headers | All in Thunderbird.
> 
> Michael
> 
> On 30/11/2014 12:05, John Sorkin wrote:
>> The headers listed below as being part of the ?raw" email messages are
>> not seen, at least not in the messages I receive.
>> John
>> 
>>> John David Sorkin M.D., Ph.D.
>>> Professor of Medicine
>>> Chief, Biostatistics and Informatics
>>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>>> Baltimore VA Medical Center
>>> 10 North Greene Street
>>> GRECC (BT/18/GR)
>>> Baltimore, MD 21201-1524
>>> (Phone) 410-605-7119
>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> 
>> 
>>> On Nov 29, 2014, at 11:22 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
>> wrote:
>>> 
>>> On Sat, Nov 29, 2014 at 7:32 PM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>> To be fair, Rolf, they have already found difficulty and are trying
>> to find their way out of this torrent, and impeding their way is not in
>> anyone's interest.
>>>> 
>>>> John: I agree that adding the word "unsubscribe" to the footer would
>> probably help those lost enough to be mailing the list. The existing web
>> page does have that word on it, though.
>>>> 
>>>> Fabio: I was unaware of the unsubscribe header... looks interesting,
>> though I would be concerned that it seems like it might bypass the
>> password protection currently in place, making it susceptible to abuse.
>> However, there seem to be quite a lot of organizations using it so it
>> may work better than my initial impression tells me it does.
>>> 
>>> FYI, if you look at the raw email messages, they all have the
>>> following in the header:
>>> 
>>> X-Mailman-Version: 2.1.18-1
>>> Precedence: list
>>> List-Id: "Main R Mailing List: Primary help" <r-help.r-project.org>
>>> List-Unsubscribe: <https://stat.ethz.ch/mailman/options/r-help>,
>>> <mailto:r-help-request at r-project.org?subject=unsubscribe>
>>> List-Archive: <https://stat.ethz.ch/pipermail/r-help/>
>>> List-Post: <mailto:r-help at r-project.org>
>>> List-Help: <mailto:r-help-request at r-project.org?subject=help>
>>> List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
>>> <mailto:r-help-request at r-project.org?subject=subscribe>
>>> 
>>> Note that "List-Unsubscribe" field
>>> [http://www.faqs.org/rfcs/rfc2369.html].  That does not seem to be
>>> enough to have Gmail add a "unsubscribe" button/link (which is indeed
>>> a useful UX feature).  Google mention some more requirements in
>>> https://support.google.com/mail/answer/81126#unsub, particularly
>>> "'Precedence: bulk'", which I find on since mailing lists typically
>>> use "list" just as r-help does.  I also found a mentioning on "DKIM
>>> key signature" being required
>>> 
>> [http://blog.mailchimp.com/gmails-new-unsubscribe-link-and-feedback-loop/].
>>> So, not sure how easy it is to enable all this for the list(s) (which
>>> are handled by Mailman).
>>> 
>>> My $.02
>>> 
>>> /Henrik
>>> 
>>> 
>>>> 
>>>> 
>>>> 
>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>>>                                       Live:   OO#.. Dead: OO#..
>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>>> 
>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>>> On November 29, 2014 6:14:11 PM PST, Rolf Turner
>> <r.turner at auckland.ac.nz> wrote:
>>>>>> On 30/11/14 14:16, John Sorkin wrote:
>>>>>> I don't see a link that is labeled "unsubscribe".
>>>>> 
>>>>> <SNIP>
>>>>> 
>>>>>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller
>>>>> <jdnewmil at dcn.davis.CA.us>
>>>>>> wrote:
>>>>>>> 
>>>>>>> In what way would that be unlike the link that is already there?
>>>>> 
>>>>> <SNIP>
>>>>> 
>>>>>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>>>>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>>>>>> Requests like this appear from time to time. Would it make sense
>>>>> to
>>>>>>>> add a link to the bottom of the email messages generated by the
>>>>> mail
>>>>>>>> program that is labeled>>> Well, there is no "unsubscribe" page as
>>>>>>>> such.  The link given, i.e.
>>>>> 
>>>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> 
>>>>> takes you to the primary help page. That provides a link to a
>> (password
>>>>> 
>>>>> protected) page where you can handle all matters pertaining to your
>>>>> r-help subscription, including unsubscribing.
>>>>> 
>>>>> I suppose that it might be possible to provide a link taking one
>>>>> directly to this second page, but:
>>>>> 
>>>>> (1) It would add clutter (I'm sure we don't want to delete the link
>> to
>>>>> the primary help page).
>>>>> 
>>>>> (2) The password protection might get complicated; I don't know
>> about
>>>>> such matters.
>>>>> 
>>>>> (3) I don't think we want to waste time and resources helping people
>>>>> who
>>>>> are too stupid and illiterate to find their way to the unsubscribe
>>>>> facility on the basis of what is already provided.  They shouldn't
>> be
>>>>> R users in the first place.  One needs at least two grey cells to
>> rub
>>>>> together to deal with R.
>>>>> 
>>>>> cheers,
>>>>> 
>>>>> Rolf Turner
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Confidentiality Statement:
>> This email message, including any attachments, is for ...{{dropped:22}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Sun Nov 30 15:22:30 2014
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 30 Nov 2014 06:22:30 -0800
Subject: [R] Remove the border/frame in a dotplot()
In-Reply-To: <1915414038.2620031.1417298354946.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>
Message-ID: <A7D27B4CA51.00000142jrkrideau@inbox.com>

You seem to have posted in HTML and the post is close to unreadable. Also you did not include any data, as far as I can see.

Please supply some sample dataand code. 
 The easiest way to supply data  is to se the dput() function.  Example with your file named "testfile": 
dput(testfile) 
Then copy the output and pasteinto your emal.  Fr large data sets, you can just supply a representative sampl.  Usually,  dput(head(testfile, 100)) will be sufficient.    

You might also find 
https://github.com/hadley/devtools/wiki/Reproducibility and 
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example useful

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Sat, 29 Nov 2014 21:59:14 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] Remove the border/frame in a dotplot()
> 
> Dear listmembersI wouldlike to remove in a dotplot() the border/frame
> from the figure and only keepthe x- and y-axis. I can?t find a way to do
> this. bty="n" does notwork. Can somebody help? I include the r coding for
> my figure below.?dotplot(plant_species ~ mean, data
> =botany,????????????aspect= 1.5,
> scales=list(x=list(tck=c(-1,0)),y = list(tck=c(-1,0))),??????????? ylab=
> "Plant species",??????????? xlim= c(-1.1, 1.1),??????????? xlab=
> "Electivity index",prepanel = NULL,??????????? panel= function (x, y)
> {??????????? panel.abline(v=0)??????????? panel.xyplot(x,y, pch = 16, col
> = "black")
> panel.segments(botany$lower,as.numeric(y),
> botany$upper,as.numeric(y), lty = 1, col = "black")}
> 
> Thank you!St?phanie
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From maitra.mbox.ignored at inbox.com  Sun Nov 30 15:30:55 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sun, 30 Nov 2014 08:30:55 -0600
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547A87CF.2060305@gmail.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
Message-ID: <20141130083055.91e407890b5ba2f95c2e8155@inbox.com>

I agree with this sentiment and suggestion. I can not see much of a downside to it, with the exception that most of these "unsophisticated" users will probably not even bother reading it. But then we would all be back in the current situation, not worse.

Ranjan

On Sat, 29 Nov 2014 21:58:23 -0500 listserve <tomuxiong at gmail.com> wrote:

> Any mailing list which respects its recipients makes unsubscribing as 
> easy as possible. If users are having trouble doing so, it's clearly not 
> easy enough.
> 
> I think putting a directly link in every message is certainly the right 
> thing to do.
> 
> On 11/29/2014 09:14 PM, Rolf Turner wrote:
> > On 30/11/14 14:16, John Sorkin wrote:
> >> I don't see a link that is labeled "unsubscribe".
> >
> > <SNIP>
> >
> >>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
> >> wrote:
> >>>
> >>> In what way would that be unlike the link that is already there?
> >
> > <SNIP>
> >
> >>> On November 29, 2014 4:09:29 PM PST, John Sorkin
> >> <jsorkin at grecc.umaryland.edu> wrote:
> >>>>> Requests like this appear from time to time. Would it make sense to
> >>>> add a link to the bottom of the email messages generated by the mail
> >>>> program that is labeled and goes directly to the unsubscribe page?
> >
> > Well, there is no "unsubscribe" page as such.  The link given, i.e.
> >
> >      https://stat.ethz.ch/mailman/listinfo/r-help
> >
> > takes you to the primary help page. That provides a link to a (password
> > protected) page where you can handle all matters pertaining to your
> > r-help subscription, including unsubscribing.
> >
> > I suppose that it might be possible to provide a link taking one
> > directly to this second page, but:
> >
> > (1) It would add clutter (I'm sure we don't want to delete the link to
> > the primary help page).
> >
> > (2) The password protection might get complicated; I don't know about
> > such matters.
> >
> > (3) I don't think we want to waste time and resources helping people who
> > are too stupid and illiterate to find their way to the unsubscribe
> > facility on the basis of what is already provided.  They shouldn't be
> > R users in the first place.  One needs at least two grey cells to rub
> > together to deal with R.
> >
> > cheers,
> >
> > Rolf Turner
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From fmagalhaes at gmail.com  Sun Nov 30 15:56:23 2014
From: fmagalhaes at gmail.com (=?UTF-8?B?RsOhYmlvIE1hZ2FsaMOjZXM=?=)
Date: Sun, 30 Nov 2014 12:56:23 -0200
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
Message-ID: <CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>

My bad, r-help messages indeed have the unsubscribe header set. Also,
at least for Gmail a "Precedence: bulk" should be set in order to this
mechanism to work, as Henrik pointed out.

Currently the raw headers set precedence to "list". I don't know the
technical differences of list and bulk, so maybe switching from one to
the other can impose some tradeoffs.

So I see three possibilities: leave as it is now, switch precedence to
"bulk" if it doesn't interfere on list behavior and have at least a
small unsubscribe button on some email clients or add an unsubscribe
link to footer.

#! F?bio


On Sun, Nov 30, 2014 at 12:30 PM, Ranjan Maitra
<maitra.mbox.ignored at inbox.com> wrote:
> I agree with this sentiment and suggestion. I can not see much of a downside to it, with the exception that most of these "unsophisticated" users will probably not even bother reading it. But then we would all be back in the current situation, not worse.
>
> Ranjan
>
> On Sat, 29 Nov 2014 21:58:23 -0500 listserve <tomuxiong at gmail.com> wrote:
>
>> Any mailing list which respects its recipients makes unsubscribing as
>> easy as possible. If users are having trouble doing so, it's clearly not
>> easy enough.
>>
>> I think putting a directly link in every message is certainly the right
>> thing to do.
>>
>> On 11/29/2014 09:14 PM, Rolf Turner wrote:
>> > On 30/11/14 14:16, John Sorkin wrote:
>> >> I don't see a link that is labeled "unsubscribe".
>> >
>> > <SNIP>
>> >
>> >>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>> >> wrote:
>> >>>
>> >>> In what way would that be unlike the link that is already there?
>> >
>> > <SNIP>
>> >
>> >>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>> >> <jsorkin at grecc.umaryland.edu> wrote:
>> >>>>> Requests like this appear from time to time. Would it make sense to
>> >>>> add a link to the bottom of the email messages generated by the mail
>> >>>> program that is labeled and goes directly to the unsubscribe page?
>> >
>> > Well, there is no "unsubscribe" page as such.  The link given, i.e.
>> >
>> >      https://stat.ethz.ch/mailman/listinfo/r-help
>> >
>> > takes you to the primary help page. That provides a link to a (password
>> > protected) page where you can handle all matters pertaining to your
>> > r-help subscription, including unsubscribing.
>> >
>> > I suppose that it might be possible to provide a link taking one
>> > directly to this second page, but:
>> >
>> > (1) It would add clutter (I'm sure we don't want to delete the link to
>> > the primary help page).
>> >
>> > (2) The password protection might get complicated; I don't know about
>> > such matters.
>> >
>> > (3) I don't think we want to waste time and resources helping people who
>> > are too stupid and illiterate to find their way to the unsubscribe
>> > facility on the basis of what is already provided.  They shouldn't be
>> > R users in the first place.  One needs at least two grey cells to rub
>> > together to deal with R.
>> >
>> > cheers,
>> >
>> > Rolf Turner
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Sun Nov 30 16:03:36 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 30 Nov 2014 07:03:36 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <A7C5FFC17AB.0000013Bjrkrideau@inbox.com>
References: <547a19ee020000cb0011bdf0@smtp.medicine.umaryland.edu>
	<547a7d73.3030107@auckland.ac.nz>
	<cafh18f22h7bqtdc_xu6aw83ekgedpw-v5+agzuwy4fasnt=rfw@mail.gmail.com>
	<cafdcvcrtg5h=2ksc_8agqry82jcubx-skg66yvt_e29pytquja@mail.gmail.com>
	<547a2994020000cb0011bdf6@smtp.medicine.umaryland.edu>
	<5e300a2f-61c6-48e8-9224-0a2f0e978f12@dcn.davis.ca.us>
	<84fbe77f-a67d-496b-8325-a6b974057145@dcn.davis.ca.us>
	<547ac1d8020000cb0011be26@smtp.medicine.umaryland.edu>
	<547B2364.2010305@aghmed.fsnet.co.uk>
	<A7C5FFC17AB.0000013Bjrkrideau@inbox.com>
Message-ID: <CAFDcVCRKCE2aRBN_qrQPj_8y8uv-amKdWcVo1zt2OjO_XQPz6g@mail.gmail.com>

My reply on "raw" email headers was regarding a suggestion on having Gmail
and similar clients automatically to add an easy-to-spot unsubscribe
link/button. No one here suggested the user him-/herself should read those
headers.

Henrik
On Nov 30, 2014 6:16 AM, "John Kane" <jrkrideau at inbox.com> wrote:

> The problem seems to be that the people who have a desire to unsubscrbe
> and post here are not the most sophisticated of users and expecting them to
> know how to track down the raw email or even to realise the message at the
> bottom of the post is meant to convey much of anything is not likely to
> occur to them.
>
> I have not had any need to look for the raw email and, while it only took
> a few seconds to find it in my email reader, one has to know it exists
> before one can look for it.
>
> I probably have not looked at a raw email for 3-5 years. Why would I?
>
> The chances of a newbie, possibly without much "computer" experience vs
> user of MS Office and E-mail even being aware such a thing exists is slig\t
> (snowballl in ... ?)
>
> A slight change to the footer seems like a good idea.
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: info at aghmed.fsnet.co.uk
> > Sent: Sun, 30 Nov 2014 14:02:12 +0000
> > To: jsorkin at grecc.umaryland.edu, hb at biostat.ucsf.edu
> > Subject: Re: [R] please please unsubscribe!!!!!!!!!!!!!!!!
> >
> > Dear John
> >
> > Perhaps you have set your mail client to hide them? Your email certainly
> > has them when I go Options | View | Headers | All in Thunderbird.
> >
> > Michael
> >
> > On 30/11/2014 12:05, John Sorkin wrote:
> >> The headers listed below as being part of the ?raw" email messages are
> >> not seen, at least not in the messages I receive.
> >> John
> >>
> >>> John David Sorkin M.D., Ph.D.
> >>> Professor of Medicine
> >>> Chief, Biostatistics and Informatics
> >>> University of Maryland School of Medicine Division of Gerontology and
> >> Geriatric Medicine
> >>> Baltimore VA Medical Center
> >>> 10 North Greene Street
> >>> GRECC (BT/18/GR)
> >>> Baltimore, MD 21201-1524
> >>> (Phone) 410-605-7119
> >>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >>
> >>
> >>> On Nov 29, 2014, at 11:22 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
> >> wrote:
> >>>
> >>> On Sat, Nov 29, 2014 at 7:32 PM, Jeff Newmiller
> >>> <jdnewmil at dcn.davis.ca.us> wrote:
> >>>> To be fair, Rolf, they have already found difficulty and are trying
> >> to find their way out of this torrent, and impeding their way is not in
> >> anyone's interest.
> >>>>
> >>>> John: I agree that adding the word "unsubscribe" to the footer would
> >> probably help those lost enough to be mailing the list. The existing web
> >> page does have that word on it, though.
> >>>>
> >>>> Fabio: I was unaware of the unsubscribe header... looks interesting,
> >> though I would be concerned that it seems like it might bypass the
> >> password protection currently in place, making it susceptible to abuse.
> >> However, there seem to be quite a lot of organizations using it so it
> >> may work better than my initial impression tells me it does.
> >>>
> >>> FYI, if you look at the raw email messages, they all have the
> >>> following in the header:
> >>>
> >>> X-Mailman-Version: 2.1.18-1
> >>> Precedence: list
> >>> List-Id: "Main R Mailing List: Primary help" <r-help.r-project.org>
> >>> List-Unsubscribe: <https://stat.ethz.ch/mailman/options/r-help>,
> >>> <mailto:r-help-request at r-project.org?subject=unsubscribe>
> >>> List-Archive: <https://stat.ethz.ch/pipermail/r-help/>
> >>> List-Post: <mailto:r-help at r-project.org>
> >>> List-Help: <mailto:r-help-request at r-project.org?subject=help>
> >>> List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
> >>> <mailto:r-help-request at r-project.org?subject=subscribe>
> >>>
> >>> Note that "List-Unsubscribe" field
> >>> [http://www.faqs.org/rfcs/rfc2369.html].  That does not seem to be
> >>> enough to have Gmail add a "unsubscribe" button/link (which is indeed
> >>> a useful UX feature).  Google mention some more requirements in
> >>> https://support.google.com/mail/answer/81126#unsub, particularly
> >>> "'Precedence: bulk'", which I find on since mailing lists typically
> >>> use "list" just as r-help does.  I also found a mentioning on "DKIM
> >>> key signature" being required
> >>>
> >> [
> http://blog.mailchimp.com/gmails-new-unsubscribe-link-and-feedback-loop/].
> >>> So, not sure how easy it is to enable all this for the list(s) (which
> >>> are handled by Mailman).
> >>>
> >>> My $.02
> >>>
> >>> /Henrik
> >>>
> >>>
> >>>>
> >>>>
> >>>>
> >>
> ---------------------------------------------------------------------------
> >>>> Jeff Newmiller                        The     .....       .....  Go
> >> Live...
> >>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >> Go...
> >>>>                                       Live:   OO#.. Dead: OO#..
> >> Playing
> >>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >>>> /Software/Embedded Controllers)               .OO#.       .OO#.
> >> rocks...1k
> >>>>
> >>
> ---------------------------------------------------------------------------
> >>>> Sent from my phone. Please excuse my brevity.
> >>>>
> >>>>> On November 29, 2014 6:14:11 PM PST, Rolf Turner
> >> <r.turner at auckland.ac.nz> wrote:
> >>>>>> On 30/11/14 14:16, John Sorkin wrote:
> >>>>>> I don't see a link that is labeled "unsubscribe".
> >>>>>
> >>>>> <SNIP>
> >>>>>
> >>>>>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller
> >>>>> <jdnewmil at dcn.davis.CA.us>
> >>>>>> wrote:
> >>>>>>>
> >>>>>>> In what way would that be unlike the link that is already there?
> >>>>>
> >>>>> <SNIP>
> >>>>>
> >>>>>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
> >>>>>> <jsorkin at grecc.umaryland.edu> wrote:
> >>>>>>>>> Requests like this appear from time to time. Would it make sense
> >>>>> to
> >>>>>>>> add a link to the bottom of the email messages generated by the
> >>>>> mail
> >>>>>>>> program that is labeled>>> Well, there is no "unsubscribe" page as
> >>>>>>>> such.  The link given, i.e.
> >>>>>
> >>>>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>
> >>>>> takes you to the primary help page. That provides a link to a
> >> (password
> >>>>>
> >>>>> protected) page where you can handle all matters pertaining to your
> >>>>> r-help subscription, including unsubscribing.
> >>>>>
> >>>>> I suppose that it might be possible to provide a link taking one
> >>>>> directly to this second page, but:
> >>>>>
> >>>>> (1) It would add clutter (I'm sure we don't want to delete the link
> >> to
> >>>>> the primary help page).
> >>>>>
> >>>>> (2) The password protection might get complicated; I don't know
> >> about
> >>>>> such matters.
> >>>>>
> >>>>> (3) I don't think we want to waste time and resources helping people
> >>>>> who
> >>>>> are too stupid and illiterate to find their way to the unsubscribe
> >>>>> facility on the basis of what is already provided.  They shouldn't
> >> be
> >>>>> R users in the first place.  One needs at least two grey cells to
> >> rub
> >>>>> together to deal with R.
> >>>>>
> >>>>> cheers,
> >>>>>
> >>>>> Rolf Turner
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> Confidentiality Statement:
> >> This email message, including any attachments, is for ...{{dropped:22}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
>
>
>

	[[alternative HTML version deleted]]


From Pradip.Muhuri at samhsa.hhs.gov  Sun Nov 30 16:10:33 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 30 Nov 2014 15:10:33 +0000
Subject: [R] no non-missing arguments to max;
	returning -Inf [2(dplyr/mutate()]
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C3892F2FE@PL-EMSMB20.ees.hhs.gov>

Hello,

With dplyr mutate(), the code below creates a new column (oiddate), which is the maximum of the four dates (mrjdate,cocdate, inhdate, haldate).  The code seems to provide the results (presented below) I desired.  But, the issue is that I am getting  the following warning message:  1: In max(13113, NA_real_, 14336, NA_real_, na.rm = TRUE) :   no non-missing arguments to max; returning -Inf 2.

Is this warning message harmful?  Any hints how to tweak the code in order to correct the problem or avoid this message?

Please note that I did not get this warning message when I executed the code on the reproducible example data posted to this forum in the past  and that I am now getting this warning when applying the code on the actual working data file.   Thanks to Arun, Mark and others on this forum for their help with tweaking the code in the past.   Sorry for not providing the reproducible example this time.  

Thanks,

Pradip Muhuri

#################  R script followed by console (log and output) #############
setwd ("H:/R/cis_study")
library(dplyr)
load("xd2012.rdata")
# create a new column of the max date from four dates

 test <- xd2012 %>% 
  rowwise() %>%
  mutate( oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0),
          oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate, na.rm=TRUE), origin='1970-01-01')) %>%
  filter(oidflag==1)  %>%
  select( mrjdate, cocdate, inhdate, haldate,  oiddate)
  
head(test)
warnings(2)
    

##########################  below is from the console  ####################
load("xd2012.rdata")
> # create a new column of the max date from four dates
> 
>  test <- xd2012 %>% 
+   rowwise() %>%
+   mutate( oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0),
+           oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate, na.rm=TRUE), origin='1970-01-01')) %>%
+   filter(oidflag==1)  %>%
+   select( mrjdate, cocdate, inhdate, haldate,  oiddate)
There were 50 or more warnings (use warnings() to see the first 50)
>   
> head(test)
Source: local data frame [6 x 5]

     mrjdate cocdate    inhdate    haldate    oiddate
1 2003-02-22    <NA> 2006-03-10 2005-09-17 2006-03-10
2 2007-12-07    <NA>       <NA>       <NA> 2007-12-07
3 1994-05-15    <NA>       <NA>       <NA> 1994-05-15
4 2003-04-19    <NA>       <NA>       <NA> 2003-04-19
5 2009-11-13    <NA>       <NA>       <NA> 2009-11-13
6 1973-10-08    <NA>       <NA> 1974-01-04 1974-01-04
> warnings(2)
Warning messages:
1: In max(13113, NA_real_, 14336, NA_real_, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf 2
2: In max(13113, NA_real_, 14336, NA_real_, na.rm = TRUE) :
no non-missing arguments to max; returning -Inf 2


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip (SAMHSA/CBHSQ)
Sent: Monday, November 10, 2014 1:09 PM
To: 'Mark Sharp'
Cc: r-help at r-project.org
Subject: Re: [R] range () does not remove NA's with complete.cases() for dates (dplyr/mutate)

Mark,

Thank you very much for further looking into this issue.  So, the "ugly" solution is better!  Would you like to bring to Hadley's attention that mutate does set the NA value for the new column?

Regards,

Pradip

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----
From: Mark Sharp [mailto:msharp at TxBiomed.org] 
Sent: Monday, November 10, 2014 12:23 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org
Subject: Re: [R] range () does not remove NA's with complete.cases() for dates (dplyr/mutate)

Pradip,

For some reason mutate is not setting the is.NA value for the new column. Note the output below using your data structures.

> ## It looks at first as if the second element of both columns are NA.
> data2$mrjdate[2]
[1] NA
> data2$oiddate[2]
[1] NA
> ## for convenience
> mrj <- data2$mrjdate[2]
> oid <- data2$oiddate[2]
> mode(mrj)
[1] "numeric"
> mode(oid)
[1] "numeric"
> str(mrj)
 Date[1:1], format: NA
> str(oid)
 Date[1:1], format: NA
> class(mrj)
[1] "Date"
> class(oid)
[1] "Date"
> ## But note:
> identical(mrj, oid)
[1] FALSE
> all.equal(mrj, oid)
[1] "'is.NA' value mismatch: 0 in current 1 in target"
## functioning code
data2$mrjdate[2]
data2$oiddate[2]
mrj <- data2$mrjdate[2]
oid <- data2$oiddate[2]
mode(mrj)
mode(oid)
str(mrj)
str(oid)
class(mrj)
class(oid)
# But note:
identical(mrj, oid)
all.equal(mrj, oid)

## This ugly solution does not have the problem.
> data3 <- data1
> data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
+   if (all(is.na(unlist(data1[row, -1])))) {
+     max_d <- NA
+   } else {
+     max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
+   }
+   max_d}),
+   origin = "1970-01-01")
>
> range(data3$mrjdate[complete.cases(data3$mrjdate)])
[1] "2004-11-04" "2009-10-24"
> range(data3$cocdate[complete.cases(data3$cocdate)])
[1] "2005-08-10" "2011-10-05"
> range(data3$inhdate[complete.cases(data3$inhdate)])
[1] "2005-07-07" "2011-10-13"
> range(data3$haldate[complete.cases(data3$haldate)])
[1] "2007-11-07" "2011-11-04"
> range(data3$oiddate[complete.cases(data3$oiddate)])
[1] "2006-09-01" "2011-11-04"
>
Working code below.

data3 <- data1
data3$oiddate <- as.Date(sapply(seq_along(data3$id), function(row) {
  if (all(is.na(unlist(data1[row, -1])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

range(data3$mrjdate[complete.cases(data3$mrjdate)])
range(data3$cocdate[complete.cases(data3$cocdate)])
range(data3$inhdate[complete.cases(data3$inhdate)])
range(data3$haldate[complete.cases(data3$haldate)])
range(data3$oiddate[complete.cases(data3$oiddate)])


On Nov 10, 2014, at 10:10 AM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:

> Hello,
>
> The range() with complete.cases() removes NA's for the date variables that are read from a data frame.  However, the issue is that the same function does not remove NA's for the other date variable that is created using the dplyr/mutate().  The console and the reproducible example are given below. Any advice how to resolve this issue would be appreciated.
>
> Thanks,
>
> Pradip Muhuri
>
>
> #################  cut and pasted from the R console ####################
>
> id    mrjdate    cocdate    inhdate    haldate    oiddate
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>>
>> # range of dates
>>
>> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> [1] "2004-11-04" "2009-10-24"
>> range(data2$cocdate[complete.cases(data2$cocdate)])
> [1] "2005-08-10" "2011-10-05"
>> range(data2$inhdate[complete.cases(data2$inhdate)])
> [1] "2005-07-07" "2011-10-13"
>> range(data2$haldate[complete.cases(data2$haldate)])
> [1] "2007-11-07" "2011-11-04"
>> range(data2$oiddate[complete.cases(data2$oiddate)])
> [1] NA           "2011-11-04"
>
>
> ################  reproducible code #############################
>
> library(dplyr)
> library(lubridate)
> library(zoo)
> # data object - description of the
>
> temp <- "id  mrjdate cocdate inhdate haldate
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> 2             NA         NA         NA         NA
> 3     2009-10-24         NA 2011-10-13         NA
> 4     2007-10-10         NA         NA         NA
> 5     2006-09-01 2005-08-10         NA         NA
> 6     2007-09-04 2011-10-05         NA         NA
> 7     2005-10-25         NA         NA 2011-11-04"
>
> # read the data object
>
> data1 <- read.table(textConnection(temp),
>                    colClasses=c("character", "Date", "Date", "Date", "Date"),
>                    header=TRUE, as.is=TRUE
>                    )
>
>
> # create a new column
>
> data2 <- data1 %>%
>     rowwise() %>%
>      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>                                                               na.rm=TRUE), origin='1970-01-01'))
>
> # print records
>
> print (data2)
>
> # range of dates
>
> range(data2$mrjdate[complete.cases(data2$mrjdate)])
> range(data2$cocdate[complete.cases(data2$cocdate)])
> range(data2$inhdate[complete.cases(data2$inhdate)])
> range(data2$haldate[complete.cases(data2$haldate)])
> range(data2$oiddate[complete.cases(data2$oiddate)])
>
>
>
>
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Nov 30 16:13:31 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 30 Nov 2014 07:13:31 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <A7C5FFC17AB.0000013Bjrkrideau@inbox.com>
References: <547a19ee020000cb0011bdf0@smtp.medicine.umaryland.edu>
	<547a7d73.3030107@auckland.ac.nz>
	<cafh18f22h7bqtdc_xu6aw83ekgedpw-v5+agzuwy4fasnt=rfw@mail.gmail.com>
	<cafdcvcrtg5h=2ksc_8agqry82jcubx-skg66yvt_e29pytquja@mail.gmail.com>
	<547a2994020000cb0011bdf6@smtp.medicine.umaryland.edu>
	<5e300a2f-61c6-48e8-9224-0a2f0e978f12@dcn.davis.ca.us>
	<84fbe77f-a67d-496b-8325-a6b974057145@dcn.davis.ca.us>
	<547ac1d8020000cb0011be26@smtp.medicine.umaryland.edu>
	<A7C5FFC17AB.0000013Bjrkrideau@inbox.com>
Message-ID: <43AC70EB-A070-40C7-8250-D0ECB587D6D0@dcn.davis.CA.us>

No one is suggesting that anyone read raw headers. This is a mechanism that requires features on both the list server end and the client end...  but if newbies are using modern facilities then that would be exactly their situation. Please read up on the mechanism at least a little bit before criticizing it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 30, 2014 6:16:55 AM PST, John Kane <jrkrideau at inbox.com> wrote:
>The problem seems to be that the people who have a desire to unsubscrbe
>and post here are not the most sophisticated of users and expecting
>them to know how to track down the raw email or even to realise the
>message at the bottom of the post is meant to convey much of anything
>is not likely to occur to them. 
>
>I have not had any need to look for the raw email and, while it only
>took a few seconds to find it in my email reader, one has to know it
>exists before one can look for it. 
>
>I probably have not looked at a raw email for 3-5 years. Why would I?
>
>The chances of a newbie, possibly without much "computer" experience vs
>user of MS Office and E-mail even being aware such a thing exists is
>slig\t (snowballl in ... ?)
>
>A slight change to the footer seems like a good idea.
>
>John Kane
>Kingston ON Canada
>
>
>> -----Original Message-----
>> From: info at aghmed.fsnet.co.uk
>> Sent: Sun, 30 Nov 2014 14:02:12 +0000
>> To: jsorkin at grecc.umaryland.edu, hb at biostat.ucsf.edu
>> Subject: Re: [R] please please unsubscribe!!!!!!!!!!!!!!!!
>> 
>> Dear John
>> 
>> Perhaps you have set your mail client to hide them? Your email
>certainly
>> has them when I go Options | View | Headers | All in Thunderbird.
>> 
>> Michael
>> 
>> On 30/11/2014 12:05, John Sorkin wrote:
>>> The headers listed below as being part of the ?raw" email messages
>are
>>> not seen, at least not in the messages I receive.
>>> John
>>> 
>>>> John David Sorkin M.D., Ph.D.
>>>> Professor of Medicine
>>>> Chief, Biostatistics and Informatics
>>>> University of Maryland School of Medicine Division of Gerontology
>and
>>> Geriatric Medicine
>>>> Baltimore VA Medical Center
>>>> 10 North Greene Street
>>>> GRECC (BT/18/GR)
>>>> Baltimore, MD 21201-1524
>>>> (Phone) 410-605-7119
>>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>> 
>>> 
>>>> On Nov 29, 2014, at 11:22 PM, Henrik Bengtsson
><hb at biostat.ucsf.edu>
>>> wrote:
>>>> 
>>>> On Sat, Nov 29, 2014 at 7:32 PM, Jeff Newmiller
>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>> To be fair, Rolf, they have already found difficulty and are
>trying
>>> to find their way out of this torrent, and impeding their way is not
>in
>>> anyone's interest.
>>>>> 
>>>>> John: I agree that adding the word "unsubscribe" to the footer
>would
>>> probably help those lost enough to be mailing the list. The existing
>web
>>> page does have that word on it, though.
>>>>> 
>>>>> Fabio: I was unaware of the unsubscribe header... looks
>interesting,
>>> though I would be concerned that it seems like it might bypass the
>>> password protection currently in place, making it susceptible to
>abuse.
>>> However, there seem to be quite a lot of organizations using it so
>it
>>> may work better than my initial impression tells me it does.
>>>> 
>>>> FYI, if you look at the raw email messages, they all have the
>>>> following in the header:
>>>> 
>>>> X-Mailman-Version: 2.1.18-1
>>>> Precedence: list
>>>> List-Id: "Main R Mailing List: Primary help" <r-help.r-project.org>
>>>> List-Unsubscribe: <https://stat.ethz.ch/mailman/options/r-help>,
>>>> <mailto:r-help-request at r-project.org?subject=unsubscribe>
>>>> List-Archive: <https://stat.ethz.ch/pipermail/r-help/>
>>>> List-Post: <mailto:r-help at r-project.org>
>>>> List-Help: <mailto:r-help-request at r-project.org?subject=help>
>>>> List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
>>>> <mailto:r-help-request at r-project.org?subject=subscribe>
>>>> 
>>>> Note that "List-Unsubscribe" field
>>>> [http://www.faqs.org/rfcs/rfc2369.html].  That does not seem to be
>>>> enough to have Gmail add a "unsubscribe" button/link (which is
>indeed
>>>> a useful UX feature).  Google mention some more requirements in
>>>> https://support.google.com/mail/answer/81126#unsub, particularly
>>>> "'Precedence: bulk'", which I find on since mailing lists typically
>>>> use "list" just as r-help does.  I also found a mentioning on "DKIM
>>>> key signature" being required
>>>> 
>>>
>[http://blog.mailchimp.com/gmails-new-unsubscribe-link-and-feedback-loop/].
>>>> So, not sure how easy it is to enable all this for the list(s)
>(which
>>>> are handled by Mailman).
>>>> 
>>>> My $.02
>>>> 
>>>> /Henrik
>>>> 
>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>
>---------------------------------------------------------------------------
>>>>> Jeff Newmiller                        The     .....       ..... 
>Go
>>> Live...
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>>> Go...
>>>>>                                       Live:   OO#.. Dead: OO#..
>>> Playing
>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>>> 
>>>
>---------------------------------------------------------------------------
>>>>> Sent from my phone. Please excuse my brevity.
>>>>> 
>>>>>> On November 29, 2014 6:14:11 PM PST, Rolf Turner
>>> <r.turner at auckland.ac.nz> wrote:
>>>>>>> On 30/11/14 14:16, John Sorkin wrote:
>>>>>>> I don't see a link that is labeled "unsubscribe".
>>>>>> 
>>>>>> <SNIP>
>>>>>> 
>>>>>>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller
>>>>>> <jdnewmil at dcn.davis.CA.us>
>>>>>>> wrote:
>>>>>>>> 
>>>>>>>> In what way would that be unlike the link that is already
>there?
>>>>>> 
>>>>>> <SNIP>
>>>>>> 
>>>>>>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>>>>>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>>>>>>> Requests like this appear from time to time. Would it make
>sense
>>>>>> to
>>>>>>>>> add a link to the bottom of the email messages generated by
>the
>>>>>> mail
>>>>>>>>> program that is labeled>>> Well, there is no "unsubscribe"
>page as
>>>>>>>>> such.  The link given, i.e.
>>>>>> 
>>>>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> 
>>>>>> takes you to the primary help page. That provides a link to a
>>> (password
>>>>>> 
>>>>>> protected) page where you can handle all matters pertaining to
>your
>>>>>> r-help subscription, including unsubscribing.
>>>>>> 
>>>>>> I suppose that it might be possible to provide a link taking one
>>>>>> directly to this second page, but:
>>>>>> 
>>>>>> (1) It would add clutter (I'm sure we don't want to delete the
>link
>>> to
>>>>>> the primary help page).
>>>>>> 
>>>>>> (2) The password protection might get complicated; I don't know
>>> about
>>>>>> such matters.
>>>>>> 
>>>>>> (3) I don't think we want to waste time and resources helping
>people
>>>>>> who
>>>>>> are too stupid and illiterate to find their way to the
>unsubscribe
>>>>>> facility on the basis of what is already provided.  They
>shouldn't
>>> be
>>>>>> R users in the first place.  One needs at least two grey cells to
>>> rub
>>>>>> together to deal with R.
>>>>>> 
>>>>>> cheers,
>>>>>> 
>>>>>> Rolf Turner
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> Confidentiality Statement:
>>> This email message, including any attachments, is for
>...{{dropped:22}}
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>____________________________________________________________
>Can't remember your password? Do you need a strong and secure password?
>Use Password manager! It stores your passwords & protects your account.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Nov 30 16:20:46 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 30 Nov 2014 10:20:46 -0500
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>	<547A7D73.3030107@auckland.ac.nz>
	<547A87CF.2060305@gmail.com>	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
Message-ID: <547B35CE.808@gmail.com>

On 30/11/2014, 9:56 AM, F?bio Magalh?es wrote:
> My bad, r-help messages indeed have the unsubscribe header set. Also,
> at least for Gmail a "Precedence: bulk" should be set in order to this
> mechanism to work, as Henrik pointed out.
> 
> Currently the raw headers set precedence to "list". I don't know the
> technical differences of list and bulk, so maybe switching from one to
> the other can impose some tradeoffs.

It would break everyone's filters that currently work, to help Gmail's
filters that don't work.  Seems like a pretty bad tradeoff to me.

Why don't you complain to Google about Gmail?

Duncan Murdoch

> 
> So I see three possibilities: leave as it is now, switch precedence to
> "bulk" if it doesn't interfere on list behavior and have at least a
> small unsubscribe button on some email clients or add an unsubscribe
> link to footer.
> 
> #! F?bio
> 
> 
> On Sun, Nov 30, 2014 at 12:30 PM, Ranjan Maitra
> <maitra.mbox.ignored at inbox.com> wrote:
>> I agree with this sentiment and suggestion. I can not see much of a downside to it, with the exception that most of these "unsophisticated" users will probably not even bother reading it. But then we would all be back in the current situation, not worse.
>>
>> Ranjan
>>
>> On Sat, 29 Nov 2014 21:58:23 -0500 listserve <tomuxiong at gmail.com> wrote:
>>
>>> Any mailing list which respects its recipients makes unsubscribing as
>>> easy as possible. If users are having trouble doing so, it's clearly not
>>> easy enough.
>>>
>>> I think putting a directly link in every message is certainly the right
>>> thing to do.
>>>
>>> On 11/29/2014 09:14 PM, Rolf Turner wrote:
>>>> On 30/11/14 14:16, John Sorkin wrote:
>>>>> I don't see a link that is labeled "unsubscribe".
>>>>
>>>> <SNIP>
>>>>
>>>>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>>>>> wrote:
>>>>>>
>>>>>> In what way would that be unlike the link that is already there?
>>>>
>>>> <SNIP>
>>>>
>>>>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>>>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>>>>> Requests like this appear from time to time. Would it make sense to
>>>>>>> add a link to the bottom of the email messages generated by the mail
>>>>>>> program that is labeled and goes directly to the unsubscribe page?
>>>>
>>>> Well, there is no "unsubscribe" page as such.  The link given, i.e.
>>>>
>>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>>
>>>> takes you to the primary help page. That provides a link to a (password
>>>> protected) page where you can handle all matters pertaining to your
>>>> r-help subscription, including unsubscribing.
>>>>
>>>> I suppose that it might be possible to provide a link taking one
>>>> directly to this second page, but:
>>>>
>>>> (1) It would add clutter (I'm sure we don't want to delete the link to
>>>> the primary help page).
>>>>
>>>> (2) The password protection might get complicated; I don't know about
>>>> such matters.
>>>>
>>>> (3) I don't think we want to waste time and resources helping people who
>>>> are too stupid and illiterate to find their way to the unsubscribe
>>>> facility on the basis of what is already provided.  They shouldn't be
>>>> R users in the first place.  One needs at least two grey cells to rub
>>>> together to deal with R.
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>>
>> ____________________________________________________________
>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alaios at yahoo.com  Sun Nov 30 10:26:52 2014
From: alaios at yahoo.com (Alaios)
Date: Sun, 30 Nov 2014 09:26:52 +0000 (UTC)
Subject: [R] starting with mixture distribution
Message-ID: <1689805307.1646617.1417339612667.JavaMail.yahoo@jws10082.mail.ne1.yahoo.com>

Hi.I was using the last night the fitdistr package to start with some fitting. I have some data sets that even though have a very gaussian distribution it looks like that also it has some very heavy tails, that can not be accurately be modelled by a gaussian distribution.Where should I give a try with mixture of distribution?
RegardsAlex


	[[alternative HTML version deleted]]


From glennmschultz at me.com  Sun Nov 30 16:15:26 2014
From: glennmschultz at me.com (Glenn Schultz)
Date: Sun, 30 Nov 2014 09:15:26 -0600
Subject: [R] cyclic dependency when building a package
Message-ID: <956EB8F8-DFD5-43D2-ACC4-640437AD16E9@me.com>

Hi All, 

I am working on a package BondLab for the analysis of fixed income securities.  Building the package results in the following:

Error in loadNamespace(package, c(which.lib.loc, lib.loc)) : 
cyclic namespace dependency detected when loading ?BondLab?, already loading ?BondLab?


It occurs when I set the generic for the function mortgagecashflow.  Further if a function uses mortgagecashflow, similarly its generic, when set, causes the above error.  Other generics do not throw this error so I am quite sure it is mortgagecashflow.  The package and the code can be found on github.  
https://github.com/glennmschultz/BondLab.git

I have been trying to figure this out for a couple of months to no avail. If anyone has familiarity with this issue I would certainly appreciate any help with the issue.

Thanks,
Glenn 


From fmagalhaes at gmail.com  Sun Nov 30 16:51:06 2014
From: fmagalhaes at gmail.com (=?UTF-8?B?RsOhYmlvIE1hZ2FsaMOjZXM=?=)
Date: Sun, 30 Nov 2014 13:51:06 -0200
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <547B35CE.808@gmail.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
Message-ID: <CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>

Duncan,

You are right, I've assumed precedence wouldn't break anything, but
looking a little more into this issue it seems some people use filters
based on this header and Gmail seems to be the only client that needs
bulk precedence set to make unsubscribe link work.

I think the question boils down to putting an unsubscribe link on footer or not.

#! F?bio


On Sun, Nov 30, 2014 at 1:20 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 30/11/2014, 9:56 AM, F?bio Magalh?es wrote:
>> My bad, r-help messages indeed have the unsubscribe header set. Also,
>> at least for Gmail a "Precedence: bulk" should be set in order to this
>> mechanism to work, as Henrik pointed out.
>>
>> Currently the raw headers set precedence to "list". I don't know the
>> technical differences of list and bulk, so maybe switching from one to
>> the other can impose some tradeoffs.
>
> It would break everyone's filters that currently work, to help Gmail's
> filters that don't work.  Seems like a pretty bad tradeoff to me.
>
> Why don't you complain to Google about Gmail?
>
> Duncan Murdoch
>
>>
>> So I see three possibilities: leave as it is now, switch precedence to
>> "bulk" if it doesn't interfere on list behavior and have at least a
>> small unsubscribe button on some email clients or add an unsubscribe
>> link to footer.
>>
>> #! F?bio
>>
>>
>> On Sun, Nov 30, 2014 at 12:30 PM, Ranjan Maitra
>> <maitra.mbox.ignored at inbox.com> wrote:
>>> I agree with this sentiment and suggestion. I can not see much of a downside to it, with the exception that most of these "unsophisticated" users will probably not even bother reading it. But then we would all be back in the current situation, not worse.
>>>
>>> Ranjan
>>>
>>> On Sat, 29 Nov 2014 21:58:23 -0500 listserve <tomuxiong at gmail.com> wrote:
>>>
>>>> Any mailing list which respects its recipients makes unsubscribing as
>>>> easy as possible. If users are having trouble doing so, it's clearly not
>>>> easy enough.
>>>>
>>>> I think putting a directly link in every message is certainly the right
>>>> thing to do.
>>>>
>>>> On 11/29/2014 09:14 PM, Rolf Turner wrote:
>>>>> On 30/11/14 14:16, John Sorkin wrote:
>>>>>> I don't see a link that is labeled "unsubscribe".
>>>>>
>>>>> <SNIP>
>>>>>
>>>>>>> On Nov 29, 2014, at 7:35 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
>>>>>> wrote:
>>>>>>>
>>>>>>> In what way would that be unlike the link that is already there?
>>>>>
>>>>> <SNIP>
>>>>>
>>>>>>> On November 29, 2014 4:09:29 PM PST, John Sorkin
>>>>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>>>>>> Requests like this appear from time to time. Would it make sense to
>>>>>>>> add a link to the bottom of the email messages generated by the mail
>>>>>>>> program that is labeled and goes directly to the unsubscribe page?
>>>>>
>>>>> Well, there is no "unsubscribe" page as such.  The link given, i.e.
>>>>>
>>>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>
>>>>> takes you to the primary help page. That provides a link to a (password
>>>>> protected) page where you can handle all matters pertaining to your
>>>>> r-help subscription, including unsubscribing.
>>>>>
>>>>> I suppose that it might be possible to provide a link taking one
>>>>> directly to this second page, but:
>>>>>
>>>>> (1) It would add clutter (I'm sure we don't want to delete the link to
>>>>> the primary help page).
>>>>>
>>>>> (2) The password protection might get complicated; I don't know about
>>>>> such matters.
>>>>>
>>>>> (3) I don't think we want to waste time and resources helping people who
>>>>> are too stupid and illiterate to find their way to the unsubscribe
>>>>> facility on the basis of what is already provided.  They shouldn't be
>>>>> R users in the first place.  One needs at least two grey cells to rub
>>>>> together to deal with R.
>>>>>
>>>>> cheers,
>>>>>
>>>>> Rolf Turner
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>>>
>>> ____________________________________________________________
>>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From Achim.Zeileis at uibk.ac.at  Sun Nov 30 16:52:10 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 30 Nov 2014 16:52:10 +0100 (CET)
Subject: [R] TSLS / 2SLS with a binary outcome
In-Reply-To: <CAMMiRhxs58u8YhapqBB+kuFnOHxm7GK5gmDhj0rvyGb4Jt5HJw@mail.gmail.com>
References: <CAMMiRhxs58u8YhapqBB+kuFnOHxm7GK5gmDhj0rvyGb4Jt5HJw@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1411301638540.17654@paninaro.uibk.ac.at>

On Sun, 30 Nov 2014, Philip Robinson wrote:

> Hi,
>
> I am wanting to complete 2 stage least squared regression with a binary 
> outcome. I have found and implemented a continuous outcome with tsls() 
> from the sen package or ivreg() from the AER package.
>
> However I am struggling to find a package/function that implements a 
> function for a binary outcome. If someone could knows of a package or 
> function and could help by pointing me in the right direction I would be 
> most grateful.

Various approaches are used for this in the literature. To the best of my 
knowledge there is no approach that is widely regarded as being "the best" 
but I'm not an expert in this field. A recent overview is in Clarke & 
Windmeijer (2012), JASA 107(500), 1638-1652. 
doi:10.1080/01621459.2012.734171.

Some authors simply fit a linear probability model (i.e., ivreg on a 0/1 
response) but this may lead to poor fits. Other related packages on CRAN 
include ivprobit, ivlewbel, LARF, among others.

hth,
Z

> Kind regards
> Philip
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Achim.Zeileis at uibk.ac.at  Sun Nov 30 17:02:25 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 30 Nov 2014 17:02:25 +0100 (CET)
Subject: [R] starting with mixture distribution
In-Reply-To: <1689805307.1646617.1417339612667.JavaMail.yahoo@jws10082.mail.ne1.yahoo.com>
References: <1689805307.1646617.1417339612667.JavaMail.yahoo@jws10082.mail.ne1.yahoo.com>
Message-ID: <alpine.DEB.2.11.1411301659580.17654@paninaro.uibk.ac.at>

On Sun, 30 Nov 2014, Alaios via R-help wrote:

> Hi.I was using the last night the fitdistr package to start with some 
> fitting. I have some data sets that even though have a very gaussian 
> distribution it looks like that also it has some very heavy tails, that 
> can not be accurately be modelled by a gaussian distribution.Where 
> should I give a try with mixture of distribution?

An overview of available distributions and corresponding fitting functions 
is in the "Distributions" task view. Finite mixture models and model-based 
clustering is discussed in the "Cluster" task view. See:
http://CRAN.R-project.org/view=Distributions
http://CRAN.R-project.org/view=Cluster

> RegardsAlex
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mtmorgan at fredhutch.org  Sun Nov 30 17:42:10 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sun, 30 Nov 2014 08:42:10 -0800
Subject: [R] cyclic dependency when building a package
In-Reply-To: <956EB8F8-DFD5-43D2-ACC4-640437AD16E9@me.com>
References: <956EB8F8-DFD5-43D2-ACC4-640437AD16E9@me.com>
Message-ID: <547B48E2.3020505@fredhutch.org>

On 11/30/2014 07:15 AM, Glenn Schultz wrote:
> Hi All,
>
> I am working on a package BondLab for the analysis of fixed income securities.  Building the package results in the following:
>
> Error in loadNamespace(package, c(which.lib.loc, lib.loc)) :
> cyclic namespace dependency detected when loading ?BondLab?, already loading ?BondLab?
>
>
> It occurs when I set the generic for the function mortgagecashflow.  Further if a function uses mortgagecashflow, similarly its generic, when set, causes the above error.  Other generics do not throw this error so I am quite sure it is mortgagecashflow.  The package and the code can be found on github.
> https://github.com/glennmschultz/BondLab.git
>
> I have been trying to figure this out for a couple of months to no avail. If anyone has familiarity with this issue I would certainly appreciate any help with the issue.
>

Hi Glenn --

The root of the problem is that you are defining both a generic and a 
plain-old-function named MortgageCashFlow -- one or the other and you're fine.

R CMD INSTALL pkgA, where pkgA contains a single R file R/test.R

setGeneric("foo", function(x, ...) standardGeneric("foo"))
foo <- function(x, ...) {}

also generates this; maybe you meant something like

.foo <- function(x, ...) {}
setGeneric("foo", function(x, ...) standardGeneric("foo"),
            useAsDefault=".foo")

or simply reversing the order of the declarations

foo <- function(x, ...) {}
setGeneric("foo", function(x, ...) standardGeneric("foo"))


?

Martin Morgan

> Thanks,
> Glenn
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From murdoch.duncan at gmail.com  Sun Nov 30 17:43:25 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 30 Nov 2014 11:43:25 -0500
Subject: [R] cyclic dependency when building a package
In-Reply-To: <956EB8F8-DFD5-43D2-ACC4-640437AD16E9@me.com>
References: <956EB8F8-DFD5-43D2-ACC4-640437AD16E9@me.com>
Message-ID: <547B492D.6060105@gmail.com>

On 30/11/2014, 10:15 AM, Glenn Schultz wrote:
> Hi All, 
> 
> I am working on a package BondLab for the analysis of fixed income securities.  Building the package results in the following:
> 
> Error in loadNamespace(package, c(which.lib.loc, lib.loc)) : 
> cyclic namespace dependency detected when loading ?BondLab?, already loading ?BondLab?
> 
> 
> It occurs when I set the generic for the function mortgagecashflow.  Further if a function uses mortgagecashflow, similarly its generic, when set, causes the above error.  Other generics do not throw this error so I am quite sure it is mortgagecashflow.  The package and the code can be found on github.  
> https://github.com/glennmschultz/BondLab.git
> 
> I have been trying to figure this out for a couple of months to no avail. If anyone has familiarity with this issue I would certainly appreciate any help with the issue.
> 

I don't see why this would cause the error you saw, but when I look at
your DESCRIPTION file, I see:

Depends: termstrc, reshape2, ggplot2, lubridate, methods, plyr, grid, optimx

It's a good idea to strongly limit the number of "Depends" entries.
Each of those potentially causes a change to the user's search list, and
may break something.

It's much better to use "Imports" instead, because that makes the other
packages available to you, but doesn't put them in the search list.

Duncan Murdoch


From rmh at temple.edu  Sun Nov 30 18:01:29 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 30 Nov 2014 12:01:29 -0500
Subject: [R] Remove the border/frame in a dotplot()
In-Reply-To: <1915414038.2620031.1417298354946.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>
References: <1915414038.2620031.1417298354946.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>
Message-ID: <CAGx1TMDKjNEdqPz=U7cOK3oRGLi2kb1fpOaUSt1ZUVYi=zKj_A@mail.gmail.com>

st?phanie,

I believe you need all of this.  Look at it with a good editor and in
a monowidth font such
as courier to see the structure.

Rich

library(lattice)
library(latticeExtra)
dotplot(~ 1:10,
        par.settings=list(
          axis.line=list(col="transparent"),
          clip=list(panel=FALSE))) +
            layer({panel.axis(side="bottom", line.col="black", outside=TRUE);
                   panel.abline(h=current.panel.limits()$ylim[1],
                                v=current.panel.limits()$xlim[1])})

On Sat, Nov 29, 2014 at 4:59 PM, st?phanie braun <r-help at r-project.org> wrote:
> Dear listmembersI wouldlike to remove in a dotplot() the border/frame from the figure and only keepthe x- and y-axis. I can?t find a way to do this. bty="n" does notwork. Can somebody help? I include the r coding for my figure below. dotplot(plant_species ~ mean, data =botany,            aspect= 1.5,            scales=list(x=list(tck=c(-1,0)),y = list(tck=c(-1,0))),            ylab= "Plant species",            xlim= c(-1.1, 1.1),            xlab= "Electivity index",prepanel = NULL,            panel= function (x, y) {            panel.abline(v=0)            panel.xyplot(x,y, pch = 16, col = "black")            panel.segments(botany$lower,as.numeric(y),            botany$upper,as.numeric(y), lty = 1, col = "black")}
>
> Thank you!St?phanie
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Pradip.Muhuri at samhsa.hhs.gov  Sun Nov 30 18:01:32 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 30 Nov 2014 17:01:32 +0000
Subject: [R] R dplyr solution vs. Base R solution for the slect column total
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>

Hello,

I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
rbind(test, colSums(test))

I only want the total for the very last column.  I am struggling with this part of the code: rbind(test, c("Total", colSums(test, ...)))
I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?

Any hints will be appreciated.

Thanks,

Pradip Muhuri


####### The following is from the console - the R script with reproducible example is also appended.


mrjflag cocflag inhflag halflag oidflag count
1        0       0       0       0       0   256
2        0       0       0       1       1   256
3        0       0       1       0       1   256
4        0       0       1       1       1   256
5        0       1       0       0       1   256
6        0       1       0       1       1   256
7        0       1       1       0       1   256
8        0       1       1       1       1   256
9        1       0       0       0       1   256
10       1       0       0       1       1   256
11       1       0       1       0       1   256
12       1       0       1       1       1   256
13       1       1       0       0       1   256
14       1       1       0       1       1   256
15       1       1       1       0       1   256
16       1       1       1       1       1   256
17       8       8       8       8      15  4096



#######################  below is the reproducible example ########################
library(dplyr)
# generate data
dlist <- rep( list( 0:1 ), 4 )
data <- do.call(expand.grid, drbind)
data$id <- 1:nrow(data)
names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')


# mutate a column and then sumamrize
  test <- data %>%
       mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
       group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
       summarise(count=n()) %>%
       arrange(mrjflag,cocflag, inhflag, halflag, oidflag)


#  This works, giving me the total for each column - This is not what I exactly want.
    rbind(test, colSums(test))

# I only want the total for the very last column
rbind(test, c("Total", colSums(test, ...)))

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Nov 30 18:49:55 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 30 Nov 2014 12:49:55 -0500
Subject: [R] R dplyr solution vs. Base R solution for the slect column
	total
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
Message-ID: <4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>

try:

sum(test$count)


B.


On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Hello,
> 
> I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
> rbind(test, colSums(test))
> 
> I only want the total for the very last column.  I am struggling with this part of the code: rbind(test, c("Total", colSums(test, ...)))
> I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?
> 
> Any hints will be appreciated.
> 
> Thanks,
> 
> Pradip Muhuri
> 
> 
> ####### The following is from the console - the R script with reproducible example is also appended.
> 
> 
> mrjflag cocflag inhflag halflag oidflag count
> 1        0       0       0       0       0   256
> 2        0       0       0       1       1   256
> 3        0       0       1       0       1   256
> 4        0       0       1       1       1   256
> 5        0       1       0       0       1   256
> 6        0       1       0       1       1   256
> 7        0       1       1       0       1   256
> 8        0       1       1       1       1   256
> 9        1       0       0       0       1   256
> 10       1       0       0       1       1   256
> 11       1       0       1       0       1   256
> 12       1       0       1       1       1   256
> 13       1       1       0       0       1   256
> 14       1       1       0       1       1   256
> 15       1       1       1       0       1   256
> 16       1       1       1       1       1   256
> 17       8       8       8       8      15  4096
> 
> 
> 
> #######################  below is the reproducible example ########################
> library(dplyr)
> # generate data
> dlist <- rep( list( 0:1 ), 4 )
> data <- do.call(expand.grid, drbind)
> data$id <- 1:nrow(data)
> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
> 
> 
> # mutate a column and then sumamrize
>  test <- data %>%
>       mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
>       group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>       summarise(count=n()) %>%
>       arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
> 
> 
> #  This works, giving me the total for each column - This is not what I exactly want.
>    rbind(test, colSums(test))
> 
> # I only want the total for the very last column
> rbind(test, c("Total", colSums(test, ...)))
> 
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun Nov 30 21:14:17 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 30 Nov 2014 21:14:17 +0100
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
Message-ID: <3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>


> On 30 Nov 2014, at 16:51 , F?bio Magalh?es <fmagalhaes at gmail.com> wrote:
> 
> Duncan,
> 
> You are right, I've assumed precedence wouldn't break anything, but
> looking a little more into this issue it seems some people use filters
> based on this header and Gmail seems to be the only client that needs
> bulk precedence set to make unsubscribe link work.
> 
> I think the question boils down to putting an unsubscribe link on footer or not.

Yes, I see two main issues

(a) would people actually take the hint, whatever we put in the footer?
(b) there's a limit to how much claptrap everyone else want to see in each and every post

However, what about just doing something like

> ______________________________________________
> R-help at r-project.org mailing list. ADMINISTRATIVE INTERFACE (INCL. UNSUBSCRIPTION) AT
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

(Not actually using all-caps of course)

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rshepard at appl-ecosys.com  Sun Nov 30 21:28:34 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sun, 30 Nov 2014 12:28:34 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
Message-ID: <alpine.LNX.2.11.1411301224370.28168@localhost>

On Sun, 30 Nov 2014, peter dalgaard wrote:

> (a) would people actually take the hint, whatever we put in the footer?

   Only some actually read everything and look for help at the bottom of the
message. Since Microsoft users almost always top post I wonder if they even
see the bottom of a message from a mail list.

> However, what about just doing something like
>> ______________________________________________
>> R-help at r-project.org mailing list. ADMINISTRATIVE INTERFACE (INCL. UNSUBSCRIPTION) AT

> (Not actually using all-caps of course)

   Or, just a line with

TO UNSUBSCRIBE: see https://stat.ethz.ch/mailman/listinfo/r-help

   Uppercase to catch the eye of the reader.

Rich


From Pradip.Muhuri at samhsa.hhs.gov  Sun Nov 30 21:48:11 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 30 Nov 2014 20:48:11 +0000
Subject: [R] R dplyr solution vs. Base R solution for the slect column
 total
In-Reply-To: <4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
	<4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>

Hi Boris,

That gives me the total for each of the 6 columns of the data frame. I want the column sum just for the last column.

Thanks,

Pradip Muhuri



-----Original Message-----
From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
Sent: Sunday, November 30, 2014 12:50 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org
Subject: Re: [R] R dplyr solution vs. Base R solution for the slect column total

try:

sum(test$count)


B.


On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Hello,
> 
> I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
> rbind(test, colSums(test))
> 
> I only want the total for the very last column.  I am struggling with 
> this part of the code: rbind(test, c("Total", colSums(test, ...))) I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?
> 
> Any hints will be appreciated.
> 
> Thanks,
> 
> Pradip Muhuri
> 
> 
> ####### The following is from the console - the R script with reproducible example is also appended.
> 
> 
> mrjflag cocflag inhflag halflag oidflag count
> 1        0       0       0       0       0   256
> 2        0       0       0       1       1   256
> 3        0       0       1       0       1   256
> 4        0       0       1       1       1   256
> 5        0       1       0       0       1   256
> 6        0       1       0       1       1   256
> 7        0       1       1       0       1   256
> 8        0       1       1       1       1   256
> 9        1       0       0       0       1   256
> 10       1       0       0       1       1   256
> 11       1       0       1       0       1   256
> 12       1       0       1       1       1   256
> 13       1       1       0       0       1   256
> 14       1       1       0       1       1   256
> 15       1       1       1       0       1   256
> 16       1       1       1       1       1   256
> 17       8       8       8       8      15  4096
> 
> 
> 
> #######################  below is the reproducible example 
> ########################
> library(dplyr)
> # generate data
> dlist <- rep( list( 0:1 ), 4 )
> data <- do.call(expand.grid, drbind)
> data$id <- 1:nrow(data)
> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
> 
> 
> # mutate a column and then sumamrize
>  test <- data %>%
>       mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
>       group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>       summarise(count=n()) %>%
>       arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
> 
> 
> #  This works, giving me the total for each column - This is not what I exactly want.
>    rbind(test, colSums(test))
> 
> # I only want the total for the very last column rbind(test, 
> c("Total", colSums(test, ...)))
> 
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sun Nov 30 23:50:41 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 30 Nov 2014 17:50:41 -0500
Subject: [R] R dplyr solution vs. Base R solution for the slect column
	total
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
	<4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>
Message-ID: <8C1EDBE9-35B8-47F3-912F-3E3C723243E5@utoronto.ca>

No it doesn't ...
consider:

test <- data.frame(first=c(1,2), second=c(3,4))
test
  first second
1     1      3
2     2      4

sum(test$second)
[1] 7




On Nov 30, 2014, at 3:48 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Hi Boris,
> 
> That gives me the total for each of the 6 columns of the data frame. I want the column sum just for the last column.
> 
> Thanks,
> 
> Pradip Muhuri
> 
> 
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
> Sent: Sunday, November 30, 2014 12:50 PM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect column total
> 
> try:
> 
> sum(test$count)
> 
> 
> B.
> 
> 
> On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
> 
>> Hello,
>> 
>> I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
>> rbind(test, colSums(test))
>> 
>> I only want the total for the very last column.  I am struggling with 
>> this part of the code: rbind(test, c("Total", colSums(test, ...))) I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?
>> 
>> Any hints will be appreciated.
>> 
>> Thanks,
>> 
>> Pradip Muhuri
>> 
>> 
>> ####### The following is from the console - the R script with reproducible example is also appended.
>> 
>> 
>> mrjflag cocflag inhflag halflag oidflag count
>> 1        0       0       0       0       0   256
>> 2        0       0       0       1       1   256
>> 3        0       0       1       0       1   256
>> 4        0       0       1       1       1   256
>> 5        0       1       0       0       1   256
>> 6        0       1       0       1       1   256
>> 7        0       1       1       0       1   256
>> 8        0       1       1       1       1   256
>> 9        1       0       0       0       1   256
>> 10       1       0       0       1       1   256
>> 11       1       0       1       0       1   256
>> 12       1       0       1       1       1   256
>> 13       1       1       0       0       1   256
>> 14       1       1       0       1       1   256
>> 15       1       1       1       0       1   256
>> 16       1       1       1       1       1   256
>> 17       8       8       8       8      15  4096
>> 
>> 
>> 
>> #######################  below is the reproducible example 
>> ########################
>> library(dplyr)
>> # generate data
>> dlist <- rep( list( 0:1 ), 4 )
>> data <- do.call(expand.grid, drbind)
>> data$id <- 1:nrow(data)
>> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
>> 
>> 
>> # mutate a column and then sumamrize
>> test <- data %>%
>>      mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
>>      group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>>      summarise(count=n()) %>%
>>      arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
>> 
>> 
>> #  This works, giving me the total for each column - This is not what I exactly want.
>>   rbind(test, colSums(test))
>> 
>> # I only want the total for the very last column rbind(test, 
>> c("Total", colSums(test, ...)))
>> 
>> Pradip K. Muhuri, PhD
>> SAMHSA/CBHSQ
>> 1 Choke Cherry Road, Room 2-1071
>> Rockville, MD 20857
>> Tel: 240-276-1070
>> Fax: 240-276-1260
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


